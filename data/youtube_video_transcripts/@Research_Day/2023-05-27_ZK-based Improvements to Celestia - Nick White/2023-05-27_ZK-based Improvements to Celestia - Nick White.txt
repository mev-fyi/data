foreign what's up guys hi I flew in from Hawaii this morning stoked to be here um today I just want to talk about some ideas we have for improving and argument augmenting the Celestia protocol uh using ZK technology so quick summary I'll talk a bit about the background of Celestia that's relevant to understand some of these improvements and then I'll go into each one of them and I'm only highlighting three they're actually more and there are lots of different ways we want to improve Celestia so don't think that this is the only things we're thinking about um so first of all what is Celestia the origin of Celestia is this white paper lazy Ledger uh published in 2019 by one of our co-founders Mustafa and in that he described this goal to build a minimal modular and scalable data availability layer so what that means is when we say minimal we want it to be minimal amount of overhead to verify so you shouldn't need much bandwidth you shouldn't need much state or storage and you shouldn't need much like uh execution to verify the chain and the end goal is really that everyone with a smartphone should be able to verify the celestial blockchain because that's how you reach maximum decentralization um modularity it comes to this idea that actually you can separate execution from consensus and data availability so Celestia rather than uh you know verifying that transactions in a given block are valid just verifies that the transactions are available and then finally the the piece of unscalability is that um actually in 2018 most of I wrote this paper about data availability sampling which is the first proposal for how you can build a blockchain that where the block size and the throughput scales are the number of nodes in the network and so that is what to me scaling like that's the definition of scaling is that you can have bigger and bigger block sizes with more and more participation like a standard monolithic chain has a fixed block size and once you reach that limit you can't go any further um some relevant details of how Celestia works for those of you who might not be familiar um data availability sampling requires that you build your block in a very specific way so you have to take the original transaction data and you divide it into these chunks and then you extend these chunks using read Solomon Erasure coding into this extended block and then nodes that are sampling choose randomly uh among that block and each time they sample successfully they have a higher confidence that the whole block data is available and specifically the block data is also mercolized in a special way so each row and column of this 2D uh square is miracleized into row and column roots and then those are merkelized into this top level data root so if you're if you're a Roll-Up and you're trying to prove to a client that the data that you published has actually been published if they have sampled the Celestia block all you have to show them is that your data was included somewhere within the data root so that's all the background that you need to know about Celestia and we can move into the more interesting stuff what's really exciting is that most of the work uh is done so we've built out data availability sampling we have block reconstruction we have bfps batting coding fraud proofs which I'll share more about later we have a namespace Merkle tree which enables people to query data according to like specific applications and we've tested this now on the vlogspace race with you know over a thousand light nodes and lots of things but even though we're shipping Celestia has not done this is just V1 this is just the start and really there's a lot of improvements that we have in the works and ideas that we we want to build to make Celestia even better so that's what this talk is really about so quick note like I know very very little about CK um basically my mental model is what you see on the right which is like I understand that you can generate the proof for the public input and witness and then I know you can verify it with the proof and the public input that's pretty much my mental model there's people in this audience who know a lot more than me um and so that's just a disclaimer um so if you came to this talk hoping that like you learned something interesting about ZK sorry it does not not talk for you um so the first Improvement that I think would be very very interesting is proving the correctness of the encoding of the Celestia block data so the the current way that Celestia works is that um a block producer uh can in like makes the extended block they construct the block but they could do it in a malicious way that actually doesn't follow proper encoding and so you couldn't actually reconstruct the block if you wanted to and so to solve this problem we have what we call a bad encoding fraud proof so if a full node in Celestia sees that this is happening they will generate this Rod proof and circulate it to light nodes and they'll know not to trust that block the downside of this approach uh is that even though it's trust minimized you have the same sort of latency as like uh you know an optimistic roll up so you have to wait for this frog proof window to elapse before you can consider a block final so a lot of people complain about this I think I think it's it's true like this latency is not really desirable so alternative solution and that you see in protocols like ethereum with tank sharding also at Veil is to use kzg commitments to include encode and extend the block data and what's nice about that is you get correctness out of the box so you don't have to there's no fraud proof like you get the commitments and you know that they're valid um the downside is that at least in our research and sort of like going deeper into kzg we realize that it's not really practical at this stage to use because they're very expensive and slow the kg commitments are very expensive and slow to compute so at least for now it doesn't seem like it's ready for prime time um and so a potential solution that we're thinking about is actually to to stick with read Solomon encoding but then actually add this layer of ZK proving on top so essentially what you'll do is you'll extend the block data in the normal way but in parallel you'll also generate a ZK proof that you know given this original transaction data if you do the read Solomon encoding and then the miraculation you get this specific data route so you can kind of prove the correctness of the code and so um what's cool about this is that you could still kind of like you could it's kind of like an optimistic roll up with a ZK finality so you could have uh you know produce a block normally and then rather than waiting for the entire fropproof window you get this ZK proof that the encoding is correct so you don't have to wait that whole time um some other questions is like is this actually better than kcgs is it will it be cheaper will actually be faster I think there's possibility that will be and um also what what proving system is best to use so we've talked a lot with the research team for example who know a lot about Starks and it seems like there also could be this cool overlap because Starks rely on a lot of like Reed Solomon uh math to prove uh their validity so there could be some kind of cool overlap there a second really cool Improvement that we're discussing is building a ZK friendly data route so um as I mentioned earlier when you want to prove that um you know the data you publish is actually included in the Celestia and is available you need to like you know give show people that it's included uh in the the root the data root the problem is that a lot of ZK roll-ups want to do that um in circuit and the issue is that we build our data route using shot 256 and that's a very expensive operation to prove inside of a ZK circuit and so it's kind of like a really bad potentially bad user experience for CK roll-ups a naive solution is you could construct two data routes so you can have the normal shot 256 one and then you could use like Peterson or Poseidon hashes to build a ZK friendly version of the data root but the problem there is that once you have two data routes that are separate you have to sample over both of them and so you're kind of like fragmenting the network either increasing the amount of work that a node needs to do to verify or you're kind of fragmenting the security so it doesn't really work unfortunately but the ZK inspired solution is that actually you could build um so you use the normal Celestia shaft 256 data root and then and you sample over that one and then in parallel you build a uh ZK friendly data route using something like Poseidon or Peterson and then but you prove you you generate a ZK proof that if you take the same block data and you miraculize it like those two roots are basically committing to the same block data so they're equivalent so now as a ZK roll up I can actually prove to you that the the data that I'm committing to was included in the ZK friendly route and then you just verify that the ZK friendly group is equivalent to the data root that you sampled like the normal Celestia data root so this would solve that problem um the question some open questions are like which proving system would be most cost effective like as we said like you know doing shot 256 in the ZK circuit is really expensive it's like building you know these these uh data routes will be very very expensive um so this will be like a costly thing to do and also how will this be funded like how do you share this cost amongst all the different ZK Roll-Ups that might use this service and I think there are some really cool ideas around um so like proving networks approving services that could be helpful there and I want to give a shout out to Mina and Miss zero also for sharing feedback on this idea um and last but not least a third idea of how to improve Celestia is some is a feature that a lot of people like this I would see this as like the number one or one of the most common complaints I get from people about like Celestia's design is that we don't have a way to support uh trust minimized bridge natively in the protocol because Celestia is so minimal there is there's no smart contracts there's like basically no execution on chain that means you can't verify you can't run a verifying Bridge basically and so um this is kind of a shame because one of the big uh selling points of Roll-Ups is that you can have trust minimized Bridges but if Celestia has to rely on things like axillar or hyperlane or I don't know like uh different kinds of the like trusted Bridges to get uh the Celestia token up to the Roll-Ups it kind of it just doesn't quite feel right um and so an IU solution uh shout out to John is uh to just enshrine a specific roll-up into the Celestia protocol and um then you could Bridge the Tia into that roll up and that roll up can Bridge into all like the rest of the ecosystem essentially um the downsizer actually aren't that many like you if you design this in the right way you know it could be very very minimal potentially but it could could have some complexity or like undesirable amount of state or execution you need to support but the the really big one is is basically that it really compromises credible neutrality in our mind and that's another big I would say value and design goal of Celestia to be incredibly neutral so um what that means is we want to make sure that we're not favoring any specific protocol outside like we're just a data availability layer and that's it we don't want to start delving into oh we want to do settlement oh we want to start like launching on roll ups we want to be just a data availability layer and so if you if you enshrine a settlement layer you enshrine this bridge you start to compromise on that so a few days ago Mustafa posted this um idea on our Forum which is how can we we can solve this problem in a really minimal overhead way using ZK Roll-Ups basically so the idea is that at the celestial level we create a new transaction type where the verification key of ezekia program is like the address so you could send funds to that address and then if you want to spend funds from that address you have to provide it a valid proof and that proof would basically be a like which would show that so like that there would be a ZK roll-up associated with this address and your proof would say on the ZK roll up I made a valid withdrawal transaction with this ID and at this block height it's still unspent and so let me spend this many funds out of the um out of this address so how this would work in practice is that you know for example you would just send a deposit transaction of Tia to this wallet that is associated with this uh verification key and then the roll up would see that and credit you Celestia tokens on the roll up from there you can Bridge wherever you want um and then when you want to go Bridge back down to Celestia you send a withdrawal transaction on the ZK roll up maybe it's a burn or I don't know whatever it is and then you prove you generate a proof that you you did that and you show that to Celestia and that allows you gives you the right to basically transfer funds from the roll-up address back to your address on Celestia um the beauty of this is that it it's extremely minimal um it could potentially be stateless um and it's also credibly neutral so we're not enshrining anything we're just adding a new functionality to the Celestia protocol some there are some open questions so like one of the big ones is which proof system should we support some people think it should be like Roth um because it seems like sorry ethereum is moving in that direction and in some ways some people made the argument that like choosing a proving system will be sort of like uh not credibly neutral but we the way we think about this is that hopefully um using recursion you could prove like let's say you're using your ZK roll up whatever uses a different like proving system you could prove your ZK roll up within whatever proving system Celestia natively supports so hopefully that's not a problem and also at the end of the day like every blockchain for example chooses a specific you know way of uh like like signature scheme for example and like that's kind of inherent to adding this kind of functionality another question is like should we include a state commitment corresponding to this verification address because that could make things a lot easier for the implementation although it does add a slight amount of state to each one of these addresses um and I want to give a shout out to Sovereign labs and succinct for feedback on this idea um that's that's pretty much it I just have a few other ideas like that I want to throw out there for ways that we want to improve Celestia going forward one is we want to increase censorship resistance so ideas like multiplicity from Duality come to mind there because I think the data availability layer should be as censorship resistant as possible if it's going to fulfill its role well and also adding like kind of in protocol and maybe support like protocol and building from skip is also a really interesting idea that we can um I think would be a great Improvement to Celestia and adding restaking support for Celestia would be really cool then we could for example launch um shared sequencer networks that are partially secured by the Celestia token um and those are just a handful of things there's also another ZK idea which is the quantum gravity Bridge generating like a ZK version of that so it's very easy to verify um so anyway uh I just want to reiterate that Celestia is never done and I think that um you know these are just a few of the improvements we have on top of my mind I didn't mention a lot of things around scalability and networking and like the core protocol um but ultimately our vision is so ambitious that I think it's going to be um an ongoing effort of research and implementation to um like be the best most minimal modular scalable da layer and we're always grateful for new ideas so those of you who are listening if you have other ideas of how we can improve the protocol you have ideas how we can solve these problems I'd love to hear from you and you always welcome new contributors so thank you very much and this is this is a link to the Forum and that's my my Twitter I would love to talk to you guys so 