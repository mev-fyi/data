foreign I work for espresso systems I'm an engineer mostly working on consensus um but I'm gonna give an overview of how we're trying to solve the decentralized sequencing and scaling uh consensus problems so quick overview of what I'm going to go over um first I'm going to go over like the flow of a transaction through Hotshot Hotshot is the name of our decentralized sequencer which we're developing um and then I'm going to talk about some of like the technical contributions we made to like improve the scaling of our consensus um our goal is to be able to scale to like tens of thousands of nodes because we think if there's a successful decentralized sequencer it's gonna attract a lot of people like a lot of people are going to want to be a validator um and it's also going to be permissionless so and improved mistake so it will be open to many people so it needs to scale um and then I'm going to go over some of the like open questions that we still have that we're still researching that I think might be interesting to other people um and we don't have a solution for so I think Josh did a pretty good job explaining like what a decentralized sequencer is um especially focusing on this first like top left block about you know buildings and stuff but I'm going to focus primarily on the Hotshot so we can swear block here um but just very briefly to start in our system like transactions start from a user and they flow to this Builder Network which we leave the details out the builders essentially bid the proposer to include their bundle and from there like this bundle enters our system in our system we run uh a version of Hot Stuff consensus um I'll discuss like why we made that choice and a few details about it in the next slide um but in parallel We Run The Block commitment through consensus to agree in the ordering and we submit the block to the data build anywhere um and hot chocolate consensus takes uh like three consecutive uh corn certificate so like you have to get Quorum on three consecutive locks for one of them to be committed so the first thing that chain would be committed at that point finally once everything's committed then we can send like the new state to our sequencer contract so they're like checkpoint into the L1 as well as the block data from the data availability layer to the L2 Roll-Ups and approvers which will then send to their own roll-up contracts right there could be many L2 Roll-Ups in this case sequencing for all of them at once um and these roll-up contracts can read the state from our sequence so now I'm just going to go over like a few of the technical hurdles that we faced and sort of like the design principles of the system so like I mentioned we want our system to scale and our consensus specifically to scale to like many many validators um so one or two desirable properties that we want are optimistic responsiveness and linear communication complexity in the best case it's not possible to not have some quadratic worst case for bft consensus so optimistic responsiveness what does that mean it means we can finalize blocks as quickly as the consensus algorithm can run one of the open problems will discuss like why that's a bit of an issue um and then linear communication is obvious that like once you start having introducing quadratic communication with 100 000 nodes like consensus is going to run way too slowly so to achieve this we chose a version of hot stuff which we've modified so hot stuff is a permissioned consensus protocol which means it's like designed around like a known set of validators but we want a permissionless proof of stake um protocol so we made some adaptations uh to the protocol to achieve that but the reason we chose hot stuff is that it has these properties it is optimistically responsive and optimistically responsive and it can be made to be linear in the what is linear communication in the optimistic case um but the first challenge we had is view synchronization so this is a problem where to run consensus like all of the nodes need or all the validators need to be in the same view at the same time they all need to be voting on the same thing in the same window of time so a Hot Stuff requires some mechanism to make that happen um in like the original paper for hot stuff like this is a an N squared process that needs to run um but there's been a lot of like Recent research in that and we chose a protocol from naor and khadir I may be saying that wrong but we call it nk20 for short view synchronization which is constantly NC and linear communication on top of that we add like a um a special timeout certificate which allows like progress to continue to be made without triggering view synchronization with just one timeout if there's two times in a row then we trigger this profile this means that we have better latency in the case where like there's one validator offline or that that's malicious and doesn't uh add to the chain uh the next step is that like we have to adapt this permission protocol to work in um a permissionless settings so that means we need a stake table and we need to come up with a different scheme for Quorum certificates we can't just simply use like a aggregate signature so what we do is we have the state table stored as a persistent Merkle tree which will dynamically change like as we go through views and people add themselves to it and then on top of that like our horn certificate has a bit Vector of all of the um validators which signed um in an aggregate signature so the bid Vector is all of the people that signed that signature um yeah so the next thing we had to do is like how do we actually solve this problem with data availability without slowing down consensus right the slowest part or like the biggest hindrance or throughput is transmitting all of the block data to all of the participants um so what we do is we separate out EA from consensus which is a very common thing to do um and we combine like two different approaches the first is we use a small committee which we send the entire block data to so in the optimistic case like this committee will always have the data and be very rapidly retrievable the problem is is that we take like a more pessimistic model on security in that we believe that like a adversary could potentially bribe any committee right because the committee is much smaller than the corruptible stake in one third of the network so we want to be resistance against this type of primary attack so we introduce also this vid encoding so vid stands for uh verifiable information dispersal so each validator is sent like an Erasure coded piece of the data um and if enough like if the threshold of the validators receive this they can reconstruct the data um from those erase recorded shares so what we do is we don't allow um validators to vote on any um proposal which references a form certificate that does not have their data availability so that they haven't seen the vid share or a certificate that proves that the data is available and like by combining these two approaches like we can get the everybody to agree that the data has gotten out very quickly with the vid shares but also we have this very fast in most cases committee to ask for the data so we kind of maintain this very good optimistic case but we don't sacrifice in the security which is the design goal of the system and then finally like to tie all this together we need a source of Randomness um like how do we choose a committee how do we choose a leader um and to do this we come up with our own uh like random Beacon scheme which is um we take like I prior blocks uh signature set um and we apply a delay function to it so I after a certain amount of time it knows or validators can calculate um a new random seed and we parameterize this delay function so that it takes longer than the timeout for one view so a leader can't bias which signatures they include to like make themselves a leader more often or an adversary the leader yeah and then finally like to speed everything up we introduced like a Content distribution Network approach so we have some like dedicated Hardware that can get all of this information out very quickly but we can't rely on that right that would be a very clear source of centralization which we don't want um so alongside of that we also gossip everything in a peer-to-peer way so that let's say the CDN is trying to censor somebody or it just goes down like AWS is out or something like that well we have we'll have this slow peer-to-peer backup and things will slow down but progress can still be made and nobody can be censored yeah so I think each of these could probably be like five ten minute talk on its own um and then people on our team probably more than happy to talk about any of them they interest you so now I'm going to move on to like some more open questions that we have um the first is around proposal Builder separation incentives and optimistic responsiveness so like the goal is right we want the network to move as fast as possible the problem here is that well if the proposer is running this auction or like waiting for the builders to submit like a really juicy or a very high fee or high Mev block to them like they're incentivized to essentially use all of their a lot of time as leader to wait for like the best value to come in like the best thing for them so that kind of defeats the whole purpose of being optimistically responsive like every block is going to take very near to the timeout for that round and we don't want that so we've come up with a few ideas but nothing like is fully fleshed out to solve this um we've talked about like having a time-based leader rotation where like a leader can lead from multiple views in a row until a timer is hit and then we do a leader transition the problem is is this makes a lot of things in the system like much more difficult we haven't before we fleshed out how that might work like for example at the end of this time where like how do you synchronize all of the validators to send their votes right they don't they don't necessarily know who the next leader is going to be some people may think we've moved on to a new leader some people might think that there's still more time left in the current rain um the other idea is kind of like the flip side of this coin which is like okay it will allow the block to to grow and accept many many bundles from proposers this might actually achieve the same throughput but the still the latency like how quickly things can be ordered will be exactly the same for each given transaction so the next open question we have is also around proposer Builder separation but this time it's with data availability so you may notice that I said that the consensus is running in parallel with our data availability solution well that can be a problem right because the Builder of course doesn't want to reveal its block before it knows that it's going to be committed right because you know if the leader fails and the next leader can steal the Mev from that block or even worse right two malicious leaders can collude to do this on purpose um so we're trying to come up with a way to con that essentially solves this we call like a fair exchange problem where like the the Builder has you know this data that the consensus Network needs and the sequencer Network needs and the sequencer network has this commitment which that you know they don't want to provide until they've seen the block um or else we'll we don't want to commit a block header that we don't have the data for so we've come up with like a few different ideas but none that fully solve the problem I think so one is like adding a partial extra round where like nodes will agree to okay we'll lock on this a quorum certificate that includes that block even though it's not committed the problem with this is that a malicious leader can like essentially leverage this and be like okay you nodes already agreed to vote Yes on the next round but you haven't seen the data so all only send the data to enough people that a quorum will be able to be formed but then the data isn't actually available not enough people actually got the data because of these optimistic voters um so that was one idea we had that doesn't I don't think work um our other idea is to use like cryptographic Primitives right we can use like secure Hardware or threshold signatures so that the data is like cryptographically revealed after it's committed to the sequence um there's one problem with the threshold signature approach is that we believe that there's an incentive for all of the um validators to collude right they don't really have an incentive not to share their their key to reveal the data right like if they wanted to scheme to steal Mev from the proposers there's nothing really stopping them um like and other validators don't necessarily lose it's I think it's debatable like but that's our view on it um and then the final solution is to use like zero knowledge proofs where each transaction signature can be removed by the proposer and rolled up into a ZK proof which proves that like each transaction in uh the bundle was signed by the correct um party um and that way nobody can reconstruct the block because they don't have the signatures even if it's revealed they only have the CK proof in that way that it sort of provides a little a barrier for people to try and steal I think that's probably our most promising approach um and so the last sort of problem we have is that if you're paying attention you probably noticed that you know I've been saying linear communication all the time but we use a bit Vector of all of the nodes which signed a corn certificate well that's not actually linear because the length of this Vector grows in n and it's included in every single uh proposal so this is N squared communication technically um we sort of hand wave around it for validator sets which are like less than 10K because the size isn't huge it's only like a kilobyte and a quarter for 10 000 nodes but it gets very large when we're talking about a hundred thousand nodes so one way you could solve this is by using a snark proof to make this a constant size or a smaller size the problem is is then you have a bottleneck where the proposer the leader needs to calculate this proof and even if we use dedicated hardware for this phrase we have some server that's really good at calculating the proof it's still going to like still potentially going to be the slowest part of the system so that's not particularly desirable another potential solution is using the threshold signatures but this is also challenging because um the network is constantly refreshing at stake and so we have to recalculate these things um and yeah this can also be quite expensive to calculate all right so that was all that I wanted to cover lots of sort of different open topics of research be happy to connect with anybody if people are interested in this sort of thing um thank you [Applause] 