foreign [Music] and welcome to the hack and Fest Workshop storage and retrieval and file coin part one joining us today is Matt Hamilton who will be taking us through this session and with that I'll pass over to Matt to get the session started hello thanks thanks a lot so yeah my name is Matt Hamilton I'm a developer Advocate with protocol Labs specifically working on fvm at the falcoin virtual machine and the point of this uh series and this is part one of a series of probably two maybe three sessions going forward is to look in more detail about storage and retrieval on falcoin specifically with a view of uh storage and retrieval initiated from a smart contract using fem so how can you write a smart contract in solidity and get it to instigate some storage on filecoin so hopefully this uh talk will give you a little bit more information on the options you've got available for how you can actually make that happen so as a quick uh recap here um you may have seen this before on previous talks especially in Sarah tm's talk uh that was on Friday uh regarding falcoin and fem so the Falcon master plan is build the world's largest decentralized storage Network we're pretty much uh uh on our way there we've we've done that we're continuing to build out the network is something original about 12 or 13 exabytes of data in size so it's about the equivalent of about one percent of the total data center storage capacity is available on filecoin step two is onboard and Safeguard Humanities data so that is bringing on a lot of data from various places things like scientific data sets um archival stuff um nfts all this sort of stuff that we want to store on there and then step three is bringing compute to the data and enable web scale apps now that's kind of the area that we're going to be focusing on today and that is regarding using fem to do programmable storage and what I'm going to do is in this talk I'm going to show you two uh different approaches to getting data stored on filecoin from Fem and those can serve as a basis for building other things on top and those other things will have a talk of part two of this talk um my colleague longfei is going to do a talk on um using these these tools for things like self uh replicating storage and self-healing storage so we're going to just focus on the basics in this talk here um and sort of where we kind of go from there so right at the bottom we've got kind of like ipfs which is a peer-to-peer network is slightly separate from filecoin but is often used as a sort of staging layer for filecoin and for pinning data so that's why that's mentioned there layer zero Parkour in the storage layer layer one that we're at now fem um compute over State and then layer 2 will be building storage related uh damps on top of that as well so storing data on filecoin my colleague Sarah created this great little flowchart and this is available in the cheat sheet that we've created the hackathon cheat sheet which will be linked to at the very end or if you search for fem uh cheat sheet hackathon cheat sheet you'll find it on on GitHub no doubt but there is a link at the end so looking at this we're starting with the with the the point of view of I want some storage so I want to store some data now there's two ways I can go about it um programmable storage or programmatic storage or non-programmatic storage so non-programmatic storage uh we can go down the sort of the blue side of this I'm not going to cover that today that is doing storage without using fvm and this has been something that has been available for a while now on filecoin and using on-ramps like web3 storage Lighthouse Etc directly through say an HTTP API and storing data onto filecoin that way I'm going to look at the other side which is using programmatic storage so the idea here is I want to instigate some storage happening from a smart contract now there's two different approaches depending upon when you're looking at a smaller amount of data or a larger amount of data and that boundary is roughly around about the four gigabyte size at the moment so the reason for that being is that storage providers on the network of which there's about three and a half thousand storage provider systems on the network storage providers are generally looking to store large amounts of data the unit they work in called sectors typically are 32 to 60 or 64 gigabyte sectors so they are generally looking for data that will fill one or more sectors think of it a bit like they are like the wholesalers of the storage if you have a small amount of data say you've got your 50 kilobyte monkey jpeg then the storage providers are not going to be interested in storing that directly it's too small data for them to store efficiently within a storage deal within a sector they would have 50 kilobytes of data and then pad out an entire sector out to 32 gig which is um you know a waste of a waste of storage for them and not efficient for them either in terms of compute or in terms of economics for the system so if you're using a small amount of data then you'd want to go via an aggregation service so I'm going to talk about filecoin data tools here which is one of the aggregation Services um in in the system and I'm going to talk about direct deal making so we're going to look at storing small data and we're going to look at storing large data and how you can go through these two areas from this flowchart so to kind of summarize the two different approaches here if you're going less than four gig a data you go via an aggregator if you're going larger than four Giga data you're going for a direct deal with an aggregator typically the retrievability is immediate because you can retrieve directly from the aggregator initially and then via filecoin once the deal is made if you're doing a direct deal typically you're not able to access the data until a deal is made or until the aggregator at least has picked up that contract and published the storage deal in terms of flexibility with an aggregator your data is combined with a load of other data and stored on the network so stored as one storage deal so you would be using the storage deal parameters that are set by the aggregator so in terms of the lifetime of the storage will be set via the aggregator if you're doing a direct deal you can set those parameters yourself so you could say when you want it to start end how much you're willing to pay for example you can set those yourself in terms of complexity going by an aggregator is simpler because the aggregator handles a lot of these and you'll you'll see that a little bit when we when we go on further and we look at the um the commands used to actually instigate this with the direct deal the complexity is a bit more advanced but you have more flexibility there so it's that typical engineering trade-off between Simplicity and and flexibility there so technology for the aggregator what I'm going to show you today is filecoin data tools uh these are the tools there is a service called Estuary and filecoin data tools are the next evolution of the tooling behind Estuary so far coin data tools allows you to actually spin up effectively your own version of estuary yourself so Estuary version 2 will be based upon this tooling set known as Falcon data tools but Falcon dead tools you can think of as a as a super set of what Estuary did but the part that we're looking at the moment is uh kind of similar to what some people may have covered with Estuary before and if you're doing larger than four deal four gigabyte deals what I'm going to demonstrate today is a thing called the client deal contract so to set this in scene let's have a quick look at what the actual deal flow is and looking at this you might think it's quite complicated that is the case and that is why I'm kind of showing you two approaches to dealing with this now the reason it seems quite complicated is that remember filecoin is designed to store vast amounts of data for a long period of time so a lot of the process actually happens off chain because you are dealing with gigabytes uh terabytes petabytes of data and you know that is not something that is efficient to process on-chain so typically a lot will happen off chain and then the final proofs of the data storage are actually put on chain so with the deal flow typically a client puts some funds in escrow with the storage Market actor which is a smart contract built-in smart contract on the blockchain the client then uploads a car file to a web server somewhere a car file is an archive file think of it a bit like a zip file but it is the the file format that is used within filecoin for aggregating and storing data it actually stores data as a um as a dag a graph which means that you can access individual parts of it as well via hashes the client sends a storage deal proposal to the storage provider the storage provider is running some software called boost with the URL of the car file then step four boost checks that the client has enough funds if so boost will accept the storage deal step six boost will download the car file from the web server publish the storage deal on chain and then the client can check that it's on chain now that entire process may take hours it may actually take days for that to actually happen because storage providers don't necessarily uh publish storage deals immediately when they come in depending upon the size they may wait a while until they have enough storage deals to fill a sector so it might be that you're waiting a day or two for that whole flow to take place so just sort of setting expectations this is not a flow that happens in in seconds this is a flow that happens in in hours typically so with aggregation um this is a diagram done by the falcoin data tools team uh shows you a bit about aggregation so historically aggregation has happened off chain so services like Estuary web3 storage uh Lighthouse have typically been off chain but a number of parts of that now as a result of fem are able to move on chain so filecoin data tools here um we're gonna actually I'm gonna actually show you how you can access that um from on chain so typically what happens is a file is uploaded to a service called Edge that is part of filecoin data tools Edge then will take these multiple files put them in a bucket uh where it is aggregated together the files are then stitched together to form a collection of data segments it generates a proof and I'll talk about that uh towards the end what that proof is used for and then creates a car file which is then passed to a tool called Delta which is another part of bellcoin data tools that actually will make the storage deal so Edge is think of edge as the the HTTP microservice that you could interact with via HTTP and it does certain things like aggregation and allows retrieval as well of the data before passing it to Delta for storage so I've got two demos I'm going to do now um one a direct deal uh going through and one using an aggregator so these are two different approaches like I said for a large amount of daily data in the case of direct deal or a smaller amount of data for an aggregator now I'm actually going to demo these on a local net that I'm running here on my laptop so with that local net I can actually make a much much smaller deals so I can make deals in the in the range of sort of kilobytes of size uh because I'm running this locally because the sector size that I'm running locally is two kilobytes like I said if you're running on uh the calibration test net or mainnet then the sector size is 32 or 64 gigabytes in size so much larger but for the purposes of this demo I'm using this local net it means it can go through much quicker um and I can kind of show you these things and show you both sides both the client side and the storage deal side so if you want to get started with localnet there's a GitHub repository you can go to and I will put that in the chat here so that's a repository you can go to that will allow you if you've got uh Docker installed then you can clone this repository and go into the directory type Docker compose up and it will set up a completely brand new blank filecoin Network for you running locally on your computer and you can connect to that with tools like metamask and interact with that directly right so there's instructions there on how to get that all set up so um let's see where do we need to go from here so I have actually done this I've got this running uh locally and we have here this instance here um this is just the log files kind of going past for the for Lotus uh Lotus is the name of the software node the reference software node for filecoin um and that is that is running here locally on my laptop so this is just watching the the log files Go by now the other part that I'm going to use for this is um a um uh starter kit so we have here the fevum um I haven't actually got it loaded here Urban hard hat starter kit and that is available there so this uh hard hat starter kit has in it a contract here it has the deal client contract that we're going to be running here so I have actually deployed this deal client uh to my local network so I did that I I ran yarn hard hat deploy Network localnet and it has deployed it to my local network and I have this uh contract running locally so now that it is running locally I can interact with it I have a Boost running so when I ran that Docker image one of the things it set up was a thing called boost and boost I can access locally and I can see the storage deals that are on here now for the sake of brevity I just ran a storage deal about 30 minutes ago that is run on the network here so I can show you here with that hard hat starter kit I can run a command now you'll see a little bit here when I illustrate and say it's a little bit more complicated you have to pass a lot of the parameters in yourself so I'm running this make deal proposal um method uh here um and or task rather in hard hat it is connecting to the contract that I have deployed that is at this address here and I've filled in a bunch of information so pcid peace size all this kind of stuff to start Epoch and Epoch costs everything here now where is it going to get this data from uh I have uploaded it to a place called The Lighthouse data Depot so the lighthouse data Depot is just a tool you can do all of this locally it's just a convenience tool that allows me to upload a file there so I created a file called uh hello hack FS just a small little text file I uploaded it to Falcon data Depot and it has calculated it's created a car file and calculated a lot of these PC IDs and everything that I need here so I was able to then plug those values into this command and run this command now running this command contacts that smart contract that smart contract then emits an event and boost the software sees that event here so we can see here these are the log files for Boost and we can see at the bottom here the Boost has accepted my contract deal proposal and then looking in boost we can see here that I have a deal here it's accepted it and we can scroll down and see that it has actually fetched the data um from where it needed to come from um and it has actually started the process of sealing this sector right and it is now in the state proving so what that means is it has taken the data it has created a sector I've cut run published storage deal here as a storage provider I can hit publish storage deals there's none left to publish at the moment but when I did that it then started the process and we're now in this state proving so this means that the data is on the blockchain and every 24 hours the blockchain asks the miner to prove that it still has my data now I'm going through this quite quickly if you look on YouTube You'll see some videos where I've gone through this in much more detail um and run it locally and gone through all the steps I'm kind of skipping over the steps here for for brevity um but that has now uh stored that data on there and I can actually access that data now using a tool called Lassie and I have I think I've got a s what if I got it here yes Lassie so Lassie is a tool to fetch data from ipfs or filecoin I can say Lassie fetch because I'm running it on localhost I've had to tell it where the provider is normally you don't need to do this because it uses a tool called ipni the interplanetary network indexer but I've had to tell it I'm actually running on localhost here so look on localhost and I've provided there the CID so that's the CID of the data um if we look here in the deal ID we can see this is this root deal CID that ends c-o-h-i and I have that here so if I run that command Lassie will fetch that data it's downloaded it I now have a car file this car file here named after the CID like I say ipfs car dash dash unpack provide that car file I'll now have a directory named after that I can go into that directory and you'll see there's our hello hack FS I could do that let me just clear the screen so you can see it clearer hello hackerfest 2023 so that's the file I uploaded right so that's going through the deal client process um that we uh that I talked about so this is a direct deal and like I said using localnet and the hard hat starter kit now the alternate approach and the approach that you're probably going to use with this hackathon is using the aggregator or using an aggregator in this case I'm demoing filecoin data tools and their aggregator and their tools Edge and Delta now to do this I've created a very simple um uh tool here called FTD data Monitor and that is intended to be just a example that will allow you to um uh to to see what's uh to to actually monitor the chain so I had some details of the direct deal um that's the process I went through um there with the direct deal um so just to recap we'll send the URL and deal parameters uh to the smart contract that was a big scary command um the contract emits deal proposal event storage providers running boost see that event and pick up the deal we saw that in the log files storage provider can then fetch the data and publishes it to the chain so we saw all of that we fetched it with Lassie um the aggregator we're going to do a slightly similar pattern here um we're going to send we're going to have a an aggregator smart contract now again this is just an example that I have created just to show you this um so there's a a repository here ftt deal monitor so I put that in the chat and there's a very simple contract in here um that allows you to store a URI and it will then um allow you to kind of see that uh data there so what it'll do is it'll you call this store URI with a URI and it emits a event and what is actually happening is we have this tool FTD data monitor that is monitoring the event so this is a JavaScript uh little demon again this is just an example to show you that is listening to the event and will then send the data to Edge so we send a URL to this example aggregator uh contract the smart contract emits an edge uh you are contract event uh the local example uh FTD deal monitor demon watching CC event makes requests to Edge http and Edge will fetch the data and put it in an aggregation bucket once the bucket's full it will then create this aggregation proof and we'll actually uh pass it to Delta to make the storage deal with the storage provider so uh let's see this here so that was our direct deal one example I have this deal monitor here and I can run this I'm running this locally um so I've just checked out this ftt the deal monitor run yarn install uh to get all dependencies and I can run just node FDT uh deal monitor ethers there's a DOT end file in which you need to specify the RPC endpoint and your contract address um in there so again I'm using a local network for this but you'll probably want to do this on calibrationnet which is our main public test net I'm doing this locally just for the um speed and efficiency of it for during a demo I can now call a much less scary command but basically uh this hard hat store data and I pass it the contract and the URI so again this URI is the same URI we used before from the data Depot and Lighthouse storage again this is the local network so when I run that that is going to make a deal proposal on the local network and we'll see when that emits an event we'll see our deal monitor will pick that up it will see that event it will then take that URL that's been passed to it send it to Edge and Edge will then fetch the data and store it right and we'll see when that comes through hopefully um when you're running on localnet it's a 15 second block time when you're running a calibration net and mainnet it's uh 30 seconds so here we go um it's sending the payload there we go so let's just recap what it did here it called um uh this Edge instance so we've got set up specifically for hack FS um this URI here and I'll put this in the chat and we'll put this in it may already be in the hackathon cheat sheet if it's not we'll add it in there and put it in Discord as well so it is calling this um API request to fetch the URL it pass in the URL it goes and gets fetched and you can see here the responses come back it's got an ID this ID is local to Edge and uh it has the CID of the data but you can see here inclusion proof is null so what is this inclusion proof once the aggregator has aggregated a whole series of data and created this aggregate car file that it sends to storage provider one of the things you're going to want to do is be able to prove that your individual file is within that Aggregate and that is what this inclusion proof does so once it's aggregated that will then include um some proof that you can send to an oracle on chain and you can actually prove that like your 50 kilobyte monkey jpeg is actually verifiably stored within that 32 gigabyte say chunk of data right there's no deal ID because it hasn't made a deal yet um it's only just got it but what we do have is a status here and um a download so I can actually take those uh I can get that download URL and I can run that as well so I could say curl pass that in and pass it to uh whatever outdoor car and then I can do ipfs car dash dash unpack out dot car [Music] too many terminals data makes no sense ah interesting okay some reason that outdoor car oh that's because I've got the wrong one I've got the status there that's not what I want that's not the URL I want uh I need the actual download URL which is one second here I've just copied the wrong one this one here [Music] um ah so that's just the wrong way around where it says status and download those two labels are back to front there um so I need to get those uh those changed um but we can fetch the data still let's try this again here curl fetch that data out dot car and then ipfs car dash dash unpack out.car and if we look here we've again we've got a directory here and you can see it's actually got the same CID right so if I go into that directory there and look in there hello hack FS there's our file again right so this is going by S3 so S3 I can fetch the data from Estuary there and it has should have pinned it to ipfs we can check the status again if I go back to um our output here where is it here so I can check the status like I said those two labels are back to front but I can check the status here and I can say uh curl get that status and if I pipe it through JQ just to format it um we'll see here the status right so this is telling us the status um there's no sub piece information here no inclusion proof because it hasn't done the aggregation yet um and there's no deal information there um but if it has gone through all of that then you'll actually see all of that aggregation data there and one of the things our script did after it has done all of that is it's actually updated our smart contract so it has actually contacted our smart contract and passed in the um uh the information that's come from Delta so if we look at our smart contract here it's actually called this update job ID method and passed in the job ID the CID and set the status to pinned so that we know it's there so I can now look up with this contract and I could actually find out and see what's going on here so I could use this as a as a building block again this is just a very minimal example I could use this as a building block to then go on and build something like a replication service or a auto healing service or a data down or whatever it might be and once we have a deal ID I can actually call that as well and I can update the deal ID information here and my smart contract once it has a deal ID and it has the proof information uh it would be able to actually verify on chain that my CID has actually been stored within a deal right so once it's got that information it can then put that all in there so um there we go so that's a view then of going through aggregation um I think that's taken us to half an hour um here is a number of FM resources uh you can scan this QR code or go to uh link tree can actually get that I can't get that I'll put that in the in the chat um but yeah if you go to that QR code or go to link tree slash Falcon VM you'll get um links to the docs the hackathon cheat sheet use case ideas Etc and thanks a lot and this has been a team effort this is just some of the people on here but I'd also like to call out specifically the people within the uh filecoin data tools team as well um Alvin uh large cake who have been working on uh getting all of the stuff that I showed you with with Edge and Delta up and running uh so that we could demo this and have it ready for the hackathon so there we go right um any questions here um I'm just looking in the chat to see um what we've got here uh can you send a year early YouTube video were explained in depth uh yes uh I will do that I think actually if you go to um uh YouTube um ipfs thing uh probably find uh find it here now I'll find you the I'll find you the link to it it's on it's on ipfs things um it's on the on on the ipfs YouTube channel sort of find it there um I'll put it in later uh can you provide links to where you can go through the aggregator example more slowly as well yes so I'll put all of this um tutorial in um or this this talk rather I'll put the slides in and also this has been recorded as well you can go back and watch it a lot of this is very much in flux at the moment and has come about very very quickly literally over this weekend some of this functionality so I hope to do a more in-depth slower run through of it in which we we go through a bit more detail what I will say is probably the best thing to do is on Thursday uh we have um a live twitch stream and I'll cover it in that so if you go to um uh twitch.tv fillbuilders I'll cover that that will be at noon eastern time on Twitch and I'll go through it and if you've got specific questions um as well related to that you can ask there as well so medivh asks I'm creating a data now smart contract I have a question is when the proposal gets accepted in the contract how can we store the metadata in filecoin storage um I saw the metadata the Json file so is that related to you on about the metadata specifically for something like an nft um you would store in the same way VIA um an aggregator so you use the same process there hopefully that I'm not sure if that answer your questions uh oh yeah Rory's put in a link to the ipfs videos there uh thanks a lot Rory and uh yeah in there there's a uh there's a talk there um regarding that um uh going in more detail brainpride asks is the CID generated based on the data content yes that is one of the specific things about ipfs and filecoin is the CID is a is effectively a hash of the data so if the data changes the CID changes um and this is one of the the the really nice things about properties about ipfs and filecoin is when you fetch the data you can check it against the CID I the address you asked for so you can actually verify yourself whether the data that's been served to you is the data that you actually asked for so the same data will create the same CID uh yes with a slight asterisk remember I mentioned that a CID uh sorry a car file is actually a dag um uh an acylic um a directed acylic graph well there's more than one way to generate a graph with the data so if you think you could go like depth first or breadth first actually the same data can produce different car files so can produce different cids um but yes with with it once you've got a specific car file generated then the CID would be would be the same um but yeah some implementations do slightly different approaches to creating the car files I.E the the like the chunk sizes they use in the car files might be slightly different so you might get different uh ones so you could have potentially multiple cids reference the same data because the data of impacting a car file slightly differently between different implementations but if you've got the the CID you can verify that that car file is what you're what you're expecting it to do uh so yes somebody was asking yes it's related to an ft yes so you could store the the nft like Json data file in the same way VIA an aggregator um there as well there's also there's nft.storage which is uh specifically aimed at nft they uh don't yet as far as I'm aware allow you to or have a way to get data uh from on chain into nft storage but you could do the same kind of structure the same process that I did here with this um deal monitor here so this deal monitor is a fairly uh what's it it's about 100 lines of JavaScript and literally what it is doing is it is listening for events on there it's listening for this store URI event to be omitted um once it's emitted it uh decodes the event gets the URI from the event and then it actually sends it to [Music] um uh sends it to um Edge so this is actually a slightly older version here actually I just realized I haven't I haven't pushed the latest version um up yet so I need to do that just after this this talk here um but yeah it constructs a payload here and sends that payload up to Edge and it also stores it in a local database as well just local Json database so you could go back and reference it later and then it updates the smart contract so yeah it's extended slightly from the from the GitHub version but still about 100 lines of code so yeah okay [Music] um yeah my Discord my Discord on my Twitter uh is hammer toe h-a-m-m-e-r-t-o-e so you can find me on Twitter or Discord I'll be hanging around in the um uh East Global Discord in the uh Falcon sponsor Channel there so if you need any help then you can come in there um and I'll find uh find you there um can we make the event in the custom contract and use that yeah that's just an example so you can you can you can create whichever event you want um and do that so okay uh right I think that's it um thanks a lot everybody yeah thanks thank you Matt for the great presentation thank you everybody for attending and again if you have any further questions please reach out on the Discord or partner channels so cheers thank you all have a great rest of the day and have a good week great thanks a lot bye bye 