we're excited to uh intro our next talk and that is carl carl's going to be talking about the optimistic virtual machine the ovm and uh carl's from optimism and uh without further ado i'll let call kick off with this talk hey carl why hello how's it going y'all very exciting this is uh been looking forward to the scaling ethereum hackathon the best topic for a hackathon possible for a while so hello i am carl i'm going to talk to you about uh just optimistic ethereum a quick overview and the future and a scalability deep dive aka what do we really mean by scalability so let's get started um the uh let me actually turn on a clock there we go so let's dive in if this is what you think scalability is this is incorrect if this is what you think scalability is this is incorrect scalability the transaction fees are way too high thankfully i have been talking about this for a long time and people seem to you know get the picture now so that's really nice 15 seconds 15 minutes these are all way way too slow we need super quick super quick transactions with low fees it is unacceptable but let me go back a little bit a little bit time travel and talk about who i am what's optimism pbc and you know how do we how do we really get here so i actually started out working at consensus for a little bit then i kind of traveled around the world with vitalik and talked on some stairs and you know ranted like i'm doing now and then you know had a little introduction to cryptocurrencies and worked on this crypto economics book with jing and uh uh kevin and you know told my friend oh you should really get into crypto and they got really depressed because he was my last friend who wasn't into crypto and then my you know my friends got me out of that depression thank goodness we formed plasma group with kelvin and we were like oh can plasmas you know scale unit swap no it cannot and so we worked on this thing called optimistic roll up and we created unipig and we created this new thing called optimism and synthetics was like oh unipig was pretty cool let me take a look and then you know mark joined and chris to join and josh joined and you know annie and liam and gigamesh and it was you know it's a big big happy explosive family so that is amazing and you know the optimism uh optimistic ethereum family is growing bigger and bigger and this talk is going to be all about community it's going to be all about all about you know ethereum but before we get into all that let's go into a little bit of technical stuff a little bit of technical right here and then we got after the technical stuff we got some design principles which is less technical and then we'll go into the rest so what is optimistic ethereum it's a minimal addition to ethereum that enables an evm based layer to roll up but what does that really mean basically it's just ethereum inside of ethereum so you know very technical work coming in we got ethereum it's the l1 right that's the base layer and then we got optimistic ethereum which is l2 and it's in ethereum wow very crazy it's a little little recursive you know and before you ask yes in fact you can do you know a l3 and put optimistic ethereum inside octa mystic there but let's dive in okay so how does this work okay first y'all can take a look at a bunch of presentations that you know ben and kelvin did yesterday and you know we've got a bunch of presentations on this so i'm not going to actually take too much time but optimistic growth is you know the thing the the optimistic ethereum is a combination of optimistic role and the ovm and uh optimistic world gives us security and the ovm gives us evm expressibility and so i'm going to give you a one minute uh presentation one minutes of course for what exactly that means all right three two one go let's see how i do okay optimistic roll up we've got the security portion so ethereum is processing all these transactions it's a tired doge it's doing too much work and so then bumping on optimistic ethereum comes in don't fear let me help you do some transaction processing and then it goes bad and then the verifiers prove fraud and then it you know goes well and ethereum is happy and a happy dosh success okay so that's how that's how optimistic rollup works vennaz and this is how the ovm works so normally you have smart contracts they talk to each other but we need to put evm inside of evm we need to put ethereum inside of ethereum that means we need container virtualization boom so we take the ovm the ovm is this container virtualized evm we can run it inside of the evm so now we're diverting calls you know to the you know container contract this virtualizer contract and all of the stateful operations they go through that that's how we maintain a sandbox and that's how this thing works kind of similar to the diamond pattern and stateless execution bam that was actually one minute i did just record it so um very good so optimistic roll up it's for the fraud proofs ovm is for the container virtualization it's to give us evm inside of the evm that's optimistic ethereum but what is optimistic ethereum really like what is the essence of this project because technology is only one uh one aspect of the puzzle so the optimistic ethereum design principles two of them that i'm going to talk about today are incrementalism and minimalism so incrementalism we it's really fun to say things like oh we've solved scalability oh there's this big breakthrough wow wow wow you know and like the world explodes right that is i i've i said those things in fact many times and it you know it's fun to an extent but in reality progress looks a lot more like this right we're like you know slowly carrying building up the kind of global intelligence of the human species right and it's been getting built for a long time so we're you know we're little tiny little tiny cogs in that greater machine and that is really what what what what things are like and so there's a real scalability solution in ethereum that has that doesn't get talked about nearly enough and that is geth that's open ethereum that's turboget that's these incredible researchers that's these people that for instance in the past few years we've increased the scalability of ethereum over 2x right like the scalability is not something that just kind of comes out of the blue it is based on a huge amount of work from a lot a lot of different people including research that is being implemented as eips like changing the gas prices of various op codes or introducing access lists right or the most cutting edge research like things like vertical tries for you know stateless clients this is this is the stuff that really gets us scale and tooling right this is we've we've got a ton of incredible tooling in the ethereum ecosystem tons of folks working on it and that is required if you're trying to build a production piece of software you need production level tooling and so all of this stuff is built on you know open source software and public goods and it's so exciting to be able to work and build technology that utilizes all of these different uh all of this different tooling and so that is what we're trying to do with optimistic ethereum right we're trying to build on top of that software and kind of fit in like a puzzle piece that means that we must support the ovm i mean the evm that means that we you know need to uh if we can implement this incredible research that's being done and we can make use of the implementations of that research that are built for eth1 it allows us you know and of course open source everything that goes without saying it's like we can be a test bed for each one point x and so the other thing that i want to talk about is minimalism so a wise age named george once said that every line of code costs a hundred dollars so you better not write a lot of lines of code because it's expansive so really what this you know this process is it's really just this like you know surgical precision that you need to have when you're you know for instance upgrading death to be optimistic death rate you need to minimize your diff you need to minimize the lines changed and the reason why is because we're standing on the shoulders of giants this is a kind of weird photo but it's standing on the shoulders of giants and so that goes for the protocol itself right we can't diverge from ethereum too far because the further we diverge the less we can kind of make use of this incredible ecosystem right it's ma we're trying to maximize our leverage maximize our impact and to do that we need to make use of all of the technology that has been built before and also all of the tooling that's been built before we have to fit in fit in like a puzzle piece and be that test bed for 8.1.x that i talked about so that those are some of the main design principles the other one is you know gotta be love gotta give love gotta be you know be uh be nice to each other so anyway that's that okay so next we got the path forward this is a kind of you know overview of where we're headed and then we're gonna this is then we're going to after that talk about this uh this whole kind of deep dive into scalability it's a little more technical then but before we get into the technical stuff let's stay at a high level so we're currently on pseudomainnet we got we've saved folks over 10 million dollars it's pretty pretty cool pretty sweet um and we came up with a few names for these releases i'm going to talk about a bunch of releases and you know these are subject to change but the first release is inconspicuous medium-sized animal this is the mascot for this incredible release and uh we're hoping to go to we need to go to full mainnet next and the thing that's taking that will take us there is improving our upgradability infrastructure so i was actually planning on talking about that in this talk but i ran out of time so uh the uh upgradability is a future talk coming up there's just too much to talk about on this other stuff so anyway uh the code name chalk marker this is our first our our full mainnet and so the reason why is because we write on windows with chalk markers chalk markers are great you should buy them they're great to work right on windows so our full you know four releases categories that i have here are chalk marker then irritated window cleaner and then poor airbnb rating and finally the final finale ultimate you know release is iphone 4. so we've got for each one of these uh releases there's you know various things and we'll go over each one so first chalk marker we've got instant upgrades we've got arbitrary contract deployment so arbitrary contract deployment that's good but we've got no slashing and we've got a single sequencer with ovm self upgrades so what does this really mean it means that we've got these guardrails right we're definitely not at the decentralized you know end goal that we want to be in where we are know that there are like things that are fundamentally broken about how the you know protocol works this would not be sustainable long term but it gives us the flexibility to actually you know iterate on and try out the software that we are building no eggs were harmed um the next step we're getting better we're closer to the decentralized utopia with delayed upgrades so instead of being able to instantly upgrade the contracts they're delayed and we've got slashing and we've got a single sequencer and we've got some simple compression for for data availability optimizations um and so that you know that we're getting there but we're still a single sequencer we're still running it and that that we definitely do not want to be doing that uh soon as soon as humanly possible then the next one is poor airbnb rating so now we're really decentralized we got super delayed upgrades multi-sequencer you know we've got we're starting to mess around with speculative execution for scalability purposes we've got plugable compression and and you know some fun stuff with you know gas limit rating or using an eip 1559 curve anyway all of this stuff but there's one fundamental thing that we're missing and that is eth2 and so finally the kind of nirvana iphone 4 is you know we've got uh eth2 sharp blob transaction feed so in other words we can use the eth2 shards for our data availability that means that we can scale up to use all of the availability uh all of the kind of uh yeah availability that is provided by youtube and we're actually going to talk about what that really means in in you know very soon and we've got some other fun stuff like optim upgrade support that allows you to kind of fork the chain arbitrarily and you know con concealed transactions and zk evm all these these fun things so this is the kind of high level progression right starting out you know centralized more flexible we have to have upgrades throughout this entire process and then we get you know more and more decentralized one thing at a time until we are like fully integrated into ethereum and decentralized so that is the path forward okay so we did we did design principles we got the road map now we're gonna go back into some technical stuff because there is you know i can't help myself i can't help myself i'm gonna talk about technical stuff no matter where i am and this is one technical question that has come up so many times it is what is scalability like when people say scalability okay it means something goes up but like do we actually talk about what is that thing that's going up is it transactions per second like what what it what does it mean to increase your quote transactions per second like that doesn't actually give you a picture a vivid image of what the blockchain infrastructure needs to be so let's talk about that when you have a scalability problem that means that you are constrained you are resource constrained meaning that you need to increase the supply of a resource so there are three blockchain resources and i'm going to claim that this is essentially universal across blockchains and all of the designs of blockchains that you will see have these three components and you'll probably hear about it in different words you know everyone uses different different vocabulary to express the same thing but here i'm going to talk about it as availability compute and storage those are the three blockchain resources and so we're going to actually use an analogy to get a little bit more of a vivid image of what this means so note i have no idea what a water processing plant is but i'm gonna use it anywhere because it felt it felt about right i just like vaguely remember from biology class or something okay so we have got this availability it's the pipes it's the pipe going into the flitulation basin and the flagellation basin is the kind of compute right where we're doing something we're churning up the water and then it's going into the storage container the kind of water cooler looking thing um that holds all of this water and this water is like the trusted computation that fuels humanity right just like we have water we need trust we need trust in our computation and we need to build a universal trusted computation layer for humanity that is the goal we need this system it is one amazing machine and we can get there so availability let's actually like dive in a little deeper what is availability mean well messages are propagated throughout the network on these blockchain systems and we come to consensus on what the next block is and so availability is essentially how much data you can come to consensus on in over what period one period of time so the more the better obviously the bigger the pipes and we're measuring this in bytes per second so the more bytes you can come to consensus on say these bytes are in the blockchain the better and then you've got compute and that's the flotulation basin and essentially what that is it's it's how much math you can do and trust that that math is computed correctly and so it's like you know your smart contracts how many executions of your smart contract can you do and how many cross-contract calls and all of that kind of stuff and how many state routes can you produce and so essentially in some ways it's just like how much you can do x times y equals k over and over again you know if you don't get that ask your neighbor um so we're gonna measure this in gas per second now notably gas per second is not really quite right uh for reasons that you'll kind of see later on but we can think of this as more like the gas of pure opcodes per second that we can do and form consensus on the result of so that is our computation pretty simple finally storage this is a little different from the first two storage is how much we can actually store in a single node so this is measured in bytes it's actually a fixed quantity it's not a kind of you know quantity over time like a rate of change instead this is just a cap and currently we're at like 70 gigabytes maybe it's 80 gigabytes maybe it's 90 gigabytes i'm always out of the loop about this it just keeps growing and changing but whatever um maybe it's at 60. anyway so s store and created so like all the things that you store in the blockchain state i call it storage but it's really in the blockchain state only it's not the history it's the storage so for instance if it were to grow to 200 gigabytes or or something like that then nodes might start falling off of the network and have to be replaced with nodes that are run in you know data centers and this decreases central uh decentralization and is not good especially for layer one we need to keep the state low and we need to make the computational requirements of running a layer one node as low as possible and notably this resource actually the state actually always grows basically i mean technically you can reduce it but almost no one does it and so it's always growing and so even without changing anything our blockchain ethereum is fundamentally flawed because it will explode at some point this water basin will just burst because there's just going to be too much state in the chain and this is a ticking time bomb that literally is something that we need to essentially you know save ethereum from you know soon and that is that we're going to talk about that that's some stateless client work but anyway if we want to you know support all of humanity on this thing unfortunately we can't in this current state of affairs right like look at this thing it's tiny and this there's no there's nothing in this water base and that will you know uh this this water this water cooler is just gonna fill up so we need to increase these pipes we need to also you know increase the computational power you know put some workers in there and then we also need a drainage system right that drains everything and this would be the ideal blockchain but let's kind of go into a more uh uh like uh mathematical kind of abstract uh representation of this stuff so we've got three resources availability compute and storage let's not talk about uh uh well first the availability and the compute there are these you know uh this rate of there's this uh uh there's technically an unlimited supply if you gave it infinite in infinite time frame but it's this it's more constrained by like the rate of growth but in the storage case it's cap supply so let's just like you know kind of ignore the cap supply for now that's a little bit of a different topic and i'll talk about it soon but let's talk about scalability in eth1 so both the availability and compute of eth1 are limited by the gas limit so what does that mean that means that as the availability usage increases the compute usage has to decrease proportionally and similarly if the availability uh usage decreases the compute can increase it's basically like you can send a transaction and i can you can either send a huge transaction or you can send a small transaction that does a bunch of computation both of them affect the gas limit so the gas limit is 12 million and if you used all of it for the availability you get about 70 kilobytes per second of available data so that pipes are kind of 70 gigabytes that were that were or 70 mega 70 kilobytes oh my gosh it's way smaller than those two first things um or if you do uh all of the if you spend it all on compute you'll get about 800 000 gas per second so now let's take a look at not just each one but let's look at optimistic eth1 this is you know eth1 and optimistic ethereum kind of running and running side by side so boom boom we got this other optimistic compute so the ether one gas limit let's say it will is 12 million let's say the oeth gas limit for first the sega of this example is also 12 million and so now we've got equal usage across all of these different uh uh you know these different resource constraints but notably you can increase the availability or the compute of eth1 without affecting the gas usage or the gas resource consumption of optimistic compute right the optimistic ethereum right you can you can spend all of your money on availability all of your resources sorry on availability and you can then also spend all of your resources on the optimistic compute and so this is actually fundamentally just how you are actually able to scale up the total resource constraints of ethereum so we've achieved more scale that's really exciting but let's keep going so notably this gas limit this 12 million gas limit death has been increasing this over time it has been an incredible amount of work by a bunch of folks and not just geth but oh you know i mean all of the ethereum clients have been increasing it over time and in fact could increase it even further and in fact some blind some folks have been experimenting with you know in practice using things like 140 million gas limit gas limits which is just kind of mind-boggling and does give you a 10x performance and it's technically possible but it doesn't come free necessarily it does require increasing the full node uh requirements and so that means that instead of you know this node you need that and you know a node of this size you need that size and actually in layer two it can be okay because you can increase the the full node requirements without affecting consensus and i have another talk about that but you can't increase it infinitely this is not a you know perfect solution and storage the state blow problem becomes way worse right because you're blowing bloating up the state really quickly you're gonna burst sooner and it's just as simple as that but don't fear the ethereum community is here right this is this has been a problem for the ethereum community since you know the early days and this is why we are you know building on ethereum so the great thing is verkle tries i'm very excited by this this is com combined with stateless clients so if if in order to provide a that uh uh the release valve on the water cooler you can actually create stateless clients and that will essentially drain the water it allows nodes to throw away old state that's why it's called stateless instead of holding on to all of the state you're throwing a bunch of it away and so that allows the you know storage to be you know to not grow over time it's just just draining the water it's just deleting the stuff from the state technically you can revive it but it's you know you you have to prove that it was in the state in the first place but notably this actually also has implications on full node requirement increases so normally you compute your blockchain doing you know single threaded uh work you go just you know one block at a time but if you provide all of the witness data for all of the blocks then you can actually as an ethereum node compute the validity of each block independently of one another and just compute it all in parallel and that gives you you know definitely a huge scalability increase just by utilizing more threads on your computer and that's pretty cool that's like a that's a really interesting synergy that doesn't actually come with a you know a lot more complexity on top of the stateless client design and we're building stateless clients in ethereum in optimistic ethereum we can be the test bed for ethereum one point x and so even crazier you can go full zk evm improve all of the blocks validity up front and that you know scales logarithmically with the the amount of computation so it's pretty i mean that that thing is that's even that's even crazier and that's you know the the final the final boss but this is how you can actually address these problems and with those things addressed you can make the optimistic ethereum gasoline absolutely massive and we've gotten more scale but now bump it on availability is the bottleneck and so guess what optimistic eth2 well eth2 is here to solve the availability bottleneck for phase one they we don't worry about compute we only care about availability and that's literally what eth2 does it just scales up the availability by you know using uh random sampling for and erase your encoding for the you know consensus on the future blocks so it's pretty pretty sweet and so now you can combine this massive amount of availability with this massive amount of optimistic compute and they'd scale independently of one another just like on eth1 and boom we can max it all out and we can reach scalability in nirvana this is what we mean when we say scalability right this is scalability it is a big set of pipes with a big fluctuation basin going into a big tank of water and that tank of water is being drained by the stateless clients and we are happy and clams we are happy happy clams you can almost see the blocks in there you can almost see the blocks and so that's ethereum you know that's optimistic ethereum that's the combination of the two it's it's uh it's great so i appreciate y'all and thank you and the time's up let's do this so uh okay i will do one shout out shout out to uh this amazing amazing you know uh thing if you you want to work on a crazy experimental eip that is called virtual call reach out let me know specifically if you want to work on some geth geth code um because it is it is it is extremely cool anyway that's it thank you 