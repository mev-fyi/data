[Applause] [Music] good morning good afternoon good evening depending where you're calling from we have orion from the graph doing a workshop on building decentralized serverless applications as always if you have any questions they can go into the zoom chat and our hosts will be more than happy to answer them and with that being said i will pass the mic off to our speaker thank you so much anna i am arya navisa and today i will tell you why i am excited about guav and hopefully by the end of the presentation you are just as excited so this is me you can find me on twitter you can reach out to me on discord i hang out in the eat global sponsor channel i am on the official draft discord channel as well the graph.com discord there we have dedicated channels for questions and support so feel free to reach out there and some of our support members will help you with anything and i'll be there as well so feel free to ping me so let's dive into it uh many people ask me like why do we need index data like the blockchain is public right but most blockchains are optimized for writing data and not for reading it so you could imagine the blockchain as a huge public library and every day the library gets a truckload of new books and it just gets added to the end of these scalps without really being sorted and then you connect to those nodes you are limited to browsing the library and look up individual titles so now imagine you go into this library and you want the list of the books with 100 books with the highest word count to get this list you will need to go to the entire library check every single book for that word count and this takes a very long time so let's let's take an example that is a little bit closer to um a practical example in web3 like say you want to create a d5 dashboard most of you might be familiar with uniswap it is a decent plastic chain where anyone can trade tokens in a trustless manner and they also have an analytics dashboard at info.unisroc.org where you can find valuable charts and data and as you know the the price of a token changes every time a trade is made and that can even be multiple times in a block now if you wanted to create a like price chart simply by querying raw blockchain data from your for example front-end application you would need to make millions of calls to an eighth note and not only would this be incredibly resource heavy we that is expensive the load time may be minutes to hours so all of this data needs to be pre-processed or indexed and all of the data you see on these charts are coming from the graph so is it only d5 charts that need sub-graphs need index data well it turns out everybody needs it we currently have over 64 000 subgraphs that have been created on the graph so that's 64 000 open apis that are gathering and gathering blockchain data and over 640 billion queries have been served so so let's take a look at a couple of the the the benefits of using the graph like you have a you can create a customized api that is tailored to your data requirements you can include any kind of like rich sorted filtered or aggregated data and that allows for fully decentralized and serverless application after all a dab that relies on a single centralized server is just an app so the graphics currently have two projects projects one is the hosted service which is a centralized service run by edunode one of the core developer teams at the graph the centralized service currently have support for 38 networks near polygon bnb and 35 more and we are currently moving over to the decentralized network that has support for ethereum mainnet currently but we believe that every dac deserves decentralized and open apis and that is something we are committed to and we are currently in the process of adding multi-chain support to the graph so we will start the gnosis chain and we will add support for multiple networks in the monstercom so say say of today to that because that is very exciting uh we can take a look at the few uh benefits of using a decentralized service because it's not just a buzzword to be decentralized being decentralized means that you have no central point of failure you never have to call your backend engineer in the middle of the night because your server went down you're not at the mercy of large centralized service providers you have a load balance system the graph is infinitely scalable and it scales similarly you have a geo distributed service and there are indexes in every major continent and even an indexer that isn't on any of the continents you have censorship resistance you will never wake up to an email saying that your server went down because your service provider have taken a non-crypto stance and least but not last the graph network is an open marketplace where 160 indexers are competing to deliver the highest quality of service to the lowest possible price so this is why i'm excited about the graph so so we can stop pause that there and see if there's any questions about the graph i have a question about the graph yeah go ahead what kind of like a application architecture question so i am building um i'm doing a project that looks at like block activity on the blockchain and then like distributes rewards in some type of token to the users that executed that blockchain to execute those transactions and so i'm indexing all of the stuff that i want to look at in the graph right but i have like a script that i basically need to run like every reward period whether it's like a day or something like every day i need to run the script and i like tally up how how much each address earned based on like the events that i've indexed in the graph and then i need to like update a contract right that to allow people to claim uh the corresponding tokens but like what i'm struggling with is like the code that i run every 24 hours or whatnot is like that's like not decentralized that's just like a script that i have running somewhere and i can't figure out like where how to decentralize that it's the only piece that's not decentralized that that is a good question um and it really like the the longer the short answer is that uh currently the graph is read oriented so writing like you taking that data inviting to the blockchain would be more very like a process that would be centralized in a way but the long answer is that we have some like really exciting research areas in the pipeline such as verifiable queries and verifiable indexing so you can you use zero knowledge proofs to prove that the data reserve is correct and that together with a technology called the subgraph bridge where we can bridge data back on chain these are the things that is part of the exciting future photograph but currently yeah that would be as kind of a centralized um feature i did that um answer your question yeah yeah the stuff that you mentioned about the new graph functionality is interesting yeah yeah we can circle back to that for sure and feel free to reach out to me as well and i can give you some links about that okay yeah yeah of course so we want to see some code and build a subgraph as well before we do that i'll just give a short primer on building a subgraph so subgroup is the open api and we will be mainly working with three files when you build a subgraph one is the sub gap manifest in this in this file it is a yaml file where you define like what data sources you want to index so what network the contracts on that network the start block because you will define a start block that indicates that you want to index data from that block on the chain and all the way up to up till chain head and forward and also what events calls other on-chain triggers to listen to there will also be a subgraph schema this is where you define your data searcher and you define your entities and relations between those entities and most subgraph developers should spend a little bit of time to think ahead and try to make the schema as close as possible to your dav's data requirements because a well-structured schema can save you a lot of time down the line um then you have the final part is the sub-gap mappings and this will map data between your data sources to your subgraph schema it will here you will do like transforming of data aggregation of data and so on so let's see how it looks in practice and here we have the graph uh the the graph.com we can look at the subgraph studio which is the staging area for the decentralized network if we create a sub gap here like in in this example i will simply index the board apiac club yacht club contract that is on ethereum mainnet let me call it bassy workshop now i've created it on the studio in the graph and here you have some useful information that's undeployed right now i don't have any like information uploaded this is the subgraph slug this is the identifier you will be using in commands in your cli and this is the deployment key that is a authentication key so only you can deploy sub graphs to this to this uh studio instance so you start but here you have some like useful commands and you would start by installing the graph cli i have already done so so i won't let you sit through that one minute um instead i will jump straight to initializing my subgolf so let's copy that command and open the cli so you would run graph in it in the studio and the subgraph slug now i have a very nice little cheat code for you is to add the index events flag what this will do is it will add some scaffold code scaffold code to your sebra and we will see that in a minute it will ask us like what type of contract it is and we want to con it's an ebm based chain so it's an ethereum the subgraphs log is already filled out for us i wanted to have it in that default folder and it is on mainnet now let me grab the contact address that looks like this the name of the the api or naming name of the contact i don't know off the top of my head so i just call it something that that's just what it will be called within the subgraph code so now it's generating a scaffold it's um installing the dependencies so just give it a second it will ask us if we want to index more than one contract but for now we say no now we enter that folder and open it in vhc now if you remember five minutes ago we went through the three different main files you will be working us working with as a subgraph developer the first one is the yaml file and here we can see what's going on we are we have one data source that's on ethereum it's called bc it's on on mainnet uh so this is the type um the evm base chain it's a mainnet this is the address and this is the api here we want to add a start block the we don't need to index all the way from the genesis block because he said the the contract wasn't deployed until blocked 12 million so let me paste this here you can find this for any contract by looking at the contract creation transaction here and you will find a block that it was created at now that we've added the start block we make sure that it starts indexing when it actually has something to index you see by since we passed in the index events uh in index events flag we already have some code populated let's also look at the schema the schema has one entity for each of the the four events that is on this contract approval available for all ownership transfer and transfer and it also has some of the properties for these events or have the properties for these events if we look at the in the source folder there will be a mapping file it's called bay it's called bayesia.ts in our example since we we call the contract pc and you see that there's already generated a boilerplate code for us that handles each and every one of the events so let's take a look at one of them the handle transfer one whenever a handle transfer happens on chain it will create a new transfer event with an id that is equal to the transaction transaction hash dash and then the log index and it will store the event at the event parameter called from in in the from field it will sort it to in the to field token id and the token id and then it will save save everything so let's this this thing is ready so let's first make sure that we we save the file that where we change the start block and we run graph code gen this will generate the code that that should be done every time the map mappings i mean the the manifest or the schema is changed and then we go back to the the subgraph on the studio we want to authenticate note that the full authentication key isn't shown here so you need to use the copy you would not show this but we can regenerate it afterwards so and then let's deploy it we give it a version label and it's deployed let's go back to the studio see it's already already syncing already synced and we can create its data so now we have approvals approval for alls uh we can add if we want to add some more like transfers we can write graphical uh graphql query for that let me yeah that's it that's um now you have a working a working sub guard that is indexing events one to one for all events that have happened in the pc contract that is pretty cool but what's really great about subgolf is ability to create which apis that are tailored to your application so this is where you would go back to your subcar and add additional data so say for example that you don't just want to have your transfer transfer entity you might want to have a like note down what the timestamp is and the block number so you could add that let me just type it out so since we have changed the schema we would also run graph cogen again that is simply so these two new fields that we created in the in the in the schema make is available for us in the mapping code so now we we've said that this is what we want in our data structure now now let's actually add these things to uh to the mapping file as well and you you see now that when i write entity dot block number you see that property is already there so let's save that you can redeploy it and add a number two let's see now uh both the first version and the second version is available here on the in this video and this allows us for example to do some some more interesting queries like uh say we want the first five transfers and we want to order by timestamp yeah not an order direction ascending this is let me just copy paste it it's a little bit weird when i'm zoomed in let's see i might need to refresh my page there we go that just took a second for the the ui to catch up so with this with this query where we order by time sam an ascending direction we are getting now getting the first 10 first ten basi nfds to ever be transferred so that shows the loop of how you can create your first sub-glob in five minutes and then you decide you want some more additional data fields in your sub-graph you go back you make some changes to your code and then you redeploy and when you are done with your subgraph and when you feel uh that this should be published on the decentralized network you can do so over here and you can publish it either to mainnet which is the decentralized network or our this our test on girly let me quickly also show you the graphics floor where if you want to not create your own subgraph but use an existing one there's the graph explorer where you can explore the decentralized network and there's the hosted service where you can explore sub-graphs that are deployed to the centralized hosted service as you can see here there's over 28 000 that has been made open source for you to use or open for you to use so we and we have two tracks for um for pisces in it global and one of them is using a subgraph an existing subgroup and another one is creating your own so happy hacking and i'll we have two minutes left so if anyone has any questions we can um you can take them now i think uh kashif had a couple questions in the zoom chat yeah let me see so so this uh sukashif has a question about um [Music] like when you are waiting for a new event to update in your subgroup and what you do on your front end the uh the recommended approach right now is to just pull at the reasonable interval uh there's currently some exciting works being done on something called live queries and you can already start using the graph client that has already has um like ways let me with the graph client you um you can tag a tag tag a query as a library and in it will do the polling strategy for you so i highly recommend anyone that is serious about using any graphql to graph or other graphql endpoints to check out the graph client not just the best client to use with the graph but the best client overall so um i have a quick question yeah go ahead so i'm actually building a membership marketplace that where users can actually get to search for communities and memberships they're interested in based on tags so if you were a dao or something and you wanted to be found you could uh publish or broadcast your community by you know associating it with some tags like you know public goods relationship sports whatnot and if you were a user and you wanted to find some communities to join or projects that you might be interested in you could find it by like searching for tags and it's supposed to display communities that you know were broadcasted with those tags associated and then you would basically check for the one you were looking for something like that so i was kind of curious if that's something that could be done with the graph because that's like the missing piece to what i'm building like where are the tags and you know how that sort of fits in yeah i would definitely used to go for that i would probably use a cheap chain so whenever somebody wants to create a profile with these tags or like create these tags uh it is not on it may not and then i would index that index that and when you when a user goes in and enters their tags they can you would send a graphql query to the graph and find the the broadcasters that correspond with those tags did it yeah yeah yeah so basically i would index the tags you know and wouldn't have anything to do with like the contracts and like the example you showed yes sir so you would probably create a just a small contract where you can you could even create a a contract where anyone can pass in a swing so it could be any kind of tags you would pass that in the subgroup and say that and uh like add tags or like uh in in the subgraph code you would sort these these entries into tags and then when you query it from your content you would create it based on the same tags okay you could also there's also a feature in the graph called full text search which allows you to just really store like a set of strings and uh and define these as you want to to be able to do full text search based on on these uh strings and when a user then goes in and he writes down a couple of tags that he is interested in you could do a full text search in the subgroup for any like matching um broadcast so yeah that's really great what was it for so that's called full text search let me pull it up here so here you can find like how to do how to define something as uh full text search fields um so in this example let's using a band search where where we have like the band and the band name the band description the band bio this is where people can search and if you also search here for full text search queries uh this uh defines like how you can like the how you can create a a search uh or like how how you define your query to search these fields yeah got it thanks a lot that was really really helpful yeah happy to help any any other questions i think cause she had a second question about um proxy contracts it's the um yet so sorry about that um yeah so that that would be a way to do it you could even um there's a feature in the graph called dynamic data sources or templates that allows you to dynamically create a new data source as a uh as as they get deployed so that would be an option if you need to make sure that your subgraph whenever a new implementation contract is deployed your subgraph is always updated to start indexing the new one but if this is more of a like one-time epoxy where you don't really do many upgrades then the the the simplest way is to use the api that has the events that you are listening for and then have the then listen to the proxy contract and so sorry for not noticing it's uh i'm trying to keep both screens off so thank you so much so that answers my question i sincerely appreciate it yeah happy to help and if this uh if you ever need any help with that uh ping us in the graph the graph channel in eatglobal or join the graph.com discord and we have like support and question channels as well so uh yeah awesome um well thank you so much oyen for um taking the time to host this workshop for eath online um i hope the rest of you enjoyed it and thanks for tuning in um yeah as we said um the graph team can be reachable on the east online discord at sponsor the graph or in their own discord channel as well um and with that being said i hope everyone has a great rest of your day you 