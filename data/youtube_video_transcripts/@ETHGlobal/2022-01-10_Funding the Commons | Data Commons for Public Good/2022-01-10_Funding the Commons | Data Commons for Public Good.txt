[Music] [Applause] [Music] dawn is professor of computer science at uc berkeley specializing in deep learning blockchains and don security going to talk to us about building a data commons for the public good maximizing social welfare and economic efficiency while protecting users data rights and enabling fair distribution of value welcome don hello hello uh can you right yes you can see you can you hear me now yes see and hear you okay great great thank you so let me um let me share my screen now right just one second let me share my screen next yes okay can you see my screen yes i can see your screen the presentation is started okay okay great great yeah thanks uh thank you everyone for being here um my name is don song i'm a professor in computer science at uc berkeley and uh also the founder of the oasis labs uh today i'll talk about data commons for public goods and so one thing i just want to preface uh this talk um with that uh right i think everyone knows that this workshop is uh organized put together uh fairly um very quickly uh and i essentially i think it was um i was invited as a speaker and essentially just with i think a couple of days uh notice and i um initially i thought i wouldn't have enough time to prepare the slides and so on but i thought the topic of the workshop um is really exciting and fits really well with some some of the work that we have been doing so i agreed to give the talk um but there have been you know like emergencies that came up uh i didn't quite have the time to really finish prepare the slides for everything that i really want to talk about but i hope that with the time that we have i can help give some high-level ideas and i think this workshop is fairly exploratory as well so it's a great opportunity to get the conversation started and i'm very happy to talk to interested audience uh in more detail after the talk um okay and thank you okay so as we all know that uh data is a key driver uh for modern economy and the lifebloods of ai and the machine learning and also huge amounts of data is being collected and the more and more data is being collected every day and there's estimated that that a significant percentage of the eu's gdp comes from personalized data and the overall global data economy is growing exponentially but however a lot of this data also is really sensitive and has handling the sensitive data has posted unprecedented challenges for both individuals and institutions for individuals as we know that the individuals have already lost control over how their data is used oftentimes their data has been sold without users awareness and approval and a lot of this data was sold um under the premise that the data has been anonymized but however there is volume on research showing that um the uh anonymization is insufficient to protect users uh data privacy so for example here is a really interesting case study that new york times did where they showed that they were able to obtain anonymize their mobile phone location data sets and from this anonymized mobile phone location data sets they were able to track the location of a service uh secret service agent with former president trump and hence knowing the trajectories and whereabouts of former president trump and and also the even bigger issue is that there's all these data being collected and they contain really valuable information but however most of this valuable data has been unlocked in data silos so today actually the biggest issue is that it's very difficult to gain access to this valuable data it's very difficult to actually utilize this valuable data for public goods for for example for medical research it's very difficult for medical researchers to gain access to medical data that's needed for their medical research and similarly also in uh in finance and in iot many different segments this has been a huge issue and um if these issues are not addressed they will only get more and more severe as we move further forward into the digital area to the extent that it could significantly hinder societal progress uh and even undermine human values and fundamental rights and hence um there is urgent need for a framework for a responsible data economy that's different to how today's data economy works and and make the the needed change changes and here what i mean by the responsible data economy what are the main goals and principles and so first we need to establish and enforce data rights data rights form at the foundation of data economy and prevent misuse and abuse of data and also we need to enable fair distribution of value created from data such that users should be able to gain sufficient benefit from their data and the ultimate goal is to enable efficient data use to maximize the social welfare and economic efficiency unlike today when datasets in data silos is now being utilized to maximize social welfare and economic efficiency and there are a number of unique challenges and complexity due to the unique nature and properties of data for example there's natural tension between utility and privacy and um and uh also a data has this property of uh being non-level so unlike a physical object for example if i'm holding my laptop nobody else can hold the same laptop at the same time so only i get to use my laptop um but whereas with data i can hold a copy of the data and somebody else can hold a copy of the same data and both party will be able to use the data and and also there's data dependency and data externality and so on and hence to address these issues we cannot simply copy concept and methods in the analog world to the digital world and hence to enable a framework for a responsible data economy it needs a combination of technical and non-technical solutions and in particular includes three components technical solutions incentive models and legal frameworks so today's talk mostly focused on i would say some particular um elements in this overall framework i actually have longer talks about the whole framework uh how to build a responsibility economy but today we're going to focus in particular on the data commons uh aspects and the relevant parts with the data commons for public good so um so before we talk more about the data commons for public goods another uh another related aspect that i wanted to just briefly mention is about um a literally more detailed the personal uh data side so as we know that the personal data also today is largely locked into um third parties uh are being followed into third parties however now actually it's a great time for making a change uh both in terms of data sovereignty and helping data to help users to make better uh take better control of their data and better utilization of their data so there is the um a number of uh privacy regulations including for example gdpr that requires uh to provide uh to the users the right to data portability so essentially it requires third-party services to provide users with the capability and to be able to um essentially download and move their data in an easy fashion and to uh to outside of um the particular third-party service and with the uh right so with this one can users could actually with the right tools and capabilities could actually um for the first time to download their data from the different third-party services and put together into what i call this personal data about and um and with this uh also including for example their facebook google data and even for example their fitbits and other medical records and so on which has similar portability requirements also and um and with the data vault essentially one can also build these collectives and that i'll talk about in a second and these data commons that can actually help put data together but still enable users to maintain control of their data specify how they want their data to be utilized and and then enable data to be utilized in a privacy-preserving way and a compliant way and help users to gain more benefit so just very quickly in order to achieve this so um again i'll talk about the data commons concepts in more detail uh in just uh um a minute but before talking about that i do want to set up some stage in terms of the technical requirements in order to achieve that so the high-level goal of the data commons is that users or other data producers even institutions for example could provide data but instead of having the data all kept in its own data cells by utilizing new technical advancements we can enable this new secure distributed computing fabric that enables data to be um to be essentially be for example governance by a structure called data commons which specifies how data could be used and um and have the techno means to ensure the privacy and compliance uh of the data usage and hence enable the state value to be extracted from the data commons for public goods and also users in the end can achieve can also receive benefits from that as well so given the limits in the temperament i won't be able to go into the details on the technical side of the different component technologies that's needed to enable this i just wanted to quickly mention essentially there has been a huge advancement in what i call responsible data technologies and these responsible technologies help and enable data to be utilized in a privacy-preserving way including secure computing which helps protect the computation process from leaking sensitive information and differential privacy which help ensure that the computation outputs won't leak sensitive information about individuals and the federation learning help help users to maintain the data on their own device or machines but enable machining models and analytics to be done in a distributed manner and finally with distribute ledger it can help provide a mutable lock to ensure to essentially want to provide the immutable log of users rights to data and how the data should be utilized and also ensure ultimately log for the actual data usage as well and i wanted to just quickly put this together and show you give you a quick uh glimpse of how what what can happen when we put all these component technologies together and how this can enable uh new structure for data commons so in this case we have the data providers again these can be individuals as well as institutions or in general we call data providers that has data and the data provider in this case can provide uh the data in the encrypted form with the policy attached to it uh to um to specify how uh the data provider wants the data to be utilized for example the data should only be used for um in a privacy preceding way for example to train differentially private machining models and also should be used by medical researchers for from nonprofits and so on for example and and this information can be committed for example to a public blockchain and and then you can imagine that essentially there are many of these um or also called data capsules so this can be in a distributed catalog and the data the data analysts out there the consumer in this case could search through these catalogs and as they find data that it wants to use it can submit a program and that it wants to run on the data and then um and then there's a component that essentially we call in this case the access controller and that will then actually run a static analyzer to um to check the required data use policy against the program and also outputs a residual policy which we don't have time to go into detail um but essentially the system analyzer will check whether the um this analytics program uh satisfies the um the required policy and the yes it can send the proof of policy compliance to this uh distributed key manager and also we have for example a trusted execution environment this can be done in different ways either utilizing a secure hardware it can also we can also use for example methods as npc and and so on and so they um right so in this example let's say it uses a secure hardware in this trust execution environment so essentially the data will be encrypted data will be sent into the strategy execution environment and the key manager will send the different key inside as well and the encrypted data can be decrypted and the program can be run and which returns the results but the results will also stay encrypted together with a residual policy and then for example if the the program fully satisfies the desired policies in the end actually the results will be um actually in the clear and the the uh data analysts could see it depending on the residual policy and uh and so on so then depending on the residual policy the analysts can download the results to create the train model around additional programs and to satisfy the policy and and so on so and all this will be also logged on the public browsing to maintain the audit trail as well and the providers can also inspect the blockchain to see how their data has been utilized and again today we have the technical means to essentially accomplish all these different aspects and when we put this together essentially we can enable what i call here a data commons for decentralized data science so essentially the data owners it is the producers they can register their data sets with the policies specified to this distributed data catalogs that can be maintained and they're also on the public ledger and then the data consumers and analysts they can um i search the data catalog identify the relevant data and then write their data analytics and machine learning program and and submit it to the platform and uh and then the platform then can provide the distributed secure computing while ensuring that the program is compliant with the desired policies and and then with others then essentially this can enable decentralized data science and that can help reduce the friction of data usage remove the data sellers and also provide strong security and privacy guarantees and also in this case as the data consumers and data analysts use the data it can also uh provide rewards back uh into the um to the data producers and also other entities in the overall ecosystem by uh providing for example uh utilizing like data tokenization and methods as well so essentially providing so essentially for example the data commons can have uh uh the pool can utilize uh instead of having pools of data tokens and the consumer and data analysts will need to for example purchase data tokens in order to utilize the data as an example and enhance the data the original data owners and data producers can get um rewarded that way so um so overall in 10 years i strongly believe that the data charts and data commons will become predominant ways of utilizing diverse sources of data enabling ownership economy where users benefit from the data as owners and partners and in 10 years data stewards fiduciaries and trustees will be a new class of entities importance in the ecosystem managing and protecting uses data and growing its value and in ten years huge economic value will be created through these new forms after the trials and the commons also the magnitude higher than today's data marketplace and i know i'm running out of time so one thing i just wanted to quickly mention is that i think this data commons also allow really interesting um new structures and new types of services so for example one of the biggest challenges for providing value back to users for their data is that in the end each user may be only getting a very small amount of value back to their data may not be sufficiently interesting to them but however with data commons when this data is is being put together then the value created by the city commons can be really significant and in this case with the decentralized governance for example in healthcare in medical domain actually uh such a data commons with medical data could actually be a provided means for providing new forms of medical insurance to users who are contributing data their medical data for the data commons and and as a reward as value received back to them they actually get benefits from this medical essential health insurance and so on so essentially this gives a really interesting new ways how to uh how to empower users to um and also for public goods to set up these data commons also and also i didn't have time to talk about some of the other projects that were also working in the process for example the data commons is not just limited to fully uh to to the type of sensitive data dimensions essentially we hope that in the future the data commons from users data accounts will train and these machine learning models that can be another form of public goods and another product from this data commons and even in the future we hope to be able to create knowledge graphs and that are being created by users together and as a form of data commons as well thank you i know i'm running out of time that was great thanks to don for giving us an overview of the landscape of responsible data technologies and some really new great exciting opportunities in that sphere [Music] [Applause] [Music] 