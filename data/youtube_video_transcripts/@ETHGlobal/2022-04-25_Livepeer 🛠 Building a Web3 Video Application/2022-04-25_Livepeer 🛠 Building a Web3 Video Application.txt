all right hello everybody thank you for being being here um my name is eric tang and i'm the co-founder and cto at live pier and victor i'm an engineer at live beer team as well yeah thank you thank you for being at the at the live pier workshop and um thanks to eth globo for for putting on this awesome event today we we have about a 45-minute workshop i'm going to spend a little bit of time talking about video streaming technology just to get us set the right context introduce you to to live peer and you know the protocol that we've been building um we'll talk about video streaming for web 3 and how that's different from video streaming in web 2. and finally we'll do some demos and tell you guys what the prices are um so just a quick um um quick uh intro about what life peer is life here is building the video streaming layer of web3 we've been building this project for the past five years we've been we've gone through many iterations currently the the network processes about two and a half to three million minutes of video per week um you know those videos are viewed by that many million uh number of users um so so a just a quick overview about video technology all right so um video is about 82 of all the data in the world today uh all 82 of all the data on the internet needless to say that's the majority of the content that we consume on a daily basis and that's why life here is excited to be working on this technology and to decentralize the infrastructure so so when we talk about video infrastructure and video streaming technology like what like what is it how is it how is it done right there's really three steps there is kind of the ingest and upload step there is the video playback step and then there's the video processing step right we're going to go into each of those steps just quickly so that we can set the right context um so here it's a kind of a typical architecture of a video application of today right where um it looks a little complex i'll go through each of the steps so it doesn't look so complex anymore um the first step we talk about video ingest and upload right so this is really dependent on if you're building a video on demand application so something like a youtube where you upload a file and have it streamable by anyone on the web or if you're building a live streaming application which is something more like a a twitch or facebook live right where people are watching you in the moment as things are happening so for live streaming it's about ingesting a live stream broadcasting it and for video on demand is about uploading a file into a back end and and on the receiving end usually there is a media server that's receiving the content right it speaks the language of the video protocol speak the language for also http if you want to upload it and and there's many different types of ingest tools that you can use right so oftentimes we think of especially for live streams we think about you can i you can either have a desktop-based broadcasting software something like an obs studio which is really popular amongst twitch streamers you can have a mobile app that that's broadcasting the video uh barack obama live stream using the camera on the mobile phone or you can have an in-browser uh broadcasting uh studio that's only recently starting to get popular uh and and you know you might have heard of like a restream or things like that so but those are just end user tools right if you're a developer and you're building an application there are a couple a few sdks that can help you to build those types of experiences so for example there are there's a react native component called node media client that allows you to build a mobile broadcasting experience and then we've actually built a tool called webrt webrtmp that allows you to build a in-browser broadcasting experience that can you know capture the webcam on the on on the laptop right um so so that's a little bit about interest the ingest is all about you know putting the video into into the backhand right and and now the video is in the backhand um how do you play that right so so here is delivery and playback video delivery is often times delivered through a content delivery network or shorthand cdn and this is because oftentimes there's you know tens of thousands or hundreds of thousands of people watching the same content in the case of a live stream you know if you're watching um the world cup or something there's millions of people around the world world watching the same stream right so in that case you really need a really scalable infrastructure to be able to deliver that kind of content and a content delivery network helps you do that or you can if you if you don't have that many viewers sometimes you can deliver directly from a media server and that's also possible but when you're delivering it you're delivering it to a video player on the client right so the video player can be you know either on the mobile phone or it could be in in a browser and and in terms of delivery and playback we think of hls which is the video streaming standard defined by apple there is adaptive bitrate streaming which we're going to go into later and then there's the video player right so let's first take a look at hls like what is hls like why um why is this thing interesting well hls is the file that you give to the video player in order for it to play right so the hls hls represents the video itself uh and the the um the format of hls is you know there's a playlist that uh describes kind of all the different small media segments and then there's the there's the media segments themselves right which is you know the video cut up into small chunks and then the the video player simply loads each of those chunks uh in a sequenced way and then they'll be they're able to play it back um in real time or sometimes if you're two exit you know it'll play faster than real time right so that's really hls so when you're thinking about a video stream it's actually tiny little files that are that are making up this big stream um so that leads us to the second topic which is adaptive bitrate streaming and this is the secret sauce for how video is able to play on the internet in the first place because if you think about this problem we're streaming video under all kinds of different networking connections from around the world on different types of devices different sizes of screens right there's so many different varieties but yet everybody expects to be able to watch the video just the same right so in order to do that what we do is we transcode the video into many different versions of many different bit rates so that you know if i'm sitting at home watching a video on my smart tv i can watch like a really high resolution version of the video or if i take out my smartphone and start watching the same video it's going to be like a shrunken down and lower resolution video right and when i'm loading that smaller video i can i can load the smaller bitrate video and adaptive bitrate streaming is saying that as you're streaming the video you can actually change the version and the resolution of the video that you're watching without a broken experience so for example if you're ever sitting at home and you um you watch netflix and it starts out really grainy and then it gets crisper over time that is adapted bitrate streaming at play right so the smaller version comes on at the first at first because your networking is just kicking in and then as the video plays the player realizes oh you actually have a much higher network throughput and it starts loading the higher resolution version and this is very crucial for video streaming to work correctly online and we when we talk about video players right it's really a piece um you know a piece of software that you can put in your in your web application or you can put in your mobile app in order to play that hls video that i just talked about now there's there are many different many different sdks or or products that you can use right there's open open source videos players or close or proprietary um video players here i'm just kind of sharing a few of them the most popular open source one is probably um video.js okay so that is kind of an overview of playback now let's talk about video processing right video processing is something that happens behind the bat in the background that most people don't know but it's actually a super super important step right we talk about that transcoding step and that's how we're able to enable that adaptive bit rate streaming way of streaming video right so usually when the video it gets uploaded or ingested into the media server it gets sent to a transcoding engine that then transcodes the video and then puts it into a cdn or stores it into object storage the thing about transcoding is that it is super computationally intense right because you can imagine videos are very complex data structures and you have to kind of decode the video understand what it is re-encode the video into different versions store them somewhere and that's really that's really expensive process so transcoding you know work the workflow looks something like this right where you have that transcoding engine you can for example ingest like a 1080p version of video and you can transcode it down into a 720p and 480p and 360p and 240p and they're all appropriate for different device devices and different different networking conditions right so that's a little bit overview of video streaming right so all of those pieces together makes video streaming work on the internet so now that that's pretty complex for anybody here this weekend trying to build a hack you probably don't want to think about all those things and put all those things together that's that's way too much work so at lifepure we built a decentralized solution to make to make all of those complexities go away and to make it really affordable so how do we do that um live pier at the core is a set of protocols it's a protocol that allows people to contribute resources onto a network that then they can also get paid for contributing that resources the set of and it's encoded as a set of smart contracts in solidity uh it's deployed on arbitrary uh it was first on ethereum recently we migrated to arbitram um and and it acts in a few ways and one of the most important things that it does is that it acts as a global registry of these orchestrators that represent kind of transcoding capacity around the world so if i am a broadcaster or if i have a video that i need to transcode i can talk to this global registry and say hey tell me a list of people who have capacity that can do this work for me and through this discovery protocol i can not only get a list i can also kind of start testing oh who's who's closer to me right who has a good latency with me has good connection with me and i can start sending my video to them and they can start transcoding that for me and of course the protocol also handles micropayment and all these things so the value transfer also happens and the orchestrators are incentivized to do that transcoding work right and the other thing that the the network does is that it's highly redundant and what that means is you know there's lots of orchestrators around the world and there's lots there's always an overabundant amount of transcoding capacity on the network so that you know if one orchestrator all of a sudden goes offline so for example you know i'm running i'm running an orchestrator in the data center and the data center loses power and everything goes offline and that's totally fine because the the software is resilient enough that it will just immediately fail over to another orchestrator it'll continue to work right so even for a video live stream it won't disrupt the experience and the other thing that you can do is you can double up you can use men you can use multiple orchestrators at the same time so that you know if one goes away it doesn't even matter in fact you can just have the two race right and whoever gets back to you first you use that one under the hood if you look at the live here protocol i'm not going to go into this whole complex graph right i just want to show this graph in that you know there's a smart contract right we have the broadcasters and the orchestrators and there's a verification process here to make sure when the broadcasters are working with the orchestrators they don't need to inherently trust each other like you can just say i'm sending my video into the network and i can trust that the network will verify the work for me and and and i will always get the right results back and if i don't get the right results back there is heavy economical penalty uh so that it's highly disincentivized for someone to cheat very similar to kind of the blockchain design concept proof-of-stake concept right if a validator cheats then they get heavily slashed therefore they don't you don't want to cheat another important concept here is that there's an on-chain portion and an off-chain portion so and of course when we talk about video streaming there's going to be millions of video streams that are happening on the network right we can't be writing transactions for every single one of those streams so all of the video streaming steps within the livecare networks happen in an off-chain way and the only thing that happened on the blockchain are the registrations of the nodes which happens only once in the node's whole lifetime and the payments which can be batched together and happen asynchronously okay so you know here i'm just going to go into a little bit of the token economics the way the way it works is that people stake their live peer tokens to the orchestrators and as the live your tokens get sick to the orchestrators the orchestrators can earn live peer rewards and at the same time the people who want to transcode their video with the with the network also paying in um also paying in in ether to transcode the video so as more demand goes on the network more the more valuable the network becomes because essentially the life here token represents um the um the amount of revenue that you can capture for all the revenue that's going through the network right and and then it kicks off this uh flywheel where the more the more demand on the network there is the more valuable there it becomes then it attracts more supply and then that that kind of wheel starts uh starts going so that's it um that's it's a little bit about the intro of live pier a little intro about video streaming now victor is going to show you some exciting demos around around video on demand streaming and also around live streaming let me set this up hello right so i wanna show you the capabilities that we have in our in our service in our api and we're gonna start with the live streams so we have this dashboard page here with the streams you have in your account i'm already i have already registered i'm logged in here and you can create a stream from here but you would normally be doing this from your application so you you we have an api that you can use and you got an api key and then you can create all the objects on demand as your application logic requires and we can start here let me increase this so we can start here by by creating a new stream and you give it a name i'm setting it to record as well and here we have a fully created object and it has the configured renditions that you want for your for your playback so it controls how this this stream is going to be transcoded and then here are the important bits right now which is the stream key and the playback id the stream key is the secret that you give to the to the user that is doing the streaming and they're it's going to give them right access to this stream to this channel and you also have the playback id which is the one you use for playback in the stream and it's more a little more public in that sense that many people will be watching but only one will be writing and here is the stream that we've just created and say this is an example application that can do video the live streaming from the browser using the sdk that we showed and all you need to do is to copy that stream key here so if you say your application creates the stream and then it's going to send this key to your application somehow and it's going to it can start streaming to that channel and then if we see here in the dashboard the stream should now become active or maybe not yeah it did so it's still loading starting the the transcoding and everything and while it does that i can also show the playback application so this is just another example that has a video video.js player and all we need to do here is create this url which is the playback url you can also copy it from the dashboard so here is the playback url and this in the same way you are in your in a real application you would actually get this specific playback id from your server from your backend and then you inject in the front end and you can see the stream as it is happening and there's just a little delay of the actual transcoding of the stream but it's live coming from this web page here let me close this and this was using this webrtmp sdk that we showed which is made to for you to stream directly from the browser and it's good to do quick demonstrations or or start getting started with the live peer platform right so the other thing i can show you is the vod api and so we have here this other tab in the dashboard it's not the streams it's actually assets and it's where you can see all the files that you have uploaded to the api and the same way you can create an asset here by giving a url to import etc but i can also show that via the api here as well so the process there is actually done in two requests instead of one and first you request for an upload url that you're then gonna use to actually upload the file and this url here can be called from anywhere so the idea is that you create this this pre-signed url on the backend give it to the front-end application and the user can do the upload directly so you don't need to do any kind of proxies of the actual file then to use that url you just do a put with the file as the as the body and here it's already going and when you import that an asset you get a task that processes the asset until it's it has all the metadata and like the duration of the video bitrate all this kind of stuff and you can also call this other api here to list all the assets in the account you can also read individually but this is easier for now and here's the asset we just uploaded and all the specs that we parsed and it also has a playback id and but let me show it in the dashboard so here it just showed up the one we just uploaded and it has a download url here which is actually how you can play back the the file so this is just playing an mp4 right now and we are working on adding hls support for assets as well as soon as you upload the file to livebear you can already use it from this your this download url and here you can see that this one also showed up and it actually came from the recording of that stream the the first part of the demo and it's also the recording also becomes an asset later and you can use it the same way and play back the the recorded stream as a as a video file or export it or even create an nft out of it and so let's go into the nft part exactly we have this sdk the video nft sdk that is built that builds on top of this vod api and you can use to easily create video nfts so it handles both the uploading of the file the processing in in in the live peer network in case it in case it's necessary and they export into apfs and then the actual minting of the nft from the exported file it can be used to build any kind of application you can use it from the front end from the back end from a cli and we actually have a couple of examples using that and i'm going to show this one which is just an application on the front end and if you are logged in the dashboard you can go to just mint nft and you're gonna see this this ui here and let's use the same video file and this is just the smart contract that we have deployed by default but you can also use a custom erc 721 that you that you have and first up so it's doing the similar the same process that i just showed in on postman to the it requested the upload real then actually sent the file then it did some processing and i'm gonna explain soon and then i already exported to apfs and it has this hash here this cid and it's already injected here and now we can actually mint with that cid and this this exporting here currently it's like we if you're using openc there is a file limit of 100 megabytes so if it's if the file is higher than that it's not going to show anything it's not going to show the preview of the file and but when you do it through the sdk it's going to check that and it can transcode the file to a lower quality just so it shows on openc and it's not just a blank nft over there and here we can see that it finished yeah so it's already available here on openc and i did it on testnet but it works on mainnet just fine and yeah back to the processing did we also intend to add support of to other kinds of things like if you upload a video that has a codec not supported on the internet on the web on most browsers we can also offer to to change that so we that's exactly where we plan on adding more and more functionality with the power of the lifebear network and we can also go through the smart contract if there's time the so just to go go through quickly here i mentioned that you were you would be using just the default contract here but you can actually create on your own and just change the address here so the the sdk calls that that separate contract and you can do so following this guide here that is in the also in the documentation of the sdk and we have like the base code here for the contract and it's really simple just uh inheriting from an open zeppelin contract and then adding a simple logic on the mint that i can show here like we not gonna show here is better we just import the the contracts from the open zeppelin then have our custom one inheriting from it one that has the storage for for the nfts and then this counters just keeps track of the ids of the minted nfts to always create a new one with a different id and then we have this event here which is sent after the mint is done and is what the sdk relies on to show what was the the minted nft the minted id of the nft and then this is the main main function the sdk also relies on a signature like this and then it basically creates the new token id means it with for the for the respective owner and sets the uri to what is sent on the request here and that comes from that thing we saw here this is the token uri that went on that argument and then that's it it emits an event with which we can use in the front end to show any information about the the newly minted nft all the and finally all the other uh methods from erc721 are already present in this contract just because it inherits from this so it supports any tool that relies on on these interfaces like openc itself so that's how it just shows up there uh as we minted and i think that's it for the demo all right thank you victor um i want to spend just a few more minutes talking about prices and ideas that you can think about building for the hackathons today live here is um offering up sixteen thousand dollars of total prizes i'm really excited to be to be here and working with the hackers here the first prize is for six thousand dollars and we're looking for uh developers to build the killer video centric social media creator or gaming web3 application this is an area that i think is ripe for disruption for web3 all of the components from infrastructure perspectives are here for us to create a web3 centric social media platform that can be comp that can be very competitive to today's uh platforms like a youtube or or a tick tock right so we're really looking forward to to seeing the creativity of hackers here building building platforms like this the second the second price is for four thousand dollars and that's for the best use of the live peer video nft minting sdk that we just that we just showed um we look forward to seeing how people can creatively use this asset of video nfts to do all kinds of interesting things right and think about um you know kind of thinking beyond the kind of the speculative use cases i think there's a lot of really interesting interesting areas that this can go to the third prize is for the best video the man application using live pier so simple think about this as the web 3 youtube right how would youtube look different if it's built in a web 3 native way what kind of features would it have what kind of value proposition would it have for creators to be able to connect directly with their fans to be able to directly monetize the work that they do i think there's a lot of really interesting ideas in here and finally uh fourth place um fourth price uh for two thousand dollars we have the best applications of live peer in the metaverse right the metaverse can be interpreted in different ways um i kind of think about the metaverse as this just already deployed and already running decentralized infrastructure in general instead of i think the more narrow definition would be kind of like a rendered 3d world right so thinking about using video streaming both video on demand and live streaming into the metaverse or from the metaverse to show kind of people not participating what's going on in there i think there's a lot of interesting use cases there as well so that's it um we i think have a couple minutes left uh if we have any questions from the audience um we're happy to happy to hear that right now i have a quick question on the um so when you showed the live video so the stream that you just created during the demo so it was also uploaded as an asset the asset that is displayed there is it only one of the encodings that's there or is that also like in the different uh formats like different kilobit streams and so forth so so the asset that is created automatically is with the from the source video so it's just the highest quality version but when we also do have a recording that is the same hls that was made during the live stream so it has all the transcoded renditions and you can actually download those as mp4s as well but by default we create only the source any other questions from the audience all right thank you both for the overview and the demo given that you're thinking about video all the time but building it from an infrastructure perspective if you had the time uh to to work on a hack what are some ideas that you would love just a spare extra 20 hours to work on using lipir maybe we can do we can search over yeah so something that would be really cool would be a mobile app using the the nft sdk and then you could just make a video and immediately make it into an nfg really really easily on on could be just like a camera phone that because that creates an fts out of every video that you create or something like that and i don't know could be also uh more more different video nfg so that you can create different interactions with video nfts like you can maybe split your nft into each one is one part of the video then you gift it to someone else and then you can merge them together if you have the continuous parts or i don't know some crazy stuff like like that that would be really cool to see um yeah there's so many so many interesting things that people can work on i have a couple of ideas um there's been a hundred applications over 100 applications built just in q1 alone on in live pier um some of the things that are really interesting for example the video streaming application for dev connect is actually built using live pier and is streamed with live pier it's called i think stream eth dot tv one of the things one of the interesting things is it was a collaboration with between life here and ethereum uh the ethereum foundation one of the interesting things that we did is not only is it now completely open source anyone can take that website and just change make improvements on top of it um for example adding like a chat function or adding the login function so people log in with ethereum so people can see you know your your ens right things like that um but it's also compotenized uh modularized so that for example the video player that's being used in its uh is actually a module and this video player has some interesting functionalities one is that you're able to have automatically have a primary and a backup stream so that you know when you're streaming an event you can have two streams going on in case the primary stream fails it automatically switch to the second stream and your user doesn't feel uh doesn't see any um didn't see any breakage in the experience but there's so much more that you can add in this video player right just think about what a web 3 native video player is can look like and what kind of functionality that you can have right like you can start tracking you can you can start allowing the viewers to log in with their metamask and show the nfts that they have in their wallet and the nfts can then that information can be sent to the broadcaster uh so the streamer themselves so the streamers can know the type of people who are watching their streams right um and this kind of like an idea off the top of my head but um there's um i guess the point that i'm trying to make is that there's a lot of really interesting toolkits that are already built within the live peer ecosystem that you can just take and make tweaks on top of it to add interesting functionalities and i'm pretty excited about that would it be possible to add extra transcoding steps like some kind of post-processing or like watermarking stuff like that yes absolutely you can do that um you can so everything in life here is open source right including the live pier node itself the live pier node currently handles video transcoding for different codecs it also handles smart smart smart av features so for example if you want to transcode but also do like scene detection to figure out if someone is like streaming adult content on your platform you can do that right so that that kind of gives you an idea of like how open-ended it can be when you talk about just open source and open video processing uh you can absolutely add watermarking you can add com like compositing right to add different um kind of artifacts on top of that so it's not just a watermark it can become animated um yeah all kinds of uh all kinds of cool ideas that can that can come into that one i like it the other way around you know something is it's not like uh you know too dull but maybe too fast so you know like really catering towards people who cannot watch too fast stuff i just took the idea i don't have a question sorry thank you for your contribution any other questions oh one you mentioned that there's a penalty um similar to proof of stake i was just wondering what exactly is the penalty yeah that's a really great question so that's uh really in the in the core design of the life here protocol right and and the idea and the problem that that is trying to solve is that um you know imagine i i'm subversive and i ran a live peer orchestrator on the network and i say hey i provide transcoding services to everybody and you send video to me and i start it's a transcoding video for you but i start ingesting weird videos in the middle of your video or i can just simply return blank videos to you or i just won't do the work at all right um so any of those uh situations are really bad for the quality of the quality of the network and we need to have a way to prevent that so the way to do that is there's a verification mechanism in the protocol that allows uh the broadcast allow the person who's using the network to say i want to periodically verify that and make to make sure the work is done correctly but i won't you won't tell me which one uh which segment that i'm gonna verify that you're gonna verify right so um if i am because i am on the network and i'm signing cryptographically for every video segment that i give back to you you have clear proof and evidence that i said i did the work right so if the verification fails you can submit that proof on chain to say hey eric eric cheated and the protocol will automatically slash me by taking uh some of my stake uh lifespare token away right so because in order to participate i have to have some skin in the game and that says this is where kind of the the staking mechanism come in again very similar to how kind of ethereum staking works a totally different question because not about the technology itself but um how do you envision like conquering the world with life beer so how do you compete with let's say web tour traditional video transcoding services is it a competition based on pricing do you claim that you can do it cheaper than the competition or is it more about that you have more features as web 3 enables what's the plan there oh man uh what's the plan there um there's definitely that cost uh aspect right live peer is ten times cheaper than amazon web services from an infrastructure cost perspective and that's just because there is so much spare capacity laying around the world that people can donate to not all people can put on this network and to make a little bit of money back right so um so that's really interesting the other thing that's interesting from a long-term perspective which i think is a lesson that we've all learned from the bitcoin network 10 years ago is that if you put a simple set of incentive out there and you say this is encoded in the protocol everybody feel free to do whatever you want with it people are smart and they figure out how to take advantage how to figure out how to game the system by improving their performance to make it a little faster for themselves and when everybody's doing that that grows organically like crazy right so 10 years later the bitcoin network is by far the largest super computing network in the world in terms of the the power of computation right because people started building uh gpu mining software and for a couple months that was profitable and and immediately it became fpgas and they immediately became asics right a6 kept getting faster and faster and faster so we already see that happening in the lifetime network where asic asic miners are coming into the network they're creating videos video transcoding specific hardware to be able to compete with kind of traditional traditional gpus so that will only get better and better over time and that's where the long-term cost advantage and scalability comes in right but i think that's just one angle the other angle that's that's really interesting is this web 3 movement that's happening right and and the weaponry movement is really about ownership it's a it's about giving people an opportunity to have a more open and transparent system and that i think is highly disruptive to the existing world of um like video platforms right when you know you use youtube youtube's take rate is about 50 that means for every dollar that a creator makes on youtube youtube takes 50 cents from that right that is crazy for a platform that is made is made up of the videos that people upload they don't make any videos themselves right um so by but using web3 creators essentially get to say like i actually own the video myself because it's tied to my ethereum ethereum address which is on the blockchain layer the application is simply built on top of the blockchain layer right so for uh so live pier is building the the video streaming layer for web 3 that has all these hooks into other web 3 kind of other web 3 components that together creates this web3 video application stack that allows people to build these types of web3 native video applications that i think in the long term are going to be yeah just very disruptive yep cool thank you um two questions first one is do you think that the the network of uh transcoders will ever be like spread out enough that you won't need cdn networks and is there like a idea in your mind to build out another set of nodes a different function that acts as the cdn or anything like that and then the second question is if i just uploaded a file to ipfs and included that address in my metadata for an nft would that work or does it have to be transposed to a mint and nft um cool first question about cdns um so live here actually already contains software that allows you to deploy your own edge node around the world in order to kind of like run your own delivery right and then for a lot of applications that works extremely well um we have a you know we have a um a user of live peer who runs um runs an application that has like over 80 million minutes a week a month and have like over 75 000 streams per month this like pretty popular video streaming network and they don't use a cdn they just run live peer nodes around the world like a couple of like three or four locations around the world and they're able to handle a lot of traffic that way so that's it that's you know the current way to kind of scale your delivery if you don't want to use a centralized cdn we're also working on a decentralized cdn solution that allows each live peer node to essentially serve as a seed of a swarm of nodes that are living in people's browsers right so what that allows you to do is to run a live stream and for your viewers to watch the video and deliver the video to each other so it's not always loading from the network and that's the way to to really scale out and and that's really that's a really good um situation for a really good solution for when a video all of a sudden gets variable right and that's kind of the worst situation for a centralized video platform because you know in centralized planning you already planned out your capacity and when something unexpected like that happens which happens all the time it can be really uh disruptive to the network that's already pre-provisioned right but in this world when the variability happens it's great because people the people who are coming in to watch those streams are just delivering the video to one another right and that kind of protects the network from this like you know almost like ddos attack right um so that's that's that second question is about um nft minting um yeah you you absolutely can just like use a video and you know upload it into ifs and use that hash and mint the video uh however video form video files come in all kinds of different formats they come in all kinds of different uh different resolutions right oftentimes um they're not optimized for video streaming on the internet or especially streaming in the browser right so have you can think of live peers network as almost like a optimization or standardization layer that just processes the video so that it makes sure when you're minting the video you have like the best file format to do it right yeah is it is it multiple formats to put in nft um currently it is one format that's like the optimal format uh but yeah in the in the in future versions we'll add in um kind of flags for people to to have a little more flexibility there yeah all right how are we doing on time we're all right last question um is it technical um possible to make a mint out of one nft video more nfts so like for example editing video you have one video and some people want to make some art out of it so and make a second nft out of the small nft do you want to answer that one uh so you you from from the from the live view perspective the the sdk you could mint the same video multiple times you can also like create the smaller segments of the video and create separate nfts out of those and but you could also build something maybe even on chain to do something like that maybe you you have the the nft which points to the video but it has an offset in the video as a metadata and then your nft application knows that it's not owning the full video only part of it and then you could do like you could could create sub nfts or smaller nfts on from the same video without needing to re upload or reprocess that video just by start by having that reference but that would be a custom protocol on top of the existing ones so you would need like your own application to parse it and and all that but i i don't know if i if i answered the question is it that okay or yeah when you make out of this existing mft a second one or more small energies that you know the small entities are actually from this oh right yeah so that that's one thing yeah still the question is if there's a way to know if the smaller file that was minted as the nft corresponds to the original one that before processing and that's something that we do want to to add as well which is like when we do the nft we upload not only the final process file in the in the right field for the applications to show the video but we also have a custom property that is like the original video is this and then you have a different ipfs file and with the proper application you could go in and play the the full play or download the full file as well so you can do both and you right now you can customize the the nft metadata as well so you could even build that on top of the sdk it's already possible to do so yeah all right well thank you all for the awesome questions and thank thanks for the crowd and thanks to youth global for hosting [Applause] you 