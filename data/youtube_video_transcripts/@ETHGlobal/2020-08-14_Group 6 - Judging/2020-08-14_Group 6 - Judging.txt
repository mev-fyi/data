okay stream is good good way to start it off [Music] [Music] [Music] [Music] [Music] all right welcome everybody my name is uh kartik one of the co-founders of the global and welcome to uh hack fest judging so uh for those of you who don't know hackfest was a month-long hackathon that we did in partnership with protocol labs is if global and uh we're taking this entire week for uh showcasing the projects that came out of this event um so for as a quick summary for people watching this uh on on video uh the past four weeks we've had 470 hackers from different 50 different countries are working across 19 different time zones and uh we had a whole mix of people who were beginners and intermediate and advanced in their skill sets on the understanding of the ethereum and the the protocol last welcome ecosystem and they spent the last four weeks working on projects that use and show creative uses of both of these technologies and as of last thursday we're super excited to say that we've had 132 projects that came out of this event and we're kicking off a whole week of showcasing these amazing projects and today is day four of our demos so i'm going to quickly walk through the logistics of how this call is going to work for everybody watching this uh in recording uh there's going to be 13 teams that are going on that are going to go on today each team will have 4 minutes for a demo and 4 minutes for a q a and to minimize any logistical and av issues we've asked all the teams to pre-record their demos so we can quickly walk through and adjust uh if if something is uh is uh not working according to expectations and uh as a quick overview of how the event itself was structured each team had a maximum of five members they could work with a lot of the projects are in groups but we also have a lot of individuals who are going to be demoing and as a general rule all code that you're going to see today was written over the course of this event so everything was done as as the event itself began and the only criteria for being eligible to uh to demo and be part of this event is that they must incorporate the tools and technologies from the protocol labs in the ethereum ecosystem so we're seeing a lot of really interesting and creative matchups of what you can do with decentralized storage and smart contracts and the way we're going to think about judging these teams today is going to be on these five different categories so each team will be rated on how technical original and practical their idea is and how easy it is to use for their intended audience and because we recognize that these four categories may not be enough for everything we also have a channel category that would like to call the wow factor that helps us sort of do a catch-all for anything that we may have missed and before i go into our demos i want to emphasize that this is not a competition the hackers are very much here to learn they're here to share their excitement and the judges are here in particular to give feedback on what they see as their projects and how they can take it to the next level whether it's improving things or using a whole different technology that might be available now that abstracts a lot of their work but it's very much a session for us to celebrate what everybody's been able to accomplish over the past month and i just kind of want to point this out again not everybody is here to become a business so the goal is again experimentation and education and we're showcasing what everybody is learning to uh to play with these technologies so with that the schedule for today is going to be that these teams are presenting to our judges and uh doing the hard job are our three judges uh we have mta from consensus labs we have raw protocol labs and we have danny zuckerman from ceramic network and they'll be with us for the next uh two hours uh looking at and commenting on uh the amazing projects that we're gonna see today and up with that i'd like to call up on our very first move of the day and i'll let the parcel team take away and showcase what they did for this hackathon so jordan i think we're uh we're not getting the audio if this is playing you may want to just quickly check off the audio flag on the screen share and then we'll be able to get file coin and brand new hello and welcome to the sorry guys just one second i don't know what's uh we're still not getting the audio so what we can do is uh if josh you're on our smart contract development darwin handles integration hello and welcome to the parcel demo parcel is a service to manage crypto payroll seamlessly with end-to-end encryption using ipfs and filecoin we are a team of three i am anwoof and i handle smart contract development darwin handles integration with ipfs and filecoin and brennan is the front-end debit parcel we're using deterministic signatures with ethereum private keys and storing all the confidential data or documents on ipfs and filecoin in an encrypted form we're also enabling money streaming and through money streaming to employees in one click our aim is to enable employees to be paid in real time which leads to making payday loans obsolete we're also enabling mass payouts in one click irrespective of tokens held by employer or employees the idea of mass payouts was inspired by my previous hack at hackmoney with the same name and with this i'd like to call internal for the demo hi let's try to create an organization we can set the name for now amazon one two three so it is asking for the meta mask pop-up so it is saying sign your address to create the encryption key and this encryption key will be used to encrypt data on ipfs and filecoin so we can just sign it now now it will ask for the signatures for creating an organization so now let's create an organization on the smart contract and the id is submitted let's wait for the confirmation so our transaction is confirmed and we are redirected to our dashboard so we can go to the rules section and add some department here so for now we can see we have marketing department we have engineering departments and we can just create it so now uh we'll first calculate the encrypted data hash from ipfs and then submitted to smart contract with mapping with the sum index and once the transaction is confirmed we'll just can see here the departments so now we have marketing and engineering department here let's go back to the people section and try to add some employees so now we can submit the request so you can see the employees are added successfully now let's try to run the mass payroll for these employees so now let's try to run the mass payroll so in the mass payroll section as you can clearly see we have three employees with the salary of 10 die and 10 usdc and we have two options one is stream and other is pay let's try to run through pay first so what does pay means pay simply means we are doing transaction batching under the hood so in single transaction will be batching up the transactions for all the addresses and let's try to run the payroll via pay button i guess we can run the streaming for the same employees so we have already selected so let's try to run the stream and now i want to run the stream for all my employees for let's say another one hour and i can press stream so as you can clearly see the stream has been started for all the employees and we can clearly see this one percent of the streaming has been done and we have one more section here which is documents and here you can add your company's confidential documents so for now we can add any document let's say baseless it all starts with generating encryption keys by signing a deterministic string using ethereum private keys and then encrypting the data with that generated key then we send the data to ipfs and filecoin and store the return hash in a smart contact wallet owned by the organization and to fetch all the required information by retrieving the hash from the smart contract and decrypting the corresponding data locally to run mass layouts on money streaming futures work includes role management of data and therefore enabling encrypted file sharing within or outside the organization we're looking to expand our horizon to a full-fledged hr management suit to manage health records w9 etc but also exploring layer 2 solutions to offer efficient mass payouts and money streaming since gas on layer 1 is a concerning issue especially these days and layer 2 solutions like greek things offer a relatively better prospect for us we're also looking forward to making the code stable block free get the contacts on it and go to mainnet as soon as possible we live on on fleek as well our demo is hosted on fleek and thank you awesome thank you parcel uh so we'll turn over the judges for comments feedback suggestions um i didn't catch the part in the demo where you added people can you just talk me through that flow and what were the identifiers for the people and how do they get added to the organization uh sure so uh so the architecture that we decided for this uh works like this uh let's say if you want to add some people in the organization we store uh all the information of the data on ipfs and filecoin and we get a corresponding hash right so we store that hash in the smart contract and that's how the transaction works uh so that's that's actually encrypted by the ethereum private key so that is deterministically uh encrypted yeah so just to just elaborate on that question just for me to understand um what you're doing is sort of like deriving or calculating a object that represents the entire organization uh with the employment structure and so on and this object as you as it gets modified it gets changed and you store that object in ipfs and you always keep the smart contract updated with the latest hash right yeah exactly just to be specific we have a mapping on a smart contract which is so we have index based mapping so let's say the zeroth index is for documents uh the first index is for let's say employees that way we have one hash that we need to change all the time and so there are corresponding hashes that we only change uh in the ipf is direct yeah so you have multiple top level objects you've got it yeah um i think this is uh a an idea that i personally thought about because you know like if you look at how the world operates today your employees are trusting their employers to uh to pay them at the end of the month and one of the ideals of blockchain in general is to operate a trustless architect architecture would which can operate in a which can operate the world in an automated fashion in some way right so it does make sense um regarding um the streaming option or the streaming function that you that you uh that you demoed is is there a possibility to keep the stream real time going and flowing as long as the employee is still working with you or do you have to manually like look forward and book streams you know in a look looking forward basis um yeah so it's it's uh actually you you uh for at this point of time you have to uh store all the information on the ipfs and then when you call the function right so we look at and look at the information on ipfs but even then while the stream is running uh if you're planning to have notification subscriptions right so you can actually subscribe to notifications so there's a protocol called epns which is basically decentralized notifications so we're trying to integrate with epns and trying to think of a way to notify uh employers and employees uh regarding what what all changes uh that have done so this is the in future they might just need to update us with with the tab and then we'll know what what happens then and then act accordingly in the smart contract level as well okay great um that's that's the time we've got for q a uh thank you team parcel uh we're gonna move on to the next team today who are verona beam verona beam i think you're already on the call if you want to share your screen and play your video we can get started hello everyone we are bologna bean and this is our presentation for hack fest a hackathon run by ets global boroni bean is a decentralized content delivery network based on ipfs for internet service providers this is routine veronica and david myself let's take a look at how the current model works content creators such as lisa they need to rely on expensive cdn companies to make sure that the creations are available everywhere in the meantime cdn companies force internet service providers to install expensive third-party hardware such as their point of press and servers to make sure that all traffic stay local let's take a look how we propose that the model should work in this model cdn companies are aren't necessary anymore content creators take advantage of bbn and ipfs to publish all the content to the internet service providers right away in addition internet service providers they take advantage of the bpm protocol to run caching servers that will be pinning all the content that's been demanded by the customers all of this when nothing has changed for the customers they can keep using the internet as they've been doing it before so how does it work viveen has two key pieces the pinpop and the gateway the pinpop is a service run by creators or publishers that they use to announce and update the list of data objects that they have published to keep track of the bbn gateways which they serve the content and to handle the customer's http request the gateway is a service is a service run by the isps and it subscribes to the bimping pinpops let's take a look to a live demo we're going to start looking at the back end on the left we're going to be starting the pinpop as you can see has subscribed to topic on the right we're going to start the gateway let's take a look at the configuration files for the pinpap each topic has a source directory that he knows where the content is going to be coming and as well that has the different gateways that he should be serving the content for the gateway it only only has the subscriptions for the proper topics as we say with this source directory that has been added let's see what happens when we make a modification to this directory as when we look at it once that modification has been done the new content identifier has been updated and the gateway the gateway which has been listening to the publisher updates and pins the new content so let's look at the front end in this case we have a publisher like bill shakespeare he has his his latest content for the demo purposes we have a trace link so we can see what happens when we click on it based on the cont on the cid request uh it's been handled and it's been forwarded to the proper gateway depending on the on the on the on the content identifier if we look for the user we just have to click on the proper link and it gets the content as you can see bbing is the best of two approaches it's compatible with ipfs and untaps the power to fully decentralize content addressable networking it's an effortless decision for developers this master's degree is not is not required for c to debug it he also has the best of the cdn model policy maintain full control of the content in addition it's important to note that is in the best interest of internet service providers to use bibim servers of a city and companies for the future we are very excited about this idea we wish we have a little bit more of time to work on it but we hope that with more work in the future this can become something very interesting if you guys are uninterested please feel free to join us and thank you very much awesome thanks bruno b um and again we'll turn over the judges for questions comments feedback so i have a i have a that was that was really cool i have a question regarding to how you associate as you mentioned in the presentation that you associate particular content ids to particular content providers or particular gateways how do you do maybe i misunderstood that part but if you could elaborate a bit further how how from a given client uh the request lands on this appropriate gateway server that you believe to already have cache that continually so how it works it's it's gateway server is it has a configuration json file that is been subscribing to each uh pinpop depending on the publishers and the publishers get the choice uh have the chance to choice to choose which gateway is gonna be serving the content uh for example if it's based on latency or if the circuits the the publishers realize that some gateways is not working properly they can always redirect to the proper gateway and make sure that the customers is getting the content right away but everything works to suggest some configuration files are there certain types of content or use cases that you think are least well served now by the current cdn model especially for isps that you think this is particularly good for well uh especially for like large files like if we go to the example of netflix for example like this is a streaming service and we have duplicates of the same video all over the network and i think we believe that there is a waste especially for cdns that they use such a very high electric consumption so we believe that we can remove the amount of duplicates with the with the help of ipfs and instead of having to start a cdn for each international provider like a point of question for its uh service provider uh we believe that with ipfs and bernie bean is possible to bring to completely remove the number of duplicates thanks so much for your submission this is really cool so this is something that you plan on continuing on what's next for you guys like and are you planning on supporting it as an open source project as of right now yes our plan is uh to continue with it and a continuous and open source uh maybe in the future if things take off and things going well we we could explore making a company but as of right now uh we believe that it's best to continue as an open source to have something to get as many people as possible to help us can you tell us a little bit more about the team i think you you're working with somebody else yes unfortunately veronica wasn't able to have to be here she's working full time as well so she couldn't get the day off from work but uh so myself i'm a student at the university of waterloo in toronto i study systems engineering and veronica she's an engineer uh what way great okay thank you team verona beam um thank you very much excited to see who you'll present uh from uh from waterloo um i hope you come to eath waterloo someday in the future when we can run them again um okay thank you team verona beam we're gonna call up the next team which is zero swap i believe you're on the call now so if you want to share your screen play your video we can get started hi welcome to jira swap a decent place platform that enables auditorized loans for file coin and ethereum via oracle less time swap burn algorithm this also has a decentralized chat feature the team consists of jay rickson nandit and brahma we have used three bugs alcoin ipfs slate and flick to develop the product here is the front end to the application we have the time swap one protocol as a user you can borrow stick or lend the money or any any denomination you can choose a die you can choose ethereum you can put a specified redemption date and you can put a collateral the collateral could be any denomination and it could be a wrapped file coin once you hit okay it goes through the authorization through your metamask and once the transaction is complete you can see your transaction in the dashboard like i said you can borrow stake and lend and here is another example of uh lending in the lending situation the collateral is a requirement and and there is multiple variations to this and let me show you also the administrative interface where one can log in and uh to the bond interface to review the transactions there is also a chat component the decentralized chat component that would be showed so this is the chat system of our application this has multiple chat rooms that can allow users to either communicate about the collectors collateralize loan on time swap or about different d5 protocols as well let me type in a message so these chat systems are created by three box ghost threads which are peer-to-peer so these data are not stored on any centralized server and the beauty of this is that at least one of the pa needs to be online so that other ps can fetch the messages from it if all go offline the messages disappear we have an inbuilt wallet connected to your wallet provider like metamask then we have the screen where we are sharing hot news and topics that users can chat about in the chat room then this is the page where user can manage their decentralized profile powered by three box yeah so that's pretty much it about our chat system as well thank you great thanks zero swap and we'll pass over the judges this is great thank you for your submission um could you talk a little bit about how you intend on sort of cooling initial liquidity by incentivizing people deposit their fill into your liquidity pools yeah so for that we have this taking feature we have all those functions in our smart contract time swap smart contract that we have created on our own so the stakers will be there who will be providing liquidity on dividends on a specified date to provide the liquidity for a specific erc20 token so this time's up uh protocol that we have created this is oracle less like others that you will see in the market but they take data from somewhere else but this is uh getting all the market interest rates by itself only by seeing how much okay the lenders are willing to lend how much borrowers are willing to borrow so that is the price of interest rate is being decided by the market only not by any external protocol as is done by others and you can you know lend your file coin tokens in here we are still working on the bridging part but right now we have demonstrated it for uh wrap filecoin which is a erc20 token so right now you can lend and borrow or state any kind of erc20 token pairs on our platform got it are you in terms of the protocol and sort of like the the mechanics um the market mechanics are you planning to do kind of like a detailed analysis of the game theoretics behind how that oracle last market would operate we know right what what oh yeah you can go forward no i'm just saying that uh this is where uh we have not included any any game theory aspects of it right now it's basically uh hinged on the stick that you put basically you take a look you want to you know suppose you want to land then you have a you have a insurance for lending and then if you are borrowing um sorry for lending you want to have a collateral and then you could lend if you're borrowing you want to have insurance so that way if the borrower cannot pay then we will sell that insurance and depending on how much incidence you take that would determine the the apr so that is it now we can also add the game theory in further versions as well rick who is our other teammate he had a full-time job he's not here right now he has published the white papers first version for the time swap as well yeah so so yeah our uh actual coder is not available uh for the bond protocol he he's the one who developed the whole thing so he's not available today okay got it thanks thanks for that answer um what i was looking for was you know the the acknowledgement that there is a lot more work to do in terms of you know designing the the mechanics of the protocol itself because it can lend itself to a lot of like manipulation potentially so definitely you wanna you wanna like really if you wanna if you intend to productize this you really wanna you really wanna dig into that but but yeah this was a really cool submission thank you this is just also for the chat feature we planned that in further versions uh you can directly interact with the protocols via our chat system like if you type in uh i want to lend 100 file coins for 200 diet let's say five percent of the interest or is it decided the interest is decided by the protocol so you will be able to do that by our chat system we are working to you know build some ai models so that it uh makes up like a chatbot system that is still working progress thank you okay uh thank you team zero swap um so we're gonna move on to the next team um uh which is eth quad i think we've got you on here already i'm going to play your video for you so let me just get that set up and we'll get started okay i'm sorry luke should there be audio on here uh no there's no audio okay i just want to make sure yeah sorry i'll just i'll just let it let it go then yeah uh i think the wrong screen is playing is it possible oh josh i think i think you're sharing a screen uh i'm sorry there's no video showing hey yeah nothing nothing was playing there sorry guys okay do you see a video now that's that's bad okay sorry everybody yeah oh if you can start from from about one and a half minutes into it sure i'll jump in there yeah thanks yeah so so this was truly a hack um i was trying out far coin and and all the different uh tools so i basically got um i got the the latest file coin running um got the docker docker containers all running that was all all there for me just what i needed um and then and then i basically integrated that into a front-end react with um with the back-end the node.js express backend um just in case just because the idea was that i wanted to i wanted to intro to integrate um ether 2.0 um and i wanted to protect the keys for that um so that was basically why i had had a separate separate back end um so what you can see there is uh all i'm really doing in this demo is is is going through the slate um guide which was actually part of the the workshops that i went through um but yeah i guess some of the things that that i was i was happy with was um uh going through with the was um yeah integrating the unstoppable unstoppable domains with pinata that was pretty um pretty interesting seeing how that all worked because i hadn't actually done any of that before um so basically writing a script and discovering other people who'd done who got involved in that before as well and then and then having the going through redirecting it from say a traditional heroku application through to an ipfs and then redirecting that again to to another um to uh the unstoppable unstoppable domains website or an ipfs hash um yes so what's happening now in that video okay yeah so you can see it's i've created a redirection there that was necessary to go through the ipfs hash and then if you scroll down the screen it basically shows or just it's just showing the a quick api query to the back end so that was pretty much in a nutshell what i managed to put together in the time frame um and then i'm just basically showing through showing the different um steps or scripts that i put together and that was just a screenshot so i've got a few a few different pins there i've got a production and a development pin on on um on pinata and it basically unpins the ones that i don't need using the script and it takes it was taking a while to to to redirect to the site from that heroku app for some reason yes it eventually takes us to a redirection page and then that redirection page takes us to the ipfs hash and then the idea there is is the um the web pages creating the the latest um okay so we'll pass over the judges i'm glad that you that you got to experiment with a bunch of things and so and so like you know mix and match a bunch of like ecosystem projects together you know it's really cool to see people you know experimenting and like you know having their juices flowing and like throwing out things to see what they what they managed to do this was pretty cool i was curious if you could uh if you could maybe talk us through some of the aha moments that you had when you were you know like navigating all these all these technologies and like you know linking them together and so on what were the things that actually made it all fit together in your head um well i i think when i when i when i discovered the script uh somewhat i i can't recall who put it together it might have been textile but there was yeah there was a docker container which basically spun up um it spun up the power gate it spun up the the lotus um file coin and and basically all the different um what else was there it also spun up uh but yeah basically spun up for all four docker containers that that all interacted together and that was basically all i had to query to to use the the front-end slate interface um whereas i guess if i had to do that manually myself it probably would have taken me a lot longer so um i don't know if that's necessarily an aha moment but um that was was quite quite interesting just to go through and see how that was done um and also um just understand like that the pin the pinning process so i went through and um yeah basically pinning and unpinning and and realizing that that um indiv like basically i was i was building the website in development and then i'd have to deploy that to production and having a separate ipfs address for each one for my workflow so that was i guess an aha moment that i actually needed a separate development and production environment and a separate ipfs just to preview what it would actually be like in production as opposed to um that was basically by the part of the workflow issues that i had um and and it was also interesting interesting looking through unstoppable domains and and actually looking at through how that was um um just discovering the transaction on ethereum and seeing where that was um looking at the smart contract and seeing if i could um how could do that manually like the transactions manually and all that kind of stuff um and and just chatting in the in the forum and seeing how other people were were tackling similar similar issues as well so that was quite interesting that's really cool it would be awesome if you could like contribute back to the community your learnings and in the form of like you know code or even blog posts on you know kind of like the story of how you integrated these things i think it would be super valuable but yeah thanks thanks for this yeah i think i think that was really hand like i basically created a checklist and i actually felt that was really handy for myself as well so anyone who goes to my repository they can sort of see where it got up to and if they wanted to sort of take it further or or borrow it and just use it for their own that's that was the i guess the key and see see what what's next you know so i guess it'd be nice to to actually work on the the quadratic sort of governments that was i guess something you know that's down the pipeline as well great okay thank you thank you luke i'm sorry again for the the video screw up there um we're gonna move on to the next team now uh which is hyben um uh so i'm gonna play the video again but i'll get it right this time and we've also got uh ken the on the live list as well who's going to translate um for the q a portion um so let me get this set up and then we'll get started okay thank you okay everyone can see that right great hello everyone it's my owner's range our team and our project where students from east china normal university at the beijing forestry university representing a heaven network technology company to participate the years is the history most of the members of our team are undergraduates and graduate students who are studying the direction of the blockchain this is our team and this is the all response and company [Music] hidden technology our projector is the item traceability system based on the ipfi size the the association when we build this the project during the current knighting epidemic the traceability of the item is becoming more and more important although some people have made the blockchain based item flexibility system it is the either based on the constitution chain or the problem of the preserving of the larger mods of the days has not been reserved this project is based on ipfis as the asterisk experienced the company information and the item information to ensure that the large amount of information is stolen on ipfis those uh our project serves the the large number of the data storage problem the projector white uh smurfs the contrast to ensure the companies save the execution of the date excise as the files the information of the item in ipfis and then uses a requisite algorithm to request the parentheses of the problem item from the institution and ipfis and finally from the dag this is the all workflow chart and first we find the ipfl drives through the institution and then we get a specific date by accessing the ipaf is plus the parent per doctor id and the third way according to this id interactor with instagram again to require the compilation ipfs device finally we'll go back to the first step this is the our demo which is the enter yeah we see the list let him addy as the uh we know the church as the will we move the most to the specific ad term the parent and the children's notes are selected enter my highlight okay and if we are company uh you can also eat the production information of that term now we select turn the date and we should lie to the company okay uh uh we select the material id who is the father of this product okay with success and the technology we use is the institution inferring and the ipf eyes thank you very much thank you okay thank you team hyben um so yeah we'll open it up to the judges for any questions comments feedback uh okay i need uh interpreter thank you yeah i think we've got ken on the line i'm here from the ethereum foundation hey ken yes i'm here do we have any questions sorry yeah sure i'm gonna give my mandarin a shot actually um um um [Music] [Music] [Music] all right um it's possible that i might ask the same question because i didn't i don't actually catch much of what you said i'm sorry about it i asked if they if they had more time what else would they have added to their project in terms of features and they mentioned sort of identification verification uh amongst other things yeah thanks thanks for that um my question uh kenneth is about whether they've estimated the cost of storing and changing this data and the references to the data on the ethereum blockchain like given a particular tracing history of a particular item say you know if it has like 30 entries or 40 entries how much would it cost to continue you know sending transactions to ethereum in terms of the transaction cost the gas the gas fee and the you know the storage cost itself which pergulates his gas that was uh i don't know if i could do that i think min is her chinese much better than mine okay so taiwanese if we do 30 to 40 transactions so an item with maybe 30 or 40 40 uh tracing entries like what would be the cumulative cost of you know the of tracking the history of that item okay so sanja dal searches the transactions um uh um um what was the transactions what are we doing tracing calls uh tracing calls i don't know how to trace my goals let's try this tracing i don't think this is right either google translate says that's not right i don't know how to translate that one that's hard actually i might be able to figure it out by looking at the other source code uh so um [Music] time i forgot sorry i'm sorry i think i've upset a lot of people okay okay well there's no more questions thank you so much team hyben for bearing with us here and thank you ken uh ken's going to stay on for the next one as well uh we're also going to have a translator um so up next we've got uh team tj wallet light so i will play your video for you i understand that there's no audio for the video um and so we'll we'll play that we'll view it and then we'll have q a q a afterwards all right give me a moment to get this set up and then we'll be rolling okay we have the team uh tj volley to light from china uh then i will oh yeah yeah yeah it's a video uh yeah yeah yeah yeah great so i'll play this and then we can do a q a oh okay okay thank you oh maybe i can introduce you uh the titivate light i find the video is no sound sorry uh this is uh do you want to speak over the video that's fine if you want to but i'll just keep it playing uh hello come on he wants to so he's just showing the video and showing uh how this works do you want him to how do you want him to do this do you want to talk through it i just want to play the video if they want to speak over the video while it plays that's fine or you know we can just watch the video um you can just watch our video first great okay you foreign it okay um how to move great thank you tj wallet uh so yeah we'll pass it over to the judges and and ken can help transit as before um okay so this is this is their their custom-made file coin wallet um and it includes we have a blockchain wallet before and then now we just made a funk home watch just for you guys and this is um how to say that customized and uh also we have the hardware wallet this is the first second you can see we have a lot of information like fine coins on other blockchain information um inside and we this all the information that is data we back up we set this and then we how to say that save this data on the ipfs you know just we use the ipfs technology to make this void this is second and the third and you can see we have a lot of dapps over 3000 inside and so we build developer tools sdk to um connect uh dapp and to find coin you know we also have uh we i think there is a lot of uh app or web games or other how to say that other programs want to join fine combat how to get in so we build a state sdk to let them assess and then they can work with us together nice that's that's very cool yeah any questions it just asked questions yeah presentation was a bit blurry for me but the ui looked pretty pretty cool um uh are you planning to allow people to do transactions wallet transactions as well and if yes how are you do you have an idea on how to mo how to make the ui model the payment channels that filecoin has so falcon has this concept of payment channels um and you know you can send vouchers and you can settle a payment channel and so on so i don't know if you've thought about the ux flow of how that would work oh come on come on falcon you know payment channels your transactions you know he says um the transaction flow is actually there um it looks like a normal transaction so he has a high quality video it just because it just didn't load well we have a faucet to get file right the firecon right and in our wallet we also do that we can let them people uh how to say that on hi okay so he said the boss is already baked in the wallet it's just uh i guess it pings your server you guys have to approve the faucet uh and then it goes to their wallets and they're able to transact directly through their wallets in the future we will help the uh fine coin user to uh solution author approve faucet rule approved uh approved that their file account to uh how is it that to send at transactions or approve the web at the web uh or at the app to get information that they want to they want to give them also all this is already in our sdk they have it but you you i mean the video is not very clear so we didn't see it and if you can download our apk you can you can see it already great okay uh thank you so much um so i think you haven't seen the chat where they got five minute break now uh so a chance to use the washroom judges take some notes thanks again tj wallet and yeah see you all back in a few minutes okay thank you thank you thanks kenneth i tried i tried good job we got a free mandarin encanto lesson i need i did thanks for having me thanks for considering me sorry so sorry to put you in the top spot like a few times i i i volunteered for this it's uh i wish i was better not ashamed all right i'm gonna i'm gonna hop off but uh good luck with judging have fun i'll see y'all soon foreign foreign foreign foreign foreign foreign c foreign okay hello everyone i think we can get back now uh judges uh let me know when you are back on the video all right we got min we got danny so i'm i'm here but my video seems to be blocked for some reason did you stop it all right uh okay we'll see if we can get it working but it says you can't start your video because it says you can't start your video because the host has stopped it interesting um i don't believe that i did that but let me see if i can uh all right i did that about that thanks my audio is also way quieter is that just me or did that happen to you guys too just me okay that's okay for me but by the way uh josh i don't know if it happened to everybody but uh the screen was the screencast was a bit blurry in the last two presentations or three presentations okay i don't know if it's like a bandwidth problem on my end or your end or something yeah i i'm not sure i've got a lot of stuff going on because we have like multiple videos loading all once so it may just be an unavoidable bandwidth issue unfortunately um these videos uh are available uh on the showcase um and i can say the links afterwards and anyone that's watching this that wants to see the higher quality videos uh if you go to the hackify showcase there's all the video links all the repos everything there uh okay so uh next up uh we have upala digital identity uh i think that i'm going to play this video again for you peter so i'll get that set up and then we'll get started greetings humans we are upala an anticipated system for the apps and the decentralized identity of the future today there is no reliable way to tell humans apart from bots on ethereum neither there is on the traditional web and in apollo we believe that over one billion people without aid is a part of the same immediate problem existing solutions out there measure the probability of personhood in percents we don't do that in the power instead our account score represents how much it would cost to forge this account we have dollars of percent let's see how it works the first concept is a group users join a group they put their deposit in a group poll and the group assigns scores to all of its units notice that the score is higher than the deposit this is where the second concept comes in explosive pulse protocol it ensures that anyone can delete their id at any time and grab an amount of money corresponding to their score here a malicious user is able to get 10 dollars from the poll sure enough other members will feel betrayed and they will not let this person in again the third concept is stacking the same way users join groups groups gather into hierarchies superior groups may require deposits from east subgroups and in turn add extra scores to their users but the same scores will be paid as a reward to an exploding attacker group at the top may require may acquire large audiences this way and they may then charge the apps for providing user scores or they may earn interest on their huge pools and the last concept is pass both an attacker or a good user need a membership path for the group hierarchy to prove their scores these four concepts incentivize groups to gather large low explosion risk audiences and users are incentivized to get the highest scores for the lowest investment of money of reputation the market's similar to insurance emerges but instead of trading coverage for premium impala scores are traded for deposits the user scores then roughly represents the efforts needed to acquire such a score or the price of forgery and it is a very reliable network for the apps to assess human conditions with apollo is a protocol a variety of identity systems can be built with it like the one based on friendship or on our membership it can even wrap over multiple identity systems and communities enabling scores that die higher than a black market cost of a state id so it has a potential to become a substitute for that and yeah that's our goal but for now we made this minimal viable anti-sible system the top group is the playwriter the other groups are entertained that out assign scores to members of existing dials and aragon based out can change the scores and decide to add groups with other entry conditions let's see how it works so first we register an id then we join a group we are a member of my hotel so this group lets us in no problem so if we join and now blade runner assigns us a score of 15 die let's change the score okay we now have 20 20 dies for now notice the weight runner now balance and our id so we're gonna explode now that means delete our id forever now let's register new id an empty one we don't have anything we cannot join any groups and we can see that the playground balance is decreased so this is how it works thank you very much great okay pass over the judges for feedback and comments hey hello everyone hey peter um this is awesome we literally were just having a conversation a few weeks ago about how someone needs to try something like this so very excited to see this project um great so a couple of questions um the first one um is the are you guys using ethereum keys as the identity or is there an abstraction away from that that lets you use it across different networks beyond just like the ethereum network we use ethereum keys to access your id so an id has a owner which is represented by an ethereum key but i think that paula could be blockchain agnostic so we can use any any blockchain for that and so where is you said the id has an owner where is that stored uh currently it's stored in the smart contract in the protocol the apollo protocol it assigns a permanent user id to to users and to groups got it and have you thought about as you start to if you use a smart contract and are linking to ethereum keys and then have users part of multiple groups um are there privacy concerns about what users have to be disclosing publicly in order to get this kind of coverage sure great great question yeah we we are concerned with that a lot uh [Music] uh well basically i'm not sure yet how to handle it but i think it's possible in the future with probably some zk snarks magic but currently we we are focused to deliver the mvp so this is out of our focus right now so i think that staking on identity and group identity is a really cool idea um it's very original um kudos kudos on that um how would you so exploding is one way to exit the group um and it's kind of like the rage quit i guess or kind of like hey i'm gonna take like the you know the lucky part or whatever um how would how would you deal with organic you know with natural you know uh rotation in that group so if a particular member really does leave a group that represents a collective identity and this is genuine how would you deal with that yeah there are two different ways that you can leave a group you can either explode or you can leave peacefully so without explosion so explosion means that you grab uh that you are stealing uh from the pool and as opposed to that just a simple living or you are leaving either taking your deposit or nothing at all it the group will decide what what the living peacefully conditions are okay uh if there's no other questions or comments on the judging panel uh we'll move on to the next team uh thank you uh to apolo thank you peter um really awesome to see this project um okay thank you um speak archivator uh you are up i see you in the chat so um unlike the last four uh this time you're gonna play the video um so i'll let you take it away i don't hear any audio robert you can hear the yard oh there uh no we don't hear the audio at all um you might have to uh stop the share and then restart the chair and click the button in the bottom left corner of that dialog box we try it again all right hi so we are teams so we are the team speech our curator and this is what we have built for the hacker physically my name is robert and i build this project with my friend tian and we build a program that uploads videos that contain a specific person to ipfs and we build this because of the problems that are emerging from deep technology deep fakes are videos or images that look exactly like real ones but they are artificially generated so for example you can have a video of some presidents talking about starting a war but you have no idea if this video is real or or if it's artificially generated so for that reason we came with an idea to record speeches of influential people and save them to ipfs so that we have a record of the of what the person said for history and how it works it uses artificial neural networks to perform face detection in the videos when we find the faces we cut out video segments that contain the specified face and then we can upload these video chunks to ipfs and now it's december time all right so on the right side of the project and on the left side is the video in which we want to find donald trump it's a video from the telegraph about donald trump and the coronavirus you see that at the beginning there's some background footage which is not very interesting for us but about 20 seconds later donald trump started his speech about chronovirus and our goal is to cut out this part where donald trump is talking about coronavirus and get rid of the beginning where no action is going so let me run the script to process the video this is the part where face recognition face recognition algorithms are trying to find the donald trump's face in the video and cut out the interesting segments and this takes about few minutes it depends on the size of the video all right the video was processed all right the video was processed and if i play the processed video running ibf a server in the background and since before options video files can be very big files it's a good idea to split the video into smaller chunks so that's what's going on right now i will split this video into three small smaller videos and then upload it okay okay so we split the video into three parts and then upload it and here's the ipfs web user interface and if i refresh it i see there are three files now i see there are three files now and these are the three video charts i just uploaded a few seconds ago and if we want to retrieve the video back we can use this hash which is basically hash of the video content so this was our project speech activator and thank you for your attention great thank you so yeah open up the judges for comments and feedback so that was uh that was pretty cool uh i think uh you know with you definitely use a very controversial person and that says a bunch of things and we probably want to like as as um humanity want to archive some of those bits uh for posterity and for for track for accountability and for traceability in the future um i could see like a lot of you know such cases um it's uh are you thinking about automating in some way i guess this is kind of like the start of a project but uh like what are your thoughts on like making this a fully automated you know bot or system that would spider you know streams on youtube or whatever and detect the the faces that you're interested in and pipe them onto ipfs and maybe like use ipns to sort of like and things like you know pop subsystems and so on to advertise whenever a new video has been uploaded for a specific person that users are interested in consuming like what are your thoughts on automating the whole process yeah for for now we are trying to look we are we are tracking a youtube channel of channels of some famous like magazines like cnbc bbc and this kind of stuff and we what do you want to do is to look for live videos and get the get the interesting faces like some of the famous politicians from it so that's our goal we are still having some problems with it so for now we just can we have we have a script which checks there particularly for new videos on some youtube channel and then i process it but yeah our goal for now is to make it work live with the live videos not just the just upload it but the live ones yeah so the most that's our goal for the future and then like may some and then of course make some better front-end for the users which can like pick up the person yeah they are interested in and some sometime some time period or this kind of stuff or some events like promotion speech of president of presidents in united states between years 2010 and 2015 or something like that this is super cool and um thank you for your submission um and how do you sort of ensure that you know on like you know the counterpoint to this that it's not used for any sort of surveillance or any sort of unintended consequence it doesn't sort of contribute any privacy concerns yes that might this is a thing to be solved actually there might be some privacy concerns like about the people tracked so yes we want to use it not for like personal use but really for the pres presidents and this kind of stuff and they are already on the team on television in these days so i don't think it's it will be such a big problem for like these very famous people who are used to be on the tip on camera but there has to be some proof that this really is like what they said and it's not modified in any way so this has to be so definitely there was some like camera which you could use it like camera connected with blockchain and cryptography what was what was filmed on that camera is really like the truth okay thank you um thank you robert thank you uh speech archiver we're going to call the next team now for their presentation which is secured finance i believe you're on the call now so if you want to share your screen play your video we'll get started and remember to click that audio share button hi everyone we will talk about a d5 project called the secured finance secured finance is a financial transaction platform with automatic margin call system so what are financial transactions it's simply a collection of future cash flows please remember this shape i'll go over four examples loans are basic form of all complex transactions you borrow money and you have to pay coupons and return the money at the end if we flip the arrow alone becomes a deposit interestingly if you combine a loan and deposit you can make a swap transaction it is a cross currency swap option is even simpler it's just a conditional swap if we can do learn we can do others too so our main focus is file coin loan our target user would be miners investors hedgers and arbitragers why we made this project since ibm and the world bank did the first cross currency swap we have accumulated knowledge for almost 40 years so we already have battle tested protocol for finance and if you use the same protocol all the traditional financial institutions can join us quite easily otc directors is peer-to-peer and has 600 trillion dollars of size we made the interbank market system open to public we aim to gain one percent of market share but more conservatively we are aiming to bring one trillion dollars into crypto economy what's missing in the current device is clear volume and liquidity we can't sell 10 million ether through an exchange also we are missing time axis because we don't have yield curve we can't manage the future cash flow and that's why large corporates are slow so we are making new market and opportunities we also have liquidity provided with incentive mechanisms to keep the bid offer spread tight and ensure liquidity our mission is to connect institutions and provide open finance our clients can provide secondary layer services to their clients as an example if a bank wants field deposit but a client deposits ether they can do a cross-currency swap let's talk about how we built it key components are built using smart contracts so we created these three smart contracts and designed at state machines here's a sequence diagram stored in our git repository for margin call our contract calculate discount factors and get pp to avoid margin call borrowers need to keep 150 coverage here's our ui components we don't need to log in lastly here's pros and cons of a service we provide zero credit risk transaction because we have yield curve clients can control the future value of cash flows thank you very much and here's our demo securedfinance.crypto is a decentralized app deployed on ipfs using flick here we have money market swap fx book history and pipeline page first we will go to book in order to set fx and loan after filling out all these input fields let us set fx let's confirm let's now set loanbook confirm when we head back to money market we can see the values we set on borrowers and lenders tables to lend we select a row from borrowers click length and entry amount and confirm next we will go to history to see the list of loans and borrows you made here we can search sort and filter our entire loan book we can also pin our table to ipfs with pinata cloud and the last one to see is five point page where we generate token create five coin address and send it and this will complete state of our loan [Music] thank you very much thank you secured finance uh we'll turn over the judges for feedback and comments this is really cool and go ahead sure um you know i love the ui as well and it's great that you guys built that um during the duration um could you talk to like you know explain a little bit what you're using for price feeds and how you're sort of managing any sort of price volatility or fill as well sure also speaking about the oracle problem uh so in terms of oracles we thought about using outside price sources uh from coinbase or cracking at the beginning however their price is not executable because lacking of liquidity so we decided to build a suitable market for large size transactions and made ourselves as price oracle so we don't need to rely on external sources and also for file coin balance currently it is manual and the transaction has and confirmation basis but we're building the p2p based file coin oracle to automate this process so let our teammate back to speak about this yeah uh one of the main problems between file coin and ethereum is uh how do we handle interoperability in order to solve this problem we've we actually created uh if oracle network which is kindly working as a way as you might think about chaining instead of using a chain link scheme where one node has its own set of smart contacts on a firing chain we have uh peer-to-peer nodes which is uh messaging to each other using pub sub and then the letter of a consensus layer right now we're using rough consensus but we're planning to migrate to our practical bft consensus we're going to commit to the ethereum uh blockchain as the state from from the file coin and that's how we're achieving the interoperability between two networks [Music] yeah so speaking about the motivation it is actually the original idea came from uh 100 hackathon idea by one and actually i talked uh i drafted the sketch and talked with him and he liked it and then decided to join this hackathon and uh try to help uh falcon ecosystem because we are very much worried about fire comprised fluctuation that's because like there's no place to trade large amount of currency so we make the block trade platform to make the price much more stable and help to grow healthy economy okay uh if there's no other questions from the judges or comments um i thank you um thank you team and we'll bring up the uh the next one for the presentation um so next up we've got uh access underscore denied and i understand that i'm going to play your video for you so let me just get that set up and we'll get started [Music] [Music] [Music] so [Music] so okay thank you access denied and we'll pass it over to the judges for feedbacks questions comments hey i really i really like the music of that presentation i was really upbeat thanks for that thank you yeah it's uh it's pretty cool to to create tools uh to connect uh to create marketplaces so that uh folks can connect with one another and sort of like improve their skills and also you know earn prices that's pretty cool it would be um it would be interesting uh there is uh it would be interesting to see kind of like the the whole workflow uh where you know potentially want to dab is very nice let it pass for a second sorry for that yeah uh like imagine you know a dab is this particular is um is approved it would be really cool to like be able to like deploy to production immediately uh by deploying the smart contracts that are associated right and potentially deploying the website on fleek uh which goes to ipfs and so on i don't know if you guys have thought about you know what comes after the the approval of attack oh yeah we have actually thought of like uh like uh deploying it in the unstoppable uh domain so that uh like it can go live right away that's the main motive but right now we are also thinking of making it further improvement such as including staking so that uh there will be decent behavior in a platform so that's the main motive and also to make it production ready that's the key and end point and also we could show a small demo if you want left because the whole demo we tried to put it in the video and turned out to be about 25 minutes so we have to cut short on the video timing yeah that actually be really cool i don't know josh what do you think yeah we've got a couple minutes so uh you know if it's just a a minute or so that's no problem we got about two minutes we can just yeah we can just show the profiles uh present in a plug awesome my teammate monalisa will present the screen so can you see my screen or am i am i audible clearly yeah both things yeah all good yeah okay so this is the like i've logged in as a solver so i can see the sort of button yeah so this is the profile like i can see the questions that are being uploaded if i click on solve i'll get the dialog for uploading my smart contact and giving the readme file and now i can show you the publisher profile so if i'm logged in as a publisher yeah so this is the publisher profile where you can where you can upload a question there are two options you can either upload op for a smart contract or for a dap plus smart contract he has the reward that he can select for the smart contract and app and there is a time limit and these are the questions that he is uploaded for now this is the dab only one solution is being uploaded for that question so he gets this and click on approve this is the next screw contact that we have initiated for this question this was completed so like the publisher will first initiate the escrow so he can chat with the dap person who has uploaded the solution and then after the dab person like he clicks on ownership transfer like he transfers ownership he'll get a the publisher will come to know about that and he can confirm the payment that is reward distribution to that so this is how the stages are after commission of a solution and uh for voting so if i'm a water the smoking part is only for the smart contracts but for the dax the publisher has the right to choose which staff he wants to approve as i showed you in the previous uh page to the escrow so if i click on vote i'll get these there are no solutions uploaded so if i if there are solutions there will be like like and dislike button so a voter can like or dislike a solution yeah so and this is the trolls portion where anyone can get a role publish a solver dab or a water because if he doesn't has any road he cannot uh like he can just see the questions he'll not get any interactive buttons on our platform so so this was the like quick demo offer and uh for the dap profile we also have a dab profile uh yeah so if i yeah this is the dap login now so there's a dac profile where you can see the dap that the solver has uploaded if he clicks on view there's a escrow contract this initiate button can only be done by the publisher because he'll select which dap he wants to approve ownership transfer is done based by the staff person and the confirmed payment will be done by the publisher so these buttons are placed according to that this was just all right we're a little over time now model is thank you for the demo uh and thank you team access denied um so we're gonna move on to the the next team up um that is uh censorship uh censorship resistant web annotations i believe you're on the call already and i'll let you play your video and we'll get started okay i'll play the video now hello everyone this is our demo of the public annotations network we build this because social media websites can censor data they can delete or mutate content people can block you there are sensitive ways that you can be censored today and every day society becomes more dependent on these centrally controlled platforms web annotations are a nice way to promote this course by enhancing web pages and they are also a w3c recommendation so using web annotations on top of ibfs and ethereum we can reduce the censorship attack factor so let's now go to a quick demo and then we can explain how all of this works so here i am on twitter and i already have the pen web extension installed which is signaled by this yellow pane here so i can come here out to the sweet page and i can write something and i can say whoa this looks super cool uh and then i can comment that when i do so uh i essentially take my um ethereum wallet and i sign the message which proves that i was the one making this annotation this web annotation is then wrapped into verifiable credential which is what contains the signature and allows for anyone to verify it so at this point my comment has been published and if i go back i can see it here now i can go again and i can do another one if we come into another browser and we open the the exact same page so this exact same tweet just reloading so everyone sees that this is fresh we can open the annotation here the extension i mean and both of them are here which is super cool okay so how does this work the web extension allows for the for an easy user interaction then we have a publishing service which broadcasts and caches annotations and then we use a sub graph from the graph for easy data access and integration between ipfs ethereum so someone submits an annotation the publisher takes it stores it on it stores it on ipfs uh then when a batch is full makes an ethereum transaction and then the graph captures the return transaction data and sends it either back to the publisher or directly back to the extension so back to some questions now why do we need a publishing service it is very important for the system to keep track of the canonical order of all public annotations see only to make sure that none of them disappear and like are censored so we store annotation logs on ethereum however doing one transaction one transaction per annotation would be extremely expensive just imagine having to pay for every every single uh tweet or comment that you make so we came up with this optimization it's a publishing service that can aggregate transactions um and allows just one transaction to record to record any number of annotations it could be one it could be ten thousand it really just depends on how long you want to wait for the transaction to be processed um this service is not a single point of failure because anyone can run their own they just need to take the server code and run their run so what's next well the first thing naturally is to deploy to mainnet uh and then implement native interactions with ipfs and ethereum so that no one can so so that anyone who wants to be totally decentralized can be totally centralized then we could work on creating a network of publishers so having several entities running their own publishing services and those entities couldn't figure out incentive mechanisms to support the infrastructure and transaction costs we can just imagine that with ethereum too this would be insanely cheaper that's all they have for you we hope you enjoy the demo and check out the github repos install the extension play around with it and let us know what you think thank you awesome thank you uh thank you pam uh over the judges um this was very cool um it looks like a great project is the intention that this would always be public annotations or did you also think about private or for example like team annotations for web pages um so we didn't really think about it i'm guessing for private annotations you'd have somehow to encrypt the content and share some key for other people to be able to see it um yeah i think it can be done we just don't have it right like an answer to you right now on how we could do that um but we we did we did yeah yeah so that's that's my answer yeah i mean it makes sense to start with public comments for sure uh we did implement uh are actually like we have a design i i'm not sure the code is there a mechanism for white listing so that you're only exposed to the ones that you want uh because that's a way to prevent uh spam because if if this becomes super cheap then everyone's gonna use it and then you just become uh spam by everyone which is not desirable obviously that's cool uh that's super awesome did you guys i was wondering if you guys thought about how to make the solution work even if the url to which you're attaching content to changes over time like how would you canonicalize that um yeah yeah that's that's a yeah that's a very good question so right now um we built this one for twitter because we wanted to get something done fast and it is just the most popular thing so the way we are identifying um like the way we figure out how to show the comments based on the tweets based on the username and the tweet id um so if the tweets url change tomorrow as long as we had some clue to who the user is and what the tweet id is we could still do it but then you can think of other things maybe what we could do would be take the data of the tweet take like the content of the tweet itself hash all of that that becomes the idea that we used to point to the thing right um yeah and then just becomes like how do you how do you um how do you fingerprint that content because it'll also be pretty cool to be able to show it on the twitter feed right which is not right now because on the twitter feed it's always the same url but you have tons of tweets uh so we cannot simply just grab the id of each one of them um but yeah we thought about all that just super complex stuff to get done very fast i'm also thinking about deleted tweets right which is also a problem so you ideally like you would you could leverage ipfs and take a screenshot of the tweet and publish it to ipfs and then yes when you visit the profile of that particular user you could like display a badge if you've detected deleted tweets or something like that yeah and like recover those from ipfs along with a common thread uh if that you can also think about a decentralized internet archive to use this type of stuff uh and you can also include the tweet inside of the web extension i think part of extension spec is that you can actually include the original content um so we could also do that and it will be encapsulated in the same standardized data format which is awesome because then other applications that implement the spec uh it would just work with everyone right yeah this is super cool and as a follow-up to that i saw you also build a sub graph like are there any sort of applications that you imagine being built on top of the network or any sort of integrations with like other sort of similar tangential products um yes so the good thing about this is that it's super agnostic it works on twitter today but with minimal modifications can work on any website for any content that you want so we could very easily change it to work on something else it's just really a matter of like we discussed first how do i then how do we identify content how from that content you decide what to show um so yeah and about thinking about more services you could actually think about the publishing network which is this set of uh parties that take your annotations and actually issue them to ipfs and ethereum you can think of a lot of business models to support that you can think donation-based models for things that are like really important that the community cares about you can also think of a model where you pay subscription and then you are allowed to do x comments per month or per year um so yeah tons of interesting stuff that we can do around this awesome okay thank you um we're at a time for this one so we're gonna move on to the next but awesome presentation thanks so much for being part of hackafast um so the next project is uh our last one for today um this project is ipfs recovery uh and i understand that i'm going to play your video as before and then we'll move into q a so let me get that set up this video is our submission for hack fest 2020 ip fast recovery coming into this hackathon i had some experience working with erasure codes in the context of distributed systems and i thought this was a very natural solution for ipfs but traces some problems that built you shortly some of these problems are data corruption which can be caused by things like coffee pouring on your laptop or a lightning storm taking out the power grid of an entire city which can cause losses and potentially vital information another problem is no churn which is when nodes just drop off for whatever reason for example their power could drop off or the person just closed their ipfs client permanent availability of content is not guaranteed in the face of censorship this is a pivotal problem that ipfs purports to solve and has been doing so for the last few years attackers can go to any extent to try to get content off the network and it is our prerogative to ensure that data persists at all costs finally availability of resources is hindered by transient connectivity when a node is downloading information from another it could fail to download the information properly due to a faulty internet connection the solution to these problems is erasure coding erasure coding is a method of data protection in which data is broken into fragments expanded and encoded with relevant data pieces and stored across a set of different locations or storage media what this actually means is data that is razer coded becomes a sort of hydra where you chop off some of the heads they can be regenerated and it's impossible to get rid of it unless you destroy most or all of the data chunks it's actually worth consuming some extra storage to obtain this better daily resiliency and even routing performance as perhaps redundant chunks could be a fewer hops away than data chunks what we actually built is an abstract erasure coding module that operates over ipld merkle back there is an elegant integration with coipfs along with cli utilities that you'll see shortly in our demo how this works is that the root note of a content dag is part passed into the encode function which operates on the entire dag according to the instructions specified by the erasure coding scheme that implements our module we created two set schemes one is the industry standard resolument code which is used by a lot of big companies such as facebook and amazon to protect their data centers we also implemented a novel alpha entanglement code which features a simple self-healing parity lattice this is bleeding edge erasure code technology which is being actively investigated by distributed systems researchers notably for ethereum swarm we also wrote some test plans using test ground for simulating network interactions and seeing how network holds up so now we're going to see the cli client in action first the client is initialized and a folder filled with files is uploaded onto the network then the folder is encoded following this the refs are displayed so we can see what the contents of the folder are and randomly selected blocks of data are deleted and finally we can see that the recover functions still works so why does ipfs need recovery data distribution in the limitless manner that is in the core of ipfs requires strong data integrity we want to ensure content persists on the network at all costs and further recovery is a long requested feature for ipfs on various layers there's an open issue from 2016 on github that proposes resolument and ratio coding there are currently no existing solutions especially ones that natively work with the ipld merkle bag which is why we thought it would be awesome to integrate something directly with the core finally it's a modular interface for any plugable or azure scheme so in the future if there is something much better than anything that we have ever seen before we could just plug that right into our module we have quite a few plans for the future namely we want to upgrade to the more complex alpha entanglement parity lattice this will allow us to create self-healing networks which can tolerate a lot of faults and further we want to take this down to the dht overlay network level so that we can actually have low level routing performance increase as well as resilience we want to create some specs for formalization through active discussions in the community we also want to create javascript go and other language implementations in the future finally we want to battle test the network empowered by erasure coding resilience this is the awesome team that brought you this hack thank you very much awesome thank you so yeah we'll pass all the judges uh i think you're hitting the nail on the head with this with this idea um as you duly noted in the presentation it has been a long long standing request and uh definitely it can be applied at many layers and the fact that you picked the ipld layer uh makes it almost like generalizable to everything to everything else which is really really awesome because like you pick kind of like that the foundation of the way that data is encoded um across the stack so that's that's pretty cool um i really like the fact that you use testground uh spoke very near and dear to me very uh is um yeah pretty pretty cool to uh to see that to see that in action i was wondering uh a couple of things can you tell us more about the team that build this how did you get the idea are you like what are your future plans are you planning to contribute this to ibfs or spin it off into a like a business or something else or a long-standing project or or something else and and yeah how was your experience with task ground uh so i'll answer the first couple questions uh so i have been working with the razer codes for like about a year-ish uh for a company i started uh a couple years ago uh it does erasure coding i work with someone else who is like a patented erasure code so i learned a lot about the field and i learned about some stuff that's happening in this space the ethereum ecosystem and so on in fact i was in touch with some of the researchers who developed alpha entanglements and they gave me a lot of resources on how to implement this and stuff so i thought you know this would just be great i ended up meeting cleve and sarah during the hackathon and both of them are extremely well experienced go coders so uh yeah that was that was really great uh as for the future yes i do think uh we want to add this into the ipfs project as i mentioned we want to discuss with you guys see what you guys want uh because i'm sure you guys have some ideas on how you want this implemented so you know collaborate and figure out how to move forward and uh if the others have anything to add to that um i'm suggesting you to look at source code and how it's implemented like how we did actual how we put it into the ipld layer because uh in in the first version even zero version because i know that there is a like incoming version of gopld prime and uh we haven't had enough time to dive deeper in it but we uh have actually working um like recovery for like current ipfs uh also like um i think you haven't seen anything for it in the demo because like it was blurred but we i can do a live demo if you're interested or you can try it yourself on our github there is a explanation on step by step how you can try it out we have a forked version of ipfs with the new cli that integrates this also there is a description how to it's all integrated so if you're interested just go ahead and look at this uh josh do we do we have time for a quick demo do other other judges have more questions uh this is the last team so i i think there's not a big deal if we go a bit over time as long as the judges have a moment for it certainly no objection for me let's go for it yeah demo would be great okay let's start let me share my screen this one so you see here my terminal let's start from the scratch i'll remove ipfs then i'll do ipfs uh init empty one and then what i'll do is ipfs add um i'll do this there is it like a directory that has a like bunch of different photos you'll see them next uh also i'll use a cd version one so like nothing special here just uh like uh logos uh filtered and by the by the like protocol apps ethereum foundation consensus like all this stuff uh this is not important um then what we can do is ipfs and recovery encode i'll use the suggestion so you can see that hashes here much uh recovering code what this does then it produce a hash of the encoded version for this hash um also i think we should add like it's quite easy to add a new option for ipfs that that will just do the same thing as chunker where you can specify the algorithm and maybe some um like there is a recoverability uh optional uh that can like i'll discover it later if you're interested so we have uh this uh encoded hash then what we do is uh ipfs refs on that hash also recursive uh this way we can see um all the blocks um this um this root cd is pointing to like hold egg uh then what i'll do is to uh i'll just um remove um a bunch of them randomly it doesn't matter through block ram just any of them this one and maybe this one this one so though those are deleted then ipfs um then what we can do is actually use uh like plain ipf has get to uh retrieve this this hash and it onto ka and we will still be able to get it uh as well as uh on the other side like meaning on the um on the network that can uh that is connected to our node and uh it sees that we serve this this hash so um let me first but that doesn't matter okay uh if you fast get so i'll do this offline to you for you to see that uh you won't fetch it somewhere else and uh as you can as you see in there like this is uh playing ipfs without any data um so we see those error message those are like not important this is just a small hacking implementation but actually we were able to get those uh get the content you want to remove those um those blogs so like they were not existing like um i'm not sure if it's enough proof for you that it works as it works but i totally trust that it works i was interested in seeing it in action this is pretty cool i can see that you know the size of the recovered blob is obviously you know a few magnitudes a lot larger than you know the original the original directory was packed which makes a lot of sense uh it would be pretty cool to see this integrated with uh with bitswap and potentially graphs and going forward i think there's a lot of stuff that we can do at the graph sync level to be able to convey metadata about you know the array the erasure coding policy that has been attached to a particular you know blob um or a particular ipld node there's a lot of stuff that we can do there i think you've built some like pretty interesting plumbing for this that then needs to be like percolated us and such that we can um represent you know the erasure coding policy at different layers so that when you go out and fetch a particular blob a particular you know ipld node that of which several leaves have you know disappeared from the network you will like backtrack and realize that you can actually recover those leaves uh using the data that you already have so like yeah it's it's pretty pretty awesome i'm this definitely got my juices flowing pretty cool uh like i i want to say that this is implemented on a dark service layer meaning that it actually works on top of bitswap so like bitswap doesn't know about all the magic happening here and uh like we have uh there is one issue uh before making it fully working uh on the network like where you can do one multiple nodes on the network or one node add the file delete some blocks and other node just tries to get it it actually can get get the blocks get get the file the content but it should wait for uh like till the uh know the understand that you can find those blogs on um on ghd so uh there's we need to add just kind of like there is an issue on a github like with several solutions for that but that so we um from the user's standpoint we it's hard to understand where to where's the moment where we should recover the blokes because um the dark service waits four blocks and it can wait like till the context is cancelled or or other stuff and if we just do recovery by default it will recover uh once we get enough um amount of files where it can uh like just start a timer wait for some time like start a timer when it understand that we have enough block streak to recover missing one then like wait for some time out and uh actual recovery yeah we could totally share some ideas in an offline discussion one potential way is to like i'm thinking about if recovery running the recovery function on the partial set of blobs that you've already retrieved is not too costly you could run this on a you know on a on a loop essentially or for every block that you receive or maybe with some debouncing there to make sure that you're not running into frequently bouncing so yeah yeah yeah but that that's uh it's pretty cool yeah i like that i'll just jump in there cause i gotta steal these judges away for a bit um thank you ipfs recovery uh thank you to all the teams who presented today uh it is so exciting to see what got built uh over these several weeks of seeing you all work so hard from a distance in the slack channel but it's amazing to see the final product so thank you again i hope you can uh tune in for some other judging sessions um and we'll see you at the closing ceremonies uh which will be next tuesday um judges if you can stick around i'll send you another call link um we'll do a quick debrief and then we'll be done okay thanks everybody 