foreign from the reference do we need a sound check is this working yeah they'll raise it I'm going to flip through is the slides first it's a bit yellow but that's what we got that's what we got yeah no problem no rush yes okay huh foreign thank you foreign I have no monitor over here one minute I don't know which one this is is it this one are you cool with mirror if I mirror then I won't be able to see my notes so foreign hi everyone Thanks for joining us um today I'm going to be talking about how liquidity pools are a really useful tool as defy infrastructure for Builders uh before we dive into all that exciting stuff I want to start actually just by touching on something that's very important to all of us here I think there's one thing that we've learned in in crypto over the last three months it's the value of decentralization transparency immutability uh in finance uh with the billions of dollars that have been lost of consumer funds by exchange like FTX lending platforms like block fi Celsius Voyager the value proposition of defy is has been validated now more than ever um and the people in this room are the people who are really bringing this to fruition so um it's we're not only here to kill build cool Tech we're actually building a safer more fair more transparent um world for all users of financial products and services and I think that the work that we're doing now I think has has always been important and I think it's more clear than ever like how much the world actually needs this so with that said um I'm Jeremy musigi I'm CEO of orb Collective uh orb Collective is a growth team for the balancer Dao our mission is to scale uh Global utilization of the balancer protocol and support the resiliency and long-term sustainability of uh balancer as a community and as a technology balancer is defy liquidity infrastructure and balancer is designed as an as a very flexible amm automated Market maker that is highly customizable so the liquidity pools within balancer um serve as this building block as this piece for developers that are that can you know integrate and build on top of this base layer for many different use cases and we'll definitely dive into that balancer serves today as one of the top uh decentralized exchanges in D5 across chains um but balancer really and and this is what balancers I think historically most well known for it's it's our exchange but balancer is actually way more than that so first I want to just kind of lay some like foundational knowledge about what a liquidity pool is so that we're all on the same page so liquidity pool is is like a stockpile of tokens that uh belong to separate individuals or or organizations that are held together in one smart contract and these tokens are pulled together in order to generate some yield by putting those tokens to work utilizing them in some um effective efficient way and creating a liquid Market using those tokens so in the case of an amm or automated Market maker these tokens are pulled together in order to create an exchange Market between different pairs of tokens so uh you make it so that a buyer or seller can trade with a liquidity pool basically by providing asset a and getting asset B in return at a given price and that that price is determined by the liquidity pool algorithmically so I'll go through a couple of examples of liquidity pools so first example is a single asset pool and a great example of this is a money market or like a borrow lend protocol such as compound in this case so in a single asset pool there are lenders that are lending a token into the pool and borrowers are borrowing that same token out of that pool lenders are earning interest borrowers are paying interest and it's one pool that consists of one token that's being used by both sides of this Market in a dual asset liquidity pool now you open up a different completely different kind of use case so if you look at uniswap for example you have um a pool with two tokens let's say it's eth and die and this pool is maintaining a balance between the two and as a Trader you can buy eth from this pool by selling it die in exchange or you can or vice versa and having this pool containing two different tokens serves as having a a liquid market so that anyone who wants to trade between these two can do so at any time and and you're not this is not like an order book which happens in in traditional financial markets where in order for your trade to be fulfilled another person on the other side needs to want to do the exact opposite of your trade at the same price they want to buy what you're selling and they want to sell what you're buying here uh in an automated Market maker like uniswap or balancer uh that you're trading against a liquidity pool not not another Trader now let's talk about multi-asset liquidity pools so this is a concept that um was originated by balancer but um one of the great examples of it in practice is the curved three pool and uh this is a so first of all multi-asset liquidity pool is a is a pool that holds more than two assets and provides multi-directional liquidity uh between all of the assets that are held in the pool and in the curve three pool you have a liquidy pool that contains the top three stable coins die usdc and usdt and what purpose does this serve it serves any Trader who is holding uh one of these stable coins or two and wants to exchange into a different one there's a very liquid market for them to be able to do that very efficiently uh on the right side of the screen here we have the balancer boosted Ave USD pool or BBA USD for short and this serves a similar purpose to the curve 3 pool in that uh it's a it's a stable coin pool if you have usdt you can trade for usdc or die or any of those uh tokens for each other but if you look at the screen you actually see that this pool contains six assets not three and and the reason is because this pool is actually can it consists of three separate two token pools that are nested together into one pool so you have a uh you have a pool for usdt you have a pool for usdc and you have a pool for dye and I'm gonna go into this specific type of pool soon but for now I'll just mention that um the goal of this pool and the reason why there's six assets instead of three is that these tokens are are also at the same time earning a yield outside of balancer for all of the liquidity providers while also serving as as an exchange between stable coins so we'll go more into that it's a really exciting product called boosted pools all right so what can you build on a liquidity pool like now hopefully you have some sense of what it what a liquidity pool is if you didn't already but now let's go into what can you actually build with this and and how does this work as a as a building block or infrastructural piece for D5 Developers so the first example that we'll look at is Iraqis Finance Iraqis Finance is built on uniswap V3 and Iraqis what it is is um it's an app it's an application that reduces the complexity of uh liquidity provider or LP strategies on uniswap V3 by automating them so if you're familiar with uniswap V3 you'd know that from V2 to V3 one thing that that really changed and was very Innovative is is that they offered this concept of concentrated liquidity whereas a liquidity provider in a in a pool you can allocate Capital to specific ranges that are trading between a token pair and uh that offers a lot of opportunity to like fine-tune your strategies and it's and it really opens the door for like highly sophisticated players to use this technology and really like have a competitive advantage over unsophisticated players but the problem then is of course that it's a lot more complex and it's a lot harder to use for your average retail investor who owns tokens and wants to generate some yield on them so Iraqis is a solution built on top of the uniswap V3 liquidity pools to make these Vault what they call vaults which are pre-programmed strategies easy to use for anyone another example is uh yearn so urine has a lot of different vaults as well and these vaults um similarly but different to curve are a way to automate like yield farming strategies usually so if you each each year in Vault is designed around a certain asset you put the asset into the Vault and then there's a strategy that's designed for that Vault that will take that asset and and use it in the most profitable investment strategy available in D5 and these are not exclusively built on curve you can see here on the screen that there's an Ave Vault there are actually a couple of balancer vaults but there are a lot of curve volts so um this example right here is a um using the the curve three pool that we were looking at previously there's a vault that uses that pool uses the lp token of that pool to invest into the most profitable strategies what this these volts can do basically is they could use the lp token itself if there are investment strategies that are you know useful there or it can access the underlying liquidity from those tokens and use that and sort of Bring It Back at the end of the day so uh another example here which I think is the most exciting one is Fjord Foundry which is built on balancer now um this I think goes to show sort of how balancer is really in a different category compared to these other amms because of the types of liquidity pools that you can use and you can create on balancer so Fjord uses a primitive a pool type on balancer called a liquidity bootstrapping pool and they use this to create the most popular platform for launching a token you want to so when you a project is launching a new token into the market they can use Fjord to uh conduct this sale in the way that in a way that is uh very fair uh uses a um like reverse Dutch auction style price Discovery mechanism to find the right market price and to give all participants an equal chance to buy into the sale it also provides protection against bots that sometimes can like buy up an entire sale before other people get a chance and also you can use Fjord to conduct a sale that actually raises capital in more than one asset so let's say you want you to you're launching your token and you want to raise a treasury that consists both of each and stable example you could actually have both of those being accepted by the pool so that at the end the day you've raised capital in both so let me just talk a little bit about liquidity Booth strapping pools the way that this works and the way that this is possible is that an LBP is a balancer liquidity pool that has the ability to change its weights um over time while it's live so if a pool starts where it's 80 percent if and 20 percent die it can actually change over time and get to a completely different percentage distribution such as like 20 80 die if I had a lot of eth that I wanted to sell I could use a liquidity bootstrapping pool to do that while the the weights shift over time it adjusts prices over time and it incentivizes traders to trade against that pool and basically to move it into the balance that I wanted to eventually get to okay um actually why not yeah so so you can see here on this graphic from doing analytics that uh we've had 299 lbps on balancer uh so far over 90 000 investors have participated in those and um yeah there's been a lot of money raised and there's been a lot of volume for those projects and Fjord is is an awesome place to do that so uh let's now dive into more of these pool Types on balancer with of course a lens toward understanding how these are useful for developers so we kind of talked about how liquidity bootstrapping pool is useful for Fjord they actually built a whole product based on that pool but there are more so first the weighted pool um this is kind of like one of the more basic foundational liquidated pools on balancer these pools can hold anywhere between two and eight tokens they have fixed weights uh the creator of a pool which anyone can create can create one can set those weights according to their specifications 50 50 80 20 90 10 pretty much anything in between and these can also hold um as I said up to eight assets so one example of something cool that I've seen someone build using this product is uh there was a gaming project and in their game there were these uh in-game assets that players would earn by playing the game now what the developers of this game needed to do was they needed to convert they needed a way for players to be able to convert between one asset and another while they're playing the game so let's say you earn a certain amount of like a certain in-game asset and once you reach a certain level you actually can level up to this other asset there's a liquidity pool on balancer that's actually working behind the scenes in this game and those tokens are being traded in that way so this weighted pool is sort of the enabling component um of of that functionality in the game so a stable pool is another example and this is a pool that holds two to five tokens that uses um a stable swap formula for tokens that contain exact or almost exact value so against this could be dye usdc us usdt but it also can be like wrap Bitcoin derivatives like wbtc Ren BTC uh sbtc and you can also you know this could be stake teeth derivatives as well so the advantages of one of these pools is that uh for Traders there are tighter spreads and lower uh slippage for liquidity providers you earn a competitive yield with very little and permanent loss which comes as a result of the the way the formula balances between tokens of the same value boosted pool is something that I was talking about earlier so in a boosted pool what you have is is of Highly Capital efficient liquidity pool that is not only serving it's as an amm where you can exchange any token for the other but at the same time it's lending its assets outside of the protocol into some other yield generating strategy so the first boosted pool is the Ave balancer Ave booster pool and in that pool you have dye usdc I'm actually going to go back to that graphic um somewhere around here around here yeah so you have usdt and ausdt a usdt is the Ave wrapped version of usdt so it has so you can see here that there's a percentage of the Assets in the pool more of the the most of the usdt in this pool is actually deposited into Ave and then the Ave a token is in this pool paired with usdt itself this pool just needs to have enough usdt usdc and die to fulfill the demand from Traders at any given moment and the rest of the pool can be earning yield on Ave so if you're a liquidity provider in this pool you're earning from two different revenue streams this is something very unique and Innovative in D5 that really isn't I don't think is possible anywhere else other than on balancer so for an integrator for a developer um boosted pools are interesting because they simplify the path for multiple operations so you can keep everything within balancer and it also enables Advanced applications so out of two like weighted or metastable pools that contain like for example USD or the euro you can create a whole Forex application that generates yield and boosted pools you know this first one is built on Ave but we have multiple new ones coming out soon with other partners that are utilizing Assets in balancer pools within their protocols to do really interesting things so a metastable tool is a is a pool that is designed for tokens that uh are highly correlated in value but not uh pegged exactly so a great example of that is rap steak eth and eth itself wrap stick teeth is since it's steak it's earning a yield and it has a different value from each it's always going to have a slightly different value from eth um but in a this what this is is a generalized stable pool that can hold these proportional assets um and another example of that would be like die and see die so you have a predictable schedule of like what the valuation uh exchange rate is going to be between die and C die because you know how on compound the value of uh deposited die is going to appreciate over time in order to account for the the interest that it's going to earn so let's like if we talk about Lido as an example so um when users stake Ethan to eth 2.0 with with Lido they get stake teeth in return and when they and through this pool lydo makes it possible for anyone to get in and out of staked East very easily by just trading with a balancer pool instead of wrapping and unwrapping or sticking and unstaking so that's really the easiest way to do that um last lastly here in terms of full types is something that we're currently developing right now that's coming out soon it's called the managed tool manage tool is designed to um optimize itself for sophisticated portfolio strategies and have more fine-grained control one of the main products that you might build with a managed pool is an index fund so a manage pool can hold up to 20 tokens actually can hold more than 20 tokens and uh it has you can set Dynamic weights you can set Dynamic fees and you have the ability to have an allow list of liquidity providers or you have a manager of a pool who can Implement a certain strategy for how that pool will invest its assets and you can change the tokens and the and the allocations that that pool has at any given time another thing about managed pools is that they have a feature called circuit breakers so circuit breakers are designed to protect against like a Black Swan downside uh event so uh you know defy kind of it's in general doesn't really have that but in traditional financial markets when there's like a catastrophic crash they have circuit breakers that can just kind of stop the markets from Trading so to manage pool a pool cannot at any point decide that it needs to stop trading because you know let's say for example one of the tokens in that pool um what got hacked there was some kind of breach there's some kind of um Market catastrophe a rug pull whatever might have happened that pool can actually just stop trading so that the rest of the Assets in the pool are protected so you can also not only can you use these these really interesting pool configurations on balancer but you can also create your own custom uh amm pools and I'll talk about a few examples um of projects that have done this so there's elephant element Finance sense protocol and Tempest Finance these are three um really cool projects that use balancer to create their own custom amm pools to make fixed rate markets possible gyroscope has built there also their own amm unbalancer which serves to power um a new stable coin that they're releasing soon uh and kind of the point here is not to dive into like all the complexity of how gyroscope works but just to show that on balancer there's a lot of room for building custom Solutions and kind of configuring Things based on the needs of your application as a developer Crown finance and excess Finance are two separate projects that are using balancer to build twams which is a Time weighted average Market maker and the point of of this product it's kind of something that has been discussed in the space for a while but no one really like built it and turned out that balancer was the perfect place to do so so uh the goal of a of a tum is to execute large trade orders over a longer period of time so that slippage remains low you can take trades and you can break them up into smaller pieces so the liquidity required for each of those trades to be executed is less and the slippage is is smaller so this is really important for like large-scale investors or Traders because in defy like slippage is a huge issue when you're moving large amounts of capital so um that's kind of a tour of some of the really interesting things that are being built on balancer now I want to talk a little bit about some of the grants and perks that are available to developer teams so these are a bunch of uh actually some of the projects that I've already mentioned today as you can see these are recipients of Grants they've received grants from balancer to build what they were building and um you know ended up building something really amazing so for any developers that are building in D5 and and need some kind of amm functionality if there's some kind of swap feature involved in your application it's a lot better to use a ready-made solution that works that's secure and that's you know battle tested that you don't have to build from the ground up rather than kind of doing all that yourself so highly recommend checking out our docs and definitely apply for a grant if that's something that's that you want to do we also have uh this really cool partnership with Satora the guys who are here and are going to be speaking after me I believe which is the balancer Satora security accelerator so for projects that are building on balancer you get access to two weeks of manual code review by Satora which these guys are awesome smart contract security firm uh and this is something that is is valuable to like any developer in the space and it's really hard to get audits when you're especially when you're a small team in the space so that's kind of what we wanted to do is make this more accessible um so yeah and through this program you get the two weeks of manual code review you get set up an introduction of of the of satora's formal verification prover B and you get uh ten thousand dollars uh worth of credits for satora's uh formal verification you also get assistance from the balancer Integrations team on your code functionality on business logic so it's really a good time to get involved um I'm going to quickly just talk a little bit about the SDK because it's been recently revamped and we've been getting really good feedback from developers on that so balancer.js is a JavaScript SDK that provides a commonly used utilities for interacting with balancer V2 uh valpai is um these python tools for interacting with bouncer V2 in Python balancer Sor Sor stands for smart order router this is a JavaScript off chain linear optimization of routing orders across liquidity pools to get the best price execution and then we also have two really cool community-led sdks that have been supported by a balancer grants program Delphi which is in delpherium and also rust um so as a as this is an example um of configuring the SDK to use mainnet subgraph and contracts so SDK examples and tests can be run against a local Fork it's easy to hack and experiment without using real funds and um the SDK uses this very easy interface the Sor to find best swaps like across all of the liquidity on balancer which is around a billion dollars and using the SDK you can very easily add liquidity to any pool and you can fetch and pre-calculate pool data which is especially useful for front ends and with that um we can end here if there are any questions I'm happy to take those thank you [Applause] are we doing Q a okay great this so this might be uh slightly vague and feel free to not answer this question but uh when you spoke about uh there being a circuit breaker in in a managed pool I I circuit breaker yeah circuit break in in your managed pool contacts uh who who acts as the circuit breaker who has that Authority and the larger question I guess is sorry who has what I couldn't hear you that well who acts as that circuit breaker is that again a decentralized role or is that like one person or a group of few people who act as circuit breakers and decide that it's time to shut down the market for the time being and uh I guess the broader question is where do you draw the line uh in the beginning you stress about the importance of decentralization in finance but uh we know that it's not a very practical thing somewhere we need to have some uh some amount of centralization to get get it to work uh properly so where do you draw the line if if you can articulate a clear question a clear answer to such a way question I'd be good to hear sure so I think the second part of your question to make sure I understand because the the audio is a little tricky uh was that you're you're saying that um while decentralization is great like we still need some centralization as well um I agree I think I think decentralization depending on if it's very case specific for each project like when it makes sense to be 100 fully decentralized but I think that when you look at the D5 protocols like the exchanges and the borrowing and lending protocols that have been operating very smoothly throughout all of the insane catastrophes that have happened in the crypto space the last couple of months while while you've seen a whole list of centralized platforms blow up and lose billions of dollars I think it's a strong indication that um this the security and I mean the transparency and the uh verifiability of a decentralized system is very Superior to a centralized system it doesn't mean that like there can't be any centralized components like it depends on on the on the project and the system that you know I don't want to give a one-size-fits-all prescription here but to me it's very clear that like defy will eat C5 uh CFI I mean it's these are the same issues that have gone on for so long in the financial industry where there are you know risky lending decisions made or or like unethical decisions with customer funds as what's been alleged in the case of FTX like these are things that are not possible in an immutable decentralized uh protocol um I think that with something as crucial as Finance we we really need to transition and I think that we are eventually going to transition from these human-led systems where there's a lot of room for either error or greed or you know bad decisions or misuse of trust into systems that are fully open fully transparent um yeah I think it's just very clear to me that that's what we need in finance and we don't need to have these billion dollar sort of catastrophes in the future um I I can talk a little bit about the manageable circuit breakers again these are like currently in development so whatever we might talk about today can still kind of evolve and change and it's it's not a final product right now um but what I can say is that um the idea is to set some like programmatic guard rails to defend or to protect the pool against like a a like a catastrophic situation so for example if you had a liquidity pool that contained um Terra USD and let's say you had Tara USD and you had like a few other stable coins they're all in this pool and then Terra USD um explodes the price is suddenly dropping what would normally happen in an amm is that the amm is programmed that when one token goes down it sells the other tokens and buys more of that token that went that that went down right so in that scenario the every dollar in that pool would be lost if you have a circuit breaker in place you can stop that from happening at some threshold that is like defined by the creator of the pool so that in you know a Black Swan event you can actually protect uh liquidity providers as much as possible yeah I I get the reason for right yes it can be designed that way um again it's it's a work in progress so um I just wanted to give you a preview of the product it's when it's done I'll definitely have a lot more to share so um we talked about the problems in centralized exchanges uh we started seeing problems in the device space Also in decentralized exchanges uh two days ago anchors uh tokens was exploited and they went to pancakes to happen millions of dollars was drained uh do you have those kind of uh safeguards in the balancer so I I couldn't hear everything you said but I think you were talking about um expired right on December 1 yeah December 1st uh and then and then the bundle had moved to pancakes are once again uh defy tax and and then it's dead from there yeah so there's always a risk like in an amm that if a token that is held in a liquidity pool gets exploited that you know any liquidity provider that is in that pool even even the one that is providing the token that is kind of trading against that that token that got exploited can lose their funds so um smart contract risks is very real we need teams like Satora to um you know help keep the keep the space safe as much as possible from those risks those are um those are very real um so I think D5 has its risks that are different from the ones in C5 right so in D5 we have more security risk in terms of like code exploits um in C5 we have more like human risk where you have a trusted person who's in charge of potentially billions of dollars in funds that belong to their customers and we have to trust them to be ethical and moral and fair and on honest and like so many times in the past and just just recently that has not worked out well so um what I'm advocating for is uh trusting more in like secure code than in like an individual or even like a charismatic person who who seems very trustworthy looks uh logic it looks logical that uh code will be a bit secure but it also gives uh opportunity to hackers and everybody else who understands that everybody can go and exploit okay uh in in the previous case it's like a one person which is not able to do good and we all get suffered because of that but here uh the information is available publicly okay the kind of exploit happened with anchor uh anybody can do who understand better for wave three so yes we can say that we are shifting our security uh measures from Direction a to Direction B but is still saying that okay Define is the better or more secure densify seems to be subjective yeah and I would also just mention like in the case of the anchor exploit so anchor got exploited but the amm pancake swap was not exploited right so but the people who provided liquidity and anchor on pancake swap lost their money so I think in defy there are kind of multi-dimensional risks that an investor has to consider so the investor that bought the anchor token and put it in and and decided to be a liquidity provider on amm uh took a risk in the security of that protocol and unfortunately that didn't work out and like I'm not I don't have anything negative to say about anchor at all and that's not my point um my point is even if a platform is fully is is very secure and not exploited the assets from all over D5 that can be held on that platform all have their own risks as well so there's like really an exponential um Matrix of risks uh that most people I think that you would agree most people who are using these Technologies don't fully understand all of those risks either they either they know that it's risky and they're they're doing it and they're taking the risk like some people like to gamble but I think a lot of people are not fully aware of those risks um and in a decentralized ecosystem it's really hard to provide good protection against those risks because there is no one there really like holding your hand or like stopping you from buying something because it's not safe um it's uh yeah it's it's very tricky sure okay thank you everyone uh and uh appreciate all your questions thanks [Music] should I put it can you hear me okay fantastic thank you I see your small crowd thank you for coming uh I'm going to talk now about formal verification for many of you it's probably a foreign concept how many few of our developers fantastic that's their talk for you how many of you know about formal verification sound great so I've been working on formal verification for a long time you can see and I think it's actually an interesting domain for many things I think it's a perfect application for D5 we had Jeremy's talk about balancing and actually it's related to what we're going to show you it's technology for checking the correctness of D5 and I have an hour for the talk I'm gonna use only half of it and the second half would be a demo with our tool which is publicly available you can try it and you can get a free version of it there's also paid version of it it's a subscription hello it's just what do I do I have to do something okay Okay so what is that Torah Satora is a company for checking correctness of code so Torah is a company which is global we have a we have 90 people on the team I didn't write the list of all of them uh our team consists of several people and I think the we have about 25 people with PhD in formal verification from top schools in the U.S in Europe as well and we combine it with other people who are Security Experts I mentioned only few of them here and I think we are very very grateful for collaboration in particular we have a collaboration with Rajiv from Sacramento and basically this help us to embod people into this domain and some of them are here and working with us like Alex Joseph and others they're actually bringing more people into this space and we are looking for more we are looking for more and there are different ways that you can collaborate with us you can work in theater but you can work in in customers that work with a tour you can also work in the community for example we have a large Grant which was just so basically you're going to write correctness and we are doing it with other protocols we are also working with some of the Auditors for example spear beat and code Arena so basically they are code arena is an is a Content company and as part of the content you would write correctness rules and you will check them with the Satora folder uh we also of course acknowledge to our connection in Israel specifically to the IDF so we have I think Amit heavy with a senior person in the idea for code vulnerability and he leads our security team so everybody knows about this bargain we had about bugs in many places there are a lot of bugs I want to actually point out to you D two ones which are my favorite this is The Nomad Act and the other one is the compound so these are cases that basically the quad actually was good actually and was even audited and for example in the case of compound it was even checked compound is is a they use a very good Auditors and they're also paying customer of Satora and they use Satora but what happened after they checked the code with Satora somebody changes the code without one Etc and as a result there was a hack which was exploited so this is why we want to use this technology to check the code before it is deployed so in the domain of security oops there are different tools uh the simplest tool you can use is testing basically you test your code and all all developers will use testing or we use fuzzing there are also tools that help you make the fuzzing easier in the area of web 2 there is AFL this is a very very nice tool which was used to find many many bugs and in the area of web3 people are developing similar technology in particular 12 of bit is developing in kidnap and found an uh Paradigm is developing Foundry these are very very nice tools they basically test behaviors the the problem with these tools they are very very useful but the problem is them that's hard to find bugs which are somehow happening in real situation and I'll give you one like this but you can see many of them in the sector approve that actually these are bugs that happen after many states and it will be hard to detect them if you start running from initial step so that's one technology it's not unique to web3 it was of course in web 2 but it's also useful in web3 it's probably less useful in web3 than web 2 because many of the security bugs in in web3 they are specific there's a managed environment the second technology which has been around for ages it's static analysis so static analysis it provides more coverage than fuzzing and there are tools available there are industrial tools mainly for web 2 that checks the code for correctness and it covers more Behavior than testing but the problem is these tools and uh that basically they have the ability to basically Miss errors and they have false positive and false negative in this context Satora actually has built a very interesting case in the Serato approval we analyze the byte code and actually we can prove certain properties automatically without the human and this is something which is integrated into the search of approval there is a static analysis integrated the right hand side these are techniques which are supposed to provide more coverage but they are potentially more expensive and they are called formal verification intuitively formal verification means showing that your program does what it's supposed to be and there are two branches of formal verification the one which I'll be talking today which is called automatic formal verification the idea is the human rights the properties and the Machine is trying to reason about these things and this is working by compiling the tool into some kind of mathematical formula and this is what integrated into the software approver and there are a lot of Open Source Tools in particular the Daphne tool by Microsoft research it's a similar tool it's a tool that basically compile your code into a mathematical formula the difference is that the central approver is more scalable and you can see the for example the Saturn approver you can run it on thousands of lines of code which is not something any this is unique not just in web3 the ability to run on such a huge code and we have a proprietary technology that we developed that help us scale this this is why we have all these Talent people that are helping us building this stuff so this one it's effective to give you effective proof and Bug finding because it doesn't start unlike fuzzing it doesn't start from an initial state but it is expensive because the problem is computationally expensive we usually in computer science we call it undecidable which means that the computer will not always do a perfect job and the other branch which is which is also useful it's called interactive sometimes called manual formal verification so the idea here is that not the computer is doing the job the human is doing the job and the computer is only checking you and there are tools in the area of of web3 there's the K framework in web tool there is tools like lean so these are tools of o'clock these are tools that check your proof you are writing your proof so in this case you can never get wrong you write your proof and from the proof you extract your code this is a nice tool which has been used in a nice methodology which has been used in many cases the problem is this kind of approaches it's very very hard for human to use even for small things like erc20 you may have to spend 10 months to to prove this poverty so this is very very hard is technology so maybe just to give you a hint on static analysis so this is one of the most useful static and other tool which is called Slither how many of you know slither great so I just learned later on the bank bank is a very very simple call and it has many many red lines do you want to guess how many of them are real error zero and the reason is not because leader is such a technology which is bad of course you can improve the technology behind Twitter but the idea that slitter does not know what the quad is supposed to do the slitter is basically running a generic test on your code in terms of comparing the tools so I try to compare you have basically The Other Extreme this is the extreme that you get very high coverage I mentioned okay lean so these are the tools that get High coverage and the Other Extreme these are the tools which are easy to use and I mentioned uh Foundry but there are other tools which are easy to use and certain is trying to build something in the middle we are trying to make something easy to use as the the or maybe not as easy but uh close to using a father but give you almost the coverage that you get from interactive temp program and I think we are there we actually have a lot of things that we have done in particular we are analyzing the executable code we are not even trusting the compiler we are checking the executable code we also make the tool very easy to use and you will see if you see Alex will show you and you can switch with the demo and the other thing that we do we involve the programmer in the loop when when the Tool when it's hard for the tool to analyze the code you can use modularity you can basically make your code more modular or tell us how your code is modular and the more your code is modular it will be easier for our record to analyze so what do we do in satura we do two things we have an open source language called CVL it's for a language for writing properties this is something that we want everybody to use and it's something that you the properties of your code this is the CVL and then we are developing technology we are developing three kind of Technologies the first this is the technology for checking the code at the moment it's proprietary but you can use it and you can use it as much as you want the second technology which is coming actually very soon is developed by Chandra and Andy and Chandra what she's she's leading she's leading the project for checking the specification and this is an open source tool it's essentially a mutation testing for solidity in which you can check if your specification is okay is checking that the CVL is okay and it's making the task of checking the writing CVL easier and the same technology that we are building now is a monitoring technology is the idea is that we want to monitor the city real when the code is executed and when the transactions are executed so what I want you to get from this talk and hopefully this is what you get when you use the Satora is the the ability of the beauty of invariant an environment these are sort of the essential properties of program which basically means these are the properties that if they if they have to get to be right and if they are wrong something is bad okay so in area of D5 the interesting thing is like solvency it means the bank has enough money to cover the loan it has some kind of property and these are the invariants that you have to work when you are using Satora so let me give you a very simple but interesting case of insolvency so the solvency the most intuitive solvency says that if everybody goes to the bank the bank can still pay the money pays debts and and solvency it's an interesting property for all the D5 D5 protocols and what's mentioned by Jeremy in the previous talk Serato works with customer and usually we work with them either before audit or after audit these are the cases that we work with customers after all it it means they completed the audit and after that they checked the code with the Satora approver and you say you can see here these are bugs that are found by this technology after the audit was completed and all of them these are by solvency I'm going to show you one like this but the idea this is bugs which allow you in a rare situation to take the money from the contract and this was found by our tool and it was found after a very very good auditor of course an auditor can also find bugs after us we are not replacing the auditor we are complementing the auditor so how does the Satora prover work you will see in in Alex demo but the idea is the user is a static analysis like Slither but you are not only writing the code you are also writing the environment and the tool can do to fix it can give you a mathematical proof that the environment is maintained that's very interesting but the most interesting case and this is what I showed in the previous slide it show you a violation it shows you a potential rare case that the program starts from a state which satisfies the environment into a state which violates the environment this state is not necessarily the initial state it can be a state which happens many many uh uh after many steps of execution and that's the beauty of formal verification it gives you an inductive reasoning why your program is correct independent of how many time it's executed so of course since we are talking about the computational hard problem the tool is doomed to fail in certain cases and in our case the failure means not false positive or false negative but it means timeout it means you run the tool for two hours and you don't get a result and we have a technology that we are building to improve it but it's always doomed to fail in certain cases and here you can use modular reasoning we are doing many many things but you at the end of the day if the code is complex enough the tool is doomed to fail the technology is very useful and already mentioned that as part of your CI we integrate like two like Circle and jit so basically every time you change your code you run the two and that's the difference with a manual audit in the sense that this is a continuous process you run the tool you change the code that assuming that the environment Remains the Same you basically maintain the same environment throughout code changes so this is essentially the tool that you want to integrate into your CI to make to keep the code safe actually is fairly complex technology and I won't be able to explain this in this talk but there is a white paper they encourage you to read which actually explain everything behind the sector approval I'm just going to give you the basic idea so basically we run the compiler the solidity compiler and then we have our own decompiler we have our only compiler that decompiled the evm code into something that we understand so this is these three others code it's actually something that that we understand at the moment we are supporting evm but evpf is coming and web assembly is coming so we will support other blockchain so we are basically building this stack to support all the blockchain that is important maybe chiro maybe others so this is all in these three others code and then we have our secret Source we have actually tools that simplify the code and that's very interesting we run some static analysis but this static analysis is not used to find bugs it's used to actually simplify the code uh so basically and the interesting thing about this and I don't know if you have seen in the process of simplifying code we are making certain assumptions about what the compiler generates but we're of course checking them so we are not analyzing arbitrary code we are checking some properties and I don't know if you notice we actually produce many of the bugs in the solidity compiler so these are bugs which will automatically identified by a tool and they are bugs in the solidity compiler itself yeah so this is actually an acknowledge from the ethereum foundation uh the other thing that we do we take the code and generate a mathematical formula here we are building on smt how many of you are familiar with smt few fantastic so smt is actually a technique I mean if you ask people in computer science they think that satisfiability is a hard problem they're of course right but the idea is even though it's a hard problem there are actually tools that work that that actually can solve many many instances of them and the idea is there are even tools for smt and we actually use all of them we contribute open source to them so basically part of the things that we do in the in this thing is we make smt reasoning easier and if you don't know what smt think about linear programming think of some kind of mathematical reasoning so what we do we actually and we we also going to do more we do a lot of things to reduce the number of timer to reduce the failures and in particular we care about financial systems because this is what all our clients are so I'll give you a very very simple example we'll give you more so this is a very very simple quote you see you transfer and the invite that you want is that the total is equal to the sum of the balance and you run the tool you see the tool automatically identify a bug in which L is transferred to herself and basically the the money is gone and this is a case so sorry actually actually increased so the the the sum is increased my mistake and this kind of bugs these are the bugs that we are finding with this kind of techniques these are the violation of your environment and so this is the case it was found by the tool when you are correcting the code we can actually produce a mathematical proof that the environment is maintained it doesn't mean that the code is bug free but at least it means that the rule that we check is maintained so that's the idea ah actually we have two type of customers and maybe now three one of them are security researchers which is fantastic they are using the tool which is great like in the spear bit and then now with us Ave code Arena the other one our our developers and the third is us and the interesting thing people that use us the maker team they have actually a very very good team I think about seven or eight solidity developers that are using this tool and they are checking environment about the code and the environment that could wanted to check is that the code is the the coin is stable so everybody know what maker is that's right so make your Implement a stable code so the environment says that the coin is stable and in fact the tool found out an example in which in certain cases it is violated so this is something that was found by the tool and basically you see there is in each function and the init function the environment that has is that the depth is equal to the sum of the collateral and with the two will actually find that in certain cases you can violate this environment and when you fix the chord it shows you that this environment holds so this is a very very good use case of this technology finding bugs in your code and these are potentially hard to find bugs that we are finding with this kind of Technology I want to basically close this first part by showing you uh a critical bug which again found by the tool and and Alex will show it later so this is the sushi swap to ident it's a code and actually related to the talk that we've seen by Jeremy it's a basically Implement what Jeremy said the Dual dual uh liquidity pool and you see the code here there's been single this is a code which is in solidity uh uh you it's probably hard for you to see the bug but I mentioned it in red basically the quad is not using it's it's more interesting bug than the bug that we have seen in the previous slide because the code is actually not using correctly the API and as a result there is aware back in the court and this wear bug is found by our tool and this where bug will allow you to completely deplete the code the the money in the Contour okay so what is the nature of the bug so you have to stay what is the invariant and the simplest environment about liquidity pool is that the multiplication is constant but I even use something simpler it's basically say if you have two tokens they they cannot be that one of them is zero and the other is is not zero so if one of them is zero the other one better be zero and here you see Bob and Alice in the trident and there is an operation in the court that says burnt singer in which Alice Banner holding and what happened this actually you see there is the number is 400 and the number of B is zero so basically you see that the invite is broken okay so this is a violation which was found by our tool by basically running our tool we found the this violation we found this I have to say before the code was deployed most of the bug that we found of bugs that were found before the code is deployed when we are finding code box after the code is deployed we are very very quiet about them uh so what's going on so in fact what's going on here this bug is a bug which is very very you notice that the system also always start from our environment so the question you can ask yourself how can how can you have this environment how can you violate this environment and what are the implications of it so this is the case that you see what happened here it is deposit a hundred coins uh Bob deposit a hundred calls and then Alice transferred 200 coins so basically in a is 400 and the token B is 200. now the band singer that basically violates the environment and finally what happened early swapped the money so basically Alice give one coin and get all the money and Bob lost all his money so this is a bug which was found by our tool but our tool doesn't see all of them that's the beauty our tool only reason inductively so what does the tools do it looks in these two states he looked you into one state which satisfies the environment into a in there is a transition from this state into a state which violate the environment and that's the beauty of the induction of course if you work with in manual formal verification it's exactly the same you you where you Vision about uh execution we start from a stage satisfy the environment into a state violating environment so that's the idea I want to close before I let Alex uh present the the the the demo I want to actually sort of tell you some things and these are of course not just my own uh experience this community has been along for a long time formal verification has been used in Hardware industry especially after several High uh important bug were identified so the question is what's the value of formal verification and this is something that we are trying to understand some of them of course are not just for web 3. so the first thing that people think about formal verification in particular on web3 you see a lot of people speaking about this formal verification is about proofs but I think the most value of formal verification of bugs these are hard to find bugs that you are finding during the process so that's the and I think that's we see and I try to make it in this talk and when you use a subtle approver you can see that it generates a proof and of course the proof has a value especially if your environment are okay but the most interesting thing these are bugs that are prevented the other thing already alluded to that is that the hardest problem people think about formal verification is go back to life theorem and others that say this is a computationally hard problem and of course it is the case but we think that the hardest problem is actually come out coming up with these invariants and actually that's why we need the second whale that's why we need people like you to help us write interesting environments and we are trying to incentivize people to write interesting environment like for example with the other we are enslaved by people with money if you write a good environment you get a reward for that the other thing is that and that's also think people are thinking about when you think of formal verification people say oh I formally verified it and one of the giant of computer science connote how many of you know news oh great so close of course is a fantastic computer scientist at Stanford which has contributed to many fields including formal verification and one of the jokes that he said I don't believe this quote I formally verified it and I've never tested I think this has a very good thing the idea is that basically formal verification is just one thing it doesn't guarantee that your code is correct it only guarantees that the environment are meeting which is of course increase your security but it's not a bulletproof uh the other thing in the web tree that people think and they approach us they say look auditing is expensive we want you to replace formal auditing it's not what we are trying to do we are trying to complement auditing I already mentioned that there are Auditors who use certain the human and the computer are are actually uh they basically help each other it's not like an automatic automatic car when you just have it and you because you need the human for example the human can actually find bugs after us if we don't have the right words and then we can update the rules the human even already we have seen Auditors that found bugs in our Woods which is fantastic it's just another artifact of the code to analyze and we want the human to and and and the auditor the human auditor and the tools to help each other they are not we are not replacing the auditor and maybe the last thing I want you to take and that's again something that the formal verification is something that you need to think as early as you can whether you engage with certain or not it doesn't matter but you need to think of formal verification particular form of specification as early as you can and use the tool even use our tool as early as you can even when it's feature complete use the tool so this is the idea you want to use this uh technology as early as you can because it will prevent bugs and it's easier also to use it because the quad gets more complex it's harder to use this technology so we want you to start use this tool as early as you can so in conclusion I want to basically come tell you sort of three things one is that bug finding is hard without a tool without a tool it's hard but the Torah actually makes it interesting by using this inductive reasoning by the idea that you write an invariant and we are looking for violation of this environment the other thing that I didn't get a chance to explain but there are talks that we explain that and there are technical people on our team we are actually producing something which is interesting in terms of uh new algorithms we are actually innovating in the area of static analysis and innovating in the area of constraint solving and we are combining these techniques and you are welcome to listen more what I talk to you is the idea of automatic formal verification this is the idea that you write invariant and it's like a quality assurance tool that checks the environment and either find a violation and this violation can be rare or prove absence of violation so this is it please if you want to scan the technology paper I I suggest what we do now I will answer some questions if they are and while I'm asking questions but maybe just let people scan uh uh uh Alex will set the demo please take the demo is interesting but I'm happy to to take questions on on my talk on formal verification uh please if they have a question I would love to take some maybe while you said you can set them hi everybody scan yeah you have questions would form a verification still work for systems that are not closed so for example for let's say our D5 application like unit swap right you can probably write an invade invariant where the total USD value of Assets in a pool will always remain same enough after scraps right but say for a system which is not closed so it's like a cross chain liquidity pool where tokens are coming in on one chain but they're actually leaving on another chain so uh what formal verification still makes sense in a scenario like this or what do you suggest here interesting so the question is uh will formal verification make sense in a system that is not closed so the answer is it makes the most sense when you have free system which is not close but it's more complex yes okay so and we work with compound for example who's calling uni swap we work with a bridges that actually some of the code is not available so the idea is modularity you basically have a requirement on one thing for example units work is monotone and then the question is do you trust this thing or do you check it so you can do two things when we analyze the code of compound for example we made certain assumption on the unit Swap and the question is do we check them or we don't check them at the moment we don't check we can check them statically or dynamically so the idea is when we work with some clients they actually call other clients and it's actually the beautiful thing of formal verification and you even seen it in the that you are finding an API violation you are finding a case that I'm calling your code and I'm not able to actually satisfy the precondition for this so yes this is actually the most useful application of formal verification is called and you are that actually there are a lot of interaction between the code and and yes we can do it either statically or dynamically we can do it statically it means that we need to analyze both pieces of code we can do it dynamically or sometimes it's just assumption because sometimes it's code that we don't see somebody is calling an oracle or somebody is calling something that is not in something that we can analyze it's a it's a bridge for example so yeah but it actually is the case we are finding bugs because if you have a bug with respect to the Assumption now you are implementing the the compound money money market and it is calling the unit Swap and the question is you're you're writing these assumptions and then you are checking the the correctness of the code not with respect to the actual code with respect to the assumption that you made so yes it is very very useful and it is one of the most useful application of our clients but it's not easy that clarifies a lot thank you there's another question here so when you have these formal verification specs um and you like you say like formal verification is computationally computationally expensive do you mean that uh you're fuzzing the invariant and you're checking all of the states like in a brute force method or do you does that competition go into calculating a mathematical proof uh that this statement never occur or is it like a Brute Force so so our technology doesn't do fasting we don't enumerate the behaviors what happened is that we compile your code into a mathematical formula and the mathematical formula enumerates all the behaviors and this is the and the question when it's working when it doesn't work it's a very very hard question in general for example when you have linear equation it's easier to solve so we are not enumerating the behaviors that's the beauty of this technique it's actually giving you exhaustive think like if you have for example in this in the ethereum you have like an integer which is 256 to the 256 we model it as an arbitrary integer so we give you a mathematical proof and when is it hard when is it easy it's very very hard to know we actually have a lot of algorithms and sometimes they surprise us how well and how sometimes it's really surprising these constraints over that they can actually succeed on things which are very very complex for a human but sometimes hard for example when you have interest rate it's actually we we we came to know but it's actually it's we are not doing fuzzy we are we are nominating all behaviors that's very very different it's of course more expensive but we are we are doing fuzzing we are not doing fasting we are basically enumerating all behaviors and of course it's it's done by the by this reasoning about formula you write a formula like say x square is is is equal to four and then basically the system will find out that X is 2. so that's the idea you write a formula and then we have open source tools that we are we are using to to find the solution to the formula and the solution to the formula it means you have a bar and if you find out that there are no solution we can generate what we call a proof tree which is actually indicate that you don't have a bar but this proof tree enumerate infinite number of behaviors we are not looking into final Behavior that's a very big difference from fuzzy we can do fuzzing for example to get initial answer and we are actually doing it because sometimes it takes two hours until you get an answer and the user is frustrated you great thank you which smt solver have you used and why and so which smt solver have you used I am assuming either Z3 or cvc4 and which one do you think has given you more empirical empirically can you comment on the performance of these yeah so that's a very difficult question because I'm I'm fond of all the people so but fortunately actually it's very surprising all so it's actually on different benchmarks on a different code they are they behave different and historically yikes is much older and people have invested a lot less but we find that in summer for example the ice does fantastic where z3. CVC we also supporting Saratoga we raise money to support here we are supporting of these kind of things and we are improving we are adding uh now support for C3 for for a large bitwise operation we we are we are working with the so the answer is that and also we are thinking of combining them because they have this idea of learning lemmas and sometimes they'll even when you have a timeout you learn something and we can actually combine them so we are we are agnostic we are at the moment we are using the three of them and our user I think there's a flag but I don't know Alexia there's a flag which one to use but I think most users will just let the system choose if you're also working on machine learning yeah and there are machine learning techniques that we are doing to optimize that yes so just to extend on that I mean since I've seen it in your tool so just for other people this smt solver these are techniques that are used under the hood here which are used of course in Microsoft Visa we basically compiled the code and the environment into huge mathematical formula sometimes few megabytes actually it's interesting that it works and these few megabytes of formula it gives to the folder and the solver gives the solution yeah so great tool chain I've seen that you have a lot of custom software right uh for your certain applications for a certain requirements right similarly uh have you thought of just creating your own solver combining all the strengths of if at all yeah yeah so that's a very interesting uh so the question is have we thought of construct creating our own smt solver we don't know at the moment we have been around for four years I think it will be difficult for us but maybe we are more thinking of contributing small things to existing solvers and and supporting them but yeah it's it's very interesting to build something specifically for D5 what we are thinking more is sort of thinking something on the opposite trying to tell like some kind of design pattern tell people if you write the code at the moment one of things that we are doing we used to charge a flat price for using the service but we are no longer charging flat price if you have code which is complex you pay us more but the idea is we want to actually reduce the price by telling you if you write the code this way and if you write it more modular it will be easier for us and it will be cheaper for you we are we are trying to scale up and it's uh but yes down the road maybe developing a solver for D5 I know the Eternal Foundation is interested in that but yeah it's interesting uh so the challenge now has transferred to writing specific and very tight invariance [Music] that doesn't seem like an easy task for a complex project invariance might get easily complex and there might be bugs in the specification so you mentioned there's another project which kind of checks the correctness of invariants could you please tell a little bit more about that yes yes so you're absolutely right so the the issues that if you know I mentioned in computer science we mentioned close but another giant of Computer Sciences I'm sure that most of you you know is diagster and I mentioned the dagster of course in one go back to a platon but Daxter said that you cannot write a program without writing the environment that's of course correct in principle but it's very hard to write invariant you're absolutely right and we also find out that when we are writing environment for our clients we made them wrong and and but the idea is the question is what does it mean wrong if it's wrong in the sense that it finds a bug that our tools say and then we check the environment that's one thing but the thing that we are aware with we are aware from environment that actually holds and give you a false confidence on your core and we already have one client who actually use us in addition to auditing and then basically if somebody found a bug and they didn't accuse the auditor so they use the the and the the customer actually wrote the environment and there was no failure of the tool The Firm that the invite was tautology he writes something like seven is greater than five and the tool of course was able to prove that seven is greater than five but it's and it's increased the confidence of the of the of the of the of the protocol so we now if you look into the Satora even if you look into the version that you have this cannot happen we have basically a vacuum vacuity check we have something that checks if your code if you have a bug it's a bank but if we verify your property we try to check if it's vacuous we try to check for example this kind of bugs we can avoid and what we do we do mutation testing we mutate your code we take your solidity called the mutations and if we change it and the environment still holds we suspect that something is bad and this is very good for us because as a company we are basically engaging with larger community and the idea is people are submitting environment and we have no idea this is are good or bad so we are using these tools to evaluate the environment that the community submit for example in the other project I think we have 25 security who are submitting environment so we are using these uh tools to check the environment both the environment that are produced by our team but which which are written by other people so you mentioned about the correctness preserving Transformations could you elaborate a bit on that like how do they preserve the correctness or like how do they work or give an example of that maybe so I mentioned the correctness to preserving transformation we have a so this is of course uh we basically uh did uh wait uh so I I don't know how much the way code is just in in the evm but it's basically what this idea was called bumper locator so basically memory is allocated directly and what we observe certain properties of these bump allocator and in in order for that to simplify the code this is how we identify many of the bugs in the solidity compiler itself and we are actually submitted an article about that and we will publish it of course the the so these are results that basically these are techniques called Static analysis which actually infers some property of the code and intuitively the ideas for example you have a load and installed and instead of letting the smt vision about it we can reason about it and this is a game changer it it takes something from time out and convert it to 30 seconds it's a game changer of course the smt it's a complex technology the the less you can call it whether all the smt is always the better and we want to do more like understanding the values and this is how we say correctness preserving transformation but of course we haven't proved that they are correctness transformation it's called that we have written in our tool but it's uh we of course up to a bargain in our tool they are correctness specific transformation thank you can you can you hear it through the speak now I think you can hear can people in the back hear me all good okay uh so I'm gonna take you through uh a bug that muli also spoke about uh it's the bug that we found in the uh in the Trident uh constant product uh liquidity pool uh the idea is to give you some sense of how uh you work with the certain approver to find bugs so um I'm gonna uh and you can also if you want you can also start working with me if you go to demo.satura.com or just go to satora.com and look for the demo button on top right you will land on this page uh just go to the interesting box part and click on the custom product broken uh piece and uh this page will open up so on one side you have the solidity code that we are trying to verify on the other side we have the spec that we've written and the tool takes both of them together and uh mashes them together does a bunch of optimization and then comes up with The Logical formulas which are then fed into the smt solver uh all that stuff that normally spoke but uh yeah let's let's uh first look at the solidity code uh and uh and then we'll look at how we went about verifying this so uh it's essentially uh as I said it's a constant product uh liquidity pool uh which implements any rc20 protocol also for uh the the lp tokens that it mints and distributes so for those of you who don't know uh a liquidity pool is basically where you provide liquidity and people use that liquidity for various applications in this case this liquidity pool was going to be used for an automated Market maker and it was a constant product uh pool where people like you and me we can supply liquidity to the pool and as an IOU we get back some LP tokens these LP tokens uh from a liquidity provider standpoint can be redeemed for your share of the liquidity so you get back uh some part of the protocol so you'll get some some part of the liquidity pool so you get back some some amount of both and uh so the idea here is that okay I'll talk about the properties later I'll just quickly run you through the uh through the the contract here so it's an erc20 contract uh on top of that it builds uh functionality for the liquidity pool so we have two tokens it's a classic two token constant product uh sort of a pool so we have two tokens uh the contract also keeps a track of the reserves that we have for each token uh it also keeps the track of the product that it uh adheres to when it's swapping uh tokens uh this product of course goes up and down based on the liquidity uh overall liquidity in the in the pool going up and down but when you're swapping uh uh before the Swap and after the swap the the product needs to remain the same uh there's uh there's a mint function which basically mints uh the lp tokens whenever you add liquidity to the pool and these LP tokens are essentially shares that you hold in the liquidity pool so when you redeem it you get a part of the liquidity with the tokens that are sitting in the liquidity pool this is a bunch of logic in here that is not relevant for this discussion so I wouldn't go into it uh this this is the most important or most interesting function here uh so typically you know in a liquidity pool contract when you're redeeming your liquidity pool tokens for uh the underlying assets in the pool uh you would redeem the tokens and the contract would give you back two tokens some out of each of the two tokens in the contract in the pool but there is a special function here which is called burn single what it does is that when you're redeeming uh your liquidity it allows you to pick uh one token that you want to get paid in instead of two tokens it allows you the x that extra functionality where if you choose to get paid in just token one or token 2 you can do that so what this function does is it does two things first it withdraws your liquidity uh based on the amount of token that you have essentially what share of the liquidity pool you own based on that it calculates the amount of each token that you're supposed to get and then after that it does a regular constant product uh amm sort of a swap where it exchanges one token for the other uh the token that you want so uh the functionality for finding out the amount that your owed by the pool is here where it's calculating uh the amount of tokens you get for each token by looking at the liquidity and the total Supply so that's your share of the pool that multiplied by the balance for each token and that gives you the amount and then when you come further down this is where it's taking a token uh and looking at the amount of that token that was calculated in the step before this and then it's based on the new state of the liquidity pool where of course now the reserves have gone down because you've withdrawn some amount for from each of the tokens so based on the new state it's going to figure out how much tokens you are eligible for of token B uh for the given token a amount and then it adds that amount that is calculating here to the amount that was calculated here and that's the total amount it will transfer to you uh in one single transaction so um okay now I think I'll go to the spec after this and uh so the idea here was that as a liquidity provider there are certain things that you would be wary of uh if if I'm providing liquidity to a liquidity pool I would want to be sure that I should be able to withdraw that so if I have LP tokens I should at any point in time be able to exchange those LP tokens for the underlying uh liquidity pool assets uh similarly if I'm depositing something into the pool I should definitely get some LP tokens which is a proof that I've submitted that I've supplied liquidity to this pool and so I'm eligible to withdraw the money that I've supplied back so the idea essentially is that from a liquidity provider standpoint uh if uh if you have certain reserves in the pool then there should be liquidity pool uh LP tokens out there in circulation otherwise uh that there's no way to uh withdraw the the funds that are in the liquidity pool similarly if there are liquidity liquidity pools in the in circulation liquidity pool uh tokens in circulation then there should be reserves in the liquidity pool itself because otherwise the tokens that you hold they they don't mean anything because you don't get to withdraw any liquidity that you supplied so uh all that uh all these properties that I just spoke of these are fairly high level properties you don't really need to look into the exact implementation of the of the liquidity pool everyone can get that concept that if you've invested I mean Supply some liquidity to a liquidity pool you should be able to withdraw it and you should get liquidity uh pool tokens which are essentially a proof that you've Supply liquidity so when we uh paraphrase that into a logical expression this is what we get so this is essentially uh the invariant that we had written here where we are saying that the total supply of liquidity pool tokens Can Be zero uh if and only if the reserves of the underlying assets are zero for both the tokens and uh when we run this very simple intuitive invariant which doesn't need you to look at any implementation just a very high level thing that makes sense to you when we run this against uh the tool it shows us a specific bug that we found and yeah so so when you run the Tool uh feel essentially uh I'll tell you how we run the tool so uh we invoke The Tool uh and we give it the contract that we want to verify we specify the contract that we want to verify in the solidity file and then we specify uh the specs that we want to verify the contract against and uh any other helper files like we would need some rc20 implementations here to model some of the calls that are happening to erc20 contracts and then the the compiler that we need and some other flags that I don't think we need to get into right now but yeah essentially we are giving the the tool the solidity file that we want to verify the contract that we want to verify and the specs that we want to verify and uh this is uh what the report looks like on the left pane here you have a bunch of rules and invariants that you've written and so if you've written multiple rules and invariants that you've run uh with the tool you would get a list here and uh for each rule it will either show you a green circle with a tick mark or a red circle with a cross on it that says violated and when you it lets you do a deep dive so here uh so this was an invariant and this this tells me that this invariant failed in the preserved state of the event so I want to talk a little bit more about how invariants work with Satora approva uh and Bully feel free to add if you want uh so invariant we prove invariance uh using induction uh invents are proven in two stages uh first when the contract is deployed and the Constructor is run after that the tool verifies whether the invariant that you've written whether that invariant holds or not and then if it employees after that the tool will assume an arbitrary state which still conforms to the invariant and then from that arbitrary state it will call any function in the contract and after that function is executed it will again check if the state of the contract adheres to the evidence that you've written once you've written once both of them are verified once you've established that after the contract has been deployed and constructed the invariant holds and after starting from an arbitrary state which conforms to the invariant and running any arbitrary function in the contract uh the the state of the contract still conforms to the invariant that you're testing against by induction you can prove that this contract this code will always adhere to the internet that you're trying to verify so uh the first stage of the invariant is what you see here what we refer to as in State this is what is verified after the the deployment in the construction and we see that the tool tells us that uh what's happened here just give me all right guys okay so in state is as I said the first stage of invariant checking where it checks it right after the instruction and The Preserve state is is a second state where it checks after that when it assumes an arbitrary state which conforms with the invariant and then checks against all the functions in the contract uh so the the preserved state is what is failing here so uh this has to fail for at least one function uh in the contract so when we click on it and do a deep div figure it shows us that burn single is the function uh I hope everyone can see this is this people on this side able to see this uh so burn single is a function which is causing an issue for us so again we further click on it uh click on the arrow and now you start seeing things popping up on the right side then it is a bit wonky yeah so this is a section that shows you all the rules that you've written within those rules if you drill down it'll show you further exactly what part of the role or the invariant has failed and specifically which function has failed you this part will tell you the call Trace call Trace is essentially showing you a detailed view of the entire execution that the tool has gone through and it'll help you understand exactly where the error is this section is where we have the variables in call resolution this section gives you more information about the exact values of the variables so if you so in invariant since we don't have many variables you don't see much here but if you like if you write a rule uh and I'll show you what a rule looks like you've already seen what an invariant looks like if you write a rule in which you've specifically defined certain variables that you want to track the State against that you want to track against the state then all those variables will get populated here and you will very clearly quickly clearly see your snapshot here of what the value was for those variables before and after some function was called and it's it makes it a lot easier for you to understand the counter example now I'll take you through the the call Trace to explain to you what's happening here I'll get to the preserved block after this it's it's uh it's an additional functionality we have uh on invariance which makes it uh a little more useful uh where we have additional specific preconditions that we're going to apply with invariance but uh yeah you see here that the tool says assume invariant and please State because that's where it starts when it comes to proving uh specifications proving invariance in resource state so it it assumes an arbitrary State uh and it ensures that that arbitrary state conforms with the invariant and then it runs a function in this case it's running the the burn Sig the burn single function and we click further uh it and it tells us more details about it so at this point uh let me take you back to the burn single function so it'll be easier for you to understand what's Happening Here mint burn single yeah so so the burn signal is getting an uh getting us parameters uh and uh a token address uh liquidity which is essentially the total number of uh LP tokens that the person has and the address of the recipient so the address that gets all the the tokens that are withdrawn from the liquidity pool that address so what it's doing is uh it's using this liquidity to calculate the uh the amount of tokens for both the tokens that need to be paid out to the uh to the user from the liquidity pool so it's using the liquidity the total Supply uh using that fraction on the total balance of the contract for that token calculating the amount similarly for the other token and then uh it's burning the liquidity tokens because now you've withdrawn the liquidity and then it uh based on the token that you've supplied here it decides which token needs to be swapped into the other token and uh that calculation is done here through the get amount out function where you supply the amount of the token that you want to swap out of and you also provide the latest state of the liquidity pool so this is the reserves of the two tokens after the liquidity has been pulled out so the amounts are updated by Reserve minus whatever amount of your withdrawing from the liquidity pool uh and then after that that amount is added to the amount of the token that you want to withdraw and then we do a simple transfer of that token that amount to the recipients it seems fairly straightforward but uh where things go wrong is that the specific example that the tool shows us here is that when we call the say the burn single function uh with certain amount of liquidity uh and some recipient that's not important right now but uh we see that the tool is showing us the in call Trace these steps where first the function is checking for the reserves it's checking for the balances and these balances are being used to calculate these amounts so we see that clearly here that it's checking for the results it tells us that it checked for the reserves and the values that it got back over five and four for both the tokens uh similarly the balance amounts that it got were 15 and 4 for both the tokens and then it checks the total Supply that is a certain amount uh bear in mind this total Supply uh and the liquidity that's been given us so this liquidity is smaller than the total Supply it's supposed to be a a share that you hold in the liquidity pool and uh after that we call the burn function so uh so right now we are here so we've we've seen these steps we've seen this step and in between we've gone past this calculation where amount 0 and amount 1 has been calculated based on the liquidity and the total Supply that we've saw we've seen so after this uh after this we go to the burn function and then we uh then you're looking up the tokens for uh so this is the lookup that you see here for the tokens and uh eventually we end up calling the myself call yeah So eventually we end up calling the get amount out function and that is this function which uh which is helping you swap from one token to the other and uh one peculiar thing that we see here is that the uh so basically you're providing it some amount of a token that you want to get rid of and that's this amount and uh you're telling it that right now the state of the liquidity pool is this and if you notice that one of the reserves for the liquidity pool has already gone down to zero and uh that begs the question as to how this happened if one person we can clearly see here that this user has a certain amount of liquidity which is clearly less than the total Supply uh which can be seen here if if somebody's really good with hexadecimal math you you can see that it's uh it's clearly a subset which means that the person does not own the entire liquidity so if they have done a withdrawal there is it shouldn't be the case that they've completely drained out the reserves for any one token but that seems to be the case here so uh that takes us back to the code and we want to understand what happened and uh that's when we realized that the way these amounts are being calculated is is wrong because we are using these liquidity shares and multiplying that with the balance of the contract and we see here that the tool shows us that the balance of the contract is different from the the reserves that it's tracking the liquidity pool against you can see for token a the reserves of five and the balance is 15 here so uh if you calculate the same small share against an inflated balance amount for a token it could very well be the case that that share of that inflated balance could be equal to or greater than the actual reserves being maintained in the liquidity pool and here in this specific example was it what the tool is telling us that uh the balance was such that for this given amount of liquidity and total Supply this amount uh ended up being exactly equal to the reserve of token zero in which case when we called the get amount function uh this value ended up being zero I mean this value ended up being zero and the other value is whatever was left after the swap so uh and if we look at this function in in more detail we figure out that uh if one of these Reserve values is zero then what happens is that the output value that it's returning which is basically the number of tokens that you will be able to swap out or swap into uh that number is essentially equal to the total Reserve so what's happening here is that uh this particular in this particular case when you call the burn single function it's allowing you to withdraw the entire liquidity of the of the second token so your the balance for the first token is inflated because of which the share that was calculated was wrong it was equal to the reserves of that token and then when you called the uh the get amount out function it ended up giving you the entire liquidity that you had for the second token uh so at this point we've already broken the variant and that's what the tool tells us the tool tells us that we've reached a state where uh where there is uh we have uh uh one of the results has gone down to zero when the uh total supply of liquidity pool tokens is still non-zero one of the results is going down to zero so uh this has told us that uh that that intuitive sort of a property that we had thought of in the beginning that if there are liquidity pool tokens in circulation then there shouldn't be a case where you uh where you can get to a state where one of the reserves or both of the reserves are drained to zero but that's fairly possible but now the question is how do uh how can someone exploit this weakness of the code and uh we looked into that and uh the attack basically is that uh you take a flash loan uh to inflate you take a flash loan send that money over to this contract and in the process you end up inflating the balance of the that token in the contract uh the way this contract keeps a track of total reserves uh versus the total balances is that there's a function called update that's called um you should see that function yeah for instance here so uh every time it's messing with the results of the contract uh after it's done messing around with it it will check what the latest balance is and then update the results accordingly the same thing happens in the mint uh function when when you've added more liquidity to the pool and it's given you some liquidity tokens uh at the end of it it'll make sure that that newly added liquidity is also captured in the reserves that the contract is tracking so uh so if you uh take a flash loan send that money over to this contract uh and jack up the the balance for one of the tokens but you don't end up calling the mint contract then what you've done is that the the reserve continues to be what it was but the balance is uh inflated Way Beyond uh the reserve value at this point if you uh using your tiny share the limited number of LP tokens that you have if you call the burn single function you will be capable of uh your your essentially your share gets inflated so uh what happens is uh all these numbers get calculated against uh these numbers they get calculated against an inflation an inferiorate balance number so for the same small share you're getting a much bigger number and if you manage things such that this big number is exactly equal to the reserve value at that time then you can make the get amount out function to give you the entire liquidity of the the other token and once you've done that the next step of the attack is that you call the swap function here and the swap function will uh again this time you reverse it this time you give it to the other token with one with which is which is one amount and uh it will again because one of the liquidity pools has been drained the token B has been drained so this time around because that was zero in the computation it will give you the entire liquidity for token a so uh what you've done essentially is you've drained the entire liquidity uh for both token a and token B there are still LP tokens in circulation and uh there are no reserves to back it so uh so our tool told us that it's possible with the get uh get single function it's possible to get into a state where you break the invariant and then looking at that example and thinking a bit more on how to make it a complete exploit we figure out uh this uh this this overall larger exploit so uh that's uh so it should give you some sense of how powerful the tool is because you've not even you've not even had to look at the implementation of the protocol you've just from a liquidity provider standpoint thought of the very basic thing that the protocol should give you in terms of security and that is the ability to withdraw your liquidity at any point of time and just just put that down into a simple logical formula and done that against the tool and the code and you get this invariant uh the tool obviously is uh much more Dynamic while the strongest properties that you can verify with the tool are invariants which are as simple as this one because they cover a large part of the code uh an invariant like this as broad as this can break because of any small functionality any small function in the code uh so you're not you're not restricting your checking to any specific part of the code but you're looking at the entire uh contract uh so these are the strongest invariants if you could think of high level invariance like this which pertain to any part of the contract uh they'll always give you the best results but the tool also allows you to write more specific rules we have something known as yeah so you can write rules rules are essentially uh a combination of a pre-state some function execution a post State and then an assertion on based on the state transition that might have happened you can write rules for specific functions uh you call specific functions then track what happened in the state change and assert the change that should have happened and see if see if the contract breaks out of that rule in any case you can write more general rules where you can have so what we call parametric rules these rules are run against every function in the contract so you write some preconditions about the state before then any function here so this this call basically means that the tool will call every single function in the contract with any arbitrary arguments so this call data args is is a dynamic data field which the tool populates with all possible ways in all possible ways and uh so to fit all possible function signatures and it gives you complete coverage in terms of the inputs that you can feed into these function calls and then it checks the state after that and any assertions that come after that so you can use some parts of the some aspects of the tool to write even very specific unit tests for small functions so like as muli mentioned that sometimes the code I mean this tool is bound to fail it's only a matter of how complex the code is and when we encounter very complex codes sometimes we have to take a more modular approach which involves uh you know looking at the most bottom level contracts looking at individual functions in those contracts verifying the functionality of those contracts and once you're very sure that those functions work exactly the way they're supposed to work then we summarize those functions and we assume that they work correctly for the more higher level contracts so that sort of eases the job that the approver has when it comes to verifying the more higher level contracts uh yeah so you can write rules very specific to certain functions you can write more generic parametric rules to test out function execution or you can write very high level properties using invariants and the tool will tell you if your code is capable of breaking out of it so yeah that's what I had any questions what's that uh the tool is free movie has said this many times but uh let me say this again go to the demo page uh work with this as much as you like it's free you can plug in your own code here your own spec here we have tutorials free tutorials on GitHub please learn uh I'm very new to it as I went through securium I learned the tool in a matter of two two weeks and then used it on a project uh it's very easy we have a very strong Community Support uh internally in sartora we give a lot of importance to that so if you're curious if you want to learn the tool our language CVL is very similar to solidity so if you're familiar with that it should be very easy for you to learn approva and uh yeah I use as much as you like it's free and get more used to it and talk to us if you're interested in working more with us anything else moving yeah good um no no we are you asking if we work with multiple contracts huh yeah so uh these properties they don't necessarily have to be from one contract uh like if you have one higher level contract and that contract interacts with multiple lower level contracts which then again go and interact with other lower level contracts these properties will be verified on the system as a whole so the invariant is checking every function that it gets from the high level contracts all the way down to the lower level contracts unless you apply some sort of function filter that's again again another feature that we have but yeah it's it runs across the board and when it runs on higher level contracts there are advances to how the tool models that interaction that enter contract function calls if you like it can make it uh it can assume the worst case scenario assume the the most arbitrary Behavior coming back from that external function call or you can if you have specific implementations that you want the tool to work with you can link specific specific implementations or you can uh we have something called dispatcher which again it has adds more advances as to how these calls are routed but yeah our philosophy is that we want to be extra careful so we we always over approximate when in doubt we over approximate so if you don't specify any particular implementation or if there are multiple implementations but you don't tell the tool how to use those implementations the tool will go ahead and assume the worst case scenario that this call could return anything though so it will do all that heavy lifting of checking all possible scenarios there but if you're very sure of the nature of that interaction the implementation on the other side then you can make life easier for the tool by giving it the exact implementation so again the tool is bound to fail if the code is complex enough and if these interactions happen with a lot of what we call havoc in Havoc essentially assuming that you know here uh so if you give it a lot of high-working chances are it will fail but uh yeah I mean the the art is in finding that balance how do you get this very powerful tool to work uh for your project uh like uh the tool can sometimes uh time out so before writing rules specification yeah do we get a sense that this particular rule will time out or like after running the two loan so usually what we do is uh before starting on a project we do something known as a sanity check sanity check is a very simple rule which says that this is the function it's so it's a parametric call if you remember seeing the parameter call where we just call do an F args call which is a call to every single function in the every single external function uh in the contract and all the contracts in the in the scene actually and uh and we just call the function and do an assert false so an assert false is bound to fail as long as the proa gets to that point but if uh your the code that you're trying to verify is extremely complex so complex that the tool is not able to get to that point but it's just too caught up in all the execution and all the branches and all the loops that are happening in the functions then it will never get to the assertion and it will timeout before that in that case your rule will pass because you never got to the assertion and the default I said passes or it times out if you do a sanity check then it times out so uh the first thing that we do with any complex project not just complex any any project unless it's uh just one single uh solidity file and it's very obvious that it's a very simple thing which which is the Rarity we I mean I've never seen a such a project in my time Etc but uh yeah the first thing we do is to do a sanity check which gives us an idea of which functions are passing which me which tells you which functions are easy and which functions are failing or rather timing out which tells you that it's too complex so it gives us a sense of uh where we need to optimize things and how how do you need to break it up aliens ask away guys are you guys curious about Satora do you want to work with it yeah yeah hello yeah if we complete all the challenges whatever you're given uh like can we become our official formal verification engineer or something like when yeah uh I think Molly would be the right person to answer that so yeah we partner with communities like that and we pay uh people in the community who write rules using our Tool uh write roles and verify code using our rules he's interested to know if um yeah obviously yeah all the challenges and everything like will I officially become a formal verification engineer like a certification I don't know if you do that but but that's not the point of these challenges these challenges are to get you a sense of how the tool works yeah so we have engagement which is a career we have engagement with the program right is that the question of how to study is that what you're asking so wherever engagement I think there is online there's an online uh so satura has collaborated with like Alex said coming online communities and one of them is securium and securium is an online community of ethereum security smart contract security focused interested you know aspirational experts the whole thing right so the collaboration in this particular case was um really to learn I mean sartora had a workshop that goes deeper than these challenges I think Alex Point here was these challenges are really for educational purposes right they don't lead to a certification but sartora has collaborated with securium and our way as well where you know once you learn the tool right you can apply it on the code base that is within the scope and the top performers are given uh I think there were certifications as well I'm not sure but securium has issued nfts that show that hey you have uh you know you've got this uh sartora knowledge and expertise right and there have been monetary Financial incentives as well foreign guys come talk to us if you want to know more [Applause] shall we start also Kevin can I start okay uh hey good afternoon friends two minutes hmm one two three foreign hello good afternoon friends uh uh so I'm here uh quite excited to give a talk uh so I would be talking about a technology right or something that that we use in our everyday life uh but something that we don't talk about much and it is something that we require as a human to build connection with other humans out there uh so that's called real-time communication technology right it's a part of our daily life uh so during our prehistic time what used to happen was that it was the communication that helped us coordinate to each other and when we were able to coordinate we were able to increase our survival chances and we were also able to bring more food to our table and distribute it much more better this is also the core reason one of the major factor of the evolution of ours we also know that the money and the crypto that we know is basically a tool a tool to capture the value and this value comes from the consensus which is basically people coming over an agreement a group of people coming over and argument this makes real-time communication technology much more critical than ever right now if we see in our web to World there are a lot of applications like Facebook Instagram Tick Tock Twitter all of them combined the social media combined there are 4.48 billion active users social media user and if you compare them to web3 there are only 84 million active wallet users and these are basically combined with centralized exchanges also addresses also and the decentralized exchanges also so you can see the ratio like we are still a lot of problems the social app that has to be solved the web 3 adoption is still an unsolved problem now now to get this real-time communication basically how do we bring it over the internet right so real-time communication is basically many to many audio video data transferred synchronized at sublatency second but like the current protocol that we have which is like HTTP TCP UDP uh they are not optimized to do so because many of them operates on request response mechanism and all of those things so there was a protocol there is a protocol called webrtc that is actually used to give this RTC functionality in the today's world but there are a lot of problems with the webrtc because it was not designed to scale out there and actually this led to a lot of problems out there uh if you see this led to like the custom servers to scale out there and since it requires custom servers so what happened was that the corporate started accumulating those servers out there and even on the P2P level you required this centralized signaling mechanism to actually establish those calls out there which is the problem now this what's happened with this is that basically the user's data goes to a server which is practically a black box so you don't know what's happening with your data you don't know what's happening with your privacy uh out there and also you'd never know like if it's the best performance that they are getting uh out of the box and on top of it the users are actually exposed to rent extractor mechanisms and even the vendor lock-in systems out there and there are a lot of other problems but if we go into that I think this we can go so now we have drtc like uh uh this is something that we were actually working on at huddle uh so huddle is not just a normal audio video conference it's incubating this RTC infrastructure of the future it's called Uh decentralized real-time communication infrastructure uh so what is it uh I will give you a visualization so basically like how polygon and other are like basically the scalability solutions for layer ones the drtc is this real-time communication layer for l1s out there and what this would enable is that now you can see this web3 social kind of uh dabs dabs which required this uh live streaming which required this audio video calls or which requires their avatars to chat with each other at real time those can be possible uh with these things now at huddle what we did was that basically uh to get this real-time infrastructure up and started we took this product first approach and with this product first approach you can actually boots boot start this RTC infrastructure layer out there so yeah how did we basically and another thing that uh point to note is that uh what you see is that uh the token uh like what happens in generally the web world is that people make token and they dump the token on the community itself uh the other thing is that like they make the technology and then they dump the technology on the users itself it's the same thing right but what we need to do is that we need to make a product and we need to make that product valuable and then once that is valuable we need to distribute that value to the users and the community now once we are able to distribute wealth uh there is higher development among that community members out there so yeah at title what we are able to do is that within a single click you can see you can access all of the best of web3 uh like you can live stream you can record you can have your ens team you have can have a Unstoppable name and lens protocol out there you can even live stream to YouTube twitch everything out there all at a single click so we are also be able to bring this experience to your web application and to the mobile applications also and these are live you can just check it out from your app store and Play Store and start playing around with it so all of this infrastructure is actually powered by a media infrastructure uh this media infrastructure if you see talks directly to the filecoin network to store on ipfs and filecoin uh it it has it live streams to live here protocol uh to live stream which is basically one-to-many uh broadcasting scene and it has this media routers uh which is made on open source libraries but on top of this media servers there are custom algorithms that we have written such as last and such as dominant speaker identification codec optimization and all of those things so this makes uh the infrastructure much more robust and this is a sufficiently decentralized architecture as of now now if you see like we have spent like a year or two year uh making this uh architecture much more robust and all of those things but what we don't want is that the developers out there to go into that same Rabbit Hole so what we did is that we packaged all of this infrastructure into our sdks Now using our sdks you can have the same capacity that the huddles app has so it's basically you can Fork the hurdle application and make it on your own you can just white label it and you can make other kind of application uh you can make Twitter spaces you can make forecaster spaces you can make a lens lens calling one to one all of them you can also make like a wallet address which is calling other wallet addresses out there and it opens like a huge door out there if you're building a metaverse in the metaverse like the avatars need to chat with the other avatars so here is where you can use the huddle sdks out there and there are other things also like the imagination can go while wherever you require this real-time communication infrastructure you can just plug in the hurdle sdks and get that up and rolling uh these are load aware reason aware globally distributed server and uh I would also like to take you the quality uh that we have actually what the Huddle uh this infrastructure is capable of first is quality uh so we can see like it does 1080P and higher quality out there so it's much better for the screen share we have been able to minimize the packet loss there's less data buffer uh this Dynamic bandwidth uh adaptation and all of this thing we are trying to do in less than 100 millisecond because uh that's the best VC experience that we get when we are doing this 100 milliseconds uh so yes we are end-to-end encrypted also uh so if you can see uh there is the call going on so this is a version that a user sees on the left side and uh the other version is what's if the hacker breaks down into the media infrastructure that is what he sees it's an end-to-end encryption call and even this is how Huddle's media infrastructure actually sees so your data is actually secured uh out there even like the Huddle servers cannot see uh other routers they cannot see the data that you are doing they can only process the meeting at a super high quality out there scalability so these end-to-end calls we were able to scale to up to 30 people out there and here you can see it live out there we were further activating the last 10 algorithm this helped us scale to more than 400 people out there and this is basically the robust infrastructure that we have got and further going on we have also can be horizontal scale so which means such meetings can happen parallely out there so can handle any amount of skill there so the progressive roadmap uh so what we believe is that uh the decentralization is not a switch which can be like zero and one it's Progressive in nature uh so huddle was born in eighth Global hack FS uh 2019 which was sponsored by the file coin and protocol lab we went into techon accelerator and we have which and this is the current product that we have right now uh so the drtc we talked about is the basically the phase two part of plans and there is an Afra crypto economics uh which is our phase three part of plan and they both would be working parallelly uh so drtc is basically uh this will make the all the central component into this nodes architecture and the afro crypto economics would be basically this incentive mechanism for all the apps to work together what we will realize end of the day where we actually want to get to is basically an open neutral borderless decentralized sensitive private assistant government Community online government real-time communication infrastructure yes uh so would love to share some of the learnings that we had while building huddle uh so in in hack FS we actually made it as a P2P mesh but we realized that there's a lot of problems with this approach uh so the P2P mess was not scalable for after four people like the experience on the user and was not something that can go as a product itself there's a lot of less security because if in in P2P mess if any one of the peer is malicious the whole thing gets compromised uh the data position you cannot persist the data in this typical fashion out there uh this is the whole reason like the ipfs actually made the file coin which is basically the same ipfs mechanism with an incentive layer out there uh and the other problem is that in this p2b mesh the other peers can send the malicious or illegal files to other peers because if they are contributing to the network so again that's a problem and we cannot always rely on p2bms because they might be available or they might not be available so they are highly unreliable what we can do is basically convert this p2b mesh to peer to node to node architecture once we are able to do so what we can do is that these nodes can become uh have this macro level feedback uh and wherein this macro properties can be decentralized and they have this uh consensus algorithm taking care of all the micro level competition that is going on so this is like a individual node which are optimizing their self game but they're competing with each other but on the overall macro level they're collaborating with each other uh so this makes it very highly scalable out there and you can always have this security and slicing algorithm this maintains the quality of service that network has and even the security uh so I have for crypto economics uh so this is something uh a network flywheel uh many people ask me a question that how the value approval would happen on the token itself so if you can see there are end users like and there is a Community Network effect starts to happen once that's happened your volume of RTC means starts to rise and once that starts to write what happened is that people start building application on top of the Huddle infrastructure or or the RTC infrastructure out there this makes your volume of RTC transaction rise and once that's rise you're basically the token value starts to raise and investor generally sees wants an upside exposure to any value that is going up so they put in the financial Capital once there is like a financial capital and the token has this both monetary value uh the people start to put forward their computational and bandwidth Capital the Huddle nodes the nodes provider and in return they get the token itself so you can see on a global level like the people are putting in more notes so what happens is that the quality increases the security increases and the pricing goes down and the scalability increases with the more the nodes that get acted out there the app for crypto economics uh so in the recent like what used to happen was that the incentive layer was only on the infrastructure layer but on the application layer the only incentives you have is basically bounties uh or some other forms of making people to make the apps out there I think we can have a protocol that can work that has this both in central air on the application layer and this has this incentive layer on the infrastructure layer and there is a dynamic between two uh that collaborately makes the whole ecosystem grow yes uh so would also love to take you to the medical fellows and social network Theory because real-time communication has this uh value in uh social network out there so metcalfilos states that that in a telecommunication Network the value of that system Grows by n square if another node comes into the picture out there so here you can see in the graph basically like first it's like one or two user but as as the node starts to increase the value of the whole network start to increase and the whole of the value can be captured into this crypto economics uh out there uh so the perfect example of explaining the Metcalfe law is that suppose you have a mobile right uh so in this mobile if other person has mobile the mobile this mobile gains value right and uh so if you're the more the number of people you are able to call within this with this mobile the more value that the mobile the whole network acts so for end users the value increases if number of people and the nodes into that infrastructure start to increase and this is like a what what the Met Cafe and The Social Network Theory actually summarize the and this is how actually the networks like Network effects product like uh Facebook Instagram and all of those things are actually validated on the network effects again uh so zoomware was able to overtake Skype because what they enabled was that uh so Zoom only you had to have this email ID to get to a Skype call but what Zoom did was that even without his email ID you can do a Skype you can do a zoom call so this led to more Network effects out there uh but at huddle what we are doing is that you can have this like non-zoom account and you can also bring in this crypto Primitives out there which is on the rise and this is again leads to this network effects out there yes uh so again uh I would highlight some of the problems in the webrtcs out there uh for a webrtc to take there's like a fourth thing that goes on one is uh first step is signaling uh other step is like you need to connect the secure out there first a signaling then is connecting then it's securing that uh whole infrastructure and then you start communicating out there uh but there for signaling you need to have this servers out there which are centralized in nature uh so again so in this if you can see like the signaling is centralized uh but if you can convert this servers into a nodes and these can be like multiple nodes which are like chatting with each other so your sdps can you can now send to this node and these nodes can gossip around this sdp and whichever Piers required that STP it can subscribe to that sdps out there so this is how you can like remove the single point of failure out there now we have realized that like you can you can use this not just for like putting out the sdps you can use it for both synchronous communication and you can use it for asynchronous communication right uh so what is synchronous communication uh so if you had used slack right they just slack button out there so it is like many people coming at call at that point of time so Zoom meeting is a synchronous out there but Discord and slack their asynchronous communication so with this mechanism of Divergent right wherein your Divergent node wherein you can use this infrastructure for signaling to for the to attain the async communication and simultaneously you can use in infrastructure to have this this async communication capacities out there so again what we did was that uh this is the end-to-end encryption that we had solved uh out there it used NaCl algorithms out there from the private public keys of the user itself so even this signaling mechanism is end-to-end encrypted and yes so we have packaged this Divergent node into the Divergent sdks now you can see that this is a WhatsApp clone made on a lens protocol and you can see a starter hurdle that uses huddles media infrastructures huddles sdks and all the chat sdks is like the Divergent sdks out there so you can see we have achieved both asynchronous capacity of communication and the synchronous capacity of communication and developers can have this imagination and can build this any kind of applications out there and the dids that is is basically a lens protocol out there yes uh uh so like now coming back to drtc like what is actually a drtc infrastructure so if you see like UPI right the UPI is a fintech infrastructure wherein this bmap phone pay app and Google pay app was made uh similarly this drtc layer is like enables this web is the spine of this web3 social app upcoming web social app so now you can have this decentralized Tick Tock you can have this decentralized Twitter uh and you can have uh another kind of New Primitives app which I think would be possible which is like the social app and the financial merger kind of apps out there because think of like a social a Twitter leveraging the defi infrastructure out there and this could this can blow up like uh we just need to like productize that very well out there but to start for the start I think the cloning of the existing webproof infrastructure would start to happen like a clone of disco a clone of WhatsApp clone of Twitter clone of LinkedIn they would start to happen and they would require this synchronous capacity and asynchronous capacity also and even in the meta was like in the metaverse like all the nfts they have these games right the MMORPG system the massive multiplayer online system all of this requires this real-time infrastructure yep uh so the huddles infrastructure is already powering lot of other applications out there so this is the whole ecosystem that huddle is actually powering so there's like schedulers there's accelerators there's like metaverse spaces there is messagings there's web 3 attack there's wallets nft communities social and I think this is a blank canvas which is like yet to be filled by other entrepreneurs and other people making new Innovations out there yep thank you uh this is swashmit and this is my barcode if someone wants to follow yep thank you 