[Music] [Applause] [Music] um so our next speaker is and we will be talking about blockchain data storage using what three stores in nft that store it so without further ado let's uh let's see how we can make an empty story welcome it's good to be here thanks all right i'll share my screen here cool so i am yusuf i work at protocol labs where we make ipfs and filecoin those are two really interesting bits of technology that we think can help everybody in this or decentralized app ecosystem take advantage of this vast network of storage that's now available so let me sort of get into the mix here so this is kind of a mashup of two talks about web 3.storage and nft storage and these are both services that we've built to make using ipfs and filecoin really easy and accessible for especially for web 2 developers or really anybody that wants like sort of friction a low friction path into this uh storage network so uh first i want to talk a little bit about nfts so we became really interested in nfts um you know we have been for a while but obviously this year these sort of take off in the public consciousness and that's when i personally started getting into them um i was like loosely aware of them before that but basically it was really like encouraging for us to see that ipfs was being used to store lots of nfts um and we think it's a really great fit for this kind of application because first of all like storing data on most blockchains is prohibitedly expensive and therefore to have an nft that represents something outside of itself which is the case for many there needs to be a link between the nft and data that lives off chain and we ipfs has some really great properties for that for creating that kind of link so we'll go into that in a little bit um but we started to you know realize that the developers uh that like openc and foundation and zora and so on they really care they care about users being able to access the data should they ever disappear and this is sort of a common thread in these kind of circles is that like nobody wants to trust any individual party to stick around forever but we combine you know if we all like play well together we can hopefully design a system that outlives any of us individually right and that's uh and it's good for for us to kind of build systems with that in mind even though hopefully of course we'll be around for a while um but again it's something that users care about because especially like they became aware that the thing that they're or i don't know maybe people are already aware of this but i think that people that are new to nfts don't always understand like what specifically lives on the blockchain and what lives elsewhere and like what's that relationship so there's like an educational piece to that that we've been involved in trying to kind of clue people into what you know what is that link and what's this strong way to make that link so the ipfs fitness um and if you're new to ipfs it is the interplanetary file system uh it's been around for several years and the gist of it is basically that you first you put your data onto an ipfs node and that node participates in this big peer-to-peer content sharing network where basically if somebody wants a piece of content they'll ask for it and if i have it i'll provide it and everybody does this and it's actually a pretty efficient way to distribute data across the network in many ways but first so anyway first you put your data into the ipvs node and you get back this string that content id and it is a cryptographic hash by default it's shot to 256 but there you can use lots of different hash functions and all the rest it's a very customizable piece of software but the the fundamental point is that this cid will always identify one specific piece of content and any changes to the content would produce a different cid so given a cid you can say hey network please give me this data and when it comes back from anybody you can always verify that it's correct because you can compare it against the cid that you use to retrieve it so this means that you don't need to really care who is providing the data or where they come from or you know anything you don't need to know anything about them as long as the protocol works as long as somebody has the data and they see your request they can provide it and you'll you'll get it and it's a pretty cool feature for linking to things uh which we'll get into in just a second but so here's the the requesting process so they request the data by the cid original node responds and now they both have a copy and if the third node comes along asking for it both of them can respond in parallel and say oh i have it uh here's a few pieces guy on the left gives a few pieces guy on the right gives a few pieces and now you get the file potentially faster than you could downloading the whole thing from one but there's lots of variables there with respect to latency and so on so it's really hard to make like absolute claims about performance characteristics versus other systems but in general there's potential for efficiency there um so yeah now this third node has it and as a result they can also participate in the providing process uh and that's great the original node go away but the content is still there and so we've kind of gotten close to this um dream of content outliving us and our you know organizational guidance and so on um the data is still retrievable from other nodes and you know that's kind of the power of peer-to-peer networking like that no individual peer is you know blessed or special um but there's some caveats to this approach with ipfs uh if all the nodes that have the content disappear from the network then there's nobody there to provide it uh there's it's like an active process where your node needs to be online in order to respond to requests and if no node is online with that content it's just not resolvable although i should mention that the same is basically true of yeah http servers like facebook.com or suddenly to be unresolvable then nobody could access it but with the um with ipfs you have kind of an interesting property where if anybody later adds the same content to the network provided they use the same hashing algorithm and everything um then they'll come up with the same cid and any links to that original content will be resolvable so it's i i guess like a third party can sort of fix a broken link in a way that they can't with http so that's kind of neat but the the second caveat is that there is an automatic garbage collection process for these ephemeral copies that get made as content propagates throughout the network each node will keep a little copy for a minute but eventually they might get this pressure and we'll have to clean up and throw stuff away so to prevent that there's a thing called pinning which is just signaling to your ipfs node please keep this alive um yeah don't garbage collect your stuff and um this has been one of the the main ways for people to practically speak and get their data into ipfs and made accessible is to use a pinning service that will provide this data for you on your behalf so you don't have to run your own infrastructure and so on and you know as we were looking at the nft space and thinking it was like what can we contribute we saw well we can make this process um a little easier for people by basically more or less becoming a pinning service but doing so using um so the some of our other technology namely file coin which we'll talk about in just a sec so the way we present this is as nft.storage this is a website it is free to use you log in you get an api token and then you can upload your stuff through us and where we provide it on ipfs and also um for long term storage it's looking to file coin so the way this works is yeah you take your nft it's a very simple um upload interface it's just an http request there's some there's a few different variations on that depending on what your needs are um and which endpoint you might want to use but then anyway we get your data through some requests and then nfc storage is going to store it on an ipfs cluster that we manage and then uh we're also we also redundantly store it with a third-party provider just for safekeeping and behind the scenes though we are also negotiating deals with file coin storage providers to store data for the long term and they are actually getting paid by the network in the form of block rewards which is kind of an interesting uh sort of economic angle that we can talk about in a second but the for now like the advantage of filecoin is that it fits this property of like allowing members of the network to disappear but still giving you some solid assurances about your data so now all if any if nft storage were to go away completely and all the ipfs nodes that we manage or that other people run lost all the content the data is still just there on filecoin being continually challenged by the protocol to like prove its existence so that's basically if you had like in the worst case scenario where we just fold up shop completely and can't pay the bills anymore um everybody has this sort of you know public verifiable escape hatch as it were where and just like or a seed vault maybe is another way to think of it where like the data is preserved and it's it's just right there and we provide all the information for retrieving it in our api and stuff so um yeah to use it you go to nft.storage which is a top-level domain now so that's cool and uh it's it's really simple and free um and you should check that check it out it's a very it's this is the http api that's not very big um the uh the main endpoint is this upload endpoint for storing things but there's also um you know stuff for retrieving status information about your upload just you know who is storing it on filecoin and ipfs and so and so on so you can kind of get that granular information if you need it and if you're in javascript we have this javascript client that makes it makes things a little simpler and will help you format data according to erc 1155 standards so if you are um building an escalating 55 contract or one that you know can be compatible with one with that use this client.story method and what uh it will do some nice stuff for you basically you can give it a file object and it will add the file to ipfs and create a hash link for you and your metadata json and then also it wraps the whole thing up into this um thing called a dag sebor graph uh it's not super important what dax evor is but it's basically a compact binary json object but it's it's a nice way of addressing hash link data that we like to play with it's part of the ipld project if you're interested um so i'm going to quickly just show you guys how to use energy storage and then we can talk a little bit about our other storage service so here's the site itself and you log in with github or email it will send you a magic link to click on if i log into my profile you'll see a few things i've stored mostly just testing things out and so on and we can go here and poke out a little bit and get an api token that we can authenticate with i should also uh mention that my home internet is very slow so things that are slow for me may not be slow for you when you're using them so especially when i'm uploading things it's kind of sad but anyway so here we are at the api keys and i made this one a few minutes ago you can make and delete them here and there's my key for later i'll probably come back here and i'm gonna i've got an empty project and or just a default over here with some images that maybe we could store on any storage and let's make an npm project to write some code so if i do npm in it and i'm just going to accept all the defaults now i have a package.json file and i can say npm install nft.storage that gets me the javascript client library um yeah i'm also going to pull in a couple other libraries once this is done to make you know building a simple little example app easier so minimist is a for pulling out command line arguments kind of nice and then mime types for figuring out what kind of file you've got because the store function kind of likes you to provide it with a mime type and this this method that formats according to erc1155 expects it to be an image file type when you provided the image field well you can actually give it an mp4 now for compatibility with platforms that use videos in the image field um so anyway we have now installed some dependencies and head over to an editor and make ourselves a file i'll call this index.mjs something that's relatively new in nodeland is if you name your file with a mjs extension or if you put a module in your package.json you can use import syntax import nft storage from nft storage i'll also pull in the file object since the the api uses the file object that you would see in a web browser context and then it provides an implementation for node if you're working on node.js so i can import that here and then in order to read the file from my local disk i'll import node's fs module so import fs from fs slash promises i can use the async await and pull in minimist so that we installed earlier and my pipes so that's all the stuff we'll need in a second and let's do a function for storing an nft so let's just call it async function store nft and it'll take a image file name and then see maybe the name and description metadata uh we'll tag our nft with this description so to do this we're going to make an nft storage client and for that we'll need a token which i'm going to be a naughty boy and hard code into my source code but yeah and obviously this is actually an area that we'll be improving upon very shortly like right um right now the best practice for protecting your api token for entity storage is probably to protect to have it uh interact with them to use support from the backend service since bundling it into a fairly decentralized app front end would expose it to the client but we're working on solutions for that which would involve direct authentication through a wallet and using decentralized identity and also sort of user scope tokens so that you can manage the authorization on your users we have i'm mentioning this because it's just a common issue that we are heads down working on so stay tuned uh in the meantime i'm gonna grab a token from here and paste it in here so i got that and now i can make a client so i'll say const uh client there's new nft storage and you give it a token argument and uh i can do stuff with it but first i'll need to read my file in so i can say file data equals fs.read file i'm sorry i need to await this it's async and image file name and type is going to be mime dot lookup image file name because it just pulls the file type from the file extension it's not super fancy and then we're going to say okay i have the data and the file types and i can make a file a new file object that takes an array of blob parts which is basically just you know things that can be turned into binary data so for uh just stuff we slurped up from our image file name here will fit that just fine um actually uh uh let's see let me quickly make this bigger so everybody okay this is a little easier to read there we go so i'm making a new file and i'm giving the file data the file name um we'll trim that down to just be the last part of the file path so import voice name now you can say this is image file name okay and then the last part of the file constructor is the optional arguments where you can pass in the mime type so we looked that up earlier and now we can pass it in and now we have a file object that i can i'm going to call this image right because that's what the store method expects image now this is a proper file that we can hand off to the client so now i'm going to say i'm just gonna return client dot store image name description uh and there's a few other you can add optional properties to you know if you have if you want to have properties with any key value stuff you want in there for a custom use case which if you are doing the the erc1155 we do recommend like sticking custom properties and properties if you can just because it makes it easier we're trying to beat the drum of standardization a little bit um having been on the receiving end we're also um you know scraping ethereum chains and finding all kinds of entities in the wild to kind of see what people are doing there's a lot of interesting metadata variations out there but at any rate um now we have this and we can say we can call it so let's make up a main function and and this is where we can grab our uh command line args that's right we don't need this complete didn't even dirty all right so and for this you pass in the process argument so process.rtv pull off the first two for node reasons and now um minimus is kind of simple it's just like it takes whatever arguments it gets and parses them out and gives you a dictionary or a js object runner so now i'm going to just assert that you gave me the right stuff so um there's nothing we want there to be an image a name and a description so if there's no image complain this may be a little fussy for live coding but still i mean error handling is important we'll let the description be optional i guess that's what i would say just pull them out of this object and i'll and then pass them to the store ft function the image here's the image file name and we can just toss that over here and say metadata equals await app store nft and then give it the image file name name and description and now let's log it to the console see what happens so all right so now if i call the main function we should be able to call this thing as a node script and see what we see so let's see here we go uh if i do node index jf and it's a dash dash image and i can give it images and name etc and yeah i probably should have added a little console log saying hey we're doing a thing now but there it goes uh it's already done so it so what happens with the result you get back at this is um you have an ipfest url which is in the ipfs colon slash format if you want you can pretty easily turn this into a http gateway url so um this part here is the cid and then there's a file path so if i wanted to make a gateway url out of this i can say cid ah sorry um copying things accidentally cid dot ipfs.dweb.link there's lots of other gateways but that's the one that sticks in my head and then um then add the file path at the end so i'll show you what that looks like real quick uh i do cid.ipfs.uweb.link metadata.json yeah i spelled it wrong the metadata yeah so because um yeah there's basically a little a bundle it makes a little graph structure for you and then um you can traverse that graph using this pathing syntax whatever but basically it's just yeah yeah there we go there's there's the metadata that we stored and you can see here if that's big enough that this is the image field has this same ipfs ipfs.com reference to the image itself so you can make another gateway link and pull it out i uh did you have brave installed it'll follow these links automatically but i for some reason didn't think to use it uh for this demo oh well um so that will chase up the image itself um and so and if you want a sort of machine readable uh or traversable form of this uh without having to parse links and so on that wrapper object like the root object of this graph where if you just have the cid uh without the metadata.json it's actually a with that dagsebor thing i was talking about earlier where you can fetch this object and then use our ipld tooling to traverse into the metadata and find the image itself and sort of all bundled into this graph so i'm not sure why this is taking so long to resolve but i i blame my terrible internet i did so we'll see uh anyway let's maybe take a break from all this stuff and uh we'll talk about web 3.storage we'll come back and hopefully it will have loaded by that all right so oh there's something i want to mention before we get on to web forge which is um that we have uh this thing called there's a format called the car which is a content archive and you can send us content archives uh and if you want to pre-format your ipfs data like you have specific layout that you want or also um if you want to send big files over 100 megabytes i should mention too that we're going to be doing this for you automatically soon so uh you may not have to do it yourself but it's kind of nice to understand what's going on behind under the scene so you have a mental model uh what's working so the advantage of using a car is that you can know the cid before you upload it's not waiting on our server to tell you what the identifier is and you can verify that it's correct that we're like storing exactly what you know you're giving us and like i said it's chunkable and it has this you can split the cars into chunks here so i have one big graph uh and i can split it into little graphs that all have the same roots and our back end will piece them all together for you and yeah that's pretty cool so i'll talk a little bit more about cars in a second because we have this other service and i'm just quickly running low on time so i should get into the weeds of web3 storage it works very much like nft storage especially under the hood they're very very similar and it's so if you remember this slide from before it's the same thing but for non-nft data so it's it essentially any data that you have that you want to be stored on ipfs and filecoin you can just upload through it throughout storage and we will store it for you um and it has the cars baked in so uh and this will be coming to nft storage soon but right now web3 storage has it already in the javascript client where essentially you give it a file of any size and it will create the car file for you and do the chunking and send everything off and it gives you access to the root cid as soon as we compute it on the client so you can display in your ui and say oh here's the thing now in parallel send it off to web3 storage and it'll get stored for you and you get progress call backs and stuff like that very briefly here's kind of where the architecture looks i'm not going to talk a bunch about it but there's some cloud workers we maintain some state in a database but then the interesting bit is the storage broker service it will take your data and batch it up into usually i think we usually do 32 gigabyte chunks um and store those each with a file coin provider since that's the most efficient format for getting data directly into a file coin sort of pipeline um and then but parallel to that we've already added it to our ipfs cluster and to redundant pin you have a cluster so it's available for retrieval pretty much as soon as you upload um but then there's maybe i think we're at like 18 hours now in terms of delay for getting it on to file coin right i'm sorry i might actually be eight but i have to actually ask people what the real number is sorry but it is a few hours because we have um we have this aggregation process going on um and but as a result of this by by meeting the miners where they are sorry the storage provider says that they're recalling we um we are able to offer this service for free so here's uh something that comes up a lot when we talk about the service is like how is this free and it basically is because um the primary economic driver for file coin providers right now is block rewards so they get rewarded first for committing capacity to the network so if you bring drives online uh onto the network and prove that you've done so then you get potential block rewards relative to your overall storage power the capacity that you're that you're adding but um if you are storing real data boom you get a 10x multiplier basically it it and and the way that this works is that there's a a system called filecoin plus in which a notary allocates this resource called datacap and datacap essentially is it's more it's sort of like a voucher that says like we we believe this is real data and not just some random you know garbage that somebody uh generated to pump up their numbers i guess um so the idea is that by flowing your data through web3 storage and nft storage like we have a reasonable assurance that you're a real person or that there's a real like sort of social need behind the data and that's kind of what we're getting at because like fundamentally our mission is data preservation and all that so anyway verified data increases the chance of block rewards by 10x and so as a result it's the actual cost of like storing the data and there's some collateral that the providers put up front to you know ensure that they're going to store it that is all basically um kind of negligible compared to the increased reward so it works out for them to provide long-term storage for free and so we're not charging users anything for storage as well um there's a minimal operational cost to us to keep the ipfs side of things you know running but that's in the grand scheme not a big deal and we're super you know into providing it to make things easier for people so that's that's what i got well thanks very much and if anybody has questions please let me know so that was awesome um so nice recovery i feel like we're going to go over time but this worked out yeah yeah totally folded in um i think uh two kind of common questions um winning accurately address which was the nuance between web3 and nfc does storage uh just the formatting and the car archive formats a common question that i think we get especially during the hackathon is what are some best practices that you recommend when people want to think about storing metadata or even updating it like how do we think about that and how does nft storage kind of come in handy for these types of things um and i want to question into uh how do you actually what's next after this like you are is this done like is this a great service you're offering it it works like how do you actually improve this thing or what are future features um actually i mean so there are some reliability things that we want to bake in and right now like we're doing a database migration that should make everything faster and more you know solid but feature wise i think those two questions are kind of related where like right now especially michael and gazelle i don't know if you guys have met them yet but they're heads down trying to figure out a sort of a workable plan for extensible nfts or like not not exactly mutating but keeping track of you know assertions about an nft over time and so the way we kind of see that happening now is using events to send out basically you know entity outreach value triples where you would say like the entity is an identifier for the nft itself and then an attribute is some assertion about it like you know it has an alternate representation here or or like this you know it was remixed into something i would imagine lots of scenarios but then eventually you fold those into you basically compact a big log and then you have i mean you know a view of the evolved nft over time but that's all kind of like speculative right now we're still trying to figure out how practical can we make this and like how and also like you know is this something that requires a lot of buy-in for people up front or is there a way we can kind of apply this to energies that already exist and i think that there is um but there's a lot of details there so i think that's kind of where our focus is nft wise right now for nft storage is to try to i'm not sure if it'll actually come through energy storage directly but i mean we will support it there but i think that that's kind of a broader effort of trying to figure out what the data model should look like um in terms of the actual experience of using it um we're writing it so right now we have a two separate services and we're gonna end up making nft storage a client of web3 storage so just for less stuff for us to manage and for the token management stuff is the the big feature that's going to be coming to both platforms soon i think it's a like so there'll be a way to have like a sort of admin token that you can then create a user scope token and then then users will be able to manage and delete their own stuff without having access to anybody else's but then we're also going to have like a fully decentralized path of using a decentralized identifier document to assert ownership of the key and then that gets you like we just want to know that they're you know be able to identify you somehow we don't have to know who specifically you are so that we're building that out and should be coming um i mean i can't promise timelines but awesome well the ids do sound pretty incredible here um that's great well i think that's all the time we have today thank you so much for doing that presentation and also yeah thanks that was great but uh perfect so with that we are ready to move on to [Music] [Applause] [Music] 