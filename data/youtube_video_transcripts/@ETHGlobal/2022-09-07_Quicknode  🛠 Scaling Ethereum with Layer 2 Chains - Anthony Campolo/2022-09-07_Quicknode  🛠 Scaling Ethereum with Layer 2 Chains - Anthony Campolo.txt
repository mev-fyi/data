[Applause] [Music] hello everyone my name is anthony campolo and i'm here to talk about scaling aetherium this is for eth online really excited to speak with you all thank you to ethonline for the opportunity to do this i am a developer advocate at quicknode and quicknote is a blockchain deployment platform if you want to get uh access to a node you can go to quick node and find a any of your chain of choice obviously they'll be talking about ethereum but we have a wide range of like ethereum layer 2 options and today we're going to be talking about scaling aetherium specifically and we won't really be talking about quick note at all we'll just be talking about what is the problem with ethereum scalability and what are some different options available to create more scalable applications on ethereum so i'm going to go ahead and share some slides with you all now this is a talk i had originally given at ethereum amsterdam and there's a recording of that but this will be a kind of slightly more updated uh more current version of that because there's some implications with like the merge that are coming up that we're going to talk about a little bit but in this talk we'll be talking about side chains zk proofs and optimistic roll-ups now if you've never heard any of those terms before that's okay we're gonna define all of them we're gonna get some context on what they mean and why they're important for scaling ethereum and then my name is anthony campolo as i already said i'm a developer advocate at quick node first thing we should talk about is what is the problem here and why is this something that you need to know about and you know consider as an ethereum developer and the problem is that the ethereum network creates a new block every 12 to 14 seconds now when people talk about the issues with scalability you'll frequently hear people talk about the number of transactions and this is uh i think a better metric for thinking about scalability because a transaction is kind of a vague term like a transaction depending on what's happening within that transaction and i'm using the term transaction within the sense of like a blockchain transaction there's a lot of things that could happen within the span of a transaction and how large or small it is will affect how many transactions you can have on a block so the real the bottleneck here is not so much transactions as it is block space so when people talk about like blockchain real estate they're talking about blocks block space they're talking about how much space on these blocks you can fit information data transactions just user activity because that's ultimately what the blockchain is it's a ledger that we are all collectively using and writing to and so if the ledger space is finite and the ledger space requires a certain amount of time to get written in then we're going to have a scalability problem so that is why there is a scalability problem with ethereum at all and that needs to be addressed now we're going to talk a little bit about the history here and we're going to go through the whole timeline starting with this first paper from vitalik buterin maybe a blog post not a paper but it there'll be a citations all the end and what this was is is a concept called shadow chain there'd be a main line state and then there'd be a shadow chain and this is a very prescient idea because all the things we're going to be talking about within the span of this talk are about how do we create a second separate ledger that the first main chain which is ethereum can interact with and can use to offload transactions somewhere else so here there's the mainline state and then there's the shadow chain and the shadow chain will have transactions and then those transactions will get combined together into some smaller representation and then put back on the main line and then you also see there's that audit arrow in the middle box and then the audit arrow is well what if someone tries to write a bunch of transactions that give themselves a million dollars and write it back to the chain like that's that's obviously an issue and we'll be talking about how we can verify these things are true as we go on the next important thing to know about in terms of the scalability is that this is not just an ethereum specific problem this is something that is also affecting bitcoin and other chains as well so bitcoin they also wanted their own solution for this which is the bitcoin lightning network and so the bitcoin lightning network had uh the same idea where there's kind of two separate things there's the main bitcoin chain and then there's gonna be everything else that's offloaded from the chain now with the lightning network it's a little bit different than that it's not like a full on blockchain it's more of a protocol but i'm talking about it here and inserting into the narrative because it's an important part of this kind of thought of we need to figure out a way to scale blockchains and joseph poon in particular who worked on the lightning network is going to be in the next slide here so now we have talc buderin who is the talking about shadow chains and then joseph poon who's talking about the lightning network they kind of came together like okay like we need to figure this out so they started talking about plasma and with plasma it was a little complicated so i'm throwing a quote here it was a proposed framework for incentivized and enforced execution of smart contracts smart contract part is important and it's scalable to a significant amount of state updates per second so the idea being that whatever the bottleneck is that's keeping ethereum from being scalable we want to make that number much much much larger we're going to make it in the billions so that we can fit as much activity as we could ever want onto this blockchain and then it would be enabling the blockchain to be able to represent significant amount of decentralized financial applications worldwide so it's first saying we want to be able to offload computation and then we want to do that so that we can do a lot of stuff and people can't send as much money as they want without having to pay huge fees along the way now if we look at plasma and a little more in depth you can see this diagram here this is from the original plasma paper scalable autonomous smart contracts and i recommend if people find this stuff interesting like there's a lot of citations at the end and there's a lot of dense academic papers written about this subject and it's you very deep on this if you want and the kind of top line of how this works is you have a child chain and a root chain and there's communication arbitration between the two secured by fraud proof so this is something that as we get into the different current solutions available some of them will have fraud proofs kind of baked into them so this is again another reason why we're talking about this historical angle because while we don't use plasma today the ideas that were explored in plasma are going to become important later down the road and then you have the child chain has its own mechanism for validating the blocks and we'll see a couple different ways that the blocks are validated across a couple different options that we have and then particular fraud proofs can be built on different consensus algorithms this is important because consensus algorithms can have downstream effects in terms of how energy efficient a chain is and you want to make sure you have the ability to include your own consensus algorithm if the difference between proof of work or proof of stake is something that is important to you now let's look at the pros and cons of this approach now the first pro is that you have layer two that labels lower fees and faster computation that is really the core pro that we're gonna be talking about throughout the course of all these different options that you have the ability to enable lower fees and faster computations so you always want you know cheaper faster and then the better is the third that may be the hard one to get and then you have reduce the amount of necessary data processing so the way you enable lower fee is a faster computation is by reducing the amount of necessary data processing and then you also want to be compatible with layer 1 scaling solutions like sharding it now this is a bit of a historical oddity because charting is not really as important today in the road map as it was previously this was a pro 4 plasma in the past but that's not really something we need to worry about too much right now when it comes to the cons though we have a system and we have a theory and we have the idea that we want to have computation offloaded but if you read the actual plasma paper itself is very long it has more of a system and less of a specific implementation actually recommends various different implementations this is why you ended up with multiple implementations down the road you ended up with plasma mvp you had plasma cash and plasma debit and again this is going to this is kind of more historical oddity than knowing the things you really need to know about but these are all different attempts at reifying plasma which we never actually got to but we were able to take the ideas of plasma and put them into practice later and the funds being only withdrawable after a lengthy waiting period is a problem that some solutions today have and some don't and this is a question of really do you want the ability to stop a chain and slow it down it's almost a question of how important is it for you for the operators of a chain to be able to kind of say hey wait we need to actually look at something and audit it and figure out whether it's true or not versus something where a math problem is going to just verify whether something is true or not sometimes you actually want a human in the loop so this is a con for some and a pro for others now let's talk about side chains this is where we really get into the meat of what this topic is about when we talk about side chains and layer two to me the two are essentially synonymous terms some people argue semantics about what's a side chain versus a layer two i i don't think that's really a particularly useful argument i think that you have ethereum and you have another blockchain like you call that a sidechain called a layer 2 chain it doesn't really make a difference to me the point is you got two chains that's what's really important here and with a side chain as you can see in this diagram you have the main chain and then you have the side chain and then you have some sort of proof that allows you to arbitrate whether the transactions are true or not and so you have it operating independently and running in parallel to the layer one so both are happening at the same time and they're both running in concert with each other and then they're speaking to each other through some kind of bridging technology and then the side chain also has its own consensus algorithm and its own block parameters because it is literally its own blockchain and we'll talk about why that is desirable when we look at the pros and cons of this approach so if we look at the first pro it's as i said a blockchain we already know how blockchain works we know that blockchains are a way to establish a shared state of the world that is very hard to tamper with and that is very useful for auditing and for tracking transactions so that's a huge pro if we're going to use this technology to extend blockchains themselves now it also supports general computation this is because when we look at these layer twos and side chains they're all set up to be quote quote-unquote evm compatible so when we use that term evm compatible what we mean by that is you can write solidity you can write the programming language of the ethereum blockchain that you're already used to and that you expect to work in a certain way and it will work that way and this is because smart contracts and solidity and the evm all of these were about providing the ability to write general purpose programs on the blockchain so we don't want to lose that when we move to another chain so if we lose that then we're losing all the power of these blockchains themselves but what are the cons here the cons is that if you have a side chain it will tend to be less decentralized now this isn't necessarily because the side chain like is required by some theoretical limit to be less decentralized it's more so of just how these things play out in the real world and it's more of an empirical fact that when you start up a new chain you need to compete with the ethereum chain and you need to compete with the fact that there's already this whole set of validators and all of these nodes running all this computation on the ethereum network and to have a comparably decentralized network for a brand new blockchain it's just like a cold start problem so this will become i think less of an issue as time goes on and as we have layer ones layer two or layer two i should say that are very decentralized that's an inevitable consequence that we're going to get to but in general when you spin up a side chain or a layer two it tends to be less decentralized it also will have a separate consensus mechanism that is not secured by the layer one and this is important if you're maybe trialing a brand new consensus mechanism that is not used by ethereum if that consensus mechanism happens to be faulty or has a bug in it that could be a huge issue because then you can't really rely on that sidechain or that layer 2 to do what you expect it to do if it doesn't have a sound consensus mechanism you also have a quorum of validators that you may or may not be able to rely on this goes back to the idea of it may be less decentralized it may have a less sound consensus mechanism that means you need to be more conscious of who are the validators of this network are they incentivized to have correct transactions and validate in a correct way to keep the ethereum chain fraud proof or are they maybe incentivized to do something else that's another thing you need to keep in mind with these systems now we're going to start looking at some implementations here and polygon is known as one of the more well-known side chain or layer two solutions and it is worth kind of giving an asterisk here which is that polygon has many different products polygon has even a zk proof product now which is what we'll talk about after this and so when i talk about the polygon side chain this is kind of like the original polygon this is the first polygon they have a whole bunch of other stuff now that is totally separate from this but when we talk about this we're talking about kind of the first iteration of polygon and it was just a clone of aetherium it was a clone of layer one and it supported transferring assets to and from the layer one to layer two and again the time they call it a side chain i'm calling it layer one layer two because i just think it's a more comprehensible terminology people argue semantics about that but it's the same idea and then you have the layer two it's a brand new block chain it own consensus mechanism and is able to create blocks based on everything we've talked about up to the point in this talk that should make a lot of sense and that was polygon now let's talk about zk roll ups with zk roll ups you have a brand new kind of way of verifying this and it's based on something called zero knowledge proofs now i'm gonna try and give my best explanation of zero knowledge proofs for people who have not heard of them there is a thought experiment that can help get the idea across because it's a dense mathematical term but it actually can be kind of simple to explain if you go through this thought experiment with me so imagine you have two people you have approver and you have a verifier and that's what we can see right now in this diagram the prover needs to prove that they are able to so sorry the the verifier needs to verify that they are not color blind and the way they do this is the prover will have two things in their hands they'll have a say you have like a red bean and you have a blue bean so you can kind of like the matrix for a pill in the blue pill and they're going to have those behind their back and they're going to show them to the verifier and they're going to say here there's red in one hand there's blue in the other and then they put them behind their back and then they may switch them or they may not and then they'll show them again and then the verifier can verify whether they have changed or not and so by doing that exercise over and over again the verifier can verify whether the prover is actually proving that they're switching it or not and they are able to do that because of just the verifier be able to see where the colors have changed but the prover doesn't have to be able to necessarily be able to tell the difference of the colors to do this exercise so it allows you to verify a secret without having to share it that's really the core here is that if you're able to verify whether or not someone has a secret but without having to reveal that secret it's very powerful because then say you could use a password on a website without having to give up that password and that would basically mean that you'd be able to have access to systems without giving that system the information that they need to hold on to and potentially guard because if it gets stolen someone else can access the system on your behalf it will completely eliminate that problem so this is really powerful now the layer two scaling solution here is that all the funds are held by a smart contract in a layer one chain and computational storage are performed off chain and for every roll-up block you have a state transition zero knowledge proof which is generated and verified by the layer one chain contract this is where the issues lie because this is very computationally expensive but you have a mass amount of data you can transfer because you can roll up such a large amount of transactions into a single transaction now if we look at the pros and cons here the pros that it reduces the fees per user transfer is because like i was saying you could take all these transactions and kind of roll them all up into this one block and then you have less data contained in each transaction because the transactions contain multitudes now this does not require a fraud proof or fraud game verification and this is something we haven't really defined yet we'll define that a little more in the next section with arbitrum but the cons is that computing zero knowledge proofs requires data optimization and this data optimization is very heavy and has a high computational complexity so if you know anything about like oh notation and things like that they still have to figure out a way to optimize these algorithms in a way that's actually going to allow this to scale so the scaling solution itself is not scalable unfortunately but this is something that a lot of people are working on and may happen there's a question of research that needs to be done so some people say you know this research may take a year some people say it take five years some people say take ten years you know who's gonna be right only history will really be able to tell and then you have a security scheme which assumes a level of unverifiable trust now we're gonna get into optimistic roll-ups now optimistic roll-ups unlike zk roll-ups are being used now heavily like in production already so this is something that if you're gonna be dealing with these types of systems these types of layer twos you are likely going to be dealing with optimistic rule ups and that is either through arbor trimmer optimism and we'll get into both of those after we explain what an optimistic roll-up is now an optimistic roll-up involves having your main chain so we see here we have ethereum we have the main chain and then we have the roll-up and the roll-up is layer two called side chain call whatever you want it's a chain that is different from the first chain and then you have these state transitions and at any point you could run that prove fraud function then that would be your fraud proof and the reason why it's a function you could run is because it's optimistic you're assuming there is no fraud you're assuming everything is going to work the way you would expect it to and so while zk roll ups prove to ethereum that transactions are valid optimistic roll-ups assume the transactions are valid and then leave room for others to prove fraud so that's why it's optimistic if you've heard the term optimistic ui an optimistic ui you send a request to the server and you get a response back as if the server is going to respond back with what you expected too and of course that does not always happen but it will happen hopefully more often than not if your server is correct so this is what an optimistic roll-up is now the pros and cons of this is that we have evm and solidity compatible optimistic roll-ups that is because when we look at things like arbitrary and optimism they are created to be evm compatible from the start they're also more flexible than zk roles because they don't require a really heavy computation involved with the zero knowledge proofs and then you also have the data available and it's secured on chain so there's this term you know data availability which is really common thing that people are talking about today so you got the data and is available now the cons are you have limited throughput compared to z care roll-ups this is because of how many transactions you can fit onto a zk roll up versus an optimistic roll so it can't fit as many transactions but it's able to make those transactions in a faster way and then it requires both an honest majority of ethereum validators and at least one aggregator that does not censor transactions when it says one aggregator that does not censor transactions they mean that you only need one person who is honest you only need one person who's available and ready to call fraud on it and so that is the fraud proof because it's optimistic you need someone to actually verify and call fraud if fraud happens but among the entire system you only need one person to have to do that so if you feel confident that within the entire span of blockchain people out there in the world you have one person who's actually paying attention then hopefully this would work now let's look at some actual implementations here now the first one we're going to look at is arbitram and with arbitron we see this kind of like complicated diagram over here this is a lot of different things going on but the most important thing is that you have this bisect challenge which basically means anytime someone believes that there is fraud there's the ability to challenge and then the challenge will run this bisect algorithm to prove whether or not fraud has actually happened so let's imagine that we have alice and we have bob and they're going on this back and forth and then we have a layer one contract that is refereeing between the two of them now to resolve that dispute you need to have this layer one contract to arbitrate between the two of them and it does that by dissecting the dispute and that is what is happening in that whoops and so that's what's happening in that image on the right over there we're seeing that we have the challenge and then the challenge leads to bisected and then there'll be a waiting period and then we'll either assert or confirm so it'll be in our assertion we'll just say we need to check this again or it'll be a confirmation of fraud or not and then they'll be appending and they'll basically run that on a loop now the final implementation here is that we're going to look at optimism now with optimism we have a slightly different paradigm which is that instead of having a fraud proof there's something called a challenge window which basically means that every time there's a transaction or every time there's a block we have this ability to lock up the funds for a certain amount of time and when these funds are locked up people can look and see whether there was fraud or not and then kind of call fraud on that so if a proposed state commitment goes unchallenged for the duration of the seven days then it's considered good and there's considered no issue but if someone does challenge it then you will have a basically fraud proof that will happen so once the commitment is considered final the layer one smart contract will safely accept the proofs based on the commitment now these are all the citations of what we talked about throughout the course of this project and i highly recommend people check this out i'll also show the link to the slide in a little bit here is our uh resources if someone wants to check out quick know they shout quicknote.com they want to check out our twitter account we have twitter.com forward slash quick node there is a discord link for anyone who wants to check out our discord then we have something called has eath merged here is the link for the slides i almost check out these slides but i also want to show a little bit of have has merged now if we look at this right here we have this website where we can let people know whether eath has merged or not and this is important because the merge is a very historic event about to happen on the ethereum chain and this is actually setting us up for this kind of roll-up centric world is the first step in the ethereum roadmap and so as you can see here has not happened yet but it is likely to happen on december 14th if you also go to quicknote.com the merge you can learn more about the merge and what it means for example you know you may know about ethereum's test nets things like roxton and the like a lot of those are being shut down we're actually going to be in a state where gurley is the test network you want to be using and then we also have you know these that have been decommissioned and the actual merge itself you can learn more about here as well so that is the rest of my talk and thank you so much everyone for listening and this is the something i'm very interested in in terms of you know scalability of a theorem i think it's a very important topic because if you look at the history of ethereum there's been times the network has become really overloaded and it's been very expensive to actually use it i think we actually want this to be a usable system by lots of users out there in the world it's important we make this scalable so hopefully you can take you know a little bit of inspiration here you may look at some of the layer twos that are available and you know check them out build some stuff with them this was three options that i talked about here but there's you know many more out there there's even some zk stuff that is starting to become added to main net things like stark net so there's a lot of innovation here and there's a lot of work being done and if it's something you find interesting feel free to reach out we'll be happy to talk to you about this and help you get spun up with some of these different layer two options and that will conclude my talk thank you so much to ethe online for having us and my name is anthony campole you can find me at ajc web dev on the internet and you can find quick note at quicknote.com thank you you 