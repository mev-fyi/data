to the cloud okay we're good i'll redo that intro welcome everybody to this retrieval markets uh symposium set of talks and demos all sorts of things we've got in store um this is part of hackafest which is a hackathon and we have some people joining from outside the hackathon for this session but um like i said a couple hours ahead of some presentations from people who are working directly on these uh parts of filecoin so it's going to be a lot of interesting content coming up juan do you want to give any overview before we before we start now i'll just jump right in and maybe talk a little bit about the i'll include that in the in in sure yeah you can um i believe you were the first up to speak so go ahead and show your screen and take it away all right awesome can you see that screen yep perfect all right uh great uh hey everyone uh i'm going to be talking about kind of the retrieval market uh in general uh and this is the whole goal for this uh set of sessions today is to um talk about uh all of the all the parts that can combine to make uh the retrieval market and this um the goal is to talk about it both at a very high level uh kind of give a motivation for it and kind of the vision for it and also talk about um uh in in detail how some of the components that are getting built up now can be pieced together um uh to to actually make uh make their visual market work uh and then we'll hear from a few groups that are working on uh on versions of this um and we'll kind of potentially see some demos of uh of of the work that that that's ongoing um and then i i also had uh some open time for for any hack-and-pass teams that are that are working on um on retrieval market oriented things to kind of talk about what they're up to and talk about what they're building so definitely feel free to to add yourself uh here i got some requests to also go over um since drafting this agenda i got some requests to go over gossip sub in general uh just just so that everybody here has a good understanding of how it's supposed to work and so on um and so that's of interest uh definitely like noted on the uh on the chat for zoom and if so then i'll i'll try to um squeeze in kind of like a five to twenty minute uh overview of gossip sub uh somewhere here in the agenda uh great so i'm going to be talking about kind of the retrieval market at a very high level um and kind of talk about the vision for it and then kind of so that we can set the stage for how that's meant to work and and and the different kind of performance characteristics that we might expect from from a network like this um and then uh i'll kind of towards the end of the talking kind of discuss different potential trajectories for for how to uh how to implement different or yeah there's a lot of ways of building this kind of thing and so um i'll maybe describe some of the different different paths that we've been discussing great so i want to kind of ground all this in thinking about the internet and the cloud in in general in general so uh at the end of the day the internet is just like this very large collection of of computers and wires uh all over the uh all over the planet uh and the uh the structure for for this is this kind of like grapevine aware where um uh a lot of machines a lot of devices are all over to all over the edges and they connect in kind of um in a hierarchy uh and there's kind of a lot of uh routing kind of close to the close to the center so you can this is kind of like a zoomed in view of the off the uh of the grapevine uh and it's another conception of it another model for the representation but you can see here each of these links um the farther away uh the links uh are going the longer um the longer the latency between between those links and uh one interesting fact about the about the internet is that it's not just kind of the physical topology of of the network you also have overlays that have maybe these logical links but the underlying distance between those is actually much much larger or much longer so you can think of a lot of the peer-to-peer networks or vpns and so on it's building kind of these overlay networks that appear logically close but but in reality very far away um in in latency and and the geographical distribution really matters because when you're trying to retrieve data uh the speed of light ends up affecting you not just in in kind of the the time to retrieve the data because that's not that bad but it's rather in the in the kind of round trip time so whenever you have to coordinate with another side and you have to talk across across the planet to do so um then those kind of like 200 millisecond round trips start adding up very much this is also the case when you have to talk to a lot of nodes that you don't yet know because any kind of a cryptographic channel has to has to be established and when you do that then you have a lot more round trips per for interaction so here's another uh view at the at the kind of internet grapevine you can see sort of like the tier the top tiers of the internet and kind of the interconnectivity there that you can think of those as being very large organizations distributed all over the world um and having really fast links between them and then as you go down to kind of the home uh home edge environments uh the number of organizations grows tremendously but those are like much smaller uh and the kind of the the time between those uh the kind of little links between them uh it could get worse i have a random question can you hear a cat meow in the background no okay good well good uh zoom zoom audio uh uh is working well uh cool so then this is you know yet another uh conception of the same thing uh it's kind of like a a simpler version where you can think of these kind of sub networks that are put into different uh tiers of the internet uh and different kinds of networks are are connected and you can think of um when you start thinking about how to distribute content through networks like this you can start thinking about how the um uh how how to place certain uh machines or certain devices in different different spots to um to improve the the um the retrieval times for for content so if you're trying to serve a lot of files or a lot of files that are very big uh it gets all the experience gets better the more you can kind of replicate and cache a lot of that content close to where it's going to be used uh and so kind of going back to this diagram for a moment um if you if you have some kind of consumer-oriented uh set of content so imagine uh things like movies or or any kind of video stream and so on where the content is large um and and you have potentially tons of viewers all over the world uh then it becomes extremely useful to start putting caches of content as close as you can to the users usually you can't get it into the user's homes but you can maybe get very close and you can start putting it in kind of those gray great clouds great networks very close to the user but not not quite um such that you have to kind of route across uh across the world uh by the way all of this gets more complicated when you start considering um the kind of emerging uh geopolitical landscape that is adding all kinds of restrictions all over the internet where these links are no longer kind of easy to move move across now there's all kinds of um of delays and and and and uh blocks appearing across links um kind of uh uh thinking about what kind of content can move uh uh to various places um so yeah so i think you know a good example to think about is you know if you're a group like netflix uh you have uh is some data center somewhere and your application live somewhere in the cloud and you have a bunch of consumers kind of in the in the very edge and in kind of what's known as like sort of the last mile or gonna be on the last mile uh and in really what you want to do is you want to get as close as you possibly can to them and i'm not sure if netflix is still doing this but back in the day they used to deploy these kind of racks of hard drives pre-loaded with most of the content that region was going to watch directly in the isp so they would grab a machine kind of like this loaded with a bunch of hard drives pre-filled with all the majority of the content that's going to be retrieved um by you know some some area and kind of ship that box to that isp and then you know pre-load most of the content right there um this is similar to the strategy that cdns take in general so cdns tend to do this but for a lot of customers i i believe like netflix had to do this for themselves and um because they had you know kind of a specific setup and it was just most cost effective for them to do it um by themselves but now um a lot of other other uh content delivery networks end up doing the same thing just they should ship these these boxes to asps um and then they decide how what content to move to these areas and and so on you can think also about the cloud this is kind of a diagram from google cloud's um uh set of uh systems uh they have kind of some set of core data centers um at the kind of center of it and the links between those data centers are you know though they seem close here logically in reality those are very high bandwidth but low uh but but also high latency lengths where because they're going across across the planet um um but then kind of from the data center out you get these kind of edge point suppressants and then edge caching and other kinds of nodes and you'll see kind of a three-tier or two-tier architecture depending on the cloud um some groups differentiate between pops and and the actual edge cache other groups other groups down uh this is you know kind of uh also this is i think our diagrams from from cloud cloud front which is uh amazon's uh cdn um thing and you can sort of see the the you know kind of amazon has some cloud server somewhere or some data center somewhere um and kind of like all the content you put in s3 or similar kind of storage um goes in that data center and then when you actually want to deliver content to the user and you expect some you know high distribution of traffic um you kind of want to cache as much of that content as close as you can to the user and so there's all these kind of cloud front edge locations in a bunch of places to kind of reach significantly reduce the the the time and again one of the one of the big reasons why this matters a lot is not it's not just about the individual you know round trip time um it's really about kind of the sequential round trips like that's what really kills you because um you know the difference between waiting 50 milliseconds and 100 milliseconds you know it's kind of significant you're probably detected as a human but um but uh the real problem is when they'll start adding up um as you you know you fetch one web page that webpage after you've fetched it has a bunch of links to a bunch of other things you then have to retrieve those things you retrieve those things they themselves now have to um you have to get other stuff and so in when you're dealing with a dynamic application that has a bunch of links especially to a bunch of different servers where you have to set up a new tls connection and so on that's what's really killing you and so ideally you want to kind of bundle up all of that content serve it from the same place and ideally kind of you know as close to the user as possible um and yeah here are uh there's a couple maps from from the data center regions from from amazon and google cloud um and that's kind of like the again data centers not the not the edge caches um and these are these are kind of their cdns um and also cloud players here you can see kind of how they try to distribute as many nodes as possible um you know as close to as close as they can to the users cool so you know this is kind of the internet and the cloud as we have today i wanna uh we we have this um this kind of like useful explainer that kind of goes through kind of how we're how we envision this this working out in in falcon uh the whole goal is to build this decentralized storage marketplace where where any party can add uh storage hardware and and software and then contribute the resources wherever they are on the network uh to be kind of to make the whole thing much more efficient to make the entire content storage and content distribution picture uh more efficient and and so that means that in you know you you want you you want you will have um parties that are specializing say on long-term durability of content and in that point you want to set up a whole bunch of facilities and machines in kind of a data center quality kind of setup and where you know you can you can benefit from economies of scale and you can benefit from having a lot of um a lot of storage uh storage arrays all put together but again that's kind of like a data center and you'll you will also have a whole bunch of folks uh much closer to to the end users and then clients of content um that are you know embedded all over the world in specific cities and so on um and those machines will tend to be a lot smaller so those will be kind of in the you know a few terabytes to to um to 100 terabytes range um and and those will be perfect for this kind of retrieval market kind of kind of distribution so they won't have the the kind of upkeep or economies of scale that that say a large storage miner might have but those are perfect for for this kind of retro market cdn uh kind of kind of use case and so when when normally when when um a client is going to to source something on falcon they kind of make this deal with with storage miners and there's kind of this whole contract flow um a client hires a miner or a specific set of miners to store some data and then those miners store them in this kind of long term uh storage mechanism with with a personal replication um and you get this verifiable storage where you get this kind of auditable trace that the data is being stored for a you know long term term and so on plus you get this this very useful kind of subsidy that comes from the block reward which can make the storage of that in the long term much cheaper but again this is kind of tuned for these larger scales these larger scales of storage that are kind of in a more data center oriented capacity when it when it comes to retrieval that's a it's a different part of the part of the equation when uh you really want to push out the content as close as you can to the users sometimes you know that ahead of time sometimes you know what content you should be pushing where other times you don't and you have to respond to to the demand of content um but the whole goal is to create a create a structure where um the content that is being stored by storage miners can then kind of flow out to the edges um either in anticipation of demand or as demand kicks up and so one of the one of the uh ideas on this is that ideally you can you can have a network where you can detect that something becomes hot over time and then decide to move it to different locations uh and so on and instead of making this a kind of centralized coordination problem where a single party has to maintain um has to maintain observation operations all over the place and has to detect all of this going on you turn this into a market problem where agents that are in specific regions that happen to be kind of in between where the demand of the supply of the content is can make the decision to grab that content as well and then re-host it somewhere closer to to where it's being being retrieved so the example here is you know imagine a piece of content that's somewhere stored uh say in the us and suddenly becomes really popular in in europe uh there's a lot of request requests going through uh some ritual minor uh or you know the network notices this decides hey it would be great to kind of re-host this content somewhere closer to these other other notes for now uh and then ideally the content can cascade uh this way uh it's worth noting that um period protocols in general tend to tend to do this by default in in kind of this um very optimistic but the way that tends to pragmatically work where you know if you imagine kind of a bittorrent or ipfs uh uh network and party started retrieving this content um as the content flows out and starts getting distributed uh just because of how the latencies work out parties will tend to as the number of nodes requesting this goes up parties will tend to retrieve it from whoever is closest and will tend to reshare it and and so on uh but the goal of the stock material market is to take that idea and kind of supercharge it to make it uh be incentivized and so uh on so that's kind of like the the long-term um vision by the way i'm gonna pause here and and maybe take some questions if there are any uh before i kind of dive into uh more specifics of how this is uh getting implemented or something like that not seeing the let's see cool so going back to that diagram from from google cloud um kind of our our uh the falcon version of that is that storage miners are kind of the data center um uh type of of of operation and maybe up to the isp so the way that maybe the the circles are sliced in the falcon case is is larger so so you can envision storage miners actually being parties very close to or directly within kind of the same isp data center because you can have a relatively like a much smaller rack you can think of um you know hundreds of terabytes to a few petabytes stored somewhere in in an isp and that could be a great storage miner so that's a lot closer to the user than um then maybe some of these large-scale data centers that the cloud gives you so so you know the storage miners can expand closer to the user but there still won't be um maybe all the way um in the very edge or all the way in the um where a lot of demand is and so that's where retrieval miners kind of uh kind of kick in and so you can think of ritual miners as following from the cdn case or you know going all the way to all the way to homes and one one important detail here um is that in the topology of the internet as it is now um you don't there are certain networks think of uh say large organizational networks so either companies or universities or you know large groups that have and maintain networks with a lot of computers and a lot of traffic is going to those those machines where having a retrieval minor node within that network can just suddenly start surveying content for that entire network and it would be really really nice and useful to enable parties within those networks to be able to set this this kind of thing up um and so cdns today don't really i think in for the most part don't tend to do that unless kind of those networks reach a certain size because the overhead and complexity of kind of creating some sort of agreement between between that organization and the cdn is kind of way too costly but if this can become a single party's choice a single party can choose to do that and the software and hardware just take care of it take care of the problem then you can get a much more efficient distribution mechanism but that's kind of like the there's a lot of work we have to do before we can really enable that kind of uh kind of thing there's another part of this which is um there are a lot of networks in the world that um where the last mile is actually way more expensive than in in kind of the highly connected uh cities um it's a lot of parts of the world where um some town or some some small city is connected over kind of like a wireless back hall or is connected over um in some cases satellite or other kinds of uh connectivity where um suddenly those links become extremely expensive and having something in kind of like the isp before that last mile it doesn't really cut it and today most content delivery networks in a lot of cases don't end up delivering content all the way to those places um because for example it might not be it might not be that profitable for the cdn in general and the cdn's you know priorities listed somewhere else but ideally with uh with falcon what you you would like to enable is you enable somebody there in that network in that um in that city or village or whatever to decide unilaterally to set up a machine uh and then start caching start kind of um being able to cache a lot of the content that is being requested from that area by turning it into a market problem that anybody is able to enter a permissionless market problem then you can uh you can enable that kind of action to happen um but in order for that to work you need a lot of the kind of observability of what's being requested and so on to be to be kind of aggregated by the network um great so i think uh i think kind of um we talked about this at a very high level but kind of looking at the concrete details of storage minus and our two miners we can look at these these kinds of diagrams where um and i've shown a previous version of this diagram that wasn't updated to reflect kind of the scr and sc uh distinction but i've added that here now where you can think of storage miners it's occupying a very large swath of of the kind of retail latency uh standpoint depending on where where the latest proof of replication land um and so today uh we're shipping with ser which has a pretty bad retrieval latency but it's but it's kind of the much more secure and stable uh proof that we have uh we were hoping to get an sc out before before making it launch we that's not gonna happen right now nfc targeted for november or december um and so kind of that that uh slice doesn't uh isn't there uh but we we do have kind of like a like a a um kind of hacky patch to this which is um hey sorry storage miners keep an extra copy that's unsealed then you can actually search miners can actually participate in in pretty fast retrieval you know kind of in the sub second sort of range um or or sorry like single second uh kind of range um but that include that includes kind of doubling the the storage cost and so it's it's a trade-off where where some clients and and some storage use cases will really benefit from from that kind of fast retrieval um and and and so that's kind of worked into the deals now where uh when you make a storage deal with storage miner you can request a an extra copy being being stored and miners can sort of do the accounting and price that differently because of that extra storage cost um but then this really kind of patches this problem where one of the copies is within a proof of replication and you get like the very hard verifiable trace uh of proofs that that content is being stored uh and then you have this extra copy for for fast retrieval now there can't unfortunately it can't be hard guarantees about the copy really being there um but if clients kind of uh try requesting it uh relatively frequently they can build the distribution of of whether or not that copy is there and it's really mostly a pragmatic solution to this kind of question around hey ideally when ideally there should only be one copy and it should be coming out of the personal application and the proof of application should be passed off but that's sort of what why the storage miners kind of span that entire region ideally over time we want kind of the source miners to to um you know as proofs improve and and operations improve and hardware gets better and so on to kind of start moving over to to these kind of faster ranges and and it is totally possible for storage managed to get into into the sub second range and start kind of um delivering content in the hundreds of milliseconds um we we can get fairly close to that with some of the proof constructions that we that we already know about but it takes a while to to analyze them in full build them refine them plug them into the protocol and so on so it'll take some time for storage management to kind of get there in the meantime um that's where retrieval minus can come in which reminders can occupy the whole area of of a retrieval latency where you know for for some distribution of content that where retrieval really matters uh then then virtual minus can come in and serve that part of the part of the equation something i forgot to mention earlier is the in general the distribution of content on the internet um is one where the vast majority of content the vast majority of of all of the data stored is accessed once or never and very few content you know by volume very little content is accessed uh you know occupies most of the content ritual requests and so because of that distribution we can you know you can think of storing a lot of the long-term storage doesn't need to be um stored in a in a way where uh you kind of have to sort it close to the user um and it's only a small fraction of the content that actually needs to be geo-replicated and cached everywhere uh and so that's that's why this this problem kind of couples into these two two different parts of it that are that are really nice um but anyway any questions on on this part i know this is like an interesting um way to look at it and maybe a lot of folks have had questions about kind of the proofs and and so on uh i'll look on if you have questions definitely enter them on on zoom chat i'd say a couple so how's the location information gathered to communicate to the ecosystem um a good question so right now right now we don't have good mechanisms for it um we have a bunch there's a bunch of different ways of of doing this uh and kind of ipfs has a one version of it uh this is this is really where um there's a lot of open design design space for for what is going to be what's going to be the right model um there's a lot of stock standard innocent systems that we could think of of employing and deploying here um but it really kind of depends on it really depends on how applications want to use them and whether or not they fit the model um and so right now there's no there's no kind of like chosen way of saying this is exactly how we're gonna do it we'd rather expect that we're gonna as a community we're gonna experiment with a few different ways of doing this before one is like naturally clearly the better one another question can storage and retrieval miners publish exclusive deals an example is only specific predetermined users of a storage miner service would get a cheaper price so the general public would be charged a certain amount and and that you know set of friends um or or you know other other known parties would get a better deal uh yeah totally so so this is a that's a great um great question so right now i think the tooling and lotus only allows lifting one price and then allows creating i think there were discussions around creating a discount structure where you could um you could kind of offer some kind of standard discount for automate automatic deals but at the end of the day this is just about generating a deal data structure that's signed by both parties so there's a lot of operational freedom there where miners could be listing whole kinds of different prices and make their own decisions about who they give what price they give to whom um and we anticipate especially for any kind of large-scale data so when you start when you start looking at many terabytes and petabytes of data all kinds of other things are going to get into the mix so like how you get the data to them in the first place and so on so we anticipate that once you hit you know single you know many terabytes of of content in in a single deal that's actually just going to move to email very quickly and clients and miners are going to interact over some kind of conversation and then decide on a price and then they're going to craft a deal based on that based on that price um so uh we we're you know we've many folks have also suggested kind of a market quote mechanisms where you can kind of as a client you can go and kind of describe the data and describe where you are and describe how you can ship it and then kind of request a quote from a bunch of different miners might just kind of think about this and kind of send it back and and i think that all of that kind of kind of stuff is totally viable here uh at the end of the day this is this is a marketplace um and that that will just require kind of software tooling built around the core of the the core of the market right so the market brings it brings the the miners and the clients together gives them all kind of identities um and then you can think of tooling like that being built being built on top there's other kinds of things that matter there like like a different kind of storage features like say um being able to certify other kinds of things like uh say hipaa compliance or some specific um matching some kind of um industry standard uh structure for for how a storage facility is capped and and so on and so those kinds of guarantees can be advertised and then kind of kept separately and and you can imagine kind of clients saying oh well i have hipaa data that needs kind of hipaa compliance um storage miners and so then would select to a subset of the miners um what this really needs is just some website that can do this do this kind of um integration of the of the uh of the offers and so on and there's a i know a few in development that are doing this but this is also kind of like an open open space where folks could could build something in the in the near future all right i don't see any more questions at the moment so i'm gonna proceed uh cool so a kind of view at the at the storage market you know the goal is to uh kind of commoditize this uh commodities digital storage as much as we can and kind of following what what i'm saying before this is kind of a you know a set of pictures from from a lot of folks who have been who have been deploying um uh storage minor facilities and you can see that they're very much tuned like like data centers and are in data centers where they have large racks and so on and there's a lot of storage here that can that can be put to put to work but again this is not as close to as close to the users there's a whole a lot of organizations are uh are are getting involved and and kind of sizing there's kind of a question around sizing um in the last test net that we did i think we we got to like 29 or 30 petabytes and so that's kind of the the scale there and that's without incentives so we're about to start the space race uh uh very soon and that will that will show us a much better picture as to how much storage is out there and you know what we might expect during during the mainnet um at the end of the day that kind of uh the block reward is going to drive optimization and it's going to drive a lot of storage to appear uh and so it what the block reward does is it gives us the ability to build a lot of capacity without having to match exactly the without having to match it with demand at the same time so we can build a lot of capacity and the capacity is being rewarded and then over time we can then put that capacity to work for um for clients so now for for um for retrieval though um you know if also a very different set of characteristics as the as a storage market um we want most of retrieval has to happen entirely of chain because we want this to be you know really fast and so that means state or payment channel networks we have the the um you know kind of a straightforward um payment channel uh system within within falcoin um there's also a lot a lot of um a lot of thinking that has gone into state channels in general um and there's a lot of really good designs out there uh over time we'll probably see a lot of that kind of stuff migrate into filecoin but we also can make use of a lot of different kind of um statement channel networks that exist already uh separately as you can imagine kind of state channels uh working over over ethereum or on some other network and um and then we also want kind of the the the distribution of kind of requests and the gathering of information about what to put where to again be kind of this layer two fully kind of off chain uh option setup where where uh you can think of that indexing or um or even kind of the requests flowing through from specific clients and so on uh to be happening over you know very low latency but potentially very large network um and so we when you can think of you know topologies for retrieval there's a lot of different ways of of doing this um but something that kind of you know many different ways of doing this might uh will tend to kind of gravitate to this kind of topology where you can think of there being kind of a network of hubs where a hub is really kind of constrained geographically geographically based on kind of what makes sense to do given the distribution of clients and miners in a specific area so you can you know think of those hubs as matching the the internet topology um and and those you know this might be like a this may be a very coarse uh course version you can think of this subdividing over time as kind of demand demand increases right so this is one potential strategy for doing this um is to kind of construct these hubs where there's one one or a few parties kind of doing a lot of the coordination work of figuring out what virtual miners and clients want in a given area and kind of facilitating that exchange of information and then if something is not in that area then kind of the forwarding the request to to other other hubs and the structure um you know there may or may not need to be this logical separation between say retro minor and hub it really depends on on on a lot of the details of the protocols right so payment channels tend to work well with with these kinds of hub hub things um uh the retrieval will also tend to work well with this kind of thing as well and so ideally what we would like to end up with though is kind of this uh uh almost warrenoy style uh uh subdivision of the world where as as the number of kind of clients and and ritual miners uh grows in various different areas you get this kind of like subdivision over time um and you can think of you know keeping keeping track of that at kind of a network level and over time kind of subdividing more and more and more and more depending on on on the demand and this you know matches sort of the uh what the cloud cdns are doing in terms of their um uh their kind of planning and so on and where they place all the all the nodes but ideally you would get get to do this just by kind of market action ideally you know this kind of subdivision could be a unilateral move by one party that says you know um this this hub is getting too big we think we can do much better by just splitting off and forming our own hope hub closer um and then kind of creating a distribution there and again this is like one one potential way to do it you could not really see these hubs and then kind of treat the entire network as as uh as just one single mesh uh and so on but that might be and a lot of algorithms could could work that way there's a lot of of r d that has been done to to build this kind of these kinds of protocols um but that may be may or may not be easier right so so um i think the hub kind of structure tends to then to be easier to kind of model and observe and tune uh whereas kind of treating it as one single fabric might be a lot more elegant and a lot more kind of from a systems percep perspective easier to describe but uh but it might in practice turn out to be turned to be harder and and and more unwieldy um really not clear though this could be this could really go either way um so i wanted to also touch on some of the components that are kind of already built out um and are kind of uh i sort of see the retail market right now as a lot of the heavy lifting of the components of a lot of the components is there they just they can be put together into kind of a kind of um version of of retrieval that can that can work to some extent uh and we'll we'll actually i think hear from a few folks uh that have already done this that have put together some of these some of these components um but what's sort of missing is with the components i might be missing are kind of beyond this which is uh how do you do the um how do you do the kind of aggregation of information going through the network um how do you make what are the incentive structures between between refuel miners and clients and so on or you know between retro miners themselves as to whether or not they they cooperate or compete um and so on and so that's we sort of see the development of the of the retro market as having many kind of versions over time as as this refines and so we'll hear about kind of like ritual v0 and v1 um early on and lotus is now i think in in in the v1 uh v1 v1 place um and we'll we'll kind of hear about that a little bit later uh we'll also kind of look at uh at uh some of the payment channels um that are there now on popcorn that you can use for for this retrieval uh cool so i think um maybe i'll jump into uh ipfs uh cids i'll give a brief overview of how that works uh just because it's kind of like important set of basics to to um uh to have in mind and then uh then i'll turn it over to to hannah to talk about uh the lotus uh parts uh kind of retrieval on how it work how it works and then um i might do the kind of gossip sub uh description uh right after that since i yeah i see that folks uh focus on that cool i'm gonna move to a different presentation great i think uh can folks do that great so if you've used type ffs and you've added content to your first in the past you you probably have used i preface add that kind of takes a directory and and adds it all and you get this kind of output that shows a bunch of cids um those cids are the kind of hash link to that content and that includes kind of all the links of the the stuff inside if this is new to you there's a whole bunch of talks out there that kind of go in depth into this so just kind of um talk about it in a general sense now then those kind of the way that those cids work is that um what you end up getting is this contiguous file gets uh chunked into a bunch of different pieces and each of those trunks is hash and then that kind of file that is a collection of chunks gets its own hash and so on and so over time you can think of all these pieces being you know constructing a whole you know um tree that whole large large tree that represents represents the file and and that's you know one one version of it um you can think of entire directories and processing built the same way or you know moving away from the file system notion you can go into whole sets of data structures like um like textile threads which are threads of a bunch of information kind of like a database um kind of view into a lot of um the various uh little data structures in an application being added over time and versioned in in kind of a large graph and so all of those things get addressed by by these by the ecids and you know and you get the benefit of kind of duplication all over the place because whenever kind of uh some some things have the same cid then you get all this duplication that happens uh thanks to the thanks to kind of the content model um and so now the way that um that ipfs works for um kind of retrieving the content sorry it's spinning wheel is these these uh nodes maintain a collection of content um and then that collection of content gets uh gets is able to be distributed to other parties and that happens over with a protocol called bitswap normally in ipfs so let's see if i can find if that description is here maybe yeah there we go so um this is this was kind of a protocol where um different parties advertise the the hashes that they that they want um the ideas that they want and if there's kind of like a peer-to-peer match then then an exchange will occur where uh parties will uh send the send the content over to to each other and this is this is what's in in ipfs today um and so some of the you know you can think of um different different parties maintaining these want lists they advertise their one list to each other they kind of establish that you know there's some some set of uh of content that you know one can send to the other and and so on and these these uh the content blocks themselves are are moved over um and then after that then kind of the want is it's already satisfied so then that that is no longer there that's kind of a very high level view of bitswap there's a lot more details into it into how do you maintain these long want lists uh you know as the content the amount of content you have increases that that gets a lot more more complex but um one very straightforward problem with with this version is that bitswap um the the kind of version of this that exists now only does it at kind of one layer right so when you're requesting one you're requesting one piece of content at a time so if you're going over a large graph that where you have to retrieve one piece of content look at the content of that and then kind of move your way down you don't get the ability to to kind of make that a single request to to you're going to suffer from kind of these these round trips and you're not going to saturate the saturated download link and that's what what a graph sync is for so graph sync is another protocol um and we'll we'll talk about that in in a bit um but kind of what that that is about is is using ips selectors uh sorry i fill these selectors let's see this this is here so the idea there is that when you have these these data structures in these graphs because you have you understand kind of the graph structure you can actually express a you can use a path expression to describe the part of the graph that you're interested in and it could be the whole graph but it could be just the subset of the graph and you're able to express that in a request and so you can uh in your retrieval request you can say hey i'm interested in this part of the graph and then only get get um the retrieval for for for that part and now graph sync is it's going to make its way back into into go up your class at some point uh and just jason's ipfs uh it's already in in lotus now so you can look at the um platform specs as well and you can kind of see how um how the kind of ritual or crafting works in just an area here um let me find it uh that kind of goes into kind of how the requests are are meant to meant to work uh so you can think of the entire you can reason through the entire flow of how a graph singer request works and also how a graphing request within how that works within within loans and and the way that we built this out is that it includes um uh the capability for for thinking about um uh it includes the capability of thinking about different um authentication tokens being passed around uh and those authentication tokens could be payments uh in a payment channel or it could be some other authentication token um but the idea there is that you can uh there's like a straightforward way to plug in um different ways of thinking about about how to authenticate that request uh to kind of enable a much a much faster retrieval referral flow so so graph sync is i think the kind of uh the way that i would recommend kind of building out um uh retrieval uh in in in falcon where you can reason about the graphs the subset of the graph that you want to you want to get and you can that it is already uh as part of the library is there now it just means pairing that with say gossip sub to then create some kind of like larger mesh of where we can advertise advertise the content so i'll pause it now and hand it over to dude if hannah's here i guess oh maybe she's not here one second let me let me uh bring home and see she's wrong hey would it make sense to uh just skip over to the next chat while we're waiting for hannah to join yeah maybe the only the only constraint is that uh probably the other ones would make a lot more sense if uh kind of after uh maybe i think i thought that the times in the doc were in psd as opposed to east so gotcha um all right we can hang out for a few minutes yeah is there any questions so far on what i presented so uh definitely yeah why don't we do q a for a bit and then uh uh give some time yeah go ahead jay juan would you uh elaborate on the term state channel i'm not quite sure what you mean by that um yeah so a state channel is kind of like a more generalized construction on top of a payment channel or kind of beyond a payment channel which allows the ability to reason about a lot of different kind of state being able to be updated off-chain so it's some construction for defining and declaring regions of state that are able to change um in an off-chain way without requiring committing to the to the blockchain in one one go and highly recommend there's a an awesome project called state channels you should check out hey there's hannah yes hi i'm very sorry uh to to everyone i realize i'm supposed to be presenting right now and uh in the middle of trying to cut a release uh for uh file coin and somehow it didn't get on my calendar and i got the time zones so i'm i'm really sorry no worries you're here yeah this presentation is going to be a little bit on the uh rough side since i'm mostly improving it um cool that's good and if you want me i can give you like a very quick um uh summary of kind of what i what i um uh presented through so i think um so i kind of gave a very large overview of um just family channels in general um we walk through kind of the how the internet and the cloud works today of just in in kind of the the how the grapevine works and so on and how cdns how clouds work and how cdns uh deploy that all the way to the edges uh then talked about um how um as we get uh then kind of like the the structure of kind of retrieval um and storage miners and the distinctions there storage miners being kind of large-scale uh operations uh and then kind of retro miners meant to be much closer to the to the edges um i gave a bit of an overview on ipfscids and bitswap and graphsync a little bit but uh you know feel free to not not in enough detail to be to be super useful mostly just kind of described how bit swapped bits up works and kind of how graph sync uses selectors instead um and then kind of described hey uh the kind of like retrieval v0 and v1 are now part of the market's module inside of lotus and then kind of all of that code is there to be used by other folks building uh building virtual miners and that's kind of where i left it i haven't given an overview of gossip so i'm going to be doing doing that later for sure yeah um and oh sorry i have already have a question and full and assigned message invoking the clerk rather than the payment chain oh sorry we were doing it right now no i i don't i don't know no i think you should do your presentation we were doing a q a right before you joined and i'd been oh okay yeah um and and so uh i mean my thought is i would uh i would sort of do a little bit of an in-depth on how the current software works um or to to the extent that i can kind of cover it conceptually um i don't have a slide presentation um uh so i may i'll probably do a little bit of talking and do a little bit of um uh like uh maybe some showing of code maybe a little bit of looking at the file coin spec which is a bit out of date but still gives you a decent overview um uh and then um yeah i think that's that's probably how how this will proceed um uh so uh yeah so let me uh why don't i just go ahead and try to do uh over you know my best overview of the current software um and uh the different components how they work um and how you might use them um in a uh in a you know future uh retrieval only minor um so uh the current software uh i i guess i would call retrieval v1 uh v0 is largely no longer in use that was it earlier we originally when we designed it we were kind of trying to design a incremental model for implementing this uh and we built this v0 version um uh and then over time built a better version we call v1 um and we've and we've replaced and removed v0 and it's actually going to be leaving the file coins back at some point in the the near future um so let's just we'll just call it retrieval v1 and and i'll kind of go over how it works um uh so uh uh the basic concept of uh retrieval um is that uh and this sort of probably goes to stuff that juan has already talked about him is that um a retrieval is a largely off-chain transaction um we are uh the negotiation of the of a retrieval deal the um uh the sending of data the uh and much of the payment for a retrieval deal occurs off chain um the on-chain component is this concept of the payment channels but the payment channels are specifically set up as a mechanism by which you can um they're essentially an on-chain mechanism for doing a bunch of stuff off chain and then submitting it to the chain later that would be like my like super like very you know like basic like what i understand the payment channels to do as someone who's largely learned learned them as i've written retrieval um the payment channels are a mechanism by which you know you essentially set up a you put a bunch of funds in a kind of an escrow and then you make a bunch of transactions which you can submit to the chain later you don't have to submit them in the middle of making those transactions and that allows you to do sort of all the elements of retrieval without stopping a bunch of times to put stuff on the chain which obviously carries a kind of time cost to it um so uh in it so because everything is largely off chain um the scent the essential mechanism of like building of doing trust uh for retrieval v1 is this sort of um uh this thing i would call incremental trust essentially uh retrieval is done uh the basic method is we agree to an overall transfer um we say and we agree to parameters about that transfer um and then um i send you uh and then the provider sends me a little bit of data and uh then they say i'm not gonna send you any more data until uh uh you send me the payment that we previously agreed to the amount of um or you know this portion of the deal um and then i send you that and then they send me a little more and you essentially have this like back and forth all the way to the end of the the overall data you're being you're transferring um uh that uh yeah there's a little bit of uncertainty around the last piece uh this is always a problem in this sort of scenario of like how do you you know ensure trust um my my hope is that a lot of these amounts are going to be pretty small so you know the the the the net value of like absconding with like the last bit of data without paying is not is not super high uh so and there's other mechanisms in there to prevent um a lot of a lot of uh fraud but um in any case so that's the basic way you do trust um and then the way it actually works um so the uh in terms of the components that are involved um at this point um so uh we have we actually have a like uh what i would say is like three protocols but they're all sitting on top of each other so that effectively there is really only one underlying protocol that uh that um most retrieval is happening on uh but um but it it the it stacked on top of that or two other things so um so the retrieval so we have payment channels are on chain component and then we have the retrieval protocol which is like how we're negotiating this deal um and how and you know essentially sending i'm reading your request for payment and i'm checking like whether they match up with the parameters we agreed to in the deal then i'm sending you a payment and you're checking out whether that payment matches what you're expecting for the deal that sort of conversations that's the retrieval protocol and that is sitting on top of the data transfer protocol so the data transfer protocol is essentially it's like a it's effectively like an abstract protocol for moving data uh from one uh and uh from one person to another without a a a super like without a specific clear understanding of what the underlying transport mechanism is now this is like a very wide abstraction the idea of like an abstract way of transferring data could mean anything from like you know like our standard stuff like bit swap and grass sync to theoretically like sending hard drives through the mail right so like that's a very wide abstraction we're still trying to figure out if we can really dictate it um but uh the data transfer protocol abstracts away the underlying transport mechanism and piggybacks upon that so the underlying transport mechanism of uh retrieval is grassing so graphsync is the actual network protocol by which data goes back and forth across the wire well actually i guess underneath that is limp p2p which goes to tcp you know whatever but um but in any case uh graphsync is essentially the the live p2p protocol that things are communicating on um there are there actually is some mild use of a separate um mostly for the initial negotiation of a data transfer lib p2p protocol but there is actually no lib p2p protocol for the deal itself anymore in retrieval um it is all over data transfer um and graph sync uh so um sorry uh let me let me uh let me rewind uh okay so how does all that work right because that sounds that sounds very like while you're piggybacking upon piggybacking so um graphsync and i don't know if bitswap has this functionality as much but graphsync has uh some very specific mechanisms for embedding other information in a request uh that can be essentially like an auxiliary or what i call a side protocol um so when i send a graph sync request i can embed in that request a essentially a packet that will get decoded on the other end assuming i know how to recognize that packet um and uh and then it can be read and processed by essentially uh there you can essentially register hooks with graph sync and know how to process specific extensions to the protocol um uh and so uh in this case uh there is an extension set over grass sync uh that is for it's actually the data transfer protocol extension and then that gets unpacked by a hook the data transfer the data transfer module is registered um and then that becomes a data transfer message and inside of that data transfer message is a retrieval message that the data transfer module like knows how to well actually retrieval is registered with data transfer and it knows how to unpack that message and get the retrieval message out um in any case so it's a little bit of a you know it's a lot of funkiness uh but it's cool because you know you essentially like um the the upside of all this is that right now um and this is more for the future right right now we do all of this with my software for retrieval which uses payment channels uh there is probably uh some future version of this that could use state channels and the nice thing is because it's all like you know these on each protocol supports putting stuff on top of it um you could write you know your own retrieval protocol to use state channels and then you know essentially just run it on data transfer the same way that the existing retrieval software does um anyway that that's sorry i'm like i i realize i'm like uh it's sort of like oh look at this this is cool but i did i'm only bringing it up because like realizing that we could we could replace this with state channels and not change the underlying thing it finally made doing all that feel worth it which which was largely what retrieval v1 was is like making all these like layers work on top of each other um in any case i don't know of any of this this may all be if this is all sounding like i don't know this makes a whole lot of sense i'm giving like a super high level overview and it's probably totally gonna take questions later um uh yes juan you have a question yeah it might be useful to just um uh even as you're describing it if you're kind of just browsing around the the code bases like if you just go into the yeah yeah yeah yeah let me let me let me show you guys some of that um i'm gonna i think i should be able to share my screen oh my goodness what am i gonna do oh hmm hold on one second i want to i think i'm gonna use chrome and look at github because that's just easier because i can keep it all in one window that way so everyone able to see my currently just shows zoom um okay so um so actually i just want to talk a little bit about i'm going to show you guys graph saying first just so you all know how that thing works um and uh and it is like i would say for transferring ipld uh graphs i don't know you know if all the retrievals we're going to be doing are ipld graphs but for transferring ipld graphs i would say if you're doing a point-to-point transmission it's probably the best mechanism you have right now um so and the way that graphsync works uh i think juan probably explained this so when i'm transferring an ipld graph um i have a couple of requirements about how i want to transfer it i want to um i would like to get it the whole i you know i have a notion of a root of that graph i know a cid that identifies the root of that graph and i want to be able to transfer the graph but i want to be able to do it in such a way that i know i'm getting the data that i originally said that the actual i want to be able to verify that the data i'm getting back is the uh graph that i expected um so uh bitswap's way of dealing with that is to essentially uh you know your graph is made up of a series of blocks with links to each other and bitswat's way of dealing with that is to essentially request one block uh get it and then look at it verify that it matches the cid and then um request the next block right um the downside of that is that you are going um you're essentially doing a whole bunch of round trips because i gotta do the top layer and then the next layer and the next layer and the next layer um and so particularly when you have graphs that are not wide but very deep it is not in the fish there's a lot of internet round trips in the mix um the way grass sync works is you start with the root and you start with uh this selector which is essentially an expression of what what kind of graph below the root you want to get um in most cases a lot of the time you're what you're trying to get is the whole thing um and there's a selector for the whole thing um uh so uh in any case uh what that means is i essentially sent a request to you uh the other party and i say i want to get the route um and i want you to also send me everything that you get when you when you apply this selector to the graph below me um uh so the remote party like starts with the root block and then runs the whole selector and gets the whole dag and sends it back to you now since you haven't done this series of round trips um you need to uh when you get all that data you actually still need to verify it so the way graph sync works is it runs the selector locally um uh with the data that's coming back in to essentially verify that it matches the selector there's a bunch of tricky things in the mix with that it's like for example the other party is missing part of the graph that you asked for you need a way to deal with that um you also may want to deal with like the fact that you already have some of your own data um so uh oh yeah yeah sorry hold on one second let me zoom in i yeah uh how is that readable i can do more how about now somebody tried man ups yes yeah okay cool so let me just show you there's a lot this is just i'm just looking at the top level file um and i'm showing you um the essentially this this thing called graph exchange which is the overall interface for uh graph sync um uh and uh it's actually gotten a little bit longer than it initially was initially this just had like a request method but now we have all of these hooks and these may actually move out of the core interface at some point because it seems like not everyone who implements graphic is going to implement all of these things but um so you know when you initialize an instance of graph sync your your main method is this request method um you uh takes you know the person you're requesting from your root and your selector and then you can see you can pass in a series of extensions and this is where you would pass in the um you know essentially the encoded data for a higher level packet that you would want to um that you would want to pass in with the request um it's going to return um uh essentially a channel where the progress comes in a channel for errors this is this actually we thought about changing that because obviously double channels can be a little bit funky but fortunately neither one is blocked on the other you don't forget i'm i'm getting too in the weeds here uh in any case so that's the method and then you can see you have all of these hooks which essentially you can actually hook into almost every part of the request um you can this stuff like here this like persistence option allows you to like change the source block store the source like um like your locally stored data you're using for requests and responses this is super useful in file coin because we're always wanting to like put requests and like put our blocks in different buckets and stuff um you can you know you can respond to incoming requests outgoing requests uh you know and the each hook has like a structure to it where it largely gets just as an example like an incoming request will get um it will get uh you know the peer the entire request and various things it can do with that request that's his hooks hook actions and you can you can see if you look at the hook actions you can oh my god where is it you can you can respond with extensions you can change the persistence options you can terminate it you can uh pause the you can actually pause it right as you start um another thing that graph sync now does is it does a whole bunch of like pausing and unpausing options so i can take any request that is in progress and stop it and resume it i can do this on either side uh so if some if i'm responding to a request i can pause it um and essentially um uh tell the other party like i am not going to proceed um until uh you uh i'm not gonna proceed until you well i can i can tell them that it's paused and then i can send an extension back that tells them like essentially you know um your uh you know here's why i'm paused here's what you can do to make me unpause if that's the responder uh the requester can actually pause and unpause uh it is a little bit of a uh it's quite a weird underlying operation because the way we do the way it's implemented is we actually cancel requests and then create new ones where we tell the other party not to send all the first uh bits of data in any case uh so these are all you know so ground sync is sort of like for point-to-point transmissions it's a very controllable like modifiable protocol where you know you can transfer large bits of data and have a lot of control over how that operates um you may or may not uh work with this directly um if you're doing anything retrieval related you most likely will want to work with data transfer um does anyone does any uh anyone mind if i go on to data transfer or like i you know if you all have any more questions before i go on to it good okay i'm gonna go onto data transfer unless anyone objects uh cool so um oops oops oh sorry uh grassland is an ipfs data transfer for now is in filecoin um so fyi okay um and data transfer uh as it relates to graph sync for right now um there's a notion that we will support other transport mechanisms in the future um but for now um data transfer is effectively what i would say it is like a nice abstraction on top of graphsync that will put things in much more semantic terms for your use case uh for the use case of retrieval um and probably is just what you want to use the one other thing that data transfer supports which graph sync does not support uh is a push request push request meaning rather than i request you to send me some data i actually contact you and say i want to send you this data that's probably not likely to come up as a use case in retrieval it's more of a storage use case because in the storage case we actually are like we want to send you this data so you can store it um but in any case that is a that is an additional feature of data transfer that's not in grassland and it's just done by adding a few extra steps to the um to the sort of like negotiation um okay so let me just look at um data transfer um oh sorry one other thing i didn't cover in grassland that's a security thing um it's probably relevant um is that the one thing about grassland is you have to be careful about which requests you're willing to serve because because we're not sending back just a single block we're actually processing an entire graph query that carries like a a potentially large cpu cost and or disk cost on the um side of the person responding um and so you have to uh so the way graph sync works is it takes certain types of limited selectors it will serve uh to anyone uh though in filecoin that's actually um turned off completely so the file coin instance of grassland will not serve any request it does not recognize and then what you uh for other requests where you want to have like a more unbounded selector uh you use one of these hooks to essentially uh it's almost like looking at a cookie in a web request where you're like you look at it and you're like oh i recognize this and so therefore i'm going to serve this whole you know this whole this large selector um to this this person um okay sorry that's a sidebar uh it becomes relevant to in data transfer so in data transfer essentially you start requests by um opening a push uh or poll uh data channel um it takes largely the same parameters as graph sync though you don't actually have to um uh though the the the thing you encode is is very specific so you have your context your other peer you have your root and you have your selector right so that's all very familiar um the other thing that data transfer has it you you put in is this thing called a voucher and a voucher is and it it is an encoding of some kind of data that indicate that the other side will be able to decode and um and know something about right and know how to process uh so essentially so as an example when you're doing retrieval so the in retrieval everything is done over this so the voucher is actually the um when you open a the way retrieval works it starts by opening a poll data channel poll means i want to i want the other party to send me data um uh and the voucher is actually an encoded retrieval deal proposal um so you take the retrieval deal proposal you you put it into this thing called the voucher the voucher um uh and you send it along with this data transfer request um and vouchers uh from the standpoint of data transfer they're very simple data structures i wonder if github will actually let me oh wow i love that they oh no they're not quite there i thought like github would allow me to just jump right over to the definition of that type uh it's gonna be over here sorry uh get up keeps getting more sophisticated but they're not quite there right uh so a voucher is a really simple type it's literally uh it doesn't we don't know any from the standpoint of the data transfer module we really know nothing about it other than it has this thing called the type which returns a type identifier which is a string this is only relevant because we need to be able to take and it is encodable meaning it can be serialized to bytes um and there's some some code in here to to deal with this but uh the way it works at an actual like over the wire level is you take this string and you write it into the message and then you take the um and you take the uh the and then you take the voucher and you put it in bytes and uh you put that in the message and then on the other side um sorry hold on i realized there's a lot of steps here um where are we manager sorry on the other side uh you essentially register types of vouchers that you know how to process when they are coming in um so basically uh you can you can so in the case of retrieval like and we actually have currently two different voucher types registered for our stuff right um we register a uh we register a storage voucher type and a retrieval voucher type um and you essentially you you pass it about your title you just have to pass it an instance of the voucher um using a little bit of a reflect weirdness internally but it's not particularly um yeah i'm not so worried about the reflect usage because it's uh because it's basically fairly um it's not used a lot so it's not very speed dependent so anyway i'm gonna just uh wait hand wave that um and then uh when you register a voucher type you have to register this thing called the request validator um what the request validator is going to do is it's gonna take an incoming request it's gonna inspect the voucher and it's going to say it's going to because it knows how to deal with that voucher type it is going to um it's going to look at that voucher and it's going to say based on what's in here this is or isn't a valid request for the uh for data transfer um in the case of retrieval there's a the retrieval provider is going to take that voucher which is a proposal they're going to inspect the parameters of that proposal they're going to say this is or does this does or does not meet my requirements uh for um uh for how i want to for what you know for serving this retrieval deal um and uh in the ca and you know assuming it does they're gonna say go ahead with this data transfer request um they can also when they do that there's a couple of things they can do i'm gonna actually show you what the validator looks like uh the validator has two different methods so just for push and pull um and this is relevant because like for example in the case of the retrieval validator it actually uh never validates push requests because retrieval doesn't accept push requests it's it's all about you know requesting data and having you send it to me um uh so anyway the for the poll uh it returns two values it returns uh an error uh if there is an error and there's a special value here which you can do that is a valid request but um you can return essentially air pause which means it's a good request i want to serve it but i also want you to start it paused um in any case that's that's relevant for retrieval for various reasons uh you may find it useful it also can return um this thing called a voucher result and a voucher result is basically the exact same thing as a voucher but going the other way it's basically just um you know encoding any additional data about why i accepted or didn't accept your request um and sending it back to the client this is actually something that probably wasn't in the original design but turned out to be super useful for um communicating back and forth over retrieval um okay so that's how you negotiate a data transfer and then in the case of retrieval we also need the ability to um essentially so in the case of retrieval you know i i mentioned this earlier we we basically the way it works is we send a little data and then we um uh we send a little data and then we ask for payment um and we pause it while we ask for payment and we don't unpause it until they send this payment um payment in the form of a voucher which is not actual file coin payment until it goes on chain after but that all happens after the retrieval deal um so the way we have the way that actually is implemented in data transfer is uh this concept of a revalidator um uh and essentially what this does is uh you essentially um a revalidator when it's registered uh will get a chance on as data is being sent to say to essentially pause it and say or you can actually pause it or technically terminate it although we don't use that that functionality um but you can pause it or terminate it and you can send additional information to the client um in the form of a voucher result as to why you decided to pause the request um and then the client has to look at that and they need to then construct a new voucher to revalidate the request um uh in this case uh it is a retrieval uh it's essentially this thing called the it's called a deal payment which is a thin wrapper around a payment voucher um and then they actually send it back to you by calling this function said voucher um and then when you get that voucher this method on the revalidator call revalidate gets called um and they look at that and they can use that and assuming it's valid they can unpause the request so you can see you have this sort of like abstract uh the data transfer is this abstract layer for negotiating a transfer that doesn't speak about the actual terms upon which you're negotiating it just you just have a mechanism for um essentially uh for you know doing all the different parts of negotiation including the initial negotiation and if you want a series of like renegotiations along the way um so that is how all of that works data transfers also have pausing and resuming um we don't currently uh have it set up we we we have a a bunch of the machinery in place to cause uh to cause it so if you shut down your node and restart it a data transfer would automatically resume like a lot of the machinery is in place but we have not yet actually enabled that because there's a few other things that we need to do um that i hope will probably ship before i mean that um though we've got a lot of feature requests we're gonna get other feature requests um so that is essentially how the data transfer layer works um i don't know how much more time i have i have a little bit of uh i think i have to 11 20 is that right yes though i maybe want to um uh maybe um let me let me just briefly pull up retrieval so just to say that these building blocks are here whether or not you use the retrieval itself um uh let me pull up markets yeah uh this is just uh i'm just pulling up the retrieval client interface this is sort of the top level um interface for uh making uh for using the existing retrieval software so all the things that use data transfer goes into this method which is retrieve and retrieve is essentially the main method for running a deal however before you make a deal you um need to identify a retrieval provider um and you need to um you probably want to query them for what the deal parameters they are asking for are um and that is relevant uh in order that you can propose a deal they're likely to accept um and right now for the most part if you propose by the if you meet the parameters that are in what they respond to the query the high odds are that they're going to accept it um there are so this is this find providers is essentially your discovery of retrieval uh other retrieval peers i want to be 100 clearer that method is very very limited in the current version um later you're going to hear about a gossip protocol for for maybe finding things a little more efficiently this thing will only return things you you personally have made storage deals for so it's not super useful in its current form um and that that's to some extent okay because we are working on you know some uh mechanisms for improving it uh you cannot currently uh do it with uh that you cannot currently find things to retrieve with the uh the chain only unless you personally know the um uh the payload cid of what you want to retrieve um and the so-called pc cid there are two different i'm not going to go into payloads and pieces just yet uh but that would that is a relevant thing to understand uh so query again you know it essentially takes the uh takes the payload the peer you're talking to this payload and parameters um parameters also can specify this other thing called the pcid um actually i i i think i need to rewind and talk briefly about payloads and pieces um which is a bummer because it's one of the it's a complicated concept it'll take a second uh so in file coin pcid refers to the um actually let me just start from the beginning there's so let's say i have a file like a system file like you know catpix.gif right um and i want to store it on filecoin um if i'm starting from a system file uh as opposed to existing ipld data uh the first thing i'm going to do is convert that into an ipld data structure we call this structure the payload um uh i i'm going to use in the case of a system file i'm going to use a chunk a a system called unix fs which is built into ipfs which will take the system file and convert it to an ipld data structure that can live in ipfs um uh and can be uh as a data structure we can put into file point however filecoin does not when miners actually store data they do not actually store it uh as ipld data they store it as these things called pieces and pieces are essentially flat bytes um they're they're essentially uh a certain amount of bytes that can be uh we can build a merkle tree around that indicates something about what the underlying bytes are so the way that happens so i have so um i start with a payload and the root of that payload the identifier for that payload is called the payload cid um uh and then i need to serialize it to uh these bytes on the other end and there's a reason we can't just take the original catpix.gif and serialize it there's a lot of reasons but in any case the way i'm going to serialize it is i'm going to build uh what's called a car file which is a serialization of an ipld graph um and then i am going to i do a bunch of other stuff i pad it and then i calculate this merkle root based off of the underlying data i'm just going to do a little bit hand waving and that is going to give me a thing called the pcid the pcid is a unique identifier for data that is stored in filecoin um it is sometimes referred to as compe but for the purpose of the dis discussion we have a pcid so um the reason this is all relevant um uh what is on chain is the pcid uh currently the payload cid is not on chain there is there is probably no plan to like require it on chain there is a plan potentially to put uh it in a sort of like notes field uh uh in the the pieces on chain and the reason for that is so that we can potentially index um payload uh cids that exist in the world and this is important uh for what you guys are doing especially if you're building any kind of retrieval index um so that is a thing that will eventually probably appear in the software we do not currently store it in the notes field but we are that is a thing we may do okay uh sorry the reason that is relevant why do you need payload cids in order to serve a retrieval um payloads uh retrievals are sent again over grassland grass sync is an ipld data format and in order for retrieval to work we need to be able to verify the data we are getting incrementally we do not currently have a format for doing that with pieces alone because again pieces are flat bytes we don't have a an easy way to like work with them directly as ipld data structures so we need to transfer payloads it's also helpful because payloads are much smaller but in but that's sort of a sidebar um so when i make a deal for a uh for a retrieval i have to know the payload cid it is also useful to know the pcid because the payload cid um could be a payload cid is not necessarily indicative of the underlying piece which may be uh where the the actual content of the piece uh cid may indicate something about a where it's stored how it's stored like um what stealing method it's stored with it it it it matters for various reasons in terms of reliability it is better if you know both and make a retrieval deal with both you can determine the pcid from the the chain um but you cannot associate right now we don't have an easy way to associate the two um uh however if you've made the deal we will have both on record uh in any case it's a sidebar and a digression that probably is a it won't seem super relevant until you get super into writing this software and it may come up um in any case so you can when you do this query prams you do have to pass this tale of cd we can't do a retrieval without one um but you in the query programs probably also want to pass the pcid which is which is part of the query params um but is technically optional um we will serve a retrieval without the pcid but it is uh it will be a slightly slower potential process and it um is a little bit more error-prone long story in any case so here is the retrieve command again it takes a payload cid parameters and this is a again like the query param struct the struct for these is in the types file but um they they have a but they they have both the um oh my god i see them over time uh it has both the uh the the parameters have both like this some some information about the piece it also has all the payment parameters how uh that includes how much i want to pay per byte for this deal and how often we've agreed that we are going to request incremental payments so that is a thing that both parties can't agree on the party the provider can also optionally set a price to unseal um and that is because uh the data um is because unsealing if they have to unseal is a um it's an expensive process um uh it's a cpu expensive process so that's that's a thing that they can set um if they want on pieces that they don't have unsealed data for um uh you're also gonna pass uh the the addresses this miner is the obviously the other person you're talking to uh we now take this thing called a multi-store um a retrieval can ultimately write to a traditional ipfs block store or they can write to this thing called a multi-store which is basically a way of isolating the data for where for like that you're retrieving so you put it in a place where you know only the only thing in that block store is the result of this retrieval i'm not going to get too too deep into that these are the basic uh again these are the basic um functions um the way you know uh what's going on with your deal is you subscribe to events um this will send you basically a torrent of information about what is going on with your deal um uh and the simplest thing you can do if you just wanna know when it's done or that it failed is you can rate wait for a finish event or an error event um and that's how the code and lotus works with it um i'm going to skip these i think i'm over time i think i'm going to just since i've uh uh [Music] since i've gone all uh all over the map but over time i'm gonna just take questions yeah i think it's a bit a bit fine to take very long depending on on on questions my sense is that uh folks need precisely this kind of in-depth view into the code and the interfaces and so on so and i know that um some other folks later in the in the program won't need their the whole a lot of time so i think it's fine for you to like you know take questions and maybe direct uh based on that um for sure yeah i'm gonna i'm gonna go ahead and just stop and take questions because i i think uh if i keep talking uh on my own i'm going to lose my train of thought a lot more because i'm running out of mental energy for it so so questions about any of the things that we have talked about uh let me let me rewind i'm gonna just look at what we've got uh [Music] hannah you mean adding a gossip protocol to lotus uh yeah that i believe is the goal uh eventually uh we do not uh just uh just in terms of well actually juan was not in this meeting so he may overrule but um uh but we for mainnet we may not get the gossip protocol in at the point we release mainnet now it's not a chain breaking anything so we can always release an update to lotus with this in without doing anything you know it's not a hard upgrade to add it um we are trying to nail down the core feature set uh so that part is you know like that's kind of our priority and making sure it's all stable and people can make deals on our network that we're gonna launch into the world um so we uh that uh so we'll see where that lands but yes there is a hope that we will get it into lotus eventually i think um though we also could um there's uh i don't know if we're gonna talk about this but there's a notion of a uh that i have in my head of like a retrieval minor uh software like package uh that it might maybe only go in there so yeah yeah probably that um yeah i think there will be a lot of tools that work externally with with lotus or around lotus or separately a completely independent that um that might use uh a gossip sub or might use other things to do all this retrieval so um there will definitely be a lot of virtual minor software that does not run lotus it might take pieces of lotus it might take pieces of the the libraries like this uh like the go fill markets uh components and we'll be like build independent processes um and then uh the in terms of gossip um i believe right now the uh the blocks themselves and the messages are are moving through gossip sub protocols and so the lotus does have the implementation embedded but it but it's not i'm not sure that it's exposed the same way that say on go if you fast you can easily like call one command and you can construct arbitrary gossip channels in lotus i believe that that facility is not there because um given that the gossip sub mesh is being used for like the critical function of moving around blocks i don't want people arbitrarily adding a bunch of other channels and passing them through um but but there might be it might be relevant to just allow you to do that if we can isolate the if we can isolate the meshes any other questions for hannah yeah i had one question from earlier um uh uh hannah um if uh uh if you just send a a message using empool push to a lotus node to um like collect a payment channel like you just invoke that it's like method number four i think um yeah does that does does will the whole specs actors thing handle all of the uh sending whatever fill needs to be sent you know either as a refund or as the final payment um like does that just happen automatically or what i'm trying to ask is are messages that come in from m pull push like treated differently somehow than yeah uh i believe that they're not treated differently you should know that there are now there's now a direct api method for for calling collect uh in lotus next um uh the i mean my yeah i mean i don't i don't know i'm trying to think about this like generally if there's an api method for doing the thing probably better to just call that um uh which i realized collect didn't used to exist um there's now two methods one is settle and the others collect um but i don't think uh but the actual transfer of funds will happen in spec actors as a function i mean in assuming you've called settle you've passed the the min settling of the settling height like it should just run i mean i've never never tried it directly but in theory yeah i don't know i mean i guess if we yeah i guess the note if it exposes them pull push over the api like you know you can definitely send anything to the chain that way um uh the the one reason with payment channels you might if you're using lotus and you're not implementing your own off-chain payment channel management um you may want to use lotus's payment channel uh methods because lotus has its own has a bunch of software for managing payment channels chain uh that software kind of sucks right now but we are in the middle of making it a lot better so yeah okay yeah our particular project can't use the lotus payment channels apis because we retain the users uh private signing keys on the uh on the user's machine and there's no lotus there i can i'll talk about it more later but but thank you helpful yeah that's that's helpful yeah that's actually a good point uh the though that might be an interesting thing that we should talk about internally um because like when we we're currently when you call collect now um on the api it's gonna look for a payment channel and you know market is in you know off chain is collected so um uh so we may it's actually a good it's a good use case that we should think about in terms of how we how we write those apis so yeah um so i think it would be trying to just defer to ample push if you just want to interact with the actors yeah other questions all of that information was like so clear and simple enough no it totally is not anything how's the parts cool together all those things yeah my guess is that uh people will kind of refer back to the video and then some more questions will emerge and then you know if we folks have questions uh working on on because we'll definitely just ask them in the retrieval channel um and and they're hannah's their other folks are there so um we can definitely kind of answer them there um and especially as people kind of start using things like graph sync and the data transfer uh module and so on um i'm sure that there'll probably be a whole bunch of questions on them for sure yeah yeah and i didn't i didn't get into this but there is you know there's a there's an abstraction and data transfer to try to handle the possibility of like other transport mechanisms if anybody ends up trying to do that like they want to implement their own transfer mechanism obviously we can talk about that um so yeah yeah but my impression is that like um uh there's so much awesome stuff in that in that module that uh that it probably it probably deserves like its own whole like talk just about that because there's a lot of different interesting ways of using it um and i think that whole thing eventually will make its way back into go ipfs yeah for sure cool um yeah definitely in the future we can talk about all right thank you thank you very much anna um uh yes let's check back on on uh the schedule so i just kind of adjusted uh some of the timing what i'm gonna do is i'm gonna give like a kind of like a lightning fast uh overview of what gossip sub is just to kind of set baseline uh for folks because the next two talks after that are going to be describing how to do referral market stuff on top of gossip sub and then that way um there are those kinds of basics there and then uh i don't i think the then the talk after that from from uh david and and elizabeth that chainsaw uh i think won't require that all the original time and um we also have you know kind of open time at the end that can get squeezed a bit so um yeah we should we should be even with inserting this kind of uh you know 10 minutes on a custom sub um we should be we shouldn't be too kind of off track in terms of timing uh if folks talking later had a very strict uh kind of start times and end times definitely just let me know on the zoom chat and i'll i'll adjust on the background now to make sure that that uh we follow that timing uh great so i will share my screen and we do have a break slotted for after this talk all right so this is uh going to be pretty lightning fast uh because i'm going to refer just back to a lot of the details will kind of become obvious through the through the next talks um and because uh there's already a lot of really good material out there um so this is mostly just uh kind of an answer to what's there uh so we've talked a lot about a thing called gossip sub and what that is is a specific implementation of a publish and subscribe protocol and um it's it's uh one of two in the whole lipid2p uh library and protocol uh and it happens to be used already in falcoin and ethereum two and i think polkadot and others um for moving around moving around information so maybe give some pointers to roughly kind of like what the puzzle problem is i'll talk a bit about the concept of implementation and kind of what what it's tuning for um and then then i'll talk about kind of uh how you might do uh kind of like a like a straw implementation uh version of how you might do retro requests over pub sub uh and then also how you might use that for for indexing information so the the um there's a docs uh website for lipitorp that has a really phenomenal uh kind of description of pubsub and how that works uh i'll be using most of that for for the sake i just want to mention a couple other resources first um there's a stack for gossip sub on on github and you can go check it out and this is uh has a whole bunch of details gossip sub moved to one point one because it uh so we had to go to 1.0 um and then we found and fixed a whole bunch of really interesting um uh security uh uh issues in just possibly general is an extremely difficult kind of protocol to to make robust in kind of a world with very sophisticated attackers and so on there's been um you know decades of work in this and most published described protocols live within um a fully trusted regime where there is no kind of adversarial parties inside and so the whole process of trying to take possible protocols and get use them outside in kind of a in kind of the modern peer-to-peer and modern kind of blockchain environment where you have a lot of parties that might be kind of attacking those protocols uh it's gonna mostly uh it's pretty new and so uh there's all kinds of very interesting security questions security questions there um and so we've done a bunch of interesting work here and i'll refer to it and i'll show a little bit of a snapshot of what that that kind of work is um but it kind of tunes for different things than say then say latency which is why gossip sub might be a good thing in the short term but in the long term it might be it might want to be replaced by a different pulse of uh protocol there are a bunch of talks already on puff sub uh i'll plug uh three different ones one from uh raul called demystifying gossip sub this was given at def con 5. um there's a link there i'll post the links in chat afterwards uh highly recommend just go go watch the whole thing um it'll give you a very you know kind of in-depth understanding of how all of how the protocol itself works how top topics work and so on then after that there's uh i talked from uh from david uh talking about uh the hardening extensions that we added to gossip sub to make it good for for 500 and ethereum 2. this is specifically dealing with um how you think about using a pub sub protocol for block propagation and so block propagation is a very specific problem within within blockchains where you want some very hard guarantees around um the kind of propagation time of of the of the of the of the block uh across the whole network and um if parties in the middle can can start uh suppressing the blocks or things like that then then those kinds of attacks can be used to to break the consensus or to attack at least attack the consensus um and then there's another talk uh from janice uh on which is kind of uh in depth in any detail about kind of uh this this report that um the team uh prepared around uh kind of all of the different extensions going into gossip sub i think this one it's not recorded online uh we have the slides and i can happy to um to make this available but uh um i think this one will end up getting recorded and put online later on so yeah i'll use the just the website the lippy website because that's just a very good uh description and you can you know refer back to it so if you go to the website the look of your website you can click on docs you land on this site and i think within concepts there is publish describe and here um this kind of goes in depth into the whole um uh the whole thing so the the basic idea is um you have you know some kind of network of parties and you want to allow parties to subscribe to a specific topic and then you want to allow some parties to publish messages uh and you want to make sure that all subscribers to that topic are indeed receiving receiving that message so you can think of that as you know there's some topic and you want the parties that are sending that message or the publishers that kind of propagate a message out you want the message to reach all the other parties described quickly with certain kind of guarantees and so on and the whole universe of puffs up protocols uh trade off those guarantees and trade off performance and so on to achieve certain kinds of certain kinds of networks this problem is pretty easy in the small scale so when you're dealing with tens to hundreds of of nodes that's not a big deal when you want to scale this to millions of nodes or in networks that have high churn or you know that have security uh problems and so on this becomes a very difficult uh and very interesting problem and this is part of the p because um a lot of the a lot of applications in general you use pub sub as a primitive uh and when you start building peer-to-peer applications and especially things in things like ipfs and things like blockchains you end up use needing this as a primitive in a bunch of different parts of the stack but when you need it different parts of the system might want to might want to use different protocols different underlying protocols because the guarantee is required different and so one of the goals of the vp is to kind of create this this kind of really nice set of set of abstractions that allow application builders to swap out the underlying implementations to tune for uh to tune for the guarantees that their system requires um this is an example right now the p has two such pop sub implementations one is called flood sub and one is gossip sub um flood sub is just a very simple protocol that just floods the messages everywhere and that means it's very chatty so it's kind of like i think of it as a very trivial strong implementation of a pub sub where all the parties that are subscribed to a single topic just propagate it to everybody else probably get messages to everybody else and and that might be you know kind of fine in the smaller scales but certainly as you grow to millions that the amount of kind of bandwidth overhead for using that would be would be pretty bad however it has good guarantees in terms of um making sure that parties do get the message and now gossip sub which is kind of the the main implementation that that uh i'm describing now that i'm going to be describing now is uh uh a an implementation that kind of tunes for uh certain kinds of um uh wants to reduce the bandwidth overhead but wants to do so without kind of losing uh losing certain guarantees around um you know message delivery and and so on and so you know there's a bunch of like you know different kind of design goals when building these kinds of protocols from you know reliability speed uh efficiency and so on and um you know this this whole kind of description talks about uh just the possible problem in in general but at the end of the day you you kind of have some large mesh of nodes that is all connected and within there you you have some subset of topics right so different different nodes are going to be interested in different different topics and there's a whole bunch of you know parts of the design space that uh put different um that approach this problem differently where for example some some pop-up protocols will uh make sure that routing only happens within within parties that care about the topic or some other protocols might might recognize that some parties might be interested in topics but are not directly in the same topic but are not directly connected to each other so actually being able to route those messages through uh becomes becomes pretty useful um and so yeah this this whole uh page goes in detail as to how you know how the messages kind of flow uh and get forwarded along and then you know kind of describes um this kind of builds up to how gossip sub works in terms of um gossip sub uses an abstraction of uh sending some control messages that that signal what messages you have or haven't seen because those messages are a lot smaller and so that allows um that allows myself to achieve much better kind of bandwidth uh uh bandwidth guarantees and so on uh without um uh without kind of uh losing a lot of the kind of uh quick uh you know guarantees on on the speed of the propagation of the whole the whole message uh and then of course you have other kind of properties like being able to choose the fan out of the of the uh of the network uh you know being able to to um you know this lets you tune how quickly um how quickly in in a large network um the message might might probably get through to other nodes uh and and that trade trades off the the um the again the speed of propagation versus the bandwidth uh uh the bandwidth waste cool so the let me see if i can uh so one of the sets of interesting problems in um in in in in file coin um and this applies for ethereum two and so on is that when when you're using this kind of protocol for for moving around um moving around blocks uh any kind of adversary that can slow down or just completely stop the propagation of messages can really affect the the consensus of the network so it becomes very important to kind of have uh protect against certain kinds of attacks and so um kind of the there's a report that kind of got put together recently um you can look at it look for it in archive and this kind of goes in depth into all the different kinds of problems that you might you might worry about in these kinds of networks for uh for this you know can for this domain of problems around uh message propagation um it goes into kind of how the how gossip builds the dash um goes into kind of how uh roughly works uh how its scoring function work so gossip uses a scoring function for uh for deciding which which connections to to uh to use for propagating the message versus just control or which connections to actually disconnect from and um and this also goes in depth into into a whole kind of validation using using a whole lot of of testing on on this this tool called test ground uh that allows us to to simulate you know pretty pretty large networks and kind of expect certain kind of propagation delays and so on and so this is um kind of gossip sub compared to the to the propagation uh times of uh the bitcoin gossip uh structure and and ethereum ones uh gossip structure and so these kinds of results are extremely useful for both falcon and and uh and ethereum too uh and so yeah you can you can dive in depth into this and it kind of goes into different kinds of attacks and so like the the good news here is is gossip is it performs better than than the other two um and so it's a really good choice for for for five minute theorem two uh and and it kind of has has good properties around uh you know delivering the message across the entire network fairly quickly like within within uh single seconds uh and so on so that that gives us a pretty and that's kind of like a the in this case the problem for is around block propagation or propagation of messages so transactions and in a in a blockchain um now we can use the exact same kind of mesh for propagating retrieval requests but uh but now that seems kind of kind of crazy because you why would you want to send out retrieval requests to the entire network uh you probably don't want to do this but now now there's a way of using pops up a possible mesh uh to do this and so that's kind of what uh where kind of the idea for for doing this with retrieval market came from um so trying to do um trying to do retrieval like this kind of like a straw implementation version which you might say hey you're going to have like you know a single topic for advertising for the entire network and this is probably fine while the network is small right so even thousands of nodes trying to to do this uh it'll it'll probably okay it'll start degrading once once you start getting you know 100 tens to hundreds of thousands and so on um but you can do something pretty straightforward where um hey clients create a some kind of refuel request and they signal the cid that they want and they're interested in and they send it along uh in in the pop submission so it kind of propagates to neighbors now when retrieval miners receive this they look at the request and they can decide whether or not to propagate it through and so they can first of all look at the requests see if the cid is content that the virtual minor has and if so um contact that data that client and then send in the content and kind of suppress the the forwarding of the message um otherwise if the virtual manager does not have that content they forward the message through to the network and so when what you end up with is a a uh a structure where um this can look again super naive right but but if this kind of um request is going through um the as the request is going it's going out uh it'll hit a set of retro miners that have the content and the message will stop propagating at that point um now that's like a in theory in practice uh if this mesh is uh that will likely work with if if the message finds its way through a bunch of clients uh then you might actually get propagation to the entire network and that's not not what you want so potentially a different implementation would use one topic for retrieval minors to propagate messages to each other and one topic for for clients asking things from from mutual minors but clients not participating in clients not forwarding anything so clients are only requesting and not forwarding stuff uh and only reveal minus forward to each other uh and then that way you get you get a better property where you know you won't actually get this request to propagate to the entire network um you might you might also employ different different kind of strategies like say hey what if you create topics per region and then that way you're bounding where you're headed uh where your message is headed so for example you can do you can define a set of regions and you can define them based on kind of latency bounds in the in the network and then clients have a you know some strategy of saying first try the closest region and if the content is not there then you ask kind of like the you go a region larger right and it has this nice recursive property where as regions get large and dense you can subdivide them so continue to divide them and this kind of relates back to what i was talking about earlier around kind of having this kind of war noise style subdivision of the world over time as the as the network grows this definitely is a little bit clunky because uh you have this question of okay well um you ask the closest region you maybe expect the diameter of that network to be maybe within within one second uh then you wait a second if you don't get it you ask the next region and so on and you kind of have to scale up the the um the times there and and so on it's definitely like chatty it's wasting bandwidth and so on um but it might be a way of using the existing primitives already there to get this kind of scaling to work uh definitely not the most elegant definitely not the best not the best way to do it um and you might but but now if you if you probably a much better way of doing this would be to to actually hack into into the the guts of gossip so itself um and then start thinking about the forming the mesh and changing the scoring function to take into account latency uh if we if we have certain guarantees about how the mesh itself is formed such that you are you have a very like a high likelihood that the um that uh all the parties you're connected to are actually very close to you um which is not what you want for say security properties um uh but but you might want this for retrieval then then as you're propagating messages out you can you can send messages with a time to live where you know you as as the message is going out you kind of are decrementing times time slips and you get a very nice property that is similar to to kind of multicast and over over large networks and so on where you can send out packets these kind of requests over over this this mesh um and those requests are not gonna actually expand to the whole network they're only gonna go one or one two or three uh layers steep uh depending on the choice and and that way you can you can only hit the retrieval minors that are that are um fairly fairly close to you and you kind of you get that guarantee out of the or something closer guarantee there um out of kind of the the latency oriented oriented mesh that would definitely require a lot more work it's diving into um into the into the details of gossip sub and tuning the tuning the parameters and so on you might end up with um less less reliable guarantees around um the the likelihood of this mesh staying connected across the world and so on because um because you don't get these kind of like long long long pathways to other parties uh elsewhere in the network uh cool so one other one other part part of this is that if you have this mesh that is through which you are um sending all these requests then you can also use use that to to index information right so a party sitting on this mesh can see all the requests flowing through and then can aggregate that information and start building kind of an index real time of what's being requested in those corners of the of the network so so that's happening then you can imagine having a number of index or nodes that are going to spread out across across the mesh collecting information of what's being requested aggregating it and sending it to each other so then parties can then reason about what's becoming what's becoming hot in certain regions or um or kind of what what distribution or requests look like over time and so on now this of course is terrible for any kind of reader privacy right like this this would be kind of building these access logs of of a ton of stuff that is being requested um and so there's there's some questions there around the trade-offs between being hyper-efficient and delivering content versus uh kind of privacy and so you know exploring how to how to do this well how to do indexing the right way such that it doesn't create like this this problem index of of um that kind of breaks real privacy uh would be really useful but but uh won't uh right now we're kind of in a mode of just getting the retrieval to work really really fast uh thinking about kind of the the um preserving reader privacy and so on it's kind of like a larger scale longer term thing cool that's uh if there are some like questions and concepts if i can cover them otherwise i can we can move move on to them next next thing cool don't see don't see questions so um this is the current uh schedule so um i think there's some timing let me adjust it so we ended up getting this excited at 45. so there's a question now of immediately jumping into um into the break which you know kind of following the right schedule or um or or having the the chainsaw talk uh curious what what folks want um uh david and others if you if you are kind of tight on time we can uh just jump straight in or we can go into the break yeah we're certainly very flexible uh mike and and uh and robert uh who are the next presenters are you fine with uh going into the break and then kind of just moving i'll kind of adjust the schedule a little bit and uh to reflect that or would you or are you tight on time i don't have any constraints anything's fine yeah i think going into a break now makes a lot of sense great perfect so let's uh let's go into the break as um a schedule here and then i'll move the stock uh to go right before we'll start with that and i'll adjust the times thank you very much see you in in 10 minutes would be perfect for uh zoom to have elevator music if only come on all right welcome back everybody from a short break um next up on the schedule we have a few people from chainsafe we're gonna be presenting let me just double check i get the names right david i think you're one of them right yeah and elizabeth david and elizabeth awesome cool i'm going to share my skin here hopefully you guys can all see that um so yeah um thanks so much juan for inviting us here today to talk about this um we have been working on some kind of preliminary stuff for enabling secondary retrieval markets and so we're certainly very excited to be able to share that with y'all and hopefully continue the discussion as to how what this is really going to evolve into so i'm david i'm also joined today by elizabeth we're developers of chainsafe and we've been working on this project the last few weeks um so presently when we look at filecoin this is really what we see is that clients are interacting with the miners on the network to retrieve and store data and so what we really want to do is try to change this model a bit to allow other parties to participate in this and kind of create this secondary market layer that incentivizes them to do so so that well there's a number of benefits to that um for one we can reduce the reliance on storage miners and so that they can put their bandwidth to better use for you know storage operations specifically it also allows participation from providers with uh with lower storage capabilities um probably um possibly higher bandwidth lower latency this will also improve availability of data on the network as you have more participants able to serve it up you should be able to do so in a more optimized manner by doing it in this kind of secondary layer we're avoiding adding additional complexity to the core protocol which is definitely very nice try to do this off chain as much as possible so that that could be used for uh more consensus critical things as well this kind of creates an opportunity for data to exist and be exchanged that may not actually be stored on filecoin so there's certainly a potential here to kind of certifying this popular but maybe nobody is actually paying to have stored at the present moment so looking at some of the kind of base requirements to really make something like this possible um one of the big things is content addressing um which allows us to you know verify that what we're requesting is what we're getting and do so in a secure manner it also provides global addressing which is super useful when you have you know these large distributed networks and everybody needs to understand really uh what is being requested as well as a data exchange protocol and so specifically allowing the exchange of data in a way that facilitates payments and protects both parties from malicious actions um and so those are two things that we have right now um some of the more open questions is a discovery mechanism for the clients so ultimately we want to be able to determine the best retrieval provider for a given request as well for those retrieval providers we want to give them insights as to what they should store and and whether or not that's going to be profitable for them and definitely optimizing for that can take many different forms so we've been working on this reef in particular definitely please everyone check it out we would certainly love to continue the conversation with you if you're curious playing around with it or if you have features or feature requests or ideas definitely please reach out to us some of the goals specifically for this project so the the big one is really allowing this additional discovery mechanism um that allows these kind of secondary retrieval providers to respond to requests when clients have them we also want to make sure that we can inform those parties providing the data as to what could be profitable certainly um you know this is a huge variable um and and there's certainly many ways to try to tackle this um but just providing insight i think is is definitely one of the core requirements um and then a big one here is doing this such that uh miners can be exclusively retrievable miners so to not depend on any of the kind of um pieces that go into these storage markets and i guess another big one here is certainly to do this all with everything that we have and to kind of try to stream like this so that we can start to explore what this will look like further down the road and really give an opportunity to the community to experiment and and play around um so to give you a high level insight into into what we've really built here um a client in one of these kind of like provider networks will be able to submit a query to um their peers uh those peers will then use the gossip sublayer to actually gossip that request and ensure that it reaches other providers and then providers who are able to serve up that data can respond directly to the client with their pricing parameters and the client is kind of free to choose uh which of those it wants to continue with and it can do so using the existing data exchange layer that is provided by the uh kind of core or the go film markets implementation presently um so to look a little more into the fine details um so the two kind of components here are the client and provider the client is ultimately uh submitting a message to the gossip network um which contains the parameters uh for what it's looking for as well as how to respond to it it then accepts response from providers and then through some mechanism that can be acted upon using the existing data exchange protocol on the provider side it's really just listening uh two requests um we've defined an interface here which is for the retrieval provider store which is really just the mechanism that determines whether or not it's able to store that file um there's certainly a number of things that could back this um for example you could take an ipfs node perhaps and put it behind this and then make that a data available for retrieval through more incentivized mechanisms um and then at the bottom here we have the query response so this is very similar to what uh hannah mentioned in terms of the retrieval parameters in gofill markets and this basically just states how what the offer from the provider is in terms of pricing definitely one of the most interesting questions here for us is kind of how you optimize for profitability or availability um you know for a provider to be listening to requests and just kind of blindly fetching things that seem popular may not end up being economically viable because they need to then consider the cost of retrieval for themselves to first make that data available there's definitely also other methods that we could look at for kind of how you populate those data stores um for example if you have something that you know is incredibly popular like let's say you know the top 1000 wikipedia pages it may make sense to just kind of like provide that without any further consideration for what the economic incentives may be [Music] one of the big challenges here is definitely that [Music] the parameters today may look very different from the parameters tomorrow and certainly these networks are very open and free and we need to constantly be considering what the kind of economic incentives that play are you know something may become popular in canada tomorrow that was popular in the uk yesterday and kind of like how we adjust for these these changes um and a big one um certainly when we're looking at things like latency is that the locality of a particular provider can affect how desirable is um furthermore um sorry i just lost my train of thought there um for latency this is certainly a huge factor you know you want to be connecting to the peer that can provide retrievable staff as possible but it's also important to remember that the perspective of any one provider on the network is somewhat unique it's you know if you observe from any given point in the network you may have a very different perspective and so it's important to be careful when generalizing um so to try to kind of facilitate some some early exploration and ideationists what this could really be in the future we've implemented to do fairly simple measures to try to get a sense of what the provider's perspective is the first of those is a very simple cache that just provides the you know and most frequent requests using an lfu eviction algorithm and so this is just kind of a very naive perspective from the provider's point of view of what is popular or at least has been throughout lifetime and then we've also kind of exposed a subscription mechanism so that this can certainly be built on top of um by adding kind of like a another layer here we can analyze the requests as they come into the provider and perhaps try to determine at what threshold we then attempt to retrieve that file from the network and and make it available and this is certainly where a lot of questions still kind of remain and there's certainly many different avenues that we could attempt and it's definitely going to be really exciting to see what the community kind of contributes here so that's basically everything we've been working on definitely please reach out to myself or elizabeth if you have questions or if you're interested in getting involved if you want to make use of it we would definitely love to chat i'm going to pass it over to elizabeth who's going to do a brief demo of kind of where we're at right now um and then i guess we can bring it back for some questions cool hey guys um yeah so i'm just gonna do um a quick little demo of secondary markets so all right can you guys see my screen cool okay yeah so um what i'm gonna show so far is so we have a provider integrated into lotus this is a kind of preliminary integration so what happens is that when you start up the storage miner it's the secondary provider also starts up and as well it's able to access the the files that are in the lotus clients as well so it uses that to um check for whether it can provide the files or not so yeah and then i'm just gonna show the client doing a query to that and receiving the response so yeah i'm just going to start up lotus now so this is just a local devnet based on just like this the instructions in the docs um so yes this is lotus this is the storage liner um yeah okay so so here we have this log for um started the secondary provider and we have some addresses um that it's listening at so i'm just gonna keep those there and then i'm gonna go into the secondary client um make the client and um okay so i'm gonna just paste one of these addresses here and then i also need to import a file into lotus as well that so that the provider has something um so notice and import i'm just going to import some text file um so yeah so this is my cid so yes i'm just going to tell the client to connect to the provider and then also query for this specific cid so yeah okay queen for payload okay cool so yeah so what happened was it was querying for this cid and then got stream from the pier um then it received a response for the yeah the cid that it asked for so yeah you can also see um i guess yeah so yeah so i got a response and then it has the parameters that it can um yeah that it can then decide whether or not to proceed with this retrieval or not so yeah that's yes that's where we're at so far with everything so yeah in the future the integration is probably going to change um this isn't like what it's going to look like in the end in the end we want it to be more into more independent from the sword liner um yeah right now it's like reliant on the the file store that's in lotus so yeah that's yeah that's basically all cool any yeah any questions okay this is awesome thank you cool yeah it's cool i didn't i didn't realize you guys had already gained when i did this that's super cool yeah yeah yeah it's definitely very preliminary but um it's cool to see and and yeah we'll definitely have to try to decide if it makes more sense to continue development as kind of a separate entity or to really move um one quick question i wonder if um you can can you do you have it such that like um and i don't know if this is double now or not but uh just being able to see kind of um say like a set of like five or ten different real minors where only three of them have the content uh and then have to have like that same that simple working um i could do that with just the provider running on its own probably not in lotus because i haven't set up multiple lotus nodes locally so yeah like i could i could show that if you would like i guess we still have time so cool totally up to you by the way don't mean to put you on the top spot of like creating a new number that you haven't played around with i mean yeah i'm happy to do it um but yeah i have not actually yeah i don't think i try this but i think it'll work so yeah um i don't know if we have time i can do this okay cool i'll just yeah i'll just go ahead then see what happens um okay so so yes we also have um like a provider um that's standalone as well so let me just get rid of these for now um okay um make this bigger i guess i can do like a few okay all right all right um okay so so yeah so for the provider that we have that's standalone um we're able so right now it just reads what files it has from just like a json um it doesn't really uh what's it called like yeah it doesn't have a actual like box or anything behind it um so provider sample data okay so okay so yeah so there's one cid in here so far so i guess i'll leave it in two of them and then just delete it from the others i didn't copy that before i did that whoopsies i think he might be on on the left bottom screen i think there's a bunch of cds yeah yeah i have some cds but i just need to make a file that has cids um okay so sample data with cds um okay cool all right so yeah i guess i'll just take this one from before right okay so triple provider um and then all right so just one i'm gonna just connect them together just to make sure that they all know about each other it'll probably make this go nicer okay [Music] okay so i'll do these two then with no data oh yeah so yes that's what data it has here uh cool okay providers are set up so cool okay um so now [Music] clients so i guess i'll just pick any of these because they should all be connected now um oops all right let's see what happens okay query okay nice yeah so it got a response from this this guy uh what is this qt at the end yeah so this one and then also 5d so yeah this one so yeah that was what should happen which is good yeah so yeah i thought yeah so it's working yay that's fantastic yeah cool yeah i guess yeah is there anything else that you'd like to see that was magical this is really cool yay i'm glad you like it i really great work guys like uh come to life so it's awesome um i just wanted to ask about uh um maybe you could just explain it again david i think i just didn't didn't get the first time like are you saying that um the the the most recent sorry it's not ally but would be which would be retained by that minor or do you mean that other miners would like um go out and fetch content uh based on what sids they've seen recently and then retain them like that yeah um i mean right now it solely exists as kind of like an observation um but yeah certainly it could be naive in that you are constantly storing what is most frequently uh requested um but yeah that's not necessarily implied by the present implementation okay got it got it okay thank you this is awesome thank you thank you so much this is super cool thanks cool so uh since i'm hearing no more questions and i think we're uh up for the next uh the next slot um mike uh uh you wanna take it away yes one second let me share my screen and do all the usual preliminaries um okay so uh hold on i gotta hide the zoom controls before i lose control of them uh okay so um gee and i have been working on a project that we're going to present i'm i'm going to just describe a little bit about it and then he's going to do a demo then i'm going to do a demo and then we can we can take questions or we can we can talk about anything uh but the basic idea is it's um very similar to what you just saw from uh chain safe uh to it's to build a peer-to-peer network of retrieval clients so the same is the same as what they're doing uh however we want ours to run entirely in the browser um and uh i'll talk a little bit more about why that is so uh the browser retrieval client is this green thing on the left so the idea again it's a peer-to-peer network uh of these browsers that that are offering and uh providing retrieval services uh they talked to the file coin storage network and uh they talked to something called pseudo oracle so let me just explain about the connection of the file coin storage network briefly um when we do everything in the browser there's some limitations or opportunities depending on how you want to look at it first off we don't want to have any lotus node uh required we don't want to require the user to run a lotus node either on her local machine or on a cloud box or whatever i don't know i'm sure most of people on this call have played with other blockchains i mean it's always the case that to run a full node it's like you've got to first wait for a week for it to sync to the chain and you know there's usually like a lot of you know set up around that and um we want something where people can just come in and just go just start either doing retrievals if if it's an end user and they would just want to fetch some content from a competitive marketplace where prices are being driven down because of the competition between different retrieval providers uh or if it's a retrieval miner who's on the other side of that market someone who wants to provide retrieval services for uh you know to in order to generate income and so uh we want people to just be able to come in and go uh we want them you know retrieval miners especially they just leave a tab open uh you know or just leave an extension running in the browser there there isn't any other um ongoing work they have to do that would be the sort of the ideal scenario um and we have this notion of customizable strategies so um different uh dif different retrieval minors this is for minors different retrieval minors might have different strategies about how they're going to uh most successfully you know generate uh income from providing retrieval and um so we're as we're trying to avoid uh dependency on a user run lotus so we have this notion of a public lotus uh cloud lotus as it's called here and the cloud lotus can do some basic services for you it can't do a whole lot because it doesn't have your private wallet keys right so those are retained in the browser that means you have to or rather the browser application logic has to create all of the messages to the blockchain sign them in the browser and then it just submits those to the cloud lotus for publication on the chain um the syd oracle is uh so hannah talked earlier i wasn't going to spend a lot of time on seed oracle but i just want to tell you what what it is because this diagram is sort of encompassing everything we're building to try to support retrieval uh hannah talked earlier about uh payload sid and p sid and there's sort of this discoverability problem where if you weren't the original party who stored the content uh you don't have an easy way to find out what the payload sit is so there's a pr now uh i don't know if it's merged yet but i think it will be soon um that adds the payload sid to the original storage deal proposal which also contains the p sid and it contains a reference to the to the storage miner and so what sid oracle does is it's just really simple program um it just walks through the blockchain and then just keeps up with it and it's it's just reading every uh every message on the blockchain and when it sees the storage deal proposal it saves that tuple of payload sid pcid storage miner it just saves it to a sql database and then serves it up on a public http api so okay with that introduction i'm going to turn over to gee who's going to demo our browser extension and let me stop sharing hey guys let me start sharing my screen then [Music] okay can you see my browser yes cool so this is this is what the extension looks like right now we have uh i have a few tabs right here but this is the home screen and what happens is as soon as the browser starts it connects to the peer-to-peer network and actually you can see here they have my own extension has three peers connected to it so um the first thing we can do right now is just uh upload a new file to this uh known seeds that i have so if i upload my own file it shows up here now i have this seed that i know that i can provide to others and this it's just really a local uh file transfer we use a unix effect fs to actually chunk uh split the the files in chunks and store them in the browser's index db so it all started in blocks and another thing i can do is just query for someone else's uh cids uh and this is one that mike has on his own computer he's running the same extension and i can query for this cid the download process starts and soon i have the same cid here and i can now start providing the same file to others or i can just since they are it is stored in chunks i can choose to download it to my own computer uh i'm not sure if you can see the dialogue here but uh it's a dialogue uh yeah it's a download dialog i can save the the file to my computer i can open it and do whatever i want um for that we have like a couple options we can configure uh the handvu ip or our lotus settings wallets my private key and stuff payments interval and increase for the whole protocol yeah i'll pass back to mike and he'll explain what point we are on and what's missing from this extension awesome thank you okay okay um all right i'm back uh can uh can you see my slides sorry i can't see anyone yes yes okay thank you thank you uh yeah that's the unmute delay i guess um yeah okay so here's basically where we are in terms of progress on this um i think we we've made a lot of progress and then i think we've gotten we've struggled a little bit to find a way to get messages signed messages like correctly formatted uh signed messages with correctly you know serialized uh parameter strings i actually published onto the chain um but the you know the first part of this is looking pretty good like um uh uh i mean this is algae but you know he's gotten all of these parts working and now we're just trying to figure out uh how to create these on on-chain objects and invoke methods on the the actors uh to manipulate or respond to our objects we create and stuff like that um there is a piece of voucher handling logic you know like um uh making sure that the next voucher that comes in is higher than um uh you know the previous ones and stuff so there's some battery handling logic that will be purely in javascript that we haven't done yet um and then there's a retrieval from storage miners but it's it's really that that third from the last one the on-chain stuff that we're um kind of stuck on right now and so zooming in on that um uh our progress is okay but not great uh a little bit lotus is kind of refactoring some stuff with payment channels so it's been a little bit hard to kind of validate some of these things but um creating a payment channel seems to work there's some not a hundred percent of the time so we're still investigating that um settling and collecting are in flight like i've implemented them um in the uh we're using a rust library which compiles to wasm so i implement those but i don't actually have a way to test them yet um because i'm waiting for some refactors and lotus to occur uh so i can't can't check those off yet and then uh you know the rest of these things are the other on-chain events and they're not uh not complete yet um okay so i was just going to talk about some of the other components that we've built we'll take questions at the end uh this won't go on for too long but i was just going to quickly talk about a couple of the other components that we've built um so one of them i mentioned this the sid um i'm sorry i i sometimes call it sid index or other sid oracle is its uh correct name so there's a typo in the first bullet um but for forseed oracle um i create a lotus client rust library um it's basically a um a library that can uh walk the blockchain from the fir you know from height uh zero up to uh the present height and then keep going or whatever instructor to do and um it can it can uh it's a dependency injection thing so you give it logic for what it should do on each block on each message within a block um and it's uh what sort of whatever you tell to do it'll do um it only implements a small subset of the lotus api just because this is all that was needed for the sid oracle tool um uh yeah it does some higher level decoding but it can't decode every possible like param string because there's so many there's probably like hundreds of them um and they weren't needed for pseudo-article um and yeah that's this is repo so let me i just jump over here and do a quick demo of this so this is one of the example programs that's in the repo so let me move these controls you can't see that um okay um but this is uh this one is called print everything and what it does is it just iterates over the blockchain so this is a free function exposed by the library uh it iterates over the blockchain and then i've provided three callbacks here uh for what to do uh when it reaches a new tip set height uh it just prints out what height it's at uh when it when it encounters a block within that tip set height because there can be multiple uh tip set blocks that's the that's the tip set uh set part of it um it'll you know it'll again just print out the block and then when it finds a new message uh it'll just print out uh the message uh structure with dashed lines between it so let's take a look at that um just uh oh oops that was the wrong example sorry uh okay so it's iterating through blocks hasn't found a message okay so now it's found a message this one only go it stops at five blocks for this purpose of this demo but um so you know here's a message it found it's bounded between the dashed lines and you can see it's just dumping the fields um uh it's uh it's not decoding the param string so um there's some things that still need to be uh decoded that aren't uh a lot of things actually um and then uh this particular one he was able to find a receipt and sometimes it finds messages that haven't been processed yet so they don't have a receipt yet this one it did but again it doesn't decode all receipts uh only this small subset that were needed for the pseudo-oracle tool so i just want to show sorry let me just yeah i just want to just show some of the repos that we're working in uh we would love uh contributors like we would welcome uh contributors who want to get involved in any of these projects uh so um so this is the one i just showed you the um lotus the library for the lotus api client and you know it's um this one doesn't have a status indicator but it's done in terms of what's needed for sid oracle sit oracle is over here is there's little explanatory stuff here but basically i wasn't going to demo this one but it's intended to just run on a server and just look for those p sid payload sid um and minor identity mappings and then just put them into a sql database uh it's using like sql lite right now i think to deploy this we'd put on something more scalable like amazon rds uh but you know that's the idea and then there's just a would be a simple node.js like a you know like a five line like node.js app that just all it does is have one single endpoint and it's just like a query for some sid and it will return you if it can find it in its database it'll return you that three-part tuple um of everything that's mapped with uh we get a little fancier sids expire over time because storage deal uh deals don't have infinite uh duration so you know there's some enhancements that could be made around that um but that's that's where the tool is now um i'll show you so the the browser extension um we you know i think we covered this in the slide so i won't cover it again uh there's that diagram again and uh but yeah this is this is the repo for that one if you want to check that out um oh this is a fork of so this is how we're sending messages to the chain or generating and signing messages to be sent to the chain the cloud lotus is the way is the means by which we send them but in order to generate them and not have the user's private keys ever leave his machine we are using a library from zondax which i made a fork of to add payment channel functionality to and i think i showed this before um so we don't have we don't have much of the functionality actually working yet but uh and this shows a little bit of the flow this is the flow that lotus uses uh that i our thinking has been to try to just emulate that um and yeah again if uh if you're particularly good with uh serialization of and deserialization of rust uh structures in especially if you're good at it into sibor um yeah you uh we would love to have your help uh so you know feel free to contact us and um oh this is just a demo program that works out our extensions to the falcon signing library so um not much there and oh yeah covered that and covered this adorable so i think that was every yeah that was everything that i had planned to cover so let me stop sharing and are there any questions or any any thoughts this uh inspires in people that's really cool really awesome thank you maybe one question would be um how do you envision the the story so um kind of like flagging the cids kind of by hand will will um get cumbersome in that um if you want to plug in like um uh like if you want to run just this extension in the background uh you could do it a couple of ways one is it could look at a local ipfs node and kind of redistribute everything that's in there and like be willing to kind of serve out those requests there or it could um or it could you know kind of have its own independent cache um or it could kind of have a strategy that you know is willing to grab content that is willing to kind of offer some space and grab some content that other parties tell it is good um i'm just curious how you've been thinking about that and how how they might evolve yeah yeah yeah so the the local ipfs thing that's an interesting idea i actually hadn't thought about that one yet um so i need i need to parse process that one a little bit but um the way i kind of been thinking about it was with with the customizable strategies you know you would you would have a miner who knows that okay at a certain frequency if i go to this url there'll be an update to some piece of software that's stored on file coin and i can get this the cid from there and then i'll just retrieval mine that because i know this is a popular piece of software many people will download it but i think it's a little bit of a hand-wavy answer i mean um the whole sid discoverability thing is kind of uh i don't i don't have a good answer for it i'm i don't know if anyone does uh because it they are kind of like it's a really important piece of information but there is an easy way to discover them and even if you could just get a list of all of them or something you know you don't know what they are like there's context behind each one and obviously you don't want a retrieval mind like somebody's you know my summer photos dot tgz or whatever because there's only ever going to be one retrieval for that um so yeah that that's kind of the extent of my thinking so far i'd be curious if you had other thoughts or anybody else does i think uh this endocrine piece is a big big part of the puzzle and how to how to collect that information well and uh there's a lot of different guarantees that you might have and um especially when you're dealing with petabytes of stuff there's different levels of granularity that you might um may want to include in these indices so it's a whole content writing problem but in kind of a with a different tuning than than the normal ipps problem it's more um there's like a better it's a different set of questions where in ipfs is about in most applications it's mostly hey um i have this content or i want this content i want to figure out who has it and get it in this version it's hey i want to know what content is interesting and valuable to to redistribute from here from where i am from where i sit on the network and that's a that's a substantially different question that um that that yeah some indexing strategies will will uh will tune forward yeah and and hannah's raising a good point in the chat that uh the the kind of opposite problem of sid discoverability is like how do you ensure privacy on filecoin and uh yeah i mean my my thinking on that i basically agree with what what hannah's saying um if if every sid is is published on the blockchain um then you can't have any privacy for the existence of data you do have some privacy in terms of no one can easily know that you uh are the person who uh stored that sid uh or the person retrieving it like it's not like the ips or log or anything but um uh in terms of privacy of of the data itself yeah i think encryption is the only uh the only solution to that um yeah and that definitely has like all kinds of other other properties and you can you can take large segments of data that a lot of parties are storing and then um store even within that store private data within some sub-segments of that um so there are ways to kind of obfuscate um storage and access and so on and kind of with some security guarantees but you get kind of these blow ups and storage and so on um the the reader privacy though so there's like different components one is writer privacy so like when you're um writing a thing to the chain you um or you're writing anything to in general um knowing who the publisher is that that kind of made that deal with a minor and so on that's that's synonymous right now so you could work on on hiding where parties sit but there is kind of an account associated with that so people that is anonymous and you can know who who the client the certain name of the client and the accounts associated with it and and so on and maybe through that build you know same kind of chain analysis kind of stuff that people do on on blockchains with with money accounts and whatnot um but then a separate part of it is uh even kind of saying hey publisher privacy uh you know even kind of independent of that model there's a whole question around uh rear privacy of like okay well there's this content and then people are trying to what content people are retrieving and where and from whom and so on that's a whole bunch of other information that doing this efficiently over a a peer-to-peer distributed network is likely going to leak a lot of that information unless special care is is put into the design of the system to preserve the privacy um more so than saying like normal cdns where like you're interacting maybe your cdn provider knows who you are but like that's it uh in kind of a peer-to-peer network if you're distributing all these messages everywhere then a lot more parties are able to see it um there's all kind of deeper questions there though like you can you can start using you can get reader privacy by by obfuscating the the channels itself like the where like again you have maybe it's anonymous um you can know the pseudonym of the party that is retrieving but you actually can't map that to a real ip address like it could be it could be behind kind of layers of something like doors or other things like it yeah yeah you know those are all good points and hannah also raises the point that um uh we're adding the payload cid to this general purpose label field on the deal proposal but um future versions of lotus could uh make that you can make that optional or a config file setting or whatever so that would give you some some greater sort of anonymity obviously what you're uh as one points out like what you're uploading is always associated with your wallet public key so like anybody who has the ability to subpoena chain uh uh coin you know coin base or whatever for uh all of its records i mean uh clearly that's you know that's not uh that can't be uh obscured or whatever but yeah great thank you i think we we should move on to uh to the next talk but uh thank you very much mike thank you for the demo gee that was really cool thank you guys all right uh robert we can't hear you i think or at least i can't ah i had two levels of muting going on sorry about that guys hey thank you thank you everybody who's uh uh sticking through this this has been super interesting for me um as well uh being somebody who's working on a project related to this now really cool to see the projects other people are doing um okay let me go get started do people does everybody see the title slide looking good all right great so um i'm going to be talking about um falcon retrieval markup market objectives it has some overlap i think uh juan uh gave you know some good thoughts uh we've been talking with him as part of our project um but you know he's uh clearly you know the master of uh uh thinking about what our objectives in the overall system where uh we're you know put in putting our efforts in so why why am i giving this talk there's a team of us about seven of us in consensus's r d groups that are currently looking at the falcoin retrieval market design um there's sort of two phases to what we're doing that i'd like to talk about today see people get a feeling for what we're doing there'll be results that we're kind of putting out there all the work is going to be open source open protocol published and so forth i know sometimes that might be a question with consensus uh because consensus does do some revenue stuff but this is all uh open projects with um support by uh filecoin as well i should mention that um so there's two aspects we're doing uh one part is looking at the crypto economic design and uh there's sort of a step back i really appreciate i think it's absolutely important uh to be looking at you know what the other projects are doing who have been presenting today which is you know looking at actually building some code bases putting together components and so forth there's there's as i go through the talk you'll sort of see though that you know i think we're looking at it from a complementary perspective uh that ideally just sort of does some you know cutting the brush out of enabling you know later work of plugging components together to kind of come together into a retrieval market that um more likely organically grows up and uh works the way that we wanted to so there's an aspect of the crypto economic design which is you know talking about the objectives of the overall market i'll have a couple slides on that and then there's some work after looking at objectives when you're doing crypto economic protocols of thinking about incentivized mechanisms how you would want to reward participants how you would want to penalize them things like slashing in like e2 if you're familiar from proof of stake are examples where you know people actually put up funds filecoin has that great use and proof of space time where storage miners have to actually put staking and they get punished and so they're kind of you know forced to uh not only give a crypto economic assurance that you know what's gonna happen to them uh so you as a user you kind of know what it's worth for your store to stay around but you know that actors are being incentivized in the right way and then later in the project we're going to work on protocol components we're only a couple of weeks in so let me give you an overview of where we are now the meta objective of course of this work is to do something that's very helpful for fat coin storage and the idea here is that if the retrieval market enables a wide pallet of different latencies uh different throughputs different bandwidths the more that it has the more useful file coin storage is and having that all be kind of a one-stop shop that you can get the persistent storage of filecoin yet on the other hand be using it for websites or iot applications where you need to have you know four five six millisecond round trip times to some computation and storage is a really powerful thing and i'm very excited and interested in seeing falcon being able to you know cover that entire gamut of approaches so i'm grabbing two slides here that wanted showed uh in the past this one's from um a while back i think the pinning summit was when i first saw juan show this one and uh you know very useful i think for a lot of people to get a feeling a lot of people in the cloud space are kind of familiar with amazon obviously they're the 800 pound gorilla and what they've shown us right is that users you know are okay with there being different tiers of storage um explicitly amazon has kind of put things together into there being relatively inexpensive glacier storage which is you know more like tape backup in terms of the latency time and the cost and then having s3 storage which is very general purpose you can use it for you know ec2 instances that are inside of aws regional data centers you can actually use it for serving data to your end clients however the way that s3 storage is organized in buckets it sort of pushes all of the but storage in one bucket into one region so s3 is not ideally the way that you would build a cdn and so amazon then offers a version of storage cloudfront which basically amplifies the sdn caching data around the world on demand based on where it's being used and while there is some additional cost for cloudfront it is kind of folded in so it's not really that much of an extra cost in fact if it wasn't there you'd have to pay more but you know amazon does this because they know that if they didn't have it s3 wouldn't be useful so it kind of goes back to that previous slide point where if you want storage to be well used you need to cover a lot more use cases so um in this picture juan kind of showed storage and retrieval mining going you know a certain distance and pinning services inside of retrieval miners you can think of that in general is like caching depending service means you're actually telling people what to store inside of retrieval miners but in general the retrieval miners would be expected to have caching in them that allows them to not always have to go back to the storage miners which are going to have a certain kind of iops and throughputs retrieval miners might actually want to serve out of ssds for instance which storage miners are not going to do because you know storage miners are looking at 20 per terabyte for a hard drive cost and whereas ssds cost more about 120 so it's about a 6x difference in cost um but if you're a retrieval miner from an iops perspective ssds are amazing right you can you know not get 10 or you know 100 times better you get thousands of times better iops performance out of ssds so um but uh then uh through this hack fs awan showed a diagram here which i think you know i like and i think is really true here which is that storage miners can come down a lot in latency some of it has to do with do they keep unsealed copies or does ceiling get faster but you know really storage miners shouldn't be you know pushed in the category where they're just operating like amazon glacier storage miners do have hard disk drives they have a tremendous amount of reed bandwidth available on their spindles and so they can really cover for the most part the s3 use cases s3 is actually regional where storage miners even have a certain element of cdn to them that if you're doing uh proof of replication you can actually populate your storage in multiple places which already starts making it cdn like and retrieval miners likewise as long as the retrieval miners have capabilities like one was talking about today which i think are really interesting to look at of how we incentivize things that are less dht like and more index like so that we cut down the number of hops to something that you know while it's not going to be one in any realistic scale is kind of order two order three rather than order log n of the number of providers for uh how long you know how many hops you have to do until you are being served the data you look for so um just for the comparison um i think i kind of said it verbally there but you know these slides are i'm sure going to be attached to the talk later uh so i just thought i'd include it here that you know the file coin in comparison with the examples on the right side um amazon cloudfront as well as cloudflare's cdn which has a totally different interestingly economic model but achieves very similar uh performance levels of cloud front um you know those s3 and glacier make one storage stack five point is very interesting but i think that uh one one with the circle is primary retrieval so direct retrieval from storage miners um you know that i actually haven't i should have updated this table that that already is going like halfway into s3 maybe even covering a lot of it and secondary retrieval is then overlapping and going up that but it's it's a simpler stack and that's not too surprising so when you think about decentralization sometimes you end up getting that that you know decentralization can kind of adapt and handle amorphously more targets i made a comment here about data rights but i'm going to skip that for this talk um so performance levels of like the kinds of things we're looking for it was it was in those in that previous chart but i'm just making some notes here in terms of retrieval conditions so cloudfront there's nothing magical amazon doesn't actually have license to faster electrons or faster photons they operate with the normal rules of physics so you know if you're going to get these extremely good cloudfront latencies it's because amazon has actually populated some um you know point of service um you know type uh spots uh at the edge now there's been a lot of work in edge cloud where you actually do put storage and the server capability like lambda edge services inside of 5g cell phone tower there's a number of startups doing that and i'd really like to see file coin and ipfs type decentralized storage in those places i think it's possible s3 of course is regional so if you're you know in the us you have you know east uh you have ohio you have you know west regions all of those are going to be getting you latencies you know across the u.s it's you know under 60 milliseconds so you're going to be able to um hit reasonable latencies around the world of course it's going to be more um and so you know that's where if you're serving from distant places then you're going to want your s3 to be fronted by cloudfront so um yeah so just keeping those numbers i think is helpful here's a drawing which is you know this is uh this is a drawing i put together so blame me for like how crappy it is in terms of you know any graphic designer would say this is terrible but um it captures i think uh you know a way that um i think we see the participants who are engaged here the left side is not directly secondary retrieval but i use this diagram when i'm explaining to kind of other people how retrieval fits in with the storage miners so the storage monitors on the left side they have their stack from the users to storage miners i even threw in because there's some people interested in offloading ceiling because that's actually pretty heavy duty computation and could very easily be a separate market juan has talked about that in the past and ultimately everything's put on filecoin and you know the storage miners themselves are a direct retrieval channel i don't actually in this diagram show them realistically as being the people who would serve the end user clients because it doesn't seem realistic or efficient to have mobile applications and web browsers talking to storage miners directly it's just very efficient to have people in the middle putting in those people as intermediaries is not at bad or evil i know you know in blockchain people dislike intermediaries but this is this disintermediated uh sorry decentralized intermediaries who uh you know don't have the ability to control a monopoly can very be very good they can make some money they can actually make a network very powerful but they can still be permissionless they can still invite lots of new participants to come in if they go away so that's you know i think the vision for uh secondary retrieval providers and what i show there um i show sort of i you know kind of different networks that are coming together there's a portion of the network on the left side that is going to be a lot more tied together with the storage miners in fact i think some of the projects or some of the easy kind of ways to get started on retrieval markets is in fact for the storage miners themselves to also participate on the retrieval market side so you know they can actually stand up ssd clusters at low latency close to their hard drives and um you know very cost effective wise have you know extremely high you know capability and make extra money off of their storage which is always a nice thing additionally just to the right of it um i show a um you know an area where these would be sort of like caching only retrieval providers so they you know they would not necessarily have any special arrangement with storage miners they would actually have to pay funding in order to do the direct retrieval from storage miners so they'll have a little different uh economics picture and then on the bottom side i'm sort of showing p2p torrents and that portion of the retrieval market i even show kind of dotted out to include potentially clients you can envision that um you know if you have uh torrent-like mechanisms they're not great obviously doing what filecoin does of having persistent store but they are great at amplifying storage and they amplify it with the number of participants who are coming in so i think as an objective it's entirely valid uh especially at the low latency edges that people who are sitting in the edges who are retrieving who are looking to both you know pay for their continued retrieval and make some extra bucks should be incentivized and find a place in the market where they can bring in their resources and do those functions on the right side there's one point that i wanted to make which is that you know all of the payments in here it's uh you know reframing the thing about it paying somebody to get a file doesn't mean the simple case that you pay for them and that's the end of the transaction payments can actually have larger loops and what i'm drawing here in terms of third-party paying providers on the top right is a very applicable one it's used all over the place in web 2 and there's you know good reason to expect that to be an objective for five coin secondary retrieval provider and it's one where filecoin allows third-party providers to sort of you know uh um pay filecoin and to also indicate token types accounting tokens if you want to call them where the accounting tokens are kind of redeemed as authenticated users are coming in and using the services so third-party providers can actually provide those tokens to users if they want to have direct tracking um if not they you know there can be other mechanisms that are still basically allowing the file coin providers to um you know kind of you know get paid up front and then redeem it based on usage and similar to like uh you know other cdns or so forth if you were being charged on a gigabyte per second basis which you aren't with cloudflare but you are with uh cloudfront from amazon um you know ostensibly the cdn provider has the responsibility to make sure that they're taking care of dos and duplication so that your competitors aren't just you know using up your cdn dollars similar to like adwords there's a lot of you know anti-corruption mechanisms where you have to detect if there's real ad throughs versus fake and so forth so there's going to be a lot of interesting economics on the right side that the protocol is going to want to be able to support in the longer term okay so moving along one thing that i just think is uh a useful it's a little bit of a refresher but um i you know i gave this talk at stanford a little while ago and it's kind of a well-received talk and i think it's just useful because sometimes we kind of talk about you know attackers as kind of evil and we get a little bit it's it you know it sometimes is useful to think about how the protocol works versus the algorithm works and one of the principal points of protocol design is that you know one it's good to sort of do sooner than later and it's good to do um thoughtfully so they're sort of on the left side in the protocol design loop there's you know people in this case you know we're doing some work i know juan and team are all over protocol labs have done a lot of work you see the result of it with the file coin storage incentivization protocols which are tremendous um and you kind of put them out for public dissemination and review and it's really important to do this because the issue is that although you try really hard with your protocol to anticipate attacks you know you you don't really know how well they work until you get a lot of very smart people to look at attacking them and so on the right side you know there's this kind of arms race between protocol designers and algorithm attackers they go ahead and you know hopefully in the altruistic earlier phases you're not actually staking money on things they or if you are small amounts you know where you're just testing a market they attack it you learn about that that's part of the public public dissemination review and then you do some editing and in this it's useful to define protocol versus algorithm you know it's uh only kind of i think really been brought out by blockchain how different these two things are because before blockchain we had protocols for like ip networking but um other than like dos you didn't make money by taking down the internet you know so you could like grief and cause other things but you weren't actually becoming rich doing it um you know whereas now that's not the case and so when we design protocols we're designing a set of rules like what's valid and then what can be incentivized and what can be slashed both incentivization and slashing have to be really clearly defined because they have to be attributable actions it can't just be that somebody reported somebody else did something because that person could be an attacker as well so ideally you figure out mechanisms where there's crypto economic proof of what somebody did or didn't do and the algorithm is a totally different mindset and the algorithm you're already taking the set of rules is fixed and you're figuring out how to work within those rules to maximize for some outcome typically to maximize for your own performance or for your own rewards a really useful example that i find in this of looking at protocol versus algorithms actually john adler was suggesting this one so i'll give him credit here uh it's a full known one though um which is you know looking at if you're trying to actually have a protocol and then people who are participating the protocol around sorting and you know we we sort of all know there's different algorithms and something like quick sort does much better than naive sorting having order n log n versus n squared um you know you can see you know protocols that have much better performance like convolution and time domain versus doing fft again has n log n versus n squared properties uh and you know um uh and uh other examples of algorithms are you know that when you're thinking about algorithms you can sort of think about statistical failures they have certain properties but you don't expect them to correlate beyond those whereas you know in protocols there's more malicious failures and you know looking at things like the sorting um you know the the known algorithms are three examples of algorithms or quick sort merge sort and more recently with python tim sort tim sort being the remarkable one where it sort of looks at the data and then picks the algorithm so that it's able to actually get order n sorting in many common cases and you know the average is still n log n and even the worst is n log n and um you know so it's it's really tremendous but you know the main point on the bottom i just want to say here is that like the protocol recommends the use of something like tim sort and then the but the protocol can't force participants to actually do things closer to the best case if you want your protocol to actually deliver the best performance you couple it with making participants want to behave in the right way and wanting to behave the right way is to get incentives that cause participants to try to give in input data that operates more towards order n in tim sort or for some reason you have to use quick sort for some other reason at least avoids people from giving the worst case every single time for a quick sort algorithm and so um you know in ethereum which is the space where a lot of us from consensus are and deer and we've been working for you know years now on the progression from proof of work to proof of stake ethereum two and it's almost like this this title really captures like it's it gets it can feel frustrating at a time because doing protocol work and incentivization is not about finishing right it's just about making it harder and harder and making it more uh worth what more worthless where attackers have to try super hard and at some point it just is not worth it for them to do it anymore and you know the um the you know the challenging aspect is that you know while the protocol designer it's just sort of very easy that we think about things in the halo altruistic case and we consider the kind of rational you know player the poker player in the middle you know the malicious actor is there and in some sense they're not really different than the rational actor you know we just got to kind of recognize that a rational actor who's optimizing themselves and harms the algorithm during it we can call them malicious but they're just following the rules and so it's kind of the responsibility of you know the people making the percent in the incentives in the protocol to get it as closed up as possible so um along with that i think uh you know the the other view this is a couple of slides you can go to take a look if you haven't vitalik had a really good article about meaning of decentralization and it's important um these sort of definitions here is like architectural is really about the physical network the computers the failure domains political is about the governance um you know you can have something architecturally decentralized but still governed and you know logical decentralization is really about like uh you know you can see this last one here of like when you cut the system in half did the two systems work as independent units probably with a lot lower performance but you know do they actually still work and then it's logical in that case and you know this is another diagram from that same uh post by vitalica you know a while back um the net combined file point secondary retrieval market you know the the final objective is that it's decentralized in that bottom right corner so it's architecturally politically logically decentralized but the important aspect is to get high performance and to really make it interesting to a lot of participants the idea is that there are individual participants can be in any of the other seven boxes you know as long as they eventually are in the net combined you know three-way decentralized market the protocol is sort of incentivize a good overall system so that's kind of the mindset where we're doing in our project um one other view here is like from you know the uh uh sort of the scrum view of like think about your you know your users first what are participants bringing to a retrieval market right they you know they do bring some desire potentially to make file coin work well and to make this market work well but if we wanted to scale we need to look at them more of like maybe they're disinterested parties and they have resources and that's what they're bringing they don't necessarily bring a zest for file coin they're just people who want to you know participate make money uh and help out eventually we want to get to that point so small scale participants you know people like us who have you know drives at home have machines around maybe even mobile phones as we're walking around uh we have you know um uh relatively unlimited bandwidth uh we could be using it every month there's no reason not to so we have idle storage we have idle bandwidth we have idle compute all of those can be put into the market we're not going to economically be as efficient as medium and large-scale providers but we have something really good at small scale participants our hardware and our bandwidth and our compute are probably already paid for so we don't have to have our roi pay for the capex it just needs to be covering the opex and the administration so we need those loads to be as low as possible medium and large-scale providers they do have you know bespoke potentially hardware that's just dedicated for this purpose but there's lots of vital resources here too and so ideally as we're building file coin retrieval markets we should be looking at you know making it uh incentivizing enough their people have long-term contracts on amazon or they have their own hosted equipment on uh equinox and uh you know it's uh it's useful for them to uh be able to monetize it as well and worthwhile for them i know of a couple projects that are looking at that explicitly so um yeah so uh design goals um a little more talking about some of the objectives from this view so one of them that i think is uh you know a really important one here is that there's an efficiency to how resources are being used so some of the kind of naive ways to incentivize the market where a participant is getting paid directly and providers getting paid directly and they own that money the second it comes to them aren't necessarily the best because it can put providers into an adversarial relationship where they don't want to share query information with each other or they don't want to actually agree who's going to cache data even though they both happen to be able to serve it with the same iops the same latency the same bandwidth so allowing providers to kind of coordinate so that they're able to achieve the largest working set possible given the resources they have and the best load balancing the best indexing is valuable so it's important the protocol covers encouraging the providers to be incentivizing the providers to actually be collaborative in that sense um and the other you know very important design goal is that even though a protocols are complex if you look at proof of work in eth1 versus e2 proof of stake proof of stake is incredibly complex and you know similarly some portions of actually being a fall coin storage miner are going to be very complex but you know joining and participating in the market and doing well in that market should not be complex it should of course be as hard as possible for the attacker to attack it but people who are doing the right thing should find it to be absolutely trivial so that's kind of an introduction uh we're gonna be posting the information as we go in the falcon retrieval market slack um you know we've gotten directions at the right place for us to be putting some of our intermediate stuff as we're going along is in five coin project uh research uh there may be some other kind of discussion boards as well uh i'm not sure if that starch will do that and then uh there should end up being some uh some components or things that will be in shipyard as well and really just welcome people if they have thoughts or if they're interested in reviewing when they see it or collaborating even more if it's an interesting topic you know we'd be we're going to be happy to do that with everyone thank you it was really awesome thank you oh it's my pleasure thank you maybe on the on the ladder point that you have so um you know right now there are a lot of folks um that are super interested in in mining file coin but they have a lot you know much uh they don't have a sophisticated setup as you know falcon storage miners demand um uh simply because you know all of the proofs and all the work and so on is like a just larger larger thing um smaller scale we've always seen kind of smaller scale miners being very tuned for for retrieval um markets um and so some of that scale could be like in the thousands or tens of thousands very quickly um but there is kind of like a gap between interest and kind of what's ready um curious how you see like the the um kind of like the the problem maybe from your perspective on even just reflecting on what we've heard from today and maybe also a question for other folks on the call um how we see kind of the tooling that is there now how far away do we think that is from from um from meeting that that demand from a bunch of folks who would like to mind falcon we like to be real minors but um but aren't quite ready yet um or what do we see as like the blockers like what what what can we can we do between now and and minute launch or soon after uh to kind of land that i think that was open to other people as well i'll sort of make commenters well i think uh you know what we've seen in um um you know all of the different spaces you guys are doing it with uh the fall coin storage market is that um you know ahead of actually having real money staked in the game um you know it's very valuable for us to start um getting things that are still kind of altruistic and incentivized but starting to look more like test nets where we kind of you know have the equivalent of you know we have our drips and you know we have participants you know take funny money and we start testing to see are we able to get you know the comparable latencies and bandwidth and iops um if you look you know i i'm very minded actually a lot of us on our particular project are very minded around the enterprise we come from the enterprise infrastructure space earlier in our career and we come to blockchain with that kind of mindset as well and we're interested in making this really be a replacement because if you look at it as you know like the scope and the size of decentralized storage is really massive but like one of the crown jewels that a lot of web 2 companies and web 2 cloud providers like to kind of point out as they're like they like to poopoo decentralization by saying that oh well it's decentralized and that's nice but decentralization is disorganized right decentralization won't get to these performance objectives and so forth so we're going to want to do test stats where you know before we uh you know as soon as possible where we're able to test and see if people are operating with this kind of funny money token and they follow the protocol as if it was real money um and we bring in the caching providers that we're able to kind of get to data lake type performances in some cases you know amazon kind of touts and brags about you know you you know you put prefixes and buckets together each of them can do three to five thousand iops each of them can do 10 gigabits per second and so if you want to get to 100 terabit per second type data analytics type applications and machine learning applications just follow this you know follow this design and then your system is doing it so i think you know it'll be i'm i'm interested in that um you know in seeing in pushing that like left edge of the performance a lot farther ahead of what would be a falcon retrieval incentivized launch um for actual funding but what i really would like to see and i'm interested the you know chainsafe and uh mike and so forth yeah i mean it it's definitely clear that you know even for the early falcon storage getting you know as much as possible even altruistic people won't be attacking the system necessarily right away um you know yeah that's uh you know it'll be really valuable and just exciting to see people using uh filecoin with a lot more performance that they i think than they would have been getting out of uh you know well maybe not right away but um hopefully soon getting out of like ipf storage as well agree i think uh uh and i totally agree with that with with the approach and and pushing the the performance edge and i think if we kind of methodically go towards that we can even sooner enough end up with something uh pretty remarkable there um i think a lot of interesting things start appearing when um when you started for the kind of applications that you mentioned around uh machine learning and so on uh the work the live peer is doing for example amassing gpu clouds and so on uh coupling a gpu cloud close to falcon storage or something like that that could work uh really well where you can very quickly get get a highly scalable machine learning cloud right away but there's probably you know i think a whole bunch of there's probably a whole bunch of work in optimizing the flows to get it to work uh you know kind of in a straightforward way um so but but it'd be great to kind of work work towards that uh one interesting data point is uh there's probably around i think um the current installs on you know the companion interface is like in the tens of thousands i think and then the um i think metamask has millions of users and so on right so one plus one very straightforward thing here it might be like uh thinking about applications companion as a target of saying okay well what it would look like to you know start earning earning money as a as a material miner directly from the browser right this might also be something that brave uh brave might be interested in as well because they're already kind of in the in the crypto space so uh mike to your point about it having an extension and using that as a deployment path uh there might be like a straightforward thing there with with uh with brave users we're suddenly like just dedicating so much to your search space to the browser suddenly starts uh you know being a significant revenue stream for you yeah and you know there are some components in here that you know we'll look to see if we want to plug in um on our team the state channel team um if people know in the state channel space there's a team magmo they currently have joined in with consensus r d but with ethereum they you know really have done um tremendous work on building out state channels to have kind of channels within channels that allow them to kind of be l2 you know squared type scaling versus simple painted channels that people think of that always exit and enter from the primary chain and they did a poc earlier this year of implementing an incentivized state channel system on top of web torrent they called it web3 torrent um it's you know it may not be exactly right in the sense that you know there's already graph sync and bitswap in here but it's an interesting potential poc that we could do sooner than later um to look at like that kind of scaling side um i really do also want to point out when you know you made that good point juan about like the cloud providers looking at this you know when i showed the diagram of the different types of decentralization you know uh that vitalik kind of drew out in that diagram the interesting point there is you know right now like there's a big friction sticking factor of clouds is the storage and you know it's a really important one they all do the kind of roach motel style where you know you can check in but you can't check out so you know putting data into any of these clouds is essentially free then you pay some storage costs but you don't think about that up front but then when you want to take the data out of there serve it out to the network and other internet or so forth it's extremely expensive and in fact it's uh disproportionately expensive in a sense if you look at cloudflare they're able to actually make their business model work without charging per gigabyte fees on data movement they and it's because the cost of actual data movement on the internet is so low you know and it sort of exposes that the cloud providers costs are not there to make money but it's a little more to discourage storage once it's on their network to be easily connected to other storage and so forth so what's cool about ipfs is if we can drive and get some of these machine learning cases that are using common data sets genome data sets you know some of these massive data sets that are in the public interest that are accessible there it points to a really good model in the future which you know it's almost like how apple defeated the cell phone market by producing the first ever cell phone that wasn't owned by a manufacturer right or by a network i should say they forced the iphone even though it was exclusive to apple you know 15 years back they sorry even though the force was exclusive to att for like three years atm t did not own the software stack for it and that really is what i mean from business standpoint spurred the actual smartphone revolution because now we had a software platform that was separate and very quickly google bought android and jumped into that and we had that really good you know quick acceleration of that market i feel like ipfs getting cloud providers to recognize that they have to host ipf storage because that's where their applications are going to be doing data processing and other stuff on will probably force them to a different model where they just have to be in an ipfs retrieval and even storage market and you know then all of the cloud providers will be competing with each other to have the best ipfs storage inside of their clouds so it's a really nice side effect of this that this is going to end up you know causing a lot more effective decentralization to happen across the providers that they just won't do economically on their own yeah that's an awesome awesome not to to uh um to end with thank you very much much robert uh i think we have one more uh um uh talk from uh thomas uh hey yeah thank you very much robert that was that was awesome uh great discussion uh thomas take it away and then after your talk i'll close briefly and and uh that'll be that for today yeah thanks uh really excited by all this talks this was really amazing um yeah so i'm uh on the team hackathes and i won't i don't really have a demo yet it's been kind of broken lately but i'm just gonna talk about a little bit about uh what we're building um and so basically the use case that we went for is um how do we kind of bootstrap a retrieval miner and onboard them on the network and i was kind of i'm i'm kind of the primary user i have a machine here and i'm hoping you know i don't have that much uh power but i'm hoping that i can join the network and so i was looking at how do i uh serve uh this data um on the retrieval market and so basically what we have kind of built currently is uh we're kind of creating this kind of we we call it a deal faucet node and the idea is um as a new miner retrieval miner on the network you can subscribe to it and it starts just sending you deals just like that and the idea is that uh the the deal faucet node can then subscribe to those deals and follow what's going on with them and kind of measure things and so the idea is that the deal faucet node is um we want it to run a statistical model and um just kind of start the idea is right now what we're doing is just a quick way for us to switch uh models and try different strategies and see what works and what doesn't uh right now the deal faucet node is hard coded a hard code at least list of cids and we're just trying to see how that works out uh for you know a new miner to just subscribe to it and start new deals and send the data about those deals and then ideally the deal faucet node would start kind of recording more and more data about those deals and have more information so right now we're looking at really basic parameters uh like just the location of the node and the clients and then the content size just kind of looking at you know if we can have any uh start waiting cids and just sending the cids that we think has the highest probability of being retrieved by uh from that provider and so ideally uh any type of miner who's already been on the mat on the network for a while could kind of run this deal faucet node and just be able to just kind of i mean send out those deals to anyone who subscribes and then in exchange get the data about it so it'd be kind of like this this exchange of things uh of of data and um maybe you know like a storage miner could could run that since they already have those cids and they can uh be incentivized so we're just trying to make this work and it's been uh it's been a little hard just like getting to know exactly everything uh and how to make it happen but i think we're pretty close and we're also building a ui for a retrieval minor to exactly see what's going on so they kind of have an idea of understanding what's going on because i think there's a big barrier of like understanding and learning about the whole process so we're trying to make it easy for someone who just has no idea how it works has a machine and just wants to on board and gets a few cids and it's like oh i'm a mind right now this is how it works so this is kind of what we're hoping to get sorted for the deadline yeah that's really cool um how do you envision kind of the the statistical models evolving over time do you think um those will be kind of like this deal faucet will be kind of like a single independent operation and they'll run their own model locally or do you or are you kind of envisioning a world where there's information aggregated by different parties and then there they then share that information or share parts of the model uh there's all kinds of like hard market incentive problems there it's probably easier to treat the most independent but just curious how you've been thinking about the problem yeah um i mean right now we're definitely just trying to make our use case work really minimally but ideally yes we want to be able to kind of share statistical models across nodes and hopefully make it possible for anyone to kind of just you know run their own faucet if they want to and i think it would be an ecosystem of actually sharing cids for i think it's the more you can share the more places you can just publicly go and subscribe to nodes and get you know data for onboarding uh i think the better it will be instead of just kind of you know closing things off and trying to be really private yeah awesome uh cool so i think um anybody else i don't know if you had anything else or if other folks had any other questions great sounds good so i'll just uh close that thank you so much thomas and yeah good luck with the hack that's really cool i'm looking forward to it um yeah so i think thanks everybody for for being part of part of uh today's uh uh day and and sessions um we looked at a lot of like really interesting parts of the retro market as it's kind of coming together and also looking ahead um i think there's a lot of uh uh awesome pieces that are that are coming together now um and you know i think we're still kind of within um uh a chunk of time between now and and maine and i think that there is a very large opportunity for yeah creating some kind of um ui oriented thing that um can you know there is kind of a hard problem there around what should party store but i think kind of like some straightforward implementations of it now could could um even if they're not perfect um could actually meet a lot of the a lot of the demand from um from a lot of folks out there that want to want to be able to mine firecoin and want to be participating in the network but don't have like the the time or or or capital to go and build out like a much larger uh larger set of machines so i think um uh yeah there is there's a pretty interesting uh open opportunity there um and and i think uh one side of things that we we didn't get a perspective on today was actually hearing from from storage miners i wonder um they might have a whole different perspective on this um where they might have you know some setups already now and they might already be thinking about how to how to plug into to retrieval networks and so on uh so maybe that's like a like a good uh to do for me for me to uh maybe potentially organize something there where we can hear from search miners as to how they envision how they're thinking about their storage facilities now and how they're envisioning kind of indexing all the data they're storing um and how they're thinking of kind of plugging in with the with the whole virtual network um and maybe kind of uh hearing from from that um we can uh collect part part of that uh into into kind of design of of these systems uh thank you very much uh thanks uh to all of the folks that that spoke and demoed uh huge thank you for for uh also trying out um things on the fly um it's really really great uh session uh and thanks for for uh thanks to trent and andrew for running the whole uh the whole show thanks so much see everybody in the session in a few minutes if you're coming to watch or get feedback to demos so see ya thank you thanks everyone 