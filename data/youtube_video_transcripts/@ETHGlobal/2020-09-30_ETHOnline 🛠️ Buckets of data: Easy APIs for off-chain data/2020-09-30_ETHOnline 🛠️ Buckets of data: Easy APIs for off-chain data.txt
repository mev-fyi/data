joining we have carson from textile who's going to be giving a workshop titled buckets of data easy apis for off-chain data storage on ipfs and filecoin thanks carson i'll let you take it away uh hi everybody um thanks for joining hopefully a couple people can you can keep rolling in i'm going to start sharing my screen and just jump right there we in [Music] cool all right um yeah so thanks for joining us today um super super glad to be uh participating in another eve global event these things are always super well organized so it makes it super easy to uh to contribute anyway i'm uh carson from the textile team um i think we're a sponsor of these online this year so very excited and that means i get to kind of force you to listen to me for a little while which is great um so we did hack a fest just recently and that was a ton of fun we got a lot of meet a lot of really great hackers we met a bunch of mentors and other people who are exploring um and so we're really happy to be contributing to uh this event again um it's super easy to kind of get involved and uh we learned probably probably just about as much as as any of the hackers learn about textile stuff along the way but anyway i'm carson i'm going to talk a little bit about what textile is a little bit about some recent additions to our tech stack and a little bit about onboarding uh hackers and developers um to actually start storing some off-chain data in some kind of new and exciting ways that i think you're gonna find pretty interesting and quite nice and scalable so um first things first i get to talk a little bit about textile uh we're a sponsor so like i said you got to listen to me self for all for a little while but i think in the end i'm going to cover a couple of things that can be pretty valuable for everybody here especially if you're starting a hack or something like that if you stick with me to the end there so textile is first and foremost a company driven by a mission and that mission is revolves around the idea of a better web a data driven web under the control of the people who are producing that data namely users and i've actually spoken about this topic a bunch of times at other east events so i'm not going to kind of hammer you on the head with the user data story but there are a couple of videos that i can link at the end to some talks we've given about this and the idea there is really just putting the control of where and what data goes where in back in the hands of the users but also textile is a company that builds things we build tools for developers to make it easier to leverage a lot of the ideals and the technologies that underlie the distributed web or deweb or web3 or whatever you want to call it so in a lot of cases this is technologies like ipfs like ipld lib p2p and more recently filecoin and what we do in practice is we build apis and products that we hope feel almost as familiar as existing web 2 technologies but that leverage all these peer-to-peer you know web3 technologies under the hood so for example we build and provide a document style database that syncs its updates to ipfs and we provide blob or file-like storage api that feels like the mix between aws and git and on top of that you can sync it to decentralized storage networks like filecoin and then along the way we wrap all this stuff up in a tidy bow and we call that the hub or the textile hub and that's basically like an easy to use always on dweb infrastructure for developers we have so we have databases we have buckets we have offline messaging we even have some user management capabilities and we're always adding features along the way a lot of them spinning out of these types of hackathons where users say like oh geez or developers say geez it would be really great if you know i didn't have to manage this piece of my stack um if i could just pull something from the hub and so um you know at the end of the day we we get a lot out of these events and we end up building features and tools that leverage kind of the best workflows from web 2 and web three or at least that's the idea so today i'm going to talk a little bit about buckets and i'm going to talk a little bit about the hub which is a sort of primary place to access that stuff and then i'm going to mention briefly mention the powergate um and that one is just like packed full of a lot of things so and we've we've actually been giving other team members have been giving talks this week about what the powergate is so i'll refer to you to those talks and slides and videos at the end of this um and then all of these things really end up leveraging our peer-to-peer database which we call thread db so we're actually going to kind of touch all these main four product points of textiles or of textile um and we're going to kind of touch them all at the end of the session but i'll try to make it so that you're you know we're keeping things pretty light and simple so in addition to textile being a company um that builds things and you know we charge people for using infrastructure and things we're also a research lab and actually we started our life more as a research lab than anything and we started with something we called textile photos some of you may or may not be familiar with that some people ended up calling it like deweb instagram or something like that but what textile photos really was to us was an experiment to see if we could build an engaging consumer app in this case it was a it was a photo sharing app on pure web3 technology and that was a pretty cool mission and what we learned was basically nope can't really do that all that well the technology wasn't really quite there yet the networks that we operate on aren't really designed for it certainly mobile phones aren't really you know set up for that and the user experience kind of ends up having to suffer just a little bit too much to get all of that pure web3 ideals in there so the experiment that we did you know sort of failed it was an experiment so you know experiments can't really fail if you learn something but it did take us a good while to get to that failure to get to those lessons the good news is we learned a whole lot and probably most importantly we spun out a whole bunch of developer tools and products out of that experiment and and built you know powergate and threads and buckets and the hub and so we started building and releasing the tools that we kind of wish we had had when we started building this photos app experiment so things like offline data persistence we needed that now we have it data sharing we needed that now we have it encryption that's built into threaddb and all of these things are now sort of products that other apps can bootstrap to create new apps faster and this kind of leads me to a really important lesson that we learned as a research as textile the research team what we learned was we had to build a bunch of this lower level stuff before we were even able to get to the point of failure before we could even learn like can you build a decentralized photo sharing app easily the answer is no but it took us a while to get there so since then a key metric for us and i think a lot of other folks in this space now is something that our ceo andrew calls time to failure and i don't know if this is a common term or not um maybe it is but the idea here is essentially we need to make it we as tool developers need to make it as easy and as fast as possible for someone to enter the ethereum space or enter the d web community the web 3 community test out a new idea or concept that they have and then fail because what we have today the web we have today it didn't just start with a bunch of successful companies it started with like a ton of failures one after another after another until something kind of worked um and then something clicked and you know companies and businesses were built off of that and i think you know a big piece of our philosophy right now and the stage we're at right now is is that is like that in web 3. we need to give developers as much time as possible to try things and fail and to reduce that time of failure so i'm going to talk a bit more about time of failure today as we kind of go through but i want to leave a bunch of time at the end to get you to the point where um you know for hackers and people who want to play around with things that they can start to fail pretty quick as well um now one of the other reasons i really like going to these events is because the ethereum community is actually already pretty good at this to be honest to building you know projects tools and and starting up companies building things on the various layers of the overall stack right so there's a lot of folks building developer tooling and then there's a lot of folks building and failing and then succeeding on top of those tooling so that's another reason why these hackathons are great why i'm happy to be participating here this year because it helps us figure out what we need to build to decrease that time to fail and then it also is pretty exciting to see when people get to that you know the time to fail and realize that they didn't fail that they actually built something kind of cool anyway the other uh reason i want to talk today specifically about some of the technologies like buckets is because a big thing with any sort of decentralized app is data storage and where we are going to put those you know your app assets where are you going to store user data or whatever it is that you happen to be storing you can't put it on chain it's going to be too big sometimes it's dynamic it's definitely way too expensive uh in terms of gas prices and things but at the same time you know if you have to spin up your own ipfs node a file coin node an ethereum node build out your back end then build out your front end and then you know maybe give up and and use some storage system and all that stuff from scratch every time we basically already lost you no one's going to build if that developer experience is too slow it ends up leading to shortcuts and frustration and then we end up with a ton of compromises and you know some significant percentage of people building decentralized apps they just settle on storing data on some you know centralized server or in the browser or something like that and i'm way too lazy to go out and you know figure out what all they are so let's just pretend it's like 37.645 percent very accurate number and that's a total bummer uh because we're stuck kind of with the same problems of the current web where you know you're still your users are locked into a particular piece or a particular data walled garden sort of uh setup so there's no way for users to access their own data from your app there's in your you end up just kind of sticking to tired practices that we're already seeing and you know in a lot of cases this works and that's why people especially at hackathons you know will just settle on something that works because why wouldn't you um and so to illustrate this point a little bit further here's a scenario that we literally see a bunch when you know users or people developers come to the textile stack afterwards and there's a lot of variations on this but it goes something like this they get excited they've got a short amount of time they're going to work on a hack and so they think okay this web 3 thing is super exciting i'm going to build a decentralized app it's going to be pure peer-to-peer it'll run on mobile it's going to run in the browser we'll have a desktop app it's going to be awesome uh you know i'm not going to store any user data because decentralized storage somehow and even the app itself is going to be purely decentralized so no one can censor it it's amazing okay awesome so i've got this you know hello world app running on localhost 3000 uh it all checks out everything's great oh okay i just need to add like 100 more dependencies to my bundle here and then i'll have to add a pinning service and then uh okay well it's not going to run on mobile that's okay because at least the browser app runs all but not between two peers that are on different networks uh okay so i'll need to add some sort and if they're offline i'll need an inboxing feature and then maybe if i can just cache some of the data in a database i could decentralize that later and then by the time you know they're sharing cat photos with between their like uh hello world app the hackathon or the weekend experiment is over and they haven't even tried out their awesome idea yet and so we didn't even get them to the time to failure so that's pretty much what the hub is about it's a direct manifestation of our effort to reduce time to failure it's basically cloud tooling for developers that are designed around user controlled data trustless data management and a bunch of cool new models for decentralized data access so actually like function based right validation and read validation and a bunch of really neat things like that so at the most basic level what we're really talking about is like a remote ipfs and thread db and buckets peers that developers can use to test things out build stuff manage teams deploy apps even connect up storage to filecoin network without having to run all that infrastructure themselves just with basic you know web 2 style api keys right now all these remote services are free for developers and that's a big part of our mission is just we want to onboard people to these ideas get them using it realize how easy it is to do and then like any web 2 platform you start with the hosted stuff you get a feel for it it works great you like the user experience that you derive from it and then you can start building out your infrastructure yourself as you need to optimize for specific web 3d use cases um and so we're you know we're really hoping people just kind of start playing around with it and you know you know the marketing spiel is like it's a remote ipfs and textile file coin nodes that will radically change the way you build apps but actually i kind of hope it doesn't radically change the way you build your app that's kind of the point i can't i hope that you can just build a reactor view app the way that you want to build a rack or view app and um you know just leverage some of these peer to peer and web3 technologies under the hood i mean our whole team is a bunch of developers some of our best friends are developers and our philosophy is we're not going to get a bunch of people building and using web3 apps until developers start building you know arguably better experiences on web3 technology and we're pretty confident that that's the case that it's doable but we can't do that if our technology ends up getting in our way um and off chain storage is a huge piece of that sort of puzzle so our team builds tools other build other teams build tools on top of those and so on and so forth until we're all guaranteed to win and it's guaranteed um so for the eve community today i can't really do a show of hands or anything so i'm going to ask a question and then not actually wait for the response which is how many folks are familiar with uh file actually before i do that i'm going to pause and see if there are any questions with what i'm talking about so far it's all pretty markety stuff so if there's no technical questions that's okay i see something in the chat all okay excellent silence is deafening uh okay so i'm gonna assume people are have a passing familiarity with filecoin um yeah okay cool andrew uh my own co-worker says show the magic so anyway um okay so for those of you who are a little less familiar with filecoin basically it is a new blockchain and it's a network that provides incentivized decentralized storage um so if you're familiar with ipfs um you know a lot of the same concepts you know it's also a protocol lab project a lot of the same concepts translate over but filecoin has an incentive structure that's baked into the protocol itself to incentivize storage of real hopefully real data i mean honestly i'd be pretty surprised if you haven't at least heard something about filecoin in the last couple of months especially because their mainnet is going live next month and they already have like something like petabytes of data on some of their test nets and you know it's shaping up to be pretty exciting uh way to sh to store data um if you aren't familiar with filecoin i'm not going to spend a ton of time talking about it here today um but i'll give you a quick little rundown on why it would be useful and important to consider if you're building an app that needs to store off-chain data so the idea is okay you've got some data that you want to store off-chain for your decentralized app maybe it's your app assets themselves so it's your you know your app your built app um and you want to you know be able to access that over peer-to-peer networks maybe it's your actual user data maybe it's all those like maybe it's a cold archive of all those cat photos of the internet seems to be so obsessed about uh or something more like noble like just archiving all of xkcd but whatever the case may be you know the idea behind filecoin is that in theory you should be able to pay fill the filecoin coin to get a filecoin miner to store your data while at the same time proving that they are in fact storing your data and this proof mechanism is actually how they how they mine um filecoin but obviously you know like ethereum running a full node is kind of a big deal like not everybody is going to be running a full node on their laptops and even proposing deals with miners at the outset is is a pretty serious bit of work it's not going to happen from like a browser app or something like that um so you've we've kind of got where you're at this situation where you're like filecoin is this sort of potentially very exciting decentralized storage network where apps and dapps can actually push data to you know a decentralized uh cloud but you can't really take advantage of it directly inside of your app so how do we do that you can use powergate the thing i said i wasn't really going to talk about um so this is something textile built i'm not going to talk about it tons because there's way better people on my team to talk about it with but it's essentially we abstract away a lot of the complexity of creating and negotiating deals with file coin miners it packs a lot of complexity into a single tool a lot of teams are already starting to use it um i think it's currently the recommended way to push data to the file coin network um and yeah like i said there's not a lot of time to talk about it but i will direct you to some workshops and videos at the end that my colleague andrew has been giving this week to folks in the uh file coin apollo and slingshot programs maybe andrew can even post a link um some links i don't know in the chat but we'll try to make those available on our websites and and doc soon in the meantime you can definitely check out the docs for powergate online to learn more yourself and then i will sort of allude to um some of this when we do a little practical stuff towards the end here but i did want to highlight that we also run powergate on the textile hub so again if you're if you want to explore some of these tools you can create a hub account you can like actually push user data or files to your hub account and then you can leverage filecoin there you can kind of test it out test the waters see what it's like in particular the buckets api which i'm going to show you later uh pairs really nicely with archiving data on filecoin and this is available on the hub already you can push data to filecoin's testnet um and that's that's a pretty awesome thing so that's going to be we'll show a demo of that at the end here the whole idea here is that you want to leverage these decentralized storage protocols but you know we're not going to all be running these full nodes in a browser or something like that anytime soon so you know are we you might be thinking are we just trading kind of one centralized system like aws for just another one textiles hub but the thing to keep in mind is you know this is a pretty radically different perspective on how data storage happens because you don't need textile to re retrieve things from file coin or even ipfs later on essentially you have a system where you push data to the network in one place say that's you know textiles hub or some other powergate instance whatever and then you can retrieve it from any number of other places and so every single textile project which are all open source by the way we recommend you go in there and fiddle around and break things they're all multi-protocol and so what that means is there is always more than one way to retrieve your data you can do direct peer-to-peer over ipfs or ipns you can get it from a textile or you know other gateway so like in fura has a gateway cloud player has a gateway protocol labs has gateways you can do it directly over lib p2p's pub sub mechanism and ethereum 2 is using pub you know the pdp as well so you know that stack is already familiar to some people or you can just do good old http web pages and even in the case of buckets and other tools if you flush it to filecoin then you have a whole another decentralized network where from which you can pull and extract and potentially query data so any system that supports any of these protocols including filecoin can get that data back out for you so you've got this sort of one way in many ways out multi-protocol sort of setup and the the reason this is nice is like ultimately if you're using an app that's a centralized piece of the puzzle because you're using that app but once you've got that data in there you want to be able to access it from potentially other applications that could leverage that and so you get potentially truly interoperable data and again this is something i've talked about before the folks at um you know ceramic have been talking about it lots of folks in the east space are interested in this and i think ethereum and like a lot of the decentralized apps that we're seeing coming out now this is a chance to kind of get that interoperability picture right um anyway the cool thing there is yes interoperability but also like if you don't like the service that's being provided by a particular you know cloud provider here's the file coin deal for your data take it and retrieve it from somewhere else no problem spin up your own note if you feel like getting crazy um these are all things that you know potentially uh could be leveraged so um i'm gonna pause for some more uh questions here in a second and then i want to get us into some actual practical workshop e-type stuff so um i'll switch slides here and then i'll check these chats here um uh okay so first one there is our apis available for python uh great question so all of textile hubs apis are grpc apis uh they are also all available via grpc web apis we provide javascript clients that interact with the grpc web apis we provide go clients that interact with the grpc apis you could similarly have a python client that would interact directly with the grpc apis we don't publish those necessarily ourselves although there is one that for the powergate apis so it's called um pygate i believe and uh that is a client that you can use to directly communicate with the powergate remote but like i said if you if you know how to do grpc calls in python then you can write a client for that and we are looking into publishing more of the grpc definitions for um like different languages and things like that it's and then joseph says got question um it sounds did you want to ask that verbally or just type it out verbal can we do that i hear something yup hey uh we we've spoken a few times on you guys slack um the question i was having uh i'm having right now is um so you're saying that it's accessible so like one of the like the real world things that we've kind of encountered when we've done some testing with this stuff is uh we're using uh a like a document store style thing kind of like firebase and the threads db is basically a database wrapper around ipfs right um so correct me if i'm wrong which it sounds like i'm wrong uh from what you're saying is that if we have like permission sets for like a document that we have uploaded through textile um my assumption was that um we would need to use textile on all the clients in order to uh like get the right permission set wrapped around those documents to be able to read them or set them or whatever is that is that incorrect well you need to use the the text like the so if you're using threaddb you need to use the threaddb clients to like correctly interpret those uh permissions and things like that but you don't need perce you don't need to use like the hub per se to enforce those permissions you just need a textile like client which could be running locally or you could run your own remote one or um however you want to set that up i just gotcha gotcha okay that that makes a lot of sense thank you cool uh and then samuel says how performant are your databases my experience with ipfs is being that it can be really slow yeah i mean it's the best database in the world um and it's perfect but no seriously uh we haven't done a ton of um performance evaluations we do um uh do some you know like ad hoc comparisons but if you're trying to find something to do like you know sub millisecond throughput or something like that then um it's not going to be fast enough for that and it's going to be pretty tough to find uh like a database that's syncing peer-to-peer that's going to go you know be able to handle that kind of volume but um uh you know thousands of updates uh per minute it's it's really great for things like you know web web apps that are creating user data um or documents that are being updated through state changes things like that um i probably wouldn't want to capture every keystroke i'm not sure that that's going to scale that well but um you know in the uh now we do actually we're currently developing a javascript implementation that is basically offline first so you'll be able to do very quick local writes and actually local queries that'll be very fast but then we'll only flush data to a remote in a you know over regular time intervals that might address some of the faster rights that are required for you know higher throughput data um is there any caching mechanisms from the hub um like at cdn uh yeah so like for faster ipfs file retrieval and stuff like that we do um enable some of that like cdn type caching um especially especially useful for immutable data because you know that the content isn't going to change so um you can kind of be aggressive with caching and things um i'm not sure what the latest on that is so i would probably defer to someone else on my team or if you hit us up in the slack we can give you the details on that yeah cool any other questions before i get to getting your hands a little bit dirty we're perfectly on time so that's great okay cool all right so if anybody wants to follow along great i'm actually going to do this live um so hopefully everything goes smoothly but uh if not it's probably someone else's fault so let's just jump into it um oops that's what that's what will happen if this doesn't go smoothly all right so what we're going to do is i'm going to get you to download a couple of things to get to get going so we're going to start by installing the textile hub command line client all right so this basically allows you to interact with the hub the remote hub to create an account and do a bunch of interactions with uh the with the remote hub so if you go to uh our github releases page it's just github.com textile io and then the repo is textile and you can go to the releases and there's a link in the slides which you don't have but i can also paste the link into the chat here if you want to go and get that and you'll just go ahead and grab the latest release aaron from my team just released this yesterday and so i'm running uh mac so i'm gonna grab this latest hub underscore for uh version two one zero release here so there are a couple of other tools um the hub is for interacting with the remote hub um and like things like buck and buck deer for interacting with local uh local bucket stamina but we're gonna use the hub just so that we don't have to set up um any things on our own system so if you click on that and download it it should hopefully download pretty quickly uh depends uh how things are going and i'm just going to actually just cd into downloads i'm not going to just list off everything that's in there um and i'm looking for something called hub underscore v20 blah blah and i actually already have downloaded it so oops okay and inside you should see four things the license to read me the actual binary and an install script if you're on a unix type system you should just be able to call install and then it'll probably do something like say something like that and then you'll have to give it some permissions my password is one two three password um and then it'll move hub into somewhere on your path so that's actually useful i was kidding by the way my password is not one two three password um and so uh if you check now you should have hub installed and you can do something like hub help and it will try and run it and if you're on a mac and it's this is an unsigned um uh developer tool so just click cancel there you might want to pop up to your system preferences go down to security and privacy oops there we go and it'll say something like hub was blocked from use because it's not from an identified um developer yes these these steps only happen on mac i'm just going to click allow anyway because my computer is trying to protect me from myself so now when i run it i can just click open and i get a nice looking command line tool so if you're running on linux probably won't say anything like that if you're running the windows install you may have to reference the binary directly but you know you shouldn't have to worry about that as andrew has pointed out in the chat i'm actually following along with some installation instructions that are on in our docs so you can check those out i'll also show you here we're following these docs here and the main one to start with is just docs dot textile dot io slash hub accounts that's where we're going to start and then and there's some install instructions in there on how to install things and it warns you about all this stuff so if you forget about it and come back later that's no problem so once we have that installed i'm going to scroll down to this account setup step and what you're going to do is you're going to initialize an account on the hub the hub command line uses essentially a magic link sign in setup and you only ever have to do it once you verify via email and you're good to go so in that situation you just um go call hub in it and you get to pick a username you get to pick an email and then you'd hit enter and it'll keep going and it'll send you an email and you can validate it i'm going to actually i've already created one so i'm going to go hub login i'm going to go over here and check my email whoops and here we go and so when i do that it says success and the um it should show you a little um authenticated page when you open up the link in your email so hopefully everybody is having some success there uh while you wait for the emails andrew has posted in the chat a great little link for ways to use some of this um and some of these tools in your hacks and projects and that's available on our blog he just pushed out the 10 things you can do with the textile hub so there's some food for thought there anyway once we've done that i'm going to just uh cd into an examples folder which is just empty and i have nothing in there and we're going to get playing around so hub init logged in we've created an account there's lots and lots of things you can look at in the documentation here um including um you know how to create orgs so that you can organize your teams around particular buckets and projects so you can create organizations we won't do that here today you can invite other users to organizations you can delete accounts etc etc you can also create api keys so that you can use some of our javascript and go clients for interacting with remote hub to do things like you know allocating data storage on behalf of your users so that you can actually leverage the hub for storing user data and things like that you can explore a bunch of different ways of using bucket storage and that's what i want to show you today all of the apis and all the tools that we're covering on the command line here right now have a an associated client api as well so like anything you can do here you can pretty much do with our javascript client anything you can do here you can do with our go client in almost all cases the go client is the reference implementation the javascript client quickly follows and then there are a few community contributed other language clients like the python pygate tool so i want to show you a couple of command line tools just to create a bucket and add some data to it and and look at some of the cool things that you can do with that as a developer i'm just going to use my developer account that i've created by calling hub in it but you can also use these same tools for users so if you create an app you can actually scope access to a given bucket or the amount of storage things like that you can scope that to a given user based on a public key so pki infrastructure so that um you can actually allocate storage or number of threads or you know whatever any of these hub tools on behalf of your users and so those types of uses are really great for when you're building hacks and apps anyway so we're going to talk about some bucket storage here so a bucket is basically like a mapping of a folder to remote storage you know very similar to like aws style blob storage or file storage so what we're going to do is we're going to initialize a new bucket in this folder and i'm actually just going to start from scratch show you that there's nothing in this folder okay and then what you can do is uh we can initialize a bucket and what it'll essentially do is create a seed and a brand new empty bucket that we can start pushing data to okay so i'm gonna just call hub oops hub buck init i'm going to give it a name ethonline and i'm going to not encrypt the bucket contents in this case because i want the data to be available in plain text later but you could also specify to encrypt it and then you're effectively creating like a private or encrypted bucket and that's also an option and it's pretty cool so we'll enter that and i've actually already got an existing um underlying database or thread that my bucket was created in so um it's a good idea to just stick with the default so i'm going to do that so i'm going to select that thread i've initialized a bucket and then i get back a little bit of output here and it says your bucket links so this is kind of a demonstration of the multi-protocol support that i was talking about earlier so in this case buckets have a direct thread link so this is basically like um how you actually can share information between uh threaddb clients so these are like if you had clients running on different machines they could actually directly communicate about this bucket over the threads protocol that's an open source protocol that textile developed we have a white paper about it and you can communicate peer-to-peer and exchange data that way you can also just access it via that url directly on a public like textile daemon or hub and you can access the data directly you also get an ipns link so the really cool thing here is every single bucket is also an ipns resolvable address so this will actually resolve directly to some data on ipfs it defaults to accessing it over the textile hub and i'll show you in a second um what we can do with that but you can similarly access it over other um gateways so like ipfs or your or cloudflare or whoever and then we also have a this um a different url called the bucket website which is actually allows you to reference uh you know bucket storage directly on textiles hub but right now we have a bucket with like nothing in it right so we want to add some data to it um what you can do is you can publish or push files to a bucket similarly to how you might add something to say a git repository or something like that so what i'm going to do is i am going to create a new file and i'm going to just do the classic um yes thanks andrew and just got a couple of links for our cross protocol support there and everybody should just give a little round of applause for andrew because the documentation for this stuff is i think really fantastic and it makes giving these sessions so much easier um so big thanks to andrew there he also happens to be in charge of my paycheck so you know it's great if you just give him a couple claps uh anyway we're going to just add hello world to an index.html file and so now i've got a file in there called index.html and if i you know capped the content out of that it's just an html file with the words hello world in it okay so now what i want to do is if you're following along here we're just going to call hub buck or bucket push and it's going to say okay there's one new file and you want to push one change and i say yes and it was only you know what 12 bytes or something like that it pushed it and when it spits back at me is an ipfs hash of the content which is pretty cool it's even cooler because again with the multi-protocol access i can access that data directly now i guarantee you there is a whack ton of index.html files with hello world content out there so it'll be really easy to resolve this cid um from just about anywhere so i'm cheating a little bit i would say uh but just to show you how this kind of works here is an ipns link which i'm going to copy i'm going to grab my browser open up a new tab copy paste that in there and i get back the raw ipa fs sort of style information and if i click on index.html there we go there's my content as uh hello world but if i go here and i do say ipfs.io slash ipns blah blah and i do that i similarly access i similarly access it on there so it's you know now i'm outside of the textile you know ecosystem but still access to the same data and things like that very handy and so you can explore some of these other links if you  push something and that's all very exciting but so far you know we're still using ipfs to push stuff and just a reminder all of these apis are available over our javascript and other clients but things can get a little bit more interesting if we jump back to our documentation and there's a lot of information here about what you can do with buckets um they do like local diffing and um like efficient syncing so if i make changes to like a struct folder structured folder or something like that it'll intelligently only push the changed files and do a bunch of sort of get like things which makes it awesome for things like deploying apps where you have build assets you know your react app or your you know create react app and you call npm run build and you get all these build outputs you can push that to a bucket and then when you make updates it's only going to change it's only going to push the updates you can do encrypted ones and you can read all about how we do that you can talk about how you can actually pull data into a new bucket you can seed a bucket from existing ipfs data all sorts of really handy stuff it's all right there here's an example of the rendering on the website but what i want to jump down to is doing file coin archiving so if you jump down to file coin archiving uh a little bit about what you know what this is all about you can check the video there's a blog post about this and of course a big old warning here that says you know be careful what you put on here this is all very experimental stuff um but you know what we're living on the bleeding edge we may get cut as we uh move along so let's just do it so a big thing i was talking about earlier is reducing the time to failure so far we've already tried out ipfs ipns and a bunch of other things with you know pretty minimal time um to figure out if this is even going to work now i want to try and push some stuff to file coin and i want that time to failure to be just as quick so we've made a lot of effort to try and make it as easy as possible to test the waters here a little bit so what we're going to do is we're going to try archiving this bucket um and so you know this is probably not normally a thing you'd want to do you don't want to just push like individual files to filecoin that's just a waste of you know foul coin mining um uh resources ideally you want to push like a whole archive to cold storage um so maybe like a bunch of app data or um you know your entire if you need long term storage for your entire app you know assets or something like that if you're if you're implementing a game and you want those assets available for a long time you know things like that but you know let's throw a question to the wind and try this out so hub buck archive and if you do help there's a bunch of other things you can do but we're just going to do hub buck archive gives us a little warning saying this is pushing to the test net not live file coin because it has not gone live yet um so this data is going to disappear at any time but i'm going to just uh press that and success archive cued successfully cued being the operative word we're archiving something on filecoin this is not a quick process this could take hours to process so this is an async operation so what you're going to want to do is you're probably going to want to check the archive status now you can just do this copy past to this hub buck archive status and it will get back saying look it's currently executing grab a coffee and be patient and that's great advice because it's going to take a while um but if for the inpatient you can always just sit there and watch so you can do i'm just going to type it up hub oops hub buck archive status watch and it will sit there it still tells you to be uh to wait patiently and the way things are working right now is there's only a few miners that are accepting deals on test net right now in the first place um so the archive is currently executing uh we pushed the new configuration the configuration is saved successfully so your deal is sort of set up and now we're just waiting for the deal to actually get processed by the power to find miners to like make the deal on behalf of your app and things like that if you let this sit here eventually it'll time out because who wants to be connected to the hub um for a long time and you can check back in later and hopefully the deal will go through the kind of workflow that this is designed to support is a sort of push and push and wait kind of thing just uh archive and then you can come back in and check if it's been archived later again you don't want to archive a bunch of hello worlds but the idea here is look at how easy that was when you have real app assets that you want to you know preserve on filecoin so i'm going to kill that and then uh and that's not stopping the deal obviously from going through all that is doing is um is just stopping to watch for updates if this if we had a ton of time you'd get something that looked a little bit more like this um and this is the output that uh we would get um so buck archive status w there and it goes through and eventually you'll get the job it'll be executed um and then you'll be pro you know you'll save data to hot storage which is ipfs you'll save data to gold storage which is filecoin and you know there's lots more things to learn about here that i uh and i highly recommend you check out our docs ping us on our slack channel or um some of the channels available during the hackathon or the eats online sessions uh to learn more about all this stuff and i'm going to leave it there we've got what like 10 minutes left so i'll stick around for some questions or discussion um if you've if you've got any more questions i'm happy to take them um and i'll just leave this kind of floating here and i'll check the the chat so if anybody's got any questions you want to post in the chat please do um and you can raise your hand if you want to ask live there's one here's joseph yeah yeah cool is it recommended to create one bucket for an entire app and then create folders inside of that structure or to make a new bucket for user or is this a structural hierarchy that doesn't really matter uh great question um we're [Music] still experimenting with a lot of different um structures so we don't necessarily have one that's recommended per se one thing we're finding is you know it's like anything it's probably not a great idea to have a huge like single flat layer of large files in a single bucket because whenever you need to do something in there it's going to take forever to query it we've spent a lot of time in the buck the the buckets on the buckets apis and on the hub to optimize um you know query times and all that stuff but i think a hierarchical structure is great when you're talking about a tree based structure like a like a set of folders there's a lot of optimizations you get from doing that uh kind of like from getting um uh you know when you're dealing with the sort of query trees and things like that yeah so andrew's got a great answer to that you can create one bucket for your app and then create new buckets for each of your users if they also need to store user uh user data and that yeah that's perfect advice um you know your app you'd have all of your assets in there your users may have file storage that they want um and that sort of thing great question so there's a couple of different security considerations um that you should keep in mind buckets does have fairly fine-grained access control rules so that you can actually do things like allocate access to a specific file in a specific folder and um you can do all sorts of like fairly fine-grained access uh you also have to keep in mind like if it's a org bucket then you know you're going to have uh members of your organization will have access to it so there are like a lot of nuances to how you might want to set that up um so the structure should reflect your security model in wherever possible um so that you know you're not allocating a bunch of different access control rules for a bunch of different files all in the same folder but um yeah again that's probably like that's a good question for a slack thread probably where we could actually discuss you know optimizing structure and things like that uh jeremy what kind of uptime availability can users expect on average um right now we're doing pretty frequent deployments but it's all backed by pretty solid um cloud you know cloud-based best practices we do announce ahead of time if there's going to be any um like disruption i don't know we don't have i don't i don't have any numbers on uptime or availability right now um andrew might have a like guesstimate or even a better number than that but um yeah so the answer is i don't have those numbers yeah i mean it's there like 50 of the time jeremy no i mean it's there as much as possible and we do have people who lose sleep at night if it's not so um you know that's a pretty decent guarantee um the access can be granted to smart contracts too uh interesting the access can be granted to public keys um we're spending a lot of time right now trying to um think through ways to uh allow other identity types um so we are working a bit with the ceramic crew to support like uh dids and things like that uh so ideally you'd be able to use like an ethereum public key but right now the best thing like the our favorite thing is ed25519 uh you know public private keys in a public key as an identity and there are a lot of ways to sort of like derive a random one and associate it with an ethereum account if that's what you want to do and so you could in theory that's a great question i don't have i don't have a like yes you can answer to that but i will try to figure that out so if you want to ping us on our slack that would be awesome uh at assets stored in buckets speed of download is below one second for small oh that's a question and then for small files like metadata is it comparable to cdn and available assets um i'm not sure the for the immutable files um we do take advantage of some cloudflare stuff in the back in the background so you should get pretty decent performance on that those types of assets um but like you know some teams heavily optimized um for you know for like cdn availability and stuff like that and um so it's probably never gonna it's not gonna currently compete with that but it that can be done um i would say yeah cool what sort of indexing and query can we do in data stored on buckets and their metadata there's a great question so buckets themselves are built on top of thread db so the structure of the buckets are actually updated you know dynamically in a doc as a document store so in so that means you can um you can query it like a document so you can do things like you know find the buckets whose name is this or who were created on this date you can look at the bucket schema to see like what fields are automatically created we don't really expose the apis to do those queries very easily through the buckets api but you can do it through the thread db api because basically every bucket is also a database the really cool thing here and just like alluding to you mentioned their metadata the really cool thing here is because buckets exist in a thread basically they are collections in a database um you can also add other collections to that same database so you can actually mix buckets and like additional metadata in the same database as separate collections and so you can query like one collection that stores maybe comments about a file and then you've got your the file as a within a bucket and you can do some really interesting um you know efficiency you gain some efficiencies there because now suddenly anyone who has access to the bucket also by definition has access to the comments and there's a lot of ways you can structure that we're really kind of um yes not as well as i'd like you to be able to um so you can nest collections in that you can create collections and reference the identifiers for the instances of those collections inside of other collections but you don't get what i think you're alluding to which is like highly nested um like dynamic you know so like if i update this sub collection the the parent collection will um reflect that it's not quite like that um but you can nest them in that you can reference them yeah uh and then yeah just one thing to point out andrew said regarding uptime we are also hiring um so if there's anyone who wants to help us add a few more decimals to that uh uptime percentage we are hiring and you should come and help us do that and look at that i have like i don't know a few seconds left on my time um so that's pretty much perfect so i'm gonna stop sharing my screen thank you so much carson that was amazing thanks for all the questions everybody that was great great so a reminder to everyone to stake your spot to hack in the hackathon and integrate with textile buckets do it join us thanks guys have a great one everybody cheers thank you 