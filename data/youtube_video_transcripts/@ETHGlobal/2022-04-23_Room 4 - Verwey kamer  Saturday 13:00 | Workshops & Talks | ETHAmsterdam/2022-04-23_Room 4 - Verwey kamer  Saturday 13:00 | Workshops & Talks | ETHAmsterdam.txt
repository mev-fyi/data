hmm [Music] do [Music] do [Music] [Music] [Music] [Music] so [Music] is [Music] [Music] [Music] [Music] and on the count of three uh in your dreams [Music] [Music] [Music] make a wish 11 11 make a wish so [Music] [Music] so [Music] do oh yeah so all right hello everyone my name is marius and i'm going to talk about go ethereum today i didn't have much time to prepare my slides as you can probably see on the side so i'm just going to wing it and we're going to go a bit into the the code i'm going to talk a bit about uh what the different modules of of go ethereum do and then i thought we had like uh we can just make a lot of time for questions and discussion and and stuff like that all right i wanted to show you uh how a transaction travels throughout go ethereum and this is the the rough overview we we submit the transaction of via rpc and it gets inserted into the transaction pool and from there we we have the east package which handles a lot of uh like so so we have the eth protocol which uh defines um the network messages and and stuff like this in the way we interact with the network and from there we take the transactions and we send we use the peer package we going to enter the peer package and send the transaction to another peer this peer because the same way back through the east package into the transaction pool all right um i think it's uh most interesting to to actually see it so when you uh when you send a transaction via meter mask to your local node um then you will always send a raw transaction you will sign the transaction not in your node but you will send the signed transaction to to go ethereum and it will end up here and from there we so this this is internal eth api has a lot of these these api methods that that you're very familiar with like uh each send transaction ease and raw transaction eth of get block all of these are defined in an internal 8th api and if we follow this now we submit the transaction and what we do we do some some basic checks before uh inserting it into the transaction pool um [Music] and so we uh yeah we we checked that we have enough fees and that the fees don't exceed a certain amount because like we had a lot of people uh mixing up the the value of the fee and the gas price and so they were sending fee sending transactions with like a really high gas price and then they were complaining uh why why why did i lose so much money and so we have some extra checks there to make sure um uh that is that this doesn't happen and yeah then we go to send transaction send transaction is actually in the interface uh from the transaction pool so this is implemented by the transaction pool this interface and we end up [Music] send turn section sent tx something like this no not here how we end up in the api backend sorry yeah send transaction is in the in the api back and the api back-end is something that we use for a lot of these apis um and it's it's it's a collection of methods that are that are useful to have uh for for for creating uh the rpc apis on on top of that and one of them is sent transactions and transaction just uh adds the transaction as as a local transaction into the transaction pool so if we follow this we come to the transaction pool at locals add transactions so the transaction pool it has all of the transaction of transactions of of course and we we sought them and we sort them by by by the gas price and we also have to with 1559 we have like a two-dimensional gas price sorry a two-dimensional gas price and that is uh as it's a bit more complicated how to how to sort the transactions because some of the transactions might be valid at a certain base fee some of the transactions are not valid at a certain base fee so we have to continuously update which are the valid transactions because we we built a pending block the pending block is just the current block that you have and you pile all of the transactions on top so that you know roughly how the next block will look like with the emergence of of a lot of this mav stuff this pending block is basically useless and we're trying to get rid of it the problem is that the pending block is used everywhere and for example if you if you create a transaction um you you will need the nonce right and if you already send a transaction to the transaction pool that is not not confirmed yet you will need to know that there's some transactions so you can increase the nonce once more in order not to replace the transaction if you send the send the same transaction you actually replace it if you send a different transaction with the same nonce you actually replace the transaction um but only if certain conditions are met and the conditions are the the max base fee per gas has to be 10 more than from the from the transaction that you want to replace and the max tip per gas also has to be 10 more and there's some discussion about this if this is actually the the right mechanism but the problem is if we if we don't let like if we don't have this if we don't um if we let someone just update the transaction without increasing the amount that they pay for it then people can just spam the transaction pool always always uh resend the same the same nonce and we have a lot of churn in the transaction pool which is bad yeah so um here we we we add that we're trying to add the transaction to the transaction pool um we uh we extract the sender so we do the the easy recover on the on the signature for the for the sender address and we add it to the to the transaction pool right oh let's see so uh yeah we we we added to the transaction pool and here we we look if we already have the transaction in the transaction pool um we we validate the transaction and if it's underpriced we we discard it and like there's a lot of stuff going on here and in the end we enqueue the transaction [Music] i wanted to go into detail about the transaction execution later on um but i can do that no i'm going to do it later so the basic idea is we're adding this transaction into the into the transaction pool and somehow the transaction pool uh has like all of these transactions now we have to if we go back to the go back to the the picture we we started with with our pc we submitted the transaction into the transaction pool now we have to uh send this transaction to our peers uh so we have uh in in the ether protocol in the eth packet so you can always see the the packet that we're in up up here if you don't know and um in in the eve packet we have the we have the handler and um that handler um has the sync transaction function um and whenever a new transaction um so it periodically asks uh the transaction pool for the pending transactions so the pending trends we have um because of someone we have we have different concepts in the transaction pool um pending transactions are the transactions that are actually executable uh we also have gapped transactions so if i send a transaction that has 9 9 000 and i didn't send 8999 transactions before that then this transaction is kept it's non-skipped because there's um there's some like weird there could be some race conditions about the transaction propagation we actually don't want to throw away all of these gap transactions but we want to store a couple of them so if someone then sends like the missing transactions we can we can uh validate them and add them to the to the pending transactions so what we do here is we we get the pending transactions and we send the the hashes to a subset of our piece so oh yeah it's a uh some of the stuff is a bit uh hard to follow um but the idea is we we we shoved the transactions into this into this announced channel and now i have to oops sorry here we go i have to look where these transfer transactions are actually ending up [Music] sorry uh here yeah in the broadcast it's an east protocol eth yeah sometimes the package names and the packages are not really great and yeah so we have in the handler we shift the transaction into this queue and we uncue the transactions at the other at the other end and uh put them into into this into this queue and this is a infinite loop that runs and if we have transactions in the queue we get them so we only have the transaction hashes in the queue yes we actually get that we actually fetch the transaction from the transaction pool if it's still there if it's by the time that we ended up here uh the transaction is not anymore in the transaction pool we just ignore it um but yeah we added to the to the pending and we send the pool transaction hashes and here we go back where we started and this actually sends the transaction hashes to our peers so um what we do is uh we announce like this there's two different ways that we send transactions we we either send so to us to a subset of our peers we send the full transactions and to all the all peers we send the transaction hashes and uh if someone receives a transaction hash that they're curious and they can fetch it from our node but we don't want like if we were to send our transactions to everyone uh there would be ex extremely uh extreme like transaction churn and a lot of bandwidth that we don't really need um because you would get all the transactions from every peer at all times and so we don't want to do this yeah so now we go to the to the the p2p packet and this just writes that writes the message onto onto the wire um yeah so we sorry um we managed to to push the transaction to the pier now we have to go to the other side and actually receive the transaction and this is done in the in the transaction fetcher the transaction fetcher [Music] initiated here and we have some loop yes and um okay i've never seen this cop before [Music] yeah so um uh we oh that's the timeout the wait the notify yes we get a notification of some someone sending us transactions and so we so we check whether we we already got the transaction we have the announcement from someone else if not uh we actually [Music] ask them to to send the transaction so we schedule the fetches and for each peer we ask them [Music] for the transaction and if they if they have the transaction they send it to us and if and if we get the transaction we actually call the add transaction function no sorry add transaction this one okay no it's this sorry um [Music] and uh yeah so this encues the transaction that transaction into the transaction pool so this add transaction function is actually uh puts puts them back into the pool and so we end up in the transaction pool again we are at remotes so we have we also have this this concept in the transaction pool we have the concept of remote transactions those are those that we get from our peers and we have the concept of local transactions local transactions are those that we get over the rpc uh we have to handle like we want to handle them differently because we don't want to drop our own transactions so we always say if you send the transactions if you send a transaction over rpc this transaction will never get dropped if a transaction from the from the wire is replaced by some something that is that is that pays more then we can drop this transaction and so we have the this notion of local in the transaction sorry and yeah so that's roughly how transaction propagation works and so the next interesting part is how do we create a block um [Music] so the miner any questions to the to the transaction propagation yes so how is it working how is it gossiping in the different section for a little out of years so when one when i'm receiving a transaction i'm recognizing i didn't saw this transaction yet so i'm assuming like then i'm just also doing the same thing and forwarding to your appearance you're forwarding to the square root of of your peers and then you're forwarding the hash to all the other piece and if you if you receive a hash then and you and you have never seen this this transaction hash before then you ask the the peer that send you this hash for the transactions so i i i have to i have to repeat the question uh so so the question was uh if um we are forwarding all the transactions or if we if uh or if we're well validating them first and then forwarding and the answer is we're validating all the transactions before forwarding so our transaction pool only has valid looking transactions so valid looking means the sender has enough money to cover the transaction cost and the nonce is roughly what we what we expect there might be some other conditions but i i i don't know them i'm quickly going to close the door because there's some some sound coming from there um all right let's get to uh to creating a blog so now we have we have a lot of transactions uh in our transaction pool we we are minor we want to see the block how does this happen for that we have to go to the to the minor package and the work yes so in the minor package um there's a lot of stuff going on the miner is extremely complicated so so i already made made sure that we're in the in the right vicinity we somehow end up in the commit work function so uh like the the miner starts a loop uh and whenever whenever a new block comes in uh we need to update our our work package um so we need to build on top of the the block that we just received and for that what we do is we we prepare the work that generates um yeah sorry no all right uh where were we no we were in the worker yes committed work [Music] we we have to prepare the work we have to um f12 yes prepare work all right uh yeah we we we have to um set a couple of fields in the block for example we have to set the the parent hash um to the correct hash we have to set the correct timestamp we have to calculate the gas limit per block you can you can shift the gas limit by a tiny amount um in either up or down and so we have to uh we have some configuration the gas ceiling or gas target this is what we what we want the next we what we want to end up with so currently this is set by default set to 30 million all the miners are trying to hit 30 million 30 million but you can also configure this and yeah so we have to calculate the gas limit we have to set the coin base uh this is where all the transaction fees are uh are ending up in the end um uh if we have uh if we if we have london chain rules then we need to do the base fee stuff um and we have some so we have the consensus engine this can be either eth hash um click or or the new beacon beacon consensus engine and we have to make some environment and so once we once we prepared the block we actually need to fill it so we need to apply the transactions sorry so what we do is we fetch all the transactions all the pending transactions from the transaction pool so [Music] pending just takes the transactions that are actually executable and then we first take the local transactions uh order them and then we take the remote transactions and and order them and if if uh and and then we then we commit the transaction to the um to the pen pending block to the to the pending work package that we're trying to build and so what that does is like we have to set the gas limit and and stuff like this um we we we calculate the sender again we prepare the state and so we have to we have the state database and we have to set some fields in there so that we can later on query them during the execution of the evm and then we call commit transaction and commit transaction actually does apply transaction and with apply transaction we go to the core package so the core package is responsible for most of the core stuff uh the tx pool lives there right now which is not great we should move that to its own package um but yeah so the like all of the all of the interesting like evm stuff and is is in the core package um so we're in the straight state processor now uh we're creating a new evm block context a new evm and then we call apply transactions [Music] apply transaction does apply message and apply message calls this new statetransition.transaction database and this is where we actually do the execution or we start the execution of the evm so we we start the execution of the evm by doing the pre-check the pre-check has stuff like get nonce uh we very we verify the nouns we verify that um oh that's the yeah if it's not fake yes uh we we verify that uh we actually have code there uh no no we've we verified that the sender is in the ua this is a pretty new change previously it was theoretically possible to send a transaction from from an address that had code deployed it's not really feasible to do that because you have to find a collision between a code hash and an and an address that you know the um the private key for but if you if you set code to an address that you know the private key for in the genesis block which is possible then you could end up at some weird state so we don't want to have we don't want to have transactions originating from from from a smart contract um then we have to verify the base fee and then we have to buy our gas and by gas just calculates how much how much gas we are at the the maximum amount of gas that we are going to use in the evm execution later on all right so we we did the pre-checks we have a lot of code here for for tracing so you can you can trace the transaction you can trace each up code you can see which which operations are executed what's the what's the outcome and stuff so if you see config debug and something with tracer you can just ignore it it's not not really interesting and then we check the intrinsic gas we check whether whether the sender has enough money and we uh if we post berlin we prepare the access lists um so in in in the berlin hard fork we we changed the rules a bit uh so that you can provide an optional access lists and calls to this uh to to the contracts that are in the access lists uh are cheaper um you can like preform a a uh a a contract and we decided that calls to the precompiled calls to the sender itself and the recipient should also be warm cost so so the idea was we want to increase the we want to increase the cost for calling a a cold address that we have to fetch from from from the state database because that's a pretty expensive operation and um but that would break some contracts that have some like hard coded limits for for for like interacting with another contract and so uh this access lists are to unbreak those changes and so in the future we can um that they're optional right now we could make the mandatory uh mandatory access lists like the concept of mandatory access list is also something that comes up in stateless um if you're if you're doing stateless you you will provide the pre-state as in kind of access list execute the transaction and then also provide the post state so that everyone can verify uh without having to have the state um [Music] all right and then we check if this is a contract creation contract creations uh if you send a sender transaction to uh to no address to the zero address um with code then the code gets executed and we call the create we call the create operation and otherwise we we call the code at um at the address that we sent to the way that we're doing the execution too um are you more interested in create or call create call okay let's do the call then um all right uh in call um we're we're first checking if uh so so when you call a contract you can attach a value to that so we're checking whether the node the the the address that central transaction originator has enough money to cover that cost then we take a snapshot of the of the state database and [Music] then we had checked the precomp files and there was uh so that there's some there's some issue here i don't know how how many people uh actually know this but back back in the day you could self-destruct contracts um that like there was a hard fork after the shanghai attacks that just destructed all the uh all the addresses without code without storage uh and the problem was that uh vitalik wrote a script script to to to all of this but unfortunately and and without a balance unfortunately uh one of the pre-compiles also didn't have like it doesn't have code because it's it's a pre-compile it also doesn't have storage um and it also didn't have a balance and so he uh successfully destroyed the pre-compile and so uh this this this clause actually checks that that we don't hit that all right then we're doing the transfer we're just sending sending the money and if the code that was sending the money to or that we're calling so we first send the money and then we we're we're starting the code that is on there if it if it's a pre-compile we run the pre-compiled contract so the pr we in in core vm we have the pre-com piles uh yes yeah in the contracts yeah right so this is like the the different pre-compiled for the different uh rules so for example in in [Music] between by in in in istanbul a new precompile was added the the black to f precompiled so it's uh like that there's different uh uh uh different pre compiles depending on the the chain roots that we have and um these pre-compiles have a run function and a required gas function um so this like if you want to implement a pre-compile you have to you have to uh like fulfill this interface and for example uh the ec recover pre-compile for the required gas it's it's it's a fixed amount it's always uh 3000 and if you run uh it will validate the signature values make sure that we we're not inputting something really weird and then does the the easy recover of the of the public key and returns the public key of that of that signature and so this is like a pretty pretty nice uh pretty nice file that's there's a lot of red like really cool things there and i like this code a lot uh other than like some of the other code that i showed previously and um yeah if it's not a if it's we're in the call again uh if it's not a if it's not a precompile we um we get the code of the of the of the address that we just called um if there's no code we're done but really done but um we're finished for now um if we have call if we have a code at that address we have to trigger that code and um so we set the call code you have three different ways of of triggering code you have to call call code some other stuff aesthetic call um [Music] and uh yeah and then you call run on the contract and run [Music] we we fetch basically we fetch in a for loop we've hatched the next operation um and then we look into the jump table uh to see the program that we have like program is like what the opcode actually does and then we execute it so uh how does an opcode look like in the evm uh you can see you know we're going to further not an instruction set oh we're going for the merge instruction set you're probably all interested in the merge um and um like you okay it doesn't do that much berlin istanbul okay here here we have some instruction sets where some instructions are actually set um so in constantinople we had a few new op codes we have the shift left the shift right the shift arithmetic right xcode hash create2 and they all have a a [Music] stack requirement a gas function and um they have like they have a constant gas and a dynamic gas if if there's like some dynamic gas so for for some of the operations um like add or sub you like static gas makes sense like you're adding two 256 bit uh elements together um like there's not much that can like grow grow out of bonds but for some operations you want uh you want dynamic gas depending of the amount of work that you actually have to perform and so for example for create uh you want to have uh you want to spend uh gas as much um uh guess that's proportionally to to the length of the uh the code that you're going to to deploy and we can now look into one of these operations so these are these are functions actually that are that are in there and we can look at one of these functions so for example the create function takes some stuff from the stack it uses some gas and then it calls the create2 which just creates an address and then calls create with that and yeah if if we were to if if we started with the create route we would have ended up right here but we wanted we wanted to look at call instead so yeah so um that's roughly how the how the how the evm works you have these these these operations uh maybe something easy op-ed yeah so uh this is like an easier easier easier function in the in the in the evm you just take uh two values from the stack uh add them together and that's it and um yeah so we did pre-compiled yes and we we are back in call um if something happens so if the like if there's some issue if the if the contract reverts um in in the call then we have to revert the transactions and so if you remember we up here we took a snapshot before we applied the transactions um and if if it reverted then we have to re like we have to reload this this snapshot and throw away all the modifications that we made to the state database all right and um so after um [Music] after after we executed the trans the transaction we know how much we know how much gas there was we we we have to we have some refunds so for example if you clear storage or if you call the the self-destruct opcode uh you're getting some some gas refunded and so we have to refund that and uh we also have to pay the coin base so this is this is this line is where the transaction where the transaction fee actually goes to the coinbase and then we return the transaction result back to apply message and apply message and now we [Music] yeah we have we have the result and before bicentium we calculated an intermediate state route after every every transaction and this is a lot of work so after byzantium we decided to not do this anymore and then we also have the receipt where we set uh if the transaction failed we we're going to set the failed in the receipt i'll understand this and we also set the logs and the bloom so the bloom is a bloom filter um where all the locks are in so the the locks is is every like we have the return op code uh that you can use to right no not the return what's how do you emit an event whatever like if you emit an event in your smart contract then it will end up in the logs we want to filter these logs so for example you you are interested in all the events that originated from your contract um that said i don't know successful or whatever so you have to send successful event um you you have those are in the logs and now you want to you want to quickly filter through all the blocks and this is where the the bloom filter comes in so we put all the logs into this bloom filter what a plume filter is i know probably half of half of the room knows that i don't i don't know if i should uh if i should start going into this but basically um uh you you take some piece of data you hash it and uh you you set some uh some bits in this in this bloom filter and later on uh you can you can hash it again and see if if these bits are set and if these bits are set then you most probably had these had this event originated from um you did apply this event to the bloom filter beforehand there's a chance that uh that you didn't and there's some hash collision um um but it it makes uh it very easy to query for four logs and uh to to see if like something if these events if these locks actually are in the in the blueprint and [Music] sorry um it's two and know four thousand bytes something like this to add to 20 48 bit um now it's it's it's fixed it's fixed length um it's not really valuable anymore and we would also like to get rid of it um but it was valuable at some point because you could you can you could just go through all the blocks look at the bloom filter and quickly decide okay this block has no none of none of my my stuff in it so i'm just going to ignore it and look look at the next block if you [Music] actually find something in the bloom filter that looks like what you what you were looking for then you need to um then you need to go into the block look at the receipts and see if that was actually what you wanted um yeah that's basically it for apply message and yeah you just return the locks from the receipts and we have some error conditions where we're back in the back in the worker where we committed the transaction to the pending okay where we committed a transaction to the pending block and now we have we have built a plan pending block we we took the we we first first of all we set the fields like the parenthesis and timestamp and stuff like that then we went through all the transactions applied them one by one and now we have a a valid block and now we need to actually finalize it create the proof of work but i'm unfortunately out of time so we're going to do that some other time thank you very much [Applause] um you're right [Music] [Music] so [Music] so [Music] so [Music] [Music] [Music] um [Music] [Music] [Music] [Music] [Music] oh the music needs to stop there we go all right so i'm here to talk about the privacy preserving proof of personhood protocol that worldcoin is developing i'll start with a little bit of background and how we got to solving the civil uh the simple resistance problem how we incorporate privacy in that how we've been testing over the past years are our hardware and how we are now realizing that this is not only just cool for us and our token this is actually cool for the whole ethereum community and how we are bringing it back to the community in the form of an sdk that everyone can build a civil resistant application of i'll give some examples of the cool stuff you can build with it and have some little hints on what we're going to do in the future so a little bit of background about the project uh crypto is awesome uh we realized a couple years ago but less than two percent of the world has used it or access to it and the way it is right now it seems to be hoarded by a select in crowd and really hard to enter and it's not not as like growing as it used to be um part of that is the way tokens are air dropped uh what if crypto had started by just airdropping a new coin let's say bitcoin when it was first released by air dropping it and giving every human on earth one token like how would the world have looked like if that was the case it would have been so much more inclusive so much bigger so much different can we do that today that was the project behind world coin what if we built a token mint 10 billion of them and give every person on earth some of that for free we have a problem to solve there how do you make sure each person only claims their part once that is how do you prevent the army of clones to take like how do you prevent people from signing up multiple times creating all these fake accounts or multiple accounts and claiming more tokens than they have a right to obviously this would skew the token distribution therefore the economics and undermine the goal that we're trying to have now we need a solution to this and it cannot be any any simple solution we need something that preserves privacy this is a value that's important to us we need something that is inclusive we really do want every single human being on earth to sign up we don't want there to be arbitrary constraints on that and we need it to be scalable turns out there are a lot of humans on this planet so we've considered a whole bunch of options um we can have people sign up with with emails uh email addresses or phones um pretty common way to do civil resistance in your web 2.0 app unfortunately it is completely insecure and easy to anyone can make new email addresses and phone numbers are surprisingly easy to steal especially for sms verification so the other approach that is the go-to approach in the financial industry is to use passports id cards official kyc documents this is actually not as inclusive inclusive as you think it is a lot of people don't even have these documents it is also the complete opposite of private so that's a no-go some of the cool solutions that have been tried in the past is web of trust where you create a community that authenticates each other and these mutual loops of authentication in the end build a system that can generate a lot of trust like spontaneously out of the way it is structured the problem with web of trust is that the attempts that have tried have not been particularly successful it also suffers from a major bootstrapping problem where you really need to kick-start it with a very large community for web of us to be meaningful so that's not an option for us at least not right now so what we settled on is biometrics everyone has biometrics um we can do this in a private way it is super inclusive so let's look at that a little bit more there are a couple of biometric solutions that are popular fingerprinting palm printing dna although not used much yet there's issues with all of them fingerprints surprisingly are not very unique i think the um the match rate on a finger fingerprint is something like one in a million if not worse than that um same similar with with for example face recognition now these are good enough to unlock your laptop and unlock your phone because the attack factor there is you have you have the real user stored in your system and you just need to compare whoever you have in front of you right now against this stored representation um so if you have a success chance of let's say one in a thousand this is already like a good deterrent like an arbitrary person would not be able to get in randomly the chances are very low however for what we're trying to do we have a much harder problem we need to compare every new sign up against every sign up in the past this is quadratically worse you now have to deal with the birthday paradox for example which means that the chances of duplicates accidentally matching goes up quadratically with the size of the group so we need something that is very very unique not just fingerprint unique or palm print unique but much more unique than that dna would solve it but even that actually has a i think 0.7 false positive rate due to identical twins but other than that there are just no good ways of doing it something that does work and can be used conveniently are irises every human eye every human eye is unique in a in a very particular way and you have two of them so that's like double the entropy right there so irises was the way to go then we looked at okay so how do we do biometrics on on irises can we use the phone camera well turns out phone cameras are not nearly good enough to take a high resolution picture of an iris it's surprisingly hard optically to take a good high resolution close-up of something that is so small and so far away realistically we've looked at off-the-shelf biometric equipment like for example the clear scanners that you see on airports they are not very convenient to use you need to hold your head in some weird goggle the resolution is surprisingly not that good because again they just need to compare yourself against a stored representation they don't have to deal with the quadratic challenge that we're facing so we needed to improve on the state of art of irises and we needed to do that with custom hardware so my life there we are that's a big problem to solve for uh for the theme so one eternity later and this this literally took um two and a half years of development we now have our biometric device that is capable of civil protecting a set of a billion human beings so what does this this device do it makes sure you're real this is something i think a lot of people don't really grasp fingerprints are not really secret you leave them on every single glass on every restaurant you've ever been to um and a fingerprint alone like the information contained in the fingerprint is not what identifies you it's not what authenticates you what authenticates you is that you're the only person on earth the only human being that has that exact fingerprint on a real life finger and it's that last part that is critical you need to make sure that not only are the biometrics what you expect them to be you need to make sure that they are actually on a real human being so that's what the orb does it make sure it's looking at a real human being um it looks at your iris and not like a contact lens that pretends to be an iris or anything like that and then it takes a picture it turns that iris into a into an embedding essentially a 100 dimensional vector that can then be compared against others and it signs that to authenticate that this is now a verified iris code so a little bit on the hardware itself because i think it's just very exciting we'll be open sourcing the hardware soon so you can actually go through the schematics go through the design files go through the firmware you name it um it's a lot of cool engineering there it's basically um well there's one right here actually so you can see there is this sensor area in front it has a lot of biometric security sensors in there uh things like you name it thermal cameras whatever we need to make sure that whatever is in front of us is a real live human being and not a picture that someone's holding up then there are different rings of leds there in different wavelengths so you can photograph the iris in i think it's six different wavelengths that we're using currently and that helps us gather even more entropy on the structure there and then there is the the big hole at the top of the little circle there contains a very high resolution zoom camera with a aimable mirror that can really really efficiently track you while you're moving because we wanted the experience to be smooth like we don't expect people to stand absolutely still you can just hold it in your hand and the camera has a focus window that is basically a centimeter size cube that it will perfectly track um while you're holding the thing in front of you and then it has wireless connectivity so it can connect to the blockchain and you name it um yes we'll be open sourcing the inside design for those who want to know more you can also check out like what sort of things we do to further protect the orb itself but let's talk about privacy a little bit because so far we've been talking about taking pictures of people but we do not want to store images we do not want to store names we do not want to store contact info we do not want to store your kyc info d we don't want any of that so how does that how does that fix um how we do do we fix that we're not quite there yet we have now now we have this 100 dimensional iris code but the naive implementation would just you would basically submit this iris code to the blockchain it would check if it was already there and if it wasn't there it would kind of bless your wallet as being a unique human but this is this is not very cool because now you have an address that is directly tied to an iris code so like in principle you could go back to an orb and check if this address belonged to this human we don't want that and it only allows you to create one wallet that's not very nice like you should be able to create pseudonyms you should be able to do a lot of things under your identity really so that's where the next step comes in which is zero knowledge proofs i'm using an anonymity protocol called semaphore that's basically the anonymizing parts of like say tornado cache and cache but without all the currency stuff and just the pure anonymity primitive the way it works is you you install the mobile app and the mobile app generates a semaphore hash which is essentially a public key here you show the public key well the wallet stores the private key the public key gets shown as a qr you walk up to an orb you show the qr code to an orb now the orb knows the public key your public key then it does the biometrics thing and it generates this this little vector the iris code embedding it combines these two pieces of information together and authenticates it with the signature and now you can send this to the blockchain and when the blockchain verifies that it hasn't seen a matching pair of eyes before it will add the public key to a big merkle tree that's step one now you've signed up now you're part of the ecosystem of all humans you're in the miracle tree of all humans we've we've signed up now in order to claim the world coin token uh you use the private key from your wallet you generate a zero knowledge proof of a merkle proof that you're in this tree and you send this to the contract using any address you want you can generate a new address for it it doesn't matter then the zoo knowledge proof gets verified it checks that the merkle root matches that you're actually in the set it does a couple more things that we'll get into in more detail later and then you receive your world coin tokens uh in in your wallet address and there is due to the zero knowledge proof layer there is like no connection between the original iris code that you use to sign up and the wallet that you received this token in at best you can say that yes this was someone who was in this set of users but that's the end of it so we have our privacy back like the only the only information that is ever attached to the iris code is that they're now a member of the set of users and you can really learn nothing else from this data so that's awesome it sounds like we have our technological solution ready we have our hardware developed we have our blockchain parts solve we have our privacy we have our we have our scalability we have everything so we started testing this project we've built some prototype orbs we've been going to several different countries around the world to see how people receive it we've been doing field trials in 25 countries pretty much uniformly randomly distributed over the world just to see how people respond to receiving a crypto token just based on the fact that they're human like the original these is like what if we actually airdrop it to uh token on all humans and the responses have been like very exciting and overwhelmingly positive um it really depends it depends on where people are in in rural communities in developing countries people just like the fact that they're included in the financial fabric they have historically been excluded they um don't really have access to banking like uh the unbanked definitely exist and there's definitely a benefit in helping them with technology like this but also in in like european cities a lot of people are excited about being onboarded into crypto like they haven't they've heard of it they're interested in it but they don't have a good way of being included in it yet and the orb the process of sign up and the token drop is a really great way to onboard new users we also needed to know how well this scales like how many of these orbs do we actually need how quickly can we sign up a billion users so we've been running an experiment in in chile with at most three orbs at a given time there's a whole model around how these orbs are distributed how people can bid on renting an orb and how they get rewarded then for signing people up and so on and local people even tend to start small business businesses around that so at the end i think there were about 30 plus people active in chile helping people sign up and we had an average weekly sign up rate of 1.5 000 each week up to 2 000 mostly limited by um by some constraints of the early prototype hardware so as we as we improved the hardware um the signup rates actually went up and the latest orbs are really efficient like you can really quickly sign up large groups of people uh yeah this is actually a cool picture of how you can see how the orb developed along the way well what's what's interesting is that in in the early iterations there were actually two cameras that were looking at each eye individually and as we got better at the optics and the aiming part of the optics it turns out that we can do with just one very good camera and just keep switching it between both eyes quickly like the tracking became that good um [Music] so the field trials went uh went almost better than expected really like given the small number of orbs prototype orbs we currently have we managed to sign up half a million people in in the last couple months um and currently we um we are switching our orbs to mass production so we have about i think 30 orbs now that are in the field for the field trials for the version that we have now we are scaling up production and we'll be producing 250 of them this month and by the end of the year it will be i think up to 4 000 per month that we are going to be producing so extrapolate from there and you'll see that it's actually feasible to onboard hundreds of millions if not a billion people into this civil resistant token airdrop so that's cool we can airdrop a token on a billion people and then the devs ask us but wait can i do the same can i reuse that verification for my app well it turns out the simple press the civil resistance we built is actually really really useful primitive for a lot of um adapt developers there so how can we offer this on its own as an as kind of an independent thing people can use um so let's do this um and one of the key things again is we want to preserve privacy at all costs so one of the things people always tell us like oh you should do a non-transferable nft that identifies your humanness but the problem with that is that it's essentially a white-listed wallet or a public unique identifier like yes it would work for the civil uh civil resistance but now you would just have one wallet address that is blessed as like your unique human wallet and if you vote in a dao and if you then participate in an airdrop you can see that oh this person who received this airdrop is the same person as the one who um who voted that on that proposal you don't want that you want to be able to have a proof of humanity while not being able to link all the actions you've ever done together and this is possible thanks to the zero knowledge proof magic that is in semaphore and we're building and a whole sdk and a user front end and everything around that that we call world id we've just launched the alpha today in a workshop let me quickly go through what it does so it's a protocol to anonymously verify that someone is a real person that is performing an action only once those are the three key aspects that it does so for your users it would look like i'm a real person and i've never claimed world coin that's what we do currently but you can also make the claim i have never voted in this poll i have never minted uh this nft and so on um and all these claims you can make and they get verified against the uh the merkle tree and another technical thing called a nullifier um but you never you never do anything more than make this claim like you cannot link these different instances together the way this works is actually rather complex it involves a lot of different steps but it turns out in the end you can abstract all of this away in the super easy to use api all you need to do is import world id from our sdk and just get a little box in your ui you need to specify an external nullifier this is sort of a context this is the context within which you want to make sure users can only do it once so if you want to make sure that everyone can only fold once you need to generate a unique id for each vote that you can put here if you want to make sure that any anyone can only claim your airdrop ones you can for example take the airdrop token address it basically needs it needs to be some context that like something that uniquely identifies the context that you want to allow everyone to do an action in only once and then you and then when you set it up you you get this little widget here and you just check that hey i'm a unique person doing this for the first time um it's a very simple javascript widget you can integrate it in minutes it it's designed to resemble the captcha because that's something people are familiar with and there's also quite a bit of conceptual overlap between a captcha and what this is is not entirely the same though because captchas you can solve multiple times it doesn't prevent you it captures captures are rate limiting and they make sure that there is a human in the loop but they don't really solve the civil resistance problem whereas our solution really solves the civil resistance problem and another fun thing that we're currently not using but that i kind of like is that it doesn't prevent you from automating your own stuff like with a captcha i like i like to write little python scripts to automate my life and captchas are not good for that um because i cannot auto debate them but this one you can actually automate and it would still prevent you from doing something more than once so it solves sybil resistance in a way that i think is actually superior to captchas because it doesn't stop you from automating quick example um let's say you want to do an airdrop and you get 50 worth in mesha a little claim button and then by integrating the widget you have this little thingy on top the more you click claim you just press it now it uses a wallet connect to show a little qr code that you can open in your mobile wallet you sign off on it and there you go identity confirmed and it proceeds and now what you get back is a zero knowledge proof which is just eight viewing 256's really that you can pass along to the transaction you're about to make and verify against the contracts we have and that's it now you have a transaction that every human can only do once it's as simple as that this is an example we have with a lot of documentation you can play around with it you can find it on vaultcoin.org amsterdam a couple more i think so what what is this flow like um so your users the users get the world id using the ark they sign up um you as a developer you integrate the world id uh widget in your the app um the user verifies the uh the world id claim in their app it pops up in there and then as a dev you can execute whatever action on chain action you want exactly once it's actually super flexible these are some of the use cases we've thought of but cool thing about an sdk and a hackathon is that people come up with all sorts of crazy ideas you can do demographic voting very hard right now everyone does token voting not so much because they like token voting they do they do it because it's the only thing we know how to do right now um but if you are able to uniquely recognize people you can do actual one person one part one person when vote voting or you can even do quadratic folding the airdrop use case like we do we think this will be a big early thing because by air dropping a token on all humans you can quickly grow a very large user base uh quadratic funding requires voting to really execute properly you can create nfts that are tied to unique humans you can create new accounts on websites and have civil protection in like a web 2 kind of way you can use it to replace some of the fraud prevention that you that you would normally use kyc for and anonymous registration on let's say social media where you would want an anonymous account but you don't want all the um all the anons or the old saudi bots um that's why we have the the whole sdk there is there's a protocol there is this javascript widget that i showed you as lots of documentation that we are currently writing we have simulators for this stuff so you can try it out locally easily and a bunch of example projects we have a discord if you want to chat about ideas get some feedback get some help with your projects i want to do a big shout out to the semaphore project whose open source solution we use to get the anonymity right another another project that's cool that we've been developing is hubble um hubble is a layer two it's less well known but it's basically an optimistic transfer only rollup which uses bls signature aggregation and this allows it to be an order of magnitude cheaper than all of the other l2s that are out there right now and for us this is important because we want the world coin token to be usable in uh for all people all over the world and right now with even like ethereum fees are just inaccessible for the vast majority of people on earth and even l2 fees um fees that are in the order of like one to two dollars are just not useful if your balances are in the order of ten dollars so so income's hubble which actually brings it down by another order of magnitude and we've been developing an open source sequencer for that in go uh that is high performance that can actually handle the transaction volumes of that many people so that's another cool project that we're building on uh semaphore as it is currently and as we're using it currently it does a lot of stuff on chain and it does a lot of like every sign up and every claim currently requires a an independent interaction with the smart contract which costs 400 000 gas to just do the verification bit obviously that doesn't scale very well for for example for voting use cases you don't really want a an economic hurdle that prevents participation so for voting it's important that you really get the cost down so for summer 4 we're working on an l2 style like an l2 ish solution it's basically just a sequencer that can do batching and aggregating of these these transactions and then use a recursive proof to submit all of this at once and you would be able to check multiple claims multiple people in in one transaction at a fixed cost all of this is open source uh we've actually yesterday um no way last week we did a big big post on why open source is important to us um how we are planning to open source things it turns out open sourcing hardware is still relatively new and and kind of difficult in some ways like for example somebody optics has drivers that were that have proprietary source code that we're not allowed to share so that part unfortunately won't be open sourcing immediately we also don't really want to help people create better surveillance hardware so we decided to open source the orb hardware under a license that specifically forbids any surveillance or privacy invading use case fortunately irises kind of suck for surveillance purposes it's much more cost effective to use use face recognition because you can do it at a distance without active participation if you want to get someone's irises like honestly it's hard enough to get a good image of even someone's irises uh with their active participation so there's like this nice consent element to it that i kind of i kind of enjoy um what's our roadmap um so yeah we we're working on batched ckp submissions if you're excited about uh working on recursive snarks then definitely hit me up we have a lot of fun stuff to do there we're working on a sdk for mobile apps if you're not having a web app but you would be able to integrate it in your mobile wallet multi-chain support we'll be collecting the we'll be constructing the mercury itself on ethereum l1 because of the extra security it provides but the sdk we can deploy on any evm compatible chain easily and you'll be able to run it on use it on on polygon or optimism or your favorite chain what else is there um so there's this concept of uh signals in the um in the juveniles proofs uh i can quickly go into that that's basically for an airdrop you just need to claim that you haven't done it before but if you want to implement something like voting you not only need to prove that you haven't done it before you also need to prove that this is the thing you want to vote for so there's this extra piece of data that can be attached to the proofs which we call as a signal and and yeah the roadmap so we're currently in in an alpha we have our first proof of concepts of all the technology we have our technological roadmap we we have the hardware done so now it's kind of the the blockchain side of things that we're developing out and it's a fast moving space so we'll probably adjust as we go along for example hubble the l2 that we're using i'm i'm kind of hoping that the other l2s will adopt signature aggregation either through bls or xenons proofs and then we can do away with our own l2 and just be nicely on polygon with our token in the summer we'll be we'll start actively signing up users at a at a fast pace using the the mass production hardware and we will be iterating on on the earth the earlier projects that want to build on our sdk and late summer we'll be just opening it up for everyone to use for whatever they want to so that's what world ideas solve civil resistance at scale in a in a way that preserves privacy anonymity is very self-custodial and you have your own wallets it's essentially no different from other wallet management other than that your public key is registered in a special way it's fully open source you could even build your own wallet implementation if you wanted to easy to use and implement and like i said we're opening it we're opening all of this up we're uh trying to release as much of the source code as we can we're trying to reach out to the communities we use like like semaphore contribute contribute back basically be good citizens of like the ethiopian ecosystem um and yeah that's the end of the talk um we still have about five minutes left so i want to open it for any q a i have this microphone to pass around so i had a quick question about um what's your approach to dealing with collusion like either people getting together and just getting a bunch of votes together like scan scanning a bunch of eyes together but really kind of do again under one person or buying votes later off of the people who have scanned it and things like that does it kind of make sense uh yes there is all sorts of um fraud mechanisms that we've thought of and that also um we saw in in the field trials that's why we did them to just see how people respond to it in general any kind of imposter attack we feel like we've covered so yes you need an actual human being to sign up when it comes to selling your wallet what we're working on is being able to reclaim your wallet by just re-signing up again um so yes if you if you if you if you if you signed up and you participated in an airdrop and then you sell your wallet then yes that token will be sold but like that is the self-custody aspect of crypto if you sell your token it's someone else's um but you cannot really um buy someone's identity reliably because this person can just claim it back at any point in the future it thanks could you run me through what happens if say i have this widget on my website your alpha widget and the user clicks on it what does he see what steps does he have to take to verify that yeah he's indeed human and other conditions are met so that he can participate in the airdrop he doesn't need to scan his iris again right no no so the user will have the world id app on their phone they can scan the qr code and then the phone has the private keys that were initially used for the sign up and that is sufficient to generate a zero knowledge proof that you're a member of this set and that you haven't participated in this particular thing before all right so yeah the use case grows as more people get onboarded by by scanning the irises right like the solution does work but as you noted in the beginning of your presentation reason why most people use kyc right now is because everybody has a passport and everybody can participate right that's yeah maybe the bottleneck with the orb that's not everybody's claim to assume that everyone has a passport that's that's definitely not the case globally oh okay okay um but then it's still like the scaling i understand you you guys are mass producing the orbs but yes like to get everybody scanned it's quite uh as you said like you did 1.5 000 users per day at a certain point i thought yeah yes but like if you just look at birth rates and stuff like it's quite hard to keep up right uh just no i'm not not like yeah i'm just curious how you're gonna oh yeah i i i did some some math on like what what our projected sign up like we know what the odd production rates are because that's all on the under under contract with like a high quality manufacturer we know roughly what we can expect in terms of the sign up rates from these orbs so you can you can compute a transactions per second that your blockchain stuff needs to handle and it's between the 10 to 100 of transactions per second so it's like what it's like to two orders of magnitude out of um out of realistic for ethereum l1 but if you do some basic aggregation sequencing use some of the existing l2 techniques we've developed over the past two years you can manage it so it's feasible okay right yeah first yeah just last remark is that yeah i think it's very like very ambitious and very well done so far um curious to see where this goes and um yeah if if there's a lot of users that are basically verified by you guys then yeah we would be definitely open to trying your your witch doubt as well awesome yeah yeah we're very curious about how it will go as well it's not it's not been tried before like this is this is um this is a very interesting experiment just to see if this is the right approach to to do it and we're pretty confident that this will work yeah yeah i agree like captchas are like over capture software and honestly um kyc based identification that's that's just another trust mechanism like yes if you trust your government it's fine but you know not all governments are trustable and in fact there have been historically instances of of um tiny countries that were handing out millions and millions of passports to uh to people for bribes so it's just not a very it works in like the small part of the world that you and i grew up in but it really doesn't scale well beyond it and that and that's not even talking about the privacy issues around it so that was an excellent presentation thank you for sharing that i thought it was very concise and clear um i guess my my question is uh you probably spent a lot of time thinking about what could go horribly wrong unfortunately yes [Laughter] socially through scalability technically uh culturally um do you want to share some of the thinkings that you have of the things that could go wrong um i mean what what can go wrong we've seen people trying to sign up their dogs for example we we obviously filter for that uh we also filter for children we we want to make sure that people are adults when they sign up like maybe in the future um like it will make more sense to be more inclusive here but right now we just want to take the conservative approach and make sure that yeah make sure that people that sign up are well educated know what you're doing i got two questions first is a link to mobile which is kinda sounds like a weak point uh because you can lose mobile you can uh someone can well if they still mob yeah they can still mobile because uh like once uh once uh once you're signed up uh your key your key is sufficient like to do whatever you whatever you want with this correct view with your address so so this uh is there any recovery mechanism or any blocking mechanism because now if i lose my private keys if i quick enough i just move my funds to another to another address here it is already linked to one private key so if i lose this private key it means like basically like everyone will have access to my to my identity like to me and basically even to my funds yeah there's two components right so this um there's the private key that you use to uh to sign the claim like to sign this like unique human claim and then there are the private keys that belong to your wallet they're different private keys they're just stored together in the same wallet and honestly this is an area where we don't want to be super innovative ourselves because what we do right now is just the same as every other mobile wallet do and we will do we will do the same thing like seed phrase backups if you want back it up in your icloud or whatever um have it replicated um maybe even hardware wallets like you can just use existing it's basically just a fairly standard wallet um that you can use there for your wallet private keys all of this is the same for your identity private key you're right this is a little bit different and there the recovery mechanism will come in handy where you can just go back to an orb and just replace your public key with a fresh one based on that hey you're actually matching this particular iris that we saw before and another one is especially because the hardware will be open source so like when when i do scan myself i actually have no way to prove that uh that this is legit hardware that it's not actually stealing my data that it's not still that it's not copying me and like sending to everyone or whatever like i mean i don't have any way to verify what what's going on inside the order actually and this is the traditional hardware wallet problem yeah still unsolved we're open to ideas we think open sourcing is a good step in this direction auditing the supply chains would be another important thing we can do here i have some fun ideas on how you can create a little bit more self-custody around this but yeah we're running out of time so we can talk about that outside of the meeting all right i think it's time for our next speaker so i'm open to [Applause] hey um [Music] [Music] sacrifice tonight [Music] sacrifice tonight [Music] [Music] [Music] [Music] [Music] what you sacrifices [Music] [Music] [Music] wow [Music] should we get started okay thank you all for coming so today we're gonna talk about foundry uh development framework i've been building with paradigm and some other open source contributors for the people that don't know me hi i'm georgios i work with paradigm we're venture capital firm i'm the city owner and so we're going to talk about this now what's the problem when writing tests for solidity contracts developers have been trained to use frameworks like hard hat or truffle or brownie and typically the issue there is that you're writing your contracts in one language but your tests in a different language and you end up having to remember a lot of things you switch contexts you go from solidity to python back to solidity all the time and uh personally whenever i contact switch a lot and when compilation takes a long time the 15 or 20 seconds i spend waiting they're not 20 seconds they're more like two three minutes because i i'll tap the twitter and just start scrolling because i'm waiting for my code to compile so there's a lot of places where we can improve things and we identified that the way to get the most benefits is by combining the language that you write your tests so you always write your tests in the same place where you write your contracts so we're at testing solidity and we also identified that fuzzing which is the act of writing tests which cover more edge cases in your code to put it very in a very high level way was also hard to do so we also seeked out for something some way to get easier test coverage get better test coverage in our code now there's also this library which people personally i dislike a lot js.big number which has caused a lot of migraine hypertension and stress uh especially when migrating for from hard hat or from truffle or when you use web3js or etherjs so how do we solve this um we write our tests in lydia as i said so this saves you from context switching you always have the same syntax it also lets you feedback into solidian like kind of provide feedback for the language so that the language improves itself over time and candidly it doesn't make sense for you to be a smart developer in spending 60 to 70 percent of your time writing javascript um we have proper debate property-based testing i'll get to that in a bit uh basically instead of testing for one concrete test case you test for hundreds or thousands of test cases for the same properties we allow vm state overriding this is the equivalent of let's say you have a storage variable that you want to change without having access to a smart contract that can change it you can literally modify a storage slot in an arbitrary address and you can use that if you're mocking if you're trying to imitate an oracle or anything else that you want and there's a lot more actually in the vm state overriding category and i'll get to that in a bit with respect to compilation and testing we want everything to run blazing fast so ideally you run all your tests in parallel you basically the problem is embarrassingly parallel so you should be able to spin up as many threads as your system can support we use a very fast thrust dvm which means that even without parallelization things are very fast and we also do very aggressive we also won't have very aggressive caching on the dependency graph and the thing that is the most underrated is runtime observability and debugging which you will see some screenshots in a bit but basically when a smart contract is executing you want to see every sub-call that has happened ideally have a debugger that you can step through things so you can know what the hell is going on so the name of the tool that solves all of this is called foundry to see if this matters if people should care we started developing around the end of 2021 and in five months we're on our way like to meet hardhat at the top and we'll see what happens people have started using it a lot you can see this in soul mate which is an upgraded open zip alien contracts repository optimizer uses it maker dow uses it mapple notably had their tests go from 30 minutes to 30 seconds which is a lot is a big improvement and these are the guys building the synapse bridge um so far we have about 100 something on the source contributors in again less than six months which shows that the project is open source first it is building with the community rather than only for the community have very rich docs templates a github action a standard library with popular contracts used for testing and for modifying those of your code and of course the core code base so let's see how does this look like so again i'll take a trivial example set function of doubles and initial value 1 for x and normally you know if you were doing hard hat you would write describe you would import ethers you would launch you would get your wallet blah blah blah it's a big process and you need to remember a lot of things whereas here you're at your setup function this could have been constructor but this is just for to make it more explicit think of setup as the equivalent of before each in javascript and a simple unit test you do require food alex is the initial value so this should obviously this assertion should pass and then you double it and then you require that it's two and you would expect that this test passes um if you have a test that fails and you want to check that it fails because you're writing a negative test and it's important that we also write tests that are not in a happy case you write test fail instead of just test and it would expect a revert to happen and if revert doesn't happen then it will actually show test failed because it was hoping to fail and also i realize i'm compressing a lot of things in a very short amount of time so in every slide there's this link to the docs which you can read and the book it's very comprehensive and gets you zero to hero in a weekend so i recommend it now property-based testing is this process where instead of me giving the inputs uh i make my test generic over an input you just give it an extra argument and it proceeds to run it for tens hundreds thousands of different inputs so this it will get run with one two zero ten thousand five thousand million a jillion whatever um and we'll keep doing that until until either it reaches the match number the max number of iterations or it finds a counter example and if it finds the counter example it gives me the input which found the counter example and then i can write a unit test for it and guarantee that the bug that was found during the fuzzing process it is never encountered again and you can obviously see that this is extra important well when building math libraries like in all of defy because let's say there's a rounding error let's say you have a division by zero let's say you know there could be any kind of edge case in hyper-optimized math so ideally you want to test as much as possible the properties now vm state overrides it gets back to the point that i made earlier about being able to hook into the vm basically in hard hat whenever you want to do some state of the ride you would send an rpc request called hard hat underscore something one example is impersonate account another is set code another is set storage um here instead of doing it over rpc with specialized calls we have a cheat code which we call it which lives at this specific address and this is for historical reasons because foundry was developed after a tool called dab tools which was before it and they also had the same address um so the way that this works is that you have your contract and you define this you define the interface you would import the interface typically from the standard library that i mentioned you would instantiate it at the cheat code address and then you have access to all the cheat codes and i have the cheat codes here and you can take a look at them but this very simple cheat code called warp and again for extra context these are all maker dao inspired names that's why they're like three four five letters with like very like memetic let's say naming um and you can see here that you can do vm.warp number and we'll override the timestamp to whatever value you want now this for anyone that has tested governance contracts using compound it was a big pain in the ass because you had to mine like thousands of blocks to advance two three days in the future and there's another cheat code called roll where you do vm.roll and you can skip to whatever block you need without waiting like a minute for 40 000 rpc requests to go through for mining 40 000 blocks so take this and imagine that there's like 30 cheat codes like this which let you plug into any kind of vm state and start to get very very powerful the compilation pipeline is the fastest in the industry we beat hardhat consistently on all benchmarks and across open zeppelin contracts and v3 core units of v3 core um we see that the more caching involved the more they converge into the same value and that is because simply there's no more salty uh invocations or there's no there's just no compilation going it just says you know cache don't do anything but one very interesting thing is that defaults in code bases matter a lot so open zeppelin contract is ripping is written in javascript which means that it has low overhead of just starting the interpreter whereas v3 core is written in typescript and it has a bunch of plugins which are required to do normal operations on a daily basis which means that anytime you do yarn test it takes a long time until it starts to comp to actually compile it just doesn't reach the code path so you see that even though this is fully cached um like in forge it is instant because it just says run the compiler it doesn't say anything it takes like half a second or even less whereas here it launches the interpreter transpiles loads the plugins and then gets the code path about the compilation so the point i want to make here is that the benchmarks that are affected by third-party non-compilation related stuff but the same time defaults are the most important thing and if we're looking to benchmark what users experience like if i need to configure your repo to compile faster like maybe you should do it so for testing i think we have very very impressive results specifically compared to the up tools on certain benchmarks we got a solid speed up you can see that you know going from many minutes to under a second your your productivity is just completely it's a different world um versus hard hat we rewrote some tests from v3 periphery in solidity and we saw an over 16x improvement i think this would be more if we had fast tests and even more tests because our testing times they're kind of invariant because we parallelized so much like the test cases they are maximally parallel so they scale sublinearly with the amount of tests that you add whereas hard hat and all the other tests they just they don't do that because they defer to moca which is not that fast but the most important thing here was comparing it against hosted services so all of these they give you simulations um you can do it with block native which has a simulation service you can do it with tenderly which also has a simulation service um and these are local but the most interesting thing was when using a remote node our literally the way that we fire our forked mode rpc request let's say that you're testing against mainnet and you want to ensure that some some pool is liquid or that maker dao the maker dow shutdown function works correctly in this case the convex shutdown works correctly i request without caching on a remote node there faster by a like solid amount i would say um on when using a local node so instead of using infura when i'm using localhost 8545 we're still a few times faster and when we have caching that's when the true speed is shown where we take half a second next fastest is block needed with 3.5 and then tenderly with whatever and then you see how it goes so it's very fast and speed translates into productivity productivity translates into money made and money saved so good um now let's get into runtime introspection uh which is very useful when debugging so when you add verbosity arguments to your forge test command and dash m just says run only test owner tests it will proceed to give you these nice structured call trace now what this means is that a green call is like you know i have a contract called gm uh it has a function and then inside in blue it will always highlight cheat code calls in green it will call our successful calls this is the return value here it has nothing here it says good morning it highlights it if it's a static call if it's a delegate call if it's a call code and if it's a reverting function it will paint it with red but one thing to notice here is that even though you see here it reverts it propagates reverse message up but here it doesn't revert and this is because this specific contract uses try catch under the hood so the error is handled at a lower level but if it didn't handle the error this area would have been red as well and the test would all would also have failed probably and you can see that this is like ridiculously fast it's like 500 microseconds it's nothing now the interactive debugger is something that many people have asked and it is what you expect jk to go up and down you scroll up codes it has a source map so it goes through the source code and it knows where you are and highlights it it shows you all the values in the stack and bear with me like for how it looks like here it's because it's a bad screenshot it shows you the memory um and yeah as you keep stepping through this is very useful when gas optimizing shows you gas reports so this is a standard feature that has existed for a while in every framework so we're like probably we should add it looks quite good it's very very easy to install you curl this link you open a new terminal or you source your file you run foundry app it downloads about 15 megabytes approximately and then you immediately have it installed there is no cargo requirement no npm everything is full across platform you literally you unpackage a new m1 you install it and you're set in 30 seconds or less actually so the onboarding experience is crazy good all right so future features faster and stabler most importantly so there's obsession with speed and we're not going to settle because we can just do it better stabler because we don't have a weekly or bi-weekly release we actually do nightly releases just because the project is moving very fast there's a lot of productive developers on it and it also creates a nice like vibe around it that you know these people ship um we're adding new commands uh the most important probably is this one the scripting and deploying right now the deployment experience is not good and it was not meant to be good because we were focusing on a testing experience now that people have started to actually use the framework we are adding deployments in solidity which means that you write the solidity smart contract and you can use the same code to test your deployment in your tests and then this code can also generate transactions which you can post on chain and would manage the life cycle of transactions you'll brokers them all in parallel it would escalate gas prices this is all infrastructure that we already have from mv traders that use the underlying libraries under foundry ford script the same but not for deployment just for doing chain operations let's say i need to deploy a governance proposal or i need to do a vote or i need to i don't know buy an nft or something um forge fmt and forge lint are what you would expect fmt is a formatter so we're going to replace the prettier and prettier solid deployment if i'm not mistaken forge length it would be something like it gives you all the lengths that soul hand gives you it would maybe incorporate slider from trail of bits it can do you know whatever we want honestly so we'll see what we do there forge dog it would take um the nut spec comments and we'll generate document documentation pages for it um this would be modeled after docs.rs which is i think the greatest documentation website that exists um and now we're also almost releasing anvil which is the hardhand node ganache cli equivalent because people want to integration test you know you're writing a front-end and you want to test your code with it so you just want the testament node and if we can deliver a testnet node that's better why not code coverages i guess everybody in the room knows what code coverage is so we are just going to add a flag that says forge coverage it runs all the tests and it highlights to you on the editor green lines red lines and with other frameworks this was not possible because the testing was not fast enough to generate you the the like the coverage report the coverage report takes like a minute or 30 seconds or whatever to produce on the javascript frameworks because it injects like it it bloats the byte code between jack tuned to instrument it and ends up taking a ridiculous amount of time so it's a very hacky way of doing it and that's why it's slow that's why you cannot have a good ux around it um other ideas that we have are invariant tests so instead of pausing one function you files many functions in a row and you check the property each time so one example would be you know is the units were pull balanced and you make one transaction without random arguments it checks the environment you make another function call with random argument it checks again and you keep doing that and this is what enables you to explore more states in your smart contract and maybe find a bug if you have written good properties flame graphs are again what you would expect they're like a nice diagram tenderly also has this i believe uh there is a nice diagram which shows where was most of your gas spent and you use this when optimizing so that you know where where you should optimize um and more languages some people have been asking about it like we haven't seen enough demand yet but maybe for viper maybe for faye we'll see um and that's it you can find the the page here you can find the org here so you click it it takes you here and the book it has all the stuff that you may need so happy to answer any questions and thanks for the attention [Applause] fastest we do not print them now because they're going to be different every time if you feed random inputs to a function it will generate different gas prices it will different it will generate different different gas values because of how cold data is priced at the minimum when you say that you want it stabler because you're chipping every night um is it dramatic change or just a small change i mean i think it's stable enough but like if it's released every night there can be a bug that goes through but like i prefer it that way rather than having to like bother with bug detected yeah we'll fix it in three weeks no we'll fix it tonight so yeah uh yeah so uh you mentioned um possibly adding support for other languages such as uh viper or uh fei um has there been any consideration to add support for something like uh cairo yeah we've talked about foundry starknet but it requires more work because we also need a different vm so we need a rastkyro vm there is one but it's not there yet so if we get a vm then writing bindings the compiler is easy now that we've done it once um and then it's a matter of putting the two together like foundry is not that complex of software like if you have a vm and a compilation pipeline they get combined but the vm and the compilation pipeline individually can get complex so if if somebody gets us a rust vm like it should be easy thank you and again we do the same techniques instrument the vm call traces like hey i was just wondering like what do you think is missing compared to like hard hat or so compared to like hard hat compared to onward access uh just like in terms of like dev tools if you think like about anything that is available on maybe i mean we built it to to give you a better experience than hardhat so in my view you know faster easier to install no context switching and i think there is a world where both exist right obviously um and right now you can have a repo which is a hybrid of the two you have both javascript and um and what do you call it and uh solidity tests like if you go to this is visible yeah if you go to this contracts you see how like it still has all the javascript tests that uni swap has but if you go to contract foundry tests you see the test here and just give you an example you know when you encode when you test libraries for example just to give you an example of the ux improvement you know how you need to write a wrapper contract which is a library test and then deploy that and it's like a bunch of like boilerplate that you don't want here you install it you just import the library and it just runs it it's like it looks really clean in my view um no help at the libraries no nothing so it's it's quite easy to keep both aside but i think what most teams i've seen do is that they write the ad foundry and they start migrating some tests or new tests or new functionality i think there was one on back um i just had a couple questions uh regarding the linting and adding uh support for slider so would it be some sort of extension that we add to visual studio code or do you have any plans to directly replace leather so we could so there's two ways to add the support for something right you can either just copy it and re-implement it um or just shell out to it so you assume that it is installed and just call it from your system we've generally avoided introducing runtime dependencies because it ruins the user experience like of you know you just download one thing and it's like battery is included so if we can do it natively like we'll do it but i also acknowledge that slider is a very like sophisticated piece of software right now it covers a lot of edge cases that i don't know how to detect right now so if we were to do it it would be a big project so we need to think about it slider supports uh foundry right now though and there's a github action for it as well so you literally do found your github action slider github action and you get the most out of it so it might be the case that like forge length is stupid then we should not do it alright thank you all what's up [Music] foreign [Music] so we decided [Music] so [Music] so excited [Music] [Music] this is cold [Music] [Music] [Music] [Music] [Applause] [Music] so [Music] so [Music] [Music] [Music] [Music] do [Music] [Music] [Music] [Music] [Music] [Music] so [Music] you 