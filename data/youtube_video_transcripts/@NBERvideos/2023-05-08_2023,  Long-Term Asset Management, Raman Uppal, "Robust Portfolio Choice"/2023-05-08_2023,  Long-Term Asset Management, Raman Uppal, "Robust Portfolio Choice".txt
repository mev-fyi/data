thank you very much for giving me the chance to present this work it's joined with the Valentina raponi and Paolo zapperoni Paolo is in the room and Valentina is online I will move around so that I stay in front of the camera for people who are watching online so it says died already okay so essentially the main variance portfolio model is the Cornerstone of financial economics not just for investment decisions and asset pricing decisions but for most of the decisions made in finance where there's a risk return trade-off but the performance of this model out of sample is extremely poor especially when the number of assets is large so they're like hundreds of papers which have identified this problem and tried to address it in a variety of ways uh I'll group those papers in two kinds of categories one shrinkage estimators that essentially try and reduce the extreme weights that come out of main variance optimization either by imposing portfolio constraints or using clever Bayesian methods to shrink the estimators or a more modern robust control approach where you use max main optimization to restrict uh and restrict the effect of estimation error another strategy has to take has been to take the N risky assets that you have and reduce the dimensionality to K factors uh essentially to improve tractability and to reduce in particular the dimensions of the variance covariance Matrix of returns but when you assume a factor structure there is a potential for mispecification either because there are missing factors or because the factors are mismeasured or because you omitted conditional dynamics of the factors so the existing literature especially recent work has focused on mispecification in systematic risk factors but has ignored the role of unsystematic risk which is quite natural to do given the starting point of most of the literature if you look at unsystematic risk and relocate any textbook treatment of unsystematic risk the textbook basically says you should diversify away unsystematic risk because it's idiosyncratic it's diversifiable so why would you want to bear this risk in contrast to all existing work our focus is going to be on unsystematic risk so we're basically going to ask ourselves what is missing in the current story that people talk about that research has focused on and how can we help complete this by essentially looking at what is missing which is the importance of unsystematic risk okay all right so under which conditions would it be optimal to diversify unsystematic risk basically you should have any asset pricing model which is called an exact pricing model so where the expected Returns on the left hand side are explained by risk Premier multiplied by on the right hand side so where compensation for expected returns depends only on systematic sources of risk then because these models do not give you any compensation for unsystematic risk it is logical to conclude that it is optimal to diversify away this unsystematic risk okay but if you are not in a world of exact pricing if in addition to the compensation for systematic process of risk you also get additional compensation then it may be optimal to trade off this additional compensation by choosing to Bear unsystematic risk even though it's diversifiable okay so essentially what we want to do is understand the role of unsystematic risk and to do that you need a reasonable model and it turns out that we do have a very nice model a model that we've known about since the 70s the APT and this model has three attractive features one it allows for expected returns to be different from systematic sources of return so there's a additional Alpha component that compensates you for something other than systematic risk you the model is reasonable because it imposes a no Arbitrage restriction on the alpha so the risk return trade-off between the alpha that you earn and the risk of bearing this Alpha the risk for bearing this Alpha earning this Alpha compensation represented by the inverse of the covariance Matrix of returns is bounded by a parameter called Delta apt and finally the APT is very nice because it's agnostic about the sources of systematic risk so you don't have to tie your hands down to a particular set of securities now it's very important to understand that if your lens was that of a exact data pricing model when you looked at the alpha your interpretation would be that the alpha is a pricing error but under the APT under the full apt Alpha actually represents compensation for bearing unsystematic risk so if you look at an expanded model and you start out with an expanded model then you can show formally that Alpha is not a pricing error Alpha is exactly the compensation that you get for bearing unsystematic risk now you may not want to start out with the APT that assumes latent factors you might want to start out with a particular Factor model so let's say the cap M or the farmer frame three or five Factor model and therefore there's a possibility that this model is missing systematic risk factors in that case Alpha will still do the job of picking up what is missing in the model that you start from it will have two components one which picks up omitted systematic risk factors if there are any and the second component that is purely acid specific picking up the unsystematic compensation for bearing unsystematic risk so in the paper we have some Theory results and that we then examine empirically and according to us these results are really remarkable so let me tell you why I find them remarkable the first result that we have is that the main variance portfolio is spanned by two inefficient funds so if you want to design an efficient portfolio our claim is that you should choose two inefficient portfolios one which will call the beta portfolio which depends only on the systematic sources of risk and second we'll call it the alpha portfolio which depends on unsystematic risk and to get the full sharp ratio that are efficient portfolio earns you need to have in that the alpha component of returns so if you start out with a model which only compensates for existing Source forces automatic sources of risk if you start out with a model that is only capturing beta risk you will never reach the optimality that is available with the given set of assets no matter how many systematic sources of risk you add to your model okay so it's very important to include Alpha if you want to earn if you want to be on the frontier of mean variance efficiency the second result that we have is that asymptotically as the number of assets becomes large the alpha portfolio is going to dominate the weights of the beta portfolio so asymptotically the relative magnitude of the weights for the beta portfolio will shrink relative to that of the alpha portfolio and the intuition for that which is very important and I want to communicate that to you the intuition is very straightforward that for data for the beta portfolios the assets have they are all correlated so as you increase the number of assets to reduce the risk of the portfolio you have to reduce the size of the position for the alpha portfolio they are all asset specific risks so they are Diversified by just taking long short positions so the optimal Alpha portfolio can have very large long short positions that minimize risk simply by taking opposite positions okay because of these differences in the asymptotic properties of the alpha and beta portfolios we will treat mispecification in these components in different ways the third result that we have is that you don't need to estimate Factor moments so what we do is we identify conditions under which the beta portfolio the portfolio that depends on systematic sources of risk can be replaced entirely by a benchmark a very simple Benchmark portfolio which could be the market portfolio which could be an equal weighted portfolio so essentially the problem of model misplacification in the beta portfolio can be resolved simply by using asymptotic results which identify the conditions under which the system are systematic risk component can be replaced with a very simple Benchmark portfolio which suffers not at all in terms of performance if there are omitted sources of risk the omitted sources of rats show up in the alpha portfolio so I'm always going to use these two terms where the missing systematic sources of risk will be denoted with the capital A and the missing asset specific components will be denoted by little a so the alpha portfolio admits this decomposition where you can separate the role of a missing systematic sources of risk and unsystematic risk okay and the last result is that the alpha portfolio depends on the alphas Alphas are like expected returns they are therefore estimated with very large error and therefore you need a way to reduce the estimation error that influences the alpha portfolio bits and it turns out that the alpha portfolio delivered by the APT is exactly the alpha portfolio the robust control methodology of Hansen and Sergeant would have delivered to you if you had applied it to the alpha component of returns so naturally by using the APT and using the no Arbitrage constraint that is part of the APT you address the issue of estimation error in the alpha portfolio the last thing I'd like to say about the theory is that we can link our work to the latent asset demand literature where essentially in our case what we are providing is a normative model for latent asset demand in contrast to the work that Ralph and motor have done where they provide a positive theory for latent asset demand so in our case the alpha portfolio will be the residual component whatever is left over that is not explained in the optimal win variance portfolio which is not explained by the systematic sources of risk in coin and yoga the latent asset demand is again what is not explained by the candidate model but relative to observed portfolio rates as opposed to the optimal of portfolio rates okay all right so in the rest of the presentation I'm going to show you the empirical results which are largely about out of sample performance of our strategy and an interpretation of the weights and the other insights that emerged from this exercise so for robustness we look at four data sets two empirical data sets two simulated data sets for the empirical work we tie our hands to the most recent paper published in this literature in RFS by AO Lee and Zhang so we use exactly the same data that they have for uh in one case 30 stocks from the Dow Jones in another case 100 randomly selected stocks from the S P 500 and in all four data sets we augment the investable assets with the Pharma French three Factor model so that's if you like the candidate Factor model and then we design a standard uh out of sample performance exercise where we estimate the model on 120 months of past information and look at the performance of this model out of sample for the next month and then we do this on a rolling window basis for the 240 out of sample observations that we have to compare the performance of our portfolio we look at five benchmarks from the uh existing literature five reference portfolios the main variance portfolio the global minimum variance portfolio uh principal component based portfolios with the number of principal components ranging from 1 to 10 and two portfolios that have been uh argued in the literature performed very well one the equal weighted portfolio and the second one the max strategy of R Lee and Zhang five benchmarks might seem like a small number to you but these last two strategies have been shown to outperform 14 other strategies so actually the set of benchmarks is closer to 20 rather than just five for our own strategy we will look at four variations of our strategy the first one is what you would get by simply applying our model the way I describe it to you the second one is instead of using um the N assets to reconstruct the beta portfolio we will use the variance covariance Matrix of the factors to compute The Benchmark portfolio and then because we are working with the finite number of assets our two portfolios which in theory would be orthogonal asymptotically in finite sample they are not so we account for that in choosing the optimal portfolio rates I'll show you results only for one data set not for all four because the results are very similar for the other data sets they are much stronger for the simulated data sets than for the empirical data sets Okay so this is a big table let me highlight the numbers I want to show you so if you look at the numbers highlighted in blue the first number is the sharp ratio of the mean variance portfolio because 100 is a very large number of assets as expected the sharp ratio for this portfolio is very poor it's actually negative the strategy that does well much better than the main variance portfolio is an equal rated portfolio that has a sharp ratio of around 0.5 and the strategy that does the best is the strategy of AO Lee and Zhang which has a sharp ratio of 0.672 the second panel shows you the sharp ratios of our strategies so when you use all the theoretical insights that we have the sharp ratio of the strategy is much larger than what the existing literature has shown and what you see is that the sharp ratio is around 150 percent higher than what the equal weighted portfolio gets or around 80 percent higher than what the our strategy achieves if you look at the portfolio of it so in this picture I plot the portfolio rates for the 100 Assets in the portfolio by taking a Time series average of each portfolio weights the blue squares show you the portfolio Waits For The Benchmark portfolio the beta portfolio and you see that they are all small and mostly positive the alpha portfolio bits is where all the action is taking place and over here the portfolio takes long and short positions depending on the residual Alpha that is left after the form of French three Factor model has been applied to the systematic component of returns this picture shows you the magnitude of the alpha and beta portfolio weights and this picture shows you that the portfolio rates are dominated by the alpha portfolio the red dots rate compared to the beta portfolio weights the blue dots in within the alpha portfolio you can further decompose and try and identify if there's a missing factor and what the pink line shows you the pink squares show you is that essentially the contribution of omitted risk factors is almost zero so once you have the form of French model the systematic variation that is left to be explained is very small and all of the work is being done by the little a purely unsystematic component of returns in the last set of numbers I'm going to show you where the performance comes from why does our strategy do well so this is the overall performance of the first strategy that we look at and if you look at the contribution to this strategy the blue data portfolio contributes only 15 percent of the squared sharp ratio while the asset specific component contributes 85 percent of the squared shop ratio okay so with that let me close and say that the key takeaway from our paper is that unsystematic risk is priced and so what has typically been viewed as a pricing error should not be viewed as a pricing error it is something to be exploited taken advantage of rather than to be treated as a pricing error thank you 