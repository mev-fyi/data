i'll be giving an overview of the ecss program and then i'm going to go into a bit of a deep dive of a particular ecss project that i had worked with maui on about five years ago so when i do that don't really focus so much on the particulars of the project i want this to be more just think of it as a case study of how these ecss collaborations work and then i'll talk about opportunities for collaboration beyond ecss how these um kind of collaborations can often grow into into something something larger so a little bit of background i am not an economist or an expert in finance if i say anything um before you say anything really dumb during this talk about finance don't hold that against me i uh my involvement in this project is um is bringing the bringing the computational expertise so when i worked with mao i was focused purely on the improvements to the computing and this is very common in these ecss collaborations so john mentioned he's an astrophysicist i'm a physicist we have engineers computational chemists we have folks who come from many different backgrounds but what they bring is that they have the they have the computational expertise often something that develops say when they were in graduate school they were getting involved with their research they realized that they really enjoyed the computing especially the high performance computing aspects of it and just another word about myself is you know even though i work directly on these ecss projects now i have a broader role i co-lead the ecss program um together with phil blood at the pittsburgh supercomputing center and i should emphasize that within exceed you know we don't want to get into the into the management structure there are six main components to exceed one of them is ecss but it is such a large part of exceed that is the only component that actually has two of what we call the l2 managers at the you know in the senior management level it's a very large component of exceed i believe that we have somewhere between 65 to 70 people who work and exceed including including the managers most of those are fractional fractional um ftes or full-time employees but we have a large base that we can draw on to do this um you know the i would say the main theme of um of css is that exceed is is much more than high performance computing um when when people look at exceed they tend to think of the they tend to think of the hardware in the machines and that's a very very important component but what exceed really brings is the expertise in fact exceed does not fund the hardware these supercomputers that we've been talking about comet and bridge and so on are funded through individual grants from the national science foundation what exceed does is it integrates all of these provides some base services like allocations and then also a lot of this expertise that you get through the through the ecss so within ecss so which is a ecss it's collaborations between between researchers and exceed we have expertise in a wide variety of areas we do a lot of a lot of what i consider to be the traditional ecss projects performance analysis and optimization we take a code or we look at it figure out how we can make it run faster we do software parallelization and scalability improvements so if you have a serial code and you need to go parallel we can help you with that also if you have oftentimes you'll have a parallel code but you have limited scalability and by that i mean you can only go out to so many cores or processors before your performance tails off ideally when you take a take a code and you run it on two processes you would like it to run in half the time on four processes and a quarter of the time and so on and so on eventually you you reach a limit in the scalability but often we can help you push that out further we do gateway and portal development um enervon mentioned very quickly the um what we call the science gateways which are you could think of as web interfaces to the supercomputers um these are great when you have a community of users who are using a common set of software we can help you with specialized scientific software visualization putting together complicated workflows and know a lot of what you do nowadays involves not running a single program but running multiple programs making them all work together you can ask for for advanced support or ecss at any time often when you make your allocation request you will ask for ecss at that point but even after you have an act active allocation you realize say later on that you could need some help that you need some extra help you can ask for what we call a supplement um for for ecss support and that's actually very common i should also add that ecss is not intended just for the biggest largest users you might be thinking well i'm only using a few tens of thousands of core hours per year i'm at the startup level isn't ecss for the folks who have really really large allocations who are using millions of core hours per year and the answer is no it's for everyone so we have some of our large users who are using ecss but ecss really targets um targets are new users who we want to make more efficient who we may grow into being to be in larger users requires written written requests but i'll show you in a few slides that it's not that hard okay so under the hood um there are five components of ecss you're not gonna have to worry about this um when you make a request for um for for ecss you don't need to decide is this something that fits under support for research teams or community codes or so on i'm just putting this up here though to show you the breadth of what ecss does um so the first two first two areas what we call extended support for research teams and community codes they do very similar kind of work this is what i think of again is the traditional ecss projects where we where we help you to improve your software to optimize it to paralyze it um the difference between research teams and community codes is really more of the um the nature of the software whether it's something that's used say within a lab or by a broader community i would say with the community codes we may have a little more emphasis on helping you with the software engineering because i was thinking this is just my definition but the differ i think the difference between code and software is code is something that you wrote to to accomplish tasks software is something that you can give away or distribute you could give to a colleague who can then who can then use it without you sitting there right next to him or her helping helping them to use the software um we have this extended support for science gateways that can help you build one of these web interfaces to the supercomputers so it abstracts away a lot of those low-level details how many cars do i want to run on do i want to use gpus which systems on we could build a lot of that logic into the gateway so that the end user can focus purely on the on the application we have something else called nip novel or innovative projects and this is really focused on getting users from domains that are relatively new to exceed and high performance computing getting them started and then finally we have extended support for training education and outreach this gives us the technical support for using the advanced cyber infrastructure so we already talked a little bit about training and ecss does have a component of that so how do you get ecss pretty easy just need to make requests answer five questions um first of all we want to know what you want to accomplish with the help of the expert staff and whether or not you've done any work on this we've done any work in this already so let's say you have you have an application it's serial or it's too slow it's just taking too much too much time and you want it you want to make it run faster you want to be able to run on a parallel machine that would be a good justification and we'd like to know what steps you've taken already toward doing that we want to know how the success of the collaboration would benefit your project we want to make sure that it's going to have an impact on your science and your research for example if you have an application software that you need to run once a year and it takes five hours to run it it might be fun and interesting to work on that code um to make it run faster but if we could take that code that runs once a year for five hours and cut the run time in you know reduce it by factor 10 that doesn't really impact your research it doesn't have a it won't make you won't make you more productive we want to know is this the application the workflow something that you're using on a daily basis something that boy if i could go from you know it takes me a week to do something i could do it overnight or i could do it within an afternoon that makes it that makes a big difference would it make you more productive we also want to know what members of your team are going to be collaborating with our staff and this is really important we talk sometimes about taking the code and throwing it over the fence it's like hey here's my code work on it let me know when you're done give it back to me that's not that is not the way we work we want remember that the c in ecss is collaborative there needs to be somebody in your group who's working with us it doesn't necessarily need to be you the pi of the allocation i know as we get further along in our careers it's um we do a lot less um c and fortran and python and our programming a lot more of as john said proposals and proposals and grants and presentations but somebody within your group we need to have somebody who we're going to be working with um we'd like to know you know did you did you work did you work with anybody within exceed before oftentimes you may have been working directly directly with somebody at a at one of the supercomputer centers who is also an ecss consultant you may have um you may know them may know them personally they may have helped you with an application you may have been put in contact with them through years of services if you already have a relationship with somebody who does ecss and it's already working you may want to um want to follow up and specifically request that that consultant we can't we can't guarantee that we could always do that match but if it's if possible we do and then finally we want to know if you've had ecss support in the past there's a lot of demand for ecss so we want to make sure that that we make this broadly available to the community and you know if you did have ecss in the past we want to make sure if you're requesting it again that is for something new or for some new aspect of your project and we do have many what we call repeat customers it's loud but we just want to know what what the history was um i know you're not going to be you won't be able to read this but this will be distributed in the slide decks just gives you a listing of the current ecss projects including and this is just one small snippet and there's also a very large table with past projects projects that have been have been completed over the years if you look through the list of project names and they don't make sense don't worry these are from just about every field of science technology and engineering but there are a few a few in economics and finance in there so with that i'm going to dive into a case study about five six years ago i had worked um directly in a project project with maui it was a lot of fun i learned i i learned much from it my limited knowledge of economics comes from reading a few of the few of the popular books like freakonomics and from and from talking about so it was a great experience big success um we were able to take his um take the time that required him to construct limit order books um by a factor of about a hundred so i'm hoping that that was a bit of a game changer for for his research now actually constructing you know constructing a limited order book i i think within uh you know economics and finance community it is is really a pretty dull activity you're taking data you're manipulating it um but you're generating data that's absolutely essential as a jumping off point for much deeper analysis so i didn't get into that i just focus on on the construction limit limit order book which makes it much easier for now then to get all this data and jump off and do do the really interesting stuff and then finally um as they as they like to say um past performance is no guarantee of future results we don't always get 100x speedups or in this case um when you if you include the follow-up based on nsf funded work that we had you know compounded by another 50 x speed up that that that that's kind of exceptional but sometimes we do um you know have a have a real home run okay so i won't go too much into the limit order book mal talked about this a little bit already and i think we're just a little over time um but market data consists of 17 different types of messages describing various activities orders to buy and sell execute orders delete orders update orders so there's really just a handful of these that we are that we're directly interested in limit order book um is really just a record of those of those unexecuted orders but then once we have the once we have this limit order book we can calculate all sorts of things that folks and competitional finance are interested in so again this work was to help mao get to the point where he could generate these limit order books very very quickly on larger on larger data sets and that dive in and start doing the doing the more interesting work so um you saw this slide already in in mouse presentation one thing i want to point out though is that this limit order book um sorry the the raw data the raw data that we get it's in something called called the itch format it's a it's a binary format extremely compact um in fact it does things like to to to reduce space it won't contain redundant information so if a if there's a order to buy of course the need to give this need to provide the stock symbol but if there's later an ordered cancel or update the stock symbol is not included so that we could save space because these these are large data files so there's a complex bit of manipulation that has to go on and here's just a example of a sample limit order book oh but going back here another complexity with the with the limit order book construction is that when we go to the itch data it is a sequential list of all of the messages that were that were posted and it's not broken down by by by stock or symbol these are all interleaved so there may be a um and and they're all ordered by time so it might be a order to buy amazon then to buy google and then to buy something else and then to cancel the amazon order and then buy another stock so there's a bit of work that has to go into um in into um processing this data so i had a slide in here i took out the took out the comments just say that they're there that there are some implications for for high frequency trading okay so the data processing pipeline um when i started working with mao there were three steps um the first was where you had to take that take that um itch data and convert it to a conv convert it to a text format that we could work with if you've ever worked with the itch data it's kind of ugly not only is it binary but but they use weird data types there's things in there like six byte integers um these various custom data types so that they could really compact the data they figure if they could get away with a six byte integer instead of using an eight byte integer which is more standard they could save a little bit of space so we need to convert that to um convert that to text format we then need to process that and uh and add in extra information and then finally what i have here is the big red arrow is the lob construction and that's that's a step that was taking a lot of time so to give you an idea how how expensive these could be um we looked at um we looked at some data these were for from the day of the the famous day of that flash crash on on june 4th 2010 that this was using the original version of the code using all 16 compute cores on on a node of the of the gordon super computer this is one that now are our older older super computer older super computer and these were a few of the few of the stocks that we're looking at and the time that it took to construct construct the limit order book and this is in seconds so if you're trying to do the math in your head that the 8 400 seconds is about two and a half hours um for for apple a lot of a lot of activity that day that 129 000 seconds i think comes out to about 44 hours so a lot of time to construct the limit order book just for a just for a few of these symbols the other takeaway here and i'll get back to this later is you can see that there's quite a dynamic range there um you know going from from 8 400 to 129 but the dynamic range is actually much much larger than that it's about a factor of a thousand so some of these symbols um we could we can construct the limit order book in the in the blink of an eye other ones could take um could take more than more than a day and a half so this again this was we we we consider this to be a rate limiting step so we wanted to figure out okay can we make this software run faster and again this is just think of this as a is a particular case study of the kind of things that we can do in ecss so i'm going to go through these next few slides pretty quickly um i realized i was putting this together on a saturday morning most people don't want to stare at powerpoint slides filled with c c plus plus code but that said we're going to do a little bit of that anyway um well don't worry if if you don't if you don't if you're not a c or c plus plus programmer don't worry we're not going to we're not going to get into the details but across these four slides i i originally put these together for a different group basically my peers who do um who do these ecss projects so we we first of all we profiled the code we um figured out where where where is the code spending most of its time we're able to narrow it down and for for each of these optimizations we have kind of a a particular theme in this one i call it do things once so we're reading in the data um trying to constrict and construct the limit order books and we noticed that within within some of the loops we were spending a lot of time over and over every time we had a character string that we're converting it to an integer and then doing some operations on it and internally that's a fairly expensive operation so we created a few additional data structures we would do that once we'd take all of this character data we would convert it into integers we'd save that in another data structure and then we would reuse that over and over next thing we did we started with a with a parallel version of the code it was paralyzed using a very low level approach called p threads um parallel threads and we realized that there was a critical region within that code where all the threads would be doing their work and then they need and they all need to write to a file and each time one of them writes the file it has to say hey everybody stop what you're doing wait till i'm done right into this file now i'll release a lock and somebody else can write to it so we have all this serialization so what we found is that when we ran on 16 cores we didn't run 16 times fast so we ran about five times faster and it was due to the serialization so we did a little bit of restructuring so that we could have each of the threads right into the wrong temporary data structures dump everything at the end and then we got near perfect scaling um another another thing that we did was what we call dynamic scheduling so that they're at a very high level they're they're i think two what i think is two main approaches to parallelization that there's a static decomposition of the work and a dynamic decomposition work so static would be let's say we have a thousand tasks that we need to do and we get um we get 10 volunteers and i hand them out the first hundred the next hundred the next hundred and the next hundred so each of you are getting each of the ten volunteers are getting a hundred of these tasks now if you if you're all equally capable of doing doing these tests at the same speed which of course computer cores are and each of those tasks take the same amount of time we're going to get good load balancing what happens though is that often the amount of time required for each of those tasks can vary by quite a bit so if there's an imbalance we're going to find that we're going to have some of the cores are going to finish early other ones slogan is still going to be doing their work so we took some of these key parallel loops and we instead did a dynamic decomposition where in this case say for our 16 threads or our 10 volunteers we take much smaller units of work we hand out some to everybody and then the first one that's done essentially says i'm done they get another chunk of work somebody else raises their hand i'm done they get the next chunk work so by doing this dynamic decomposition we could get a lot better luck better performance and then finally the last optimization we did was again kind of a at this scaler level the code is we looked at some of the loops um they had um conditions that once we know that condition is met we don't need to do any more iterations so we put we call break statements in there to break out of the loop early in fact i should have reordered these slides because we did this first and realized that it introduced a new new load imbalance scene then we went back and we implemented the dynamic um dynamic decomposition so it's just kind of a smattering of the kind of techniques that we could use to make the make the code run faster within the group of ecss consultants these are things that are that are very well known okay so what was the impact looking at those three very expensive symbols um for a first column i have that original time you know the 8 400 seconds 129 000 seconds and the next column i have the time for the for the modified code and we see that we got speed ups ranging from about 66 to 113 x so i'll just say we got about 100x speed up so already mao is is going to be much more efficient he's going to be spending less time worrying about this what i think of is a very from from a finance point of view not a very interesting task it's just something that you need to do so that you can get on with your research so then in the beginning he was originally working with just the subset of the data he would take since it was so computationally expensive he would take maybe 120 symbols and work with those i said hey we've got this running a lot faster why don't we see if we can do entire markets which i think is what you is what you really want to do so we looked at we looked at at three different days we picked days that we considered to be very challenging um where there was a lot of activity there was the day of the flash crash the day of the night capital computer glitch oh then actually from from just the typical day and i won't go into all the details here it's showing some um some runtimes across different machines but essentially we got to the point where to construct these limit order books depending on the day we could do it for an entire market for all um for for all just under 3 000 symbols in anywhere from two hours for a typical day to about 10 hours for a um for for a really challenging day and remember that that top table there for the day of the flash crash 10 hours that's 10 hours for the entire market whereas just one of those challenging challenging symbols um i believe it was apple was taking us about a day and a half so we've um you know really made it much more productive okay so next part of talk is about going beyond ecss so ecss projects are of limited duration they're initially for one year they can be re they can be ended early if the goals are met um sometimes this happens i've had a few projects where i worked on we we looked at our work plans like hey we're done um so we we could wrap that up early but if there is more work to do they can often be renewed and they're also limited by the level of effort of the ecss consultant so this is a very valuable service you're getting essentially a quarter of a person's time and we haven't we have a large user base that we're trying to trying to serve um so you know there's a little limited level of effort sometimes we can have multiple consultants working on a project but often they will work at a little bit lower level okay they got five minutes um okay can i go about five minutes over just since we started a little late okay thank you all right um so i'm saying here that ecss can can often see the initial work that can lead to an externally funded collaboration and in this case i think we needed to do that um so again our first project was um you know it was very successful we got that that 100x speed up we realized there was more to be done if any of you have worked directly with mao um and i mean this in a very good way you'll notice the pattern that there's a certain goal they say okay now we could now that we could do this let's do something else that's even more ambitious so there's always going to be something bigger that you want to do which is good which is exactly what which is exactly how we want you to think john mentioned earlier don't think about the hot don't think about the how think about the what think about what is the problem that you would really really like to do if computing was was not a bottleneck so we want to get a little more ambitious we realized though that this required a complete rethinking of some of the algorithms rather than just tuning the existing algorithms we had to do a little more advanced work to make optimal use of flash storage so we applied together for a for an nsf eager award so mao was the pi and as the co-pi on that of course mao's work focused on the finance i was focusing on the continuing focus on the fast construction these limit order books so we realized you know we wanted to do combined analysis of all stocks across multiple markets on on on very busy days of activity so we wanted to further reduce the time to solution we also needed new algorithms to reduce the memory footprints um as energon mentioned earlier we have these large memory nodes but they're kind of specialized hardware sometimes they're in very high demand and you and if possible you don't want to be tied to a particular to a particular hardware and we also need to think of data management strategies for working with large input data and file counts so i could go through it pretty quickly a um gives you a summary of what we did we started with that message data we would take first take it we would split that into chunks i'm just going through sequentially by breaking into chunks um for clarity i'm only showing showing 16 processes but this could be extended to all of the cores on a shared memory machine and then for each of those chunks we split those into stock or symbol specific chunks so remember i said how all that itch data is is is interleaved so so now we have um for example from chunk one we have the data specific just the apple on just the google and just nvidia and then for chunk two we do the same thing here i'm only i'm sure i'm only throwing showing the three stocks but we could uh we could extend this to an arbitrary number then then we combine them together so in these first two steps we've essentially taken that um taking the itch date hitch file with all the interleaved data we've split it we've recombined it and now we have one file what one separate file for for each symbol we then construct the construct the limit order books and here i'm doing a different different kind of parallelization here i'm doing parallelization instead of the within the code processing prop processing data for stock i'm doing the parallelization at the level of the stocks now remember i mentioned earlier that there's a there's a great dynamic range at least at least three or four orders of magnitude and how long it can take to construct these limit order books so we developed a um a dynamic um a dynamic scheduling approach where we're essentially handing out the work to the processors um whoever got apple might might only work on one symbol um somebody else might work on or work on multiple symbols so we're able to get very very close linear scaling and then one where um oh sorry i see a slide got um slide got lost here but we take when we take all these limit order books we then combine them into large archive that contains all the data and you could post process later so what happens so so now we got another 50x speed up over what we had earlier so now we're talking a few thousand x um speed up the other thing to notice is that we really reduce the memory footprint um for for some of the for some of these cases you know if you look at that second last column original memory you know was 29 to 59 gigabytes that's not too much but as we went to these more ambitious problems we're going to be spilling beyond what's available on on standard hardware if you look at the um last column though with our new algorithms rethinking the data structures we're able to reduce that down to just a few gigabytes so as i mentioned when you work with mao there's always a more challenging problem that he wants to tackle which again is a very good thing we want you all to be thinking about that thinking about what is the thing that i would really really want to do so now we we um we extended this to um i think i got this right combined new york stock exchange nasdaq and bats on the heaviest days of trading to date so this work was done a little while ago if you look at these last um last two columns um total time to solution you'll see there and this is in minutes and seconds now it's about two hours if we had used the original version of the code we estimate that it would have taken 2 400 to 7 200 hours just to construct the limit order book which is a long time to wait before you can dive in and again start doing the interesting work so hopefully this was was able to make everything much more efficient so with that i guess we did finish right on time so i hope from this you got an appreciation for for for how he can benefit from exceeds ecss program again this was just one specific example we have folks with expertise in a wide wide variety of areas and high performance and high through com high throughput computing and i'm hoping that we're going to get some more exceed users and we're looking forward to working with you 