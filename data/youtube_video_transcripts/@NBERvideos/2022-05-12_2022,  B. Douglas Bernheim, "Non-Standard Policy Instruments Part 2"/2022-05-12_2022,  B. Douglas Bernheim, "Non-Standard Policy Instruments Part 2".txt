um okay so i'm going to pick up where dimitri left off and talk about non-standard policy instruments and you see a lot of um points of commonality here there are some themes that i think this helps to reinforce i'm going to discuss two particular types of policies the first is financial education uh the second is default options so let's begin with financial education so there is evidence a lot of evidence of pervasive financial illiteracy as well as problematic choice patterns and this kind of evidence raises a lot of questions about the quality of financial decision making so there are these surveys of financial literacy tons of them the papers that are cited there are survey articles that summarize a lot of the literature in that area of which there is as i said a lot and then there are tons of examples in the literature of questionable decisions financial decisions this list is not intended to be even remotely exhaustive but it includes things like the apparent inadequacy of saving although it's what do we mean by inadequate um you know you have to think about those issues low enrollment and pension plans that offer generous matches uh naive diversification and a tendency to invest heavily in employers stock all of those patterns and others have been questioned so what is financial education do well it seeks to improve the quality of decision making in a couple of ways the first way is by providing factual information and you could think about that as being sort of a standard welfare economic standard conventional intervention just providing information but it could also be that this information is specifically addressing biases that is people have access to the information and they still have beliefs that are not incorporating the information in a proper way so by drawing their attention to the information perhaps making it salient uh could um help to correct those beliefs but the other part of financial education i think is is an important component is that it trains people to use whatever information they do receive more effectively in their in their decision making you know you can think about it as kind of abstract knowledge as opposed to concrete facts it's uh deliberation skills it's decision making skills and there are lots of good examples of this i mean my favorite one is this is what we teach all undergraduates right why you should take economics uh you learn to think at the margin that's not a that's not a factual kind of thing that's simply an abstract principle that makes your decisions better all right now there are many types of financial education um uh the main types of financial education falls generally into two categories one is high school classes which are often mandated i think at this point more than a third of the us states some form of financial education in high school as well as employer-based programs and this is where most people do get their financial education more than three-quarters of pension plans pension plan sponsors um provide seminars and meetings uh so okay uh how how do we go about evaluating these kinds of policies not just seeing whether they have effects but how do we go about evaluating them well there are two methods that conventionally have been used in this literature you know this kind of uh uh you know earlier today i was talking about wave one and wave wave two and wave three of uh behavioral public economics this is all kind of wave one stuff all right so uh the literature begins with this paper uh that i mentioned earlier today in which we studied a natural experiment of sorts with high school curriculum mandates basically different states adopting these mandates at different points in time which allows you to look at people who went through high school in those states immediately before and immediately after the mandates and compare uh their choices in life you know uh 20 years later um there's uh that that's a high school education paper we also did another one on workplace education uh diplo and syez had one about workplace programs it was an experiment it came out at about the same time so what are the limitations of this method of evaluation well the question is how do we know that this effect is off to the extent you measure an effect and all of these found that you know there there is an effect of these things and in some sense it goes in the right direction um so how do we know that the effect is actually offsetting a bias rather than introducing a bias i mean you know on the one hand these programs could be providing uh good education good training on the other hand this may be indoctrination uh people may be deferring to authority they may be uh succumbing to social pressure and so forth so how do we know that these effects are actually improvements and that actually was the question when people pressed me on this way back when we were doing this stuff that was that was the thing that made me stop and go huh i guess we need to think more seriously about welfare um which then led to many years of work um these and this now uh resonates with what uh what dimitri was talking about that these analyses ignore heterogeneity of the biases and of the treatment effects and if the biases are heterogeneous and education works as intended then the treatment effect should be perfectly negatively correlated with the biases in other words people who over who who over save if you will should save less and people understand should say more as a result of these interventions but is it negatively correlated is it correlated at all and these questions were not addressed at all in the first wave literature it was just measuring average treatment effects now method two in this literature is to measure average treatment effects on financial literacy okay so financial literacy is supposed to be a measure of uh knowledge and ability to make these decisions and the literature as far as i can tell there's long literature long-standing literature measuring financial literacy but studies that related financial literacy to education as far as i can tell start with this study by the jumpstart coalition as well as paper by mandel which are basically just correlational analyses of high school students financial knowledge and whether they completed a class and the limitation of this method even if setting aside the obvious question about you know is it correlations of causation limitation of this message is that conceptual knowledge may not translate into decisions just because somebody learns something doesn't mean that they're implementing it when they when they actually make decisions so does knowledge translate into better decisions well the literature on financial literacy tries to address that there are some correlational studies that relate knowledge to various kinds of behavior where you know we presume that certain behaviors are good and others are bad but it is just correlational and then there's also a number of studies that try and get at this by taking that kind of evidence and using instruments and the most common instrument has been something like you know is there uh you know when one study was uh new university starts in a particular area and uh we assume that that has an impact on knowledge uh do we see people in that area making better uh financial decisions in each case though the instruments may proxy for a wide variety of things they may be affecting tastes again it may go through the channel of uh of uh deference to authority and so forth we don't really know whether the causal effect here is the one that we want which is an effect that people are making different decisions because they understand their problems better okay none of this is actually demonstrating that um this is a figure that comes from a recent meta study you know i i alluded to the fact that there were these initial studies and i'm not mentioning the subsequent literature there's a lot of subsequent literature on this topic of measuring these effects so this is a meta study it was conducted in uh 2021 or published in 2021 and you can see the horizontal axis is measuring effect size the vertical axis is measuring basically precision or inverse precision of the estimates so each point is an estimate effect size and inverse precision so you know points down here are really precise and really big and there are two colored dots uh red which is effects on financial behaviors in blue which are effects on financial knowledge the red dashed vertical line is zero so you can see here there's been a lot of studies of this a bunch of them have found negative effects uh but the average effect on financial behavior is positive the average effect on financial literacy is positive and the cluster really is here so there's a lot of concurrence in literature that there are significant effects on both of these things and here's uh uh the results of a meta regression that they that they run in this paper for different categories of behaviors and financial knowledge they get an overall positive and precise effect on financial knowledge of these interventions and you can see things like budgeting is a big effect saving is very positive and significant and so forth okay so in looking at this let me just finish this last point then uh in looking at these results you would say well this is kind of a comforting message right because what we're learning here is that behavior is changing and what we think is the right direction what we have some reason to believe is the right direction for the right reasons financial literacy is improving that's the impression you're supposed to take from a sort of figure and that's exactly what we're going to start to investigate in a second has anyone done a p curve on these studies or just wanted the treatment effects against standard errors like on that scatter planning show before where there are some extremely high yeah treatment effects i would guess some of those might um they're sorry treatment effects against sample size those might be smaller and studies they they probably are yeah i i don't i haven't looked at the individual ones okay so um what we're going to do now this is now moving from wave one to wave three wave two gave us the tools to answer these questions better so now we're going to come back to these questions and try and answer them using those tools and that that for me that is literally what went on uh in uh in this particular sub literature i'd written the early papers uh then got concerned that we didn't really know how to answer the questions we wanted to answer and then once i felt that we had the methods came back to it and have written this paper which has gone through many many versions we believe this is the last one um we think we're almost through the golf um okay so the objectives of this paper are to first of all use an experiment to examine the reliability of the conventional evaluative metrics that i described kind of the wave one metrics and then second to propose and implement an alternative evaluated metric uh based on the principles of behavioral public economics and then to compare the answers that we get okay the focus in this paper is on comprehension of compound interest why did we pick that particular topic well a number of reasons first of all it's a foundational concept in finance you know very central concept second it's suitable for an experiment because it's relatively easy to understand and can be taught quickly so we can do relatively short interventions and have some hope that people might understand what we're talking about third it's a case where we believe that we know that there's a known bias and the known bias is called exponential growth bias there's literature on it and it just says that people tend to underestimate compounding that they tend to do things like simple interest rather than compound interest so you have a case where you've got a known bias and therefore a presumptive direction that is beneficial we want people to value future payoffs more highly than they do when they're stated uh in ways that implicate compound interest okay and so what the experiment does is um to assess assesses test performance to evaluate effects on literacy that's the first thing and then it also assesses valuations to assess effects on behavior and by valuations this is just an example we assess the willingness to pay for a ten dollar investment in an asset that pays two percent interest per day compounded daily for 36 days all right why 36 days well that allows you to apply the rule of 72 very easily then you can figure out that the thing should double during that time period okay and so we use this to determine effects on behavior okay structure the experiment works like this stage one is an educational intervention stage two are the valuation decisions and then stage three are the exam style questions to assess their ability to compute compound interest this is our financial literacy test okay uh what are these educational interventions what we did is we took a um leading investment guide malchiel and ellis and took the reception on compound interest and i narrated it uh we put it on slides and i narrated it i tried to get hunt to narrative because i hear he has a tremendous divorce uh but uh unfortunately he wasn't uh available now what's uh what's in this intervention well there's some substance that focuses on two things one is just the mechanical description of how compound interest works in the standard compound interest formula also it describes this rule of 72 which is that uh the um uh the interest rate uh times uh the the doubling period is equal to approximately okay the other thing and this will become important believe it or not the other thing that's in this intervention is motivational rhetoric so let me give an example of that this is literally in the the um the investment guide so we just i just read it and and it's in our it's in our recording it says uh albert einstein is rumored to have described compound interest as the most powerful force in the universe okay stuff like that is used in these educational interventions to try and get people cranked up to make them think this is really important all right now we also use the control which is again a narrated video that's just based on another section of the same investment guide and it just covers an unrelated topic it's very similar to the idea that hunt was using when he provides information and then he provides on related information you know you want to control for people being exposed to something similar but not have the same content there are two versions of the experiment in which we use different versions of the intervention and again this will be important the first intervention a the um the educational intervention does not include practice or feedback now most of these financial education programs in the workplace they do not have practice or feedback okay you just go to a seminar and you listen to somebody talk you don't try solving problems or making decisions and having somebody advise you on how you're doing so this is kind of a naturalistic workplace intervention and then experiment b was exactly the same as a except we created some automated feedback and gave people practice okay so uh and you'll see the the role that this plays in a minute okay now let's have a look at conventional outcome measures and evaluate these two interventions according to those measures we have yes i'm sorry who are the subjects um this one was done with m turgers yeah so m turkers it turns out don't really understand compound interest or at least most of them don't understand it very well we actually were originally we started to do this with stanford undergraduates and we found out that they all understand dropped out interests so that didn't work um okay uh so um conventional measures are uh as i said we have um test scores this is literacy this is understanding compound interest and then we have valuations in the complex frame and we have experiment a and experiment b light bars or controls dark bars or treatments and the first thing you see looking at test scores is that both interventions significantly improve financial literacy and in fact they do so by almost identical amounts all right and then you look over here and you say both interventions significantly increase valuations and we have a presumptive bias here because of exponential growth bias so we say you know this is making decisions better goes in the right direction it's statistically significant in both cases and the effect is almost exactly the same size so both interventions are effective both interventions highly significant in terms of their effectiveness and both appear to have the right effects for the right reason in the sense that financial literacy improves and behavior moves in the right direction but don't bother with practice and feedback right because it doesn't accomplish anything okay that's wave one analysis all right so um now the experiment now we move to wave three analysis and the experiment also assesses money metric biases so how do we do that well the general strategy is to study two objectively equivalent decisions decision problems one with naturally occurring complexity and the other simplified to make the consequences of the choices completely transparent and then we define the welfare relevant domain to consist of only the second okay the very specific strategy that we use is to employ what we call parent valuation tasks so in addition to assessing the willingness to pay for et cetera et cetera the same thing that i said before we also assess the willingness to pay for 20.36 days subject to rounding these two problems are identical so people should have the same willingness to pay and the differential between them means that somehow there is a bias that is being created by their misunderstanding of compound interest okay um so uh the money metric bias here is just the difference in the valuations is the clarification question yes you just do at baseline ask the exact same question that you would ask to measure um we're worried about anchoring yeah i i we here we decided to this is always a choice that you make when you design an experiment do you do it within subject or between subject here we decided to do it all uh between subjects rather than with them but we have done another experiment where we did it within uh where we were looking at social influences on choice and we find very similar things there um okay uh so um uh now what are the results for um uh money metric bias um so here uh let's let me explain what these figures are showing um the horizontal axis here is showing the difference between the willingness to pay in these two situations in in the the transparent frame and the complex frame okay so what you would like to see is everybody at zero that means no difference okay so what we're drawing here is cdfs you'd like the cdf to be flat and then to be straight up like this and then to cut across that's what you would like okay now what we find uh in the control is a cdf that looks like this and if you look at it carefully enough you'll realize that it is skewed a bit in the left direction which means that people are undervaluing these assets on average but you can see that there's a tremendous amount of heterogeneity in the bias and that some people actually overvalue the assets to start with and over here we have the effect of treatment a and you can see that what treatment a does is shift the entire cdf to the right what the intervention ought to be doing if the effect is negatively correlated with the bias which is what we want is it should be taking this thing going like this instead it's taking this thing going like this in other words it's getting everybody to value the thing more now look at um experiment b where we use the treatment without with practice and feedback and it's very different you still get this beneficial effect of people who are undervaluing valuing more so this is all the welfare improvement and you don't get any effect up here i mean you'd like to see a beneficial effect with these people uh value less we don't get that but they don't value it more and so intervention b turns out to be unambiguously beneficial whereas intervention a is not it's very ambiguous okay now to understand the difference between so we got this real sharp conflict between the conventional methods and looking at money metric bias and to understand that difference we also field two other treatments one is a substance only treatment so from the substance only treatment all we do is drop that that motivational rhetoric and then we also field a motivational rhetoric treatment where we dropped the material on the rule of 72. so it still has the description of compound interest it is it does have some substance in it but that isn't very useful for people the rule of 72 is the substance part that's easy for them to use i mean you know typical people are not going to be doing you know this compounding formula that's a little bit complicated all right so what are our findings well the first finding is that effects on tested financial literacy come on almost entirely from the substantive elements of instruction okay you see that in these results here so these are test scores this is financial literacy and for the control you can see that they're getting about you know two questions right out of five and then when we do our treatment they get about three and a half right out of five so that's a huge improvement but now if we do rhetoric only you don't get much of an improvement you get a bit of improvement but if we do substance only you get almost the same improvement as with treatment a so that means that almost all the effect on knowledge comes from the substantive elements of instruction that's great that's just what we want okay so now let's look at behavior completely different picture for behavior uh without practice and feedback the effects on valuation come almost entirely from the motivational rhetoric rather than from the substantive aspects of instruction so this is the average valuation it's about 59 in the control and when you do the treatment it goes up to 73 so you're you're pushing people off in their valuations counteracting what you think the bias is um if you do substance only you get very little increase in valuation but if you do rhetoric only you get basically the full increase in valuation so the the improvement in knowledge you know the the superficial picture is you're getting the right effects for the right reason right but you're not because these effects are completely unconnected the effects on knowledge are coming from the substantive instruction the effects on behavior are coming from the rhetoric and so they're unconnected and that's why you get these these very dysfunctional patterns for intervention a okay now in place of using these conventional outcome metrics the paper proposes using the absolute value or the square of the money metric bias a measure that we call deliberative competence and this is extremely closely related to what dimitri was talking about before when he was referring to the importance of the variance of the bias right this is basically the same principle turns out that these measures can be rationalized as the dollar equivalent welfare loss a consumer suffers due to characterization failure when they make their decision in the complex frame and um uh to to uh you know in dimitri's work um uh if you remember what he was doing he's considering a market in which there's a price and the thing that has a distribution is preferences and biases okay so he's that distribution allows him to do you know sort of harvard or approximations and he ends up with something that's the square well this just sort of flips it around the the outlook that we have is look we're doing an experiment there's no true price in our experiment what we're trying to do here is say in these types of situations the following things happen in the real world that price could be anything so here we think about the price as having a distribution and then say and then ask ourselves well what what is the loss that people are going to incur due to the bias now the use of the absolute value you can see very quickly that that's going to give you the largest possible loss the person could sustain and because of the harbor harbor approximation the square of the biases is going to give you the expected loss okay um so when we use that measure instead of the conventional measures this is this is now our financial confidence measure this is what we get for intervention a and intervention b between the control and treatment you can say c for intervention a there's a little bit of an increase in financial competence but not much and it's statistically insignificant differences whereas for intervention b you get a very substantial increase in financial competence and the difference is highly highly significant now you i'm now going to come to an issue that hunt raised um which is uh an interesting issue that it's important to make some progress on using money metric bias is an evaluative metric raises a general concern which is that even if simple framing removes the type of characterization failure it's designed to address you know that's that's what we're doing here we're trying to give people transparent problems hunt was doing the same thing even if that removes the type of bias that it's designed to address other valuation biases may remain okay which i kept on saying i'm assuming there are no other biases right um so whether these measures provide valid normative benchmarks when we start taking into account the potential presence of other biases is unclear to give you an example let's suppose that people not only underestimate compound interest but that they're also time inconsistent okay that assumption is certainly plausible given the data in our experiment so maybe a good policy would distort consumers understandings of compound interest in a way that would offset their time inconsistency if you thought that time inconsistency was a bias and these measures of bias don't take those kinds of things into account so the question is what do we do about distortions fatigue other distortions the one ones that we're not focused on when we do a study like the one i'm describing are the ones that hunter is describing what what do we do about other distortions which in some cases may not even be known to us right i mean we don't know everything about behavior so maybe there are other things we should be wondering about this is actually an old question that arose many many years ago outside of behavioral economics question being how do we evaluate a policy that either ameliorates or aggravates the distortion when there are other distortions elsewhere in the economy and there's a classic paper which everyone should read to be an educated economist by uh lipsy and lancaster that argue that the right way to handle these types of issues is to analyze all distortions in all remedies simultaneously and i refer to this as comprehensive second best uh welfare analysis it's comprehensive because it considers everything it's second best because it recognizes that there are all these distortions and you know you can't get to the first test all right now due to feasibility concerns the overwhelming preference of economists is to address distortions and their solutions one or two of it at a time as as we've seen um in other words the way i think of this is we we think that there is this big puzzle that we need to solve we can't solve it all at once we want to carve off pieces of the puzzle i'm going to take one piece compartmentalize it solve that piece i'm hoping other people will solve the other pieces so need back in the mid in the 50s as well proposed compartmentalizing by evaluating one policy targeting one distortion at a time but accounting for all other distortions when you do that and i refer to that as narrow second best analysis now the problem with that is first of all concerns about feasibility remain you'd have to know all the biases and take them all into account and there's also a conceptual problem here which is why take another distortion into account if there's another policy that could correct it that you're just not considering as part of the current analysis so why should we distort consumers understanding of compound interest for example to counter time inconsistency if we can combine effective education with commitment opportunities right i mean why not have policies that address each one of these things why should we think about this policy treating this distortion leaving the other distortions untreated when we may treat them as well it's just we're not thinking about that right now we're not designing that piece right now okay so the dominant approach in behavioral public economics as i said is to analyze a small number usually just one bias and an associated policy at a time sometimes two but while assuming at least implicitly that the consumer's decision-making apparatus is otherwise flawless and i call this myopic welfare analysis lipsy and lancaster called it piecemeal welfare analysis it's tractable but the problem is that there's no reason to think that a piecemeal approach like this yields desirable solutions when you solve one when you solve one problem assuming that the decision apparatus is otherwise uh flawless and in fact it is flawed you will get the wrong answer and then when you put all these solutions together these compartmentalized solutions together you'll get garbage all right well an alternative approach which is what we propose in the paper is to compart is to compartmentalize as follows you evaluate policies to design to design to address a single bias or a small collection under the assumption that effective remedies for other biases will be forthcoming okay and we call that idealized welfare analysis so the difference between that and myopic welfare analysis is myopic welfare analysis assumes that the data that you're observing that has been generated reflects no other decision making flaws idealize welfare analysis recognizes that it it reflects other decision-making flaws but you're solving the policy problem on the assumption that those other flaws will be uh resolved okay so if you can do this this avoids the lipsy lancaster critique of myopic welfare analysis and it logically permits a compartmentalized approach to resolving biases subject to some qualifications that for time reasons i won't go into but it basically allows you to solve problems one at a time i think of it the way i describe it is imagine that you have a rocket and the rocket has a propulsion system and a guidance system and they're both malfunctioning and so you give the proposed propulsion system to team of engineers and say fix this and you give the guidance system to a team of engineers and you say fix this you don't say to each one fix the propulsion system taking into account the guidance system is wacky you say fix this take assuming that we're going to fix the guidance system right and conversely and by doing that you manage to compartmentalize and assemble things in a way so that it works now a natural concern is that idealized welfare analysis may be no simpler than comprehensive welfare analysis because it requires you to figure out how the consumer would behave if all of the other biases were corrected and how would you know that particularly if you don't know what all the other biases are so this paper has a result in it that i found very surprising uh which is that under a separability condition this is not perfectly general you do need an assumption there is there is a separability assumption but under that assumption deliberative competence calculated myopically nevertheless approximates the idealized welfare effect up to an unknown scale okay so you can't perfectly recover the welfare effect but you recover it up to an unknown scalar that that does not vary okay so the idea is that despite the unknown scale you can still reach a lot of useful conclusions you can rank policies according to their effectiveness you can gauge the percentage difference between the dollar equivalence of the associated benefits from those policies you can also aggregate over decision problems the other thing i promised we would get back to normative ambiguity is this is also completely robust with respect to normative ambiguity you're saying there's another bias uh that you know we're doing our analysis of understanding compound interest the other bias is timing consistency and we don't know whether the present frame or the forward-looking frame is the right frame well it doesn't really matter because for both of them you're going to have the same constant proportionality and it's going to be unknown you're going to have a constant of proportionality it'll be different in the two cases but in both cases it's unknown so it doesn't matter that it's different to the two cases okay so i have an illustration here of this principle which i think i'm going to skip uh the just for time reasons but the slides will be available to you and you can read through it's a very simple example that just is designed to try and make it plausible that you would get what otherwise sounds like a kind of crazy result and it goes on to the next slide okay so now let me switch gears and talk about default effects yes but is it true that this idealized welfare analysis uh i think the setting in your paper is the only one for this entire weekend where that should be done because in your setting you know that ten dollars now equals twenty dollars 36 days whereas in all the other settings we'll look at there's some non-financial thing where you don't know there's some non-financial aspect of the decision so you don't know what the right decision is yeah i'm not sure that's right i mean i have we haven't tried to apply it to other things but there's a lot of discussion in the paper about you know how you could apply it in other areas i think it has a lot of applications but you know i haven't tried to figure out can i apply it to your problem to the extent we can put everything into monetary equivalence i think we have a good shot of doing it um but in any particular application it's a question mark so this is pointing a direction there is a method that surprisingly makes progress with a problem that i had originally thought was intractable and so you know maybe there are other things that can be done to to generalize this okay let's talk about default effects um so uh i'm going to start by describing some of the empirical findings on default effects um every decision has a default option uh it's just the option that prevails if no choice is made but in some settings the choice of a default option turns out to be consequential and here are some contacts contribution rates and portfolio allocation and pension plans health insurance plan choices organ donation elections on driver's license these are all examples of where default effects have been studied okay the literature on this begins with madrid and shea and they study a fortune 500 company it changed its default contribution rate for its 401k plan from zero to three percent as a particular date uh the paper examines three groups i'm really going to focus here on two of them those hired during the year before the change which we'll call the window group and those hired in in uh the year after the change which we'll call the new group there's also an old court it verifies that those groups are similar demographically including their age when they were hired they then compare elections for the window group on 630 1998 to the new group one year later so in both cases all people in these groups are within three to fifteen months of being hired okay and what they show is this unbelievably dramatic difference between contribution rates for the two groups but you know you look at the window group and you got 63 of them at zero and the rest kind of dribble out here very few at three percent and then you look at the new group and you've got this huge spike uh at three percent so this result got a ton of attention when they came out with it um there was another change at the same time about the immediacy of eligibility i'm going to skip that they have a simple way to rule out that that's what's going on here and then they also find these unbelievably big change big effects on um portfolio allocation uh so the default option in the plan was to put the money in a money market fund that's the dark area and you can see the window group here very few people put put much money in in the money market fund and then it goes up to 80 percent uh with the new group so absolutely massive default effects i mean you know you think about the literature on taxation and uh saving and and nobody finds effects even remotely this large so so this really blew everyone away when they they found that the effects were of this magnitude uh those findings were corroborated in a bunch of subsequent studies that are reviewed in this handbook chapter there is an important qualification which comes out in this recent paper by czech mini that says that there appears to be substantial catch up of contributions after 12 months so you know these are people who are high savers and you can see big difference for the first 12 months and then a lot of catch up after that same at the median not particularly the 25th percentile of the distribution there are lasting effects down there he also in that paper documents a lot of catch up at subsequent jobs all right so um the literature so now we're going to turn to theory and talk about the theory of optimal default rates there are a bunch of ideas floating around in the literature one is to set the default rates to maximize contributions because people don't save enough thaler and sunstein proposed that in a 2008 paper the question is why do we think that that's a good policy remember for a 401k election when you make an election that has no immediate consequence it's not going to have a consequence until your next pay period at the earliest maybe even the pay period after that so if you think that self-control is captured by the beta delta model well there's no particular reason to believe that people would be making you know present biased decisions with respect to these kinds of elections you're basically completely outside of the beta window all right another idea is to set the fault rates to minimize the frequency of opt-outs this is an older idea due to thaler and sunstein and they said look the people who stick with the default must find it acceptable so that means it's good so this is sort of a notion of exposed validation then there's a completely opposite argument that we should force all employees to make active decisions so that they express their preferences and this is in this carol at all paper but it's not obviously not in the interest of someone who wants to avoid the costs of making a contribution election you know someone who is perfectly happy with the default and goes why force me to to do this um so you'll notice that there is the sharp tension between this second and third ideas they basically are diametrically opposed which carol and all actually they're not arguing for this position they say some of the time this is optimal some of the time this is optimal okay um so determining the best policy certainly requires an understanding of what drives default effects and i've listed some possible theories here it may just be that opt out is costly it may be that people are time inconsistent and so they they um procrastinate their elections maybe that they're inattentive just not paying attention to this or it may be some sort of anchoring phenomena the default is an anchor that kind of sucks people into that option so here i've listed various formal analyses of optimal defaults i won't i won't discuss all of them here because i know that we're running late in the day much of the literature focuses on identifying conditions that justify the thaler sunstein opt out minimization criteria or alternatively it's off its opposite opt-out maximization one or the other question is when are those optimal what i'm going to do is follow the recent paper that i wrote with one of my graduate students because it illuminates i think the problem's mathematical structure more effectively and also arrives at the most general results so um let's go through the model someone faces a default of d okay this is a contribution rate could be any other kind of decision i'm just using a pension plan and a contribution rate as to be concrete so the worker chooses the contribution rate little x to maximize the expression that i've written here let me run through the elements of this v is the future utility from the choice of little x from your contribution rate you can interpret this as a state evaluation function so it looks like a standard a static model it can actually be interpreted as a dynamic model because once you make an initial choice the default doesn't matter anymore so you don't have to worry about future effects of the default okay except through your your initial choice of x um all right x little x star is the worker's ideal point v is maximized when little x is equal to x star rho is a parameter that just basically governs curvature the function eta times lambda is the opt out cost in utility terms and why make that two symbols rather than one the reason is simple the purpose of having so ada is going to vary across the population okay but you're going to see in a minute to this is a it's a it's a difficult mathematical problem and the way that we crack it is by taking approximations from the case where uh opt-out costs are small so i want to be able to take that limit but i want the whole distribution to shrink so i just multiply everybody's a to times a common lambda and then take the limit as lambda goes to zero okay um this i function as an indicator that tells us whether the individual opted out by selecting something other than d beta is the weight attached to future consequences so you can think of that as beta from the beta delta model if you like i'll come back to that in a minute and then uh heterogeneity we allow for arbitrary forms of heterogeneity in beta x-star rho and ada this is a lot of heterogeneity allowed for here okay so a worker who opts out chooses x-star their ideal point if you opted out and did anything else that would be totally crazy as long as you're bearing the cost of opting out you might as well choose the best thing and consequently opt out occurs when the continuation utility you get from choosing your optimal thing minus the continuation utility you get from going to the default and that this difference we'll just write as delta is greater than or equal to your opt-out cost rescaled by beta okay very simple criterion now um in the employer or whoops or alternatively the planner has to set a single default rate d and they can't condition on uh x star or theta that data is just shorthand for the other three parameters okay that that are heterogeneous can't condition on those has to set the same default rate for everyone um now uh uh we also assume that the employer is a utilitarian who believes that beta minus one is a bias okay that you don't have to assume that i'll come back to that uh shortly when i'll talk about normative ambiguity uh but for now assume that that's a bias so aggregate welfare relative to the first best is the expectation over theta of this expression which looks a little messy but i'm just going to break it down for you so the the first term is what the welfare loss would be if everybody opted out and chose their ideal point relative to the first best because in that case it's just everybody is incurring uh the opt out costs and getting x star so that would be your answer if everybody opted out now everybody doesn't opt out okay yes i thought ada was a random variable did i get confused here i'm doing this for a particular individual yeah so we're gonna we're gonna integrate over all these parameters yeah um so uh does this guy opt out um uh well now we're talking about yeah i mean i guess you have to think about integrating this thing so you can see it so this would be the fraction of people who opt out um uh yeah so think about that first term as the size of the population is unity and we've integrated over it so that's for per capita okay so this term is the fraction of people who opt out and now for the people who opt out their um uh their welfare loss is not going to be ada lambda it's going to be less than atlanta okay it should be eight o'clock that's not it um so to what extent have we reduced the welfare loss for those individuals who opt out well what they end up losing is the expected value of their um uh of their uh uh uh of their of of uh delta which is the uh the difference between the two of these you get from x star and from d that's the welfare differential from not opting into the default we're just going to take the expectation of that conditional upon uh these guys opting out okay and this is the loss instead of this so basically what we're doing here is reducing the welfare loss by this amount to this differential for those people okay um yeah so you'll notice that now we're going to think about optimizing over d you'll notice that the first term doesn't depend upon d and therefore we can ignore it when we optimize so here's my observation if it were the case that this expectation term didn't depend upon d then the bracketed term would just be some function which we could write as omega of theta which we can treat as a weighting function would it would depend upon the individual characteristics it wouldn't depend upon uh it wouldn't depend upon um uh the the d the default uh and in that case welfare maximization would be equivalent to this which is just weighted opt-out minimization okay so weighted opt-down minimization will be optimal if this thing this expectation term doesn't depend on d so all i need to do now is convince you that that expectation term does not depend upon d and in fact the claim is that for small lambda if you pre-multiply that expectation term by lambda inverse that's approximately equal to eta over 3b so if you assume that the claim is correct then this whole mess just becomes eta times one minus one over three beta and that's now our weight so the optimal solution is just weighted opt-out minimization with these weights that's it it's actually pretty simple okay um now i have to convince you that the claim is right and for that i draw a picture so um here's the expression that we're trying what did i do with the thirds here's the expression that we're trying to evaluate um to a second order approximation this thing is a parabola where it's minimized at x equals d okay x star equals v because when my x star is the same as the default i have no welfare loss okay my x star is d so if i get d there's no loss so if you think about um the this how this term looks as a function of x star when x star is equal to d it's equal to zero and if we take a second-order approximation nearby that it just looks like a parabola okay now the other thing that we know is that if lambda is small the opt out window the opt-in window is is small as well so density is going to be approximately constant over that interval and that means that this expectation is going to be approximately the area under this parabola divided by the width of the interval okay that expectation is just going to be proportional proportionate to that ratio uh now the area under this is just a parabola doesn't matter width of the parabola you know it's always the case that the area under the parabola is going to be one third of h what's h here well h is just this thing okay you're looking at the parabola to the point where people opt out and they opt out when you get up to that point so substitute that for h and you end up getting that this term is approximately eight over three data and that that's it you then substitute that back in go to town you have weighted opt out minimization now the actual proof of this is quite a bit more difficult because you actually have to show that all of the you have to show a lot of uniform convergence properties so there's a lot of work to button this all up but basically this is the picture this is this is why it works okay uh so as i said that observation points to the main result here which is that weighted opt-out minimization with those weights is approximately optimal and again that's for small lambda but we do simulations in our paper to show the approximation is really quite good surprisingly good even for substantial opt-out costs so it's you know we do a lot of these first and second order approximations and this one seems to work pretty well um now you there are a couple of other things that you learn here let's suppose that there's no heterogeneity and data for a minute okay then with sufficient bias if beta is less than a third just go up here and look at what happens to this thing when beta is less than a third all of those things flip signs okay and as soon as they flip signs then the objective becomes weighted opt-out maximization rather than weighted opt-out immunization uh so i have a question about what type what is the original bias here so people when they're deciding whether to opt out or making a quotable rational decision in the sense that they're trading on costs and benefits yeah but i'm just not paying attention do these results they they this is not what i've written up here is not an attention model but it's close to that i'll come back can i come back to that in a minute because i'll refer to that shortly okay um so you know for right now think about this as a procrastination model rather than an attention model okay um the other thing that follows here that i think is really interesting to go back to the uh the general welfare framework that i described earlier is that as long as beta exceeds one-third so that we don't have this issue normative ambiguity concerning beta doesn't affect the optimal okay you can you can say i don't know whether beta is normative or not whether i include it or whether i don't include it if i throw that into the welfare relevant domain it doesn't have any effect on the optimum now if beta is less than a third it has a huge effect on the optimum because then normative ambiguity makes the difference between opt-out minimization is is uh is optimal versus opt-out maximization is optimal but as long as beta is bigger than a third normative ambiguity doesn't matter at all um okay uh uh for cases with bunching and finite menus it turns out the same result holds except that the weights simplify which also surprised me it's just the way it's just become ada uh and finite menus and bunching that you know bunching happens because of like you know 401ks we have matching provisions and they run out at some points the the opportunity constraint kinks and people tend to to collect at the king points so we wanted to see whether that made a difference and it actually simplifies things it makes the results stronger in some sense now that what what shepard and thales chefren and sunstein originally proposed wasn't weighted opt-out minimization it was um simple opt-out minimization so the literature has been mostly interested in when that's optimal we're the first ones to look at weighted opt-out minimization so most of the results are just about you need these conditions following conditions to make unweighted opt-out minimization or maximization optimal but you can see that an immediate corollary of our main result is that unweighted opt-out minimization is optimal if and only if it coincides with weighted opt-out minimization so now you can answer the question about whether unweighted optimization opt-out minimization is optimal uh extremely generally by just asking what what are the conditions under which it coincides with weighted opt-out immunization and here are some sufficient conditions uh the characteristics of beta and ada are independent characteristics x star and rho you also need limited mass of very small values of beta less than a third although you can relax that condition too if the firm can also impose penalties for for passive choice and then you're left mainly with these correlation conditions which are extremely weak conditions if you look at the other papers that preceded us you know they're they're listing lots of conditions like symmetry of distributions and concavity and things like that that actually are not needed um there's a question so i'm trying to reconcile this result with the intuition that what really matters is the targeting of the instrument and so why isn't there a term here that says something like defaults are good if they affect behavior for people with the highest data um that is in here through the correlations um so absolutely you've got something where if some of these things are correlated in certain ways that causes you to want to place more weights on those people and that's precisely what the difference in weights are doing but the interesting thing is that doesn't you know that doesn't always happen um i i haven't really completely thought through how it fits into the framework that dimitri was describing because there is one difference here which is that um decisions are discontinuous you know they they jump when you get to the end of the the opt-out interval and i just don't know how that affects um that part of the mathematics uh it may not affect it at all but i just you know formally i think the the models don't directly apply okay um okay so i finished on that slide yeah so i read this as saying that we should really be going for opt-out minimizations because beta less than a third for the majority of the population seems totally yeah unrealistic um but then i have a vague recollection that that in the carolina paper they had a broader region and there were something like active choice was optimal i didn't i i don't remember a number for that i know that they have yeah it's just okay i thought they had an abstract result says there's a threshold that they did something with the uniform distribution where the region may be both but anyway i was i might be completely mystery the other thing is i don't the other thing that's important to remember is that you know this is a limiting result their calculations were not at the limit and so they won't match it perfectly and this gets back to the issue of how close are the limiting approximations and you know we have simulations where they do really well but i wouldn't rule out the possibility that it breaks somewhere um okay the last very last thing i want to do and then i promise i'll stop and we can we can uh go on to uh to more relaxed activities is to briefly talk about empirical implementation um so there are two papers that study this this issue empirically uh one is mine with um andre fratkin and you are papa and the other is uh chuck mani's paper um so i'm gonna i'm gonna refer to to our paper here uh it considers multiple theories of default effects so it looks at just plain opt-out costs then it looks at sophisticated time inconsistency which is actually what i was just talking about i mean the model that i was describing is sophisticated time and consistency but golden and wrecked paper adopts that framework and then says it applies to a bunch of other biases i think it's more limited than than they were saying it does apply to some though we describe a different model for naive time inconsistency inattention and anchoring which is hunt's question about inattention we actually it's this is not rational in attention this is this is irrational inattention but um uh we do have a model of it okay and then we calibrate the the models to the available data and in each case we entertain the entire range of possible assumptions about welfare relevant domain so we don't hear you know insist that we know which choice patterns are the welfare relevant ones and our findings are first of all that as if opt-out based on the empirical calibrations as of opt-out costs have to be very high as in thousands of dollars to rationalize uh the magnitude of the default effects that's consistent with some calculations uh that's stefano delavinya did uh but i will note that chuck many in his paper finds opt-out costs of about 250 rather than 10 times that amount uh and he says it's because he has a fully dynamic model and it has to do with this catch-up phenomena that i described i'm not entirely convinced that that's right because the thing that i pointed out to you earlier that our model uh uh can be interpreted as a reduced form for for the dynamic specification talk to taha about it now he's not sure about it so we haven't we haven't really sorted this out but even if it's 250 dollars that's implausibly high how could it i mean these elections are easy to make if you if you ask yourself the question how much would i have to pay the typical worker who makes 50 000 a year to go and make their elections i mean probably 20 bucks would do it in most cases right not 250 so the next result is or certainly not you know 10 times that amount next result is that the data appear to favor the anchoring model uh rather than the other models that we considered and the reason of um that well first of all the size of the opt-out costs make it hard to rationalize this as time inconsistency there's also no trough in the distribution of elections around the spike that you get at the default and if this was just an opt-out cost story even if that was magnified by time inconsistency that would just sweep out a trough near the default so you should see a trough you don't see a trunk what you see is the whole distribution being pulled from both sides and that looks much more like an anchoring model so the data seemed to favor a gray generally we find that firms should optimize the default contributions by setting them at points of accumulation in the distribution of choices which occur at boundaries either zero or the maximum and at kink points uh the match cap and that empirically this usually coincides with opt-out minimization uh and when there are differences it doesn't do much much worse than opt-out minimization it was this the robustness of this result which you see here as well as in chapter manny's paper that made me and uh and jonas my co-author go okay let's figure out the mathematical structure of this problem because something's going on here that is making this an extremely robust finding uh finally for three out of the four theories alternative assumptions about the welfare relevant domain you know uh taking different positions about what's welfare relevant have surprisingly little effect on the optima or on the implied welfare effects now on the optima isn't too surprising given what i told you a little while ago because i already explained why you'd have a lot of robustness with respect to normative ambiguity there but for the case of sophisticated time inconsistency if you assume that the costs of that says output it should say opt out are 25 or 30 dollars say from the forward-looking perspective and people are acting like they're 100 times that much because of biases then you would imagine that basically if you did a welfare calculation where you said 99 of this opt-out cost doesn't count you should get a difference of thousands of dollars right but that's not what we get um this is uh default rates here different default rates that you could set this is equivalent variation measured as percent of income this is a negative percent of the amount that you lose by setting something other than uh the optimal well uh something other than the first best okay and uh the red dots are the equivalent variation associated with the in advance frame and the blue dots are associated with the contemporaneous frame the only difference between these valuations is that here you're excluding part of the opt-out cost the part of it that isn't normative and you can see that the difference is like maybe not the percent of income so somebody who has an income of 50 000 this is 250 it's not nearly large enough right so why does it why doesn't it make more difference in terms of why isn't there more normative ambiguity here given the enormous ambiguity of evaluating these costs you would think that there's more enormous ambiguity and there isn't so let me explain why there isn't so uh calculated welfare is higher when welfare is evaluated in the perspective of the in advance frame rather than the contemporaneous frame because basically what you're doing is excluding um almost all of the as if opt-out costs from consideration okay so this is the argument that says that suggests that this should be a really big effect but there's actually a distribution about that costs not everybody has an opt-out cost of 2500 you know empirically in this model there's a lot of people who have much much smaller opt-outs and then people who have even larger as propped up costs now when calculating welfare from the perspective of the in advanced frame we exclude almost all the opt-out costs for those who opt out because they're the only ones who are incurring the costs the people who don't opt out are not incurring those costs okay so those with the really really high opt-out costs they just don't opt out so changing the frame of evaluation doesn't change the equivalent variation for them because they haven't they haven't incurred the opt-out costs changing the frame of evaluation changes the welfare calculation only for the people who do opt out and for them the opt-out costs just aren't very large on average so it doesn't make much of a difference the normative ambiguity isn't very large and i wanted to end on that to underscore this point about normative ambiguity and it seems like a lot of times people are afraid of it i get asked the question a lot about doesn't the fact that you're allowing for normative ambiguity mean that you won't be able to reach any conclusions and the answer is no it is not what it means you can often deal with normative ambiguity and still reach sharp conclusions this is a great example the norm of ambiguity subject to the beta less than a third restriction doesn't affect the optimum and it doesn't have much of an effect on the equivalent of equivalent variations at least compared to what you would think okay so that's a summary of those topics as i said i think this all fits together really well as a package in terms of you know the the methods and how they work and what's important so i think we're now at the end of our first day 