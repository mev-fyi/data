so um i want to talk today about biases in allocation of cover 19 relief funding this is work a joint work with pravia pragya kakani who's a phd student at harvard ziad obermeyer and amitabh chandra ziadza faculty member of berkeley and on the top the faculty member at harvard so what i want to do today is to talk about one paper which is a very short paper we had in jama that came out it was part of this exciting period that kind of given tragic circumstances but i think really changed the way a lot of social scientists do research like we felt like covet is happening wow like i want to contribute to doing something about this activity and that is what motivated this paper has motivated many other people so what i want to tell you is the problem we we were dealing with so the issue was um goes back to right around the time at the beginning of the virus and we were worried about hospitals being overloaded etc we started to people quickly realize wait there's kind of a problem here like there's a health care problem but there's actually a pure financial problem which is hospitals are about to be slammed they're about to take massive financial hits and what are we going to do about that i found this new york times headline particularly cutting hospital knew how to make money then coronavirus happened and the forecasts were very large we are talking about um hundreds of billions of dollars and as those of you working in corporate finance might know these are not just transfers from you know hospitals deep deep pockets of hospitals to something else these risk genuine financial distress and hospitals shutting down and if we don't do something we could actually face far fewer hospitals and sort of lots of fixed costs gone okay but the government tried to do something about this this is a an example of the cares provider relief fund the idea was well we've got this problem covid the way we're going to try and do this is we're going to support the impact that covet had the fiscal impact by transferring 175 billion dollars the question is how should those 175 billion dollars be allocated now where do we want it to go we wanted to go to the health systems most affected by coving specifically the health systems are you know most revenue loss due to coverage so the delta in impact uh from kobe so the question we're interested in is how equitably will these resources be allocated and in particular racial disparities in this so because anytime we allocate resources we worry about inequities and along the way i'm actually going to talk a little bit about the efficiency of this allocation now a lot of us who were motivated to do something about covet i think it's fair to say the right stepping off point for all of us is not just the question of interest but what we knew anything about and we had done a little bit of work and it's seen problems like this before and what the kind of problem i want to talk about is the targeting of resources is a prediction problem that we're trying to predict the covet burden predict the revenue shortfall and in fact we've seen exactly this kind of problem in a paper that we just finished that had come out in science on uh racial bias in an algorithm and i'm going to walk you through this paper briefly because i think it'll be very useful to see the analogies between this paper and what we find for the cares allocation data because in part i think it'll tell us both something about covid and about how we ought to be allocating these resources in the future so let me tell you this brief side note about this paper allocation of care coordination programs is what this paper dealt with so the idea for those who don't know health care is that patients with a ton of chronic diseases are the source of the biggest costs in health care so programs are like wow we want to help these patients out because they're the ones who are going to be the biggest cost so for example if we give them a nurse who they can call before coming in then they don't need to come in and clog up the system maybe there are some things that could just be dealt with by a nurse so sort of focus resources so these people can more efficiently use and seek care now these programs are expensive so targeting is crucial in fact the question is how do we target care coordination program to patients and you'll notice this looks exactly like how do we target care's resources to hospitals now in the cares in the coordination programs there was already an algorithm a rule used to target these patients at scale so this algorithm has been running for several years these algorithms have been running for several years implying about 100 million patients so what we looked at in this older paper was how does this algorithm do and i want to take that and ask what lessons for the rules used by that algorithm are there for the keras act so just to remind you this is what the distribution of patients would look like by sickness and this is the algorithm risk score so what is an algorithm it's just a rule for scoring and this algorithm is going to determine who gets treatment so the top two to three percent would get auto enrolled in a care coordination program the next 45 percent would get enrolled as a function of something and the bottom 55 are screened out so what we were interested in is okay you have this algorithm deciding who gets these programs how much racial bias was there in this algorithm so what do we mean by racial bias we mean at the same score people should be treated the same and they should have the same needs so the color of their skin should not matter and here's what we find on the x-axis is the percentile of the risk score on the y-axis is how many active chronic conditions that people ended up having the realized conditions and you'll notice at the same score white patients in the bottom curve are far less sick than black patients and this gap is enormous they're 28 more chronic illnesses of the auto enrollment threshold but let's that's a little hard to interpret so let me instead point out to you we have 18 blacks enrolled right now in the program if we just equalize these two curves we'd have 47 blocks enrolled that gap is that big and you can kind of read out by looking at the marginal white patient look how much you would have to go across the curve to get to the marginal black patient to be equally sick so what was happening in this program so what's happening in this program is that the algorithm to understand where it went wrong you kind of want to get a clue as to where it's going right if i redid the same exercise not for health but for costs you'll find the algorithm is remarkably well calibrated for cost instead of finding the patients who are going to be the sickest we found the patients who are going to be more most costly being biased in health and unbiased in cost is what we managed to accomplish because blacks and whites do not have the same relation between health status and costs whites have better access to health care as a result at every level of health blacks cost less so if you go about targeting costs you get biased health protection so the depth of the problem is that so basic that this isn't some trade-off oh maybe i really care about cost if you knew you cared about cost and health you can actually do well at predicting an algorithm that does nearly as well at predicting costs but has no racial bias and predicts health better and that's because when you build these algorithms you can imagine it's a flat of the curve i kind of roughly optimized for one variable had i known i cared about two variables i would have actually found a solution that was almost as good for the first one but did really well on the second so there's approximate money on the table even if you really just cared about cost so the key takeaway is in targeting getting the exact measure to be predicted matters i think this is a cousin of goodheart's law you know how a target becomes a measure it becomes useless here we often end up predicting the target we have not the target we want in this example the coda the postscript is that actually people when they saw this paper they're like holy cow what are we doing so they started trying to fix the problem it's just we did this through convenience now you can imagine where we're going to go let's go to the carrier's funding allocation how was the first round allocated it was allocated to the hospitals based on their revenue in the past now the second round took a few other things into account like safety nets rural providers but ultimately conditional on those the variable at play was net revenue now that's a little funny because the desired target was hospitals will have high needs due to covid what was used was that the systems who used a lot of resources in the past resource intensity is not the same as resource need especially not resource needed to covet and you'll see the analogy is perfect here and that's why it was we started working on this problem so what do we find well first obviously the rev the revenue that uh systems got after the revenue the systems realized um was highly correlated with the cares act fund per resident so on the x-axis is um how much funding did you get on the y-axis is what was your realized revenue for the the following quarter and you'll see that in fact uh there is a strong correlation okay but let's show you how different that correlation is than uh what where covet actually hit and where the burden was so the top is where this first figure is where the money went and the second figure is where covet actually hit and you can see this is not really such a discipline now you may say oh is this just about like kobit was hard to predict actually that isn't it because these are the comorbidities on the bottom map so it's not where covet hit it's where covid would have the biggest consequences based purely on xanthe comorbidity we could have chosen the second figure but we kind of ended up choosing the first one let me show you how off the correlations are on a bunch of other things revenue correlates very well but the chronic illness prevalence hospital financial health which you thought we would have cared about didn't matter and certainly covet 19 cases and debts don't matter now this is just a bad targeting rule but as the racial bias paper told us because it's focused on revenue it could have a racial bias component which is what we looked at next and the x-axis is the care's funding yet again and the y-axis is the code of debts per 100k and now you'll see conditional on the funding there were far more debts in the counties that were highly black than in the county is that we're highly white so this is very similar to the graph i just showed you it's just racial makeup of county what this is telling you is if you went to counties that had 800 you know 800 funding for residents the white counties had far fewer covert debts than the black counties like by a wide wide margin and you see this not just for covet debts you see this for comorbidity you see this for each of the elements including something as simple as hospital cash on hand or hospital operating margin there was always a disparity this is a regression which in the interest of time i'll skip but this is in the paper just everything i showed you in regression format so what do i want you to take away from this well i think the money missed the intended target and we know this a little bit now in the last few months some places a little bit ashamed are giving back the cash they're like well we're making a lot of money this feels a little weird that we're putting high operating revenue on and we took money from the government but more importantly the money exacerbated large racial uh racial inequities that we already know were occurring due to covid and i worry that we're going to leave a scar that hospitals serving black communities may take longer to recover or some may even frankly shut down so this effect is not simply oh we made a mistake this mistake may persist we're about to allocate 35 million dollars now in this new bill are we going to make the same mistake again with this 35 billion um i would hope not but this isn't a mistake it's an entirely preventable mistake you could say the financial burden of covet is hard to predict yes completely agree but better modeling could easily have been done we could have targeted the policy to needs not to revenue that's complicated but we have a lot of data that could have been used again this is not about predicting the spread of disease it's not an epidemiological thing this is about recognizing comorbidities financial help to the hospital various things could have all been used to predict the distress that a hospital would face i think i want to end on a more general point i think the empirical policy toolkit is highly advanced that's the amazing thing that economists have contributed to and driven over the last 50 years but predictive modeling is not yet a big part of it and i think as these things show allocation of resources where money should go so many choices are about predictions that we're implicitly making and i think if we took what we are starting to understand about that and could import into the toolkit we could prevent what i think is a disaster like this all right thank you 