thank you very much so Michael asked to ask ask the speakers that I include some advice for the Youth for graduate students who are watching this I'll start with some advice for the Youth I'll close with a question for the elderly which I count myself as one these days um but so advice for you I think there's a lot of great open terrain for research at the intersection of finance and Market design doing this work I think requires paying two fixed costs and a recurring cost so the the advice for graduate students is to pay these costs you have to pay a fixed cost in mastering the market design literature of course you also have to pay a fixed cost in mastering the finance literature I think the intersection the the set of students who have both Market design and finance as their fields is already kind of a shrunken set and then the recurring cost is just staying on top of financial news whether it's through the Wall Street Journal or Matt Levine and Bloomberg but if but if you pay those fixed costs and that recurring cost is just tons of really interesting Market design problems there's huge economic value huge social value a lot lots of markets to think about improving with that context and said let me let me talk about I want to try to make the case to you over the next next chunk of time about improving the design of financial exchanges around the world and I'm gonna try to argue that the predominant exchange design used used globally in finance including markets regulated by the SEC and the cftc so thank you to my co-panelists it has a design flaw I'm going to try to convince convince you uh convince you that frequent batch auctions would address this this flaw but before I do so let me step to a very high level and the probably the most famous idea in finance right the first you learn as a finance graduate student is the efficient markets hypothesis so the efficient markets hypothesis says that prices reflect all available information and Gene farmer my colleague is careful to note this is pretty extreme as a hypothesis so he he asks at what level of information does this hypothe does this breakdown and what he concluded in a famous paper from from 1970 is that it breaks down at the level of private information if you know something the rest of the market does not know uh you can you can make money you can profitably predict securities prices but that public information whether from past prices or from uh fundamentals uh is is not you're not able to beat the market on the basis of that kind of information it's been a lot of work over the intervening decades on efficient markets Theory the modern consensus is that there is some predictability in asset prices over longer time Horizons Bob Schiller is famous uh famous for this work was part of what what he was awarded the Nobel Prize for there's a raging debate on how to interpret this long run predictability is it risk is it behavioral uh but it's it's there in the data on the other hand the consensus and the profession is that at the short run efficient markets Theory Works uh works very well there's a hundred percent consensus from an IGM experts panel the Nobel committee describes short run predictability as a quote basic malfunctioning of the market mechanism so that context in mind let me tell you about the arms race for trading speed among high frequency Traders a famous early example that I've written about is in 2010 a company called spread networks invested several hundred million dollars to improve data transmission times between markets in Chicago and markets in New York and New Jersey by three milliseconds or three thousandths of a second observers at the time talked about three milliseconds as a quote eternity they joked that someone was going to go through the Earth rather than around the earth to shave transmission time even further and that joke in a way manifested so not literally tunnels but microwaves are a faster way to get information from one place to the next for physics reasons and the arms race for Speed has continued to this day it's commonly measured in millions and even billions of seconds and as you'll see from from my estimates and and some others it's on the order of tens of billions of dollars a year globally if you extrapolate across all financial asset classes and this includes Hardware software communication links and most importantly a lot of high quality human capital um so the the question that's animated my research over the last decade plus is how could such tiny speed advantages be worth so much money it can't be about fundamentals three milliseconds isn't enough for a fundamental Edge over other investors quarterly earnings are announced once per 8 billion milliseconds um and Technical trading economists are intrinsically skeptical about this is the efficient markets they're as describing earlier Bert malkiel in a famous book cut so calls technical strategies usually amusing often comforting but of no real value and again a rather basic malfunctioning of the market mechanism so the answer that's emerged from from my research with um with Crampton and Shem and and other collaborators since uh is that the the source of the problem the sort the high frequency trading arms race is a symptom of an underlying flaw in the way Financial exchanges around the world are architected and the flaw is the combination of treating time as a continuous variable and processing requests to trade serially that is one at a time in order of receipt this Market design is called The Continuous limit order book or the electronic limit order book and so forth this combination of continuous time plus serial processing means that there are riskless Arbitrage profits I'll show you the theory for why from symmetric public information so that is there's a violation of efficient markets Theory uh it built directly into the market design the kind of information that's supposed to get into asset prices for free symmetric public information uh instead earns Arbitrage rents and these Arbitrage rents first of all they're not supposed to exist they serve as a tax on liquidity and they induce a never-ending arms race for for trading speed and the market design solution is to put time into a unit to make time discrete and that enables a notion of multiple orders arriving to the market at the same time which is not possible in a continuous market and then those orders can be processed and batch using an auction um so I'm going to organize the talk around a series of three papers how roths often emphasized that uh Market design research often occurs over a series of papers over an extended period of time and this has been a big chunk of the last decade of my research um so let me start with this uh this 2015 paper and I want to start with some empirical facts about how financial markets behave at high frequency time Rises so this is data on the two most actively traded uh financial instruments that track the S P 500 Index and they have an Arbitrage relationship between them one's a Futures Contract one's an exchange traded fund and as you'll see over this is a day of trading data and as you'll see over the course of a day of trading data the prices move in perfect lockstep as they should because they have a basically perfect Arbitrage relationship between them here's an hour of trading data a minute of trading data and then this is 250 milliseconds this is about the amount of time that it takes to Blink your eye and what you see when you zoom into high frequency Horizons is that prices that look like they're behaving the way asset pricing Theory says they should actually behave in a much shocker fashion and that creates lots of Arbitrage opportunities you can see there's an opportunity to buy the cheap one and sell the expensive one and lock in and essentially riskless riskless profit the duration of these Arbitrage opportunities has come way down over time with competition on speed the the profitability of these Arbitrage opportunities has actually been pretty constant and I'll show you why theoretically the frequency of these Arbitrage opportunities does vary a lot with time but the variation is explained almost entirely by market volatility which makes sense if the Market's jumping around like crazy there'll be lots of lots of opportunities to exploit differences in prices across highly correlated assets and then this is another way of showing the same phenomenon this correlation breakdown that leads to Arbitrage opportunities you can see if you folk if you look at the right side of the figure at 100 milliseconds the market is getting faster and faster and faster at incorporating uh information from Chicago prices into New York prices and vice versa but at high enough at high enough frequency the correlation is always basically zero and then it has to be there's nothing in the market architecture that would enable prices to move at the same time um throw races everywhere um this is just one one trade I'll show you an empirical paper that shows how to extrapolate uh how to quantify a latency Arbitrage more widely but there's hundreds of traits conceptually similar uh to S P 500 Arbitrage where you have highly correlated highly liquid assets so here's uh here's arbitrages in the U.S treasury market and other Equity indices in the Foreign Exchange Market Commodities markets more Commodities markets the coffee Market of Alan I like to drink coffee um and here's just a long list of of other Arbitrage pairs um in fragmented Equity markets the same asset trades on in the US for example the same asset trades on about 15 different exchanges and about 50 different off exchange trading venues so there's some arbitrages that are even simpler it's the same asset across multiple venues there's a race to respond to public news so every time the FED makes an interest rate announcement for example that that triggers a trading race and there's races to the top of the trading book so let me give you the theory behind uh behind why there are so many trading races and why the root issue is continuous time serial process Trading so the the model in this paper it's a descendant of the famous Gloucester Miller model this is security that trades on a continuous limit order book Market we take the details of the market design very seriously in this paper and um in a way that some some past Market microstructure models uh cause some Market microstructure models to to miss the possibility of trading races uh there's a signal um why of the value of this security so think of the signal as information from Chicago that affects prices in New York uh or just more abstractly and then we'll make the purposefully strong assumption that the asset is just worth the public signal that's that's jumping around so the goal is to create a kind of best case scenario for Price Discovery and liquidity provision uh in a limit order book Market um so the model is designed to try to strip away all of the traditional sources of liquidity uh in financial markets there's no inventory costs there's no asymmetric information everybody's risk neutral um so you might conjecture free liquidity and I've stripped out all the traditional sources but that's not what happens because of a phenomenon we call sniping or latency Arbitrage it's rents from symmetric public information so here's a visual explaining the key idea let's say you're a market maker the public signal is currently y1 you're making a market with bids and offers so offering liquidity to the market let's say that signal jumps you'll send a message to The Exchange to cancel your old quotes and to replace them with new quotes reflecting the new public information but if the information is symmetrically publicly understood other trading firms will send a message to The Exchange seeking to pick off or snipe uh snipe wins deal quotes they'll send messages seeking to trade at your now stale ask prices to uh that's too low and because the market design is processing these requests serially that is one at a time in order to receive the likelihood of getting picked off is quite high in the theory model it's n minus one over n even even in the extreme theoretical case where information is completely symmetric and we all act with zero latency kind of take take your theoretical limit model um so in a continuous limit order book symmetric public information creates arbitration so again that's not supposed to happen repeating myself and in equilibrium these Arbitrage rents ultimately get paid uh by investors the the consensus in the literature had been that asset prices are next to impossible to predict in the short run but that's actually wrong if you focus on the extremely short run in the extremely short run asset prices are very easy to predict and there's a lot of money in doing the prediction uh this is one of the key equations in the paper I haven't defined notation but what it says is that the the excess cost of liquidity in the market because liquidity providers have to get compensated for getting sniped all the time um so the excess cost investors have to pay for liquidity is equal to the value of all of these sniping races and then when you add an entry in entry game so you can invest capital in in getting faster you get another condition that says that um the investment in speed technology dissipates uh dissipates the rents it's sort of a standard telegram seeking tournament uh intuition the arms race for Speed has continued vigorously as I mentioned the microwave connection between Chicago and New York next time you're at Millennium Park check out the top of the Aeon Center which for a while was was one of the Hops here's some time lapse data from 2010 to 2016 of microwave licenses uh in in you'll see the region in a moment um so you can see the the microwave links getting faster and faster and faster straighter and straighter and straighter here's the end of our our data and you'll see Washington DC is included it's actually just a few blocks from here it's somewhere on K Street ironically um and why is Washington D included in this latency Arbitrage triangle a lot of symmetric public information gets announced here um so let me talk about the solution which is what we call frequent batch auctions so at a high level the the idea is to take the current market design The Continuous order book and just make two changes so one is to put time into discrete units and the second is that to process orders that arrive at the quote same time in batch using uh using an auction there's some design details I'll point you uh to the papers uh but the the one thing I want to reiterate is that otherwise design details are very similar to The Continuous order book so priority is the same but when time treated as discrete information policy is the same but with information disseminated and very frequent uh discrete discrete time um so why does batching solve the uh solve the problem of sniping in the arms race for Speed the the first kind of obvious reason is that if you have a batch interval and the speed different speed advantages are small relative to that batch interval it's unlikely that information will arrive at a time where I can act and you can't if I'm a little bit faster than you so you get this ratio Delta over Tau in the paper where tau is the batch interval and Delta is the relevant speed differences whereas in the continuous Market if I'm even a millisecond faster than you or so even if I'm even a millionth of a second faster than you that's that's relevant for any new public information the second and more subtle and I think more important reason is that auctions change the nature of competition to competition on on price away from competition uh on speed so even if information does arrive at this critical window if there's an auction there's a Nash equilibrium in which we bid the new public symmetric public information whereas in the continuous Market you still have competition competition on speed to pick off skill quotes there are huge computational benefits of discrete time we just put a pin in this is something I'd love to see research on uh at the intersection of economics and computer science discrete time respects um respects communication constraints between exchanges in a continuous Market you have to take relativity in account into account uh to make sense of the paper trail of financial markets there's a lot of you clean up a lot with with discrete with discrete time um so let me talk now about some research with Peter O'Neill and Mateo aquilina who are re at the time were at the UK Financial conduct Authority and this is a paper that enabled us to quantify latency Arbitrage in your arms race for Speed in a way that had never been possible before and the code from this study is publicly available extensively documented I hope I can convince others to to replicate this work in other contexts um so we're going to use a simple new kind of data to measure latency Arbitrage in a way that had previously never been possible the prior paper I mentioned measured latency Arbitrage for one very specific trade but there hadn't been good comprehensive comprehensive estimates of just the magnitude of the magnitude of the issue across across markets more generally um so the the kind of data is called message data so in traditional limit order book data like the the taq data set that many asset pricing researchers have used uh you can see very detailed play-by-play of the limit order book Market um but what you don't see is you don't see messages that don't affect the state of the limit order book because they fail so if I'm trying to pick off a stale quote and so are you and I succeed and you fail you will get bounced back with an error message that says you're too late or if you try to cancel and you're a little bit too late you'll get bounced back with an error message that says sorry you just you're too late to cancel now this our simple Insight is that these failure messages which are recorded by computers are are empirical signature of speed sensitive trading if you could see multiple participants at the same time some of whom succeed some of whom fail that can give you a sense that there's a race races have winners and losers limit order data don't let you see The Losers of the race so we obtained using some regulatory muscles so kudos to the financial conduct Authority message data for a long period of time from the the UK stock market with great time stamps and this data lets us measure lots of stuff I've been wanting to measure for a long time here's a schematic of how exchange systems architectures work on the way in Traders send messages to what you can think of as the market on the way out the market sends messages back to the Traders and we we grab data at a very convenient point in this systems architecture for measuring for measuring trading races this is a fax paper let me tell you the the key facts that emerge so first races are very frequent about one per minute for large cap stocks about 500 races per symbol per day um they're very fast the the modal race lasts between 5 and 10 millionths of a second and time between the first winner and the first loser of the race uh this is probably the most astonishing fact in the paper 22 percent of all volume takes place in trading raises um race participation is concentrated so the top six firms uh win and lose over 80 percent of trading races and they disproportionately are our snipers as opposed to liquidity providers um races are small per race on average a few bucks but because of the volume it adds up to significant fractions of of traditional measures of the Market's cost of liquidity so about a third of the effective spread and a third of a measure called price impact that how Shang talked about uh and then Market design reform could meaning reduce the cost of liquidity using a little some theory-based reasoning ask if we remove latency if we reform the market design to remove latency Arbitrage and kind of resolve for equilibrium pedest spreads eliminating latency Arbitrage would reduce the cost of liquidity by 17 and it adds up to a meaningful total size of the price it's about a half basis point tax on trading which is about five billion dollars a year uh in equities markets alone let alone uh Futures currencies options bonds and so forth um let me skip this slide and come back to it at the end other than to say this creates the magnitudes in this study create something of a concentrated dispersed issue where there's a small tax on a large number of Market participants and a smaller number of parties who benefit from uh from the tax if you're if you're one of the parties earning a share of billions of dollars a year from the speed race you have significant incentive to try to preserve preserve the status quo so lots of concentrated dispersed dining Dynamics I think over the course of the last uh last couple of days and then last let me talk about a paper with Robin Lee and John Shem on whether Market forces will will fix the problem um so Market design research usually focuses on designing the best possible Market mechanism for a given problem but we want to ask the complement which is suppose you've designed an attractive mechanism you're just just suppose uh will it actually uh will it actually get adopted so what are the private incentives uh for stock exchanges to uh to adopt a frequent batch auctions this is a question of do private and social Innovation incentives uh align or will the market fix the market so we study a model closely tailored to the institutional details of modern uh modern electronic Financial exchanges I'll skip some of the details in the interest of time um we first study a sub game in which all exchanges use the status quo Market design and any equilibrium fine that trading fees are brutally competitive and but that exchanges are able to earn economic rents from what we call speed technology so how Shane talked about data fees co-location fees those are some of the fees we have in my mind and these facts align with empirical facts these features of the equilibrium align with empirical facts that we document trading fees are in fact brutally competitive it's as close to Birch Run competition as I've ever seen about 0.01 pennies uh per share to trade in the U.S stock market whereas speed technology fees are large and have been growing they're over a billion dollars per year have been growing rapidly we then study sub games in which there's innovation in which one or more exchanges adopts the Alternative Market design frequent batch auctions the first result is that if a single exchange adopts it actually wins share and earns profits in any equilibrium so we don't hit the traditional chicken and egg issues and getting a new platform off the ground and this is thanks to regulation that gets to a very efficient electronic search across venues so frictionless electronic search if we think about Michael ostrovsky's talk uh in the in the last session there are lots of of markets were searched across across platforms has has small frictions uh or or the the housing market this morning we saw we saw search frictions playing a key role um second result is that if multiple exchanges adopt frequent batch auctions then the the market design actually wins um uh tips the market but it's bad for the exchanges trading fees become brutally competitive again um and there's now but there's now no more speed rents so it's good for society but bad for private uh bad for private profits and then this leads to a third result which is there exists an equilibrium in which incumbent exchanges maintain the status quo Market design and the intuition is is something like cooperation in a reputed prisoners dilemma um there's some policy implications in this paper let me skip this slide and just mention policy progress uh which is the SEC recently proposed a form of auctions for the retail uh component of the U.S stock market I've written a detailed comment letter essentially saying why this is a sensible idea and I hope it will will also generate data that just shows the efficacy of auctions uh because I'd love to see auctions used in the in the on Exchange part of the of the stock market in addition to offer exchange retail Trading uh let me conclude so I this is just a recap of what I've just uh talked about so let me um let me skip this recap and instead just advertise three quick directions for future research so one is just keep doing the work of of inventing and analyzing new useful Market designs one great topic for research is is thinking about the optimal duration of financial markets how shang's done really Innovative uh work on on that topic something I've been working on with Crampton Kyle Lee and Malik is what we call it flow trading so building into the batch auctions idea the app the ability to directly trade arbitrary portfolios of assets with positive and negative real valued arbitrary positive and negative uh uh real valued weights this actually allows you to solve the correlation breakdown problem directly you could have a buy X cell wide portfolio preventing the prices from diverging uh in the first place and there's a lot of great work uh great topics for research um about about rents in the financial sector tomorrow it'll work on that second direction is measurement again please use the uh the code we've made publicly available to uh quantify high frequency trading issues and other asset classes and I'll make a quick science of science point which is that this is a big data style research project but very theoretical at heart and I think Theory and data are importantly complement complementary and that's something else that's come through uh in the last two days of sessions but I sometimes worry that economic theory is drifting away from data not uh not towards it and then the third issue for the third direction for future research this is kind of my question for uh for including myself for the old in the room is how to think about the political economy of Market design adoption this also came up a lot over the last couple of days um something I've been thinking about a lot let me let me quote there's first the Milton Friedman view which is just keep doing the work and wait for a crisis and I want to quote I want to quote also Al Roth and my my finance colleague Luigi's and dollars so Al wrote and The Economist as engineer we need to Foster an unfamiliar kind of literature and economics that facilitates bridge building from Theory to practice and Luigi's talked about we should get more involved in policy policy sometimes enjoys a lower status in our circles but if you can publish a paper that's got a profitable trading strategy and get academic professional credit for it why can't you get academic Professional Credit for for policy work and the point I want to make is that these changes seem especially important in cases where there's academic research where social value is large but where concentrated interests are opposed because when social and private line there's Natural Bridge Building from theoretical ideas to to practice and a lot of the past work and finance has this flavor but when when social interest and private profits diverge not only is there not the bridge building but sometimes there's actively Bridge uh Bridge bombing so in the end I'm an optimist but I wonder what we can do to speed up this transition from from Theory to practice uh thank you very much 