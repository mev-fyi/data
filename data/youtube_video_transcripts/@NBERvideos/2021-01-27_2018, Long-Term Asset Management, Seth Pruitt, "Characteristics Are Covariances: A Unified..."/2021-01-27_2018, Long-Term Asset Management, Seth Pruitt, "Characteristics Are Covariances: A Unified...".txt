Seth Pruitt: The question
that we're going to tackle today is very familiar; why do different assets earn
different average returns? Theoretically, the
answer is clear. They should be exposed differentially to
undiversifiable risks. But when we take our measures of those undiversifiable
risks to the data, we find a lot of anomalies. A lot of ways to differentiate assets
that lead to differences in average returns that aren't associated with the
risks we can measure. When we measure this, we have in mind a conditional linear factor model
of that form, where the excess
return at time t plus 1 is related possibly
to an Alpha, something you knew at time t, plus a Beta, some exposure you
also new at time t, times a realization of the systematic risk in the system. Asset pricing theory tests
really want to ask is Alpha 0 for all the assets
and all time periods. There are two broad
ways they we'll say the literature is
taken to test this theory. The first is to use what we'll
call observable factors. Let's sort stocks based on some observable characteristic, some observable
characteristic that's been associated with
average returns. Think SMB, HML, momentum,
something like that. That's one approach. The other is a purely
statistical factor and analytic approach. Ever since Chamberlain and Rothschild's '83 Econometrica, we know that the APT says that these aggregate
risk factors should be the factors that are
responsible for most of the common variation in
these stock returns, that's estimated that way. Now, when these techniques
are taken to the data, an identifying assumption
is that the loadings, the relationship of
the stock returns to the aggregate risk factors
is static over time. But we don't really believe that because in that observable
factor approach, we allow stocks to transition between the long and the
short end of these portfolios because stocks evolve over time with respect to the
characteristics we see. We combine this into a new procedure
called Instrumented Principal Components Analysis, trying to combine
those two approaches. It is a latent factor
model estimator that allows for time
varying loadings. The time variation in these
loadings are going to come from the data, the
observable characteristics. This is going to allow
us to ask and answer, an interesting generalization
of that important Gibbons, Ross, Shanken test question, are all the Alpha 0? That question has been
asked with respect to a particular measurements
of aggregate risk. We will ask that question
with respect to some set that we estimate
at the same time of common risk factors. Do some common risk factors
explain this anomaly, that anomaly, all the anomalies? What we find in the
data is that once we allow for 2, 2, or 4 factors, we find no evidence that characteristics
are generating Alpha. What we find is evidenced
that the characteristics tell us robust information
about expected returns, and it's coming via what they tell us about risk exposures, how they differ across assets, and how they differ over time. Nonetheless, we'll
consider a large set of characteristic
information and we'll ask, do we need that entire set? We will find no. We'll find that many
of the characteristics that we analyze are
statistically irrelevant, do not provide significant
new information relative to the other characteristics. To make these claims, here's the model I have in mind. The first is that factor model, where R is the excess return. All we do is we add one
equation to this model. It's an equation for the
loadings, the Betas. Beta_t minus 1 now equals
Z_t minus 1 times Gamma. Z_t minus 1 is this matrix of observable
asset characteristics. They are mapped to the risk exposures by
this Gamma parameter, which is constant across
assets and constant over time. We're tying ourselves
to an explanation of risk exposure that is coming
from observable data. The reason why we're doing
this as we want the model to have a chance to explain
the relationship, the previous literature is found between expected returns and characteristics via a
risk-based factor model. If the information
in characteristics lines up with expected
returns exactly in the way that those
risk exposures to aggregate risks look, then this more general
model is going to ascribe the impact of the
characteristics to Beta. It's going to estimate
non-zero elements in what I'm calling Gamma, Beta. That matrix. However, if the
characteristic tells me something about
future returns that is not associated with exposure to the sources of aggregate risk, then this more general
model will ascribe the impact of the
characteristics to an Alpha, to an intercept, and those elements of the
parameter vector Gamma, Alpha will be non-zero. That's going to form a
hypothesis test we'll run. Is that Gamma, Alpha
parameter vector 0 or not? We take those two equations, we drop them into a least-squares
objective function. I'm not going to talk
about that right now. I'm going to give you an idea of what this
estimator looks like. The solution to the objective
function looks like this. For each characteristic, run a cross-sectional regression
at each point in time of the returns in the cross-section on the lag characteristics. What you've just calculated is a return on a
characteristic-managed portfolio. Do that for all the
characteristics, call that XLT, every time period, every
characteristic put that together into a panel, this X. These are the returns on characteristic-managed
portfolios. Pull out the first K
principle components of X. You can see hopefully
the similarity and the difference vis-a-vis
principal components. Principal components
is going to pull out the factors that
are responsible for the common variation in returns. IPCA is going to pull out
the factors responsible for the common variation in the characteristic-managed
portfolios. The key parameter here is Gamma. It provides a tight link
between the factors we estimate to the
portfolios we form to estimate those factors to
the individual asset level. All of these are tied together. Therefore, to
estimate this model, I do not need to take
a stand on what are the proper test assets or the portfolios I should
bring to estimation. We bring to the estimation just individual
stock level data. The two hypothesis tests I'm going to talk about
in this presentation, the first is about anomalies. I'm going to ask, is Gamma, Alpha equal to 0? If it's not equal to 0, then there's some information realized before returns are realized that tell me about those future returns and are not associated with
risk exposure. That is what we'll
call an anomaly. But if I can accept
the hypothesis that Gamma Alpha is 0, then these characteristics
don't tell me anything about future returns that is not
risk exposure information. That's going to be our first hypothesis test. Second one. Once I think that these characteristics
are telling me about risk exposure, we thought a natural
question to ask is, do you need the entire zoo of characteristics that
we bring to the table? That question is going to boil down to a
question about one of the rows in this
Gamma, Beta matrix. Because if the jth
characteristic tells me nothing
about risk exposure, that's going to be translated
into the jth row of Gamma, Beta being zero because those characteristics move
cross-sectionally over time, but they don't tell
me anything about the Beta on the
aggregate risk factors. That'll be the other
hypothesis test that are present results for. The empirical findings
that I'm going to talk about is
monthly data from 1962-2014 on about
12,000 stocks. We focus on 36 characteristics that are very familiar; size, book-to-market, momentum of individual stocks,
profitability. In the paper, we analyze the different nature of the information coming
from the characteristics, what we call the unconditional coming from
the time-series average of a certain firms
characteristic and the conditional coming
from the deviation. I'm not really going to
talk about that here, but in essence, at the end, we're going to have
73 what we call instruments to describe data. The three statistics
I'm going to report. The first we've
already talked about. Actually, let me talk
about the third. The third are the p-values
of this Gamma, Alpha test. Can I accept the hypothesis that characteristics do not give
me anomalous information, information about future returns that's untied to
risk compensation. The other two things
that we think that a risk model should give is one, a description of the aggregate
risks in the economy, and two, a description of the compensation
for those risks. To measure that, I will first turn to
the total R-squared. That's the proportion of the variation in
individual stock returns that is coming from the aggregate risks
we're estimating. That's an important statistic. But even more important to the asset pricing
question is understanding the risk compensation
these stocks receive for being
loaded on that risk. That we're going to measure
by the predictive R-squared. We're going to measure what is the proportion of variation
and realized returns that's coming from the model implied conditional
expectations. In the general model,
if there's an Alpha, that's part of your
conditional expectation. There's a Beta, you knew
that ahead of time, your exposure to
risk, times a Lambda, which is just going
to be the risk premia associated with those aggregate risk factors we're estimating right there. Here are the benchmark results. What this is saying is that once we allow for three, four or five factors, aggregate risks, as
we measure them, account for about 20
percent of the variation in individual monthly
stock returns. What we also uncover is that the conditional
expectations, the compensation for bearing
this aggregate risk, explain about 2 percent of the variation in individual
monthly stock returns. You will notice that the model imposing the Gamma Alpha is zero or allowing
it to be non-zero, achieve essentially
the same risk of description that's going
to go hand-in-hand with this idea
that as soon as we estimate a multidimensional
aggregate risk space, that is, once we allow
for two or more factors, we can accept the hypothesis
that there are no Alphas. We can accept the hypothesis, the characteristics matter, but only with respect
to what they're telling us about risk exposures. Now, are these results good? I don't know. Let's compare
them to alternatives. The alternatives I'm
going to have in mind are principal components or
observable factor models. I'm going to use the
Fama-French Five. I'm going to add
momentum. How do they do? We know that the
Fama-French Five Model gives us small Alphas. Are these numbers good? Furthermore, did I introduce
a lot of parameters? Was I hiding something about
how many parameters I'm estimating here to get that good performance
if it is good? It is good. Let's look
at the comparison. When I compare what the IPCA, our model is telling us
about aggregate risks, to what Fama-French
Carhart models tell us, they agree in terms of how much aggregate risk there
is in these stock returns. About 20 percent of
the variation in individual monthly stock returns is coming from aggregate risk. These observable factor
models have needed to estimate almost 20 times more
parameters to get there. Why? Because if you have 11,452 stocks and you
estimate the CAPM, you need to estimate
11,452 parameters. If you estimate
the Carhart model, you need to estimate
45,808 parameters. One for every stock.
We don't have that. We don't have asset
specific loadings. We just have that
mapping matrix, that Gamma matrix between
characteristics that are data and the risk exposures
that we're using. Nonetheless, even
though we estimate about 6 percent
of the parameters that observable factor
models estimate, our depiction of conditional
expected returns are far more accurate. Once again, in this
matched subsample, the conditional expectations that we're estimating explain about 2 percent of the
variation in realized returns. If I use the Fama-French
Carhart model, I explain less than a third of a percent on the basis of those conditional expectations. We take this as suggestive as evidence of an idea
that we are better capturing the risk
exposures that the panel of stocks face. If that's true, what
we've also done is better estimated
systematic risks. One way to test for that or measure that
would be to ask, how close is the
aggregate risk space we estimate to the mean
variance efficient frontier? One way to measure that is to ask what's
the Sharpe ratio of the tangency
portfolio associated with the systematic
risks we are estimating? The out-of-sample
Sharpe ratio on, say, our four factors is 2.6. That compares to the Fama-French
Five Factor Model plus momentum achieving
and out-of-sample Sharpe ratio of 1.4. We take this as strong
suggestive evidence that we are better estimating
the aggregate risks in the economy because
the factor space that we estimate appears more closer to the mean variance
efficient frontier as measured by the tangency
portfolio Sharpe ratio. Finally, this model gives us a means of understanding many characteristics
all at the same time. There is a famous, well-known, at least to me, statement that John
Cochrane gave in his presidential address about a factor zoo or zoo of factors. When he's talking
about the factor zoo, he's talking about
these different ways to slice and dice assets based on observable characteristics
that give you all these differences
in average returns. He asked, "Do we need
the entire zoo?" We don't think you need
every monkey in the zoo. Only eight of the
characteristics of the 36 characteristics that we look at are significant
at the 5 percent level. There are return based
characteristics, there are the market Beta, and there are size,
either measured by market cap or book assets. If we restrict the
model to only use these eight pieces of
information about every stock, we find very little degradation of the model performance in terms of those two R
squared I talked about in terms of what it's telling
me about aggregate risk, that riskiness of stocks, and what it's telling me about individual stock's
risk exposures. On this basis, we would say that most characteristics are irrelevant when you're able to properly evaluate that
statement jointly. In the paper, I'll just flag a number of extensions
that we have, some robustness
checks we also have. I'll highlight that we analyze whether or
not this is all in small stocks versus large stocks because we have this large
panel for stock returns, it appears that the
predictability and the explanation of the riskiness is very similar
across those two. Maybe more pertinent
to this conference is an idea that when we
look at annual returns, some more characteristics
do pop up as significant. There is some scope for
using this model for longer-term returns and thinking about longer-term
asset management. I will note perhaps
as a digression, that a nice feature
of this model, because I'm selling
it right now, is that you can estimate
this Gamma matrix, this mapping between
observable characteristics and risk exposure on
stocks over here, and then bring another stock in that has some
characteristics associated. You can just apply that Gamma over here and get a
cost of capital for that new firm without a long time-series of
returns for that new firm. That in the paper allows for
some interesting, I think, cross-validation exercises where we estimate Gamma on
the large stocks, use it to estimate
Gamma on the small. But let me conclude. What we've done is
we've come up with a new latent factor estimator called Instrumented
Principal Components. It handles dynamic asset
pricing models very easily. I did not talk about
how you compute it. You iterate on regressions. It converges within
seconds. It's very quick. The empirical model
performance is outstanding vis-a-vis the well-known
alternatives using the Fama-French Carhart
Model principal components. I didn't even talk really
about principal components because its depiction
of risk compensation, expected returns is so abysmal. The empirical facts
that we find on this large panel of stock
data by 1.4 million stock month observations,
is that once you allow for a multi-dimensional
aggregate risk space, it appears as though there are no anomalies in the
cross-section of stocks. Yes, characteristics are telling us important
information. The information they're telling us is about risk exposure, how that varies across stocks, how it varies across time. 