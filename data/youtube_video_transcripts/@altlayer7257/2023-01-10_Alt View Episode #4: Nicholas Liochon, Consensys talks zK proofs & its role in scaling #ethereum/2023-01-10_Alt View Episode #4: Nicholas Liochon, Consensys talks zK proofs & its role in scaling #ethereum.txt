[Music] thank you hello everyone Welcome to our alternative view of Simply auto view at all view we chat with industry leaders to get to know them their opinions and also insights uh meanwhile we want to hear about their popular and popular brand new or alternative views or anything in between yeah I'm your host Yoshi from earlier and elastic execution layer on ethereum for what three and today is our great honor to have our guest Nicolas he's working with consensus and the mainly leading the team to deliver the Eco to deliver the DK evm at the consensus which is sort of like an EDM equivalent Zola to ethereum so yeah then uh Nicholas can you tell us more about yourself and what kind of stuff you're working on at the moment yes hello everyone thanks for having me so I'm Nicola YouTube I'm responsible for R1 that consensus which is actually an applied research team uh responsibility is to solve or contribute solving the problems that are on the bus up with web free world that's basically our mission and we work actually on many different topics uh the ethereum protocol itself where we contributed for example a lot to proof of stack and to the and to the merge we work as well on Bridges and Christians and question is can we make with this safe what should be done how can we make things better we work a lot as well on formal meet us we work for example on formally verifying the data on protocol which is something that we're doing with the term foundation so we notify properties and we prove that the properties are met or not met with work as well on formal methods on the smart contract verification we want to make smart contracts safer so we have a team that is identifying all the different ways of moving smart contracts giving tools to developers so they will be able to write better smartphone packs so this is a work in progress but we hope to have very interesting results soon and we contributed recently actually the evm specification in Daphne so it can be used as a tool to verify the quietness of exertion at the biker level we worked as well on cryptography and we're getting closer to Roll-Ups when we when I'm saying this on cryptography we contribute to a library called that allows you to write uh zero knowledge circuits in go and this Library comes with a library that you can use directly for highly uh efficient uh cryptographic functions that you can call directly around curves bearings and so on so this is something that we do as well and we have a lot of activity on roll ups about the scalability where we have a team working on the arithmetization and the team working on the product part of develops so that's what we're doing in r d but on myself I come from distributed systems I did a master on networking and distributed systems quite a while ago I even work on financial systems and then a Big Data Systems I contributed a lot of code to Hadoop and big data for people who are important enough to to know what it is and I joined consensus at the very beginning of 2018 to participate to about it I am too how it was called like this and we notified that we quickly that hollabs were a solution for scalability from basically I'm working on roll up since the beginning of 2019 as we believed that it was the solution I see it sounds amazing I I can and I can sense that you have a lot of experience in like applied crypto and also distribute the system right and uh can you like you some simple words to explain what's zero knowledge proof and why we need zero knowledge like for scaling ethereum yes so I mean with zero technology is a kind of magic thing which is you can prove that you know something and you don't have to reveal it and simple example is uh you can know that you know the gray image of Ash like why you have a function of y equals as the x of X and you say oh I can prove that I know X but I won't reveal X okay that's a that's a nice story and actually foreign uh if you know if you can go back to normal pass you can actually prove it to another state and if you can prove that you know State you can prove that you know about the stat charge and actually multiple search changes and you can prove as well that was a state change was driven by the contents of another part of the states but we can prove as well and this other part of the state is basically a problem so from this small tool which is I can I can prove that I know something you can prove actually execution just by building on it and by itself it seems a little bit useless but the point is the schemes that we have for zero knowledge have some very interesting properties and this thing that we call snack stands for Success which means that the proof is actually very small and can actually be constant size of few hundred percent by for some skins that's a very good feature because we can prove something that is very big with a very small statement so maybe your state it's 10 gigabytes of data plus that but it's going to be 100 bytes uh second thing is still unstuck the n stands for non-interactive it means that you can verify your state asynchronously without having to discuss to speak to the proverb part okay you receive a profile alone you're going to verify your proof without having to connect to any piece of software where proof will stand forever okay so what we're saying is you can prove a complicated execution that will require uh possibly gigabytes of data in basically a few milliseconds on an isolated computer uh with both sides of one of our bytes and the point of this is linked to ethereum I mean you add this story uh basically five years ago actually when I joined people were saying oh I'm going to deliver faster because I've got a faster consultious protocol and people will say oh my fast consensus Portugal and so fast yeah okay it's so fast but the point of it's the execution part the fact that the state is very big and the fact that as we don't trust the miner we are going to re-execute the transactions in order to check that the execution is called and you just take this uh proof instead of by executing all the transactions and you don't need the State anymore and verifying the correctness of the execution takes verifying this proof in a few milliseconds wider than uh receiving gigabytes of data and re-executing all the transactions one by one so that's why it's quite key uh we can basically solve the scalability problem of ethereum if we can replace the re-execution by the verification of a proof yeah I got it like so in Defcon right I know your team basically talk about the ZTE VM work consensus right can you share a little bit like about the definition of ziki evm in your opinion and meanwhile like what kind of the current progress of the zkebm Persia you know team yeah so we have a I will say a strict definition of a caveat which is a CK evm is a ZK VM but takes as input uh dbm by cloud natively uh and it means with this definition that you can reuse existing by code existing tools and it's gonna work and uh that's that's valuable the good definition of physical now you've got some pain points like you put ketchak and ketchak is used all over the place uh in the term if you take the Leisure paper you have the op code track but as well the block itself is calculated with the Ash and the block hash function and the state is represented over Patricia Michael tree that is using a circular power place so if we want to take a full yellow pepper which will represent the state with ketchek and and that's it we have performance issues when we do that yes for the West so far you have a good moving time if you can check so we do have what Vitali calls the type 2 ZK VM which is the state is represented differently and the only reason for this is performances and when you do this you basically have a different function and a slightly different state representation I still consider this as the zkvm because the change is mostly invisible for our smart contract now the few things that we leak but it's mostly visible I still think however that in the future the L1 and the L2 will be able to represent the state in the same way and there are some working parts a great time foundation in order to change with static representation a key point of this definition and basically why we need this definition is uh the link to decentralization the fact that we have exactly the same specification as the layer 1 specification and that you can have multiple independency KVM representing uh the bicode using exactly the same bycodes means for a smartphone developer that we can move Layer Two and that you can move from the layer 2 to layer one if you're not happy at the point but as well uh and we're coming from this data uh to world is you can take the layer one smartphone fraction you can move them to the layer of two uh so you will have this scalability improvements uh without having to do an audits uh or new bugs or new things like this so that's why we think of the ZK VM in uh I would say type 1 or type 2 are very important for the scalability of it around and then for this decentralization because we can have multiple providers I see and uh yeah I think this definition is very useful and helpful for us to understand these um like the difference across different projects right and at the same time can you share a little bit about the current progress about the implementation or also about the design uh on your team for this uh evm development part yeah so when you build a zkvm you have a quite a lot of challenges and at the end of it there we are going to be very summarize in a single challenge uh you basically have two components you've got this arithmetization which is uh transforming the evm specification in the yellow paper into a set of constraints on execution classes table logic is you have execution generate stresses and we can prove that the only value choices will correspond to the execution of a smartphone plug that you asked for and this is incredibly complicated because if you have is complicated uh historically it has been complicated there are many things that are a little bit strange and it's very complicated as well because you want it to work in a CK logic which adds a lot of complexity uh so as a first component the second component is the program is going to prove that the constraints are satisfied so you don't need to run the you don't need to receive execution presses and to run the constraints by yourself you have a proof I have a choices and your choices are satisfying the constraints so you the proof is enough uh to Progressive execution and this is as well complicated but but the main point is probably about being fast uh because if you can you can write a perfect arithmetization and the perfect over but if you need 10 minutes to prove a single transaction you're not exactly solving the scalability poly movies and you can say yeah we can have a thousands or thousands of computers but okay it's just gonna be incredibly expensive and that's one of the challenge is the challenge is to solve those two problems in a very efficient way uh to us a reasonable Target is to be at the beginning at 50 TPS uh on one another machine you have a one overcome machine to generate the proof and you can do that L1 Block in uh 12 seconds that's our targets we're not exactly there but we think that will be there that's something that we are that we want to achieve and we want to achieve more than this as well that's uh that's the first point uh so we published actually a specification about meditation a year ago trust 50 pages or one something like this we published a new specification just before difficult it's 250 Pages now the art museum I think will be finished it will be have around 300 pages and it's really it contains everything it contains it contains everything about the arithmetization it says it describes the wall light meditation and why it is done like this so we have an explanation of why we did this type of choices so it's probably something that I encourage people to have a look at uh basically if you find about here it's uh it's critical so we found a few bugs since the publication so there are features well we found some improvements as well uh so obviously you published a newer an updated specification uh but it's probably something in terms of status that we think is important to have this shared specification that again it's 1250 pages so it's not exactly uh 10 minutes uh 10 minutes work uh but it's there I think it's quite important that it's well with the ideas that we have around uh how to get a fast power so a new things that are not done externally I mean that never seen them mentioned that I'm warmed and so it should be enticing for it but it's a matter of days uh it could definitely be done from this podcast but it's just a little bit late uh uh and that's the two components and then we will build from this unbelievable things uh always will be visible in the test net we announced it at Defcon actually we had a form that was closed and we're going to reopen it again soon and the idea of a test net is you can deploy protocols you can deploy smartphone facts you can call whatever you want so it's uh I unwash people as well to have a look at it and we can't deploy because we want to deploy we won't be at 100 coverage we will have something for example we don't have a python files yet it's something that will come later uh but we actually have a quite big piece of the system so it should be uh quite interesting to see yeah sounds great and I think like as you mentioned right for the a few hundred pages of uh of the like sort of specifications that definitely can be the standard of a lot of these um uh zika evm implementations I mean well I think people are very excited about the test net and especially later if we reopen it again and I think definitely there will be a lot of like community members who like to participate in the test night and try out what's like sort of the zkevm like you know and uh yeah on the other side as you know right uh for uh for the like for any of these DK proof like sort of protocols we always need uh sort of approvers to generate uh like to generate the the ZK proofs right um like in your opinion do you think like decentralization is also very important for ZTE VM and the meanwhile how you feel like we can decentralize the approvers in the near future yeah so I mean this optimization is key if you don't care about decentralization if you're happy with the centralized system you can run a system on Amazon Einstein so just do that so if you're using this type of system it means that digital transition is important and if you run a centralized system again that's fine if you what you need but in our world it means basically calling for FTX to happen again we should not have costed FTX and if we trust centralized ZK VMS or ZK whatever we will have exactly the same thing um we should not cost basically even operators including ourselves and the key point to me it's really related to speed that's why I'm really sitting on this these people who are using FTX because well if you want something but it's cheap and fast you need this type of centralized solutions to them so some politicization is decent solution is key but in order to get it we need to have very fast over 100 ship Proverbs all of this and then people it will always be a little bit more expensive than using a single server on a single Amazon instance yes but it should be cheap enough so people can without sacrifying too much Financial money uh use this type of system so I I think this authorization to me it's valuable being efficient and being fast and vitalik mentioned a target of five cents per transaction I think it's it's a good Target that's why we should go you know it's important so anyone can force the inclusion of a transaction not only uh compose a transaction but circuit you're going to execute this so that's basically this entire sequencer having multiple C concerns without any elimination 20 I think it's something very important and it's exactly the same with our program anyone should be able to run a program and to get some fees out of this uh it's not actually that difficult there are multiple different ways of doing this and the hard part is actually when you want to split the sequencer and the problem how are you going to show the fees um if you let one decide whether we'll have nothing so you basically want to create a kind of markets saying if I execute this transvest service uh this batch of transactions I'm getting this amount of fees and this is possible but it becomes a little bit complicated you don't want to organize the market that will take 10 minutes to uh to reach the optimal to uh just to decide on the price for one batch you need something related it's a more efficient than this so that's why the pen point is uh but I think it's I see it more as an optimization issue than a real issue like we just can open the system so the first move is accepted and uh and the fees won't be perfect but it may be good enough for a while and something that can be done in the future so I think that now that we made a lot of progression programs uh separating the program is going to be uh under sequencer is going to be the the next agreement Point uh shoot upon in the next quarters I expect yeah I see so um as you just mentioned right we can set up some Marketplace like for the Proverbs and to generate sort of the proofs right and uh um I I are there any other potential ways to also speed up like sort of the ZK proof generation yeah serving that so many ways in a way you can try to use Hardware gpus fpga and that's kind of obvious solution um we should not forget that the eye medication has an impact of the performances if you do a bad arithmetization basically you will have too many things to check to check and it will be incredibly complicated as well so your augmentation is really a point that should be taken into account and as well the scheme itself uh we're doing complicated things we compiles one of them and adding an optimal scheme is something that has actually value so the way I see it there are still a lot of work to do on arithmetization unproving scheme itself and then we can Target the hardware uh hpga being a reasonable solution but I will send on my end I'm not sure when we'll see okay now we have done all recruit on the scheme we really need to go on fpga I'm sure that we're not there yet maybe we'll be there in one year I don't know maybe one year to four years I would say but that's really this Gap the improvements that we can do at the scheme level are quite true I think it's quite important to see this and it's interesting to have a global view because the argumentization impacts recover which impacts our skin which impacts basically the other implementation you really have always dimensions and your Global understanding is actually important as well you have something that are easy to implement on Hardware but you can't really have them efficiently it's complicated to having a program for example so you want to uh you want to select the scheme that will go well on the hardware as well so that will be the challenge for next that's how I see it yeah go there so I it's quite tough to have some bad phrase okay roll up implementations um because as in you know right just for a few lines of code for the proof probably we can have over 30 000 line lines of the circuit circuits like sort of code um but in your opinion what what are the matters we can apply to reduce or eliminate these bugs I mean probably existing in the ZK roll up implementations yeah so I mean vitalik is totally right uh and it's not only doing implementation it's as well with specification I mean again our specifications there's no way that we don't have bugs I mean it's just impossible and it's even worse than this is even if it's audited and we are we're very happy about very proud of the specification we've done our best but okay there will be some Mis misses and probably to improve that the specification is platform it will help it will likely find works but movie Life works well so audits are useful but for something as complicated it's not enough uh we do have other tools like for example we run the reference unit test as well I mean we the fact that it's a pvm means that we can we use a lot of existing contents so we're running uh reference units test we're running on mainnet as well so we're trying to prove uh all the mainnet blocks but this does not prove that we can't create the effect we prove that we can create proofs for everything but we are not proving that we can create effective which is an incredibly big issue uh forward verification should help and I do expect that it will help to make a difference as well and we do have teams working on this circumstances so they will definitely help us and we will still have implementation issues and even with our verification I think with a few properties will be verified so that's why I'm in vitalik solution which is you need multiple Proverbs I think it's a very very good solution uh to me uh that's resolution and it's interesting because it means that the teams should have different arithmetization different proverbs but actually different address but at the end of the day if we want to change the state of the roll up we need multiple proofs Converse multiple implementation and with this great ID that you even you don't need all of them but the super majority will be useful like if you can have a proof you have four systems and three of them are validating the updates with a proof then you can move on I think it's a very very good solution so it serves a lot of points it serves a lot of points as well because uh issues with Audits and careful reading and time proven Technologies is that what happens if you change something like you need to make it a little bit faster you need to add an opcode and your audit is not valid anymore so even if you do if you did a lot of work in the past that's not useful why if you have multiple systems running concurrently to prove the same roll up uh you really need a bug to be in all four words in order to have a big issue so it's not only it makes the system safer it makes also the system easier to change you don't need anymore to do a six months audit after each change or to say something like okay trust me the audit is two years old and I've done uh 2000 changes but uh we think it's fine it cannot be fine with something that's complicated so it's oiliverse solution so to me if we want to be able to have a flexible system uh that is safe that's where we should go and life that's our responsibility as all up uh zkvm implementers to get basically if it's done uh it's not simple uh typically as explaining the states we don't have the same state representation between all the ZK VMS and here we modelers need to have an argument uh so there's some stuff to be done uh but I think it should be done and we will try to to get it done as much as we can that's uh I will say why we want to uh to make the system better yeah I believe so like basically you are the expert like uh in the like formal verification and also being in this space for a long time I believe I know so I definitely will apply a bunch of these measures to try to figure out these bags and to fix this box right and uh yeah on the other side like what are the remaining social open problems for zkevm and uh like how can researchers or developers like us help you guys to solve these issues okay so I think well one big issue on our multiple small ones um typically I mean getting 100 coverage of the evm up card is difficult uh and when you run the unit test uh you usually see that it's not actually like you wanted it to be at this point on our hand we have no involves actually on the reference streets uh quite part of it and it took us quite a lot of time to get there we don't have yet 100 coverage so we still have a few things to do but on everything that we have done so far uh we're fully compliance so I think it's not an open pool anymore it's something complicated but not uh open anymore I think uh the real stuff is Hollywood performances and how to get good performances again to me we should be able to put one layer one batch in one second on a reasonable Hardware that's really where we should be and there are many things to do there how can you have faster pre-compiles how much data do you need to do this that's a lot of cryptographic oriented problems uh for seven problem which is still open is how can we have type 1 gke VMS again at a reasonable Hardware cost and we know that there would be some changes and one specifications uh and we need to get them white we need to be sure that the changes will allow us to have this fast layer to implementation yeah a lot of times yeah exactly and it's going to happen as we need to get it right yeah we don't have to write the layer one to have a better layer too and hopefully when people won't let us do it which is very good uh so it's going to take time to find the solution so that's why we need to find the right solution and to be sure that we're not missing anything uh because that's the key point to to have a free decentralized system yeah yeah that's true I mean well to the last question right so as you know we are doing is um like alternative views right do you have any like sort of non-mainstream advice for our audience yeah I do have one I think it's a kind of a don't trust to verify unfortunately it's uh it's not mainstream at this point I mean we saw that with FTX and uh I think that's what we should be doing for this uh for this system as well uh we're building the system there's a circuits don't trust it to verify you have a specification that's uh don't trust that as a single operator we are the only one to be able to update the system and we won't do anything bad I think it's don't trust us on that the system should allow anyone to submit the proof and should in a trustable way that's our that's our seats yeah especially for us right we're building some like sort of brand new technologies right and basically we I think the only way for us to uh to trust is really to do the verification like on some new technologies yeah I see there's no much reference we can really refer to yeah exactly yeah thanks a lot Nicolas I believe it's a really like great conversation with you and uh yeah to the audience right uh thanks for your listening and as you know our views basically we are inviting all the sort of um industry leaders and especially the technical leaders to share about the industry and also learn to scability topics and uh yeah thanks for your attention and we sort of signing off to the next time [Music] foreign 