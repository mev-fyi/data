so um so everybody uh welcome to our cornell city uh financial data science seminar and i'm really excited to have laura leal today who is uh going to talk about learning a functional control for high frequency finance so uh laura is a last year phd student at um at princeton and uh and yeah i've been following her work with a lot of attention and and she has some very novel uh approaches that uh i'm sure you all will be excited to hear so uh just um as questions pop up please put them in the q a um or the chat room and then i'll uh you know as i see fit i'll either you know ask them in the middle if it's a very sort of timely question or i'll keep it for the end if it's a more general question so so laura great to have you and floor is yours thank you sasha and thanks for the very generous introduction uh so thanks for coming everyone today i'll be presenting first paper on my thesis which is learning functional control for high frequency finance and here uh this is joint work with matthias and charlotte which are both great co-authors so um just okay so this in this stock we have a trader and they want to either buy or sell a very large amount of stocks in a certain amount of time of course if they do it all at the same time like let's dump it in the market they'll they'll make huge losses for the firm and they'll be fired next day and probably the sec was what's going to come after them so we need to solve this problem in a in a better way than just dumping that creates the necessity of an optimal execution problem so we don't want to have that large market impact we want to be as smooth as possible in terms of being stealth so we want to not be identified when we trade especially because other players are going to trade against us so we solve this problem using deep neural networks and the idea here is that we have a stochastic optimization problem it's usually solved by a pde method so we find first order conditions which have a closed solution for very specific parameters which make the problem solvable and once we get rid of these all of these assumptions we can no longer solve them but with the neural network we can so we make the problem more realistic and we want to create an approximation to the solution that is still something that the agent can use to trade the problem with neural networks is always that people say oh well it's a black box how how am i going to explain this to a client do i have to set margin for it so here we provide the idea of explainability so it's going beyond model distillation in the sense that once we explain the neural network we're not going to use the distilled model so we're not going to use the simple version of the model we're still going to use the neural network solution to trade the difference here is that we'll understand better the risk that this new solution is bringing so we have this idea of projecting the neural network control onto a lower dimensional manifold or a simpler space that on which the known solution lies and we want to know how far away this neural network solution is from from what everyone is used to so by everyone i mean risk sectors regulators everyone should be very comfortable with using neural networks for trading and then we of course we want to know are we actually improving our performance so we look at the value function the wealth marked market and of course the relative errors in our projections and okay so we propose the neural network solution which we benchmark against the classic closed form pde solution and then we notice that the neural network can give us so much more in terms of more realistic execution schemes and so we improve um on the type of data characteristics that we can use for example uh sometimes high frequency data has some auto correlation the neural network can learn that of course financial data has heavy tails it has intraday seasonality so the neural network can react to all of that while the pd solution really has a hard time doing it um the only problem with the neural network solution is that neural network takes a long time to run so while the pd does not dislike that second so the way we solve this problem is by proposing a multi-preference controller what this means is that the neural network's not only going to take as inputs the usual time and state variables it's also going to take as inputs the risk preferences of the agents so if a new day starts you do not have to wake up at 4 00 am to train your neural network to adapt to the new [Music] risk aversion parameters of the agent of that specific date instead you have trained on many sets of parameters and once you you have a new day coming in you just use that as input to the network and you're good to go so the outline for the presentation uh i'll quickly go through the literatures we're in the intersection of a lot of different branches so i'll skim through then i'll for those not as familiar with the optimum execution model i'll explain the structure of this model in some detail and then explain how the neural network control works numerical results in terms of explainability and all the performances and finally the conclusion so we're in the intersection of of course optimal execution which is where the motivation for our problem comes from but we also draw from more general uh literatures in learning reinforcement learning and deep learning techniques and i want to give a huge shout out to the deep learning techniques here because their seminal papers they they represent approximations to pd's and we took inspiration from that to instead of approximately approximating the pdes which are the first order conditions for our problem we'll be approximating one level up so we'll be directly approximating the solution to the stochastic optimization problem so once given an objective function and dynamics we don't need to derive a pde we don't need to derive anything from that the neural network will directly learn the solution given the structure of the problem and then if you're a trader you only need to your only task is then to well am i defining the problem in a correct manner once you do that everything else is solved free okay so the optimal execution model is the following so you want to either buy or sell so you're one directional but of course during the day if the opportunity is good you can go the other way so if you're buying you can be selling for a little while if it's profitable otherwise you just go one direction so here we do not impose that the the trader should go in only one direction although you could include this constraint because some some firms have this mandate so as for state variables we have the inventory so here you'll notice that i'm writing it in discrete time i'll write it in continuous time soon to show the closed form for the pd but for now bear with me so we have the control which is the speed of trading and so here this means for a given time step let's say five minutes uh if i trade faster i'm going to accumulate inventory faster and then i have the price so i just want to make one remark here this is a time differentiable function uh in a subsequent paper with professor carmona as i was telling sasha we actually proposed that we should include a brownian component here based on looking at the data so the price process uh evolves in the following week so we have a drift component that is affected by the speed of trading of the agent so by the control and this generates a permanent market impact on the price so the faster you're trading here let's say you're buying you're pushing the price up and we have um the fusion components uh that in this case we're just considering it to be uh like monte carlo generated increments but we'll see later that when using real data this doesn't have to follow this structure of having normal zero one noise or we don't we don't need any assumptions on this diffusion term finally the wealth it's a little bit a little more convoluted so the wealth will evolve according to the speed of trading but in a quadratic form and it so the intuition here is that we're pushing the the amount that we have to pay the faster we trade so let's say we're trading super fast here from starting from our midpoint we'll be having the effect of crossing the spread and the faster we trade the more liquidity we're going to consume on the other side of the book so we're going to be pushing our price uh to one of the sides so if you're buying you're gonna be pushing the price that you're gonna pay up and therefore you're gonna have temporary market impact on on the limit order book so this assumes that we only have market orders this this does not take into account limit orders okay so as you can see like the faster you trade the more you're going to have to pay to execute that trade so ideally you don't want to trade super fast but if your mandate is to trade very in a very small amount of time then you will need to pay that price so our objective criterion to minimize it depends on the control so of course that's the speed of trading and it has a terminal component and a so terminal component and a running cost component so the terminal cost we can break down in three parts so the final wealth that's in cash plus um how much we can sell our final inventory for and here we're assuming that we can execute everything at the last moment let's say in the final auction and we have a penalty for holding inventory so this is here because we want to make sure that the agent once strongly wants to execute by the end of the day so if they're not penalized they'll just keep it for the next day and this is controlled by both a risk aversion parameter a and by gamma which um which i'll explain later how it comes in but keep in mind that gamma is very important for our neural network solution and finally the running costs it's a penalty for holding inventory throughout the day so instead of being able to wait until the very last minute to execute given a risk version parameter gamma sorry phi the agent needs to be executing throughout the day and these two parameters a and phi they're very important for risk management because they will accelerate or they will slow down the execution of the order so this is something that is based on on the personal preference of the firm and we while we don't have that information explicitly we can have a range of these parameters uh to train on so this is what we do we we set a range of pairs a and phi and we're going to train the neural network for all of these and going back to gamma so usually in the literature gamma is taken equal to two so this would give us a quadratic objective function and this would be very close to a linear quadratic problem if we set gamma to a more realistic parameter we can no longer solve it in closed form and that's where the neural network comes in because neural network can learn uh this approximation with birmingham and of course we're looking for optimal control which outputs how much we should be trading at at each time t starting from the beginning of the day until the end of the trading period okay so here we have looked at the discrete time problem we are going to benchmark it against the continuous time solution and in the discretized form so in a continuous time model we have the same structure so the same objective same dynamics but here of course everything is in continuous time so we have the integral and we have the s the q the x and our value function we want to maximize for our control this is easily solvable so the first order condition is a hemotone jacobi belmont equation with terminal terminal condition written here and of course we want to maximize it for the control if we assume gamma equals to 2 we can solve this equation by by setting nsats so we assume that the value function has some quadratic term on the inventory and that is that is an enhanced that comes from our objective function since it's quadratic we set this n sets as competitive as well so the important thing to remember here is that once we solve this problem we have an optimal control that is a linear function of the inventory right so we have an intercept term and a slope term times the inventory function so here we're only depending on one state variable for the control and we can solve this sys this this problem by solving the ode system so this is a ricardi equation this is a simple ode and it's very easy to solve but the important thing i want you to remember is we have the optimal control as a linear function of the intensity okay so how is the equivalent solution when using a neural metric so here we have the same problem but instead of having to optimize for the control mu we have to choose the parameters of the neural network so we have to choose theta and theta are weights and biases if you imagine a deep neural network we have to choose all the weights and biases for this network so i'm not going to go into the details of the implementation i'll be happy to go over them later if someone is interested uh but we use a stochastic optimization algorithm to update um the cost function at the loss function at each uh trading day so the way it works is that the neural network we use the same network for all the time steps so the network is learning at each time step but also for the whole trading day so it's going to learn all the time steps as inputs and it's going to learn how to react to that based on what it's seeing in the state variable so in the price and the inventory and the wealth of the agent so i'll leave the details for those interested in the questions um but i'll explain really fast so we use a feed forward uh fully connected neurometric so this is a simple structure and we use as inputs time and inventory and the reason why we're using these inputs is coming from the agb solution so the the classic solution they they uh have the control as a function of time and the inventory so we're like well let's try the neural network with this first and but this can be generalized in many ways so we can have time we can have inventory we can have the wealth we can have the price you can have many inputs but what we use here in the sequence is the risk preference parameters as i said before this is a way to avoid retraining the neural network every day so we can learn from the risk preference values so if you look at this structure it's not very deep right so it's not an extremely deep neural network with hundreds of layers but it is recurrent and it's not recurrent as an rnn so it's recurrent in the sense that we reuse the same structure at each time step so when we update the weights it's actually updating for all the time steps at the same time so here's what it looks like uh in figure two which should be the first one actually uh in figure two we have so we have the time and the inventory being input to the network which is going to output the control so the control is a function of time and inventory here and this control is going to be then input to the dynamics of the problem so we're going to generate the next step in in state variables and we're going to repeat this until the end of the trading day so figure 1 shows the structure of one step so we have time and inventory go into the control the neural network outputs this control so the neural network is the control it outputs for each time step a certain amount of stocks to trade and these go into the dynamics of the problem to output uh the next state variables okay so how do we train this network how do we generate sample paths for this ideally we just get data and plug it into the network but financial data is extremely expensive as you're probably all familiar with or it's too sparse so what we do instead is use transfer learning we don't want to waste all our data on the amount of training needed for the neural network so what we do is we simulate data using monte carlo but this data of course is based on the real data that we have so we estimate parameters from the real data to generate the simulated data so with that data we generate a first approximation of the neural network and then we continue the training unreal data just so we have uh fine-tuning of the model okay so the data we're actually using here is from turn on to stock exchange we have it from january 2008 to december 2009 it's a lot of trading days we actually uh tested for different time periods and the result is the same so the structure of the data is the same and we have 19 stocks but here i'm only going to show one of them so the data is in microseconds but it's asynchronous meaning that at each trade we have the information and trades don't happen at interval times so in this particular case since we're interested in risk control and not so much in how to place an order in the limit order book we're going to aggregate the trading days into 78 pins or five minutes okay so again why are we using the neural network so this is the data we're using uh here's a qq plot showing that the data has heavy tails therefore we we should not be using um the the brownian motion normal zero one generated uh diffusion terms um second one is autocorrelation so since we're dealing with uh high frequency data um the traders that are executing they're going to be pushing in one direction so we might see lags that that have autocorrelation in this data and finally the most important one uh which is intraday seasonality so if you've ever looked at intraday data we have this very classic u-shaped curve for both the spread and the volume and also the volatility so if if the spread is larger of course you're going to have to cross the book further so you're going to have a lot more market impact when you trade at the same time if you have more volume you're going to have less impact on that same limit order book so keep in mind like the more the higher the spread the more you're going to have impact and the higher the volume the less impact you're going to have so as numerical results i'll explain the idea of explainability to explain explain uh so we have trained the neural network to find the optimal control we're actually finding the parameters theta but what does mutator do right so this is a crucial question uh that we should address if we want to have the neural networks being used so as a reminder i'm going back to the the optimal control for gamma equals two we have this shape that mu star is a linear function of the inventory q so the idea is that we're going to project the control obtained by the neural network onto the space of linear functions of q and of course if you have a different problem set up you might want to project it onto more generally the linear space of the functions of all the state variables for example but here we're drawing inspiration from this result so we only project on linear functions of q and the idea of projection is simple so we use linear regression and we want to find these beta1 and beta2 terms and the important part here is the r squared so how much of our non-linear functions of our neural network can be projected onto the space of closed form controls so how much are we um how much is our function linear or non-linear you can put it like that so how much can we explain of this great variability so here are the first results so on the top left we have h1 which since we don't consider mean field uh term it's only going to be zero all the time and then h2 which so just as a reminder this is the term we're looking at the r squared so here we have everything very close to 1 but i wanted to show that it's not perfectly one except for the stylized closed form which of course is perfectly linear and finally the control process new so here what are we looking at so in blue we have the stylized closed forum which is the benchmark so this is coming from the pde solution and then we compare the neural network on simulations meaning we assume everything that the classic fose farm assumes in terms of um brownian motions are are normal zero one generated uh we don't have seasonality we don't have real data so this is a benchmark and as a benchmark it's really close in terms of the control and then we start adding functionality to the code so we have simulations but we add seasonality in terms of spread and in terms of volume so now our model starts reacting to the seasonality so if the spread is larger we're going to trade a lot less because we don't want to push the price up or down so much so seasonality here is already having a major impact and then we add real data to it which doesn't make that much of a difference again it's just the fine tuning and we add the multi-preference control so this is when you're actually learning the risk aversion parameters of the agent so once you're learning that you actually react a lot to not trading as much in the beginning of the day because you're still you're still trying to gather what is uh on which foot you're standing in the market okay so this result was for gamma equals to 2 right so we keep that quadratic parameter in the objective function now if we look at gamma equals 3 over 2 which would be more realistic in terms of the execution of real traders we have something more interesting so i'll skip to the r squared directly and notice that we're considering different sets of risk version families so the first set is the one that keeps all the execution very similar in terms of keeping it similar to gamma equals to two so we can tune these parameters and and have very similar execution as to when we had uh a different gamma but here when it when we keep the exact same parameters and just change the gamma we quickly see a non-linear solution for the neural network so here as you remember the r squared was very close to 1 all the time here we're actually taking it from 0 to 1 and we see a very uh non-linear structure so the closer to one uh the more it means that this control is linear but here is very far away so the neural network's actually learning a non-linear structure for the control and of course we want to know is this uh is this making money or is it not uh is it executing better so i know it's a lot of plots but on the left we have the value function versus the initial inventory on the right we have the mark to market wealth versus initial inventory and then on the top we're considering gamma equals to two and on the bottom gamma equals three over two so i'll go one by one so the value function versus q zero for gamma equals two i compare for all of all of the possible cases so stylize closed form neural network on simulations add seasonality add multi-preference control with real data with seasonality and they all have a very similar type of structure for the value function when gamma equals two if i then change it to gamma equals three over two and i compare the stylized closed form um with the neural network on simulations we now have something that has the neural network outputting a better value function and of course this is because we're changing the objective so we do expect it to be different and then if we look at the mark to market wealth same thing it's very similar when gamma equals to two but once we look at gamma three over two we notice that the wealth is varying a lot less so for the neural network on simulations you are actually paying less or getting less in terms of how much your wealth is varying back to market than you would on the stylized close form so here you're you're paying less for each time you trade so how do we evaluate the performance we're going to look at the relative error in the projection so we take uh our control so this is the learned learned neural network control and we compare it to the projected version so we compare it to something that is on on the many fold of linear functions of g and on the left we have gamma equals 2 on the right we're going to have gamma equals 3 over 2. so if you notice here so we have initial inventory q from minus sixty thousand to sixty thousand stocks and we have time uh in bins so from zero to seventy eight trading bins and the relative error here on the z-axis on the left-hand side you notice that the error is very small so it goes until 0.04 and it only increases at the very end of the day and this happens because um the less the more concentrated uh our inventory is so once we at we're at the end of the execution all the points are very close to zero so our our projected version is not as accurate but that doesn't really matter because we have so little to execute that this error is not no longer relevant so this execution of let's say 60 stocks is not relevant as it would be if i had 60 000 stocks right so here this is an error that we shouldn't even worry about and on the other hand uh for gamma equals three over two we have a very large relative error and this is actually coming from the fact that the neural network is learning something non-linear so in the beginning of the trading day is actually doing something very different from what the known control uh the classic closed form solution is doing so while we have shown that it has a better performance it is something that we don't fully explain in terms of the known solution so you would have now you have the possibility of discussing this with your risk department so do we still want to trade using neural network do we want to set margin for it based on the fact that we know how much uh how far away we are from a solution that we are very comfortable with so this is something that allows for this discussion and finally uh on the multipreference controller so here i considered the time steps until at least 90 percent of the order is executed so if we have uh parameters that are more that are tighter we're going to execute much faster and if we have looser parameters we might not even finish executing by the end of the day so this is expected but when you look at the left hand side you're looking at the closed forum pde solution and on the right-hand side you're looking at the neural network solution and you notice that the neural network solution is always taking a bit longer at least dominantly longer to execute than the pd solution for all sets of parameters and the reason for this is that it's reacting to seasonality so we're trading less at the beginning of the day where the spreads are very large and therefore we're pushing this trade towards the middle and end of the day so this is where this is coming from but either way it's a it's an interesting result to see like how fast uh can we execute this order and and the best part here is that well now i don't have to train the neural network at 4am uh wake me up we can input our current risk conversion parameters and start trading right away with something that we already trained and then if you want to retrain the model once a month that is okay but it doesn't have to be something you do everything okay so for a conclusion we propose a neural network-based model for optimal execution which of course allows for getting rid of a lot of assumptions from the classic model assumptions that we we know for a fact that don't hold in real data and then we propose explainability through this projection idea which uses a linear regression and we propose a multi-preference version of the same problem which allows to remove a bit of the computational burden that you would have i want to do some propaganda so i have other papers in this thesis first one is a theoretical bound for the projection so here we have shown numerically how this projection works and on a on the next paper we're going to show the theory behind it so we're going to make it more robust and explain this explainability idea and and how these bounds actually work and the second paper is the model improvement through high frequency econometric tests so we use both regular regularly sampled data and on-time asynchronous trading data to show that the inventory process is actually not just time differentiable it has a diffusion component and of course i have other projects so this one has become a paper so price avalanches in product repricing i am currently working on graph networks in limit order books and of course we can use this neural network approximation idea for many other financial problems so the most interesting one for me is the it's the hedging problem but of course you can find a myriad of other problems in this area so this paper you can find on archive and the financial the high frequency econometrics paper as well the other ones oh actually this one you can already find but it's not related to the stock and and this one will come out soon so thank you very much and if you have questions you can ask now or send me an email later at lleal princeton.edu so thank you i hope i didn't go over the time oh no actually we have plenty of time and so i had a couple questions in the chat then uh and maybe i'll ask a question or two and in the meantime if anyone has other questions please add them in there so i i had a first question which was is the speed of trading limited by the neural network latency so i'm thinking that they're asking if in the model there's a sort of latency or slowness to it but maybe you could comment just on maybe the the speed of the neural networks and whether this is something that would work well live or whether it's as you said something you train uh in free so this is something that you would train offline so this is not first say online reinforcing learning so you would wait until the end of the trading day to update all the weights so you would not be limited by latency here because you you have trained ahead of time so pretty much to simplify it uh and by the way i really like your demystification of neural networks that sometimes sometimes seems more complicated than it is but you've clarified things um ultimately it takes in time and inventory and potentially risk aversion parameters but yes but ultimately once this neural network has been trained on past data that's all it does is it just uh inputs it takes these two inputs and spits out a rate yes it's it's ready for use so that's what i meant as in well once you have uh your objective function and your dynamics really accurate then all you need to do is just obtain the control and start trading so you don't need to worry about like what's under the hood it doesn't really matter to the person trading it only matters to implement it once so the end user doesn't need to know what's going on and so as this is used intraday do you expect the risk aversion to be uh tweaked over the course of the day or who would control that or if that's an out it's a now it's just a an arbitrary input you could you could do it uh the person who would control it is actually the trader okay so your risk aversion might be a knob that speeds or or sort of slows down the process yes okay i had another question which was um can you elaborate the fine-tuning procedure in the uh so maybe i should say the names uh this is this the other question was kevin deffagen and this one is from yuan yao who asks can you elaborate the fine-tuning procedure in the transfer learning parts yeah so here uh this is this is something that we debated a lot um and there's so once the the network converges and of course there are no theoretical uh explanation there there are no theoretical results that to say like well has it converged but once we have um we have the the result not changing for a very long time so for many iterations uh then we assume that it has converged and once we reach that step uh we instead of using monte carlo generated increments we start using uh the real data so ins so the increments are now coming directly from the increments we calculate from toronto stock exchange that meaning that now every component of heavy tails every component of autocorrelation is now taken into account and then we train and continue the training on this data so i don't know if you're asking about the the actual implementation but the way this implementation is done is through checkpoints on tensorflow so what a checkpoint does is it records the last uh the last weight and bias and you can continue your training from that that particular point of the training so you train save the checkpoint and then retrieve the checkpoints to continue training on another side of of the project so i hope this answers both sides of the question yeah um so i've got a good a question i like as well from alberto chop chop who says do you perform any kind of pre-processing in the input variables i time an inventory and what function is the neural network optimizing exactly i don't know if you yes yes that's a good question um so these are two questions right so the first one uh do i perform anything before yes so the neural network when it takes for example the inventory as input if we had used um the input as the pure value of the inventory let's say like 60 000 and we used time as time between 0 and 1 let's say from from an interval then the neural network would not learn very well it would have training issues because of the difference between the size of the variables so what we do is that we have instead the inventory as a proportion of uh the average volume for that stock during a day so let's say we're not trading um 50 000 stocks we're trading five percent of the daily volume so once when we input into the neural network it's taken as a value between minus one and one because we could be trading nega the other direction so it could be negative um but once we put it back into the dynamics we change it uh to actual values so when we put it in the neural network is a proportion and when we put it into the dynamics is an actual value that you're trading so that is one question sorry can you remind me of the second one yeah the second one was what function is the neural network optimizing exactly so maybe they're looking for the objective the objective function so here so here you have a maximization problem you have the objective function and you have dynamics if if you were to solve this maximization problem it would output a control so this control being new caden so the function that we're looking for is a function of time and inventory and what we're outputting here is what are the weights and biases and the structure of this function is actually here so once we input time and inventory these are weights and biases which are our theta right so this is the structure of the function um and and this is what it's out so this is the problem we want to solve and we set a structure for the neural network and the output is actually going to be this function tweaked for weights and biases in the problem so this is this is the the instead of using the neural network in the classic way like saying well it is you have a training set and a test set this is using its most intrinsic form of function approximation so we don't have the training set at testing set what we're doing is approximating the solution to the stochastic optimization problem and so is it fair to say that there's sort of two input nodes and these four hidden layers or would is there a diagram that sort of corresponds to this in in in neural network land i don't have it in these slides but yes it seems like no there's this structure is more like a snake biting it still right it's sort of like um yeah so this this would be a very simple structure just like uh just like you have the nodes and you have the inputs you have the nodes and then you have one output that is the control so the speed of trading so you put in time and inventory you output how fast should you trade in this five minute bin and this what we have this equation right here is sort of telling us about the architecture yes okay um so we've got a question um by michael sotiropoulos which uh actually i know well and uh in fact i i was going to ask a version of this uh question myself so he asks can we interpret the difference between the two control solutions gamma equal to two and gamma to three halves as a result of the changing of the utility of the investor and i guess my version of this question would be do we know for sure that gamma 2 is not great and three halves is a better uh model of an investor or what is our evidence that we like so you know feel free to address both questions but we're kind of both dancing around the question of how is fun is gamma two and three halves a fundamentally different uh animal so so of course it's uh it's gonna be a difference of changing the utility function so if we have a different utility function that's a different stochastic optimization problem that we're solving so the control could be just reflecting that fact but what we are saying is that with the new um with the new setup the new framework with gum equals two we no longer have a closed form solution coming from a pde for example we will have an approximated solution coming from the neural network and okay so then the question becomes okay why three over two so this is something that is not um it's not out there it's not published this is something that comes from uh the experience of one of my co-authors he tested this for actual uh traders execution within uh the firm he was working at so here i don't have uh an explanation coming from the data that we have it's just a heuristic explanation okay um then we have someone spencer dean who says i know this is a stupid question good start um but do you have any idea what the network is doing at the times when it can't be well projected to a linear control strategy what kinds of positions is it taking at these times how are they changing i know that it's fundamentally non-parametric so it's probably challenging if not impossible but he's asking the question anyways okay um so we do know what the network is doing um we have we have the the trajectory for the execution um what kind of positions is taking are they changing we have all that so if you look if you look here uh the average control process is new we actually have uh this process for the network so this is the speed of trading at each given time from 0 to 78 bins um so we do know what it's doing it's trading at this speed um [Music] so the time yeah so i don't know i think this answers like around the time 50 60 which i guess is the worrisome bit uh where something is the r squared is poor and that's not actually the contr average control process seems to be going the wrong way as far as the optimal solution is concerned is that so so here for gamma equals two they're actually all very close to one so this is just a matter of this is 0.997 so here it's very very close to one and and the process is just saying uh here we're starting to trade faster it's not that we're going in the other direction here's just it was trading a bit slower because in in the middle of the trading day there's not much volume and the spreads are large so we're reacting to that and then we're picking up again towards the end of the day so i think the question might actually be here but here we cannot see it as well so um the r squared is actually saying that the solution is non-linear but in the average control process we have a very non-aggressive execution leaving for the next day so yeah we do know what the control is doing at each given point of the day and we do know how it's changing so it's not impossible one thing to keep in mind though and i know it's not related to the question but here we're looking at the average control process and the neural network is very good at outputting this type of like expectation result but when you're trading you're actually looking at one trajectory so while the average control process is a great guide on how your execution is going to look like uh once we go to one trajectory um it might not be exactly how uh it might not be exactly this so this is something to keep in mind i know it's not related to the question but it's something that we have discussed a few times between the co-authors and if someone has inputs on this i would love to hear if you're a trader or have used these methods before okay and so i guess there's one last question and we're wrapping up the hours so sounds like a perfect final one uh domenico spotto is asking as an optimization method did you consider using a two block method slash decomposition for the w and the b so w and b i guess are your weights and your biases and i don't fully understand the question but the question is uh did you consider a two-block method or decomposition for them i also don't fully understand the question but i did not consider a two-block method i would love to hear more about it if if dominican could okay say more about it oh we've got a final one from marcos a fellow uh brazilian i think marcus carrera what could this method learn from gme and other uh meme stocks would the dynamic have to change well here here yes uh you would need to change um let's see if i didn't bring this slide but you would need to change uh the way you're impacting the price so here uh this is you impacting the price but if you have a mean field game of agents so if you have a meme stock you would be considering like many people acting and pushing this price in one direction so instead of having the control as being you pushing the price it would be you plus a mean field game of agents pushing the price and then how this would change the solution would be that instead of having this h1 is merely zero in in every case you would have this h1 as an actual function of time so you would have this this guy changing so yes the dynamics changes uh change a bit and you would have a different slightly different solution so thanks thanks this is a fun question well i don't know if uh renee carmona is in the audience but i'm sure he would like the answer with them okay well uh great to have you thank you so much for this great presentation and uh i guess we'll continue the seminar in the new year thanks for having me and thanks for everyone who came and asked questions 