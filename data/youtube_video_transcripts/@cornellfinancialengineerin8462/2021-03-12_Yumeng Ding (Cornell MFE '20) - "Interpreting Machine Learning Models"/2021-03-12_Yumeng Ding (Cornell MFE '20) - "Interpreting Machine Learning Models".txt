uh so uh yeah so um i uh introduced before um we mainly explored how we uh evaluate and uh interpret the the trained machine learning algorithm so um we started with a multi-factor model to make predictions on the future stock prices and the data we use is the s p 500 consequence data and the data frequencies monthly we are considered three classes of three types of factors which are technical quality and value factors so technical factors of course are statistical trains gathered from trading activities quality factors are related to the financial statement data while the valuation factors are usually based on the stock valuation so mostly we use p pb or ps after that some of the most widely used machine learning models were implemented in the classificat in the classifiers of regressions and after that we used uh interpretability methods um to evaluate and interpret this trend machine learning algorithms basically as for interpretability methods there are two categories uh global models and local models so global models usually shows the average effect of our factors while the local one shows the future effects of a certain range of the data or for some certain instances some model can be both global or local it depends on how you could use them yes and so next slide um so also to better evaluate the uh machine learning algorithms that we had we uh we built up a trading algorithm and used the back test so from our back testing we have uh two main conclusions the first one is we found out that most non-linear models outperform the linear ones in this scenario and uh secondly the factory effects are actually time varying um that is to say that is to say uh not a factor can perform well all the time and their effects are changing over time and uh among all this machine learning interpretability oh sorry among all these machine learning algorithms uh in this scenario other boost was the best model and the problem but the problem is can we interpret what an edible city is doing the answer is yes so with uh by implementing interpretability methods we can um we can interpret how our predictions are made and how on these factors are making contributions individually as well as interactively so um firstly from partial dependence plots and aoe plots we can know the average marginal effects of each individual features just like the um plus shown in the right side and the only difference between uh ai plus and partial dependence plots is that aoe plus considers a correlation between some features and that's aoe plus sr is more robust but slower to come in computation uh individual conditional expectation plots are similar to partial dependence plots and aoe plots but it shows the marginal effects of all instances and thus this is a local model besides that we also apply the permutation feature importance model to measure the importance of a feature a larger value in the permutation feature importance means that on a larger contribution of this feature besides all the individual effects that can capture by the uh the above interpretability methods we can also apply uh ash statistics shaft and line to capture the interactions of these vectors so edge statistics measure the strings of interaction effect between features compared to the strength of the individual effect of the feature itself uh sharp line on our local models to capture to show you how the interactions are exactly are by visualization so sharp shows the uh measures interaction effects between features in regressions uh lime is a popular it's another popular method only in classification and it only measures the interaction effect of one instance um so with all this uh interpretability method as we said we can easily capture the feature effects and their interactions so if we consider decompose our predicted variable it can be composed of four parts so will be linear functions of our factors polynomial or nonlinear parts for our functions of our factors interactions of some factors and plus some noise basically partial dependence plots and ale plus are enough to explain linear and polynomial part but they cannot capture more complicated functions or the interactions or functions of vectors uh ash statistic will be a very quick and good way to find the most predictive interactions but it can only show the strength instead of the how the interactions are and sometimes you may need the two-dimensional partial dependence to visualize some easy interactions uh shaft a line would be a good way if you want to dive into the detail of these interactions and and it is a good way to visualize local interactions as well if the data is not noisy uh so uh so in summary uh i think there are two takeaways from our project uh the first one is uh machine learning or nonlinear models do you outperform those linear naive regressions in our scenario and um the reason is probably that there are a lot of interaction effects compared to the individual effects and that's why we are using machine learning most of the time the second takeaway would be um if machine learnings are better then can we interpret them easily and the answer is still yes so with um all these uh interpretability methods uh we can um we can uh we can we can we can easily explain like how how these factors contribute to our predictions individually but also interactively so that's all for our project yeah thank you so much for your time 