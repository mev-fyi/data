we figured or I thought that maybe I would select a few topics that are sort of at the intersection of finance and I suppose I made a list of things that people care about the don't know much about it I think on this top of this list was machine learning and came FinTech and then critical currencies these were we're happy to RIT q2 is the reputation so the top this also I think another reason is that this is a very exciting oh my god look you know we'll keep you informed about our next talks but thanks everybody for coming I'm sure you were curious about the compost brother and a disfigured so history buddy hazardous of their preferred reason to my computer girls go out of business that's my preferred list whenever you leave that Aponte's give me back the money or shutting down you you want to do it was morning to understand what they do prostitute or have in the same situation these are the descendant points i'd i have found the word that the years to match modes of the cases so let me take them only one the first one is like all in wants what does that mean well suppose that you are importing one a year of the discretionary fun like running marathons you are hired to manage money and to take some bets based on ideas object me objectively formulated if you could object we formulated formulate them you wouldn't work in a discretionary funds will work in systematic fun so essentially you have a any audience explanation about what is happening economy but it's not something you can actually formulate you have a little more of a something short of the theory you cannot invade to your colleagues in an abstract rigorous way so that prevents people from having a truly contracted conversation so when you attend one of these investment comedies that Acorah I find typically what happens is someone throws a later another person throw some other anecdotal evidence but there is not really much of a theory being discuss something you can experiment test and as a result of course discretionary funds are very well as the ability to is a p.m. to interact but not much they should work inside us there isn't it inside those seas as they are trying to avoid that one and if once the other eventually yeah what's on that perhaps you should put your mics on one Ian influences the other p.m. eventually what happens is that you end up paying fifty peers for the work of one that wouldn't make sense so in the discretionary marker fund or discretionary equity fund portfolio miners are asked to work in silos that's in the one world not really that's one of the reasons I often see one funds fail essentially the logic hoping of the board of the firm is let's do it once what hasn't worked with this country for for the managers and it just doesn't work you cannot hire 50 PhDs and put them to work together to to work in silos and everybody is doing 50 times as anything collecting the data 50 different people collecting the data between different people cleaning the data 50 different people visualizing the data and recruiting people repeating exactly the same tasks over and over and over again when you mask 20 lady portfolio managers to do that essentially what will happen is typically one of two things will frantically look for some investment opportunity or strategy practice it in the daytime very often these factors will lead to a fault discovery be presented to the boss me personally committee approves it was an overheated strategy it's not going to perform and eventually what happens is that there is no strategy and the person gets fire or whatever so that's that's very common another thing that another option that you will see very often is many of these 50 PM's will read the literature readable many public allegations are already in the journal finance and Journal of economics so on eventually they will sell for some strategy that is based on all factors factors affecting investing and there is there is evidence that this abstract is actually war but the reality is of course they can have each operation of two rating of 0.5 before transaction cost so yes these papers are are evidence that there is some some profit that you can obtain from fact investing but it's not what they board is suspect in the for disrespecting each operation to so eventually the project is shut down and and you see made very often that the funds that have been very successful in discretionary or for management actually failed in one day you try to go 20 days and they go through version 1 2 3 4 5 they are a new portfolio manager to leave the coin area and eventually still they they are not able to launch fund and I think we go through multiple iterations so that's why I called decision upon sniffing ones are ones that are asked to roll this massive rock at the mountain all on their own and guess what they are very close to the summit and just when they think that they have found something didn't work they have to start again and there is this quote by Albert Lee and you wrote the myth of Sisyphus there is no more dreadful punishment than futile hopeless labor is any truth think of it if you have to go every day without any help an assistant your work in a silo and you are asked to develop I mean you already know it's not going to work and I'm asked to do it impossible it's just at this stage NH it is impossible for a single individual to on their own without any help identify a strategy that they can develop and implement and run on their own is we are at the stage where the level of competition is such that it may be possible I mean like winning the lottery it's going to be very very hard at this point to get requires a team effort so what does a team effort inhale that's what I call many strategies you need the strategy to develop it strategies strategies cannot be the result of artistic in inspirations or some sort of you know incredible insight that you realize now you need the strategy to come up with the strategy essentially unique an industrial process you should be able to produce the strategies us at the NW produce Mars in the pan right there are many more places more developing inside I need to build a around high performance computing infrastructure software development feature analysis execution simulations simulators back testing and so on and the best way to do it is to identify these tasks dividin allow everybody in the group to actually specialize in these tasks there will be someone who will be the absolute expert in the firm in how to deal with unstructured data right it's on its own it's such a such a topic I have to deal with that structured data on its own actually deserves several people focus just on that there will be all individuals that are experts in high-performance computing whether it is distributed computing or these clusters in faster or whether it is he PU there is so much so many complexities involved in that that you actually need people specialize in that that's all the other people there are experts intensive law how to develop deep neural networks with specialized software you cannot ask everyone to be an expert at everything it's just it's not much for people now mind is situation where you are working in your work in an individual Factory Yoga has to will to build the car on your own just build the car you know one day you need to be a master welder another day you need to be an expert in placing the [Applause] hydrological system whatever I know Nick Carson I'm making it up other day you need to be an expert in the automation of the windows right it's nobody nobody works right why would any company as someone to work like that it's because they don't understand once alright so what would is medically marlyne do every individual is a specialist they work independently by knowing but at the same time known the whole game plan you know word of each other right the person who is in a specialist in a structured data I'm dealing with an effector they needs to know how this rate is going to be used needs to be able to answer queries right this person will be next references in fixed protocol well it needs to it needs to know the the analyst who is going to develop a market make the structural strategy that is based on the cancellation rate that is technically in the e-mini S&P needs to the person who is dealing with an abstract data needs to know what sort of queries are relevant what sort of fields in the fixed message need to be a store how they should be a store how to handle revisions Corrections to the data everyone needs to be aware of each other but at the same time they need to be specialists this is not only true for developing studies but in fact you could think of a pieman strategies everything in the front not only developing strategies but actually how to hire someone right hiring someone is the process of sampling right at some point there is a stopping criterion at some point you stop interviewing people and make a decision what is the optimal stopping point at what now the person has joined the team how do you oversee the investments now that you oversee the performance of the strategies at what point are you going to stop at the strategy so the meta strategy paradigm is not only useful for developing strategies but when you think about it is all about how to make decisions under uncertainty where the scoring is strategy is one of the decisions you need to make but you actually need to answer many questions about how to manage one you define alright the second problem into your differentiation how people wonder why so many papers take us a hormone complete that you should depend see the data you know we get some financial data of course a place known as visionary because it is not a stationary you are not going to be able to do inference right if you can only use inference on a distribution that is a stable over time so most papers just say well let the currency the data well what does differentiation theta because it shouldn't be that you achieve the stationarity has any cost you should you're not what you're paying when you're differentiating differentiate and you are giving up some information are you giving up the most valuable information as it happens that's typically the case king when we differentiate they haven't we complete returns for instance we are erasing signal and if we raise it the signal there is no hope we are going to be able to predict anything so there is a dilemma on one hand we have to make this user stationary but on the other hand we need to do it in a way that is still allow the series to preserve some memory information about previous observations that allows you to discern whether this price or series is at the critical point at the point where you can actually make a prediction so this is an example of a fractionally differentiated series of the e-mini S&P as you can see the line in the ACE the green line here shows the missiles of the emini futures roll forward I'm pleased to say practically differentiated data where I have different state the data coefficient of one for instead of the equal one which is what most people do in the publication right they just complete returns I know I'm not differentiated by any clear I'm differentiated by differentiating by fraction so when D is equal to one this you can see it's something like a mix of returns and levels right when you look at this blue line at a global point it looks like returns but when you look at the whole series it actually resembles more like the Green Line the levels right goes up and down right up here around 2008 2007 and then the big drop then the chords so this happens to be more useful this is the blue line is this is a series that is a stillness is this stationary so you will be able to run classical analysis some more right the distribution of the blue line happens to be stationary at the same time is C contains memory we need that for instance here this is draw at the end of 2008 because of the crisis and and it takes a while to recover from that drop he takes perhaps a year or more to recover from that drop which is something you would not observe in an eternal series in your return series you know if you compute the return of one day at the next all the way up so it's a combination if this new series is actually differentiated series or how I call it something frankly this practice series happens to be a combination of the two let's try to understand a little bit what's going on with you fact when you do attract people to serious on one hand if you don't frankly differentiate the service if your piety or to 0 which essentially means you do nothing 80 at the start of this series will be minus 0.33 87 which means that actually you cannot reject the hypothesis that reads the unit group now if you apply returns the ADF is minus 46 so we need to minus 46 to run some analysis that Sigma stationary no so it's over done right do someone between the point where you are within the threshold that you that you are willing to accept for stationarity but at the same time this usage is still highly correlated with the original series and that happens around here because here the blue line which is the idea is that the alias stop touches the critical level of minus 2.8 istakes and what is the correlation of the original series with the attractive series at this point is point 995 what this is what this means is that you have achieved a stationary series even though the series is essentially you have not no memory this all is almost perfectly correlated with the original series so that's why I mean with with not even on too much memory at this point the series is almost perfectly correlated with your inner one and get it stationary compare that with the situation that most people handle where the correlation with the original series is virtually zero right the the standard situation in the literature is returns equal one yes ADF is minus forty six point nine corrosion almost zero so yes much in the stationerity but that but there is nothing to deceive is useless now is this case of the emini unique not at all actually there is not a single future liquid future what this is not true here when I'm strong it's a table where a breached contract I'm using bloomberg code here you can see what are for each future liquid future or why what is the ATF associated with the concealed upon 1 upon 2 all the way to return and I have plotted in green where the value is above the threshold and when the body drops or fall below the threshold and as you can see point two is more than the median point two not one two and not it's not in a single case if I go to the next list not in a single place you would mean the over point five pollution most studies in the literature that try to achieve the stationarity by differentiating they are over differentiated by a lot because most cases spawn two will suffice and yet they apply yes oh yeah all right what a class is just p.m. I think so III was surprised at first time I saw it I have not seen these punished in any papers hood these breaking breaking news is the first time I showed you some my improv is mad at me tonight insurance is out there now so the point the point these are the a-team Oh liquid futures worldwide on all asset classes this includes commodities facts future some on fixed income equities everything I've not found a single case where you would be justified to use returns let's put it that way I think what one means one trading day yeah he means one observation where in this case are an average of 50 observations per day observation project but it would it will be the same on a 50 of the business on average these are warning bars so some days you may get ten bars of the days you may get seventy bars if you use it on on day on daily data it's even more the case meaning that this is this serrated room on on intraday data on higher frequency data is already true that you cannot you don't you don't need to complete returns on daily data is even more details yes yes now these are these are warning box on an average of 50 parts per day in the year 2016 the body parts do not have a written are some frequency yes I'll explain I'll explain in five minutes persist exactly 100 I guess many people work with they depart god knows what why but yeah and if you use very large speed is even more the case that you do not want returns and the reason is because if you have any any chance of predicting like the price he is within today I mean it's just not rendering off all right you know it's like I always say my presentations try it yourself I think you will you will agree that there is nothing special about the equal to one I mean why it would be for white would be equal to one be magic what is magic about the equals one why not be 2.95 why not 1.15 why why would everybody use the equal to one there is nothing there is no theorem that proves that the equal to one is the walking home in pronunciation misstep okay inefficient something so that's now we want to discuss paula most the most people in the literature you read that a sample values using daily observations or one-minute observations or feminist observations these are this what i called canonical something right there they're based on a number of parts per day a nice fragrance why would that we use why would that be useful I don't know I mean why would why would you want to sample 10 times per day during the flash crash and 10 times per day on you know December 31st one of the most boring sessions in the year why I suggested that you try on sample based on the amount of information that arrives at the market so when there is a lot of information arriving at the market you want to sample more frequently when there is less information you sample less frequently a couple of examples what I call lower bars so what is the dollar mark it samples whenever there is a certain amount of tourists transacted in the market so that involves warning on price information you you multiply the amount traded by the frustrated when it exceeds a certain threshold which can be arbitrary arbitrary chosen you sample that means that things with no audio you receive very general observations or days where there is little volume and prices were are low because it's much cheaper to transact there is less money at risk you would expect that ones increase right so for instance do you think that there was the same level of market activity before and after the crash of 2008 no part of the reason is because after the crash it was cheaper to buy and sell something so people who wanted to risk a certain amount o of audit risk people want to risk the same 1 million dollars they would TransAm all towel after the crash not before the crash well it sounds like we should take prices into account when we sample definitely you know taking ten observations per year or per turn searches per day regardless of the law and for the prices is missing a critical information what happen thing we need to go through the exact way these are the completed important notion is that you want to take into account price of model information so that these sample are equal amounts of information that arrive at the market you want to synchronize your sampling with the amount of information that arrives at the market so that when there is a lot of information arriving at the market you want to take more samples right because they are more useful they contain more information all right three examples here lower parts volume bars and the bars so you sample for instance every 10,000 things you will observe you would obtain this amount of samples per day this is more serious but you get that you know around 2013 there's a big there is a there is a large number of tips that we put sample or T parts that you would sample per day what happens when you use boy bars well this is less the changes are less dramatic this use is more stable but it still there is here is sort of like pinnacle goes down and when you sample like $5 bars you pain and much a smoother read something frequency where you could link these increase to just the market expanding there is you could you could actually link this to the expansion of the market market just grows and there are more participants and you can see how the big black line is very well the Green Line is very small and dollar bars are much more estate why because you're something closer to the among to the mechanism that is contributing information to the market okay it's one number for wrong labeling so what does that mean you will read that most there are no mini machine learning papers in finest but most of the machine learning papers in finance happened to label in a rather arbitrary way essentially what they do is they take the price I mean the price of a given point in time he let's say ten observations later the price went up this operation will be label as one if it goes on minus one maybe there is some dress all I need within the pond they might buy the trestle is is label as do well that's kind of arbitrary right because when people label observations that way they are giving up information about the past how did the truck how did the price converge to that outcome that's more problems another problem is that why would you sample why would you label excuse me why would you label this feature is observation is a third feature by looking at the next n observation what is magic about that right so that's why I recommend an alternative way to do these which is take into account what happens the price how did the price reached that that particular album so that's what I found people very method essentially what the way this works is you will start a at an initial point the price goes up and down we can touch barriers in upper horizontal barrier the lower horizontal area or or vertical barrier if he touches the upper horizontal barrier that's what you could call a profit-taking level if he touches the lower personal barrier that's what you would call the distal most level and if it touches a vertical barrier does just like a time out you are not willing to hold the position longer and you label face on the variant that is touched first in that way it doesn't matter what happens after 10 bars the important is what happens in between now why does that make sense well because whether we like it or not actually most people need to follow risk levels and sometimes we hold the position and we are stopped out either by the risk manager or the investor wants the money back or this change comes with a marking ball so it doesn't make sense to develop a strategy that does not take into account these situations where your horse out of the of your position so to be realistic we've all been in strategy should take into account its top out the stock losses Marty calls the cetera now there is something called methylamine and what is methylamine the meta labeling means developing a strategy on top of another machine learning a strategy is a machine learning strategy that does not try to predict what the price is going to do is trying to predict whether the prediction is good you have a machine learning algorithm that produces a prediction and the petition can be something like buy this stock and hold it for until you know either makes one percent or system at maximum or that would be one prediction by the machine learning algorithm and then on top of that you develop another machine learning algorithm whose function is to decide whether you're going to ignore that or that's or you're going to implement that forecast why is that interesting because in that way you are composing the two important decisions into two different models one mobile determines this side of your trade the other model deterministic quantity of the trade where one possible quantity is zero meaning that the first model names may want to buy a stock and the second model will say yes fight with but investing the zero dollars which essentially means pass I pass on that why it is useful because if you're familiar with that one is force all right you have you heard of can you raise your money you know what if it one is for is okay so a net one is for is a way of combining information about the precision and the recall okay now I have to say what position is well precision is the percentage of your predicted positives that actually are positives that's the decision you can have a decision let's say of 90% and you would say I'm very happy because you know whenever there is whenever I say there is a positive there is a 90% chance that is a true boss it well wait a moment how about the recall and what is the repo the ripple is the percentage of the actual positives that your classifier is identifying so for instance you could have a test that predicts that has a 90 90 percent precision to detect whether someone is drunk right person and you would say well this test is good wait a moment maybe not do it because how many of the drunks is the test identifying we know that when the tests say that someone is drunk there's a 90% chance that this person is actually drunk but maybe it only say it never said that someone's right or maybe since we you know one out of a thousand do you need to take both into account precision and recall right and everyone is essentially harmonic mean of the two harmonic mean of precision and recall you could ask why are quite harmonic mean why not they not really well because actually there is a trade-off between the two and whenever there is a trade-off between two finals you rather use a harmonic mean I suppose we all solve these kind of problems where the trains are about to collide with each other and the teacher is asking you when are they where are they going to follow them and what time and they also said harmonic mean right because the two trains are passing one again they over right and the same happens here you you typically is very hard to achieve high position and I recall you may have very high precision but very likely you have low recall or you may have very high recall and low precision that's why the harmonic Queen listen mate sex and for the same reason you want to machine algorithms to take care of two very different tasks what machine learning algorithm will have the person by the day the same day the first level the first layer machine learning algorithm will have high recall and opposition and the second one is one that will that will filter a lot of the junk produced by the first algorithm and will achieve high precision and high recall right once you have higher equal even you have high you can have high recall and low precision that's fine as long as you have high recall using have a chance but having it a good strategy why because the the law position is something you can address you can just filter a lot of the false positives and achieve high precision without using too much recoil so that's something that is useful I mean particulars should be very useful to finals that are getting into fundamental interesting right fundamental investing in this sort of culmination of one investing and sentimental investing and they do use your humans are the first thing your machine learner right we hire you call an opposition true true and then you have the machine learning algorithm sitting on top of them where they are filtering a lot of the false positives that are pushed by these discretionary traders on achieved high precision we hire people all right people notify over there waiting of non Hyades samples well is it a problem right one of the reasons why you cannot find many people from Google the starting hedge funds is because it's what finance is harder than recognizing faces dealing with financial series is not easy and I like explaining this with the following example if you work in a lab like you know you know doing you know I think blood you can take one sample per patient right you have your sample for this patient blood sample in the tube now you're going to measure the cholesterol dispersing amount of whatever right red cells white cells insulin and that's easy right now that's not my hand is nothing right anesthetic finances someone collected all the samples and then someone arrived and moved them and now tube number 10 contains some blood from patient under 10 but also an unknown amount of blood from patient number one and two and three or four or five to six and seven and eight and nine and then to a tube number one contains the latter on samples from pages two three four five six seven eight nine okay right that's what non iid samples mean it's a mess there is no way to link a particular observation to a particular patient so when you observe when you are dealing with no my ID data you know that there is information about what happened that day but there is also information about previous samples and you don't know how much you need to you need to apply specific techniques to deal with these community of data now do not she recognized his face is pretty good scene I have no idea about investing all right so whenever someone comes to you and says Wow look I have and I have this machine learning I were they might develop a Google or Facebook recognizes faces let's just plug in some financial data I say look my dog faces my wife claims to be able to drive cars anyway dealing with financial data is not easy at all and one of the reasons is because it's a mess is that all the dirty data not only the financial markets change all the time right our DNA is continued all the time right there is there is a new regulation a new law and things change completely and it's change changes some way of training versus it could go from five four assignment of the a 5-4 criterion for placing orders in the future a pro-rata and they just a flip of a spur of the street as it happened to the two years futures if you use ago now how can we address this what others are always to address a non uniqueness of the observations one is to complete the uniqueness of the solution to derive it this is one method that I like essentially what you do is for every observation we try to determine the amount of overlap in that observation so think of the people for the triple barrier method where there is a label as a result of minister catholic process essentially what you are asking is how much how much of the label is the result of information shared with other labels so for instance is one station one observation lasted the label was decided four observations one to ten and observation to what set it over observations 2 to 15 right they share two to ten 2 to 10 over 2 to 15 for the second one and 2 to 10 over 1 to 10 for the first one so the first one is essentially overlap is essentially a useless observation the second observation is a little a little bit more useful why because it contains information that was not shared in any other label so once you determine the uniqueness you can divide how much of the sample weight should be used by the classifier in order to identify particular pattern and what you will observe is that sometimes there are solutions that are very useful that's an either-or are useless now if automatic provide regional image many people think that consolidation is some sort of money trade that is going to always tell you the truth whether this classifier is accurate or not and the answer is not not in finance anyway why because cross validation techniques and in general but in particular capable cross validation assumes that the observations are IID again that's a truth we wish so we have to do something about cross validation because if we apply close validation to financial series we are justifying methodology that is assuming that observations are IID when they are entire so one thing we can do is we can figure out some way to identify observations should be remove from the training set so let's say that you have a temple temple cross validation all right so you know how it works you split the series in ten and now you're going to produce ten training testing splits in the first one the first packet of observations will be the testing set in the second the second bucket of the duration will be the attention sets and so now every time you do a split between training and pencils and testings that you have to figure out what abstractions in the testing set are linking information about the training set what observations in the trainings that have leaked information from the testing set from the premises all right so you want to to porch you want to purge observations in the training set we have the part of this year the party that is it way too soon to say certainly this is a one of the partitions where this is the data set and once you have decided what your vetting studies you figure out what portions of the training set need to be removed why do they need to be removable because they contain information that is older than what shared with the and so there is something that I call poured in right these two differences this overlap is a version there is an overlap in the in the information that that was used for forming the label this information needs to be dropped but in addition we need to develop tomorrow tomorrow sometimes 14 is not enough even even though you have removed the overlapping information in the training set in fact you need to to catheter just to be sure just to be certain and you need to remove some of the information that pours after the testing said not before the testing set occurs before the test is set is fair game right we eat in a filtration so we don't care about information that we learn in the past no you care about information that we learn in the future and that's why the embargo of course on the right side today that's is that so to summarize for evaluation in violence is not that easy to identify of the residency in the training set that contained information using the test set and that involves two operations for it in the party now finally people number seven Vipers over media news so I thought it's a bit about these maybe you have already read my favorite I love all thinking essentially they is that when you compute another Baptist's even even if the Sharpe ratio of the strata is zero just by repeating back this practice practice eventually you're going to find an amazing strategy on the paper right and this is illustrated in this quad where essentially what I'm point is what is the maximum separation that you will identify out of a random process random Gaussian process which means your own violence whatever line segment whoever buys me you just repeat these practice a hundred times after a hundred times the width minus one the spectres are registered expected maximum Sharpe ratio the spectral messenger ratio is around two point five so it's very hard not to identify false positives it's almost impossible you know doesn't matter how well you back this you know you will you will try to persuade yourself and come into yourself but I found everything my report I cleaned the date I look forward I made sure that all these corporate actions were known at the time I computed I apply these transaction costs that are I found in this paper everything was like by the book and yet the fact is useless why because you repeatedly 100 times and and in smiling because you see the parody man the better you get back testing the less useful it is right you know I tested for many years visit thirty years so yeah I know how to like this and for me and to identify strategy in the back test that looks good is kind of trivial I'll find someone I just need to I know that is it run a few simulations and everything will be by the book right everything will be you know I apply this transaction coughs and it's times in the literature I need to deliver this way which is recognizing the theme in the literature but the thing is that you know you repeat this a hundred times you are guaranteed a an amazing shot ratios for the Baptist's so what is the answer the answer is not be back to subtly other than be smart you need to back this but you need to practice taking into account the number of trials involved in your discovery meaning that the more you practice they higher the threshold you should demand for the practice so after you have practiced something a hundred times you'll not be excited when you find a sharp edge of - you need to require Sharpe ratio at 1/3 and you have tested it out sometimes do not be excited by a shortage of five you need to expect the sharp edge upset and so on and there is no horizontal asymptote so if not like there is a level at which you know I found this at starting with the shortage of 10 it has to be true I mean it's a sharp edge of 10 no tell me how many observation how many trials it took to identified to make this discovery because if it is 10,000 probably is useless well this statistic that I call the deflated strawberry show incorporates a couple of things more not only the number of observations the number of trials involved in your discovery but also the number of the length of the of the sample in all the practice of one year the series took office its most strategies you find out there happen to have negative units and positive excess kurtosis in fact most of the attachments that you see being launched and racing fans have negative skewness and positive excess kurtosis and you wonder why why is it that almost all hedge funds out there have negative is finished and positive kurtosis well nobody there is no hedge fund manager that is targeting negative this is positive excess kurtosis but because everybody is being evaluated based on the Sharpe ratio everybody is trying to maximize the Sharpe ratio and as it happens is statistically you can inflate your Sharpe ratio by achieving negative skewness and positive excess kurtosis so it's kind of funny because nobody's targeting these to mention of moments because everybody agreed on using n statistic that happens to be inflated in those simpletons everybody ended up producing these sort of returns all right ladies strategy and I know I shall be 2.5 after mining one independent trials we define yourself what's the business that I use we need the skewness of positivism these salmon is called you and say we want invest and your answer is no why because once you take into account this is because the sample land and the number of trials involved in making this discovering the result in mind is only 90 percent probability that fish report the Sharpe ratio of 2.5 happens to be in reality greater than 0 so if there is a still 10% probability that the true fabric of this strategy which is the one that the fish are everybody is negative even though this diminish our values all right [Music] [Music] [Music] [Music] [Music] [Applause] cross-sectionally or oxidase well so even though one is to fit your method go back another one is to feed your face on some ways that occasionally and in that way is not that it is hard before we use and then one day or one where you want to use that way you have now the environment of choice will be the speed of that PA but it's not so much that we should use body my personal view is that you do not need to to achieve in any type of - 47% only stop so much to every to achieve is basically a we could we could buy a position of equal to seriously the I we have so much in your only copy of all the memory we've not really off of the civilization architects use this to the spot here is to preserve as much memories your hand and still being able to buy mystical methods and yes the implication believe that the students will not be hiding but that's fine because I am II know Miami has food is the size of a point is a hospital you need to it makes cross-pollination very hard it makes feed a very bar but at the same time that's why in fact we the goal is never to make a society or maybe the stationery you have to make a decision right off for you to apply these methods and at the same time deserve as much memory as possible even if certain that memory incorporates additional problems like reporting arguing of the [Music] [Music] [Music] [Music] you know [Music] well my my dear is that is a result of what is consider a an attractive track Network right the same that when you are when you're breeding dogs there are some traits that are considered preferable for the doctor is a shepherd dog and Una's have you sold these traits are preferred just because some referees garden and over time yes that's the dream right any converges into that and it is essentially something like that has happened occasions everybody like this operation a separate party ended up using the the Sharpe ratio this trade of negative is skewness a positive for positive which is very lenders it's an explosive combination happens to be the preferred one and eventually all hedge funds are normally ended up producing this combination even though it was not targeted right it's not we are is not realized you know that's exactly the point but this is for the bonus fraction is harder right because even though there is no event that has happened no last one they they have they have been selected like we develop dog races right they are selected by our aesthetic preferences but as it happens they are ticking bombs then you could say something about incorporating correlation into example 3 where you're talking about using dollar and volume bars yes because if you're forecasting a bunch of different series in that way then at some point you do take you would take time to quarrel over [Music] iiiiii oppressor you said something about using recent price data always set your contention that it's also good data what the recommendation is is this kind of data you think that more recent data is more relevant for the immediate future as opposed to data 100 years ago they couldn't they think the point is is how do you decide sample length and my answer was well rather than using some our retirees on land let's use all the data just with a an exponential decay in the waited so you you come up with your wedding with your supper waste and the of the reasons are our most recent are receive more weight than very observations but sometimes they're all invalidated by macro change yes yes well that's essentially what I'm saying is you you think your classifier with an exponential decay or the weighting and then you make sure that the practice is supervised in practice that for instance will be peed on very old a nap and then see if it company the present so you title this reason why funds fail machine learning funds fail does that mean that if we don't do this it's at the same set of reasons why machine learning funds succeed this is the kind of things I see whenever I hear that they fund grew up it was based on a silo model because people didn't practice properly because they take into account that observations are non iad also to all sorts of reasons right sometimes is our party and they are reported by the press and sometimes it is I you you interview candidates and this candidate comes from this case on WR and you ask this candidate so what did you do and they tell you what they do when you are taking notes of what you shouldn't after 20 years this is what I found us to most conferences that mean that that this is what you should do any will work if we have more for me but maybe I was lucky the next court date was for I think I think it's a it's always a combination of thing it's not like each of these patients at low are committed seven scenes sometimes they when videos were not not a very often you see that you know especially the fact that many people practice without controlling for the number of trials or they are forced to work in silos these are very very common reasons given or to hear you talk about a price volume but obviously to be a successful trader you need to look at many industries yes is that so yes I'm wondering if a lot of these funds into hiring statistic very often so that is also something very often look we all have tremendous respect for people that do amazing things in machine learning Silicon Valley voice recognition right and they are deep amazing things but the realities finance is different and for the same reason that we have you and I you have very little chance of developing a self-driving car well yeah developing a final algorithm these are well I think we'll end on on these wise words and thanks I hope that a lot of you 