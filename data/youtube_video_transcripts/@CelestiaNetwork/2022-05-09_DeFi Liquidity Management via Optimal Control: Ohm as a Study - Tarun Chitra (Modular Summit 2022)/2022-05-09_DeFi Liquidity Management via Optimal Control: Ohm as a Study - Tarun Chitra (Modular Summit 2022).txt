hello uh slight change of uh research topic but i'm going to talk a little bit about liquidity management d5 which i think in a modular world becomes even harder as we talked about earlier on the panel so uh i want to kind of talk through uh this recent paper i wrote um with three of my collaborators on uh on kind of uh you know how some of these mechanisms that i think maybe maybe they have misleading advertising there actually is some real thing going on uh from from a math standpoint and we'll kind of talk about that so just as a basic background you know what what's sort of the goal of of defy in this scenario it's really sort of in my mind this this concept of unbundling investment bank uh you know decentralized protocols basically you compose things they also let you automate things like incentive management of like how much you're paying users for liquidity in a way that was just not really true before but hopefully many of you probably know this uh you know i i think one important thing here i wanted to call out is like you you could basically compare side by side the d5 protocol version of the world to sort of their traditional finance version and the main difference is that incentives are sort of algorithmically optimized in the defy side amongst other things [Music] and uh you know if we zoom out a little bit they're sort of three-ish ish being a you know catch-all three-ish principal agents in d5 they're sort of liquidity providers who are providing liquid uh to be used uh for risky activities they're traders and asset managers who are actually trying to build positions uh also kind of you know synchronize their portfolios and then their keepers and the keepers are sort of the most important part who somehow need to be incentivized and compensated by the protocol for ensuring that some sort of high level kpi is met such as you know assets are always greater than liabilities so what is defile liquidity management uh you know protocols basically attract liquidity by offering incentives usually these incentives are some combination of fees and governance tokens or rights to some future governance rights sort of like the ve model but one problem is that protocols generally have many pools that they have to distribute incentives to think about say a sushi swap thousands of pools but most of them probably don't really need sushi incentives and the process of allocating incentives to different protocols uh and deciding how how to do that is default liquidity management so for the most part this is sort of important because if you overpay for incentives oftentimes what happens is you have much more concentrated token ownership um you know things becomes less decentralized if you underpay you effectively can't attract liquidity from your competitors and kind of can be cannibalized this has led to activist investing from the form of like urine convex etc and uh there's tons of examples of protocols that died without incentives uh because basically they got cannibalized so one one question is why is it hard and so this is sort of the problem that ohm maybe accidentally solved uh but to get some sort of intuition for why a protocol may have hundreds or thousands of pools that it needs to distribute incentives to uh and it can be extremely expensive gas-wise to to manage that state especially on chain secondly incentives need to be dynamic if there's suddenly a ton of volume in some pool and it's draining all this liquidity you need to actually suddenly increase your incentives and you know if if you don't rebalance fast enough you may have something where you're overpaying for one pool that basically has no usage and underpaying for another um and the last and most sort of subtle thing is these incentives interact with each other and cause can cause feedback loops so for instance trading volume can become correlated with liquidity because uh suppose a bunch of trades are driven to a certain pool uh then other lps notice the api has gone up then they add more liquidity the slippage in that pool goes down and then now routing algorithms like matcha one inch etc will tend to route to those pools more and this rich getting richer feedback loop especially driven by aggregators like aggregators who route orders to different places has is is also quite uh tied to how incentives are distributed so at a really ten thousand foot level we could view protocols uh incentive optimization strategy as doing sort of three things uh one is a they're sort of renting liquidity they're instantaneously paying for liquidity that could leave at any time two is they're sort of buying liquidity they might the dow might have a treasury it may have a ton of assets of its own and it provides liquidity to different pools and three is this concept of leasing liquidity and this is sort of the i would say the 2021 innovation in d5 of effectively coming up with novel versions of bond-like instruments where people commit to provide liquidity for a certain amount of time or for a certain amount of or to guarantee a certain minimum amount liquidity and then they get rewarded sort of in a time locked coupon like fashion so one question is can you automate liquidity management uh and uh i realized i didn't have a site that explains what ohm does but uh this is sort of abstract more mathematical definition what ohm does but at a very high level uh olympus dow has a reserve asset or what they want to be a reserve asset they wanted to have low volatility and so in order to kind of ensure low volatility the goal is to have uh basically the protocol decide how to incentivize people to lock up assets depend if the supply is too liquid and uh distributes more rewards if the supply is there's not enough supply and the high demand so abstractly however we could actually represent this as sort of a control theory problem um so how that works is you say we have sort of a notion of inflation that can be adjusted at every time step that's sort of the emissions we have n capital pools um and each capital pool uh you could think of as has some high level summary statistics so uh you know the reason this is in in rk here is k represents sort of like the summary statistics of the pool so for instance uh amm pool with two assets would you provide the reserves of the two for uh assets for each pool um or uh similarly for maybe like a multi-collateral asset pool you may have to provide all of the assets plus some extra state about the assets like how much is liquid how much is locked and uh then the other thing you do is you you add some uh you kind of have a objective function you can think this is like a kpi for the dow so maybe it's hey we want very low volatility given the pools and inflation and distribution of uh inflation that we have maybe we actually want high trading volume we want the the fees generated for liquidity price to go up that's represented by this function lambda capital lambda so uh the idea is that for each pool pi we add an incentive uh which is some fraction alpha times the inflation at each time and we can think of the the liquidity in the pool as sort of a random variable whose value is adjusted by how much incentives are paid to it and the goal is to construct an allocation rule which is how much of inflation should i distribute to each of these pools so that's sort of this middle line which says you know hey construct this probability distribution pi such that you know basically we optimize the expected value of that kpi over the next time period so maybe we optimize it in the way that we want the volatility to be lowered over one time period or maybe we want sort of the net fees generated to be optimized over one time period so again as i mentioned earlier you can really think of this in terms of like feedback loops right and so as a very simple description this sort of looks like a sort of classical feedback controller where our controller is the thing that's adjusting the inflation the amount of inflation distributed at each pool and so what we're really doing is we observe some pool values we choose the inflation and how how we want to allocate each of these pools and we make a prediction about the future pool value then we distribute you know we have some algorithm let's say which we'll we'll talk about in the next slide but just for now think of as an oracle that says hey here is the inflation you should how many tokens you should mint at this time step here's how much you should distribute each pool then you observe after one time period the real the real pool values and then you look at the difference between your predicted and your observed pool values if the difference is small then you can reduce your inflation you you actually have been able to predict pretty well and you can see if hey actually maybe if we spend a little less we can get the same result but if the difference is large then you may have to actually increase the inflation and re-rebalance the allocation uh and so you know one question that's natural is do we know if this is stable does it actually optimize our metric so uh what we did in this paper is we formulated this problem sort of generically in terms of optimal control so optimal control is sort of different than sort of what you may have learned in sort of like a initial controls class like a pid controller or something like reinforcement learning optimal control tries to have much stronger guarantees uh on sort of uh what what sort of bounds are on performance in the system um and uh these kind of bounds are actually quite important for something like incentive optimization where you really care about uh you know not spending too much money uh you know something like reinforcement learning has this problem of a you don't know if it converges and then b you also don't know if the variance of the estimator sort of grows unboundedly and so optimal control does have some guarantees and the reason this is a nice formulation is it lets you really control your budget for these protocols so the the main thing uh that kind of classical sort of control you know you what you do is you sort of construct a cost function which is a cost of what your expected payout and kpi is given given your incentive portfolio so the allocation of each a different type of inflation and then you say hey we're going to compute a value function which represents sort of if we start at a certain point in space so that means a certain set of pool reserves a certain set of inflation we compute sort of this minimum which tells us what's the minimum what's the sort of best action we can take given what we given our current state and this sort of gives you an iterative update that that says hey given the value function we can pick the next inflation schedule and the next uh distribution of rewards uh and then it turns out that you know it's a very hard equation to solve but there is sort of this equation that lets you solve for the value function called the hamilton trig hubie dominant equation now this is all abstract and in some ways it's it the reason it's hard is that differential equation the in fema minute basically guarantees you no smooth solutions for for for almost every type of uh game you construct um but there is one type of uh value one type of hjb equation that actually is you know very well known uh and people kind of understand concretely and it's also the one that's used in say like autopilot in a plane which is something called a linear quadratic regulator so just uh one thing that you know it took us a little time to kind of like read the ohm contracts which i don't think they were like designed in this way thinking that they were going to build this linear quadratic regulator i think they kind of wrote this code and hoped it worked and then you know got a couple billion dollars in it and then they're like okay i guess it works um but if you if you if you actually like read what they what the code is doing and convert it it turns out that if you do a coordinate transformation of how the ohm mechanism pays out incentives it is exactly this linear quadratic regulator and so what is a linear quadratic regulator well what it is is um basically maybe i'll just manually point so we have this stochastic differential equation and this uh value u is the control so that is how much are we inflating and how are we distributing the incentives in the protocol and uh effectively what you're doing is you're saying hey i'm going to you have a normal geometric branding motion so i have this the si terms there and i have this control which is trying to sort of either reduce the variance or reduce the drift and the quadratic part it comes from the fact that the lambda that you use here you use a quadratic function and so the idea is you you adjust your control so this is your inflation uh and your distribution uh in order to try to basically minimize quadratic loss and you know in practice the crazy thing right like if you show you know most people in crypto would be like oh who cares this percent staked distribution's not that interesting but you show this to like a control theory person they're like how the did this work like there's absolutely no reason that like the stake percentage should be this stable yeah given that like there's a lot of ways there's a ton of noise in the price process uh and so that's kind of what led lead led us to try to look at this so you know one thing that we showed is ohm has this mechanism where you give them an lp share you give them liquidity and then they give you sort of ohm over a time interval so like maybe you lock up your liquidity for a year you'll get paid ohm for a year kind of like like a bond like a linear interest and one interesting thing is that for the linear quadratic regulator that ohm has where you have you don't really even know what the state of the system is we basically showed that hey if you start with sort of random uh price random drift and random volatilities as long as you have an increasing number of bonds so number of durations of bonds the controller converges faster over time and so if you look at the ohm data the moment they start introducing bonds you actually see that basically the price volatility of the asset you know obviously it's drift has been very negative but the volatility has been shrinking and part of the reason is that these bonds act as sort of like a slowing a term that like sort of slows things down from from from an inflation perspective um so uh you know last few things uh you know one one one question is like hey this result almost seems like too good to be true that it's like that simple well well one thing is we didn't add in a bunch of constraints uh and when you add in the constraints of course you can't really solve this analytically anymore uh and so you know kind of seeing how well that that works um and and also note a bunch of the assumptions can be removed over time cool questions yeah i mean that's a good question um i i think like in general yes but only numerically you're not getting a nice like provable result right like um these like grandma type estimates don't really don't really work i think for generic functions so uh out of luck with that but yeah that's a great question actually uh so you could actually view this as the mean field limit and in if if because we're sort of assuming sort of some generic behavior like the distribution of agent actions is effectively the same which is why we're kind of can assume this kind of stochastic model of hey i have this sde sc has some like function that's controlling the drift and variants that assumption there is actually like a mean field assumption um so to zaki's point the way you'd want to analyze it for other functions is to go away to like move away from the mean field thing and like perturb by those kind of corrections but um yeah you should definitely think this is a mean field thing you know we're using tons of like concentration equalities uh assuming like large end limits and stuff like that so i think of this as the mean field result and you want to expand outwards to like the uh different types of agent uh scenario yeah yeah so i think uh i think their goal was well maybe not even mean variance optimization just variance optimization they just wanted low volatility um what it turned out is like what the the bond mechanism basically does some type of mean variance optimization i don't think they purposely did that right they purpose they started with this like pure farm staking thing it had no bonds no there was like nothing other than whatever 10 000 apy which you know there's no free lunch in the world uh but uh they didn't actually build kind of the uh the mean variance stuff until they basically started having these huge drawdowns um but what i meant by they backed into it was they were just like oh look our token price is crashing let's like try to get people to lock up their tokens and then they made this mechanism now do they have some divine insight i don't think so i think they literally were just trying to like throw things at the wall and see what reduced volatility and that too it's also not obvious they were doing mean variance optimization um there's sort of a non-trivial coordinate change you have to make uh in in the way they've done design their controller which is in this paper but uh nevertheless they kind of ran into it on their own i i mean i think like the long-term thing is you have all three right like you don't yeah i and i think the interesting thing that ohm's bond design showed was like you they kind of had all three uh because you could view the staking like the ohm locked and staking as a zero duration bond and that's like effectively renting um now of course it wasn't really providing liquidity to anyone and the protocol is just getting locked up and doing nothing but uh i think in the long run it's going to be all three like i don't think it's going to be purely rent or purely buy or purely at least and that market conditions will dictate that there might be i i mean i that's why that's why formulating it as this control problem i think basically lets you say like i could design something that takes the bond aspect from ohm takes sort of the like full protocol own liquidity aspects not just like leasing uh from say like a fae or something like that or orca i guess now um and you can merge them together under the same controller that's just allocating to like how much do we spend on buy rent and lease and that's sort of like the natural next step if you took this paper and wanted to like extend it or like make a protocol that's like new from it you would basically try to build something that is a controller that's allocating to those three like decides instead of it just being like hey we're allocating these from these different pools and we cover this in a section in the appendix you could have something where you have duration weighted uh liquidity so your objective function is not just quadratic but you say uh i want i i value least liquidity more than rented and you account for that with like a time dependent factor like how long it's locked up the longer it's locked up the more it contributes to the objective function and so you can definitely do that you unfortunately lose the analytic solvability so uh you know if you've ever done any reinforcement learning or or game simulations you know that basically it's your analytics solutions are basically impossible for these types of things the moment you add any constraints so else yep cool [Applause] 