the reason that we wanted to do this space is that we're we've been exploring a lot of different Core Concepts to modular blockchains and just blockchain infrastructure and research and The Cutting Edge of what people are building and so you know more recently we had a Twitter space about solving Roll-Ups then we did one about intense and a natural topic to follow up from those conversations is about ZK or zero knowledge proofs I think everyone has definitely heard of zero knowledge produced by now if you hadn't haven't you're probably living under a rock um and zero knowledge proofs are extremely exciting but they're also not very well understood and so we've invited three speakers today to help Enlighten us explain you know what zero dollars proofs are how they work how they're going to be used in the blockchain stack and Beyond and so I'm really excited to introduce our three guests today so we have Brian retford from um risk zero we have Preston Evans from Sovereign labs and yisun from Axiom so to kick things off why don't you guys go ahead and introduce yourselves and tell us a bit about your guys projects okay sure uh so uh Brian Redford CEO and co-founder at risk zero and our Focus that was zeros is on enabling anyone to use zero knowledge technology by leveraging existing code base so our sort of core open source technology is through zero ZK VM which actually implements the risk 5 instruction set which is just a complex way of saying that it lets you run normal code in a ZK verifiable context without needing to program custom circuits uh yeah our Focus right now is um you know maturing that technology and also bringing our sort of uh massively parallel high-speed proving Network to Market that's called Bonsai yeah thanks thanks for having me here thanks Brian Preston or ye sorry go ahead hey everyone my name is yusan I'm one of the founders of Axiom we're building a way to use ZK to provide application specific scaling to Smart contract applications and or packing that in something we're calling a ZK co-processor that allows smart contracts to trustlessly access more data and do compute over that data and as part of that we're building an open source library of zkproof Frameworks that we're allowing anyone to use to build their own Zeke applications awesome and then hey everybody I'm Preston Evans I'm the CTO at Sovereign Labs uh Sovereign is a company that builds tools to help you build the UK Roll-Ups so basically we saw the great work that Brian and many others were doing at the bottom layer of the stack making ZK proofs more accessible but we looked around like the only teams we saw actually using those things in production were extremely well-funded and extremely technical companies so you've got the you know 100 million dollar seed round kind of startups and you know we wanted to solve that problem as well so what we do is we let you write your business logic in Rust and then we integrate with a number of ZK VMS including risk zero to convert that into a fully fledged ZK roll-up so basically do you act much more like a smart contract developer but you get deployed as a sovereign roll-up running on top of any da layer that you want foreign guys um I think you guys are all way too humble uh I think I'd love to hear more about your backgrounds there you guys are all extremely smart and um knowledgeable in the ZK space and have accomplished a lot um but I think the first thing I want to do is establish just a baseline background of um about ZK that we can build off of as we go deeper into the conversation so um I'd love for someone to take a stab at you know explain it like I'm five on zero knowledge proofs like what what are they how do they work at a very high level and what are they useful for thank you I did I did write something down here I'm actually going for the explain it to somebody like they're five so I don't know if people have this outside of the states but um uh if you're like sick and you miss school you're kind of required to produce this like note from your parents proving that you're that you're sick and it's like this gets you out of being in trouble um however so I think that the ZK proof is kind of like this you know uh it basically is uh a portable note that proves something about you um in a limited sense that you can then present to somebody else who can in theory like quickly verify it to to produce you know some other sort of desired action on the basis of the the truth of that receipt so uh in this case you know this note proves that you we're sick to your teacher without revealing any of the details of you know how exactly exactly you know how you were sick um and this is like a way for computers to do this zero knowledge proofs about any kind of any kind of data um except for you don't need to like trust a parent or a teacher that actually removes any kind of need for for a trust relationship there the the sort of validity of the statement is encoded in the statement itself people I like that yeah um we've all I think experienced that and being sick and and uh needing a way out of it um do Preston or uh Yi have any uh sort of further analogies you guys want to use or maybe expand a little bit about what what Geo knowledge proofs are useful for yeah I can talk a bit about why zero and entrepreneurs are especially interesting for blockchains so the core principle here is that when you validate a blockchain you have to re-execute all the computation that's being done by everyone globally so for blockchain like ethereum or roll up on Celestia that's extremely expensive it has a lot of redundancy what certain all truths allow you to do is to have one person or machine execute some computation and prove that they did it correctly and then everyone else only has to verify that proof which is much cheaper so the difference between everyone re-running every transaction and only having one node generated proof of validity of that transaction is fundamental gain that's your own Ultra proofs give for on-chain applications cool that was very well put yeah the last thing that I would add is that there are two very cool things about ZK proofs so one of them we've touched on is what people call sickness that's this property that he was mentioning where it's much faster to check the proof than it would have been to do the computation for yourself the second thing which we haven't touched on yet is zero knowledge or privacy you can prove something about a computation without revealing other things that you want to hide so kind of the canonical example here is like maybe you could prove to somebody that you are over 21 and you can buy an alcohol drink without revealing your actual age now that's not a very interesting example because it still relies on a trusted third party maybe a more interesting thing is that you want to reveal to somebody that you have the right to spend some money without revealing what your bank account number is I like that so the the clear two um key features of certain entrepreneurs are the succinctness property which means that you don't have to actually recompute something on your own so you don't have to like duplicate all this work you can have one node do the work and and generate a proof so that other people can just verify it and be done and then also there's this notion of privacy that you don't have to reveal the exact details but you can prove to someone that a certain statement is true and I think both are like extremely relevant in blockchains because blockchains have this problem of you know forcing everyone in the network to verify things and if everyone has to do that redundantly that's way too much work and then also blockchains have this problem of sometimes you know they're public and transparent and they should be but um perhaps they're too transparent and we need to find ways to um only share the information that's necessary and be able to keep other things private because we don't want our whole lives if we transition things on chain we don't want our whole lives visible there um to continue the the expand on this this Baseline uh background I'm curious if there's any like key first principles um or like building blocks that people should know about zero knowledge proofs and how they work that is like helpful or helpful mental models so they can kind of like reason about them so are there things that have to do with like the cryptography involved or maybe there's certain Concepts like you know proving systems or circuits the ZK circuits that um people should have yeah some kind of mental model of so they can understand what's actually happening I think it might be helpful to have just an API level view of how you actually can concretely create a zero and Ultra proof from a computer program that you might want to run let's say on your normal computer and so there's basically a two-step process the first is you have to translate that computer program into what's called a ZK circuit so this the word circuit there is an analogy for a physical circuit for a physical computer chip and in decayland it means that you have to translate your program into a system of polynomial equations and those equations have to be somehow equivalent to the execution of your program the Second Step once you've done that is you can apply a cryptographic algorithm called a proof system to prove that you've actually run the program successfully and thereby produced a solution to the system of polynomial equations so whenever you hear people talk about ZK circuits this is these are polynomials over these certain large Prime fields that they're actually referencing um so whenever uh VK companies build circuits what is actually happening is that there are specialized ways of encoding certain programs in these polynomial systems yeah uh that's like an excellent explanation I would say like from a ZK VM perspective it's slightly different because the circuit is actually uh like a machine that interprets other programs um similar to an actual processor so in this case you know in the case of like Risk zero and many other kind of zkuvm systems you know the circuit that's described is is a circuit that can take in another program and then produce a proof of the sort of correct execution of that program through through a VM um but to the original kind of question I think um understanding sort of Applied cryptography and and some of the key like features of ZK like what does it really mean to commit to something you know what aspects of the particular circuit are actually private um you know in what circumstances might you be actually leaking information that you expected to be private or where might you not be committing to things that you need to commit to in in order to actually be proving um you know what you want to prove within pretty tight bounds so I think this concept of like committing cryptographic commitments is is really critical Preston you have anything to add I think these two guys covered it really really well the only thing that we might want to touch on really quickly is just some of the terminology that we throw around um so you mentioned the notion of a circuit you'll hear people people talk about circuits all the time if you hang around ZK spaces the other things you'll hear are words like snarps or Starks or plonk all of those are that tool that you mentioned the proof system which converts a circuit into an actual proof so snarks and starts and proofs are all just like slightly different underlying mathematical implementations of the same broad idea awesome that was that was a great background um I think it makes a lot of sense to imagine that you can take your program express it as a polynomial and then it like if you have a solution I guess that I'm assuming it's like an equation it's very easy to verify that it was that that it satisfies those constraints or or what have you and I I don't know I heard this is like my own understanding but I remember listening to some podcasts where the way that the sickness works is is sort of like you you kind of like check you don't have to check the entire computation you kind of check it it's like probabilistically true like your proof is not actually like 100 true but there's because you check it at certain intervals or something throughout the execution like you have a probabilistic guarantee that's extremely high that the the proof is valid is that and someone explain that concept I'm gonna let I'm gonna leave that one to Yi I think I could I could explain it kind of poorly but um it's roughly correct though yes um you know it involves error correcting codes and the outshimir as well uh to really you kind of have to understand both of these Concepts I think to to understand uh you know really what's going on there at least from that start perspective yeah well rather than getting too deep into that let's we will save that for a little bit later uh that's my own like intellectual interest um but I want to also it's just like the last part of background uh talk about what are the um main applications of zero knowledge technology like in terms of the overlap with blockchain so you know people talk a lot about things like privacy obviously there are things around and that kind of also encompasses identity um there's this new field of co-processing and zkml obviously there's Roll-Ups and bridging and and things uh more on the infrastructure side um I'm so I'm curious uh if you guys have can give like kind of an overview of the different applications that you can see um for ZK in in crypto and blockchain sure I'm happy to jump in here um I think you gave a pretty good Roundup actually of a lot of the things that people are very excited about um just to sort of briefly mention you know um this all goes back to those two properties we talked about before of privacy on the one hand and scalability on the other um ZK is great for both of those things and it can be great for the combination of those two things so in general if you're looking at a problem and you say oh this is great but I wish we could have some way to do it privately then you should probably reach for ZK or if you're saying oh this is great but it's too much work because everybody has to check it then you should probably reach for ZK so uh Roll-Ups are a fantastic example of this people build roll ups because they want much more scalable blockchains and people build roles because they want privacy um so that's of course the thing I'm biased towards because that's what we do at Sovereign but there's you know a lot of other really exciting things that I think are developing and will gradually come out in the space um so I know Yi has done some some interesting work around ckm if you want to chat about that a little bit yeah definitely um our general orientation at Axiom towards using ZK for on-chain applications is to enable developers to do new things that they really couldn't before and so they came out as an example of that uh so as you came out it's a very fancy acronym and a lot of people are hyped about it but it just means that you take a neural network or any other machine learning algorithm and you treat it just as a computer program and as we're mentioning you can verify the correct execution of any computer program using ZK and so in particular you can verify the correct execution of a neural network and you can also verify that execution while hiding certain inputs even hiding the network itself or other fancy iterations so our vision at Axiom is we want to allow on-chain applications to be able to use the outputs of these very complex computations that wouldn't really fit into any blockchain VM basically we don't think it's ever going to make sense for you to train a neural network or run a neural network on this time shared VM that anyone in the world has access to instead we think that you should be doing that on your own generating a proof to a blockchain or roll-up that you did it correctly and then sharing the outputs with the whole world and So within dkml we've done some work to actually enable that for some of the larger scale neural networks that are in production around you today I don't think I've muched much to add there actually I think that was that's an excellent uh coverage of that cool um so let's transition a little bit more into some of the deeper questions around ZK um obviously the title of this you know conversation is um exploring ZK proofs within the modular stack so there's going to be definitely an infrastructure and modularity bend to some of these questions but I also want to leave room for um lots of of just like pure ZK or even you know things around zkml which it sounds like a very interesting and Powerful use case but my first question is like what is holding back ZK from more widespread adoption is it the cost of generating ZK proofs is it the the speed like the fact that it takes so long and is slow is it that you know the developer experience is kind of difficult um like you know it's it's hard for people to actually program um ZK circuits or is it something to do with like the security like people you know don't feel comfortable in trusting lots of value to these systems because they are kind of relatively new cryptographic um you know Primitives um so I'm curious if you guys have any thoughts on on that yeah I mean I think it's uh it's yeah really just overall maturity and I think all of these are kind of factors in like what a sort of mature technical system looks like so it's great to see you know people like saw uh building you know user accessible kind of Frameworks that take advantage in CK because you know I think it's Preston said start you know it's pretty complicated right now and so I think there's a just some learning that we as an industry have to do in terms of like what design patterns um are going to be most useful at what sort of different layers of abstraction and then similarly you know you can see a lot of debates going on around the exact security level of various protocols and really debating you know what's necessary for for securing certain amounts of assets and I think there's just a lot of sophistication of the way the industry like talks about these things as well as you know measures these things and we're starting to see a lot of that work get done so foreign yeah I think Brian is spot on there um two things that I would add are first on the security front um I think there is a bit of confusion in sort of the broader Community around the security of snarks there's two Dimensions to security right there's the security of the underlying protocol that you're using and then there's the security of the implementation of that protocol so implementation that's true are often very new and you know uh lots of teams are doing great work around making implementations really ready for Prime Time use um so implementations are are new and maybe a bit untested so there are some very justifiable security concerns on those fronts especially if you're using a brand new tool on the other hand the protocols we're using are not new and risky in the way that a lot of people seem to think they are so things like Starks are pretty you know they're based on hash functions which are extremely extremely well studied now sometimes people make riskier cryptographic assumptions in the Quest for perform for performance of course so it you know your mileage may vary from protocol to protocol but in general I'd say the the risks are really at the implementation side and it's more a matter of good software engineering at this point than it is of you know new research and development um although there is some very exciting new research coming out as well and then I guess maybe there's some communication challenges for us collectively to sort of explain some of this to people better maybe I don't know it does seem like a constant kind of you know fear that's in the background so um yeah seems like as an industry you probably need to develop some educational materials around us and from my perspective like I I always heard people you know critics of cka say oh well you know security is unproven and we kind of point to things like hash functions which are you know you never know until they're secure until they've like been around for enough time um and uh I think maybe maybe hash functions are harder to prove that they are secure than like a some kind of um you know cryptographic tool like um like ZK proofs and and there's also the I think there is a um conflation of the implementation security and then the actual like underlying Theory security that um that Preston touched on I definitely was not aware of that but obviously there's always implementation is always risky and error-prone so that that um if that's the case then I think people which yeah there's definitely a communication gap there you do you have anything to add yeah definitely would Echo the concerns around security that Preston and Brian highlighted just communicating that security I think a different factor is also performance so I know about everyone in the audience but I remember trying to run a z cash transaction in 2018 and I think it took at least 10 minutes maybe 15. and we've come a long way since then I think maybe this year or last year was the first time that it felt that CK proofs could concretely reach levels of performance to be useful for the first applications in a more scalable way and so that's progressing very quickly with the new waves of proof systems that are coming out and I think there's this trade-off between performance and developer experience that the space as a whole is working through so once we're able to get the best of both worlds I think it'll be much easier for an ordinary developer to use EK but in regards to Performance is it not it's not just the speed right but also the cost is like huge you know to for example prove one roll-up block or something but go ahead Brian yeah I mean you're just starting to see that really drop in in a lot of places though and you kind of you know computations get past this like uh you know if it costs 15 to approve one needs transaction that's obviously way too much but you know you only need a couple like find you know 100x Improvement before it starts to become reasonable but we're seeing those kinds of improvements in improving systems like you know like all the time so we continue to make huge like Leaps and Bounds in the performance of our system by parallelizing things and seeing all of this amazing research and the sort of Stark based ecosystems as well yeah certainly cost is a factor for a lot of applications but in the context of blockchains um you know what we expect is for the cost of the data you're posting onto the L1 to Far and Away be the dominant factor in your total price um so you know I think polygon zkevm is claiming something on the order of like a tenth of a cent per transaction or a hundredth of a cent per transaction and we've been doing some back the envelope numbers and you know we certainly think that subset transactions in terms of proving costs are extremely achievable even without needing you know crazy performance optimizations um so you know cost obviously matters more for web scale applications but for blockchains I don't think that will be a factor going forward got it um so it sounds like so we covered you know a couple of these the security is you guys don't feel as it would just kind of misunderstood but this performance cost and developer experience um is is a real problem that the industry is trying to tackle and work through is there anything like what do you where do you think the most gains are to be made is it at the you know the proof system level uh is it like in like deep research is it at the sort of implementation level like software um or is it in Hardware optimizations like where and how do we actually solve the problems that are blocking ZK from being more widely adopted I'm sure Brian has an interesting perspective on this but I think it's it's a little bit of all of the above um we've seen massive massive improvements in proof systems over the last couple of years and I expect that to continue going forward um specifically there's some really interesting research around folding schemes that we're keeping an eye on and then there's also some really interesting research about using even smaller finite Fields than we use today um so I think risk zero was actually one of the teams that led the charge on this they use one of the smallest Fields that's that's live today and there's more work going on on that front yeah feel free to jump in Brian yeah I mean I think it's all it's all of the above you know it's like there's you know a pretty like obvious potential for some of these like advances and the sort of core research to you know very meaningfully change the change the sort of scaling properties of some of these systems on the other hand you know just pure engineering seems to yield you know a lot of a lot of really positive results you see this kind of work land is doing with uh with Cairo and then also just you know we've been focusing on performance a bit more and you know it's very easy to to find like sort of large large performance uh opportunities um by by just engineering your system more intelligently and then of course there's this sort of core ability to um to parallelize things and that's something we've been focused on a lot and I think also with these folding schemes you'll start to see the ability to really use a much broader set of much cheaper machines to do very large computations although as Preston points out you know if you look at the like polygons numbers you know for blockchain context we're kind of like already cheap enough for most applications I think you know one thing maybe to point out is that there's kind of a coupled relationship between the developer experience and performance essentially if you can get performance good enough and cost low enough then it's fine actually to be a little bit wasteful in your circuit design and precise implementation details so that developers can do things in a simpler way and so as the proof systems get better and the hardware gets better we can actually Design Systems to optimize for the developer point of view rather than just eking out every last inch of performance you guys are throwing around some things that I think most people aren't familiar with although I keep hearing about you know this this term folding schemes um Can someone just unpack that a little bit more and like what what is its role and what do you guys what does that mean and why is it important and I also think it would be interesting uh to talk a little bit about recursion too because I know that's a really big part of um you know making ZK proofs more practical and I feel like there's um you know I remember in 2018 going to um a presentation by the founders of of Coda or formerly Coda naomina and like at that at that time it seemed absolutely crazy to that you might be able to actually recursively prove DK proofs um but now that's very much a reality so um can you guys explain some of those concepts for people and why they're important yeah I can take a crack at folding so folding is a sort of new tool in the ZK toolbox that was introduced in I believe early 2022 and or maybe like 2021 and it's the idea that you can take two ZK proofs of different instances of the same statement let's say applying the same function twice on different inputs and you can generate a random combination of those two statements and only generate a zero knowledge proof of that random combination and this can scale up so I I gave an example of two statements but you can imagine taking a random combination of 1 000 statements randomly combining them together and only generating one proof and so the whole idea behind folding which was introduced in the Nova paper is to find a way to make that cryptographically secure so that your final proof will actually imply as you're an entreproof for your original 1000 statements now obviously there's a huge savings there because instead of generating 1 000 independent proofs or you're at the end only generating one proof for What's called the folded instance and so this idea has recently been kind of weaponized in several different instantiations at first it was in a very limited context and now it's been discovered that folding can be applied as a generic tool to many different types of proof systems and so folding allows for very cheap instances of what's called accumulation where you take multiple statements and group them into a single thing to be proved I think maybe Brian or Preston can talk more about other approaches to that that involve recursion yeah I mean recursion uh as you pointed out you know me knows the sort of the pioneer one of the pioneers of actually building functional recursion systems and actually it's still like probably one of the easiest ones for programmers to experiment with but recursion is simply the idea that yeah you can inside a ZK program verify multiple other ZK programs so you can take similar to this idea of folding if you have 10 proofs you can then pass those 10 proofs into a ZK program which is something that verifies those proofs and then it will you know produce effectively one proof that verifies all 10 proofs and because kind of you know Nest that procedures as many times as you want to to get down to a single proof so we do this a lot in our Bonsai service and we sort of utilize different properties of starks to be able to chunk programs into very small bits that can be parallelized run on a bunch of different machines and then realize recursion rather than the sort of folding property to produce one succinct proof so this is really just you know kind of nesting the succinctiveness capabilities of zero knowledge proofs to produce a very succinct single proof Preston anything you want to add I think these two guys covered it pretty well maybe taking a step back and looking at the very high level from a very high level folding and recursion are pretty much the same the same rough idea the idea is that you have a bunch of things that you want to prove to somebody but you want to do it as cheaply as possible for yourself and make it as easy as possible for them to verify so instead of making 10 separate snarks and then sending them all to that person over the network you combine your 10 snarks together and then just send them the combined instance now technically speaking folding lets you um sort of skip a certain portion of approval work but there's a trade-off that's involved you have to use basically like a larger finite field and actually use some group arithmetic so like there's mathematical trade-offs involved but both of them are the same sort of high level technique let's combine a bunch of groups together and then send the combined proof to somebody and it'll be just as fast to verify or actually much faster to verify than verifying all 10 of them separately got it um and as I understand recursion has uh is very important in terms of actually proving the entire you know like blocks of a blockchain because as I understand you know each like let's say you express your VM as a circuit is actually a limit to like the size of the input that you can like pass to the Circuit to prove but like the the size of an actual block might be much bigger than that so then you you prove like smaller chunks uh in in parallel or or and then and then you kind of like uh recurse them up kind of like make a tree in which you like prove uh those proofs um through recursion into like one master proof uh is that the right way to think about it yeah definitely although a z points out you know folding is a different mechanism of proof aggregation with and as Preston points out the goal is really just to get down to what you know a sufficiently succinct proof for your use case which obviously you know if you're talking about um proving you know state or data availability or things like this between different you know blockchain systems you know making these proofs as small as possible it seems to be pretty pretty important mm-hmm so one last question just on the fundamental stuff and then I want to transition a little bit more into the applications and the the blockchain stack and infrastructure uh is why is it that certain types of computations that seem you know pretty easy and straightforward are so expensive to do within the ZK circuit so things like hashing you know like cert um like why is hashing like a Shaw 256 hash so expensive or even as I understand Preston like certain kinds of serialization are are really uh expensive to do within a ZK circuit so like what's going on there and like so why why do we need you know people are developing a ZK friendly hash functions like Poseidon like why do we need these things um I just have never really understood like what what's happening under the hood that makes this so difficult so the core reason for this goes back actually to the definition of a ZK circuit as a polynomial over some prime or so over some prime field so the problem is that every variable you use in ZK is not sort of a binary number like you're used to on your computer and uh actually is that the core of these hash functions like shot 256 but rather a number of modulo some prime that's you know could be small like is used in wrist zero like a 32-bit prime or in these elliptic curve based snarks a 254 bits or even 381-bit prime and so the problem is just that you have to express a binary operation for hash functions in an operation over this Prime field and so the conversion between the two is extremely uh has extremely high overhead and maybe to give one cartoon of why this is the case in some cases you might be using one prime field element which perhaps is 254 bits or maybe 381 bits to represent something that you know is a bit so zero or one so obviously that wastes the other 253 bits and that's the source of most of the overhead for hash functions okay that makes a lot of sense because yeah hash functions are always like bitwise operations just like a ton of them and um it just that doesn't really play nicely with like the sort of fundamental mathematics of ZK proofs Brian to go ahead right I was just going to say and that's exactly kind of what Poseidon and other kind of finite real friendly hashes kind of you know move away from these kind of very bit like heavy bit wise operations and more into like algebraic operations that can actually like be executed in the sort of you know finite field that everything else is happening in I'm not an expert at exactly how all that works though okay cool that was something I've wanted for a really long time um all right so my next question is also I think more more directed towards Preston and Brian but you know I I feel like people have been talking about ZK abms and and you know building ZK Roll-Ups for years now and yet we only have just finally started to have the first roll outs of actual implementations of the zkevm um why has it been so hard for people to build like ZK virtual machines is it because the evm itself is just not you know a particularly easy uh VM to sort of like put into this kind of structure or is it just you know we didn't understand ZK stuff well enough to you know prove General generalized computation like what what has been the thing that's like bottleneck this and um is that is that going to change yeah it's a really good question um I think we really have hit an inflection point in the availability of these systems so before maybe three or four years ago ye maybe jump in here I can't remember when the Halo 2 paper came out um but before then you know proving non-trivial programs was basically just impossible it wasn't like you just needed clever engineering or you needed you know to spend more money on compute it was essentially impossible um that was only a couple of years ago and then since then there's been this Cambrian explosion of proof systems getting more and more efficient you know you had Halo 2 and you had plunk and you had now you've had all the Nova related work you've had Starks we've had you know tons and tons and tons of um of proof systems which are just way way way more amenable to proving on the the sort of Hardware that actually exists in the world so that's one reason why it's been so hard historically is just because you know these crew systems just appeared a few years ago and none of it was very well understood they were all academic papers which are you know extremely complex and so like really only phds were working on these sorts of things so it just takes a long time to actually build implementations and all that sort of stuff so there was that whole factor and then there was also the whole factor of the evm being a pretty snark unfriendly VM I think it's gotten much less snark unfriendly in the last couple of years because snark systems have gotten so much more capable but before a couple of years ago the evm was kind of like it was kind of unimaginable that you might try to prove the evm so basically the technology just came so far in the last couple of years that suddenly these things are just way more feasible than they've ever been now the other answer is that people got excited and it turns out when you put a lot of smart people on a particular problem it's often easier than you think um and so you know not too long ago there was no one working on ZK EVMS and then a couple of years ago suddenly everyone was working on zke avms and a couple of weeks ago suddenly we had you know three or four first zke EVMS all within a week of each other so I think that's that's a lot of what happened yeah in a certain sense like the evm is is as hostile if not more hostile to like ZK proving than these kind of old school hashes right it's it's not it was never designed to be turned into a computer or a ZK proving system um so I think it was just always a huge challenge for ZK but I think part of part of the reason ZK has advanced so much over the you know past couple years is exactly because people really wanted to prove the evm you know with it and it just required uh you know mini advancements along lots of different axes and just massive improvements in code quality and optimization across the board so now we kind of have that so um yeah it's just a huge set of new things is going to be possible with CK over the next couple years and specifically though go ahead yeah go ahead I found an app one last right here about the that this illustrates a trade-off between the developer experience and the difficulty of snarking a VM or putting a VM in ZK so if you look back at Cairo from starkware I think that was probably the first ZK virtual machine that got any level of usage but Cairo if any of you have looked at it it's very adapted to ZK fundamentally and so that's a lot easier to implement but that means that the developers using pyro have to know a little bit about ZK whereas if you look at ZK EVMS developers really in principle are not supposed to know that there's even ZK going on you just write evm code and so I think those are almost on polar opposite ends of the spectrum of difficulty and developer experience that's a great point and I want to dig a little bit more into that because from what I've seen there's a lot of there's a like a couple different approaches to making ZK VMS practical and and also have have like friendly developer experience right so on on the one hand as ye as you mentioned there's approaches that the software team have taken which is hey we're actually going to build our own you know domain specific language and like you know our own VM that's tailored to ZK and that way it'll actually play nice with the the proof system and all that stuff um and maybe you can also design in a way that's like yeah just just more optimized essentially but then we've also seen other approaches and I think zero is really a good example of this where um you know you can use an existing you know VM or like instruction set um that you know a lot of different languages can compile down to and just build a proof system or proverb like for that and that way you know like developers don't have to learn a whole new uh programming language they just kind of use what they already know and it can be made compatible maybe like Risk uh five is not the like the most optimized um you know VM for that but but perhaps like that's that's a fine trade-off for the fact that like the developer experience is better like how do you guys see this um like these two approaches is this the right way to think about it are there more approaches and like what are the trade-offs foreign yeah I mean there are definitely lots of approaches to doing um to building developer friendly like Pathways to ZK certainly you know while risk five I think it's pretty well suited for ZK but obviously you know the uh really cool work by the maiden team and the train team and all these other people building you know very ZK specific Cairo itself obviously um you know all very valid approaches uh I think I think Chris fight strikes a pretty reasonable balance but you do see still the need to provide access to the underlying proving system for certain operations like hashing functions or elliptic curve cryptography so you know we have one perspective which is like focus on the general purpose and provide access to you know acceleration Primitives for uh for other people to build these like uh small accelerators and kind of attach them to this general purpose system but there are lots of other approaches yeah I think we'll come to look back on the current ERA of startups or maybe maybe now it's already the previous era of Snorks but we'll kind of look back on this the same way we look back on people like handwriting things in assembly code right so like in the early days of computing performance was so bad that you really did need to handwrite your assembly and also the tools like compilers just weren't Advanced enough to generate optimal code for you now we're getting to the point with CK where yes you could get better performance by handwriting things in many cases but for almost everything you want to do you know the vast majority of your logic it's still going to be cheap enough that you don't really care and then for a few specialized things like Brian was saying you probably do want to implement you know sort of the the cryptographic equivalent of an Asic for this particular operation um so we're really excited about those approaches you know at the end of the day we think developers kind of are the Ultimate key to getting these things in people's hands um so we're really excited about developer friendly tooling now the other great work that's being done though and you know people like start wearing Lambda class are doing great work as well on making the more ZK friendly environments more developer accessible as well so the gap between those two systems is is slowly narrowing and we're excited to see what comes from both ends of it he was there anything you wanted to add on that point maybe just wanted to Echo Brian's point that getting the interface right between these more generic system part of the system where maybe performance is not as big a concern and these uh specific uh computations like hashes or elliptic curve operations or even things like ckml where performance is quite critical and does at least right now need to be hand optimized is one of the bigger challenges right now in the space I see so there's this kind of Merit to both um both approaches and and maybe there's like a hybrid that that allows like kind of the optimal trade-off um that's very interesting yeah you're starting to see like uh the Validia effort by like uh Daniel and other and I'm not sure who else is working on that um that you know delendum's working on you're starting to see people kind of uh evolve this notion of what a ZK system is and starting to look you know more and more um kind of unsurprisingly to me like kind of like patterns we already see in actual um computers so people are starting to think of you know actually having kind of the equivalent uh of bosses to connect these different components um and you know to Yi's point I think zkml is you know if this becomes uh kind of an important part of of how all of these systems operate like I think it will you know you're gonna definitely have the you know moral equivalent of a of an Nvidia chip that's sort of attached to your ZK proving system um specifically focused on density or algebra whoa so there's going to be like different components that can communicate with each other but then they each kind of have different functions sort of similar to like how you would have that in a computer architecture that's that's super interesting um and you guys keep on talking about Hardware and you know one of the things that I understood at least about this year's approach is that for example or just generally like this taking an approach where you use a more common sort of instruction set is that it it plays nicer with Hardware optimizations um but in general I I kind of open up the topic of like what role does Hardware acceleration uh play in making ZK proofs like the performance with the speed and also the um the cost uh better um because that does that does seem like something that people talk about a lot but I really have no idea exactly what what's going on there I can talk a little bit about um yeah so certainly uh you know we didn't we picked us five for a bunch of reasons none of which actually had to do with you know potential suitability for Hardware acceleration although you know we're starting to see witness generation become a bottleneck in certain points of the system in which case you know it's probably kind of nice to have um a more like actually physically friendly kind of micro architecture as your primary kind of um circuit uh that said I think that the advances in folding and sort of recursion and continuations and these kind of things are really going to be the thing that makes Hardware uh the ability for a hardware confirms to deliver chips like much more of a reality you know when you're when you require like 500 gigabytes or two a terabyte of ram it it really massively complicates the process of building an effective accelerator but if you can push those memory requirements down then you can start to do like you know hbm interposed directly on top of the logic and and you can probably start to achieve really that's kind of astonishing performance improvements um you know I think prior to prior to these kind of techniques existing I was kind of a believer that gpus would be the the primary way in which proving systems are accelerated in the you know three to five to ten year range but I'm really starting to actually become pretty optimistic that there will be some specific Hardware that's going to provide some really amazing capabilities yeah so so is it going to be so you're saying that they're going to be Asics rather than just gpus I think there will be some Asics in the next yeah one to three years that actually um yeah provide meaningful performance bumps for all several different sort of proofing systems president any any thoughts on Hardware stuff yeah I think with Hardware there's the core challenge is that the proof back ends basically the proof system part of generating is your knowledge proof actually involves some pretty heterogeneous uh operations and so those are also changing all the time as proof systems get more evolved maybe we're using different types of prime Fields different types of elliptic curves or different types of hash functions and so I think the challenge for Hardware companies is to be able to develop a system that's generic enough to not get outdated in let's say one year but still custom enough to actually deliver performance and so a big part of why gpus have been really popular is of course you're not taping out a GPU so you can actually evolve as a proof system evolves we're also seeing companies work on fpgas which are sort of intermediate between a GPU type solution you can program your fpga it's much more difficult and the end point of course would be an Asic but I think the challenge there is how can you make your Asic generic enough to accommodate some change in the proof system although maybe you can't hope to get something fully generic sometimes like the because the proof systems and the underlying technology is not yet hardened or sort of like uh I guess like at a level of maturity where we can kind of like um I guess use it as a foundation it's a little bit hard to to sort of like make these lower level optimizations and Hardware um and I I bet that's probably representative across the other other parts of the stack too yeah absolutely it's exactly as he says it's um uh this the sort of trade-off between you know making a big bet now and the sort of uncertainty in the evolution of the field is you know a pretty difficult spot to be in as a hardware company um that's that uh you know how how I've seen some impressive work how far coming out of various companies yeah how far are we away from that point do you guys think from where we've like hardened everything we like there's a there's maybe a limited set of proof systems of like everyone's okay we've reviewed on this kind of maybe I don't know if this happened the same way with like hash functions or something but like now everyone just uses shot 256 pretty much so like what like are we are we going to reach that point at some and if so like when when will we get there I would say as somebody who uses these systems I hope we're still far away because the reason we keep moving is because we keep finding things that are so much faster um so it's not about you know security we're not migrating because things get broken the way we did for hash functions like we kept moving because shot one got broken so we had to move to shatu um in these systems we're still finding very very meaningful performance gains so big that they balance out even the gains you can get from Hardware acceleration um but that being said the field has gotten incredibly mature over the last couple of years compared to where it was so we might be you know only a year or two away from having something that we've kind of we've hit where we think the limits are and the performance you can get um where to the point where Hardware starts to matter more than new systems do super interesting um I want to talk a bit about the intersection of ZK proofs and uh specifically blockchain infrastructure and modular blockchains um I you know at Celestia we're close to launching mainnet but we already have some ideas of how we want to improve the core protocol like for our next iteration after we've launched and a lot of them actually involve zero knowledge proofs um you know one of them is that we want to add a ZK uh sort of verification op code to our core protocol and that will allow for trust minimized bridging um from from Celestia up to the roll-ups and we also have ideas for how we can use um ZK proofs to prove the correctness of the Erasure coding of our extended block data as that's like really important for the security of the the data availability sampling scheme that we use and we will prevent we'll make latency better and also prevent basically the need for our battery Erasure coding um fraud proofs and then we also have another one which is um unfortunately or fortunately we use sha-256 as the way that we hash our data root and unfortunately you know that means that if you want to prove inclusion of data in the Celestia block inside of a ZK circuit it can be really expensive and so we have this idea that we could uh you know use some kind of service to generate an equivalent data route but in a ZK from the hash function like Poseidon or Peterson and then um then we can actually and we can have a proof that proves that those two different data root hashes are are equivalent to each other um so those are a few of the the improvements that we have but in general uh it just seems like ZK there's almost like no bound on the different applications that it can you know the ways that it can be applied to improve uh blockchain infrastructure so I would love to hear what you guys think are the most like the highest leverage uh places I know for example Sovereign you guys have a vision for doing proof aggregation across a bunch of uh like the Roll-Ups in The Sovereign SDK ecosystem and then they can have like this succinct sort of like um many to many bridging but with just through just one proof for example and so anyway I I'd love for you guys to talk about where you you see the most exciting applications the ZK in the infrastructure side of crypto foreign happy to jump in here a little bit um and Brian feel free to speak as well if you have things you're excited about but yeah at Sovereign we're very excited about as you mentioned the application of ZK to interoperability um so I think there's there's kind of two different challenges you have with interoperability today one of them is trust and one of them is cost so when you're bridging between two chains say like two Cosmos chains for example um you have a fundamental problem which is that one of the chains can't validate the other Chain's logic right if you did that you would just have one bigger blockchain with more expensive blocks so you fundamentally can't validate the other chain all you can do is you can check that their validator set has signed off on some signature and so in most cases it turns out that's good enough right the trouble is if the validator set ever lies then they can steal money from the bridge and so if you have a world with hundreds or thousands of blockchains where some of them have very small market caps suddenly you have to be very careful about who are you bridging to because if you bridge to the wrong person they could steal your money um so ZK just completely solves that problem right you can check once that they're that they have rules that you're comfortable opting into and once you've done that check you can check forever that they're following their own rules and so you have no opportunity for loss of funds um the other property like you mentioned the specifics that we keep coming back to um if you're bridging between two different blockchains say in Cosmos for every other chain that you want to bridge to you have to verify that their validator set is correctly producing blocks and that means checking a bunch of digital signatures inside of your blockchains VM so for one or two chains that works pretty well but if you start to think about having a hundred or a thousand Bridges suddenly you'd be spending all of your time just checking signatures to operate these Bridges and you wouldn't have any time left to do computation and the number where you hit that point is is very small it's like maybe low double number of bridges before your chain is completely unusable with ZK like we talked about you can upgrade all the proofs together and suddenly this is a complete non-issue you just check the proof once and it takes you know in Native terms maybe a few milliseconds to validate that say a hundred or a thousand other Roll-Ups are following the the rules that they prescribe for themselves so those are two things we're very very excited about yeah I think the thing as you pointed out there's CK touches I think almost everything and in this space and can make almost anything better I think the thing I'm really excited about right now is to see um the kind of combination of of like optimistic approaches with CK approaches so you know you can make you can get the benefits of of you know an optimistic system without a lot of the downsides of needing to build this kind of separate fraud proof mechanism you can kind of let ZK handle a lot of the the sort of heavy lift and then you can deal with the fact that he hates may be a bit slower than you want your system to be I think Sav is actually doing some uh work on that front um I don't know uh Preston can talk talk about here one shot the optimistic stuff you're doing would be really interesting but I think seeing you know seeing that'll be applied across you know potentially stuff Celestia is doing and sort of what optimism uh looking into with their latest are p is really interesting and going to provide a lot of capability without a lot of um you know Capital uh intensive research and development yeah absolutely that's a fantastic Point um so maybe to give a little bit of context for for listeners who may not be deep in the weeds like we are when you're building an optimistic roll-up you have this sort of fundamental problem that it's expensive for some other blockchain to verify a proof that fraud has been committed um so let's take the case of optimism for example they're running a full ethereum block as I roll up on top of ethereum so anytime there's fraud in the naive implementation the ethereum blockchain would have to re-execute basically and a whole other ethereum blockchain in order to check whether or not fraud had been committed and that's just way too expensive to ever work in practice so what optimism and arbitrim did was they came up with this clever interactive on-chain game where they um play back and forth between a challenger and the guy who claimed that you know a certain transition was made and after maybe 50 rounds of on-chain interaction they can find the exact location so the exact assembly instruction of of the CPU code of the code they can find the exact assembly instruction where the two players disagree with each other and then the evm just executes that single assembly instruction uh so that's a really cool trick but it has this super big drawback which is that it takes a long time because you have to send maybe 50 different messages onto the blockchain and any one of those messages might get censored and so you need to wait a long time to make sure that everybody who wanted to challenge this could challenge a state transition so one of the things we're working on at Sovereign is just remove this interactive game entirely so basically if you've written your code using the Sovereign framework you already have all the capabilities to generate CK proofs so now the idea is okay sure take your take your blockchain but instead of making the proofs all the time um just just make proofs when there's a dispute about what happened in a particular block and that way you never have to pay any proving costs um at least not on the happy case and you can you can design the economics in a cool way to make sure that the only way you ever have to pay the proving costs is if someone else paid them for you because you can slash whoever lied about the state transition so you can avoid ever having to pay any proving costs um but still have the full security or you know the security that you expect and significantly reduce the latency that you'd have to wait for a block to finalize DK frog proofs yeah I remember first hearing about that idea from um at least the first time I heard of it was uh Mustafa brought it up in a conversation um like a in October last year and I was like totally mind blown and then I had never thought of the fact that yeah you could actually ZK prove the validity of a frog proof um and then and then you had to get the best of both worlds where basically you don't have to um prove every single block um but you also don't have to worry about like these you know very big um fraud proof sizes that are difficult to verify so I'm a huge fan of this idea um you is there anything that you wanted to um time in there I know co-processing is something that you're working on and it seems like uh you know very relevant to the fact that it expands the capability of what blockchain infrastructure can do um so feel free to like chime in here and on where you see ZK plugging in yeah what we're working on at Axiom is offering a way to I guess modularly expand the set of capabilities that are possible on a blockchain VM by allowing contracts to make asynchronous calls to off-team actors without adding additional trust assumptions so we see that coming in two forms first we allow contracts to access more data trustlessly from the chain that they're actually on and second we let them actually compute on that data to perform computations that might not be possible within a blockchain VM either for cost reasons now or just for fundamental scalability reasons if the computation is large enough and so we think this breaks the current model where all blockchain computations are fundamentally synchronous that's very expensive from the blockchain validation point of view and so by relaxing that assumption we're hoping to enable Smart contracts to do many more types of operations without adding additional trust assumptions yeah that's that's absolutely huge I want to talk just the last point on the infrastructure thing is what is the relationship between zero knowledge proofs and uh data availability obviously this is a very clear connection with um you know Roll-Ups because uh you need the data behind you know the the chain like the data you need the data to uh the minimum amount of data to be able to reconstruct the state of your roll up and data availability is the way to ensure that that's the case um but is there are there other uh like interactions with between data availability and ZK proofs in some of these other applications like maybe in co-processing or zkml um or uh I don't know I I'm curious if if there's more ways in which those two things interact obviously because at Celestia we are building a data availability layer yeah I think this ties into some of the specifics about what the guarantee of data availability actually is so my understanding is that we say that data is available if it was possible at some point for anyone to download that data but what that doesn't guarantee and we're probably going to see this more and more as more data is available is that in one year or in 10 years you'll be able to access that data and so there's a proposal across blockchains of having stateless blockchains which means that when you send a transaction you actually have to prove that all the data you access was somehow validly in the blockchain and so this could apply to Historic data or even data in the current state and so what ZK can allow you to do is to compress the proofs that all of the data you're accessing actually is committed to in the state and that allows you to access much more data and it's I view it as almost complementary to data availability absolutely that's such a good point and um sort of like an extension expansion of kind of what I was talking about earlier as one of the one of the things that um we want to help make like proving inclusion of data in Celestia Cheaper By by having like a more friendly ZK uh hashing data route but like I think there's like a lot more like you said um and I think Preston you you've written about this when we were talking about them adding this this trust minimized bridging um ZK verification op code um how like you know you can you could be able to prove the inclusion of data like arbitrary data like arbitrarily back far back in the past essentially uh which sounds sounds related to what what he's talking about um but anyway I think that's kind of a bit of a rabbit hole unless professionally if you think that's something interesting to talk about um otherwise I I was I think the last kind of connection between the modular stack and um ZK in my mind is this idea of of proving networks and this is something I'm kind of new to but we've we've seen you know one of the Theses behind like modular blockchains and the modular stack is that you know we we're going to start to build these decentralized services that perform certain functions necessary to build these you know trust minimized systems that we call blockchains and so you know we started out with like just kind of two two basic types of like services or layers one is like the data availability and consensus layer like Celestia then we have execution layers like you know Roll-Ups like optimism and all the stockware and all the all the ones that we're familiar with are sovereign and but now we're we're even expanding that even more with for example things like shared sequencer networks where all of a sudden you can Outsource sequencing to this decentralized uh sort of service or layer and um to me at least that that's my frame of mind when I hear about these proving networks as I understand them there's sort of like a a network of people uh or like that are running uh that have the hardware necessary to um prove uh certain computations generate proofs for you which can be expensive and and you need you need like resources to do that and and people so it kind of becomes this decentralized Marketplace uh for for proving and so do you guys see that as as something that's part of the modular stack also like maybe you can explain like what these proving networks are in the first place and how they would work I mean there are a couple of them already out there you know like equals nil uh they have theirs live and I think dolphinous Labs but there's EK plasma also has like a sort of nation-proving market and you know I think as we see demand for ZK proofs hopefully you know massively expand over the course the next couple years as you know zko processing becomes I think yeah you know a major theme in how work gets done in these systems um you will start to see you know collectives of people uh that can actually you know bring serious infrastructure power to this Market in a way that uh is probably like possibly more cost efficient than relying on you know big sort of big Tech but certainly more scalable and um and more able to respond to you know various like widely different compute kind of needs in the ecosystem because we've seen you know at least historically huge Spikes have really negative impacts on pricing and user experience and I think by pushing more computation off chain um to intensity K code processors and by enabling people to kind of participate in these proving networks um and you know really kind of instantly decide to start you know performing proofs for money you're going to see like a much more resilient compute fabric evolve over time but beyond that I think there are still huge opens around you know the economics of how the system is going to work and the sort of breadth and scope of which proving systems also support and all of this kind of stuff but I do expect it to be like uh an important part of the future for sure Preston are you do you have any thoughts on this I'm curious like why why does it need to be a network and like why can't it just be a centralized service or something it can be and you know we Bonsai right now is very centralized and there are potentially benefits for that and you know one of those is some of those could be related to privacy and letting people you know produce proof some data you know that they control on infrastructure that they control um but there's something kind of magical about if the hardware requirements can get low enough allowing anybody to kind of participate in this network and it's really just its ability to soak up demand anywhere in the world and also help power these kind of censorship resistant um hyper structure type systems got it so I'm not wrong and thinking of it as possibly another layer or service within the modular stack no I don't think so yeah it seems it seems very much like a execution a type of execution layer that's different than you know I think how people would have you know what people would have called an execution layer in the past um personally do you guys have any other thoughts there I think to add on to what Brian said I definitely think one thing that will affect the shape of how these markets uh evolve is the actual aggregation properties of the proof systems I think and one reason why probably the market structure hasn't really stabilized is that the proof systems are evolving so quickly and the basic problem there is as Brian mentioned like the resource requirements what vary with what proof system you're using but also the way that is most optimal to chop up a large computation into smaller computations and do recursion or aggregation is actually somewhat different between let's say folding or Stark paste recursion and as these things evolved they actually can imply dramatically different forms of Market structure so it'll be really interesting to see how the different proof marketplaces handle that very interesting well we have about 10 minutes left so I want to start wrapping up my I've so two more questions my first one is a little bit more of a philosophical question um and basically what it is is you know why do we need like to prove things and verify things in the first place um and the reason I bring this up is just that um at Celestia we big Believers in uh the importance of of verifying uh things rather than just you know trusting uh third parties or committees um but it sometimes it feels like a lot of people are just aren't really aware of like the fact that that's really the the core of the blockchain security and and like decentralization that we um are all here for and trying to build so um you know that's why we think data availability sampling is really important rather than using a data availability committee or an L1 that doesn't actually support um data availability sampling um and so we think Roll-Ups are so uh great because you can you know using very light Hardware actually verify the the execution rather than just you know verifying that there's enough signatures on a block header um so I would love to hear from you guys like why you know why is verifiability why why are proofs such an important part of this of of what we're doing and what we're building in blockchain and crypto sure happy to jump in on this one um it's it's kind of funny that we that we even have to ask this question uh because if you if you look back at history right the history of humanity is the history of people being able to work with larger and larger groups of people so you know if you think way back like the the good old sapiens story right in the early days of of humanity it was maybe your family and before if you know before Humanity at all like maybe it was just individual organisms sort of looking out for themselves and then you you get the family structure which is much much more stable than individuals right families can easily out compete a single individual trying to find for themselves and then you get tribes which are all genetically genetically related to each other and they can now compete you know small families but that's where it stops because humans can only maintain you know at most a few hundred interpersonal connections and so in order to cooperate with someone you have to be able to trust them right in all of your actual meaningful relationships there's asymmetric downside if somebody really wanted to hurt you they could very easily do something which would be catastrophic to you so you fundamentally you really have to trust these people well one of the next big stories in in human history is um is you know cooperation through memes so that could be shared government it could be shared religion it could be shared ideals but cooperation together through shared ideas and suddenly even though you know Nick you and I are not genetically genetically related and honestly like up until a year ago we didn't even know any of the same people but because you and I share a lot of ideas and we work in the same space we're able to work together in a you know in a great way um but still we're lying on sort of on social proof on things that are not ultimately scalable and so if you look at the world today you know cooperation kind of stops along the boundaries of nations so like I can't just venmo somebody in Argentina right um and so what proofs do is they let you scale trust because suddenly there's no social component left it's all just purely mathematical and everybody in the world has the same laws of physics and the same mathematics and so suddenly you can cooperate with people that you have nothing in common with and you can know that there's no way for them to break this trust relationship that you have um so fundamentally that's why we're so excited about proving and then of course there's lots of concrete applications that we get to talk about all day long which is fun too damn that was that was a mic drop right there um go ahead I was just I was just appreciating yeah uh Preston's explanation I think that was I think that was amazing um yeah the only thing I would add is that you know uh in addition to everything Preston said you know these systems that rely on kind of you know macroeconomic security kind of games like staking and slashing and all this stuff you know it's amazing that these work as ways to prove the you know sort of what happened um but it's extraordinarily complex and there are a whole bunch of you know potential like failure modes and odd interactions and stuff that I think fundamentally limit the complexity of the kinds of applications you can build with these systems so I think just in order for you know blockchains and decentralized systems to sort of compete with um with their centralized uh you know uh ancestors I guess um they kind of need to reduce the complexity of analyzing a lot of the you know more interesting interactions and ZK gives us a path to do that and build more complex systems uh in ways that you know the brains of the people building them can can grok the the sort of emergent behaviors of the system uh innocent in a reasonable manner yeah yeah I think what Brian and Preston said is are both really important properties of CK I would only add one thing which is when you compare something guaranteed by a zero knowledge proof on a blockchain to a guarantee from let's say a government regulator like the government is fundamentally running an optimistic system namely if you perform some action and it's fraudulent they offer the guarantee that maybe later on be an audit they'll catch you and you'll be punished that's sort of an incentive to not to do commit fraud whereas if you have to forgive a Serial knowledge prayer for just any type of proof that your action is actually legitimate then I think that offers like an even higher level of guarantee that the system is behaving as uh as planned and so I think that's a big step towards achieving the goal of blockchains to offer a more objective point of view on trustless systems that's a great point and even it can be turned around the other way rather than you know governments like in enforcing rules on people people also enforcing sort of the the rules on on governments like you know uh you know government officials being forced to prove that they actually carried out um things in the way that they they claim uh I I love this this Vision stuff and the social stuff that was a great answer from all of you guys so to wrap up um my last question is just um you know where will ZK where will blockchains and where will your project be um in five years uh if if we're successful and some of the things that we're attempting to do and in general do you have any you know final takeaways for the audience um uh as we wrap up I think like everything in the world it's going to be a story of gradually and then suddenly you know right now we're in the phase of gradually people are adopting ZK proofs gradually people are deploying Roll-Ups and you know a year or two from now it's suddenly going to be everywhere um so you know five years from now we envision a future where many many things probably almost every app on your phone behind the scenes is doing something that touches a blockchain something that involves a zero knowledge proof right um but the magic is that in five years it'll be just like the internet you know every app on your phone uses the internet but you don't think about the fact that you're using the internet you're just thinking about the apps you're using um we hope and and we're working very hard to make sure that that future is five years or less away and we should have you know production systems hopefully soon TM and what about uh Sovereign and any any last takeaways for the audience um I mean if if you're interested in this sort of stuff we would love to chat we are always looking for people who are interested in building applications um if you've wanted to use EK but it's been too hard come talk to us um and and yeah come you know let's build together yeah um I think five-year five-year vision's always hard but um I I hope that and really believe that five years from now we're gonna live in a world where you know big Tech hegemony over kind of like every aspect of our digital lives is is over and it will be over because we've built this this like trustless um trustless set of systems that can interact with each other uh and that are based on these very resilient networks um such that we can actually trust you know our digital identity to this fabric sort of resilient fabric of systems um and and by having that kind of core rooting of our digital identities in a in something that we actually kind of own ourselves and get to control how it's used and the policy around it I think that's going to enable yeah a huge set of new applications that are going to be like Pro social instead of anti-social and um I think you know I hope that receiver is a huge part of of powering the computations Behind These systems yeah foreign yeah I think for a ZK more broadly the metric I think is most interesting is sort of what's the ratio between the cost of giving a ZK proof for a computation and the cost of exceeding that computation on your computer is in a normal way and I think that ratio right now is pretty high maybe between 10 000 and a million depending on how you compute but we're going to see that fall more and more and I think within five years we I'm hopeful we'll be within sort of the theoretical limits Maybe 100 or even less and so once that happens once the cost of generating a verifying they keep verifying anything drops well it'll become a question of why aren't cheesy K verifying your computation instead of you know why are you and I think we're going to see trust minimization extend to many different types of applications and we're hopeful that there can be hybrid on-chain and off-chain applications that offer the sort of liveness and consensus guarantees of a blockchain while actually having the same performance and Rich experiences of normal applications today uh sort of empowered by ZK and so our goal at Axiom is to be part of that transition between purely off chain and partially on chain off chain um we're launching pretty soon with the first steps for purely on-chain applications today so you can check us out at axiom.xyz amazing well I am so grateful that you guys came on today to share uh all this knowledge with us and uh the listeners there's um I'm sure a lot more to look forward to in the future from all of your projects and from ZK and the modular space as a whole and um we're going to keep doing more of these spaces to uncover and talk about the more technical uh aspects of blockchain and crypto so please join us next time and until then uh Brian Preston Yee it's been a pleasure and an honor thank you so much 