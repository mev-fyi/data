um right so perfect right dumb blockchains need clever titles um this this talk will primarily be about shared sequencing in the modular stack and is somewhat related to the title or maybe not um but uh as it will become clear shared sequencers are designed as dumb or lazy Ledger systems that don't execute transactions and just sequence and that poses some challenges that requires some Solutions first just quickly about our organization espresso systems we are a team of Engineers researchers and designers we are building infrastructure that is going to assist Roll-Ups to achieve better better scale better interoperability and better security um we are a very distributed team I am Ben Fish and uh uh I'm the the CEO and my colleague Jill was uh just introducing the event she's our tree strategy officer and there's a number of other Executives as well um so let me start talking about this problem of uh of sequencing in in the in the roll-up ecosystem and the modular stack more generally uh but first it it a starting point is to talk about what exactly are Roll-Ups doing okay so roll ups are horizontally scaling the application layer of blockchains um primarily today Roll-Ups are being built on ethereum but of course or uh on top of Celestia too so if you view Celestia as an L1 as well so um but in general the idea is that the layer one all it does is just verify fraud or ZK proofs um it may also provide availability of data and some other services but it doesn't execute transactions and so as you add new applications the reason why this horizontally scales is as you add new applications you don't burden the layer 1 with having to execute for those applications you can introduce a new set of servers that executes for that set that application and just proves the state results to the L1 rollups are applications that host other applications so things like optimism or ZK sync are are General virtual machines which can host other applications but now we also have app chains that just execute their own application specific States directly and all of these are horizontally scaling the the execution layer of blockchains another key Point besides charting of computation across applications is that Roll-Ups leverage heterogeneity in the network they're leveraging the fact that in realistically in networks not all nodes are the same if we want to scale layer ones to be extremely decentralized so that there's 12 000 nodes participating and one of them is a Raspberry Pi or as I heard yesterday apparently a touring pie is a thing too but then the weakest note obviously will not be able to compute transactions as fast as the strongest nodes so roll ups allow the more powerful nodes to do even more computation when we're talking about ZK Roll-Ups it's 10 000 times or more expensive to produce a proof than to even just execute itself so we increase even more the computation of some powerful nodes and this helps weaker nodes uh catch up so um the thing is today roll ups control a lot they control a lot more than just doing execution and horizontally scaling ethereum in fact they they centralize the entire process of deciding which transactions to include and in what order and this brings us back to a world in where there are essential actors that have the power to discriminate that have the power to impose monopolistic pricing or maximally extract Mev from users and these are all the things that blockchains were promising to get us away from uh if you think about it the roll-up ecosystem today is essentially web 2 applications that are being audited by an L1 right but the the actual processing and everything is really just being done by the web to application it's just being followed and verified by an L1 so um what is the solution one solution is to separate ordering from execution so that application layer roll up servers will execute transactions and uh and not handle any of the ordering process not handle any of the process of even making data available the L1 would not build or execute its roles would only include finality on transaction ordering availability of transaction data and the verification of State proofs and users would submit transactions directly to this decentralized L1 so this has also been called a based roll-up architecture where you have the consensus Network that users submit transactions to roll up servers read a transaction stream from this um from this consensus Network and uh and then post to stayed rude and approve like then gets verified um challenges arise from this however if the L1 is not doing any of the execution then how does it set prices for including transactions that doesn't execute how does it verify that the fees that it's receiving are paid correctly does it need to have some kind of minimal state to do that how is revenue that it's generating shared back with Roll-Ups or applications how do we prevent spam could the L1 overload the proving Network without compensation for work all of these are challenges not all of which I will address in this short talk today but these are all things that need to be considered when when working with uh with with such base roll-up architecture or more generally what I would call decentralized secret sequencer architectures um so we can also look at hybrid centralized base architectures where and this has also been called Escape hatches or L1 inboxes I would say that is a form of based rollup where um or related to maybe not exactly the same where there is a designated roll-up server that can order transactions but users can also submit directly to the L1 so the L1 orders some of the transactions the designated rollup server orders others and we have some way of deciding well maybe the transactions from the rollup server go at the head maybe they go at the tail there's different approaches to doing that and this hybrid architecture can be applied to any decentralized sequencing design as well we can mix and match um so there's also perhaps a reason to separate the order finalization layer at least logically from the layer one and why might we do that why would we use anything except for ethereum's gas or protocol today for ordering and making available transactions well specialization right ethereum makes some decisions on how it works to optimize for certain sets of properties for example ethereum is extremely available extreme theorem is extremely decentralized right if you wanted to design a protocol that is still decentralized but prioritizes fast finality and can give faster pre-conformations then that could be a reason to design another layer if perhaps it's something that's that's designed for high throughput data availability that's another reason to design what I would call some layer one and a half that sits between the layer 1 and the layer 2. so protocol modularity opportunity to make different design trade-offs higher throughput lower latency faster pre-conformations um when it comes to talking about faster pre-confirmations a common misconception is that ethereum's finality is 12 seconds this is not actually true this is the average block time of ethereum transactions must be several blocks deep to be confirmed and it takes in fact 15 minutes for transactions to finally be finalized by Casper FFG which is the finality Gadget of ethereum often users may consider a transaction final after five minutes some may consider it final after 12 seconds but that's very very risky you can read more about this by looking at ethereum's discussion vitalik has a post on single slot finality where he explains that ethereum's finality is actually 15 minutes not 12 seconds so let's say you want to design a decentralized protocol that could provide faster finality than ethereum why doesn't ethereum have fast finality well it runs something called a dynamically available protocol which means that even if 10 of the network is online not 100 it still can process transactions it still can make progress Bitcoin has this property too this is in fact one of the Innovations of consensus protocols in the last 10 years that started with the Nakamoto consensus protocol um but we also have protocols that are on a different side of What's called the cap ethereum meaning they are it they cannot be dynamically available but they can achieve what's called optimistic responsiveness which colloquially may be called Fast finality an optimistic responsiveness is the ability to respond as fast as the network will allow when networker conditions are good the consensus protocol can give you instant finality it also has an asynchronous fallback path so that if the network conditions aren't good it will eventually make progress but it will stall if enough nodes go offline right ethereum doesn't have that property ethereum cannot achieve fast finality because it will remain live even if a small participation set is online whereas protocols like Hotshot developed by espresso systems will go stall if too many nodes go offline but if they're all online and the network conditions are good they can give you very very fast finality almost like a centralized sequencer there are protocols that achieve neither property like tendermint um but uh so responsiveness it's the idea when when there's a high rate uh when the sun is shining you get this High rate instant confirmation when when it but it's still robust when when it's raining right right so we call this web 2 performance with web 3 security we can also blur the lines between the physical lines at least between the layers when it comes to things like eigenlayer um things like restaking enable you to to incentivize or at least subsidize the participation of the L1 nodes in this layer one and a half so that the same physical set of nodes are running it and you're making the same ultimately the same trust assumption but just the protocol properties are different so um moving on to sort of a second challenge um fragmented liquidity and interoperability it's beautiful that this application layer is being sharded by Roll-Ups but this fragments the interoperability so now two applications can no longer call each other they can no longer make function calls to each other um your you know your your Ave liquidity pool is no longer shared across all all all applications if they sit on different uh different roll-ups um bridging across Roll-Ups is complex atomicity is limited so how can we recover this and specifically to what degree does sharing an ordering layer only and not an execution layer which would make everything the same roll up right does sharing an ordering layer only help okay um so this is the next question I want to explore so there are three advantages I will only focus on one one advantage is simplifying cross-roller bridging and atomicity because you are sharing at least the same ordering protocol so you don't have to verify each other's consensus the second is mitigating what I would call systemic risks of bridging overall and the opportunities for profit that they provide to adversaries you can mitigate that and reduce it by sharing a consensus protocol I won't address these first too we have blogs on it but I will focus today on explaining why this supports what I would say cross-roll a building with economic bonding this is not the same as sharing an execution layer but it gives you some very interesting guarantees so first quickly on proposer Builder separation this is the way things work in protocols like ethereum today it also works like this in Hotshot there's a proposer that's elected by the consensus protocol in every slot to propose transactions but this proposer while it needs to sign and broadcast information doesn't need to come up with everything that needs to go into that block that could be outsourced um in fact it could run an auction among competing Builders who are able to build an optimized block there are different things that this might be optimizing for generally if we leave if we let the proposer run this auction then naturally the builders who win the block auction are going to be maximizing the revenue of the proposer and that's what motivates us to do some other designs which are designing like an ideal functionality that implements an order flow auction where you which is optimal for users and stable for users could we design something where users are are getting the best execution prices available to them or guaranteed that their transactions don't fail and this is something that the teams like flashbots and Suave have been working on and other teams too and is sort of the future I think of um of sort of the order Flow Design of blockchains but in order to uh in order for this to work the the consensus protocol needs to be extremely decentralized so that the proposer doesn't just say okay you know what screw this ideal functionality it's not good for me it's not maximizing my Revenue I will just run my own auction the way I want to no if it's extremely decentralized the proposer gets elected once in a blue moon it can either take transactions from the ideal functionality or have no transactions at all it can't make a credible threat to users to abort the ideal functionality and that's why decentralization is important this is in fact why EIP 1559 works it only works because ethereum is extremely decentralized but with proposer Builder separation over an extremely decentralized shared sequencing layer decentralization is key then you can also introduce these Builder functionalities on top and these Builders or ideal functionalities can also start to provide some interoperability guarantees example a builder could say to a user okay the user wants to trade on optimism and ZK sync it sees some Arbitrage opportunity it wants the Builder to include both of these transactions in the block and ensure that they both succeed because the Builder is basically able to win this auction of a super block wholesale that that sends blocks to both zksync and arbitrary it controls it basically has a lock on the state of both the zika sink and arbitrim and thus can make this guarantee to the user it can promise that that it will include both trades in the same block and it can also write this promise in a cryptographically authenticated way so that if it violates This Promise then the user can go to some smart contract and slash it okay so if if I don't do this then you can use this as evidence to slash me and it can put up a big collateral in order to give the user confidence uh in this that this promise will be satisfied this is a simple example but we could go through an example of even cross roll up flash loans it will take more time so I I don't have time for it in the short talk today um but just to summarize so espresso sequencer is one of these layer 1.5 sequencers it sits between the uh the the L1 ethereum and roll hubs although we're trying to blur the physical Lines by using eigenlayer and it provides this consensus on ordering but um there's a there that also supports proposer Builder separation and we envision most of most blocks being built in that builder in that Builder layer which can actually provide the interoperability guarantees to users which wouldn't be possible if you had different consensus protocols because Builders would not uh well Builders would would have to simultaneously win many auctions and that carries a lot of risk a common concern is as how is revenue from Crossroad bundles allocated back to roll ups another common concern is whether this leads to Builder centralization um to address the first concern uh the concern that Builders will need to execute for all interoperable Roll-Ups and that may create a higher barrier to entry leading to fewer competing builders so first I think it's important to recognize that Builders and validators are not the same thing and we don't require the same level of decentralization at each layer of the stack we need to work from first principles and look at why what do first of all what does decentralization mean does it mean a lot of economic stake does it mean a lot of distinct physical nodes does it mean geographical and what is required from each layer given the given the service that it's providing executing for all rollups is not actually that hard maybe it's hard for 12 000 nodes including a Raspberry Pi maybe it's just hard for a Raspberry Pi but executing is not a huge barrier to entry and we don't necessarily need 12 000 competing Builders we just need enough competing Builders to create competition in the market that drives down Monopoly pricing not necessarily 12 000 of them um so it's unlike the decentralization requirements of proposers and in fact if you have a highly decentralized uh base uh layer or a consensus protocol then proposed that's what that's what enables proposer Builder separation that's what makes these proposers more passive and able to be compatible with ideal functionalities that are designed in an ideal way for users that are that are thus stable for users um furthermore the barrier to entry is much higher without shared consensus because it requires more Capital to win simultaneous auctions the Builder absorbs more risk and it can't promise user atomicity without this risk this phenomenon of Builders executing for all rollups is an inevitable consequence of the user desire for interoperability it will happen no matter what and so I would argue that designing a shared sequencing layer is going to lower the barrier rather than create more asymmetry among Builders and increase the barrier which is the alternative of many independent Roll-Ups with their own sequencers so um I uh this is a small meme about that right well there's where there's a will there's a way builders that execute for all rollups anyways we'll find a way to do it uh shared sequencing enables more builders um I don't want to go into the revenue sharing problem because I'm out of time but I just want to say it's connected to order flow auctions and there's a cool idea of splitting up slots so that it even slots you don't have cross roll up bundles and it's very easy to divide the revenue and in odd slots it may be trickier but you get a good approximation from the even Slots of what to do in the odd slots announcements we have adopio test net we also have double shots of espresso available at our booth but the second test net of espresso sequencer called dopio is now released and it features an end-to-end integration with polygon ZK evm a fork of polygons ekvm next we're working on op stack Integrations we're working with Caldera Aspire Catalyst injective alt layer we recently won an optimism sequencer decentralization RFP so we'll be working on that and here's a little picture of our little growing ecosystem if you want to join this please let us know we're happy to talk to everyone so thank you so much foreign 