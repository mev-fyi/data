all right hey everyone um thanks for having me so yes they said I'm Josh I'm the CEO uh founder of Austria so I actually renamed my talk asteroids vision for the end game I used the talk uh speedrunning the end game previously so I get the slides in late but what I'm going to walk through here really is what asteria's architecture looks like and kind of the the top to bottom of like why we're building the architecture we're building because you know as shared sequencers have given gain prominence in the last five months since this has even been like a kind of a concept um you know uh there's been a lot of questions about like why it should be designed one way or another um and so we're gonna give that and so for Astra Airline we have like two kind of key principles we think that Roll-Ups should be decentralized by default this is generally a pushback on the idea of this Progressive decentralization which has been promised by a lot of different roll-up networks but quite frankly we haven't seen it you know we're 18 months into mainnet on a lot of Roll-Ups and they're still just decentralized if they were day one when they launched so we believe that if we want to see a world with many many Roll-Ups they're going to be decentralized by default otherwise we'll have this recurring window of we launched it at centralized we'll get to the decentralization later and there will perpetually be newcomers that are just centralized so that's principle one principle two is that we believe deploying a roll-up should be as easy as deploying a smart contract also am I going to get a clock time there or should I just guess okay um so we believe we're deploying a roll-up should be as easy as deploying a smart contract and now I'm just going to go into kind of architecture stuff I have 53 slides to get to so I'm going to talk quickly this is how we view the general kind of transaction thing you could call this like the transaction order flow but we put it in a kind of four stages and noting that we are or at least myself is not in the camp of a roll-up being defined by its Bridge so that's just you can argue with that we have a panel after where we can fight um but we believe we start with unordered transactions that could be intense we go to an ordered block from that ordered block we end up with an executed block that has a state DB and presumably a resulting State Route and then after that you can have a succinct proof or a ZK proof um and that is kind of what we're going to argue the ordering we'll label these as order flow sequencing execution and proving and view those four phases again people in this disagree with terminology but I have to pick some semantic definitions to go with right okay so state of sequencers to gay this is what I'll argue is kind of the most simple case for a centralized sequencer today you have an end user they're going to talk to a roll-up sequencer get a soft commitment there as it's one box that's a centralized sequencer that sequencer pushes batches to the DA layer you get a firm commitment for that what are the problems with that like why would we decentralize a sequencer's typo there um because this roll-up sequence or the centralized have the persistent Monopoly on ordering right and that's a problem for any number of economic reasons on transaction flow on censorship right but we don't want to have one party that has a persistent Monopoly when we say persistent we mean across all time right across blocks so if we go to a decentralized sequencer where we'll just simplify and say we have a leader rotation so there's multiple entities this is still for one roll-up but multiple entities get a chance to be the sequencer for the block and everything else is the same we moved to having a per block Monopoly on ordering this doesn't resolve everything right we've seen a lot of like interesting designs like multiplicity for like multi-validator um like block proposing but it is will argue better than having a persistent Monopoly across all time there's various research on Mev things where you can maximize Mev by extracting no Mev in one block and putting all that Mev in a second block we remove cases like that when we say there's now a per block Monopoly on ordering you can't guarantee you're getting multiple blocks or at least it's probabilistic well argue that's better right so why shared sequencers why would we want to go from decentralized for one roll up and many Roll-Ups having many decentralized sets to Shared um and this is what we're going to pause it as like a model for this you'll still have a user they'll communicate with the RPC for a given roll up so this is your metamask to like a guest note or whatever and it will push transactions to a shared sequencer we implicitly assume the shared sequencer is decentralized here um and so what are we doing here right now we're shared right here we have multiple Roll-Ups users still can interact directly there's more complicated designs but for this Taco limit here where you can have multiple roll-up rpcs sharing a sequencing so this is our kind of simplistic model it's very similar to like the espresso guys kind of more complex like diagram and they have a great demo visual on Twitter that you can look at um come on right so what does a user actually getting from a sequencer commitment when we say it's like a soft commitment what are they actually getting out of it so I really like this quote I've used this a lot of times it's from Nick Carter's article it's the settlement Assurance it's stupid from way back in 2019 um it's obviously Nick Carter right it's a little bit Bitcoin adjacent but I think it is some of the better written work on what we're talking about when we get a commitment of finality it's a settlement assurances refers to a system's ability to Grant recipients confidence then an inbound transaction will not be reversed right this is usually used in the case for the specific article of Bitcoin this is the sixth confirmation depth thing right it's probabilistic finality when do you know a transaction will be reverted we'll say settlement assurances or settlement is this act of not being reverted so we'll say a sequencer guarantees a user that their transaction will not be reverted right and then if we think you know okay is this a settlement layer right we have this quote from James fresh which we pin this in our marketing channel and slack this is one of the things that would influential on moving from we're building a settlement layer tool building a shared sequencer the term settlement layer is very busy muddy right and confusing so we're not going to use that but why shared sequencers right come back to this question why would you want a shared sequencer we argue again from the Nick Carter it's the settlement assurances both right Ledger costliness is the most profound and direct variable available to it to evaluate a blockchain settlement guarantees but simply it's the equivalent to the amount paid to validator slash transaction selectors per unit of time so in like a Bitcoin case which is probably the most simplistic one to understand this is like the amount of computational effort put into a given Fork of the chain right and literally the money burnt to give you that layer of like settlement finality right in a proof of stake chain in like something like ethereum right where you still have like a heaviest chain and it's slashable right it is the depth or like the weight of a stake that has been posted on one given Fork of the chain right that's your like that's what you're gonna call Ledger costliness right so we argue that sharing a single sequencer set between multiple Roll-Ups will increase The Ledger costliness right what we mean by this is if we have you know 10 Roll-Ups and the you know we'll assume they have kind of heterogeneous transaction flow right they're maybe not all EVMS there may be serving different use cases and they are all relying on a single point of settlement and they are doing like a proof of stake mechanism or even if it's something like you know proof of governance or just like kind of an implicit governance kind of chain link style implicit staking right if you have multiple use cases and more order flow using a single point of settlement a stronger guarantees if it is shared between all entities rather than each of those Roll-Ups attempting to acquire its own kind of set of Ledger costliness right um so this is what we're looking at right let me look at this architecture we'll assume that the soft commitment has a high likelihood the transactions are settled specifically if it's shared we can assume it as a higher likelihood that the transactions are settled in a shared set than if it was decentralized across any given role so then we'll say why lazy shared sequencing and so again I think our architecture and I you know espresso's architectures implicitly we say It's a lazy shared sequencer what I mean by this is it's not executing the state transition right to the original picture it's doing the ordering not the execution for all the Roll-Ups so why are we doing that right well really there's a question why wouldn't we do the stateful shared sequence it would be really nice if we could say hey we all do it in one go and we all get this commitment over a state route we get the Ledger cost leanness and it's nice and clean why are we not doing that that seems like the obvious nice solution right well are you that the resource requirements for a stateful shared sequence are one doing execution for all the Roll-Ups scales in proportion to the number of roles it's not explicitly the number of Roll-Ups right but if you assume that I as a validator set a sequencer set need to execute three different heterogeneous State machines I need to keep the state and I need to process and do the execution use the computational power and the storage requirements to keep all these states in these ledgers that increases if I add another roll up then I have to pay more cost right so going back to one of our principles deploying a roll-up should be as easy as deploying a smart contract right if it's a stateful shared sequencer it prevents permissionless use of the shared sequencer and what this means is if you are introducing every time you add a roll up to a shared sequencer you increase the cost to the resource cost to the actors in that sequencer set then that cannot be permissionless because you've now introduced a Dos Vector right I can go say I'm going to go make 10 Roll-Ups and I'm going to push them into the shared sequencer and I've just increased the workload of all these entities right so if we look at things like polka dots parachain options right that is a mechanism to create an economic cost to join the sequencers at the validator set if we look at interchange security with the cosmos Hub now replicated security right there's a governance process you need need to convince the validator set that they should allow your state machine to join the set and we believe that it should be as easy as deploying a smart contract you don't need to ask for permission to deploy a smart contract you simply go to the chain and you pay the gas fee and you deploy your contract right so that's one of our arguments for why we should use a lazy shared sequencer but then going back if we're not doing the execution right what is a lazy shared sequencer actually guaranteeing to our end users right and we're going to argue that a lazy shared sequencer guarantees that a transaction's position in the canonical block ordering won't be reverted so specifically this is a weaker guarantee than saying the resultant state route of your roll up is X right and it's actually giving you this state root hash if you're familiar with like a tender mint kind of cosmos space there's a distinction between tenderment giving you a block hash and the cosmos giving you a state route right we are talking about a block hash right you're giving a commitment of The Ordering of a given block but not a state route of a post State machine execution right and so we are you again right deterministic State machines it's kind of what we're doing with blockchains generally right a chain state is determined by recursively applying its state transition function to an input state in an ordered block right so very simplified function here right for at state zero and we don't move to State one we provide block one and we just run the state transition function now we have state one right I'm not like a math guy I don't know what the math symbols would be to recurse this right but run that every time from Genesis you now get the resultant State Route and the important thing here right is that from a Genesis state if you have access to all of the ordered blocks for a roll-up but not the state commit of those roll ups you can still as a full node executing that deterministically reach the same end State as everyone else for a given Fork of the roll-up right so we still have the capacity to do this execution but really when I was like when are these blocks actually being execute like who's doing this execution if not the sequencers at the validator set right so this is when we go to like ethereum land right so this is a picture from Mev booster picks is a great dashboard place to look for like information on Mev Booth when I checked on looks like the 16th right we're at 95 percent of ethereum validators are running block through Mev Booth right or like 95 of the blocks on ethereum overall are meth Booth so we're pretty close to 100 of people are using PBS for this right and then let's look at the relay dashboard right so within relays there's really two types right I guess there's three types if you consider the censorship ones like a type right but we see the largest relayer 28.3 is the ultrasound relay and the ultrasound relay is considered an optimistic relay and what we mean by that is that validators are actually not checking the block that is given to them by a builder to ensure that it is a valid State transition function they're not re-executing the reason they're not doing that is they save some milliseconds of latency by not doing that execution and the way that PBS works as an option mechanism Builders want to be able to submit their blocks as late as possible in the block timing by shaving let's say 100 milliseconds off of that they notably change the amount of order flow the amount of blocks that are sent to them as a relayer and they want they're all trying to competing for order flow right so by saying will yellow right we're going to assume that Builders are not sending us fake blocks um and we will not execute that right so what we argue is 28 of all blocks 28 times 95 is like 26.8 or something of all blocks going through ethereum today the validator is not actually executing the state transition function so what does that mean where are these blocks actually being executed so we'll argue this is like a rough design um for how we would see a shared sequencer having like a PBS Mev supply chain order for right users go to roll up our PCS those rpcs could be you know any V Supply flow we could have like Suave whatever right but they'll go to something that's order flow and we're gonna assume that order flow is the thing that takes transactions maybe there's bundles in the middle Searcher Builders they're not that distinctive parties actually in actuality at scale but it outputs blocks to the shared sequencer proposer right and the important aspect of this diagram is that to generate these bundles to generate these blocks execution is needed to find profitable blocks right if we think about what we saw with Mev before Mev Geth this is pre-emerge right what would you do you do a priority gas auction you spam the chain to try to get your transaction and it'll revert if you didn't like it right we introduce an auction mechanism and actually it's not economically desirable it's not like game theoretically optimal to go submit non-functioning blocks right if I'm like a PBS person I can like go grief the chain but if I'm here to make money like I'm a sophisticated professional actor I'm James Street I'm jump whatever right I want to make money so I want to submit good blocks so I have to do execution I have to run the knapsack problem across you know all the state machines and theoretically find what is the optimal block right it's like a PNP problem or whatever right they're gonna do execution to find these profitable blocks and they're going to know whether a block works right and so the shared sequencer the key thing defines the canonical block ordering but really what it's going to do is it's going to choose the most most profitable block that is offered to it and structurally a shared sequencer is essentially the same thing as an optimistic relay right it's going to be given a bid and a block and the economic incentives say that the people who are going to be sending it blocks are going to send it profitable blocks and profitable blocks are going to be executable blocks that are valid not blocked that are just kind of griefing the chain and saying oh look you have a block and it's kind of like revert or whatever right so that's our argument like where the execution is actually happening in this stack we can have like a lot of debates maybe in the panel on like the trust assumptions you're making whether you've moved to economic assumptions instead of like like programmatic assumptions or cryptographic assumptions but remember this is where 27-ish percent of all ethereum blocks are already being pushed this way and that's relatively stable but we could see increase right this is status quo today so touch on bridging really quickly here right we're not doing the execution so when we go to bridging right either role defined by its Bridge not answering that question here but if we say three components of bridging right I'm gonna argue that bridging is between ascending party and a receiving party and the key of Bridging the sending party has to come into receiving party that the data is available that there's a canonical ordering and what the post execution state is this is broadly what like a contract on the receiving side of a bridge is looking for right if the data is available and we have shared da we're going to say that to trust minimize Bridge we're not going to go too much in depth to that but that's generally what we're looking at like the roll-up sphere but really when we look at this kind of order flow diagram we're going to say the soft commitments again the shared sequencer is defining the canonical ordering of the chain so we're getting a canonical ordering between all the Roll-Ups on the shared sequencer the firm commitment coming from the da layer that's giving you the data availability so the question is who's attesting to this post-commitment state route right who is actually executing the chain and saying I will give some kind of guarantee cryptographic economic whatever of this actual post statement so what's the state of the world today right the status quo evm chains by and large so whether you want to say like a gnosis chain you want to look at like the Roll-Ups between each other right they're often not going through the optimistic Bridge seven day withdrawal window that's really a long time right so you have mechanism that can use connects they can use something like hop but in reality a lot of them are using things like layer zero they're using things like axolar they're using things like um I'm forgetting the third one Wormhole right fundamentally I'll consider the Third Party Committee Bridges you have some off-chain set of actors that are making a multi-sig attestation and staking their reputation maybe they have an on-chain stake on the validity of that State Route comment bft chains they're using a native validator set it's still a committee bridge and it's still an attestation making an honest majority assumption but they use their native validator set right we'll say this looks like this right you have sequencing you have an ordered block you can do execution you get an executed block that executed block that is implicitly ordered right goes into a committee that committee generates an aggregated signature whether that's BOS multi-sig whatever right and that aggregated signature is sent to the receive side and that's the kind of attestation we're making what is the next gen right we see succinct Labs working on proof of consensus of ethereum sync committee polymer is working on ZK mint right and so what fundamentally these are is we're going to do the whole first step right we're going to do an order block we're gonna do an executed block we're going to pass it through some committee that committee is going to have an aggregated signature pass that aggregated signature into approver and we're gonna get what we're going to call like a proof of consensus to use the zinc term right why do we want this proof of consensus it's kind of like an interoperability solution right cryptographic curves are hard to verify they're expensive to do in contract right eth doesn't know how to verify an ed 25519 signature natively or cheaply for tendermen so to go between tenorrent comment bft chain to like ethereum if you wrap it in a snark you essentially have a very expensive yet off-chain signature aggregation modification right so this is what we're seeing a lot of things move towards right um but what do we think the end game is right a morgue that prover networks are going to ease the creation of succinct State person I'm not a ZK person I'm going to details of VK stuff of storage proof for the state proof right but fundamentally we have things like Risk zeros like Bonsai Network we have like the nil Foundation guys right we have these people working on networks that say you take a state machine you do the execution and you pass it into this generic box of proving and it's going to give you a stark a snark whatever right so it's succinct proof of execution that allows a light client to verify it however it's worth noting inter-cluster bridging still needs this proof of canonicity or this proof of consensus over the ordering right because fundamentally you can easily generate a proof of a state machine or theoretically you can easily generate it but you could generate a proof that is a valid State transition but is not the canonical chain State transition so you still need both components right what you get with shared sequencing and it's like one minute so I'm rushing one you one proof of candidacy for multiple Roll-Ups because the shared sequencer defines the ordering for the change right so you can generate one proof for all the chains using the shared sequencer that tells you this is canonical chain and then within the shared sequencer you just need the state proof so we'll say this looks like this right you order a block that's happening on the shared sequencer standard kind of like next-gen stuff right this is the succinct style stuff this is the comet BF or the the uh ZK mint from the polymer Labs guys right you generate this proof of consensus and then once per roll up you do the state execution you pass into a prover Network you get a ZK State proof both of these things go to your receive side chain now you have all the components you want again we can go back and say if you're in a shared da layer you get something trust minimized right you know if this is everyone sharing Celestia if this everyone sharing ethereum right you get slightly better guarantees as well but this is how we view it at like the layer above that um so again looping back to where we started we believe that role should be decentralized by default we're giving come on we're getting our workshop at 4 30 like shortly after the panel in the couchy stage we're going to show off like what we have for like a demo right now we have a development cluster very similar to actually like what espresso has we'll show you guys how you can run this locally and how you can deploy your own roll up to using a shared sequencer so thank you everyone okay 