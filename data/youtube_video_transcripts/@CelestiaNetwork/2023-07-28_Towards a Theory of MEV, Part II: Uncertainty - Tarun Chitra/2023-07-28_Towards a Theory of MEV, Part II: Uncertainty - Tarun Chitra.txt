[Music] um cool so yeah so we're going to talk a little bit about something I've been uh probably working on for a few years um at this point which is to try to really come up with a good understanding of what the what the word Mev means and if you try to really formally Define it mathematically it turns out to be quite a bit uh difficult but it turns out uh there's a bunch of different components to it and this is the second of some number of parts I'm not sure how many there will be in the end um but uh you know oh I guess this is uh these are the the old ones you know but uh so basically the the idea is that you know understanding what Mev is from an incentive mechanism standpoint involves really undersing many different applications right there's of course the most common type of Mev with amms but amms of course add a ton of different properties that make it easy to understand them there's Mev for Liquidations in lending protocols and Perpetual protocols there's Mev for front running nft auctions all of these things have different sort of levels of understanding for the user and in theory right blockchain is supposed to provide audibility properties verifiability properties and other things that form to users so you might say how is there uncertainty that can come from from these things um so I'd like to to think about the uncertainties as falling on the Spectrum and the spectrum is sort of defined by how much the payoffs that users are taking vary and are uncertain and PBS is aiming to kind of change some of that uncertainty amongst the first four categories which are ordering inclusion atomicity and relaying so ordering uncertainty is I submit a transaction to a blockchain uh and I expect a certain payoff I expect to pay a certain price for a trade I expect to sell an nft for a certain price but my realized outcome is not that inclusion is censorship resistance like if I send a transaction does it actually get into the next block and it's slightly more severe than say just uh liveness which is I eventually get my transaction in I may want to have some time preference on how fast my transaction is accepted atomicity is of course the idea that I can compose two things under it's executed to sort of fill or kill like the entire transaction is executed or single transactions are executed relay which I'm sure you'll hear a lot about today is uh is the uh idea of having you know a networking layer and some sort of agents who uh who who convey transactions who may be more trusted than you think and I think that's certainly the the one part of the PBS system that we'll hear today has some of the incentive problems from many different speakers and finally since we're at the modular Summit we we should also remember the the highest payoff uncertainty for the end user can come from a DA layer if a DA layer doesn't work doesn't doesn't behave as expected you can have arbitrarily bad payoffs your roll up is not working as expected and one question you might say is like what does it mean to move from left to right on this diagram um so just as an illustrative example and this is more a statistical learning theory perspective on this is is I have sort of a class of payoffs that's the script curly F I have sort of some functional say like a variance or some type of deviation and I have some sort of notion of the types of uncertainties and I say what is the conditional expectation of that functional and what does it look like what's the worst case so one definition of Meb you could use is any sort of mechanism that creates payoff uncertainties where unsophisticated users lose value relative to sophisticate users and the uncertainty is the key to the unsophisticated users uh expected payoffs so of course there's been sort of multiple different ways that people have tried to go about this it's not lost on me that everything in the Communist side is only a paper and not a product and everything in the capitalism side is a product and not a paper so just as a funny aside but the communism side is things where the mechanism designers or the protocol designers are trying to enforce a lot of constraints on what types of orderings are allowed to be uh conveyed to the blockchain and the capital is inside the blue pill is how do you make a competitive market for transactions so flashbots sort of created that initially uh I guess arguably the the spam in the ethereum mempool prior to flashbots was the first version of this uh and then it sort of expanded and now we see this whole ecosystem built around this right so we have the red pill we have the blue pill are the really only these two options um well one thing that you know both purveyors of all parties will tell you that hey our mechanism reduces uncertainty for users it reduces payoff uncertainty it's easier for unsophisticated users or it's more efficient for the system as a whole but neither of these types of mechanisms neither the the full ordering complexity piece nor the economic piece actually can remove these uncertainties for users so maybe we should take a step back and try to understand what fairness looks like in general so I found this actually very nice old paper from 1970s from from Hal Varian who's the chief Economist at Google Now um on you know distributive justice and Welfare economics and theories of fairness and the tldr of sort of the principle of fairness he uses the maximum payoff for any particular individual is not so much greater than the average payoff average welfare of any individual and that's sort of the maxim for how to measure this type of uncertainty I look at the maximum payoff that any user gets I look at sort of the average payoff people get and as long as those two things are relatively similar you're relatively Fair um and you could argue that the the Communist the order fairness things focus on one side of this but they're very payoff agnostics they kind of can't tell you anything about whether you're getting the worst case or best case they just say hey well validator said you got this transaction first so I guess I'm putting in first Maybe and the economic mechanism sort of focus on maximizing payoffs right maximizing Revenue that goes to validators maximizing Revenue that goes through the system uh but it doesn't really capture the externalities necessarily as well as you might think and so one question is how do you get this balance between maximizing Revenue which obviously can be good for the stability of these systems especially if they rely on Arbitrage versus making sure the expected welfare for all participants on average is not so far away from the the worst case so one important thing to think about is maybe fairness should be done on an application specific level so the analysis we'll talk about is from the perspective of there being sort of fixed Universal transactions so adversary or malicious Wilder could have added or removed transactions before we analyze it and the only actions that the malicious adversary can take are reordering transactions so maybe it's I have a bunch of Sandwich attacks I'm reordering them so that the most expensive ones are first so that the later ones have to pay a higher price uh and the key thing that we'll talk about is we're going to view these as these kind of payoff functions that depend on a permutation and give you a a value a real number and that that's sort of the the fundamental objects we're looking at so in amms you have kind of this very smooth payoff with enough liquidity reordering doesn't really change the price impact enough and you can kind of smoothly vary how that looks but then on the other hand we have liquidations right liquidations are very not smooth you know if the price never touches a certain point there's no payoff to the user to say a searcher of course the price touches a single point uh you have a jump and discontinuity in your payoff and so what we'll see is that these actually turn out to be the fundamental basis of all the payoffs of this form where you're looking at reordering so let's maybe try to demonstrate this in pictures so we take an amm like a unosop a CFM and now consider a set of transactions there are uh seven transactions here and there are four transactions that are price goes up one unit those are the green bars there are three transactions that are price goes down one unit and as you can see if I permute the green and red arrows I get different price trajectories right and so you can see the first one sort of is like you know up up down down down up up and then the second one is up up up down down and at each point you can say given a permutation here's the price trajectory created by this ordering and so the x-axis is sort of the index as the transactions are processed so one of the the first part of the towards the theory uh sequence sort of showed that for amms this thing is actually bounded in a very interesting way in that provided you have a particular liquidity constraint you the worst and expected Behavior are only separated multiplicatively by a factor of log n so that that sort of is actually pretty good um it means that realistically I'm not going to get that much worse of a price even if I'm sandwich attacked and that paper also showed some examples where people get better prices if they're sandwiches where someone takes a worse price but the N trades in the block get better execution and so there's sort of this somewhat surprising thing of course that these sandwich attacks these things that you know the Ari jewels of the world would call robbery can actually help the welfare of the system which is like a totally interesting and surprising result but the the thing is this doesn't really dictate all the other types of Mev right it doesn't tell you anything about nft minting it doesn't tell you anything about liquidations it doesn't tell you anything about cross chain so we'll start with a gedonkan like a thought experiment and the thought experiment is suppose we construct you know this is not necessarily a good D5 protocol but this is just one that you can analyze and so you'll see why this is important but imagine I have an amm I have two n Dex trades uh half of the trades are plus one so half are the green arrows half of the trades are minus one down arrows and given a permutation I get one of these charts right one of these three things you can see how like permuting the indices gives you different price trajectories right and if the price trajectory touches the red line the liquidation has a payoff of one and if you don't never touch the red line at zero so the idea is this is a very simple thing where I like say I give you some trades I look at all the permutations if it ever touches a particular point then you realize uh again if you don't you realize the loss so what you can do is you can kind of look through the sets of permutations say okay does this one give me a loss no yes does this one give me a loss no yes does this one give me a loss yes and I somehow found some Mortal Kombat uh fonts online and I wanted to write you know like you know the Finish him finish her thing I I figured writing liquidata in that font would be fun uh so one very very interesting fact is any payoff function that you can write in a blockchain that is a function of these reorderings of these permutations can be written as a linear combination of these liquidation games so any payoff that means for any application is written as a sum of these different liquidation games that's sort of something that's very unintuitive that that the these kind of very abstract things that you find in D5 for people taking leverage somehow are a basis for the set of all payoffs you can get but the interesting thing is the liquidations are much worse than the amms and the amms we showed this thing where it's bounded by log n but in liquidations I can construct something where it's actually the ratio of the worst case payoff to a user versus the average case is O of n factorial which is obviously significantly worse uh you know you know with needless to say that's not really an ideal thing so that sort of says this idea that the space of these you know welfare metrics that you're measuring on users can vary quite a bit and again a lot of the kind of things people have made and said that would fix and make things more fair don't solve this problem like none of the ordering schemes in the Communist column actually can can correct this so you might say okay well what do we do to actually measure how fair these things are is there a way for me to say give me your function and tell me what the difference between the maximum payoff and the average payoff is and and give you some guarantees on fairness and so we'll we'll see that sort of some analog of a Fourier transform is the way to do this so one thing kind of just as a a reminder or you know if you haven't seen it well what what it what is the traditional Fourier transform so you know if you think about sound waves what you're doing is you may have this turquoise curve that represents the analog sound signal you're hearing but you can decompose it into high frequencies and low frequencies so maybe high pitched voices and low pitched voices represent the red and blue curves and the Fourier transform lets you take different segments break up the curve into pieces and say okay this is the sum of these different components you might say what does that have to do with Mev it's like a smooth curve and someone's singing and all sorts of things like that but the interesting thing is it turns out all of these payoffs under reorderings you can write as the sums of liquidations and the analog of the the sinusoid curve the single pitch is actually a liquidation and so the high frequency modes are liquidations where there's very few permutations that can trigger them very few reorderings and the low frequency modes are ones where there's many permutations that trigger them so you can kind of think of it as it when I expand out of payoff I am looking at how constrained I realize that particular payoff uh and you know again like as I was saying this is sort of a fundamentally in important thing is that something that we understand relatively easily and that people do in practice liquidations actually generates a set of all payoffs now this expansion might be very big right I have a sum over a subset of subsets of permutations there's two to the N factorial of those so there are many of these you might need to expand it but the key is that this is a basis like it represents the the core set of all these payoffs and I I put examples of people involved in the algebraic versions of Fourier transforms uh those pictures so one question is what do we again how do we interpret this Fourier transform like what does it really mean so one way of thinking about it is the Fourier coefficient f-hat and these are sort of heuristics there's a lot you know the Fourier Transformers over finite groups is quite a bit different than the continuous one is if a for a set is large of permutations and the Fourier coefficient or that set is large that sort of says the permutations have the function achieves its average value on those if the set is small but has a very large Fourier coefficient you're near the maximum value and so the idea is that this is why the spectrum of this thing captures what the maximum and average values are of these functions so you know there's a bunch of things you might need to talk about these we're definitely not going to talk about them and since it's a Celestia conference I had to put uh Jake Jacob always says weird aphorisms such as none of these words are in the Bible so I I've he's mad at me though for picking this picture but if it's the first thing you find when you Google his name so uh you might say okay great I have this Fourier transform I can take any function you give me in a blockchain I can sort of write it as a sum of liquidations and that's like what the user gets paid but that's great but like what does that tell me about bounding the difference between the Max and expectation uh many of you may have heard of things mimetically like uncertainty principles but uncertainty principles exist outside of just physics in fact they exist in information theory in general as the sort of lower bounds on localization so I can I if I can squeeze a function and make it very sharp I can't make it Fourier transform super sharp also uh and a very nice thing that turns out and this is exactly why we're you know the all of the stuff we're talking about earlier is important is a liquidations generate all the payoffs B the Fourier transform it gives you a way of going from your payoff to the payoff represented in the basis of liquidations so the Fourier coefficients really give you how to expand it in terms of liquidations and see the uncertainty principles give you a bound on the max over the expected value over the max value which is the difference in payoff for users so this gives you an explicit way to quantify this type of fairness and you can kind of think of this inequality as showing you fairness bounded by sort of these spectral properties uh I didn't want to go into any more details for this but you can read the paper but I'll just give you a very very tiny uh kind of understanding but the idea is if you allow a large enough number of permutations there's sort of a notion of the size of the number of orderings you allow is sufficiently large relative to the Fourier transform you actually avoid the maximally unfair payoffs where the expected value is extremely small relative to the maximum on the other hand if your sort of sets of orderings don't have sufficient overlap with your coefficients you will all you'll get a lower bound on fairness you'll always be at least some amount unfair and this sort of shows any of these types of ordering mechanisms whether they're the time-based ordering and arbitrum whether it's pure Fair ordering sequences whether it's sequencing rules they all only work for certain payoff functions right they only work if they don't they they restrict the set of orderings to some set of order to a certain size set of orderings but that means they distort any payoff functions that depend on orderings with a larger size and so you get this kind of lint sort of Shannon sampling limit of like the payoffs are tied to how you're ordering algorithm you sort of can't you can't get a free lunch of like offering things like first come first serve uh and satisfying every possible payoff function which is what this says the second thing is you could think of this as like a sampling theorem so uh the sampling theorems are you know the most practical time you've ever encountered one of these is when you've you know maybe listened to an MP3 that sounds really shitty and then you go you know get a vinyl and you you listen to and it sounds great and you're like oh why is the MP3 sound bad well the MP3 didn't sample enough frequencies for it to resolve correctly versus the analog and this is sort of a sampling it says like for a payoff you have to have resolved enough frequencies for you to be fair in that payoff so what what this sort of suggests is the Communist version of the world uh the fair ordering type of stuff things that are sequencing rules doesn't you know is always going to preference certain applications over other applications we always talk about Mev as being sophisticated users taking advantage of unsophisticated users I would posit that the Communist ordering world is sophisticated application developers taking advantage of unsophisticated application developers all you're doing is changing who the person who's enduring the penalty is because the application developer is defining the payoff function and if they don't understand how all this works then they're they may have defined one that's extremely unfair on purpose and now you're forcing the application developer to understand that whereas that's not as true in the the unrestricted ordering case but what this says is application specific orderings orderings tied to these functions are actually can be better in practice and maybe that comes from marketplaces like Suave things that allow each application to specify some sets of rules as opposed to having these Global sets of rules uh and yeah it's much rather than sort of some of the useless communist versions of things so what's part three well everything here is like a formal theoretical thing there's a lot of n factorials everywhere not all of us love sharp Peak complete problems dot dot so the next part is approximation can you come up with measurements that you can make on real functions that give you some notion of measuring how much the Max and expected Mev are up to some error in production and monitor these types of metrics and see see how well people are performing and this paper so with that I actually finished 30 seconds early so if any any question yeah so you you gave this point about household great point when I talked about the the O of log n thing calsop is achieving that so that's what I'm saying login is not that bad right like I If there's end trades and that and I'm able to not get front run but I may have to pay in the worst case log in more in price multiplicatively that's not that bad paying n factorial is much worse right so like that that's the idea like this is like a way of quantifying how much the worst an average are and the point is once we can approximate these better you can run these on live systems and say like oh actually this particular payoff is like not that fair you should like loosen the orderings or or Shrink the orderings and the marketplaces can then adjust after that anything else if not thanks I'm around all day so [Applause] 