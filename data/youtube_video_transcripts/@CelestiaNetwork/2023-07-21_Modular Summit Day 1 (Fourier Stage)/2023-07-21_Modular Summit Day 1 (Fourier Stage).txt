foreign [Music] foreign [Music] [Music] foreign [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] thank you [Music] [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] [Music] thank you [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] thank you [Music] foreign [Music] [Music] [Music] [Music] [Music] foreign [Music] foreign [Music] [Music] I'm not going to keep it too long because we are on a very very tight schedule so I'm going to call lzrs to the stage you are building modular cloud and you're going to tell us something about the economics of modularity so please give him a hand [Applause] hey everybody thank you for coming do I just go to the next slide oh no don't look spoilers okay um so um yeah my talk was originally called the economics of modular blockchains but I realized that that was a very broad topic and it have to cover a lot of breadth and not go very deep on any specific issues so I thought I'd kind of apply some of the principles I was thinking about in that original topic towards answering a very practical question that I think that the industry needs and and what I want to answer is if somebody is an app developer meaning they're building software for users that serves a purpose why should they consider to include modular blockchains in their Tech stack choice and before I before I answer that and go into this I do want to introduce myself I'm lzrs I'm the founder of modular Cloud we make we have a cloud infrastructure for modular blockchains and I am on a panel in about an hour from now and I encourage you all to attend and we're going to talk more about the specifics of those services that we provide more in depth in that presentation so okay now on to why should people use modular blockchains for their apps so here's the common Narrative of why somebody would want to use or what like what how a blockchain Works essentially usually user and this user you know creates a transaction and they they securely send this transaction to some sort of decentralized network and once this transaction is off into the internet on this decentralized network there's this group of nodes that come to consensus and they verify that this transaction is is valid and update the state and its broadcasts and finalized and sent out to everyone in the world um now I think that this is like a common explanation but I don't think that there's some parts of this type of common conception that I don't like and the the one I want to highlight right now is that I don't like that when people skip when they say okay the user uses the blockchain because I think that really takes out a really important point and a part of the equation and in doing so it kind of makes people that are building apps not really understand where they fit into the picture because the real the reality of the situation is that the user is not using the blockchain they're using a device like a phone or a computer and on that is some code that's run that's written by some sort of third party like probably like it's some sort of project which that is the app and the developers that are building that app are integrating with the apis and sdks provided by the blockchain so the app developer in a sense is the true consumer of the blockchain and I think like as we go on over time um it's gonna we're gonna transition more from everything being where we tell people like okay this is a crypto app this is a blockchain app and a lot of stuff will be going on behind the scenes once developers realize the power that blockchains can provide them just as a technology in their technology stack so um okay so imagine you're an alien and you're like coming to Earth you have no context about this and you um look at these two apps these are undeniably apps they're both on the Android play store so you can install these apps on your phone because these are apps these are not blockchains they're not decentralized networks right there's a venmo app and and the Bitcoin mycelium Bitcoin wallet um now what's the I would ask what's the difference I mean you can say there's a different UI different name stuff like that but um by the way sorry I thought the time was frozen but it was actually moving um never mind um anyway um so I'm trying to be mindful of my time anyway um so if you compare these apps um like they both connect to the internet um one of them you could say connects to the Bitcoin Network the other one connects to venmo's servers um but that in and of itself is not a particularly meaningful distinction um what I would say is the difference between these two is that the Bitcoin wallet is actually not only retrieving the some data from the network but it's also doing some sort of verification on that data and um so um like in the way that it does this is it connects to this very powerful API that you can call the Bitcoin node RPC and what I want to do is I want to in this talk propose an abstraction that we can use when we think about talking to rpcs and this is going to apply to all blockchains not just Bitcoin I'm starting with Bitcoin because it's a very simple case it's a it's an app it's basically an app chain for payments and over time we've modulized these and expanded the scope of the well that these protocols can do but this is going to be an easier case to explain so I have this abstraction that I'm going to present to you called a cost function and this is how I think that app developers should be conceptualizing blockchains like they shouldn't be thinking about the internals of the peer-to-peer networking and cryptography I mean it's important context you need to be aware of that but it's not the fundamental thing that you should think about when you're considering how or if you should integrate a blockchain into your app so what is a cost function a cost function is essentially um it's if you've given a statement it's the the cost that the that the person making that statement would incur if they were to commit fraud so in the case of Bitcoin this is a very this has a very narrow capability so if someone says I sent you five Bitcoin and I'm going to be very much abstracting this process I'm not talking about actually how this works this is a very high level description of this process but if someone says I sent you five Bitcoin you wouldn't want to necessarily trust that that's true and like do something irreversible like sell your kidney uh just trusting that it's true they could be committing fraud in the the difference between something like the venmo and Bitcoin both are hard to commit fraud on but if you use venmo you don't actually have the information for how much it would cost to commit that fraud so probably you'd probably be fine with venomo but there are situations where having that additional information would be good so in this case this person claims to have sent five Bitcoin to this person in exchange for some few some you know some service or goods and this person realizes that the cost to commit fraud in this scenario is lower than the value of the transaction and now they can make a risk assessment and they can model the risk based on their use case on how confident they are and how they want to interpret that data um between the two but I think that they're actually connected at the last modular Summit I gave a talk on the subject I encourage you to check it out if you're interested in learning more about that but I'm not going to talk about that here um so okay so how does how does the cost function work essentially um you like you start off by having this assumption that you have access to the open internet and you through accessing a peer-to-peer Network you're able to scan and get you know all the possible change or maybe not all the possible chains but among the chains that you can find when you scan the internet is the one that you are looking for which would be called the canonical chain it would be like for example the longest Bitcoin chain with the highest difficulty that would be the canonical Bitcoin chain and what happens is you retrieve data from the network and then you apply a rule set to actually determine which of these potential canonical chains is the canonical chain because you can't of course trust anything you hear on the internet just because someone says this is Bitcoin doesn't mean that it's true so the way that this works is you can break this down into two pieces first is validity and the second is a fork choice so if you think of all these things as just Rob bites like just blobs binary data you will parse that and you'll check if the structure of that data follows the rules of the protocol that would be checking the validity and then even if you have 10 chains maybe there's eight of them are valid and two of them are invalid you still have to decide which one is the canonical change so a fork Choice rule will take two potential chains A and B and it will return either chain a or chain B depending on which one it prefers and if you go through all possible chains that are presented to you from the network with this connectivity assumption assuming that you're connected to the internet you should have by the end of it the preferred chain out of the whole list will be the canonical chain and so how this plays into the cost function is that there's this thing I don't really know what I what we should call it but maybe we can call it like security units once you you know have this data and you are um you're able to and you know what the canonical chain is now you can actually statically analyze those that that binary and you can determine what would be the security units that it would take if someone had these security units in an abstract sense could they commit fraud into the system so let's go through a concrete example of this so in the what we're talking about Bitcoin um it's proof of work so you there's a certain hash rate and if you so that like a hash rate would be a unit perhaps and if you had enough hash rate you could do a 51 attack and now in and of itself that's not actually that useful because how do you know like how hard it is to do that hash right maybe you can use your laptop or something and and you know commit fraud um so you there's another assumption that goes along with um this this assumption that you have access to the open internet and that's access to Market data I mean this is not built into the Proto call so it can be kind of counter-intuitive that but but this is actually really key to properly utilizing blockchains and so with this Market data basically what you want is the cost of the hash power so in this case essentially I don't actually know how people really calculate this but I assume it's basically like the electricity costs and maybe something to do with like Hardware but there is a way that you can model the cost of getting the hash rate that you need to commit fraud and from that this is what you would have as the cost function and you can now say based on this statement that I'm verifying how expensive would it be to you know commit fraud in this case and then now I can determine based on the circumstances for my application how I want to interpret what is on the blockchain um so and then of course like who uses proof of work anymore I guess right so I mean proof of stake is exactly the same thing it's like you have your tokens that can be slashed and there's a price of a token you have access to Market data you can do the same exact thing it works the same way um and so I'm not going to go into this connectivity assumptions but I do think that this is one area that really does Chip people up because there is an assumption when you're using blockchains that you have access to the open internet and if you don't actually a lot of things break down I think when a lot of people think about it they just look internally into how the protocol works and sometimes not all the answers are there and so that might be a disconnect why some people don't understand the value prop of crypto but I'm not going to go into this because we just don't have time um but I do want to talk a little bit more about selecting the canonical change just to be a little bit more clear about how this works essentially you're getting all the chains um this is the pseudo code you're filtering out the valid one so now you have a list of valid chains and now you're just literally running a reduce of the fork Choice rule on all the valid chains um but what's interesting is you can actually collapse this down and you can combine validity into the fork truth rule itself and it could it would look something along these lines where instead of a function that takes a and b as an input and returns either A or B depending on which one is preferred you also can return like a nil value if both chains are not valid so you're just both basically checking the validity at the same time as determining what is your preferred fork and so um this is actually I would argue like the most cons or the most concise abstraction on for how a blockchain like what is the blockchain all this other stuff is implementation details like are you using proof of work or proof of stake do you have like Merkle trees like a lot of these things are like just it's it's to achieve this but this is the actual conceptual um like the essence of what we're actually working with here and the but the thing is though is again I want to reiterate that the four Choice rule by itself is not really useful because you're okay this is the valid chain but like what's the implication of that right you need to have what I call this like broader thing which is like this cost function to understand how like what does it mean like when you when something is when you find data in this chain what is the like what kind of guarantees can you expect from and like how expensive would it be like how much can you trust this data essentially um so I want to like I want to now build up from Bitcoin to modular blockchain so we can see how this all ties together um so um okay so Bitcoin had two problems and I wanna I wanna Focus mostly on this first one and essentially the problem with Bitcoin is that it's hard to engage in Commerce with Bitcoin and one reason for that um is of course you have to get a bunch of people to get Bitcoin wallets you have to get businesses to you know put their payroll or their point of sale system on bitcoin that's all very hard and we've made very little progress on doing that um but there's also kind of a more fundamental reason why it's hard and that's because um it's really hard to bridge on chain and off-chain events um and like the people working in real world assets and like dealing with oracles and stuff they they face this all the time and I won't go into the because we just don't have time I won't go into the theoretical reasons why but I think there are some interesting things uh for why this is true but I'll give you an example to make this more concrete so like this was the example we went um so like someone was gonna sell their kidney or something um and um this person claimed to send them five Bitcoin but really did not and um they were able to not trust that because they could calculate whether that it was likely that they could be profiting by committing fraud in this scenario um now this works in this narrowly defined scope of saying I sent you five Bitcoin in the the because because essentially like that's what the Bitcoin app does it's a payments app um and the um so the the cost function can let you verify that this the the cost of how much it it takes to commit fraud in this case but it can't do other things like for example if they claim to have provided the service um you wouldn't be able to verify that that actually happened you'd have to introduce some sort of Oracle and then that introduced additional risk into the system and you know all this kind of risk the more risk that you introduce in the system the more you have to have a margin of error on anything that you're calculating and eventually if you have enough error that's going to all compound and it's going to be a useless value so you want to constrain any of those things you want to have as much to be directly verifiable by the cost function as possible and so um the way there is a way that Bitcoin could have addressed this and expanded the functionality if they wanted to and I'm not saying that they should have I'm just saying they could have and the way to do this would be to hard fork and add more op codes and increase the power of their of their scripting um to you know do the other things um to do other things that people want to do and the more things that you'd want to do the the more I think the more different types of statements you'd be able to verify with this cost function and understand you know you understand the context around how expensive it would be to commit fraud in these scenarios and um so but they didn't do this and why did they not do this I think this is a really important point I actually think it's exactly what you would expect um so there's this thing called Brook's law and it talks about how you add Engineers to a project and it it makes it harder to actually complete the project because essentially as you add more people the lines of communication increase combinatorially so what this means is as you add more people to a group the communication overhead gets way more and more and more difficult and and the implication of this is at a global scale you really can't coordinate it's not possible it's prohibited and that's why you know these permissionless networks are really great because you actually don't have to coordinate and I'm not going to go into this but I do want to say like this this idea that you know Bitcoin or that blockchains you know allow people to reach consensus I think is not a good way of all of looking at about it I think blockchains allow people to verify things and calculate the probability of fraud but they actually work because you can't come to consensus like for example a 51 attack or a 66 attack like these would require consensus among the participants of the network and the fact that those don't happen because that's very hard and very expensive is the reason that this works so we're actually playing off the fact that you can't reach consensus it's kind of a it's maybe not important but I just thought it was worth mentioning um and so essentially it makes sense that Bitcoin wouldn't be able to upgrade because everyone's verifying their own thing independently for their own purpose and you'd have to get the people sending it to upgrade and the people receiving it to upgrade because you want to be sending with someone's trying to receive and receiving what someone's trying to send and it's very hard to do so um if ethereum fix actually fixed this problem though because what they did is they modulized the application logic of Bitcoin and so um like I if you remember I'm not going to go back a bunch of slides but I had this diagram where it showed that the cost function or how or the canonical chain is determined by the validity rules and the fork Choice rule um well essentially what ethereum did is they modularized the validity rules and so you're able to essentially do something like this which is where you can make a statement like I did X according to module Y and that module y would be a modular validity rule set that can be loaded all into the same blockchain but the thing is is since this is modular you don't actually have to um you know Fork the network and you reach consensus with the entire developer community and all the users that are verifying the chain so it's this allows people to build this stuff and use it in a modular context without the coordination overhead um so allowing you to not just um have a modular validity set or validity rules but also a modular Fork Choice rule so you're able to Define um so like if you think about like a roll up on Celestia for example essentially that roll-up has its own four Choice rule with its own validity rules and its own for choice but it also uses Celestia's for Choice rule as an input so it's it's not just a function that takes a or b it's a it's a higher order function it takes a b and another function which is a fork Choice Rule and so in in this kind of way you're able to um get you you're able to import the the verification capabilities of other chains into your chain and that's what a roll-up essentially is in its Essence and so um like this allows you to express a greater number of um of things that can be verified and you can understand the the cost of fraud in these systems and so I'll just kind of go through this little three-dimensional diagram like initially we had like an app chain which was Bitcoin and you could just basically have different wallets and they're just verifying these very narrowly useful statements which is I sent you this many Bitcoins then we had ethereum that would allow for dapps and this had so many more use cases like nfts and D5 and stuff like this and there's a lot you can do with this but now what we're going to have is with modular blockchains we just kind of added this other dimension here since you can customize the the full Fork Choice rule you're actually able to even do more interesting types of things like for example you can customize you can like decrease the level of security and so that you can increase like performance as a result and you can verify things in you have more customizability in in actually setting the um the parameters for the use for detecting fraud in the use case that you are actually building for as an app developer um and so yeah I think that's my time so this is like a great place another conclusion sliders here so thank you everybody I appreciate you coming thank you Liam that was Liam next up is Andres ah there we go the pointer from range and you'll be telling us something I think tacking onto this on security of uh modular chains there you go hi everyone uh I'm Andres Monte co-founder of range and today we are going to talk about sovereignty and and security and also how app specific uh roll ups can be the answer to the security problem in crypto so I have a couple of questions before I start talking and yeah here for you which is uh who in the in the in the area in the room things that uh ethereum would Fork if there's taken deposit contract uh would get wiped out and all the Eid was stolen like raise your hands if you think would have another doubt for contentious Fork okay who thinks it wouldn't okay maybe we have like uh 75 that we would Fork who thinks here that if Lido all the TBL of Lido all they is which I'm not sure if it's between 10 and 20 of the supply got hacked uh who thinks here we would Fork as with the dove work now one okay that's interesting so then like if the all the TBR of maker Dao got hacked and now will you hear things that we would Fork right okay that's interesting uh we will come back to these questions later uh but yeah like let's start kind of a stepping back and and understanding what's the level of of security in crypto uh we are doing not fine uh in in 2022 more than three billion dollars were affected uh some of these were recouped but but definitely like we are not doing fine uh this is a huge number and I always try to make analogies uh with kind of more real world numbers so this is I think almost 20 percent like three billion dollars almost 20 percent of the annual defense budget of my home country in the European Union so we are talking about very very big numbers right and I think everyone in this room agrees that security is important I would go even farther I would say that uh I mean I'm biased but I think that is the key and solved problem in crypto from instant adoption uh it's great that we are working on solving scalability uh it's great that some people are looking for product Market fit but security like nothing of that matters if we don't solve security a good example is x infinity x infinity like was the product that kind of crossed the custom right like it was more like mainstream adopted like very adopted in Philippines but then at some point like the running Bridge was had hacked for more than half billion dollars and you know all the users all the mainstream users that were using like actually probably are not coming back because they got wrecked right uh and so I would like to ask you here uh if we are ready to build like secure model blockchains and if we are ready for thousands of of roll ups or tens of thousands of prolapse kind of talking to each other uh yeah I come from the security background so so I have like uh you know we have certainly some challenges what I call Modern nightmares so like modularity implies that there is uh more external dependency so we have like a sort of like a supply chain risk for the counterparties that we are kind of integrating our model stack we also like using a Cutting Edge stack right like roll ups as your knowledge like this is like super cool technology but it's uh mostly not battle tested in production yet and then as well you know like this world of many many Roll-Ups and blockchains implies that we are like bridges are not going anywhere and cross chain is not going anywhere and and bridges are are complex bridges are hard so I mean we should understand as well that not all bridges are created equal and I think like as a community and in particular this sector of of the crypto Community has done a lot of progress moving from centralized to trans minimize uh and translate Bridges so this is great uh but the reality is that most exploits that we've seen and we've seen in 2022 uh more than 2.5 billion dollars were actually due to implementation flaws so in this infographic you can see well the yellow bars correspond to like a design poor designs so that means like uh for example a case of ronin and Harmony yes key compromise or multi Bridges but all the green bars are actually implementation flows so the point here is doesn't matter how sound and robust your Bridge protocol is doesn't matter if you are using like a trustless bridge trust minimize like ABC or even like a canonical bridge between ethereum Mountain and an L2 there can always be an implementation flow so I think as a community and I think this is happens already in web 2 we need to internalize this statement there will be always said another software back so we kind of need to work on controlling the blast radius of this incidents and particularly uh when we talk about bridges and Roll-Ups that are very complex software projects uh which you know like complexity means a larger attack surface and a more error-prone type of code basis but not everything is dark uh I think like modularity is kind of bringing a new paradigm with all these challenges that I've been talking about but also like a lot of opportunities and I think like the opportunity is definitely outweighed the challenges and I generally believe that app specific Sovereign Roll-Ups might be the only possible way actually to build truly secure blockchains and and this is not talking about like five years ten years from now right like the future is now like prices like Celestia are going to enabled very soon that you know there will be thousands or tens of thousands of relapse Sovereign talking to each other and that every application is going to have its own roll up uh and also like kind of align with this beautiful vision of like Community computers where all the stakeholders are aligned so in this world uh sovereignty rules and and for this I always like to use this analogy of of seeing blockchains as countries and seeing Bridges as sort of like International treaties or International relationships between these countries or or blockchains we are going to talk about these three things in this context so blockchain jurisdictions uh borders and trade control and separation of powers who knows about like the BSC hack here so this is a very interesting exploit uh it was almost the biggest exploit in the history of crypto I think was around like half a billion dollars hacked but the most interesting thing about this is that um the binance validators let's say the binance validators were able to post the chain and hold the chain very quick to control the Plus radius so like the hacker was only able to get only in quotes uh 100 million dollars out of the chain so was able to bridge out 100 million dollars but all the 400 million dollars that remain within the blockchain jurisdiction which is the BSC chain were able to be recouped and recovered so this is a very very interesting example there is this another one which is this is not security related but it's also like a proof of of the power of of social consensus so that you know blockchain Community decided to confiscate uh tokens from from a whale address that had received more than the community thought was okay in an airdrop that was flawlessly designed and then this was through Community governance and and they actually confiscated the defense and of course the downforg which I would say is top three in terms of importance of events in the history of crypto uh this happened a long time ago like seven years which in crypto years is almost 50 years ago but but it's also like a kind of the importance of social consensus so also like regarding that out I would also like to question ourselves how would this happen if ethereum back then was connected with different Bridges so like if the Dow hacker was able to breach out part of the eighth or if there were stable coins that were already like in this primitive ethereum chain right so with these three examples what we see is the importance of social consensus and blockchain jurisdictions but also that the the power of these jurisdictions starts and ends in the bridge and this is specifically clear in the case of of the binance hack and these you know like the importance of the breeds bring us to this part some of these things are going to be a bit controversial but uh but yeah like it's I think it's worth it to explore them so the importance of the Border in blockchain context and trade control so I would say let's be the wall or at least let's explore if we should build a wall of course this is not a political statement but I think that we should explore how you know like breaching works right now breaching is binary right it's either we connect to a chain or we don't I think like this is very primitive and and we should explore ways to parameterize this to make this more granular with mechanisms like rate limits transaction delays like the world Hall Governor has implemented and as well like with transaction screening and blogging I'm not talking about Theory here like there are many applications Cosmos chains that already do this type of blocking with Blacklist there is thousands of D5 applications that do this as well but this is not explicit and that's why you know you need to post the change and hold the change because you don't have this type of mechanisms in place I would also like to talk about ABC rate limits I think this is a super powerful primitive it's I think to what I what I think is that is the first governance configurable rate limited standard this is in production for uh bridging fundable tokens over IBC and this is super important because it doesn't only covers you if IBC implementation is actually exploited but it also protects you so protects you as a community as a chain or as a roll up if the search chain is exploited so in the case of binance if we had rate limits in place that this attacker wouldn't have been able to get 100 million dollars but maybe 5 or 10 million dollars and also like the binance validator set wouldn't have been able to wouldn't have needed to pause and hold the chain and also more importantly it also protects if the destination chain is exploited so like it gives Community like Sovereign Roll-Ups and blockchains as well sovereignty over how much you trust your counterparties so there might be the case that you want to bridge with a new uh fancy blockchain but you don't really trust their technology debt or their Economic Security so the rate limits enables you to parameterize this and kind of position yourself in this trade of space between security and liquidity and this is just the present I think ABC limits in the future are going to be like very different much more complex and much more Dynamic and Powerful for example a standing medium fungible token transfers but also like being able to dynamically adjust to events that happen on chain so something that would be very cool is that if real limits could be integrated with on chain events like upgrades so if a chain upgrades you can Define like a small rate limit because upgrades are normally error and then as you get more confidence on the new version you can gradually increase the rate limit and then the last one is separation of powers I think this ruling encapsulates very well like the the power of modularity the ability that you can kind of specialize every Ledger of the stack and build like customized mechanisms in our case build customized security mechanisms across all the layers of the stock something that I think can be super cool I know that other teams are working on this which are modular mempools this is something it's a concept that we've seen already in the wild Cosmos change like Terra Define like mempools that have prioritization for different transactions so for example Oracle transactions are going to be always at the beginning of the block and I think like this can be super powerful in the modular context a modular paradigm because we can really customize this uh combined like with app specifics Orient Roll-Ups and really make this super powerful combining with security mechanisms customized for the given application this is the case for example for circuit breakers so we could see a feature where circuit breakers are totally adapted to like the app specific roll-up functionality and also have more priority in the mempool so then we can make sure that all security related transactions get put at the beginning of every block and this is really like the future we are building at range so we are providing the tools uh to for for blockchains for Sovereign Roll-Ups in both the cosmos and Celeste ecosystem to express uh their sovereignty and also the security and how are we doing this so we are integrating of chain monitoring systems and on chain mitigation techniques like rate limits uh circuit breakers and more and also we put a lot of focus on on Bridges as we discussed in the call we see Bridges as as the border and and this we should put a lot of security uh in the border right so we are building security mechanisms security mid admitters around translates Bridges like IBC and yeah like as a little surprise we have integrated uh MoCA in the in Rage test net so so yeah from tomorrow from the second day of the modern Summit you will be able to to Tinker with the star monitoring addresses transactions and messages in in mocha from the range uh Community app and and yeah that's that's all um join us at range.org I'm as Monty and Twitter and I'm always super down to discuss all these topics some of them are controversial some are there are less controversial but I'm always super super down to discuss this in Twitter and also in the conference I think that we have a bit of time for for Q a so if you guys have any question or if you would like to you know like come back to any of the slides also happy to do that thank you [Applause] so we have five minutes so if does anyone have a question no questions yeah that's a good one uh I yeah I definitely believe like if there's taking the positive contract is hacked I know they is wiped out we definitely Fork I think that if Lido gets hacked and all they eat uh gets wiped out I think we would probably Fork like I think like the room only like 25 of you said that or almost now one I I think it would uh it's a meaningful percentage of the supply of of it and there is a lot of yeah quite important stakeholders as well um so yeah I think like there is like uh more than 50 chance that it would with maker I don't think it would and that's if I were a maker though an application like that and kind of came back with the rest of the talk um you know you have a DBL of I don't know what maker that has interviewed but maybe like 10 million dollars I'm not sure exactly but I should ask myself as a community that I have like a TPL of 10 billion dollars but then I don't have the ability and the power with social consensus to be able to to to do this type of decisions right so you are handling a lot of money but you don't even have like the power like to to decide these type of things and that's why you know Apple specific software and roll ups are are so important and so like powerful in the future for security because its application imagine like this maker though uh app specific solving roll up would be definitely like able to to decide like a fork if all the you know like eth or older TBL uh were you know affected in a hack so that's kind of like really the connection and and why like teams like maker now and others should definitely like consider launching us or enrollability yeah all good all right thank you Andres give him one more hand next up I think we can uh save a few minutes here and there so uh bunny if you want to come to the stage money is building Dora um a search engine slash Explorer for the modular ecosystem this is your uh there you go the big green button so give him a big hand [Applause] hello hi everyone my name is I'll say my real name Mauricio Trujillo and also known as bunny or Conejo capital on Twitter um we're building a multi-chain search engine a block Explorer is called Aura and also thank you everyone for being here right now um yeah name a talk what we search for search engines in a narrow modular existence so first of all what's what does this mean what how can Dora actually help with any of this what does it there you go how can I how can we actually use the search engine approach to approach let's say some stuff that have been talked about already modular applications being able to actually interact with epic specific specific chains and also how do people actually even just to begin with how do we approach infrastructure today what are the different heuristics that we interact with some of the ones that we were already talked about um application specific Roll-Ups and so on so forth intensity creators multi-consistent type of application then search data how do people actually relate to all of these goods and services day-to-day how people start searching let's say through Brands instead of searching for a very clearly defined queries to engage with a good and service then externally Blended monolithic chains as opposed to internally random modular apps that may leverage infrastructure that is embedded exclusively that is very opinionated as to what they may enable and as well as hey how do we ultimately end up engaging with all of this so first of all I see a little story so Jazz and Jacob also from the Celestia team approached me they're like hey bunny can you actually speak at the um or something I'm like yeah I'm more than happy to um always ready to speak whenever someone else needs to so well the first things that I go is like okay I have no idea what people are going to be talking about modular Summit or then it's modularity in the overarchy sense of the world so what do I do I start searching how do people actually start searching in their day-to-day lives people start searching on their day-to-day lives in um let's say at least within crypto we've somehow stumbled upon the uh semblance of having intense intense meaning um whatever your definition of it may be as it being bounced on the end state of uh of an action on the state change constraints on this stage on the stage change or also as Vlad said something along the lines of uh they are a glimpse into your into your deepest desire the deepest desires of someone's brain no matter your definition of intents there's something that we cannot clearly agree is Express this is something as simple as I want to do X and that's it so how do intense are you how are intents able to leverage and stuff like D5 gaming nfts and identity specific applications they're able to leverage all of these because they don't necessarily make any concrete differentiator between them they may not necessarily measure different security assumptions they all they really care about and that is the nature of intenses that your end interaction gets fulfilled and that's it how does what type of world do we will we love this type of infrastructure the type of world that we build is one in which is composability is pretty much unquestionable and we end up in a world in which we have any to any type of relationship between goods and services in which if no matter what resources you have currently available there will always be infrastructure that allows you to partake on any good and service You may wish so how do we how are we actually able to enable this we have some multi ecosystem infrastructure this is honestly one of my reverse decks we have some of the people in the room uh from those logos there you may recognize a couple of people from Caldera modular Cloud that um it's quite skip routing mechanisms roll up as a service indexing mechanisms they're all very and of course intense they're all very much needed to be able to enable this type of theme this type of workflow that people are very used to in the regular World um that regular world meaning outside of crypto but is that how people really relate to sorry sir to go back this one sorry thank you how do people actually relate to all of these goods and services within crypto and how do people relate to all of these outside of it it's very clear there's a very in there's a point in which every single clear crypto office does starts pretty much looking like each other uh we call this effect uh in seeing recognizing patterns where there might not be any uh paridolia there's a parody of the apps in which people start seeing stuff like nft marketplaces on uni stuff people start seeing stopping mechanisms within NXT marketplaces people start seeing options where they may not necessarily be a need or a desire for someone to actually start leveraging options so what we find is that all of these goods and services eventually become commoditized something very fascinating though is that while the business services may be commoditized their providers are non-fungible every other provider will be selling you the exact same thing but in a much different type of delivery packaging that some people may be used to and that's actually good that's very good actually so how do people outside of crypto relate to um searching intents and fulfilling of any desires they may have we where can we actually look at something like this we can look at search data which is honestly one of the most valuable data in the world in my opinion um people don't necessarily look for goods and servicing in a very clearly defined query um they actually if you look at the top 100 searches on Googles or even across their changes uh especially if you start very heavily localizing people relate to goods and services through Brands they don't necessarily um it is very rare that actually something that's con as concrete that is not brand heavy makes it to the top 100 searches is usually just related to like World Cup events and even then you could argue that okay there are events there are sports so we have bronzers branches of proxy for actions uh we have antimeria in which the verbalification of nouns uh not the announce nft of course but what we get to is that we have these two first and second degrees of Santa Maria where a lot of infrastructure is currently laying on is that we have for uh we have ways in which you have protocols like don't necessarily protocol election an action at this point emailing uh people feel very comfortable saying hey email me just send me a message they don't necessarily specify which provider they may be engaging with and that's completely fine another way of using um is not accessing protocol but something's akin to being able to emit a message uh Twitter people feel very comfortable uh using the anti-meric or Twitter tweet it um these very easily allows us to convey hey I want you to express an opinion I want you to tell that opinion to the world people feel very easy doing that so if this is how people search okay we understand that brands are very important we understand that maybe it's actually good to have branding around certain applications maybe certain chains but is it enough there's this concept of branding externally branding your monolithic chain it's in this sense meaning that if you have an uh let's say a 4K VM chain is just done it's exact same thing as an evm but you just happen to have an nft Marketplace in that chain and that's all that you really do there it's not necessarily optimized for nfts it's just a chain that has an nft is marked an nft smart contract and that's completely fine and that's pretty good for most people where we very much like to push for it though is that we want to people people to be incredibly opinionated about the infrastructure that they leverage for their specific use case in this case in this senses where we are actually pushing for is app genes we believe that very entire approach will be to create Brands around a generalizable chains applications whereas what we should be aiming for and forgiving forgive me there's a typo there is to create infrastructure around so change specific applications in this sense if you're application they say very high frequency trading specific application should have instant uh the shortest finality time actually we can test it maybe something like IBC should we considered maybe something that um I don't know the ydx is a very clear example of that maybe there's applications in which you should rely more on social consensus as opposed to some very very clearly defined cryptographic security mechanisms who knows we can play around with this the ethos of modularism is very much of built anything and we strongly believe that if we should build anything why shouldn't we actually build this in a way that we can actually start iterating on goods and services on monolithic ecosystems watch which is precisely what we've seen and then actually go into production and optimize for service providers for different service providers economic incentives on something like a modular stack in this sense one of these examples that is actually a paper that is should be getting published either today or tomorrow by tarun chitra is in how sequencing and the you can mod you can model pretty much every single day if I app has a sequencing of Liquidations in that sense if you start considering that sequence then ordering becomes really incredibly important and you can start arguing for the 13 certain sequencing of uh how to say it of certain chains should be the most theoretically optimal for this specific D5 application that is a fascinating concept I think is very interesting to say every single application that is deployed on this chain will not have a Competitive Edge against this one D5 application that's fascinating so now every single app is a chain how do we actually go about searching every single one of these applications how do we actually go about engaging with every single one of these providers uh once we every single one of these providers starts looking the same or hopefully they don't and one of all and once every single one of these providers is able to leverage their specific infrastructure that makes their ecosystems Blossom as much as as almost theoretically no one else can what we do what we do at Dora is we like to take the approach of our generalized generalized search generalized search engines we very much believe that power users will and end up engaging with topic and specific aggregators uh we're all in Paris right now I don't know how many people in the room are based out of Paris or even France or Europe in general but I will bet that most of you ended up using at some point either something like a airline aggregator maybe at first we started engaging when we first got into the industry we're like oh I'm going to my first conference I want to use I want to I want to see what I can use for traveling if we were in very extreme experienced Travelers before we probably use something like Google then in the end we of course narrow down into okay I want to use my Expedia I don't know there's there's plenty I just use Expedia because very convenient um but what we see for an appropriate ecosystem that lends itself to being Mass adopted is that users will engage with the most generalizable meaning the one that and he's able to capture the most providers has the most coverage friendly quite simply just being able to understand it from the get-go uh I thought it was fasting it was insane the first time I got into a plane I was like wow how do people actually get this and my parents told me oh you just go on the internet and it was blown away by that and provider acknowledge search engines if we believe that every single one of these Brands is actually incredibly meaningful to the experience of a user actually engaging with this good Services search engines should be incredibly intentional as to what brands they're leveraging in order to provide all these services well we do Adora is you have a couple examples of it actually um what we do adore is we try to be incredibly intentional as to hey these are the specific tokens that you're you're solving this um if we click on let's say the crypto.com too the transaction there you and yourself in UCC we tell you that you this uscc is being provided by Circle if you click on every single one a Smart Country we try to make it abundantly clear what types of organizations these smart contracts are associated to that way hopefully giving people their Assurance of hey you don't necessarily even have to trust Dora right we're a search engines uh there's a very uh funny thought experiment that maybe the chain is dead and the block explorers have just been producing information for you uh that could be true blogging Sports could be lying to you um but still we don't want people to trust us what we want these people to trust friends that is who they seem to trust right now that is who people I mean Celeste is also a brand we seem to trust them to figure out modularism they're doing an amazing job at it so therefore I wouldn't why should we actually change the way people just behave and think right now and thank you so much love you all thank you for coming here okay thanks if anyone has any questions as well more than happy to um yeah if anyone has specific questions as to how our stack works as well because it is infrastructure day as well more than happy to dive a little bit more into that yeah feel free um Yeah we actually I think blocky sports are actually interesting on that because we haven't found a whirling which we needed to rely that heavily into the into our own proprietary technology up until recently um there was a very much a rundown to the bottom on stuff like indexing within evm chains that was something that we found as how does it there were applied to providers that ended up showing up there's been a run into the vanilla so how to actually go about indexing it I think we've done a fairly wonderful job at it uh not only us but also some of our close Partners close guys simple hash um I think it is an interesting question as to see what are are we gonna see a run onto the bottom indexing approaches on a modular ecosystem I think that is honestly quintessential to be able to even begin to Fathom whether or not we're going to be able to let this ecosystems Blossom um yeah I think there's a couple really good teams doing amazing work at that I think modular cloud is one of those themes so let's see how we can make this ecosystems be better than everyone else [Applause] thank you bunny um yeah we're a few minutes ahead of time so I don't know looking at the panelists I guess whether you want to jump on stage already you're ready to uh to continue all right next up is the panel on developer infrastructure we've got again bunny um Jordan you want to come to the stage from Austria Celestia representative Josh lgrs again from modular cloud and then Steffy from massari is going to be moderating the panel are there enough chairs to sit down oh there's one more no no no no there are plenty of chairs all right so please give them a hand [Applause] testing's on yeah well hey guys thanks so much for being here today I'm super excited to talk about developer infrastructure in the modular context um you want to get us started by introducing yourself and about what you're building your protocols I guess I have the microphone so I'll go first hi I'm lzrs I'm the founder of modular Cloud so we're building cloud services for modular blockchains and our first product is a a block Explorer it's one of the things that we do we have a definitely a very different approach to Dora and we actually work with Dora and we're very good friends but um we what we do is we index da layers l1s as well as the Roll-Ups that are on top of them and there's a lot of really interesting implications to doing this and a lot of different architectural decisions that we make as a blockchain cloud company that differs from ones that were previously servicing monolithic chains so I'm excited to dive into this more on this panel hi I'm Josh and I'm a Solutions engineer at Celestia labs and we're building Celestia which is a layer one data availability and consensus uh layer one blockchain and the goal of what we're building is to make it as easy for people to deploy a blockchain as it currently is to deploy a smart contract so yeah really excited to talk about infrastructure for developers today I'm Jordan I'm the CTO co-founder of Austria uh Austria we're building a modular uh shared sequencing chain built on top of Celestia right now using modern da the the goal of what we're building here is to make it such that when you make deploying a roll-up is as easy as deploying a smart contract that it can also be done in such a way that it's decentralized today the l2s and whatnot that people are familiar with using all use centralized sequencers and so we're trying to to change that and hopefully create a you know a better future for us in that regard hello again my name is bunny uh also Maurice Trio which I was fine um military multi-chain search engine call Dora as LC lcrs or l s z ERS uh said uh we work very closely with them uh there were the block is for a modular block is for a modular indexer uh or also a roller power indexer many names for it uh wherever they are multi-chain search engine um we very much like to uh we made some interesting infrastructural decisions let's say as well in order to be able to support this module infrastructure we're very happy to talk about it um a lot of that is just pretty much pretty much relies on very heavy collaboration amongst all of these very compostable infrastructure um so I think a common theme that you know all of you guys talked about and just building modular in general is you know how do we make it simpler to you know build blockchains or Roll-Ups for for teams right um but at the same time you have to interact with a bunch of different layers a bunch of different you know piece together a bunch of things you might not have had to before um so I guess my first question is generally how do you think that developer infrastructure and tooling can you know support um you know making things easier for developers and perhaps if you feel as though developers that are thinking of building module are a little bit intimidated you know in doing so and you know what can be done to support them is that is that for me it's for everyone we can I'll take turns yeah I think that this is um a actually a very um difficult problem in engineering but I don't think that it's specific to modular blockchains um when like so the I think the the general problem is and this is something that we Face building an indexer and a block Explorer is um like imagine you have like a thousand different chains these are all going to be built slightly differently and there's going to be nuances in the details of each one of these systems that you can't create a common abstraction on you you can't necessarily for example make an abstract block schema that you build your application on and you can do that and but you're not going to have the depth that every single protocol you're not going to be able to go and you're going to lose resolution on the data so this is a hard thing and I don't I don't think that it's necessarily a bad thing that we're facing this but we definitely need to be making the right engineering trade-offs when we're building tools so like the way we think about it is we are there's kind of a spectrum whenever you're as an engineer when you're designing something you're going to have two engineers in a room and one of them is going to say let's make let's over engineer this let's make this super generalizable so we can upgrade it later it's going to be very easy and um on the other end of the spectrum there's going to be an engineer who's saying wait wait no this is the requirements for the customer so let's just build exactly what they need and I think as tool developers and infrastructure developers in the space we need to go way more towards that flexible side so that we can make our tools very adaptable and so the attack that we're taking at modular cloud is we're really focused on acknowledging that we can't generalize across all protocols but what we can do is we can make the developer experience of creating an integration which needs to be done manually but we can make that developer experience as easy as possible yeah oh I I was just gonna say that I think that you know we talk about this in the context sometimes of modular blockchains but I think it's really a a like whole crypto blockchain space problem where you know my my background is like more web 2 and big Tech and the reality of you know someone in that world trying to get into this space is that there's a huge Headroom to just jump in you know if you're uh and you're a front-end Dev and you say I want to build an app and I want to try and use a blockchain you're trying to figure out like how am I gonna run a local blockchain or if I'm using ethereum I gonna Pony up you know whatever like 20 a transaction to Dev test this application there's all sorts of hiccups along the way and so much tooling along the way it's it's very complex and it's a huge barrier to entry to actually get some of these ideas onboarded so you know when we think about building and modular we we see it as an opportunity to kind of correct some of that to an extent make it you know I I hear lots of people I talk like well isn't launching something modular like more complicated and I was like well we get to have a more narrow space of what we're focused on which means like we can really work on tailoring that experience and we can make it a lot better and easier to use and then that can breadth can grow as we go more and more specializations and there's more pieces in this space much like if you use you know like Google Cloud today you don't really know how networking works like the the the fact that we're sitting here and like if you want to be a smart contract developer building an app you're like I need to understand exactly how the core protocol works like that that in my mind is an abstraction that we need to kind of move past in order to so building the tooling so that we can do that in the future is important yeah I was going to say pretty much along those lines I think one of the biggest problems uh well you've pointed out like it's not really a modular problem it's more of a crypto problem in terms of like where the industry is at um I think the most complicated part that needs to be figured out in the next like five ten years is uh those sort of common apis and interfaces that allow uh composability but also like optionality for people to pick what they want to use um so I guess for example like a data availability interface that would be somewhat standard so that people can use different da layers but also use the same tooling I think that's something like roll kit is working on for example Dimension is another example a roll up as a service provider they've packaged together both their rollup SDK along with the celestial light node so instead of having to go and start each one of those manually you can actually do it all in one in the command line interface so I think things like that they're some of them might last some of them might not but I think whatever the like the happy middle ground with all of that is is is the way that this is something that we can take to the web 2 developers and be like hey do you want to try this out it's actually fun and it's not gonna you know you're not going to spend your whole day trying to set up the light node or trying to start the roll up so uh yeah I think we have a long way to go but uh it's really cool to see things like Dimensions like roll up SDK for example like that actually exist already and excited to see where that goes good um I'll give a brief I think first of all we're very much relate to the point of trying to create a very good somewhat abstract generalizable schema uh it is a noble approach it's very hard um someone in the room is very some people in there are very familiar with that um I think but yeah very much resonate and echoing the fact that it is a lot of trying to create packages trying to create bundles trying to create any semblance of hey we maybe figure out the best way to go about building a D5 specific app chain uh FCS specific app chain uh Define enable nft app chain uh you can leverage composability I think it's a very it's a very one it's a very wonderful thing once you are able to come into an ecosystem and come into an entire industry and say hey there's a lot of people that have done a lot of the groundwork for me already I can just get extremely creative with whatever I want here yeah I totally agree with that as well um and I think you know the challenge then is on you guys you know in developing your protocols to you know make it easier and Abstract that away so they don't have to think about it um so I guess a question for all of you again is what are some of your biggest challenges in doing so what are the biggest hurdles that you have to go through to be able to you know make it simple for everybody else uh things are always changing and I think in the early stages of all this we don't really know what the best way to do it is um so like speaking of like the DDA interface with roll kit for example like we might have like a beta version of that but at the same time uh we don't know that that's the final version so I think it's just a yeah I guess a factor of like where we are at in the life cycle of this modular ecosystem and crypto ecosystem as a whole yeah I mean I'll definitely Echo that I think that the amount of attempts on goal is the key so the cool thing about this um and like like one thing like for example that you know Austria enables is for um you know it just it lowers the barrier of Entry of having like a decentralized chain so you can you can it used to be really hard to deploy uh blockchain based application and now with Celestia with shared security and now shared sequencing and stuff like this it makes it really easy so from the from the perspective of people actually building applications we're going to have so many more shots on goal on trying to find out that one thing that hits a Zeitgeist like like Bitcoin did I mean I think people don't realize like when Bitcoin came out like nobody thought that that would be something that people would actually find valuable but that application was very valuable and that's why we're all here today because everyone got inspired by this we started trying to improve it and now we're all here at the modular Summit and um I think that's one thing that's going to happen we're going to find out like the killer apps um through making it easier to experiment and we're also on the tooling side also trying to build systems where we can we're basically right now the post we're taking at modular cloud is we're finding services and like apis that people want like for example people want nft apis for evm rollups so we have an nft API this is something that um there's clear demand for and we're trying to build a collection of these things and then what we're doing is we're finding we're we don't know what the generalized platform is that we don't know how the design should be for a generalized platform that can provide cloud services to all protocols that's a really hard problem but what we're doing is by making a bunch of attempts we're trying we're finding out these General patterns and we're discovering how these things should be built um yeah I think I I resonate a lot with the idea that like you need a lot of attempts um and I think that's one of the things that the modular space really enables and you know one of the things that we think about trying to enable as a as a shared sequencer is launching these Roll-Ups and and what's the likelihood that you know the of the first two blockchains that like really became big that those are like the Final End State and like enabling more iteration on what you can actually do and it's you know um I think that's really important the the difficult part is that if you want to be the base of that Foundation you have to make it such that people can actually innovate um and so I think there's a lot to to how what uh Josh said here of like we're building things for the for the first time and then like we're building things on top of things which are iterating pretty quickly and there's a lot of interconnectedness and bootstrapping your your own project um and so I think the one of the big things that we do internally is like just dog fooding what we do it's you know it's hey we have this and it's like cool let's go build a roll up on top of it like you you have to actually make sure that what you do and it's it's not perfect um you know dog fooding we come with our own biases and you try to try to work through that and that's why you get product out to people and you get it in their hands and you find out and the same as any like iterative development approach it's like okay what was wrong with it and what can we do and learn from that hello um can you repeat the question again oh yeah I was just saying like what do you think are the biggest challenges um for you you know in your protocol having to make things easier you know for the user or the developer um I think one of the biggest one is honestly again do I quit everything that everyone said in the room but I actually did give a very concrete example we got a chance to um because we were there well Jason search engine um we got actually the chance to chat with a bunch of note operators throughout this week um it was a very enlightening and they were very enlightened in chats because we got to see how one of the very core um entities on the stack is able to think to reason through whether or not to support a certain ecosystem uh we all formed these very implicit types of questions uh some more explicits than other uh some very large node operators have a very concrete equation that they use to actually figure out whether or not to support a certain ecosystem um one skills which but um something interesting is that we one of the very key components of that question is just how much is this ecosystem iterating on their notes uh being able to actually Tinker around with your notes is something very powerfully something that you can you can get very incredibly complex with uh I mean there's nothing necessarily intrinsically wrong with it but there is something where there is a point in which infrastructure providers really want to feel comfortable saying okay this is going to be the one version of decline that I'm gonna be able to spin up 28 notes uh per ecosystem per chain whatever and I'm going to be able to provide industry grade offerings on top of it and yeah that type of offering is just something that has presented to be a very insane straw for everyone like yeah like we might be able to Center schemas and such but still it's something that's a simple quote-unquote simple as defining okay the signal client can prove to be a very hard thing to do totally um and I think going on to the idea about different you know building in one ecosystem first and then perhaps moving to another I think you know some of you are starting this ethereum ecosystem others more so in the Celestia ecosystem um I guess why would you select one over the other like why did you ever if everyone wants to let me know like why you kind of went with One Direction first and if you feel there are times where just it's just best to stick to one ecosystem and not try to integrate with all of them like if they're just a certain level at which it just becomes too complex um so let's say a couple very a couple of me honestly very practical things I do think to think a lot about infrastructure as being the byproduct of current economic incentives um in that sense incentive alignment at this point is one in which they let's say we do incentivize a plurality of validators within ethereum the theory ecosystem you run a validator on ethereum um on the active set you can get paid to be able to secure ethereum that's that's great uh you run a full note not so much so from this standpoint there there's very much the approach of hey I like this technology I find it very cool I think it's very impressive I think it's the most secure the most optimized for whatever my use case is that's great easy viable economic solution long term and that is not to be let's say incredibly cynical of a lot of really wonderful technology but that is also just to say hey we do need to make uh infrastructure infrastructure is only as sustainable as the economic mechanism holding it so from that standpoint that is something that we took very much into consideration we looked at all the different ecosystems that were the ones that had the most uh the most please explain simple demand the most demand of people ask you know hey can you build this can you build this sort of thing uh I'll pay you right now I need to I need to get my hands on whatever you're building right now and that is a very clear Cod example for it however we also know that there's we're in crypto there's the ecosystems that are very very uh wealthy and Powerful still and they may not lend themselves to give us as much flexibility as something that that we can actually do within a modular ecosystem so that is also why we decided to build on top of it we very much think that people can get very creative with it and there's nothing more powerful than very creative creative infrastructure I I think you know to that point on the you know the economics of it all being important I think I take a slightly different approach I I 100 agree but I go down and I look at just kind of the first principles of like okay if I'm trying to build something scalable right we talk about like oh we want users we want like actual useful applications in crypto one of the things I I always say to that is like okay I used to work at a web 2 startup and we had a database that had two terabytes of information that's like six years of of ethereum data uh so the the question is like okay if we want to actually have these useful applications we need like scalability at not like a uh we need a huge multiple and so coming from a first principles of of that is like okay how would I build that and and that's I think modular is just you know if you're building software in the world you know for the most part if you want to scale you end up going more modular um you have specific specializations of what you're working on and so I think that's that's is a part of why you know I I look at the space and then to the point of the economics it's like okay well like ethereum can also make these changes and they're working on things that'll help with scalability but it's a it's a question of also just like velocity you have you have all that Economic Security it's it's all in this like one space and you have all this liquidity it's it's difficult to move it's a financial product with a ton of money it's like how quickly Are banks changing their banking systems right like it just doesn't happen that quickly so if you want to actually be like come in and challenge the the incumbent and be like hey we offer something like better it's I'm not going to do the exact same thing as what the incumbent is doing I'm going to actually try and change a lot faster yeah so we um we first started off um supporting Celestia um that was our first integration and that's a cosmos uh chain essentially so um when we launched our block Explorer we first were only only supported Cosmos and we've since added evm support and we do have proof of concepts of other VMS that are compatible with our infrastructure but those are the two primary ones I just think on a practical level if you support right now Cosmos and evm for your tooling um I think you're going to have uh you're going to have compatibility with a super majority of apps that people are using so that's a really good I'm starting point but I think on a theoretical level the reason why we started with Celestia is back to this point that we were talking about earlier about getting a lot of shots on goal and essentially what is possible with um like let's say that you have the ethereum virtual machine and you want to improve it if you wanted to contribute that Upstream to actually leave the ethereum network as something I'd talked about my talk earlier coordinating with a large group is extremely hard so that's a very difficult process if you want to change that execution environment it's very difficult to do so and there's so there's actually if you look at a blockchain there's actually a lot of things in the monolithic architecture that's all bundled together and these things they don't actually have to be so what needs to be bundled what needs to we need a lot of people to all provide security to The Ordering of the data and there is a strong Network effect in that and if you subdivide that into many different l1s that I'm not saying that there's not viable I think it is very viable and there's a lot of people who are great solutions for making l1s that are other than just the major top 10 chains I think we're going to see even a lot more L ones but but it does you have to admit that it does sacrifice security and there is kind of like a economies of scale to security as well and especially with data availability sampling as you you add an additional byte to the network it's actually sublinear scaling so it actually takes like log n steps of verification more per n bytes and so that's there's actually a really great property of having an L1 that's just like dominant and that most people contribute to but that Network effect does not necessarily carry over to other parts of what the blockchain is so in my talk I talked about like the fork Choice Rule and you can like like a roll up is basically defining this and this is operating on the on another Fork Choice rule which is like the L1 I give this talk earlier today and um essentially the um like being able to customize a lot of that stuff actually makes it makes it possible to make a lot of improvements to the way that these systems work and a lot of I mean a lot of things in ethereum we're kind of just we were kind of just figuring it out as they went and I it's not necessarily like I think someone had said earlier just because what are the odds that one of the first blockchains was optimally implemented I think that there's a lot of improvement but going through an upgrade path of actually convincing the community to take every single change necessary to to get there is really difficult and also you really don't want to take any you don't want to experiment at all in one of those situations because if you take do try a crazy idea and it destroys the network you're gonna nuke everyone's bags and we're all going to be unemployed so we really don't want to do that um so I think like what's cool about modular blockchains is you can have a bunch of Roll-Ups on top of an L1 this L1 has a giant you know a giant Network effect but the the actual implementations um you you can have these all be permissionless and what you what's kind of cool about this is it actually is a better way of building a blockchain than um it has a really interesting productivity scaling property where you can parallelize the iteration process because all the different people that are trying to make different Roll-Ups are not needing to communicate with one another and as a result you can have a much much higher speed of iteration something it's kind of like if you have like a distributed system and you and your application is not designed for that you can't just add nodes that's like trying to build something within the confines of a single project where you have to agree with everybody you're going to have a lot of communication overhead between each person trying to put out put forth an idea but if you have permissionless Innovation you can do everything asynchronously and this can scale you can scale the amount of innovation with the amount of people trying to innovate because everyone can take their own bets and I think that that is why I believe that the modular ecosystem is going to be where the dominant amount of innovation happens and as a result I think there's going to be a large amount of activity in the future on that and that's why we took a strong bet entering this ecosystem very early I guess uh I'm a little biased here I work for Celestial Labs um but I think the thing to take away from me is that uh like people building on top of Celestia uh and actually building on top of other D.A layers uh I forget the actual question but I think the thing that like the reason that I really like yeah I know where I was going to go oh no the question was just you know why start out building in one ecosystem versus another or you know maybe staying in one yeah so I'm definitely biased um but I guess the thing that I do have flexibility uh for like of my choice is what execution environment I'm using uh so I think I just like think in the grand like long term uh having standardization to some degree between those execution environments uh as great as it would be to keep them in the celestial ecosystem I think that like having the ability to connect with other da layers that are building the same sort of consensus like shared consensus network is something that can be really powerful all right um want to jump in a little more here into your specific protocols um I'm gonna guess I'm going to start out with both Bunny and lzrs you guys are both building block explorers or search engines would love to hear from you guys you know how your approaches you know differ or also how they could be similar or additive to each other as well sir yeah I I can go first on this um yeah I think they have a fantastic block Explorer um ours is um it has a very different angle um first of all it's it's primarily for developers and we are trying to build um we have an indexer that works with Roll-Ups and and lots of different chains including da layers and um we think of our block Explorer as kind of like the web console for this so this is like like you can like you know log into AWS and you know set up your services and you know run computations on in their cloud and we think of our block Explorer as just like the the web interface for our cloud and it's also kind of a reference implementation since it is an open source block Explorer it's a reference implementation so someone who wants to build a product with their Cloud can look at how we use it and they can just copy that exactly and we would love for them to use their apis because that's how we make money um and um I guess like the last but not least I would just say that um we when we design it our approach is that we are very developer focused and we we because we're working mostly with tail projects things that are there's not any users at all so we um but no it's true the users are the companies that are developing it and that's who we're talking to a lot and so but so they're debugging things right now this is the stage that they're at um and of course yeah they're users on any blockchain protocol I mean that's a question but um I'm sure there's there's hundreds but um yeah no but we're trying to make um all the tools that developers need for you know building applications and debugging their protocols as they're building it live I I can confirm there's there's users in other blockchains um true uh yeah I know as long as the blocks are not empty we're happy or or even you know as long as there's gun people that need block explorers that are very uh we we you used to use the word uh human read the phrase human readable quite a bit um I feel like over time now I've grown a little bit more detached from it I think it's just more so from the tampon is I also have not so great word I'm trying to find a new one for it but legible from the standpoint that is something that people can just understand uh it's maybe maybe friendly is the appropriate word for it uh something that you can feel it's approachable something you can relate to something that does not assume in a single level of complexity uh from the user prior to knowing oh I don't know what is a swap but oh everyone can understand what is ascent and receiving what is sending and what is someone is receiving um in a swap or exchange transfer beyond that a lot of our infrastructure is set up in such a way that we're able to actually leverage uh infrastructure like modeler classes to collaborate on let's say hey you have a really wonderful indexing indexer can we get some of that data right uh also in the exact same way that okay going back to the economics of it all um we do believe that let's say if you're building critical infrastructure for a lot of these ecosystem even whether or not they're uh long tail or like very much on the on the at the center of the developer um you should be still getting paid you should be still you should still be a very sustainable project on your own right um I think we more so prioritize the fact that developer tooling can only takes us so far in such a way that we can allow people to create we can allow providers to create Goods that people can start interacting with very easily however in just developing infrastructure is stops at the point in which as soon as some users are trying to engage with your ecosystem that is where you don't want to show someone hey here's the here's the console right you very much want to create a product that someone else that knows very well how to use the console can then use a product like ours and say hey look you just minted this you just engage with this good you just particularly service um you just send money around the world you were just able to bang yourself I actually or even let's say something as communication I actually didn't have a phone number for an entire year and I think uh yeah very free and I highly recommend it but being able to leverage your infrastructure let's say uh peer-to-peer messaging networks I had no problem living around the world that way that's awesome might try that actually one day just not having a phone number it's great um I had a couple more questions for you guys if I think I'm going to move on just so we don't run out of time here um so sorry oh I can keep oh I have five more minutes oh okay perfect all right so great um so basically the way I understand it you know Bonnie you're more focused on you know the consumer side of things and lzrs more so on like the developer kind of back-end kind of things um I would love to hear you know I guess starting with you more about the cloud uh platform that you're building and how you can help yeah there um so I I think um one issue that is gonna we're going to be facing very soon is like it's becoming very easy to launch a chain and um that means there's going to be a lot of chains um and like these chains are continuously producing blocks um and there and the cost of putting data on these chains is now plummeting so people are going to be putting a lot more data on these chains and so um one interesting thing is like so first of all there's basically two child this leads to two challenges one is and I think I might have mentioned this earlier but fragmentation of the different types of implementations of everything so if you have a traditional indexer and cloud-based application or tool that works with for example evm chains you're you're already not going to have compatibility with every non-evm chain and as we get more chains that's going to be a large selection of um interesting projects that you're not going to have compatibility with and even within the evm um space there's fragmentation so not all EVMS are the same there's some EVMS that don't have like a given like RPC endpoint that you might want or they just don't they they like have like some like pre-compile or like they just have like it just doesn't work exactly the same way and it's it's actually becoming increasingly hard to just simply make an evm compatible tool um so one thing that we're doing is we're just trying to think from first principles how can we rebuild these systems so that we are not making assumptions about what how a protocol should work and we can just let people Define that but as I had mentioned earlier we want to make that developer experience as easy as possible so that's one of the things um that we're doing um and the other thing is it's kind of like it kind of gets into the economics of actually running a cloud-based company and this and when you have a lot of chains you're going to have this long tail of chains that are somewhat interesting but maybe they're just not extremely well adopted yet or they have potential but they're just not that much usage yet and you might want like accessing any one of these given chains it probably doesn't give much value to people um like maybe not that many people want an API for that but a lot of people will sometimes want to access data from some of these chains and so like if you I can't remember the statistic off the top of my head but last year I was quoting this thing where there's some very large percent of Google searches that are long tail so people are searching for data I'm searching for information on Google and a lot of these searches have never been searched before it's a non-trivial amount it's actually surprisingly high so that what that indicates is that people there are like when you have like a the distribution like you have like a head of data most people are accessing data in the head and this long tail there's a lot of demand to access data in that long tail the problem is that it's really expensive to store that and and if you just say okay well I'll just buy all these terabyte hard drives and just like put them in my basement it's also then hard to actually like run computations on that and access that and query that in a way that is performant and acceptable in a way that is useful for people building applications so we're trying to make the infrastructure um on the the cloud side of things that can allow people to run computations and query this data set and make that available for everyone so um this stuff doesn't just get lost to history you're up why consumer focused um I guess the question was just I believe that you're kind of more on the consumer side you know helping you know users like interact very easily with the block Explorer more so like a search engine so I was just curious as to why you picked that direction over something like modular Cloud which is more of the back end side of things sure um so I say we ver we very much are intentional with the with the wording of referring to our product as a search engine as opposed to a block Explorer um but I'll actually just pick half of uh the there's a lot of queries that do not get actually searched on Google uh the statistic case insane uh as you were saying you know which is thinking okay just think of like a standard query like five letter like what is and then just insert whatever word do a permutation on that on those characters it's gonna be an insane number um and yes they're never going to get searched and I do often find myself finding stuff that oh there's no search result for uh page for this I I think it's kind of fun um then how do you build a product that actually allows you to access these things you don't necessarily build a product that allows you to access only hash data um you may want to do that if you want to specifically again take the approach of letting people be extremely developer focused that is great that is deeper actually the perfect product for that and that is how you want to reference stuff maybe block guide some people do that as well um why not support at all but the point in which we were very intentional on intentional on on us being a search engine as opposed to block Express is we believe people don't necessarily want to search for a specific data sets or a specific uh how to say it um factual information that all of the top 100 searches on Google uh every single year are all brands they're all brands they're all Goods they're all good their services and the only exceptions are stuff like weather uh food around me and stuff of the sort in different languages as well uh because you know everyone searches is not something appropriate to the crypto ecosystems therefore I think it's such a good approach to actually take it okay if everyone in the world searches there's and he's saying billions of searches every single month I forget the precise amount but it's definitely on the two digits end of things uh like 36 billion searches I think um everyone don't quote me on that you can Google it yourself uh but or Dora it yourself someday and we take that approach because we want people to actually not not search for these factual information on every single block every single transaction every single uh internal internal transactions logs whatever decoded locks what we want is people to actually search for these goods and services and we at Dora when you search for nft smart contract right now it's only bound to let's say or uh erc721 uh proxy contracts but we want people to be able to Mint with Endora which you are able to do right now if you search this in a team smart contract again sort of draw proxy7 721 you're able to Mint it with indoor if you search up uh Dex within Dora you are gonna regenerate a friendly UI for you to be able to engage with the swapping widget within that right now it's of course bound to one of the most used ones we use the uni sub widget in the future we hope to have this very generalizable infrastructure allows you to Leverage every single got an application um regardless of whether or not it's the first so the last time that someone's looking for it as well um we think that that we've seen we think that that is how people relate currently to goods and services so therefore why you actually not offer that in the space we offer a lot of we have a lot of providers for many things why not actually give give it to people in a way that they're already used to engaging with them sounds great you guys are really additive to each other and kind of approaching it from a different angle um I think it like makes a lot of sense so thanks for going into that um Jordan jumping over to you on shared sequencers um you know there's a number of different shared sequencer networks popping up um including Austria would love to know you know what's different about Austria from both you know the I guess the developer infrastructure experience for the most part or how easy is it to will it be to plug in and use your solution yeah I think um I mean first of all we're really excited to see you know uh more people building the shared sequencers we think uh you know it's only a from our perspective it's it's only positive to have more people thinking on this and more people working to you know push us to build something great um I think the the reality of this space is that you know the shared sequencer narrative took off and like I don't know like March April and uh yeah I I think you know espresso yesterday launched like a a demo thing that they posted which is great pretty cool excited for them we're gonna do a demo of what we have a little bit later here today at a workshop so I think the the reality is that like it's really early and the debating over like who has better product ux and whatnot it's going to be really early I mean to an extent where it's like I I looked this morning I was like oh espresso had this post let me go look and see how this works because I'm going to be talking about how you know we're all thinking about our user experiences and it's it's one of those it's it's just so early to really really give you like a this is our differentiator in terms of how our product actually works what I can talk to is you know like our our experience and whatnot which is that like my my background is in developer tooling I worked at gcp I worked at meta doing like their API designs and worked at a CI CD company for a while so it's like our it's really our background is building developer tooling and so everything we do comes from kind of that mindset of like what is what is a user what is their Journey how do we make it so that it works what are all the things they're going to want to do how do we work on those Integrations and then you know from here we get you know products out and then like I said earlier it's it's going back it's hearing what people have to say and continuing to improve on it before we get to you know a final launch and that's kind of how we think about it and um yeah thanks for that um I'm also kind of curious from you know the node operator perspective when people are coming in to you know run a sequencer um maybe it's too early to touch on that as well but I'm just curious to hear like who might be you know such an operator is it someone like a traditional validator or you know professional um node operator that already exists for other kind of things yeah I guess then there's a couple I I have kind of a follow-up question but I can answer both of these switches which is when we talk about you know uh a node operator are we talking about like validating sequencing nodes are we talking about like a node that someone runs at home so they have access to the data oh I meant so the former okay um yeah I think you know the the way I think about this is similar to other specialization pieces and similar to tenement we'll go after you know traditional validators for the most part to start with I think this is a big part of the appeal of a shared sequencer network is if you want to go and launch your blockchain like we're gonna do the leg work of making sure that there's good validators that are using it that's part of like launching this product um and that way when you go and you launch your roll up like you don't have to do that because that's a huge that's a huge it's to people coordination problem um and so whether or not that's you know an Institutional node operator or that's an individual with like their special high performance setup um I think at the end of the day it just comes down to doing it and like well so so it it doesn't I don't have any like specific biases one way or the other um you know we are building our sequencing chain is built on top of comet bft so lean on top of the institutional knowledge that and and I say really like ecosystem knowledge of that people already have in terms of running this thanks for that um yeah Josh your turn so you're a Solutions engineer at Celestia um would love to know a little bit about what you work on day to day and you know how you're helping the entire Celestia ecosystem build things on top of it um so I guess like a lot of my day-to-days uh mostly maintenance of our documentation uh so if you've run a light node uh there's a good chance of like at least edited something that you followed to do that if you're running a roll-up on Roll kit I also work with their documentation as well um I guess on the integration side of things uh I work like on different execution layer Integrations so I worked with the op stack integration with our engineering team kind of like polish the docs up for that and give it to the end developer to go ahead and play around with um but I guess like one of the most fun things that I've had uh like or enjoyed the most recently is trying to abstract away the console or The Terminal for people when running a light node uh so I have like a beta version of this Mac OS app that I made that you can just download on your Mac like you would any other application and start a node up um so yeah I kind of just experiment with things but uh I think that's the beauty of like where we're at in this space uh we're still figuring all these things out there's many EVMS as lzrs was talking about that could be used as execution environments but some of them have different pre-compiles and just like different properties about them that aren't all the same so figuring out uh like which one of those are best in the long run I think is going to be like uh yeah like a really important thing for the space I kind of got a little bit uh out in the end there but uh yeah oh you're good a little bit all over the place but mostly experimenting and uh helping people post data um maybe this might be a bit too early of a question so apologies if so you're good but I'm going back to that you know our first kind of question about how easy things will be um you know given you know everything you just said how easy do you think it will be to launch a roll-up you know using Celestia both from the perspective of you know someone just doing it themselves or developing themselves or you know leveraging a Ras solution yeah um so I guess like one of the next ideas I have for this Mac app is to like first put in a transfer function so it can act like a wallet uh I want to also put in like a posting data to the network function but like the bigger addition to that would be something where you can go in and like literally click like start a roll up or initiate a roll up and maybe leverage something like dimensioned for example to do that uh so I think like in the next year or so like there are going to be things like that that exist maybe even sooner uh conduit is an example that has not built on top of Celestia yet but they do have the ability if you go to their web interface and make an account for free you can start your own roll up on Gurley and I think that's fascinating uh they handle all the infrastructure for you you can like inspect the logs of the actual uh like software that's running and it's I'm very optimistic about uh like this basically like drag and drop sort of like roll-up infrastructure like the same way that if you want to go make a web store right now you can use Shopify and basically have no knowledge of like development or anything and you have something that works and is a fully fledged product um I guess I'll stop after this but I think that's one of the beauties of where we're at is we're going to be able to figure out all the different pieces of the stack really well and like the really optimistic Vision I have is that the same way that like blockchains work in the future is the same way that software works now I know it's called The OSI model I don't know much about it but there's seven different layers in the way like most applications we use uh operate and like I think I want to get to a point where we don't no one has to know what's going on under the hood of that roll up they just know that they have a roll up here's their like you know special key to access it or whatever but I don't know what happens when I send an email like every single layer of my email I couldn't tell you what happened so like I hope that we get to a point where developer tooling and like even just the end user like products are at that place where people don't have to think about it because it's overwhelming to be honest and I think that's probably one of the biggest challenges of this space so I think we're out of time um yeah at a time thank you guys so much for being here um would love to do it again sometimes I have some more questions for you but it was really an engaging conversation so really appreciate your time um yeah and thanks again everyone thank you foreign everybody so we have a short break now because one talk fell through so please be back or stick around um at around 10 past 12 I think to see Aditi I think she entered the room at some point there she is um so yeah stick around or make sure you're back at around 10 past 12. thank you guys again [Music] thank you [Music] foreign [Music] foreign [Music] foreign [Music] thank you [Music] foreign [Music] [Music] thank you [Music] [Music] foreign [Music] [Music] thank you [Music] [Music] thank you [Music] [Music] thank you [Music] foreign [Music] thank you [Music] thank you [Music] [Music] foreign [Music] thank you [Music] [Music] [Music] foreign [Music] [Music] [Music] foreign [Music] foreign [Music] foreign [Music] thank you [Music] foreign [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] [Music] foreign [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] foreign [Music] foreign [Music] [Music] [Music] [Music] [Music] foreign [Music] foreign [Music] [Music] [Music] [Music] foreign [Music] foreign [Music] [Music] [Music] foreign I'll just point to you it is yes there we go okay oh wow it's just such a beautiful picture and just image amazing okay uh today I'll be talking about capsule uh but the context of why this is such an important topic for uh modularity and this Summit in general uh is because as we increase the surface area of chains uh we actually end up with more problems and so this is where transaction signing infrastructure becomes really relevant uh next slide oh wait there's a slide before that no keep going back back there we go okay cool next Slide the perfect okay um so congratulations we did it turn to your neighbor and give them a pat on the back uh because hell yeah we're on our path to solve the scalability trilemma which was necessary to solve for so-called uh mainstream adoption so yeah we're on the path there but because of this we've actually introduced a bunch of new problems that uh hinder uh potential mainstream adoption so that's kind of what I'm here to talk about today next line thank you so here's what metamask looks like today managing a bunch of tokens managing a bunch of networks it's a very complex flow to sign transactions next slide assets are basically everywhere and essentially as chains the number of chains grow this problem gets uh much worse next slide and so uh yeah I've been thinking about blockchains in general since 2017 started my journey at consensus uh had a stint at the graph was recently at Celestia and then ended up joining nitya the founder of capsule to think about this problem because I it's kind of observing that there needed to be a better way to manage transactions across all these chains so more into that on the next slide so here's what we know about the path to mainstream adoption of course there's more steps on this it should say one two three but um yeah it's fine yeah there's probably more steps on here but for all of us the steps to mainstream adoption are one we know we have to separate out execution from the L1 to to just scale better two we have to create more compelling applications to bring people into crypto and then somewhere in the middle we need to profit hopefully next slide um and so if we think about this in the framework of uh three product categories applications wallets and chains we actually end up seeing something super interesting next slide yep perfect um there you go perfect uh We've successfully added more chains to the Spectrum and protocols uh because we've obviously been thinking about scalability a lot for the past three years to the point that we've created more and more block space and created more forms of execution like all tvms ZK VMS Etc so this side of of the space is kind of teeming with activity next slide next there you go um also we know on the other side of the space applications we've seen a fair amount of activity there so uh we're somewhat there in terms of mainstream adoption with apps like Open Seas or a rabbit hole lens but frankly it's been a challenge to see a lot of mainstream people use these applications outside of things like airdrop farming and so what what gives next slide um oh yeah go back yeah the castle thesis is that uh solving for mainstream adoption is not just about creating more compelling applications I think this is a very prevalent narrative on Twitter today where people are like devs should be building better applications and use cases suck but we actually think that's a misguided take um and the problem is of course innovating more at the application layer but it's also managing the transacting experience across this wide surface area of block space we've created over the past three years um and so the key to that is the wallet layer side everyone should just like take a moment to cringe because I know like wallets are just like overdone and over talked about so like let's just take a moment to like accept that and yeah it's the reason why it's been so exhausting to talk about wallets is because we've thoroughly like just exhausted our mental space for wallets in general and I'll kind of explain why that is in the next slide there we go so uh the reason why is that over the past few years we've innovated a ton at the UI layer but not on the fundamental transacting layer so this is metamask Rainbow Phantom kind of represents like 2018 still need to switch a bunch of networks you still need to sign transactions or messages transact you also have to like inspect the transaction to make sure you're not signing anything Jank and so it's still very much the same as far as like third-party wallet applications go next slide there's also been a lot of innovation at the embedded wallet side of the space so this is like coinbase wallet Circle um magic link web3 auth there's a bunch of players and I think engine as well is in the space but um this like wallet as a service uh product category is also pretty exhausting um and the reason why is you get this like clean experience of not having to deal with signing messages and signing transactions in the middle of your applications experience but as soon as you want to take your wallet and go elsewhere so Celestia talks a lot about this exiting with interoperability it's very very difficult so these are the steps you have to go through to actually take an asset from an embedded wallet and actually import that into metamask and then list that asset on openc for example there's a lot of steps and so that's also very confusing and exhausting and bad next slide the third uh We've exhausted ourselves is with third-party app building wallets so if you think about this it's like uniswap building a wallet or Robin Hood building a wallet um this is awesome and actually works a lot in favor for the application so the app now has full control over their end user experience they no longer have to go through like a metamask they can just go through uniswap wallet but it now requires Hayden and the team to fight the good fight with giants like apple on apps or policies and making sure the app doesn't get delayed and uh kind of growing their user base from zero which is a really tough thing to do next slide um and so you can see why we're kind of exhausted of of wallets and this this Market in general um and at a high level this is where these this this layout is kind of where all these products sit um it's it's crowded it's confusing it's it's not perfect um and there's an obvious gap of needing ways to transact that are embedded and don't require like leveraging a third-party app like a metamask in the middle um but also managing the signing um and switching networks and making sure that you can take your keys and kind of go elsewhere and take your assets elsewhere as well um and so the the crazy thing is that this is what this Market looks like for just a single chain so just within this like single chain Paradigm you have all these options and so as block space surface area increases Mo chains we go um so yeah you guys you guys didn't say that um there we go yeah participate um take two um and so next slide yep yeah there we go so uh yeah so in a world where you know thanks to modularity and and better better scaling wallets as Standalone products are you know constant RPC endpoints uh always switching network uh in the middle of your flow and just shifting the user friction uh which was once on the infrastructure side of things down to applications which is is not good um and so next slide and so this gets keep clicking one two three four five there we go now we're done uh so this gets a thousand times worse so this is just a couple of examples of uh El tuser networks that have shipped recently so there's like the public goods Network Zora Network base Claris also also shipped recently and so as we keep increasing the number of trains we're transacting with you kind of need a better way to manage the transacting experience and the intention to transact in a clean way without making user experience really bad next slide and so our our core Insight is um you know forget the wallet uh I think wallet as Standalone products are really really tough and instead focus on the ability to natively transact so in a world with Mo chains no problems uh having a third-party app like a wallet uh just adds to the confusion and so if you have a native way to transact within the application or the product you remove the ability the the need to kind of switch between signing things and also uh needing to kind of have a browser extension to to transact next slide yeah um so this is kind of how capsule thinks about it and we'll go through a demo as well um we basically add a notion of the the images a little messed up but that's okay we add in a notion of permissions uh into this experience so by permissions we remove the discrete uh proposing signing and inspecting of transactions that need to happen in today's kind of transacting Paradigm um and so how we do this is we take NPC uh npc-based key management and we wrap it with a permissions engine so no more pop-ups switching networks but you also get the interoperability benefits of of wallets by being able to take your keys everywhere so functionally next slide yeah functionally what this looks like is a developer tool you can click again it changes color uh functionally yeah right functionally what this looks like is a developer tool with a single sign-on experience so this means theoretically a user could onboard onto an evm specific application and then one click on board into a cosmos wallet which removes the need for uh the cosmos wallet to acquire new users and also get the get users to bridge through the friction of going into a new ecosystem and so we think this design kind of drives Network Effects by not only simplifying the customer acquisition process but also the user's transacting experiences next slide and so this is a demo I'm not sure if it's going to work click again okay great so what we're doing here is again the single sign-on experience of creating a wallet we can do email phone number WhatsApp whatever you want um we verify that with a six digit code um oh does that work I guess we'll do it again okay that's fine next slide anyway the the point of the demo is you can log in with any form of auth Leverage Hardware enclaves to transact and also simplify the user's transacting experience with this this concept of permissions which the the demo should show you next slide no oh okay maybe that was not on me that's fine now go to just go to the last slide no previous yep okay so the takeaway um ideally posted demo which I can send to everyone here if you're interested is wallets aren't the problem our mental model of how data is written to the chain is the problem in a world where we have tons of chains users should not know ideally in my opinion and and won't know what chain they're transacting on and in order to to live in that world you probably need a new paradigm of writing data to the chain and transacting and ideally the last bullet this doesn't just create more and more silos and walled Gardens this is created in an interoperable way where you have a broader abstraction layer that can manage this transacting surface area next slide yeah so that's a little a bit about me if you want to get in touch and yeah feel free to reach out if you want to see the demo properly thank you so much foreign yeah any questions hello yes yes we're in the process of integrating with wall connect yeah wallet aggregators are key to how this interoperability works but generally you should be able to take your keys going everywhere and so that's kind of how we think about it and we're in private beta right now I don't know if that was clear yeah this has come up a lot um we're actually working on this right now um the having the ability to eject and also go elsewhere is is extremely important and whether that's NPC to eoa or other things is kind of on our roadmap as well yeah foreign yes so I think we yeah phone number Apple WhatsApp whatever you want it's pretty trivial for us to add yes yes well idea ideally if you're able to manage all of this like intention to transact in a clean abstraction layer that doesn't involve the like vitalik's post of like my eth is all over the place and I have no way of like unifying the the networks that the youth is on that's the intention and and that's what capsule does um yeah cool hey all right I think we're done thank you Aditi all right next up we're gonna have a panel on investing in modular infrastructure Joe free agent is gonna be uh is gonna be moderating Kelvin and Yuri from signature guys please give them a hand hello hello I think this is on uh great to be here everyone appreciate everyone attending and uh a big shout out to Celestia and Maven 11 for putting this on had the privilege of attending uh last year as well and uh by far one of my favorite events I've had the the privilege to join in so I'm excited to lead this panel today about uh really some great perspectives uh about investing in the modular ecosystem so I want to throw it down the line but first my name is Joe I invest in the space and yeah happy to let these guys introduce themselves yeah I'm Matthias I'm one of the partners of Maven 11. um I think we were the first investor or Becker of Celestia and I hope therefore we help the modular movement uh move forward a little bit that works yeah I'm Yuri um I think together with Maven actually were the first investor like the first second I guess right after you guys um when you call it a ledger we're a little bit different I guess as obviously so maybe have a different perspective here because uh we look at the production space not specifically as blockchain but we have like a broad perspective on a better internet let's say so I hope you get a different perspective here between the more uh crypto VCS that's great okay hey guys yeah Calvin here investment associate Spartan um I guess we're the third investors last year after you guys um so yeah we've been investing since uh 2017 um and looking into more uh module space um starting in 2019 and uh yeah we've been fairly involved uh really pretty recently as well that's great guys um I think how I like setting this conversation last year when I had the privilege of moderating is uh kind of getting some context into your guys history in the space I know you shared a little bit about it but maybe quickly like what was maybe the first project you kind of recall uh giving you some some of the inklings of kind of where the modular narrative is today and like maybe what's one of the more recent ones as well yeah I think the first one Easy Shot there is Celestia but I think maybe the sort of plasma or even lighting Network on bitcoin You could argue that it moves execution of gen um currently the most recent one I won't skip I won't name any portfolio company but I think eclipse is doing pretty cool I think it's cool to see that they bring the Solana VM to like I don't know ecosystem which sort of shows the power of moving that execution of Jane totally agree Yuri yeah I'm I mean we went with uh Celestia as the first time we saw something really really different from after like Bitcoin and ethereum and it became clearer that there's something happening where you have to actually motorize or split certain functions and we're kind of moving slow in the direction so we're looking now at what's happening out there so with all the central sequencer within 10 based architectures with follow-ups obviously and then rollers with services and just looking at from a tech perspective like okay when's the next time something something comes up that's so big that splits again in a way right uh well you need to really sponsorized in such a way that it scales up again what's maybe like a recent project you've heard of that kind of maybe fits into some of those narratives the one that you're following I've found a couple of projects that I I talked yesterday for Australia guys as well so I'm kind of interested really in this centralized sequences not because they're right now interesting to us but I think they're going to a big thing once robots become a little bit more thriving right once you have this happening around more there will actually be a thing where you say okay what is the next bottleneck we have to let my break and that might be one of those things cool I'm excited to chat some more about that in a little bit and Calvin what about yourself yeah so let's stuff the uh uh one of the first projects I actually pique my interest in the module space as well um so yeah back in 2021 you know started looking into it um uh it's interesting how such a minimalistic design chain could um align so well with the ethos of you know sensory persistent uh blockchain um so yeah so this is definitely one of the uh first um that that's a Pioneer in the space as well um for for a more recent project I've been um you know like you just mentioned you know with the proliferation of roll-up uh Roll-Ups in the space um I've been thinking more into the permissionless uh mess of you know moving liquidity across across these Roll-Ups right so um an example that uh project that we involved in is called catalyst so essentially you can it's a liquidity layer across all these uh roll-ups that allows use to you know transfer value natively um across these um yeah it'll definitely be an interesting challenge I think that we'll probably get into a little bit during this conversation as well when it comes to maybe some of the trade-offs and modularity as well um yeah I think I I would also just love to kind of understand like we kind of hinted at it a little bit there as far as some of the recent projects that you guys are are following but you know when we think back to you know maybe 12 or 14 months ago in Amsterdam um what are some of the things that are like top of Mind as far as like what has changed specifically in that period of time yeah I think back then it was sort of like okay da and Roll-Ups that's all there is to the modular ecosystem and since then a few big trends uh optimism arbitrum obviously taking off in a big way um also get interaction on the application Level which I think is very key and we'll talk about infrastructure here all day but it does actually matter that we have users using these things um I think that's sort of validation of the teachers that Roll-Ups will skill more and then obviously on the more technical or experimental side you have things like modular Mev so cross chain Mev intent based architectures Aditi just talked about that um and I think developments like solvent Roll-Ups with Sovereign Labs is obviously working on are also like in that bucket of new experimental ideas that we love to see and what about maybe Calvin will go to you and then to urine sorry could you repeat the question yeah maybe trends that you've seen over the last 12 to 14 months specifically that have like very much piqued your interest in the modular space absolutely so I think uh Ras sarova's service um so similar to what matters just mentioned as well um we've seen a lot of these getting competitive in space um different different ways solving the same problems as well um I think um da is also something that's interesting um so a cyber Celestia we're seeing obviously other Data Solutions in the in the market uh whether it's Avail or eigen da good and Yuri maybe anything out of that before we move on yeah I agree with you guys also Russ kind of the easy way to think about once you think of that there might be many Roll-Ups right you need somebody to deploy them so there's a service that's kind of an easy idea let's say not easy to to actually realize but it's an easy idea to think about maybe they added that a little bit I'd love for you to maybe dig in on like if you have any opinions on maybe some of the economics that exist at that later I know I've heard maybe a variety of perspectives on how sufficiently those businesses or protocols can kind of bootstrap the economic considerations around where they sit in the stack so free to anyone to answer but I'm just curious opinions on this one uh you want to go first or shall I shouldn't go ahead I I think one sort of thing we hear a lot now is abundant block space um so all these DEA solutions that we hear about are like oh there will be so much blog space that it won't really be valuable anymore whereas I think there is a big difference in the quality of block space whether that's liquidity on that verifiability of the block space which obviously light clients play a big role in um so that's something where the value accrue will definitely happen in my opinion on the most valuable blog space that a user can easily verify there's a lot of liquidity on it or MVP extractable on it which could be interchangeable and that you can easily deploy different Roll-Ups on and that's I think also interesting that on ethereum you yeah still often deploy evm rollups whereas on Celestia you'll probably see a proliferation of different virtual machines a little bit of a bias for other execution of course hear anything out of that yeah um I think the biggest gravity at the moment maybe it's the bear Market base liquidity it's fun to see if you even look at how to beat and you think a tlv for example of the Roll-Ups it's strange why for example arbitrary Optimus doesn't have more of it and more of it especially after the breakdown last year moved again to mainnet maybe this is the quality right of the of the block space and you have more security or more battle testedness of their maintenance right you just trust it more amateur but seems to be like why isn't going more up right why isn't going more to the to the Roll-Ups to do something because Urban units of all of this is there right so the basic stuff basically we're using I I think we discussed this one earlier or sometimes if I leave my assets somewhere for 10 years I'm not going to do it on the road lip right now I will just use ethereum mainnet or Bitcoin exactly so so how do you how do you solve that and then I thought about a certain degree maybe you need some sort of well two are a company protocol that's only existing role like GMX for example an arbitrome Naval launch right and around that it's slowly will built around ecosystem and then only it becomes as trustable uh as not as real um as a minute yeah maybe it's a kind of like add to that and maybe pose another question to you guys I think it actually might be like one of the trade-offs that probably is under discussed in this space specifically which is uh you know to what degree with some of these like new implementations with these new configurations of blockchains can you know institutions or potentially like more advanced like larger liquidity holders actually underwrite the risk associated with these architectures so maybe we can pose that question to you guys like how do you as investors kind of like underwrite that process kind of the activation energy or like potentially some people would use the word lendiness that has to develop in order to accrue or attract that liquidity yeah I think for us as Venture Investments we can Venture investors we can underwrite that because we sort of do need to take a lot of risk to get the returns we aim for um but as like an Institutional I don't know debt fund allocating in D5 or something yeah I understand that they see more risk and like experimental projects that are now going live in the modular space Etc and they would maybe rather stick with a more mature defy uh stack on ethereum so I think there you just need to prove yourself over time um that you are there to stay and that they can allocate so it's about sort of the risk yeah appetite of the investor anything from you guys as far as like I don't know maybe how you as investors kind of at least attempt to underwrite uh some of the risks that like you know these more modular configurable systems or architectures can introduce yeah for sure um so when it comes to assessing different projects um I can actually use um perhaps like a DA layer um so there's several ways we can assess this right so um uh obviously you know the Asus function of costs as well as a transaction count so you can do certain um projections right given how how much I guess Revenue that the da layer could actually make and then you you add on a premium to it and you can actually um you know have thinking like how how they could actually monetize on top of it right so you think of it from more of maybe an economic security perspective or kind of where you're going with that as far as sorry you're thinking of it more in relation to like the economic security perspective of like that sort of a thing would help an investor like maybe like a liquid fund better underwrite the risk of like a modular architecture yeah I think that's certainly will help um Matthias I think one thing we had chatted a lot about is kind of like some of the different like founder types that we see specifically in the modular space would love to maybe throw it to you guys as far as like are there things that stand out about like the types of individuals that you've you've had the privilege to to support and invest in that are building in this space Maybe unique characteristics maybe bad things who knows yeah I'm happy to take some we've backed quite a few uh Founders in this domain I I think right now what you see is it's usually quite Tech heavy people and they like to be sort of nerd sniped so they like to think about ideas that are complex and that easily change as they move along so they also need to be flexible in the architecture um I think that's sort of the current founder type you see in the space I do expect that to sort of change over the next three to four years to also more consumer facing more commercial business minded people who just want to build an end product for users what do you think that shift will be like a byproduct ever like what do you think will cause that like I think there's maturity of the tech stack right so that they don't yet think to some degree so that they don't need to worry about like the trade-off of Mev prevention or an intent or not right I think somebody who just wants to build a good user app doesn't want to care about what sort of transaction type there is um maybe I I pivot this question to you guys as well when it comes to you know I think everyone kind of agrees on this kind of like this kind of opinion in the Zeitgeist that like everyone is focusing on him for others probably not enough people focusing on applications um what are some of the things maybe that you guys are are impressed by when it comes to like making some of these Stacks more accessible like we have mentioned some of the roles as a service providers but I think you know whether it's like net new execution environments opening up the doors for uh developers from other ecosystems to come into web3 like is there maybe a specific highlight of those categories that you think like make this technology more approachable um for you know the application and like potentially consumer developers as well you know what I think actually what's really cool about the modular let's say mindset is it's not that you build modular but the way that you're not locked in into an ecosystem especially through a token right so I I try to to run around Berlin and talk to people at WISE and people collaborating more together there are a bunch of different accesses in there and somebody mentioned to me well you know when you when you develop something in your ecosystem the incentive is really still like developed in your ecosystem because you develop it outside well their profit from it right so and unintentionally the talk provides a barrier for collaboration certainly because it been so big already the model race doesn't have that because you can collaborate very rather easily there's everything is more aligned so the the room for experimentation the whole environment is a bit better so what you have is really that there's a lot of people building really cool stuff out there and they're just trying to figure out how to combine it recombine and so on but one that's a coming a lot of great ideas coming out of that and one of these great ideas is that you for example can abstract away the token right I think I think Nick mentioned that uh two days ago on the ZK day that you can actually build directly uh something on Celestia don't have a token this is a good thing because developers don't have to be Financial anymore they can just like start building which is a really good for their application users in the end right so those kind of thinking is is way more free and running more free and doing more experiments in the modern space it's also about the founders who are really mind to it like that I don't know we might have some people start sweating in the room when we start hearing no tokens but um another thing I'd like to post to you guys I'm like quite curious uh specifically maybe on like Calvin and matthias's perspective on like what are you bearish about in the modular ecosystem are there like specific things that you think are are like currently discussed or like a lot of people are excited about that like maybe specifically as an investor you aren't that interested in or you know maybe even like intellectually or like from a product Market fit perspective you think like doesn't have a have it doesn't have a chance or you're not as excited about yeah so I guess I can just quickly take this um yeah so that's a very good question I think uh you know moving forward um there's going to be a challenge when it comes to um justifying valuation so um I feel like during the bear Market a lot of people are looking into infrastructure that squeeze up all the evaluation um and in order to justify these evaluations depending on what you build you know um fees might eventually compress in the future so you'll have to find other ways to accrue value to what you're building right so um perhaps owning you know a more vertical stack you know that's how you accrue more value also bearish on high valuations but Matthias I'm curious to hear your thoughts yeah I I don't know if I agree with the feast points I think sort of fees will compress per user but the sum of fees that we collect on like the infrastructure as a whole I hope will increase as we onboard more users um sort of the bare case for modular crypto I think is either the complexity that you add by sort of incorporating all these different systems together so if one of them breaks that might not be good um and overall maybe but that's a larger bare case in crypto that people just don't really care about and use verification so a large part of you know building a modular blockchain with data availability sampling is that everybody can run a light note very easily I mean we see the people from Celestia especially do it everywhere um but ultimately the Assumption here there is that people do run around a light note and verify this thing themselves whereas maybe well they just don't do that do you think people want to run like clients yeah I think otherwise you shouldn't be in crypto but it's sort of why you built on a blockchain right you want to be able to verify it otherwise you can just use Excel sheet but it reminds me of like the accessibility point that we mentioned earlier maybe earlier we were talking about the accessibility for developers with like external skill sets from crypto but when you think about from a retail perspective maybe what some of the purists who have like grown up in this industry like really like kind of like prioritizes is really ensuring that these networks can be robust and a huge part of that is ensuring that you have like a culture that exists around these these blockchains of of of verifying State and having individuals capable of doing that but uh maybe one thing I would pose to the group is I'm kind of convinced that we have to and then in the same way we have to build uh you know like modular execution environments Etc to make it more accessible to developers I think if we want people to care about you know verifiability we have to make it almost as like you know easy as like wearing like a wristwatch to tell the time in order to actually see like wide adoption so maybe counter that if you guys deal man that perspective even as like a and I I do think people care about it so that's sort of in your question like will that I fundamentally do things just because the most valuable sort of crypto networks also have that culture of running their own full notes right Bitcoin is go mad if you make it slightly harder to run a Bitcoin full mode um it's sort of the whole block size debate was about that um and ethereum also puts in a lot of work uh into making it easy and accessible for everybody like all over the world with not a lot of money for Hardware to run a full mouth and obviously you have trade-offs but I do think that's what matters so that's also why I'm pretty bullish unlike being able to verify it yourself quite easily maybe a question in the room like how many of you guys have like ever run like a full node on a network or maybe or even like have tried or attempted to run a like they're gonna counter my points kudos to all of you everyone else homework at least give it a try I really encourage everyone to to give it a try um I think don't maybe there's a there's a difference in how you phrase like if you especially if you go outside the the blockchain space General blockchain space where everybody's kind of excited about the tech what does it mean to care about running a lifetime for example right I think people do care about a lot of things but they have like a let's say I care about two seconds right if you give it two seconds to me and I'm able to do it in two seconds I do care if it takes me 10 seconds I will not care right so there's a there's a kind of a resource allocation problem here we say okay how can we do can we make you care about that within that time frame right and that's what you have basically in the website right you can website there's a green button saying okay check done right cool so I care for a second that's it but fine as long as you can establish that root of trust in your green SSL checkbox into your browser um I think we've seen a lot of like kind of like thought and probably innovation in the past 12 or 14 months on some of these like more Sovereign constructs that we've started to see um getting constructed do you guys like have maybe some thoughts on like the economic kind of implications of those sorts of constructs when you like really remove kind of the application and execution layer from maybe some of the underlying economics that you know a network might be inheriting from a from a from an alternative L1 despite maintaining that sovereignty I know I I'm happy to go um I think that especially unlike Sovereign app change or app specific rollups whatever you want to call it I think the value capture is way more easy right because it's inherent to the application um so probably valuable accrued to the application of the crypto stack and to the sort of bottom layer which in my case should be a d a layer or whatnot um and I think if you have an app specific chain then it's quite easy to capture value by just extracting a fee for offering the application um so I think yeah the features in unit shop is famous but if they had an app specific chain it would be quite easy to make it valuable because every time somebody uses uniswap the blogspace gets used and validators captures some of that value any thoughts from you guys on kind of sovereign constructs and like how they could potentially like modify or alter some of the economics for application Developers yeah so um I agree with the test just said as well I feel like um you know app specific chains will probably have a better chance of accruing more value um in some way I actually feel like modularity um it does make um certain layer 2's like struggle to accrue sufficient value that's this is why we're starting to see Layer Three is getting built out right that's how you try to find other ways to to accrue them oh sorry uh yeah on to onto your your layer so so yeah moving forward I think um we'll continue to see more more layer three spilling on top and yeah continue to scale that way yeah I don't see a difference happening and and there's a normal let's say traditional word well quantization means that you will lessen there's a true value and everything on top of that will accrue more value it's just that within the net within the Innovation cycle I like to say that every infrastructure was application once like you started out with that like an email even like an email protocol was an application once you started in signing Emos and then more and more people build on that it compressed basically down what Matthew said before that was that the fees per user might go down but the fees in total might go up right so it depends like how what do you mean by by really accrue value but in general as a sum it might be that most well at some point will be a duplication but once the system is really thriving like we have now in the web 2 world do you think unit swaps an application or infrastructure which version no yes sir we argue about this at the office like are you investing applications infrastructure and you're also alluding to this right and I I do think that in crypto is often both um because uniswrap for a sort of penaltic as an example they're building options using unif3 liquidity so for them uniswap is the infrastructure and then you sort of have an infra layer again that captures value it's probably like why the conversation like I guess like that's probably part of the reason that that's like become such a maybe like a common theme or like something that a lot of people are chatting about is because there's probably like alternate definitions of those things as well and they probably they convolute over each other a little bit um coming towards to be an aggregator so they're moving toward application now and then kind of letting go the protocol ones um maybe something I would like to maybe ask you guys from like a more kind of like personal and investor perspective I know earlier reach out about like maybe some special things that we like see modular Founders those sorts of things are there like explicit things that you guys like really uh enjoy seeing out of like maybe the founders or even like the technical teams that you have the privilege of supporting that you would wish to see uh from from others are there like highlights there that like you would like to share like lessons learned from some of these portfolio companies in the modular space that you guys are that you think is worth sharing oh sure uh I guess uh yeah when you're building like modular infrastructure the founder should be I guess really agile as well so you can module in that sense but but yeah um yeah some of the backgrounds that we've uh um some some of the uh Founders that we backed um yeah uh we actually um would like to back you know Founders that has previously built in um you know whether it's like a monolithic environment or a modular environment um so Founders actually know how to appreciate you know the the amount of um the the module the modularity nature of of you know blockchain right so um if they're agile and that they actually understand you know um you know what's the benefit of having modular infrastructure yeah what about you your amateurs anything spicy as far as like things you want to see from more from from Founders or what I like about working with our Founders in the motor spaces I'm often the dumbest guy in the room right so they're all smarter than me and I'm learning from them as well that's the sign of a good investor at the same time I mean it's not that different right they do need to be smart and sort of flexible or agile as you shed but they also struggle with the same things every other company struggles with uh hiring uh Team Building you know just building a company is hard whatever you do um I think that's sort of it's yeah I think that summarize it yeah there might be a balance as well probably in this space I've found um at least during my time as an investor that the majority of of kind of the core founding team was quite Technical and oftentimes they do need kind of uh more I guess kind of like kosher traditional support from investors when it comes to the types of it like things you can actually do to to help them win yeah I mean these guys don't need me to tell them how to write code I I have no sure right but maybe helping with my first hire Etc that's more where they need to sort of be alleviated um so they have their core muscle their core strength and we try to work sort of around that yeah interesting um I want to kind of like go into some maybe potentially spicy topics now um that I think are again like quite uh quite quite timely when it comes to many of the ideas that are getting discussed over the course of the next two days here um what are some of your opinions on kind of like like rehypothecation of like proof of stake assets um specifically do you think there's like unknown dangers that investors or Founders or application Builders are not considering are there like externalities that you think long and hard about or potentially keep you up at night like I do yeah oh I mean we have a company in our portfolio for example it's a pure Bitcoin company and they don't like it at all right people but there's a Bitcoin maximalism involved here so I understand that right you're talking about uh kind of storage right values um but generally what I find more complicated with the infrastructure now is that you add to the financial complexity technical complexity and the technical complexity you need that scalability complexity so you might think that well if something breaks down I can all like execute my contacts and it goes down this way but all of a sudden boom it doesn't work out because everybody runs through the same Gateway and so you have this all complexity even getting bigger and it's really hard to evaluate that how big is that actually it's a lot of unknown unknowns and that makes I would I would I'll go slightly right really really careful about that and see how far you can go with this because at some point we just break and then you realize what it is so maybe just do that experimentally with small sums just to trigger and figure it out a little bit but doing it on a big scale as we saw so last year that might be a problematic thing yes definitely as we were with this last year advertising spicy takes on this yeah I mean I I like to experimentation with it in general I like experimentation and trying out stuff and maybe breaking um on this specifically I think the economics behind it are still quite hard right so it's hard to quantify the risk of like real publication of assets as quantifying risk in crypto is hard anyway um and then there's also not that much fees collected right now that you can sort of give enough yields to on all two yeah yeah funnel to incentivize people to take that risk and that's I think sort of the big question here like okay maybe there's a small group of people who will do this but to incentivize a lot of people you need a lot of fees and that's just no there right now I think I would broadly agree with that um I maybe want to pose like a question of the audience like I like opening these up to see if anyone has anything to add to the conversation or maybe things that you disagree with like is there anything that anyone here would like to raise their hand and potentially ask the panel I'm happy to to walk up and give you the mic I see a Spartan shirt over there any spicy takes for your colleague he can't put Calvin on the spot like that yes uh well I guess one spicy take that out we kind of you know touched on was uh you know module blockchain might at some point you know bring us back to maximalism because going back to a point right like my previous point if if you're trying to accrue value to a specific layer you'll start to find other ways to accrue more value right so for example just um Thinking Out Loud here so a d-layer if you're trying to like um fees do compress in the future and you find perhaps you're trying to own another layer instead maybe execution layers then you're starting to see you know we're going back to the cycle whereas like we're trying to own more of the stack so you know um that's perhaps like one one spicy ticket yeah so dance Celestia would at some point be like hey that settlement layer on top of us is also quite valuable why don't we sort of enshrine it into our stack yeah yeah that's that's a good bear case yeah there are any other bear cases in regards to that that spicy take I think my my biggest war with uh with the whole ecosystem generally is that are we actually building something completely different and new or we just build rebuilding the stuff that's already out there in a little bit slightly different way and we're just not seeing it because it's not convert it's not so new we haven't converged yet but in the end you just end up with the same system the same centralized Parts like a better validator is so big it just control some stuff right and maybe it's something so big it controls a bunch of stuff you have like a bunch of operators that are just Grand and and you haven't seen it coming but the economic gravity of that just made it happen right that's fair um another pivot maybe in the conversation um are there like certain types of of applications that you guys believe are like specifically empowered by by modular infrastructure I know we've kind of chatted about like oh you know like these concepts of of kind of turning specific applications into kind of their own like Sovereign execution like layers Etc across the stack but um when you think about kind of like the second order effects maybe you know this time next year or in two years um what type of applications do you think will have most benefited um from this sort of architecture yeah I think yeah sort of the the downside of building a modular blockchain is I think interoperability and as a result of that applications that don't need too much interoperability are going to be I think very interesting to begin with a good example of this could indeed be gaming so a gaming specific chain for just one game and I play like FIFA and I want to sell my coins or something on there I don't need to interact with somebody playing World of Warcraft right I have no need for that right in D5 that's very important that you can plug these different Lego blocks into each other so I think the first wave maybe and we saw Argus present earlier we'll probably be gaming specific chains so that's I think something modularity enables and then indeed the different execution environments right stuff like the Solana VM the fuel VM move VM Etc maybe order book type of decentralized exchanges will be enabled by that um although information we've seen how many people play out there but these type of products as well you maybe want to chat on that as far as like some of your like cross domain mov perspective uh when it comes to like how that conceptually alters or or is modified by like modular architectures yeah I mean we're we're talking about it's a lot one thing we are currently still maybe debating and haven't I don't have my Minds made up yet it's where do you want Mev to sort of land right so One Vision is you want the a layer to capture the Mev because then it will accrue more value and you'll have more Economic Security on the other side you maybe want the Mev to sort of be isolated in a separate execution environment because then if like one game gets extremely attractive and a lot of people play it it doesn't trickle down to to the other Royal Labs so it's a trade-off right do you want it to go down a lot and it's I think where the leader selection happens is where it will go to and I don't know what ultimate the session is I think there's still very much an open question the first thing it makes me think of is if uh and maybe I could be ignorant to this but whether people have thought about Dynamic systems that would be able to like maybe like modify or like point where that Mev could go but between two layers like that I don't know if that's been explored or if that's the dumbest idea that's been set here today but I also don't know honestly but I would be down to sort of look into that more I think that's one of the more interesting areas that indeed we talked about these modular Founders if you want to come like that are sort of nerds not by and look into and I'm sort of happy to tag along with them yeah I'm doing so yeah as we kind of like get a little bit closer towards the end of this conversation maybe open it up to all of you you have an audience here that are quite modular peeled are there like specific types of things that you want to see built kind of requests for startups or any concepts that you think are like rather unexplored or that you wish you had more looks at as far as different ideas so when I was reading up I I just thought really recently reading about the about the intent based systems and I found it's a really cool way of thinking about what how it actually should act and we have a a company that's kind of in a similar space but it's an agent-based space and so intents and agents are a similar thing but in the end if you talk about if you look at how an app is built for example right it's it's not possible to have an app built on just smart contracts you need some sort of in-between like agents to trigger certain functions such that the person can just like have a phone in the pocket and just notification arrives right something like that so you need all those things and you need to cross them the chain barrier to this the octane and on chain so I'm not excited about this stuff experimenting more of this kind of things to really figure out okay what does blockchain fit into the bigger it's a world solving problem space than just really running around the small pieces of the blockchain access themselves because I think we've crossed the barrier already a couple of years ago where blockchain was just a really kind of a big space we could put all your hope in and it was not concreted there which is part of Hope and you can just really think about oh that's the potential but now it's getting more crit and it also shows you more things that breaks that works that can solve and cannot solve right and it becomes really hard to have the Hope um and so you have to really think about now okay what does it actually can achieve what where does it go and how can we go there and I think this is kind of this it's intent based thing together with the agent base I'm not sure how how different they are actually from each other as a kind of a conversation a different conversation um is kind of a really nice way to explore it Calvin Mathias any requests for startups or areas that you wish were maybe ideas that you saw more of as Venture investors oh yeah I'm about to take it um I think one okay this is going to be a bit boring and someone's contrary now D5 it's not very sexy anymore right especially amongst Venture investors um I do think the whole real world assets thing is actually quite cool um that we have like close to a billion of bonds being on the ethereum Chain right now is I think very interesting to see um so in that regard stuff like noble that aims to bring usdc onto these Celestia chains I think it's very interesting so deep these type of products that actually connect to the yeah sort of real world or web 2 world or whatever you want to call it um are quite interesting I would love to see that more moving forward as we grow more into that adoption uh part of the tech sector usdc the quintessential real world asset I mean I've been arguing here about end user verification now I'm the usdc bull but yeah that's all fair and also privacy Tech but that's more generic stuff like penumbra um anoma nymtech I think that's sort of where my sort of more crypto native heart lies um and I would love to more of that maybe dig into that a little bit because I actually feel quite naive as far as like maybe some of the privacy considerations that are empowered maybe uniquely by modular infrastructure is there any like thing that you would add to that or like things you've seen recently that excited you specifically with like privacy type applications or privacy-based architectures I haven't seen a little privacy deck like on the modular ecosystem like a roll up that's only privacy or f-specific tornado cache uh would be quite cool I'm not sure if they're sort of and then on five change you have sort of two layers of Rights I think a lot of financial institutions want privacy on their orders and don't care if like regulates can see it and then you have more the crypto anarchistic privacy which are maybe dark fine integral welcome where sort of everything has to be private they're very purest about that um in the major ecosystem I don't know you can make a lot of design trade-offs you can maybe encrypt a member which for financial institutions would be and of privacy right um so yeah looking forward to seeing these uh Founders try out stuff there yeah it's another one I don't want to bore people with because I feel like it can be quite cliche but like uh I'm curious if you guys have any perspectives specifically on you know like maybe like non-web three native use cases for some of these modular architectures I think I could probably speak for everyone in the room in the sense that like they like like Enterprise blockchain Etc has has failed in the majority of its capacity but I'm curious if we feel that there's any inkling of of feel that the modular infrastructure could maybe help Empower that in some way I I um had this conversation yesterday about like how do you build a social network a new social network and I find this is a mistake most people think about social networks into films of Facebook and Instagram and YouTubes uh as kind of there's a graph because I think in the new way if you have blockchains you have this new technology you can rethink that and I think in the center of that is the feat and the feed can be for example um modular right you can you can actually do and choose your own feed how you want to like it and the feed procuration connects to people right not anymore through kind of social granted a really existed and you just walled it in it really is about like there's a center piece where people are creating stuff and that flows all into the feed and that connects to people right and this is the emerging quality of a network then all of a sudden you have a social network without wanting it just like it has before but it's a new way of thinking and I think that's what blockchain enables is a new way of thinking the old stuff all the things that we have already we can have it back but we have it in a new way and build it in a different way and only then it works I actually like to build on the like last point that you made um is there anything like very specifically that you guys feel like maybe getting modular pills whatever we want to call it or just like becoming more aware of how people are thinking in the modular kind of infrastructure space are there explicit like explicit things that has changed around how you think that could be I don't know from like a ethical philosophical perspective it also also be from a technical perspective as well I do I could take it back to the Enterprise question if you know um I I don't think we'll see a lot of Enterprises starting to build on these systems earlier right you asked like how do you underwrite the risk of it being quite experimental I think especially Enterprises are scared of that um I do think that sort of a road up itself is very interesting for them because they can sort of keep a level of control that maybe they feel like they miss on like an permissionless L1 or maybe a certain regulatory uh yeah exactly so I do see a lot of like experimentation happening there but I do think it's way further out than yeah next year or something I should ask right I don't think they'll be like oh we have to deploy a roll up uh no I think they're more likely to be at the to look at more established Networks cool well I know we have probably maybe two or so minutes left just to to finalize this conversation but um what do you guys hope we are like uh you know if we can return here in a year and and have the privilege of of meeting at the next modular Summit um what is it that you hope you're you're seeing become successful what are some of like maybe the the next Milestones that you hope you see uh the space achieve in order to kind of get us to the next stage I mean Celestia launching is a good first one right it's launching the main net successfully um second I think I'll show more CK Roll-Ups going live like in full I know she can shank is short of live but that ecosystem maturing to a similar sort of level as maybe the arbiterm ecosystem is because I know we're here at like more just something we're talking about especially but a lot of Roll-Ups also have like the largest ecosystems by far on ethereum um eip4844 going live successfully would be pretty cool I think as it makes workspace more accessible for these Roll-Ups um and maybe the first cell phone roll up on Celestia more app specific Road UPS going live hopefully some acceleration isn't around restaking as well maybe yeah fast experience but experiments but small ones hopefully what about you guys yeah so uh yeah aside from those um I think um we want to see more more of the DAP layer development as well so I actually want to touch on on-changing gaming as well so I feel like watching gaming can actually um take advantage of what you know module blockchain could actually offer um so bringing the entire game logic as well as game economy on chain could actually bring about like Silo different type of economies on the side right so for example strategy game you're trying to like attack someone right let's say it's a and then someone can like front run you know that action you know it'll be like a priority it will create like different new Dynamics right so so I feel like um you know that that's some place that we can perhaps no I've definitely heard Scott from Argus talk a lot about what excites him building like modular infrastructure specifically for like game designers is like attempting to create something that can create like very emergent like net new like player behaviors because I think that's one of the things that actually makes games exciting or like when good games become exciting is when it's like something you haven't done before I remember like like reselling in-game assets for the first time that's like actually what got me into crypto in 2012. um I think seeing more experiments around that will be pretty exciting as well awesome guys I think we're just at time so really appreciate the attention from everyone and everyone supporting uh the whole gang here at Celestia and Maven appreciate you guys having us and yeah enjoy the rest of your time at Paris everyone thanks thanks a lot I'll just take one no one more talk I'll take it thank you these are all three for you oh can I take yeah there's one more speaker right does he have a microphone already yeah there's one more speaker guys okay no problem all right everybody please make your way either out of the room or into the room to see if we can quiet this down a little bit for you um next up it's going to be Arjun head of ecosystem for mantle so uh I guess I'll call you through the stage take some time for these people to uh to wash out which is yes no this is the last thing we don't have the modular Lego after hello hello um so I wanted to actually uh so we've talked about so we're all excited about modular architecture but I actually wanted to cover something um something which I think doesn't get discussed a lot when it comes to modular chains and which is how the economics is going to look like right when you have all of these different layers working with each other what what are the economic models which we have at play and what the incentive design is going to look like ultimately what we've seen as a modeler technology in general when it comes to blockchains is not something new we've seen this in web 2 as well so what we've seen is that uh you know web 2 software architecture was always was always monolithic it was replaced with apis and microservices and ultimately what we're seeing the same in web3 is that the monolithic chain architecture is also going to be replaced with model architecture right so at mantle for example we built a modeler chain uh we've gone live with eigen layer data availability we've taken the op stack and turned that into a modular stack um and what we've also seen is that API driven architecture led to like billions of dollars of value creation and we expect the same to see at least I expect the same thing to happen with the with the model architecture as well so let's try to look at some of the different layers of the blockchain and try and see what the incentive design is going to look like um so ultimately on the execution layer right we've seen like a lot of interesting things happen so if you've been following uh what what some of the other layer ones have been sort of doing for example Applause came up with block STM which is parallelized processing um there's also arbitum uh orbitrum stylus and polygon maiden and and what we've seen with different execution layers is that people have started thinking a little bit beyond evm so uh there was a there was a time or rather I would just say over the last 18 months we've seen that evm has been the sort of execution layer of choice but of course now we've come to this point where we can also see that evm is reaching a stage where either we optimize evm or we look at a different kind of execution model where we can use possibly other languages Etc um to sort of write smart contracts possibly do things more efficiently and ultimately you know there are a couple of ways of doing this at the execution layer where you could possibly charge gas fees a cruise from yield to stakers moment you start to decentralize you need to figure out some sort of economic model and ultimately the value will lie in in very optimized execution and it has to be deterministic in nature as well so if you can solve something like this in a decentralized manner where you've got multiple execution environments all fighting for this piece of the Spy we could see some new interesting economic models come out so I fully expect that more and more VMS there chains will not sort of work with only one VM there could be one multiple once depending on the kind of outcome you're looking for when it comes to gaming or D5 and ultimately as long as it's fast secure and deterministic and you can parallelize things we're going to see some interesting economic models come out of the execution layer um similarly on settlement right so uh if you guys have been following what happened on Twitter uh Anatoly posted something interesting where you could take ethereum transactions and put those on Solana um I don't know if you want to do that but uh but but it kind of gives you this interesting choice right so can we settle on other networks in the interim before we settle on ethereum like these days you must have seen so many different roll ups are coming out on a daily basis and and which is great for for the ecosystem because that just means that the barrier to creating a chain and running a chain has reduced so much that everyone can have their own blockchain which is great but this also produces other challenges where we're going to see the block space on ethereum which is earlier crowded by transactions is going to be crowded out by roll ups more and more State routes are gonna eat up and stay truths while you can optimize them and you know we'll sort of get into that later but ultimately block space is again going to become a premium and and we need to figure out some interesting ways in which we can settle we can solve for incentives and we can achieve the kind of performance we need without like sacrificing security assumptions so ultimately you also have like this L3 app chain narrative going on these days like you can build your own app chain I think so many people want to do that um should you settle should they settle on ethereum should you only settle on L2 like how does for example the hyper chain model work on ZK sync like some of these things have been discussed from a technology standpoint But ultimately what you really need to solve for is how do you create value of the token of the chain building on top so all of these chains which are l3s all of them gonna have their own tokens how is the underlying layer going to build value accrual for those tokens ultimately is going to be the main kicker and of course valued lives sort of in derived security and faster finality but along with ecosystem benefits so for example if you're building your own L3 chain should you build it on ZK sync should you do OB Collective like how do you make that decision and what you've seen time time again is that the ability to get speed execution finality is something we've continued continuously become better at solving but how do you help the ecosystem and what does the ecosystem benefit look like ultimately when you have all of these different sort of chains fighting with each other you scroll you have polygons CK sync op arbitrum Nova how are they going to help you design your ecosystem and how they're going to help you create value for your own token ultimately in my opinion is going to be the most important factor when you make this kind of a decision um and that's kind of why ecosystem benefits ultimately are going to be a very big factor so for example when we try to uh at mantle talk to chains who want to build l3s like the main conversation always is around ecosystem benefits for example liquidity listing of tokens and what else can we create markets for the tokens building on top um and if you go to the next layer right so data availability of course is now this hot new layer right we've got Celestia we have eigen layer so we went live with eigenlayer but we've been talking to Celestia for a while there's also polygon avail so many so uh so so much so many different like data availability Solutions with different let's say security assumptions are also there and we also have E3 staking now as this new primitive where you can take for example the economic value of a token and you can use it for utility versus collateral based deals but ultimately you again have to create utility for the chain token so for example in our case what we liked about eigen layer is the fact that we could restake Ethan get security but we could also take our own token and stake that on on the data availability nodes thereby creating yield and value for our token and this is super important so whenever you talk like for example about Celestia or a whale luckily all the founders are here so I can quiz them about these things but uh how are you going to help my token and where do the ecosystem benefits lie so with more data availability Solutions ultimately the ability to solve token related and value related problems is going to become more important than any piece of technology out there um and and we're just at the start of data availability so I expect to see like more economic value sort of uh or rather more like different approaches to economic value come out of the time to come but this is like the main question I literally have when I talk to like data availability uh players out there and if you go to the next layer right the consensus layer now again like consensus layer is a total war zone right now with ZK VMS doing their own thing um the share sequence of approach is also interesting but again the question is always the same how do you create yield right so you have all of these ZK approvers you have like shared sequencers shared Bridges fantastic how does that help my token like how does it create value for me so I I sometimes feel that we talk a lot about technology we talk about eip4844 we talk about local trees to reduce proof size and optimize all of these things but ultimately and yeah you can find gas free extraction models and offer yield on decentralized designs but how's the trade value and ultimately these are the conversations we need to start having so you know I think we need to start looking a little bit beyond the technology and try and see how we can solve uh for Value in these decentralized designs um I'm just going to keep it really short and this is basically the last slide but ultimately technology will decide if we can build modular chains But ultimately the incentive design is what will decide how we do these things how these execution layers come together how these data availability layers come together how the consensus layer comes together so uh no value no token equal to no bueno and we need to really solve that so uh so anyway thank you so much for listening I just want to keep it really short and want to get more people start talking more about incentive designs and I think the key of how we're going to implement all of these things lies in in the token itself so so anyway thank you guys that's really it [Applause] you wanna maybe take some questions oh yeah um do you guys have any questions anything anything you want to cover about incentive design foreign how are y'all thinking about the eigen layer you know kind of beat icon D.A before they even were out yeah you're the part of your token model surprised by how the economic um not necessarily because the core security assumption or the underlying infrastructure of how eigen layers built is already set in stone right uh because it's in the white paper so it's kind of already decided upon now the way okay so the way to think about these problems is that the way you solve modularity with technology you cannot really change that so I'm actually against changing technology to fit the incentive model what we need to do is take the infrastructure more like whatever the security assumptions are whatever the restaking layer is and what we need to do in that is bake economics into it so the data availability nodes which is securing data availability for many different chains which is ultimately secured by the underlying eigen layer restaking infrastructure unless you can offer some token utility there you know I feel chains may think twice before adopting this kind of a sort of a data availability model right and similarly for Celestia Celestia has got such an interesting model itself right which is a little more optimistic in design polygon Avail is using cardi polynomial commitments but ultimately how they create value for the networks token and what those where those benefits lie are are going to be like super important so I don't think these companies or or anybody else building this needs to change the infrastructure they need to just figure out how to fit an incentive design into into their underlying infrastructure so eigen layer is doing that using nodes I think celestium shows hasn't will have some approach I think Avail is going to be live possibly by q1 of next year so I look forward to seeing how they sort of solve these problems for Networks is that does that cover the question how mantle themselves are thinking about incentives right because you're using that both on the gas fee context and I guess if da stakers are also staking yeah this is the so so I would say that in terms of token what I would say is that how we plan to structure it as an ecosystem token so it'll be used for gas fees it'll be used for infrastructure staking it'll be used as the ecosystem token it'll be used for governance and then we'll it will also be used in all the other protocols You're Building like the liquids taking database protocol which we also plan to roll out possibly by Q4 of this year so the token will have utility across all of these all of these sort of you could say infrastructure pieces so that's kind of how we've designed the token and whatever is produced in the future and whatever products we're going to make we're going to ensure that we bake in some sort of incentive design cool yeah all right all right in case you have any other questions you can always just reach out to me on Twitter it's a first name last name and telegram is also first name last name so you can just just feel free to ping me um and uh yeah just just it's only first name last name because there's another Arjun culti out there who's going to ask you for like one eat because this dog died so just be like very careful right so it's first name last name all right all right thank you guys all right so um I think that concludes the first half of the day there's going to be lunch in the main room and we start in an hour again so see you back then [Music] foreign [Music] [Music] [Music] [Music] thank you [Music] [Music] foreign [Music] [Music] [Music] [Music] [Music] [Music] foreign [Music] [Music] [Music] [Music] [Music] foreign [Music] [Music] foreign [Music] foreign [Music] [Music] [Music] thank you [Music] thank you foreign [Music] foreign [Music] [Music] [Music] [Music] foreign [Music] [Music] [Music] thank you [Music] [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] thank you [Music] foreign [Music] [Music] [Music] foreign [Music] thank you [Music] [Music] [Music] foreign [Music] foreign [Music] thank you [Music] foreign [Music] [Music] thank you foreign foreign [Music] foreign [Music] foreign foreign foreign [Music] foreign [Music] [Music] thank you [Music] foreign [Music] [Music] foreign [Music] [Music] [Music] foreign foreign [Music] [Music] foreign [Music] foreign [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] [Music] foreign [Music] foreign [Music] [Music] [Music] [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] [Music] [Music] foreign [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] thank you [Music] [Music] [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] [Music] [Music] [Music] foreign [Music] [Music] mm-hmm [Music] [Music] [Music] foreign [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] [Music] thank you [Music] [Music] [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] foreign [Music] thank you [Music] foreign [Music] all right [Music] foreign [Music] foreign [Music] foreign [Music] foreign [Music] foreign foreign [Music] foreign foreign [Music] foreign [Music] foreign [Music] [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] thank you [Music] [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] [Music] [Music] [Music] thank you [Music] foreign [Music] [Music] [Music] [Music] foreign [Music] foreign [Music] [Music] [Music] foreign [Music] foreign [Music] [Music] foreign foreign [Music] [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] thank you [Music] foreign [Music] [Music] [Music] thank you [Music] foreign [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] [Music] [Music] foreign [Music] foreign [Music] [Music] [Music] [Music] [Music] foreign [Music] foreign [Music] [Music] [Music] thank you okay hello welcome back to uh the afternoon of day one of modular Summit I hope you've all been having a great time so far my name is Jill Gunter I'm with espresso systems and I will be here MC uh for the Fourier stage this afternoon and first up it is my honor to introduce my friend and co-founder Ben Fish from espresso systems we'll be having a whole track here for the next hour and a half on the topic of shared sequencing and first up Ben will be talking about why dumb blockchains require smart Solutions so without further Ado I think we'll have some more people trickling in here but I will hand over the stage to Ben thank you so much okay thank you Jill um right so does the clicker work nope back one slide Perfect Right dumb blockchains need clever titles um this this talk will primarily be about shared sequencing in the modular stack and is somewhat related to the title or maybe not um but uh as it will become clear shared sequencers are designed as dumb or lazy Ledger systems that don't execute transactions and just sequence and that poses some challenges that requires some Solutions um first just quickly about our organization espresso systems we are a team of Engineers researchers and designers we are building infrastructure that is going to assist Roll-Ups to achieve better better scale better interoperability and and better security um we are a very distributed team I am Ben Fish and uh uh I'm the the CEO and my colleague Jill was uh just introducing the event she's our tree strategy officer and there's a number of other Executives as well um so let me start talking about this problem of uh of sequencing in in the in the roll-up ecosystem and the modular stack more generally uh but first it it a starting point is to talk about what exactly are Roll-Ups doing okay so roll ups are horizontally scaling the application layer of blockchains um primarily today Roll-Ups are being built on ethereum but of course or uh on top of Celestia too so if you view Celestia as an L1 as well so um but in general the idea is that the layer one all it does is just verify fraud or ZK proofs um it may also provide availability of data and some other services but it doesn't execute transactions and so as you add new applications the reason why this horizontally scales is as you add new applications you don't burden the layer 1 with having to execute for those applications you can introduce a new set of servers that executes for that set that application and just proves the state results to the L1 rollups are applications that host other applications so things like optimism or ZK sync are are General virtual machines which can host other applications but now we also have app chains that just execute their own application specific States directly and all of these are horizontally scaling the the execution layer of blockchains another key Point besides charting of computation across applications is that Roll-Ups leverage heterogeneity in the network they're leveraging the fact that in realistically in networks not all nodes are the same if we want to scale layer ones to be extremely decentralized so that there's 12 000 nodes participating and one of them is a Raspberry Pi or as I heard yesterday apparently a touring pie is a thing too but then the weakest note obviously will not be able to compute transactions as fast as the strongest nodes so roll ups allow the more powerful nodes to do even more computation when we're talking about ZK Roll-Ups it's 10 000 times or more and more expensive to produce a proof than to even just execute itself so we increase even more the computation of some powerful nodes and this helps weaker nodes uh catch up so um the thing is today roll ups control a lot they control a lot more than just doing execution and horizontally scaling ethereum in fact they they centralize the entire process of deciding which transactions to include and in what order and this brings us back to a world in where there are essential actors that have the power to discriminate that have the power to impose monopolistic pricing or maximally extract nav from users and these are all the things that blockchains were promising to get us away from uh if you think about it the roll-up ecosystem today is essentially web 2 applications that are being audited by an L1 right but the the actual processing and everything is really just being done by the web 2 application it's just being followed and verified by an L1 so um what is the solution one solution is to separate ordering from execution all right so that application layer roll up servers will execute transactions and uh and not handle any of the ordering process not handle any other process of even making data available the L1 would not build or execute its roles would only include finality on transaction ordering availability of transaction data and the verification of State proofs and users would submit transactions directly to this decentralized L1 so this has also been called a based roll-up architecture where you have the consensus Network that users submit transactions to roll up servers read a transaction stream from this um from this consensus Network and uh and then post to stayed rude and approve like then gets verified um challenges arise from this however if the L1 is not doing any of the execution then how does it set prices for including transactions that doesn't execute um how does it verify that the fees that it's receiving are paid correctly does it need to have some kind of minimal state to do that how is revenue that it's generating shared back with Roll-Ups or applications how do we prevent spam could the L1 overload the proving Network without compensation for work all of these are challenges not all of which I will address in this short talk today but these are all things that need to be considered when when working with uh with with such base roll-up architecture or more generally what I would call decentralized secret sequencer architectures um so we can also look at hybrid centralized base architectures where and this has also been called Escape hatches or L1 inboxes I would say that is a form of based rollup where um or related to maybe not exactly the same where there is a designated roll-up server that can order transactions but users can also submit directly to the L1 so the L1 orders some of the transactions the designated rollup server orders others and we have some way of deciding well maybe the transactions from the rollup server go at the head maybe they go at the tail there's different approaches to doing that and this hybrid architecture can be applied to any decentralized sequencing design as well we can mix and match um so there's also perhaps a reason to separate the order finalization layer at least logically from the layer one and why might we do that why would we use anything except for ethereum's gas or protocol today for ordering and making available transactions well specialization right ethereum makes some decisions on how it works to optimize for certain sets of properties for example ethereum is extremely available extreme theorem is extremely decentralized right if you wanted to design a protocol that is still decentralized but prioritizes fast finality and can give faster pre-conformations then that could be a reason to design another layer if perhaps it's something that's that's designed for high throughput data availability that's another reason to design what I would call some layer one and a half that sits between the layer 1 and the layer two so protocol modularity opportunity to make different design trade-offs higher throughput lower latency faster pre-conformations foreign when it comes to talking about faster pre-confirmations a common misconception is that ethereum's finality is 12 seconds this is not actually true this is the average block time of ethereum transactions must be several blocks deep to be confirmed and it takes in fact 15 minutes for transactions to finally be finalized by Casper FFG which is the finality Gadget of ethereum often users may consider a transaction final after five minutes some may consider it final after 12 seconds but that's very very risky you can read more about this by looking at ethereum's discussion vitalik as opposed on single slot finality where he explains that ethereum's finality is actually 15 minutes not 12 seconds so let's say you want to design a decentralized protocol that could provide faster finality than ethereum why doesn't ethereum have fast finality well it runs something called a dynamically available protocol which means that even if 10 of the network is online not 100 it still can process transactions it still can make progress Bitcoin has this property too this is in fact one of the Innovations of consensus protocols in the last 10 years that started with the Nakamoto consensus protocol um but we also have protocols that are on a different side of What's called the cap theorem meaning they are it they cannot be dynamically available but they can achieve what's called optimistic responsiveness which colloquially may be called Fast finality an optimistic responsiveness is the ability to respond as fast as the network will allow when networker conditions are good the consensus protocol can give you instant finality it also has an asynchronous fallback path so that if the network conditions aren't good it will eventually make progress but it will stall if enough nodes go offline right ethereum doesn't have that property ethereum cannot achieve fast finality because it will remain live even if a small participation set is online whereas protocols like Hotshot developed by espresso systems will go stall if too many nodes go offline but if they're all online and the network conditions are good they can give you very very fast finality almost like a centralized sequencer uh there are protocols that achieve neither property like tendermint um but uh so responsiveness it's the idea when when there's a high rate uh when the sun is shining you get this High rate instant confirmation when when it but it's still robust when when it's raining right right so we call this web 2 performance with web3 security we can also blur the lines between the physical lines at least between the layers when it comes to things like eigenlayer um things like restaking enable you to to incentivize or at least subsidize the participation of the L1 nodes in this layer one and a half so that the same physical set of nodes are running it and you're making the same ultimately the same trust assumption but just the protocol properties are different so um moving on to sort of a second challenge um fragmented liquidity and interoperability it's beautiful that this application layer is being sharded by Roll-Ups but this fragments the interoperability so now two applications can no longer call each other they can no longer make function calls to each other um your you know your your Ave liquidity pool is no longer shared across all all all applications if they sit on different uh different roll-ups um bridging across Roll-Ups is complex atomicity is limited so how can we recover this and specifically the what degree does sharing an ordering layer only and not an execution layer which would make everything the same roll up right does sharing an ordering layer only help okay um so this is the next question I want to explore so there are three advantages I will only focus on one one advantage is simplifying cross-roller bridging and atomicity because you are sharing at least the same ordering protocol so you don't have to verify each other's consensus the second is mitigating what I would call systemic risks of bridging overall and the opportunities for profit that they provide to adversaries you can mitigate that and reduce it by sharing a consensus protocol I won't address these first too we have blogs on it but I will focus today on explaining why this supports what I would say cross-roller building with economic bonding this is not the same as sharing an execution layer but it gives you some very interesting guarantees so first quickly on proposer Builder separation this is the way things work in protocols like ethereum today it also works like this in Hot Shot there's a proposer that's elected by the consensus protocol in every slot to propose transactions but this proposer while it needs to sign and broadcast information doesn't need to come up with everything that needs to go into that block that could be outsourced um in fact it could run an auction among competing Builders who are able to build an optimized block there are different things that this might be optimizing for generally if we leave if we let the proposer run this auction then naturally the builders who win the block auction are going to be maximizing the revenue of the proposer and that's what motivates us to do some other designs which are designing like an ideal functionality that implements an order flow auction where you which is optimal for users and stable for users could we design something where users are are getting the best execution prices available to them or guaranteed that their transactions don't fail and this is something that the the teams like flashbots and Suave have been working on and other teams too and is sort of the future I think of um of sort of the order Flow Design of blockchains but in order to uh in order for this to work the the consensus protocol needs to be extremely decentralized so that the proposer doesn't just say okay you know what screw this ideal functionality it's not good for me it's not maximizing my Revenue I will just run my own auction the way I want to no if it's extremely decentralized the proposer gets elected once in a blue moon it can either take transactions from the ideal functionality or have no transactions at all it can't make a credible threat to users to abort the ideal functionality and that's why decentralization is important this is in fact why EIP 1559 works it only works because ethereum is extremely decentralized but with proposer Builder separation over an extremely decentralized shared sequencing layer decentralization is key then you can also introduce these Builder functionalities on top and these Builders or ideal functionalities can also start to provide some interoperability guarantees example a builder could say to a user okay the user wants to trade on optimism and ZK sync it sees some Arbitrage opportunity it wants the Builder to include both of these transactions in the block and ensure that they both succeed because the Builder is basically able to win this auction of a super block wholesale that that sends blocks to both zksync and arbitrary it controls it basically has a lock on the state of both zika sink and arbitrum and thus can make this guarantee to the user it can promise that that it will include both trades in the same block and it can also write this promise in a cryptographically authenticated way so that if it violates This Promise then the user can go to some smart contract and slash it okay so if if I don't do this then you can use this as evidence to slash me and it can put up a big collateral in order to give the user confidence uh in this that this promise will be satisfied this is a simple example but we could go through an example of even cross roll up flash loans it will take more time so I I don't have time for it in the short talk today um but just to summarize so espresso sequencer is one of these layer 1.5 sequencers it sits between the uh the the L1 ethereum and roll hubs although we're trying to blur the physical Lines by using eigenlayer and it provides this consensus on ordering but um there's a there that also supports proposer Builder separation and we envision most of block most blocks being built in that Builder um in that Builder layer which can actually provide the interoperability guarantees to users which wouldn't be possible if you had different consensus protocols because Builders would not uh well Builders would would have to simultaneously win many auctions and that carries a lot of risk a common concern is as how is revenue from Crossroad bundles allocated back to roll ups another common concern is whether this leads to Builder centralization um to address the first concern uh the concern that Builders will need to execute for all interoperable Roll-Ups and that may create a higher barrier to entry leading to fewer competing builders so first I think it's important to recognize that Builders and validators are not the same thing and we don't require the same level of decentralization at each layer of the stack we need to work from first principles and look at why what do first of all what does decentralization mean does it mean a lot of economic stake does it mean a lot of distinct physical nodes does it mean geographical and what is required from each layer given the given the service that it's providing executing for all rollups is not actually that hard maybe it's hard for 12 000 nodes including a Raspberry Pi maybe it's just hard for a Raspberry Pi but executing is not a huge barrier to entry and we don't necessarily need 12 000 competing Builders we just need enough competing Builders to create competition in the market that drives down Monopoly pricing not necessarily 12 000 of them um so it's unlike the decentralization requirements of proposers and in fact if you have a highly decentralized uh base uh layer or a consensus protocol then propose that's what that's what enables proposer Builder separation that's what makes these proposers more passive and able to be compatible with ideal functionalities that are designed in an ideal way for users that are that are thus stable for users um furthermore the barrier to entry is much higher without shared consensus because it requires more Capital to win simultaneous auctions the Builder absorbs more risk and it can't promise user atomicity without this risk this phenomenon of Builders executing for all rollups is an inevitable consequence of the user desire for interoperability it will happen no matter what and so I would argue that designing a shared sequencing layer is going to lower the barrier rather than create more asymmetry among Builders and increase the barrier which is the alternative of many independent Roll-Ups with their own sequencers so um I uh this is a small meme about that right well there's where there's a will there's a way builders that execute for all rollups anyways we'll find a way to do it uh shared sequencing enables more builders um I don't want to go into the revenue sharing problem because I'm out of time but I just want to say it's connected to order flow auctions and there's a cool idea of splitting up slots so that it even slots you don't have cross roll up bundles and it's very easy to divide the revenue and in odd slots it may be trickier but you get a good approximation from the even Slots of what to do in the odd slots announcements we have a dopio test net we also have double shots of espresso available at our booth but the second test net of espresso sequencer called dopio is now released and it features an end-to-end integration with polygon ZK evm a fork of polygons ekvm next we're working on op stack Integrations we're working with Caldera spirocatalyst injective alt layer we recently won an optimism sequencer decentralization RFP so we'll be working on that and here's a little picture of our little growing ecosystem if you want to join this please let us know we're happy to talk to everyone so thank you so much [Applause] great thank you so much ben um we're going to be hearing more about shared sequencers next we have Josh Bowen uh CEO of Austria coming up uh who's going to be talking about Austria speed running the end game Josh over to you [Applause] all right hey everyone um thanks for having me so yes they said I'm Josh I'm the CEO uh founder of Austria um okay which button the green one okay all right so I actually renamed my talk asteroids vision for the end game I used the talk uh speedrunning the end game previously so I get the slides in late but what I'm going to walk through here really is what asteria's architecture looks like and kind of the the top to bottom of like why we're building the architecture we're building because you know as shared sequencers have given gained prominence in the last five months since this has even been like a kind of a concept um you know uh there's been a lot of questions around like why it should be designed one way or another um and so we're gonna give that and so for Astra earlier we have like two kind of key principles we think that Roll-Ups should be decentralized by default this is generally a pushback on the idea of this Progressive decentralization which has been promised by a lot of different roll-up networks but quite frankly we haven't seen it you know we're 18 months into mainnet on a lot of Roll-Ups and they're still just decentralized if they were day one when they launch so we believe that if we want to see a world with many many Roll-Ups they're going to be decentralized by default otherwise we'll have this recurring window of we launched it at centralized we'll get to the decentralization later and there will perpetually be newcomers that are just centralized so that's principle one principle two is that we believe deploying a roll-up should be as easy as deploying a smart contract also am I going to get a clock time there or should I just guess okay um so we believe we're deploying a roll-up should be as easy as deploying a smart contract and now I'm just going to go into kind of architecture stuff I have 53 slides to get to so I'm going to talk quickly this is how we view the general kind of transaction thing you could call this like the transaction order flow but we put it in a kind of four stages and noting that we are or at least myself is not in the camp of a roll-up being defined by its Bridge so that's just you can argue with that we have a panel after where we can fight um but we believe we start with unordered transactions that could be intense we go to an ordered block from that ordered block we end up with an executed block that has a state DB and presumably a resulting State Route and then after that you can have a succinct for a VK proof um and that is kind of what we're going to argue the ordering we'll label these as order flow sequencing execution and proving and view those as four phases again people in this disagree with terminology but I have to pick some semantic definitions to go with right okay so state of sequencers to gay this is what I'll argue is kind of the most simple case for a centralized sequencer today you have an end user they're going to talk to a roll-up sequencer get a soft commitment there as it's one box that's a centralized sequencer that sequencer pushes batches to the DA layer you get a firm commitment for that what are the problems with that like why would we decentralize a sequencers typo there um because this roll-up sequence or the centralized have the persistent Monopoly on ordering right and that's a problem for any number of economic reasons on transaction flow on censorship right but we don't want to have one party that has a persistent modeling when we say persistent we mean across all time right across blocks so if we go to a decentralized sequencer where we'll just simplify and say we have a leader rotation so there's multiple entities this is still for one roll-up but multiple entities get a chance to be the sequencer for the block and everything else is the same we moved to having a per block Monopoly on ordering this doesn't resolve everything right we've seen a lot of like interesting designs like multiplicity for like multi-validator um like block proposing but it is we'll argue better than having a persistent Monopoly across all time there's various research on Mev things where you can maximize Mev by extracting no Mev in one block and putting all that Mev in a second block we remove cases like that when we say there's now a per block Monopoly on ordering you can't guarantee you're getting multiple blocks or at least it's probabilistic well argue that's better right so why shared sequencers why would we want to go from decentralized for one roll up and many Roll-Ups having many decentralized sets to Shared um and this is what we're going to pause it as like a model for this you'll still have a user they'll communicate with the RPC for a given roll up so this is your metamask to like a guest note or whatever um and it will push transactions to a shared sequencer we implicitly assume the shared sequencer is decentralized here um and so what are we doing here right now we're shared right here we have multiple Roll-Ups users still can interact directly there's more complicated designs but for this Taco limit here where you can have multiple roll-up rpcs sharing a sequencer so this is our kind of simplistic model it's very similar to like the espresso guys kind of more complex like diagram and they have a great demo visual on Twitter that you can look at um come on right so what does a user actually getting from a sequencer commitment when we say it's like a soft commitment what are they actually getting out of it so I really like this quote I've used this a lot of times it's from Nick Carter's article it's the settlement Assurance it's stupid from way back in 2019 um it's obviously Nick Carter right it's a little bit Bitcoin adjacent but I think it is some of the better written work on what we're talking about when we get a commitment of finality it's a settlement assurances refers to a system's ability to Grant recipients confidence then an inbound transaction will not be reversed right this is usually used in the case for the specific article of Bitcoin this is the sixth confirmation depth thing right it's probabilistic finality when do you know a transaction will be reverted we'll say settlement assurances or settlement is this act of not being reverted so we'll say a sequencer guarantees a user that their transaction will not be reverted right and then if we think you know okay is this a settlement layer right we have this quote from James fresh which we pin this in our marketing channel and slack this is one of the things that was influential on moving from we're building a settlement layer tool building a shared sequencer the term settlement layer is very busy muddy right and confusing so we're not going to use that but why shared sequencers right come back to this question why would you want a shared sequencer we argue again from the Nick Carter it's the settlement Assurance it's both right Ledger costliness is the most profound and direct variable available to evaluate a blockchain settlement guarantees but simply it's the equivalent to the amount paid to validator slash transaction selectors per unit of time so in like a Bitcoin case which is probably the most simplistic one to understand this is like the amount of computational effort put into a given Fork of the chain right and literally the money burnt to give you that layer of like settlement finality right in a proof of stake chain in like something like ethereum right where you still have like a heaviest chain and it's slashable right it is the depth or like the weight of a stake that has been posted on one given Fork of the chain right that's your like that's what you're gonna call Ledger costliness right so we argue that sharing a single sequencer set between multiple Roll-Ups will increase The Ledger costliness right what we mean by this is if we have you know 10 Roll-Ups and the you know we'll assume they have kind of heterogeneous transaction flow right there may be not all EVMS there may be serving different use cases and they are all relying on a single point of settlement and they are doing like a proof of stake mechanism or even if it's something like you know proof of governance or just like kind of an implicit governance kind of chain link style implicit staking right if you have multiple use cases and more order flow using a single point of settlement as stronger guarantees if it is shared between all entities rather than each of those Roll-Ups attempting to acquire its own kind of set of Ledger costelliness right um so this is what we're looking at right let me look at this architecture we'll assume that the soft commitment has a high likelihood the transactions are settled specifically if it's shared we can assume it as a higher likelihood the transactions are settled in a shared set than if it was decentralized across any given role so then we'll say why lazy shared sequencing and so again I think our architecture and I you know Express those architectures implicitly we say It's a lazy shared sequencer what I mean by this is it's not executing the state transition right to the original picture it's doing the ordering not the execution for all the Roll-Ups so why are we doing that right well really there's a question why wouldn't we do the stateful shared sequence it would be really nice if we could say hey we all do it in one go and we all get this commitment over a state route we get the Ledger cost leanness and it's nice and clean why are we not doing that that seems like the obvious nice solution right well argue that the resource requirements for a stateful shared sequence are one doing execution for all the Roll-Ups scales in proportion to the number of roles it's not explicitly the number of Roll-Ups right but if you assume that I as a validator set a sequencer set need to execute three different heterogeneous State machines I need to keep the state and I need to process and do the execution use the computational power and the storage requirements to keep all these states in these ledgers that increases if I add another roll up then I have to pay more cost right so going back to one of our principles deploying a roll-up should be as easy as deploying a smart contract right if it's a stateful shared sequencer it prevents permissionless use of the shared sequencer and what this means is if you are introducing every time you add a roll up to a shared sequencer you increase the cost to the resource cost to the actors in that sequencer set then that cannot be permissionless because you've now introduced a Dos Vector right I can go say I'm going to go make 10 Roll-Ups and I'm going to push them into the shared sequencer and I've just increased the workload of all these entities right so if we look at things like polka dots parachain options right that is a mechanism to create an economic cost to join the sequencers at the validator set if we look at interchange security with the cosmos Hub now replicated security right there's a governance process you need to convince the validator set that they should allow your state machine to join the set and we believe that it should be as easy as deploying a smart contract you don't need to ask for permission to deploy a smart contract you simply go to the chain and you pay the gas fee and you deploy your contract right so that's one of our arguments for why we should use a lazy shared sequencer but then going back if we're not doing the execution right what is a lazy shared sequencer actually guaranteeing to our end users right and we're going to argue that a lazy shared sequencer guarantees that a transaction's position in the canonical block ordering won't be reverted so specifically this is a weaker guarantee than saying the resultant state route of your roll up is X right and it's actually giving you this state root hash if you're familiar with like a tenderment kind of cosmos space there's a distinction between tenderment giving you a block hash and the cosmos giving you a state route right we are talking about a block hash right you're giving a commitment of The Ordering of a given block but not a state route of a post State machine execution right and so we are you again right deterministic State machines it's kind of what we're doing with blockchains generally right a chain state is determined by recursively applying its state transition function to an input state in an ordered block right so very simplified function here right for at state zero and we don't move to State one we provide block one and we just run the state transition function now we have state one right I'm not like a math guy I don't know what the math symbols would be to recurse this right but run that every time from Genesis you now get the resultant State Route and the important thing here right is that from a Genesis state if you have access to all of the ordered blocks for a roll-up but not the state commit of those roll ups you can still as a full node executing that deterministically reach the same end State as everyone else for a given Fork of the roll-up right so we still have the capacity to do this execution but really when I was like when are these blocks actually being executed like who's doing this execution if not the sequencers at the validator set right so this is when we go to like ethereum land right so this is a picture from Mev booster picks is a great dashboard place to look for like information on Mev Booth when I checked on looks like the 16th right we're at 95 percent of ethereum validators are running block through Mev Booth right or like 95 of the blocks on ethereum overall are meth Booth so we're pretty close to 100 of people are using PBS for this right and then let's look at the relay dashboard right so within relays there's really two types right I guess there's three types if you consider the censorship ones like a type right but we see the largest relayer 28.3 is the ultrasound relay and the ultrasound relay is considered an optimistic relay and what we mean by that is that validators are actually not checking the block that is given to them by a builder to ensure that it is a valid State transition function they're not re-executing the reason they're not doing that is they save some milliseconds of latency by not doing that execution and the way that PBS works as an option mechanism Builders want to be able to submit their blocks as late as possible in the block timing by shaving let's say 100 milliseconds off of that they notably change the amount of order flow the amount of blocks that are sent to them as a relayer and they want they're all trying to competing for order flow right so by saying will yellow right we're going to assume that Builders are not sending us fake blocks um and we will not execute that right so what we argue is 28 of all blocks 28 times 95 is like 26.8 or something of all blocks going through ethereum today the validator is not actually executing the state transition function so what does that mean where are these blocks actually being executed so we'll argue this is like a rough design um for how we would see a shared sequencer having like a PBS Mev supply chain order for right users go to roll up our PCS those rpcs could be you know any V Supply flow we could have like Suave whatever right but they'll go to something that's order flow and we're gonna assume that order flow is the thing that takes transactions maybe there's bundles in the middle Searcher Builders they're not that distinctive parties actually in actuality at scale but it outputs blocks to the shared sequencer proposer right and the important aspect of this diagram is that to generate these bundles to generate these blocks execution is needed to find profitable blocks right if we think about what we saw with Mev before Mev Geth this is pre-emerge right what would you do you do a priority gas auction you spam the chain to try to get your transaction it would revert if you didn't like it right we introduce an auction mechanism and actually it's not economically desirable it's not like game theoretically optimal to go submit non-functioning blocks right if I'm like a PBS person I can like go grief the chain but if I'm here to make money like I'm a sophisticated professional actor I'm James Street I'm jump whatever right I want to make money so I want to submit good blocks so I have to do execution I have to run the knapsack problem across you know all the state machines and theoretically find what is the optimal block right it's like a PNP problem or whatever right they're gonna do execution to find these profitable blocks and they're going to know whether a block works right and so the shared sequencer the key thing defines the canonical block ordering but really what it's going to do is it's going to choose the most most profitable block that is offered to it and structurally a shared sequencer is essentially the same thing as an optimistic relay right it's going to be given a bid and a block and the economic incentives say that the people who are going to be sending it blocks they're going to send it profitable blocks and profitable blocks are going to be executable blocks that are valid not blocked that are just kind of griefing the chain and saying oh look you have a block and it's good like revert or whatever right so that's our argument like where the execution is actually happening in this stack we can have like a lot of debates maybe in the panel on like the trust assumptions you're making whether you've moved to economic assumptions instead of like like programmatic assumptions or cryptographic assumptions but remember this is where 27-ish percent of all ethereum blocks are already being pushed this way and that's relatively stable but we could see increase right this is status quo today so touch on bridging really quickly here right we're not doing the execution so when we go to bridging right either role defined by its Bridge not answering that question here but if we say three components of bridging right I'm gonna argue that bridging is between ascending party and a receiving party and the key of Bridging the ascending party has to come into receiving party that the data is available that there's a canonical ordering and what the post execution state is this is broadly what like a contract on the receiving side of a bridge is looking for right if the data is available and we have shared da we're going to say that to trust minimized Bridge we're not going to go too much in depth to that but that's generally what we're looking at like the roll-up sphere but really when we look at this kind of order flow diagram we're going to say the soft commitments again the shared sequencer is defining the canonical ordering of the chain so we're getting a canonical ordering between all the Roll-Ups on the shared sequencer the firm commitment coming from the da layer that's giving you your data availability so the question is who's attesting to this post-commitment state route right who is actually executing the chain and saying I will give some kind of guarantee cryptographic economic whatever of this actual Post State Route so what's the state of the world today right the status quo evm chains by and large so whether you want to say like a gnosis chain you want to look at like the Roll-Ups between each other right they're often not going through the optimistic Bridge seven day withdrawal window that's really long time right so you have mechanism they can use connects they can use something like hop but in reality a lot of them are using things like layer zero they're using things like axolar they're using things like um I'm forgetting the third one Wormhole right fundamentally I'll consider the Third Party Committee Bridges you have some off-chain set of actors that are making a multi-sig attestation and staking their reputation maybe they have an on chain stake on the validity of that State Route comment bft chains they're using a native validator set it's still a committee bridge and it's still an attestation making an honest majority assumption but they use their native validator set right we'll say this looks like this right you have sequencing you have an ordered block you can do execution you get an executed block that executed block that is implicitly ordered right goes into a committee that committee generates an aggregated signature whether that's BOS multi-sig whatever right and that aggregated signature is sent to the receive side and that's the kind of attestation we're making what is the next gen right we see succinct Labs working on proof of consensus of ethereum sync committee polymer is working on ZK mint right and so what fundamentally these are is we're going to do the whole first step right we're gonna do an order block we're gonna do an executed block we're gonna pass it through some committee that committee is going to have an aggregated signature pass that aggregated signature into approver and we get where everyone call like a proof of consensus to use the zinc term right why do we want this proof of consensus it's kind of like an interoperability solution right cryptographic curves are hard to verify they're expensive to do in contract right eth doesn't know how to verify an ed 25519 signature natively or cheaply for tendermen so to go between tenorrent Comet bft chain to like ethereum if you wrap it in a snark you essentially have a very expensive yet off-chain signature aggregation modification right so this is what we're seeing a lot of things move towards right um but what do we think the end game is right a morgue that prover networks are going to ease the creation of succinct State person I'm not a ZK person I'm going to details of VK stuff of the storage proof for the state proof right but fundamentally we have things like Risk zeros like Bonsai Network we have like the nil Foundation guys right we have these people working on networks that say you take a state machine you do the execution and you pass it into this generic box of proving and it's going to give you a stark a snark whatever right so it's succinct proof of execution that allows a light client to verify it however it's worth noting inter-cluster bridging still needs this proof of canonicity or this proof of consensus over the ordering right because fundamentally you can easily generate a proof of a state machine or theoretically you can easily generate it but you could generate a proof that is a valid State transition but is not the canonical chain State transition so you still need both components right what you get with shared sequencing and it's like one minute phone rushing one you one proof of candidacy for multiple Roll-Ups because the shared sequencer defines the ordering for the change right so you can generate one proof for all the chains using the shared sequencer that tells you this is canonical chain and then within the shared sequencer you just need the state proof so we'll say this looks like this right you order a block that's happening on the shared sequencer standard kind of like next-gen stuff right this is the succinct style stuff this is the comet BF or the the uh ZK mint from the polymer Labs guys right you generate this proof of consensus and then once per roll up you do the state execution you pass into a prover Network you get a ZK State proof both of these things go to your receive side chain now you have all the components you want again we can go back and say if you're in a shared da layer you get something trust minimized right you know if this is everyone sharing Celestia if this is everyone sharing ethereum right you get slightly better guarantees as well but this is how we view it like the layer above that um so again looping back to where we started we believe that role should be decentralized by default we're giving come on we're getting our workshop at 4 30 like shortly after the panel in the couchy stage we're going to show off like what we have for like a demo right now we have a development cluster very similar to actually like what espresso has we'll show you guys how you can run this locally and how you can deploy your own rollups using a shared sequencer so thank you everyone [Applause] awesome thank you Josh I I now see why the original title was speed running that was truly a speed run uh coming up next we're gonna actually have a panel on shared sequencing I'd like to welcome Evan uh from Celestia up here who is going to be moderating and hosting the other members of the panel please come on up as well Evan are you supposed to be on the left you want to do an order good hello alrighty so the whole theory that I have for this panel is that all the talks that we just saw they're sort of like movies this is more like the features on the DVD this is this is something to go you know get to know these guys this is something to sort of I I hope that if we if we uh don't answer any of these questions and we just sort of go with the flow I'm totally okay with that um this is just too just to go with the flow just something interesting so um we already sort of have an intro so I'll just run through these intros really quick right here we have Ben Fish he's the CEO co-founder of espresso he's also an assistant professor he has some incredible research that that widely used today so uh proof of replication I just learned this for filecoin literally the most used uh I'm supposed to talk on a microphone the literally the most used ZK proving system today no big deal um also vdfs and even some economics research on mining really great work we also have Conor so Connor is just a general purpose gigabrain I have learned so much from him he's oh yeah he's the CEO of roll kit apparently he's an engineer and a researcher at Rocket I personally I've learned a ton from Connor about how you actually decentralize rollups and without using consensus to use something like four Choice rules it's really really interesting work and you've also done work with NPC and you're also uh you were a guitar teacher yes so he can riff okay and then we have Josh Bowen so Josh uh you are known I think for your width and depth of knowledge which is rare uh you've done work again some also some research at uh Celestia on execution environments fraud proofs optimistic Roll-Ups and um before that you were at Edge node right yes and then before that we don't want to talk about that no okay there's a Google he worked at Google okay okay so the first question is what is love no I'm just kidding this is not like the Lex Friedman podcast but we could talk about that yeah okay um the first topic I really want to get into is not really um comparing which is best with like consensus and decentralization but one of the really interesting things with this panel is that we have three shared sequences or with roll kit a way to build shared sequencers with as a roll up but they're all in very very different contexts so it's like these the all of these folks and all these projects are incredibly smart but they made different decisions based on that context so if we can dive into the why and the how of why we use the consensus algorithms that we used then I think that gives us a better understanding over the problems that we're trying to solve which of course shows us what where what shared sequencers actually do because sometimes if you go on Twitter uh one of the leading questions is just like WTF is a shared sequencer so we can just go in order um Ben sure yeah um so the way that I view it is if Roll-Ups are built on top of the layer one then the default shared sequencer should be the the layer one if it's not the layer one what are you doing right well you're trying to do something that the layer one doesn't provide so if you're trying to build roll ups on top of ethereum and I'll talk about building Roll-Ups on top of Celestia in a second but if you're trying to build Roll-Ups on top of ethereum ethereums are dynamically available protocol meaning it's very available it works even if 10 of the network is online it has very slow 15 minute finality so we decided that well what does it make sense to build for a shared sequencer that is not the layer one but sits on top well something that provides a different property and that's fast finality so that's what Hot Shot or consensus protocol does it optimizes for getting 12 000 validators to be able to reach consensus within a few seconds uh it sacrifices the availability guarantees that ethereum has in the sense that if less than 75 of the network goes offline then it may not make progress um but that is the reason we did that if you were building a shared sequencer on top of a different L1 like Celestia which uses tendermint then it may make sense to use something else right um tenderman we didn't decide to use centerman because tendermint is not optimistically responsive that's like a separate discussion it's like it it is it is it can have fast finality but it it doesn't necessarily scale to as many nodes if you want to retain those fast finality guarantees so HotShots designed to scale to ethereum's validator set because we want to be as close to the L1 as possible just providing a different property in this case fast finality instead of high availability um never thought about using roll kit as a shared sequencer that may be a possibility but we've been we're more interested in using shared sequencers with roll kit roll kit is meant to support all different kinds of sequencer schemes because we've identified many and the trade-off space between them all is unbelievably complicated so uh we like shared sequencers a lot because one of our goals has been to allow people to launch chains without needing to provision a validator set and when you've promoted that idea and got everyone excited about it and then they find out they have to have sequencers uh then it's not it doesn't seem as cool anymore so you can do you can do a roll up without sequencers easily if you do the base Roll-Ups the no sequencer roll ups but those inherit the block time of L1 which on Celestia is 15 seconds 15 second finality 15 second blocks a lot of people want to go faster than that when when people think about Roll-Ups they think about arbitrum and optimism which give very quick soft confirmations and provide a very fast ux to the users and if you lose that when you go to develop a roll up you're going to be sad so shared sequencers let us do this no validator set easy to launch and also have the fast user experience so shared sequences are probably one of our highest priorities to integrate into real kit as soon as possible yeah if they're going to redirecting what the other panelists have said right like I take a much more kind of like practical background like I'm not an academic by any means and so you know I the evolution of vastra as a project came out of my work at celestion broadly what we were working on was like how do I deploy a roll up on top of celestion what are the components necessary to kind of do that right so we go look at like why are there sequencers in like ethereum roll up we've all seen like the based rollup design mechanism right but the fundamental reality was that users would prefer faster response times and slower response times I often reference right there's some research from like like 1991 on like how do users feel about like user experiences and like web applications right and like roughly it says users want to click a button and expect it to respond within like one to four seconds shorter is better there's probably more modern research on like mobile uis right everyone views like an older phone or like iPhones are known for having like much faster latency and it feels kind of smoother right but users like responsive user experiences to Evan's point right with the centralized Roll-Ups we got these very very fast responses and again I'm kind of cynical or like you know I view it as practical right if we want to say hey we have these centralized sequencers we want to decentralize the sequencers if you sacrifice the latency benefit that is the reason they move to centralized sequences in the first place users are going to say oh this is just like a degradation of my Protocol no one in like a roll-up wants to be like the first mover to say cool I'm going to use the shittier experience that my users like less than the centralized ones so it's kind of our job will be like we think decentralization is important then we need to provide a user experience that is adequate that users will actually use the damn decentralized thing because I am not optimistic that users are going to be just like altruistic actors who say no I use the thing that is the most decentral like no they don't they use the thing that is convenient for them that makes their life easy we need to provide a decentralized solution and I think shared sequencers are a way to do that while minimizing against the it should be easy to deploy a roll up right we can't have everyone do this problem like if we want a thousand Roll-Ups we can't have every single project need to do this process every single time yeah if you um going back to the point of like taking away the fast responsiveness have you guys ever taken away ice cream from a child it's like it's not fun okay so next topic another way to think about a shared sequencer is it's it's a committee and it can perform some sort of service for Roll-Ups as a committee and specifically like um there's just like a lot of different services that you can provide doing that for example like with espresso you can provide da and with uh with Astria as far as I understand you can do something like IBC and uh like settlement like with the evm portion so I'm curious to dive into what are the other committee Based Services that we haven't already touched on or what are some committee Based Services that you think would be useful for roll-ups so again we can just go in order yeah well I mean the the it's interesting that you think of it as a committee uh I mean the committee cannot if the committee is like uh 12 000 nodes or if it's if there's the same set of nodes as the underlying L1 then it's not necessarily committee it's the same physical set of nodes but it's logically playing a different role of offering a modular component of the overall services that a rollup needs primarily ordering and then availability can come for free as part of that but then you bring up a good point like what other services can you get from an ordering layer so we've been talking about in our talks how shared ordering layers like espresso like Astra also give you interoperability guarantees um beyond that if you you could think about adding validity checking as well so what if rollups could also just settle directly to the shared sequencing layer then you might ask well what is the layer one doing right well the layer one is still there Perhaps Perhaps layer one is being used for availability but the layer one and a half for some reason and is better at um at providing for example it may be easier to add a a custom op code to verify ZK proofs at the layer one and a half that is uh that is faster it really depends on what you want to move between the layers because the layer one can provide all these Services as well I can't think of anything we want besides a fast dumb decentralized ordering machine okay I'll give a more optimistic take I guess like like fundamentally I've used shared sequencers and this is going to my kind of like like Cloud SAS Enterprise SAS background right and this is the land of middleware right like like when I join crypto I think one of the weird things to me was like you know the architecture was like oh there's like ethereum and then you just like slap a UI on top of ethereum and I'm like that's not what Enterprise architectures look like there's like 13 layers between like an Enterprise service bus and like some Oracle DB from like two decades ago right and like the mobile app you use to check your insurance right layers exist and middleware is used to kind of intermediate between these and to like reduce complexity of interactions with like a broader kind of ecosystem of things so if we think about shared sequencing again it's a committee what can you get from this committee I think of it as like you know we've used the term decentralization as a service but also it's like what can a roll-up get for free by using a shared sequencer um again it gets these soft commitments to like my talk right there's bridging benefits if you say you still need some kind of bridging guarantee of like the candidacity of this chain mean this is less useful if you're doing like a settlement to like ethereum thing right where you say well okay you know is the roll-up defined by the bridge well the bridge on ethereum has control over the ordering of the roll up in some mechanism then that's fine from bridging but if a roll-up wants to bridge to like some extra domain space it's going to need to make an attestation of the canonicity of its given Fork to that receiving chain um we could also think about things kind of like farther out like okay is an oracle you know is it a roll-up of like the shared sequence or whatever but you could say part of the data stream of this shared sequencer is some set of Oracle transactions from off chain how is that happening is the committee of the shared sequencer having you know an increased amount of state and actually making some claim over the validity of you know this off-chain data there's various things like that but I think really the way to think of it is like it's a stream of data generally we assume the roll-up is only kind of filtering out the stream of data directly relevant to it there is potentially data you could push into that stream that gives a shared timestamp of it across all the Roll-Ups that they may choose to filter out as well so again you could have some Json format for Oracle data and all the roll up to the shared sequencer can choose whether or not they want to parse out that Oracle data and use that in their state machine there's a pretty broad design space there but it's unclear what will be like useful and I think the research on like what are the kind of trade-offs and security guarantees and whatnot of these things but like I don't think we're solving the Oracle problem here but there's potential like ux benefits that's like a rope developer yeah that's really good um one of the things that I was uh to lead into the next topic is Mev and PBS specifically so some of the things that I was trying to hint at is with with these community-based Services is that whenever you use a shared sequencer and if that shared sequencer is using some sort of Mev infrastructure that Mev infrastructure is like sort of already set in place for you so um to get into the Mev part monopolies are bad in general that's usually a safe thing to say amongst crypto people and most folks in general but we don't always get rid of all of the monopolies and I think especially from Ben's talker you had some really really good answers to this so I really want to dig into monopolies and basically profitable censorship so we still rely so crypto like we like to think about getting rid of monopolies yet we have each proposer has a monopoly over which block is used for that given slot so I kind of want to dig into um who captures Mev in the system and how can we change that to be more programmatic and no matter which direction we want to go in um how can we change that so yeah we can just again go in order yeah I mean this this conversation is relevant even just talking about uh layer ones like without rule ups but the same problem happens with uh with shared sequencing layers for olaps too um so it's interesting that you said wait a minute the proposer in a consensus protocol has a monopoly on a slot it gets to decide what goes into the slot um so this is I think one of the really interesting things about consensus protocols there's a there's a number of papers on this like there's a paper called Monopoly without a monopolist a blockchain is a monopolist a a proposer has a monopoly over one single slot right does this slot-based Monopoly Behavior achieve Monopoly pricing meaning do users pay for um pay pay the price that maximizes the revenue of the blockchain or do they pay basically the market clearing price where Supply equals demand and so ignoring Mev of ordering and sandwich attacks and all that right if we just look at what's the price to include a transaction EIP 1559 has solved this problem users pay even though the proposer in the consensus protocol has a monopoly users pay the market clearing price and the reason is that if the proposer is not willing to process the transaction of a user paying the market clearing price the next proposer will so having a monopoly for a short period of time does not give you a monopoly over prices for the and this is the key property of blockchains that's why they have to be decentralized right because I'm elected once in a blue moon to process a block if I don't take the transactions as they are paying the market clearing price there's someone waiting in line who will just do it so I cannot make a credible threat to users to reject their transactions paying below market clearing price now when it comes to Mev this isn't the case because the transactions are available to me I can sandwich attack them I could even get the help of a bunch of Builders and Searchers to figure out how do I extract as much about a value as possible by reordering the transactions in front of me the willingness of a proposer and a later slot to do it without extracting value doesn't matter I can do it now because the transactions are there now and that's why we need to move towards order flow auction design where we introduce an ideal functionality that has a privacy element to it which Shields the transactions from the proposer builds a system which is ideal and stable for users so that all users submit their transactions there and then we turn the proposer back into a passive entity that can either take the block output of this ideal functionality or have nothing at all and again that proposer does not have the ability to make a credible threat to users to not take their transactions if they send it to the ideal functionality they just tried to take anything that's available to them at the time so and it's very hard to design those ideal functionalities it involves a lot of cryptography perhaps trusted execution environment but that is the direction the industry is going in that's what flashbots and Suave are working on and those are only work with highly decentralized ordering protocols that's why we're advocating for shared sequencing yeah yeah so to respond to that really quickly it's like we in theory you have multiple different Builders so maybe multiple different swabs or something like that and the proposer since they do still have this Monopoly for this one block it's very short and it's very limited they still can pick the block that gives them the most profit so this is sort of where I was uh right but the block that gives them the most profit may be the one that has all the users and the one that has all the users is the one that is shielding users from Mev so you can either design something that's stable for the proposers or you can design something that's stable for the users if all the users are participating only in the order flow auction that gives them the best execution price the the the the short-lived proposer has no choice but to take from that pool otherwise it doesn't have any transactions to process it can't make a credible threat to users to say no don't submit there I won't take it because it has a short turn and then it's gone ASL it's proposed like the spicy like Counterpoint right of like dumb flow is dumb I guess and like what I mean is that like generally when we think about like retail flow and like users getting sandwich it's because they're like unsophisticated actors and like they're not necessarily doing like the labor to find what is like the optimal execution for them right and then there's also like we can think about user preferences and like Financial senses but like also in like a product sense right so like I spent like years at Google right like what does Google do well Google provides you a lot of free services like are those Services free no Google's monetizing that on the back end with ads and why are they doing that because users don't like friction and transactions are friction you know crypto talks a lot about transaction friction because if it's like two and a half dollars the main transaction won't do it well like when apps came out like the App Store and like apple right it was like 99 cents to like buy an app or whatever it's like no money right like functionally use an app for like 10 minutes you should be willing to pay a dollar for it right but people didn't so they made them all free and then they monetize on the back end users Trend towards things that are low friction and they monetize on the back end we see this in financial systems right with like Robin Hood and payment for order flow right users don't think and they don't read the MBA paper papers that say like hey maybe it's sub-optimal for you to actually be like submitting transactions that are free and then you get like marginally worth execution though the actual quality of execution on payment for order flow it seems to be like an unanswered open question from like analytics and like availability of data but like fundamental like users use the thing that is low friction not necessarily like the thing that gives them like Optimal execution so I think like again like I'm very positive on like like Suave and like flashbots but I think it can be a very hard-fought battle to say we are able to convince users that they should only submit transactions to this if that may result in some marginally higher transaction cost for the user and then someone else comes along and say I will ruthlessly front run and sandwich you but you will not pay any upfront transaction fees the users might say yeah I am fine with that so I do think there is like something from like a product perspective that maybe like trickier to get from like user demand rather than the kind of like again like the ideologically like corrective like we just need all the user flow to go through um one of these kind of like tee environments and therefore we can't do all the sandwiching attacks when you're yeah what if the users just like don't care I think we're moving the target I mean whatever is good for users is good for like let's define what's good for users that's the ideal functionality maybe it's not paying for failed transactions maybe it's not paying Monopoly prices maybe it's both but if we design something that's stable for users then that will be stable for blockchain too only if it's decentralized and that's the key Point yeah yeah and I agree on that it's just like defining what like what is actually a user preference across like many parameters it's like hard agreed oh if you use a lot of a lot of people talk about uh Roll-Ups inheriting liveness and censorship resistance from their base layers uh we found that if you build a sovereign roll-up on a DA layer which is built such that it inherits censorship resistance and liveness from its base layer fundamentally you leak a form of Mev to the validators of the base layer called profitable censorship uh and if you don't want to uh leak that Mev because maybe you don't want to create anything like gas Wars on the base layer then you can't inherit liveness and censorship resistance from the base layer so if you're using a shared sequencer and your shared sequencer has its own consensus and its own proof of stake in its own token the cost to create aliveness failure on the shared sequencer is the cost of one third of the stake if it's tenderman style and that could be very high that could be high enough that role of developers don't feel as though they need to build a force transaction inclusion mechanism from L1 it might be censorship resistant enough on its own and so uh the shared sequencers do can help remove that Mev from da layers this is really really good before we finish it up on Mev do you all envision any way for a roll-up to be able to capture its own value just like that like like what would be like more of like a mechanism design for for a roll-up programmatically capturing Mev as opposed to only relying on something like Suave or whatever is built into the shared sequencer I mean I think that if a roll-up is using a shared sequencer then that the shared sequencer becomes part of the role of this protocol and so it does need to be programmed into the shared sequencer um you can always view things as roles participating in some kind of order flow auction so if you do design order flow auctions then maybe there's a way of doing it without programming it into the into the shared sequencing protocol but I think that that's the opportunity that we have right now so one of the ways if we didn't really touch on none of us really touched on this in our talks but um with base roll up if you use the L1 then there isn't really a way of programming into the base layer like oh roll up should get back this portion of Mev we designing these decentralized protocols on top of the layer one have that opportunity now and I think it's important for adoption it's important for at least the major Roll-Ups out there to be convinced to use espresso or Astra or roll kit right an important thing to do is to say here here's a credible Revenue sharing protocol in place that can allow you to get back the value that you're creating for the system rather than the system taking all the value and so that is a I think a very important research problem that I'm trying to get people excited and interested in we have some in thoughts on that I shared a little bit in my talk you can have like alternating blocks where in some of them you run independent auctions some you let me run joint auctions independent being one for each roll up joint being auctioning off wholesale blocks for all the Roll-Ups at once and that allows you to estimate and approximate the marginal contributions of each more more directly and and um and then use that to inform some reallocation strategy but this is a wide open problem that welcome everyone to think about and and offer better Solutions on we think a lot about how you can do Mev redistribution and things like that and we suspect that the way it might work is if you're if whatever layer is doing your transaction ordering has really really good censorship resistance maybe with something like a threshold encryption scheme or possibly with a multiplicity style scheme that Duality proposed you can use verifiable sequencing rules and maybe something like protocol and Builder to capture that Mev and do interesting things with it there's also of course all the all the various and epbs smoothing and burn schemes that are coming out of the ethereum world uh and maybe those would would have some way of ensuring that it gets captured and redistributed in some Equitable way as well I guess I'll just throw like a contrary point in here maybe of like so from our view of like the idea that like deploying a roll-up should be as easy as deploying like a smart contract or whatever the term we use there was a question to me of like who is the roll up and what I mean by that is like you know not the mechanism design of like calculating like the counter factual of like a single auction versus like a combinatorial auction of like what is the value that this roll-up deserves which question of like who is the entity that like represents this roll up and how is the shared sequencer aware of that being like a distinct entity so it's kind of this question of like and Ben we've talked about this like various research things like where do you pay back like the roll up itself like what is the state machine that is like actually calculating and like you know receiving these funds and choosing like to distribute them like to our thing we think from like a ux or like a developer experience it's important that like there's not like a registration phase for like a roll-up to like sign up to the shared sequencer that's kind of an intentional and why we're like a lazy shared sequencer so to this degree it's unclear who would be like the valid entity that is being rebated the actual funds even if we had a magical way to calculate like the optimal value that should be returned it's like well who are we actually giving this to and then the other point I think of is like where do we want this value to be like returned to should we be thinking about like the roll up as some like nebulous entity or like application developer should we think about like the users right what if we see some space where you know I didn't have you know tough time in my talk to cover but like what if users are doing something where they have some kind of front end or singular order flow thing whether it's like Suave or some other kind of aggregation mechanism that is actually using multiple distinct State machines and then settling to a single shared sequencer well that user may not have some kind of like preference for one of these chains versus the other and so should we be thinking more about rebating the Mev to the users and again to Ben's point right going to order flow auctions of like well actually we're trying to get the Mev fairly back to the user and you know just right now in the current like Mev design even on like eth right like 90 of that mmv is captured by the proposer so that's like the entity where you have to get that margin from to give back to the user but it's unclear if we want like an intermediary up to like give it to the like the sequencer or like you know the nebulous entity that is the roll up really we just want to be giving it back to the user and giving them like best execution price nice okay so much good Alpha right now um let's let's focus um on base Roll-Ups bass Roll-Ups are a critical part of shared sequencing you can't really have shared sequencing without some sort of lazy execution so I'm not really sure on the exact definition of based roll-up but effectively you agree on the transactions beforehand and then you execute them so this is what I think what Josh was talking about earlier on his talk where you have um sort of like an optimistic relay where you're you're submitting a block you're submitting some sort of transactions and then you have some sort of arbitrary execution environment on top so another thing to do with Mev is I'm curious on like with this execution environment itself on reordering the transactions or doing something to do with a base roll-up capturing again this goes back to like programmatically capturing its own Mev is can you have a based roll up that doesn't necessarily respect the ordering of the shared sequencer and can that like be beneficial in any way do you see that as like a viable thing or I mean a very fair answer is no no but no and or is it only yes and can we do a no and okay no uh anyways it gets into the definitions of a roll-up can Define its own State transition function so and that could be on a block level for example you could have an ordering of transactions in a block but then an application which reads all those transactions like takes the average and then uses that to determine like the state of an amm so you can process you can Define your state transition function to be not just executing transactions in the order that they appear but it could be some deterministic function of how they appear in blocks you have to of course break it up into some parts you can't wait forever until you decide what your transition is but you could do transitions on a block level as opposed to an individual transaction level and that does give you some ability to Define these reorderings but the key thing is you can't do it in a dynamic way you can't do it in an opinion opinionated way anyone looking at what the shared sequencer outputs and knowing the the state transition function knows what's going to happen there's no like Dynamic thing that the rollup can now do so that's the nuanced perspective yeah doubling right like the state transition function like we argue like it has to be deterministic right how you order it you can just say I read it backwards like why I don't know because you choose to right like I think a batch auction is probably like the cleanest thing if you have like an amm like a penumbra style bash auction right like everyone gets the same price it doesn't care matter if you're at the front of the block or like the back of the block right but like it has to be deterministic you're not like doing like a random shuffle because again then the shared since they're like against like what is the commitment giving you if you're like ah someone's gonna randomly Shuffle It by some exogenous extra protocol rule you're like all right well you won't come to consensus on it then like what are we doing here right um so it doesn't have to be deterministic again like how you order it how you refund it like fine but also from like the shared sequencer perspective like it's just like including the transactions it doesn't really care what you're doing after the fact that's on you the the name of the concept is verifiable sequencing rules I believe and it reduces the problem of fairness to the problem of censorship resistance if you can get something included then it will be ordered fairly according to the verifiable sensor verifiable sequencing rules there was a research they talk about it from Matthias it's it's quite good under our guide to have a general opposition to like the concept of like fairness being like a thing there might be some like useful economic definition for it but like I think arguing of like fairness is where we get like spam and whatever right like all of the first come first served things they're like oh is it fair and like was it fair that the guy has like faster hardware and like a better like a shorter ethernet cable is like faster than you well maybe not fair but something that you can capture and redistribute possibly yeah exactly so what I was trying to go with that is that you definitely need a deterministic function but could you design a deterministic function that can Direct Value capture to somewhere where you want some sort of programmatic Mev capture so something like a batch auction like what you were saying yes but I think that can only be the value capture within the state machine of that specific roll up that cannot be the value capture of say an inclusion fee within the shared sequencer like you on your roll up cannot deterministically reorder something and such that you extract value from like the inclusion fee on the shared sequencer yeah I mean it's also important to know though that if you have a deterministic function and you are the protocol or the Builder that does have Dynamic control over the ordering of transactions that then go into that straight transition function you are the entity that can figure out which order is going to maximize my own profit or which order is going to maximize some profit so you don't really have control just by defining the state transition function over where the profit goes and that's why you still need to get back to this order flow auction design that we were talking exactly because the proposer has Monopoly over not the proposal well again if it comes back to consensus protocol the not the proposer has a monopoly for one slot right which is important because that means that it will take whatever output it's given if that's the only output from some order flow auction that it can choose from that's the consent that's why consensus protocols that's why blockchains are good right blockchains turn proposers into monopolies from one slot and that's why each con centralized systems are bad because you have a monopoly over all slots and it's amazing that when going from Monopoly over all slots to one slot allows you to achieve non-monopolistic behavior in a system that's like the coolest economic thing about blockchains um but you still need to solve this like Builder side you need to solve this order flow auction that designs a system which is stable for users if you really want to mitigate or minimize Mev or control where it goes your verifiable sequencing rules can't they don't know if somebody sold on a centralized exchange after they did a swap for example for example great because how all the Mev is extracted nice nice okay so we're bear with me we're going to bike Shadow on naming just a little bit fun um Okay so one of I think actually the main criticism of shared sequencers is just the name so like do you think that shared sequencing is a good name like is it Justified or would you rather go with something like I've heard shared proposer I've heard sure to Shared aggregator is it not sure it seems reasonable but maybe not even that I don't know what do you guys what do you guys think are we going in order here I think that when it comes to names there's no there's no perfect name for anything so I mean blockchains aren't a great name I'll say it [Music] um they they made a lot of sense for for proof of work consensus but um you know other other consensus protocols may not be blockchains but but it's the thing that catches on and it's a thing that resonates with people and it makes sense and I think that shared sequencing we've all now been using it and of course once you start using something people are going to point out reasons why it may not be the perfect term um but in the end of the day it's a pretty decent term and sequencing refers really to finalization of the sequence in which Roll-Ups will execute their transactions we could add that to the title that's a mouthful and I just don't know if there's another name that's like nice and short and succinct that captures it but if somebody comes up with one you're the winner I think it's a good name a lot of people like aggregator I think that's a good name as well I guess I'll say like yeah we need like a very intentional decision to like use shared sequencers like it was like a marketing term right but like fundamentally like people that use the same shared sequencer have a shared view of the sequence of transactions so like certainly better than like settlement layer where everyone's like what the hell is a settlement layer what are you settling what is settlement right we're like no no you use the shared sequencer you and everyone else using it has a shared view of the sequence of transactions that feels pretty explicit right yeah we implicitly assume that it's like in our terminology right like a lazy decentralized shared sequencer but again you just have to pick words and put it in your marketing copy are there any other misconceptions on shared sequencers that you guys would like to address now shared sequencing is not one roll up shared sequence is not shared execution it's not shared building per se it makes some set of shared building easier I don't know shared sequencers are real that's a great segue into uh does anyone know really quick how much time we have left oh wow okay well okay that's great um no no there's no need we don't have time I was gonna we were just gonna handle if Roll-Ups were real or not so we'll just uh we'll just leave that for next time all right thank you everybody I'm super I was super excited for shared sequences before take them now I'm extra excited for shared sequencers great thank you Evan thank you all stick around because uh coming up in a moment we are going to hear from Neil um all right I'm just gonna give it a moment of transition protection all right thank you all if you want to chat I'm going to encourage you to make your way towards the door if you would like to stick around however I would encourage you to do that please we're going to be hearing from Neil from eclipse in a moment all right wrap it up wrap it up take your seats everyone please all right I'm giving everyone a countdown to grab their seats in three two one okay thank you so much all right thank you all coming up next we're going to be hearing from Neil somani uh the CEO of eclipse and he is going to be telling us why Roll-Ups as a service are going to zero very controversial so hopefully not all of them over to you Neil thank you hi okay this is on um okay so for context Eclipse builds Roll-Ups as a service so uh this topic might be confusing for some folks and in this presentation so I'm Neil I'm the founder and what I'm going to explain is one like different economic or technical considerations for app specific Roll-Ups gonna talk about the roll-up of the service landscape and uh and yeah well let's get right into it all right so there's been a lot of discussions about rafts or Roll-Ups to the service and what I want to do is I want to First Define what is a roll-up as a service a role of the service is something that deploys roll-up Frameworks and that requires understanding what is a world framework a roll-up framework is something that implements execution and settlement related capabilities for a roll-up so this is something like op stock or arbitrum orbit you uh deploy one of these Frameworks yourself or you can use a Ras and then you can start having your own chain for your own application so this is a like Market segmentation and I'm sorry think piece which I actually signed off on the times are at the time so this is partly my own fault for not thinking it through fully but what I think is more useful for this kind of segmentation is to think about what parts of this stack are Cooperative with each other which parts are competitive and I think if that's the right way to frame it so the way that they frame to here is they have sdks which I'd probably call Frameworks instead since they're not all sdks you have shared sequencers and you have no code deployment and I'm going to talk about how I'd reframe this a little bit so what what are the sequencer sequence I mean we just had a panel on sequencers right now but it's something it just is ordering ultimately without ordering you have to compute the actual State transition so that's execution so roll up to the service as they exist right now this is maybe a little bit too narrow I called it isolated sequencers as a service usually it's also deploying the execution related capabilities but that's essentially what Roll-Ups the service as they exist right now are uh they might do some additional support Consulting and some stuff which I added as a footnote I'll talk about that a little bit more but uh what I want to describe is basically what what is a business model so right now it looks like some amount of fixed fee that might be a fixed field charge there's some variable components so it's a percentage of the sequencer fee which you have to actually Define that a little bit a little bit more clearly because that could be a percentage of the congestion fee or the execution fee for a roll-up that could be just a premium that you add to every single transaction but uh this is kind of what I want to address and I think if this is something that every roll up as a service should have a view on but the first thing is that the roll-up framework to some degree actually competes with a roll-up as a service and that's something that I'm going to cover in the next couple slides so I'm not going to talk about it too much right now the other thing that roll-offs the servers have to think about is that given that they're deploy isolated sequencers as a service there aren't actually like a lot of network network effects there aren't really economies of scale for every single isolated sequencer for each additional roll-up that you deploy the service doesn't really get better or it doesn't get cheaper unlike I mean a shared sequencer for example for every additional roll up now you have additional composition between those Roll-Ups or for certain types of services like da the more folks that are using a single da layer than more valid there's more fees coming into the into the system because blocks get full maybe it's a fee Market it goes up that incentivizes more validators to run for like Celestia or something so that's very synergistic whereas for a roll-up as a service that kind of network effect doesn't naturally exist alone there might not even be a token uh so that's something to keep in mind so as I also want to so I think this is the right way that I want to frame that discussion of how a roll-up framework could be competitive what they roll up as a service and the way I want to put it is by thinking about the functions of a modular blockchain so we're here at modular Summit everyone should be aware of this stuff but the functions as Celestia puts in their docs we have execution and I threw a bunch of stuff in there I put sequencing the actual execution of the transactions and Computing the state transition function I put proving for ZK Roll-Ups the second part which John Trav would say doesn't even exist is settlement so it's figuring out like what's the canonical chain or what's like the correct state of this roll up and then there's da which hopefully everyone's aware of here but like let's say you're an optimistic roll up you're a verifier you need to know what were those transactions that were run in order to even call for a fault proof or even on any L1 you need data availability uh just to so that all the full nodes can know what transactions were run they can keep keep in sync with the network so another way of thinking about these functions of a blockchain is these these are the possible ways you can try to accrue value or the place where you can try to capture value whether you're a roll-up framework or some other type of part of the blockchain stack so um so yeah now I want to go a little bit more deeply into each of these three areas and think about where could a roll-up framework feasibly capture value so settlement to me is not a viable place to capture value because one we're not even sure that it exists but two settlement doesn't make very much money so for optimism may not and this is actually all about optimistic Roll-Ups partly because that's what we have deployed for Eclipse right now so that's what I think about the most but you can probably make similar Arguments for ZK Roll-Ups settlement costs might be a little bit higher but even if they're 100 times higher that's still only like 500 bucks a day not a great business to be in for every single chain uh whereas Optimist and mainnet it's as optimistic roll up so it's just basically posting State routes and in the happy path that's just five dollars a day so that's basically zero to me or I mean should be to everyone else as well so a competitive settlement layer to ethereum is going to make even less money because they don't have the security budget of ethereum to justify why they would charge more there's less congestion fewer people would use it so so that's not a great tip place to play is my point and then da this would basically be the case where a roll-up framework deploys their own competitive da layer uh so this would be like if Arboretum had a selection your competitor or something or if any trust became the primary business model and my argument here is that that's not a very great place for a roll-up framework to play either partly because Celestia already exists and we're all using it and for da in particular there's very good reasons for all the Roll-Ups to try to use the same da layer because you're all like posting to the same place the fees go up like I was saying before it's synergistic for everyone to use the same da layer because more people are providing security for that DNA layer then so so yeah so I'm saying the only place that's viable is actually execution and as a result those fees that come in from the sequencer are basically Zero Sum like you can charge more but that just makes you have a less competitive sequencer or less competitive roll-up framework or Ras so between the roll-up framework and the and I call it isas here isolated sequencer as a service maybe I shouldn't do that it shouldn't have done that because it's just like additional jargon but uh but I just put it there for Simplicity and this is a graph on the left side I want to think through like the like the business model game theory of an isas compared to a roll-up framework and those numbers might not make sense because chat GPT generated the graph but uh what I want to convey is that I want to start with the isolated sequencer as a service and think about whether it plays nice or doesn't play nice with the roll-up framework that it's deploying and playing nice means that it shares Revenue back to the roll-up framework and not playing nice means that it tries to capture all the value for itself and in the case where it shares value my argument is that they're subject to being undercut anyone can choose to not play nice and that's going to drive they're going to win in from an economic positioning and economics is probably the biggest reason why people deploy their own option so I don't think that's a sustainable configuration and if the roll up as a service chooses to not play nice then the roll-up framework themselves it needs to monetize somehow so the roll-up framework likely will deploy their own Ras similar to like what optimism has done with conduit in my opinion so that that's kind of how I would think the student and what I feel is it's the stable configuration is for roll-up Frameworks to have their own roll up as a service because then they can they have all the flexibility in business model they're not forced to share like some fixed amount of sequencer fees they're not getting undercut by someone else they get all the profit for themselves so that's kind of my thinking and then this is just considering a little bit further the case where a roll-up as a service competes with a roll-up framework themselves so they're deployed this is like if someone's deploying a roll-up framework that they don't own versus the roll-up frame framework deploying their own reps and then I'm just comparing these two cases where my argument is that the roll-up framework has more flexibility they likely already have a liquid token they can subsidize fixed costs so this is this is not like a like a fatal thing it's more just something that every roll-up as a service should have an opinion on this and they should like establish their positioning think about what's their business model and how do they expect to sustainably capture value and the reason why it's really important is because developers care because developers don't want to build on a stack that they think won't exist in like one or two years and that's probably going to happen there's no sustainable business model so this is how I'd reframe the massari framing from before and I've basically renamed Roll-Ups as a service to isolated sequencers and what this really shows is that you can only have an isolated sequencer or a shared sequencer but you can't really have both and then similarly I renamed rollup's sdks to roll up Frameworks just because I like that better it's a little bit more General and then if you're in the roll-up frame or category you should probably find yourself also in isolated sequencers or shared sequencers similar to how op stock or optimism has the Super chain that's likely going to manifest as a as a shared sequencer all right so this is like an economic thing and this slide's a little bit dense so I won't like go through all the specific numbers um but what I wanted to look at is let's say you ran an OP stack chain I use op stack because it's just an open source framework so I deployed it and it costs about an eighth to one eighth to deploy the smart contracts I consider like roughly zero just because overall long enough it's a one-time class so if you're running a roll-up for years and years or something it gets amortized so the recurring costs are more interesting to me and for like most a lot of optimistic rollups they're still posting to the DA layer even if no transactions are run that's because the sequencer is allowed to do some additional stuff so that's half an eighth a day of just overhead cost which gets amortized over the number of transactions and that brings it brings it down and then there's some variable costs and that's the biggest component for all uh for all Roll-Ups and Sanjay at electric actually wrote like a great piece on the cost breakdown for a given transaction on a roll-up but the da cost is is the biggest one so this I'm not going to make you do the math but it ends up being about 15 cents on a good day this is assuming like 20 five Quay gas price uh and then assuming two thousand bucks per eat but yeah that's basically like the cost that a roll-up transaction can never get lower than that if it's deployed to ethereum itself so this is like considering some of the other things that could potentially impact this like after EIP 4844 maybe the cost goes down by like 10 times or something that's all speculation because we'll have to wait until it's may not similarly we don't really know the Celestia I mean that cause because once that's up we'll we'll have to see similarly with eigenda but my point is that just look at that variable cost and you should think about what applications make sense or don't make sense given that and I think an obvious one for example a game would never make sense like a fully on-chain game couldn't make sense on the ethereum L1 as a roll-up because 15 cents per transaction is likely prohibitive unless somehow the players are making money off of every transaction but if it's fully on chain every transaction is likely not profitable for them so that's that just seems unlikely to mean whereas a DAC could make a lot more sense so having a variety of Da options is really critical to enabling things like consumer apps uh I mean another way of thinking about this is what does make sense that's probably like D5 people don't really care about paying 10 bips or something like that on a big D5 trade so this is probably reasonable given given like the price propensity or the marginal propensity to spend for uh for D5 users on ethereum a lot of them would make sense to be on their own roll up given that they're used to paying such high fees it's a strictly better solution for those D5 Ops and then I just want to think about most applications do they have that transaction volume to justify amortizing or to feasibly amortize the fixed costs associated with running a roll-up and that answer for most apps is probably no nft projects in particular probably doesn't make sense to be on their own chain small D5 apps probably don't have enough volume so this is I'm not saying this to like discourage app specific webs I think people can experiment but we've seen a lot of app specific Roll-Ups on testnet which would never be viable on mainnet so I just want to point that out and then this is like one last consideration that I want to talk about and yeah there are some technical reasons like in order to do shared sequencing it assumes that there's some Builder the builder needs to generically support many uh I'm I'm maybe assuming some knowledge here but we just have the shared sequencer panel but Builders need to be able to execute for base they have to run a flow node for all these different chains so that implies some sort of interface for execution uh for settlements you need to have some some restrictions on how execution could occur so that's those are some reasons but the main reason to constrain a customizable Roll Up is really just to better motivate the use case because if you look at Cosmos SDK for example this might offend some folks in the audience but I never really felt like there was a plethora or diversity of use cases or implementations for Cosmos sekn if you look at Terra for example without the stable coin it was just a regular Cosmos SDK chain that's how a lot of the chains look at this point so I what I think makes a lot more sense is sector-specific architectures such as a D5 specific architecture with extra short block times that might impose an additional constraint such as sequencer must now be centralized in order to support that short block time or maybe for games for example like we were talking about earlier it might need centralized da or a DAC or something like that so this is an example of a sector-specific architecture that we put together for worlds which is some polychain-backed game fully Unchained Avenue world's previously built uh Unreal Engine 5. so he comes from a traditional gaming background and his view is actually like uh contrary to mine but his view is that the purpose of the blockchain for the game is to act as a read-only interface or well for the users it's not read only but as a game developer they just write to that blockchain and they make it a public API for anyone to compose on top of similar to the steam items API or to I mean there's like a bunch of these that people can compose with but the advantage of being on a blockchain is that it's standardized so that's how he thinks about it and as a result he had these additional constraints which is one he doesn't want the users to know that they're using a blockchain and that's particularly important because he can use steam If he if he abstracts the user or if he abstracts the blockchain from from the user and steam is the biggest distribution channel for games so that's one thing like he doesn't want to build financialization himself such as like these played earned games he's not like a player iron guy and then he also wants to put a bunch of data on chain and like we talked about before that can constrain the da options for him so as a result we built this chain for him we deployed a one of the standard Eclipse chains we put an evm on it I don't know if everyone here is familiar with neon they actually recently went mainnet but it's like a Sputnik VM spotting VM is a rust implementation of the evm deployed as a smart contract to the svm So This Is How They achieved this parallelized evm higher throughput than any other evm chain of the subtlemen layer they uh so ZK the the point that's here is basically that a ZK roll up can it will never be strictly better than an optimistic roll up and the reason for that is that there's that additional cost for generating the ZK proof whereas for an optimistic role if you're just posting State routes it's always cheaper to do that so you kept it as an optimistic roll up and then the da layer will hopefully Celestia is cheap enough for this to be viable and then otherwise we'll switch them to a DAC so that that's what the world's chain looks like right now and they've been they've been using it pretty heavily all right now I want to talk about what our roll-up Builder looks like and this is our self-service uh deployment framework or our website for this this is a soft launch we haven't posted this anywhere so you're getting the first Glimpse at it this is what it looks like it was actually a video before but I removed that because I didn't want to risk the video not playing or something but this is the front page you can specify the network name standard configuration options like the VM and things like that specify block times or things that are a little bit more technical in the future you might expect this to look like templates or just specifications based on the type of application that you're deploying whether it's defy or something else it just tells you what the roll-up is going to look like and this is what the chain looks like we're giving a one week free trial so you can heavily slam the chain you can Benchmark it you can try it out yourself and then after a week you can actually pay and it's going to be nft gated so if you scan this QR code and I I won't like waste everyone's time and stay here too long so can you can scan this you can get an nft you'll be on the wait list I'll be sure to let everyone off who is here at the modular Summit so I'll get the list later and you can try out this roll-up deployment website so I'll pause for a second yeah of course yeah go for it foreign one last thing we're deploying we're doing an accelerator in San Francisco so this was inspired by modular um what was it modular fellows which is actually kind of how Eclipse came about it was Nick who reached out after Tara depacked uh and we were just talking about how we can make Solana into a roll-up so we wanted to do something kind of similar for Eclipse to motivate the use cases for app specific rollups we have some ideas on the types of apps that make sense and we'd want to see in our ecosystem there's also a few uh like rfps for things that we need built into the eclipse core product so we'll be uh we'll have those out as well we're gonna get we're putting aside I think like 200 and 300 Grand something like that we'll be funding different projects and we're actually going to host them in our office and SF so it's in San Francisco based a program but for exceptional projects that are outside of SF we can actually fly you in and this is kind of funny but we have rooms in our office so we can house you and you'll be living with our team and you can talk with her with our Engineers every day and yeah that's that's kind of idea so it's smaller than modular files this is only five it might even be as small as three depending on how much we think we can reasonably support all right and that's it so I I think the rest of this is just like um like appendix stuff so yeah [Applause] awesome thank you so much Neil I don't know it doesn't sound like they're all going to zero I think there's hope yeah so up next we'll hear from Matt Katz who's the CEO of Caldera who will be talking about the recent op stack uh Slash Celestia roll-up combo that they've dropped okay that one cool that's an interesting presentation as the founder of a roll-ups's service company to go afterwards uh also um if anyone saw that slide I am not the co-inventor of ZK sync just just to uh keep that clear um yeah I want to talk about uh Caldera our involvement with Celestia um how we're unleashing Roll-Ups with da networks and also just want to talk about some of the motivation behind application specific Roll-Ups why you might want to build them why we are personally still bullish on Ras and why we think it might make sense for some applications um so I'm just going to take you through a journey of some more thinking around this and then talk through our involvement with Celestia and our recent developments there um so yeah first of all Matt founder of Caldera caldera.xyz come check us out um we are the easiest way to launch a dedicated roll-up for your application project or ecosystem we're also the first as far as I know Rob's a service company uh to go multi-stack and so we you know really emphasize developer choice we support uh optimism op stack chains we also support arbitrum orbit chains with many more coming in the pipeline soon we also focus on being an infrastructure layer for modular chains so we know how hard it is for people to launch viable blockchains and that doesn't stop at just the sequencer so we aim to provide all sorts of different infrastructure and we're also a white glove service we are a Ras very nebulous uh definition um but we are one of a few companies that is defined that way oh looks like our emojis didn't didn't render that's all right imagine beautiful emojis there chosen by Chachi PT as well we do reliable sequencer hosting that's a huge component of it of course um you know having reliable rpcs making sure that sequencer doesn't go down uh making sure that archival data is available to users that's a major unlock and that's one of the more annoying things about you know for folks who are trying to launch their own roll up we also do all sorts of additional infra as I mentioned like block explorers rpcs interfaces for bridging like we've actually found that is in some sense like a lot of the value add that we provide um you know teams there are some teams that are able to get started with the roll-up sequencer but they still lean on us on all that additional infrastructure and value-added services that we provide as a cloud provider and as well dedicated support we found you know we are probably the top of funnel for most teams that are thinking about application specific chains or ecosystem specific chains and so we know best uh what people want what people need and and the problems that people are thinking through as they're you know making these decisions and so oftentimes when we're working with teams we're working with them as a thought partner as they think through these major decisions um so yeah I first wanted to motivate just why build with an app roll up and I want to start from the very beginning um in the beginning there is ethereum and ethereum was good but ethereum is also slow um whenever I talk about the speed of ethereum I always include this photo of the Altera 8800 I personally am too young to have ever actually used one but this is a personal computer from the mid-1970s and the thing about this computer it's probably the closest in terms of instructions per second it's the closest comparison comparable to ethereum mainnet so both this Altera 8800 and ethereum mainnet can process about 0.2 million instructions per second in total across their virtual machines now unlike the Altera 8800 which is a personal computer basically single threaded only running you know a single application at any time ethereum is probably the worst Cloud multi-tenant infrastructure ever where you have hundreds of thousands of applications that are all competing for scarce computational resources on top of them and so that leads to high fees this graph was a little bit cherry-picked you might notice it stops in 2021 and another thing is ethereum is ossified or ethereum is in the process of ossifying ethereum as this like Global base layer computer for you know the world's new Financial system like ethereum cannot move fast and break things ethereum needs to be ultra conservative and for anyone who has done anything in the EIP process you know this to be the case it's basically impossible to make changes to ethereum and and especially breaking changes are impossible and this is like generally a very very good thing um for ethereum but if you're building certain types of applications you might want to make changes and that might motivate you to build your own chain as well this uh is true of most l2s that are being built on ethereum right now so if you've talked with anyone from these general purpose L2 chains whether it's optimism arbitrum or any of the ZK teams the Holy Grail is ethereum equivalence basically saying like we want our rollups to behave from a VM perspective in the same way ethereum does and that makes sense for them as well because they're motivated to produce chains that are effectively successors to ethereum's general purpose Mission um but that might not be what you want if you're building an application with specific requirements and so even if general purpose l2s are solving the first you know two problems of speed and cost they're still relatively ossified you know they're going to wait for ethereum to make changes to the VM before they make major breaking changes as well um and so that leads to why you want what you might want to launch a dedicated chain again Emoji not rendering but you have dedicated TPS you have a dedicated Lane to scale and that TPS is all yours again going back to that multi-tenancy point you're not having resource contention between uh all of you know a bunch of applications all in one chain you have either just the applications of your ecosystem or your own application on that chain you also have ultra low fees you can explore the trade-off space um where you settle where you post da Etc um to get the best fees for your application I mean in the last presentation there's a lot of calculation around fees that calculation is legitimate but all of those variables are configurable and so when you're building a dedicated chain you get to choose what the inputs are to that function and then find you know the outputs that make sense for you lastly there's latency I think latency is a really really underappreciated aspect when you're building web 3 applications I spent some time in the gaming industry when you're in the gaming industry if your application has like over 100 milliseconds of latency people like go into your DMs and your email like telling you to kill yourself blockchain that's not the case um you know you have relatively High block times users are used to that but if you're building on-chain social or you're building on-chain gaming like you might actually really want ultra low latency and being able to choose where you sit on that sequencer decentralization Spectrum might be really helpful for that uh also there's customization of the first order there's pre-compiles right A lot of these pre-compiles might be very useful they've also languished for quite some time um us specifically we worked with a team who was waiting for years on the BLS curve operations pre-compiled to get merged you can find their CTO has comments on that uh that EIP back from like four or five years ago they're waiting on it they they needed it they was what would have been most you know helpful for them to develop their application uh it's not getting merged into ethereum anytime soon it's pretty stale we're able to merge it into their roll up get that set up and then they were able to go live like a couple weeks after and so there's other a bunch of other really interesting ones too like the Poseidon hash function ZK friendly hash function but it's not just eips and it's not just custom pre-compiles you have basically full control over the state machine So eventually we're going to be able to support different VMS like the Solana VM the move VM you know whatever crazy VMS or custom State transition functions people might want to do uh there's also value capture um imagine a token Emoji over there you can use a custom token you can generate sequencer fees you can also run some like lightweight Mev and so you can choose how to monetize and especially right now where a lot of projects are thinking about how to make money this is a super important aspect a lot of teams are thinking more and more about this how can they take fees from their roll up how do they distribute that back to their Community how do they use that to fund development and they're going to be a lot of really really interesting models on this going forward lastly uh wanted to defend settled Roll-Ups a little bit we think that the roll-up space and the modular space in general is going to be a homecoming moment for a lot of these application chains to come back into the fold with ethereum via roll-up Stacks that's not to say that we're anti-sovereign roll-up we think makes sense for certain applications makes less sense for others but we're really into this idea of a hub and spoke Altus and l3s all eventually settled by and settling to and secured by ethereum and also having native composability with ethereum assets and access to liquidity on ethereum l1's ethereum L1 and other ethereum l2s and eventually l3s um so there's this wonderful quote from vitalik oppression is always back from 2021 um and this is we're really really aligned with this thesis we get a multi-roll-up feature for ethereum which is effectively the cosmos multi-chain Vision but it's on top of a shared base layer uh providing data availability and shared security that's what he said what you might notice on that data availability point is that we haven't fully gotten there yet um ethereum when we're using ethereum for D.A we're just posting data to ethereum call data that is not super efficient it's quite costly and it's leading some to some big limitations when it comes to roll-ups uh so yeah that's the major blocker um when you're running a roll-up on ethereum you have a bunch of costs and then you have d a uh as a major bottleneck you can split up costs into three buckets the off-chain infrastructure costs this is like your Cloud servers your hosting networking Etc that is relatively fixed and also something that can't really change that much you have on-chain fixed costs there's a little bit of cost and settlement there's also a fixed cost when it comes to Da so a lot of these roll up Stacks they're posting a lot of data uh to ethereum just like empty blocks kind of like metadata for the chain even if there are no transactions being processed and that was talked about in the last presentation as well and it is a major blocker for people who are launching app chains where they might be trying to bootstrap a little bit of activity but you know that activity hasn't come yet they don't have guarantees that there will be people around to pay for fees and cover costs and so you know they are wondering how do they cover those costs and then there are their variable costs so posting transaction data that gets sent to the sequencer and then there's a major bottleneck which is data availability we can quickly go through them these costs are really killer they make it hard to get off the ground as I mentioned um when you're settling on ethereum you might pay a hundred thousand dollars per year in these fixed da like metadata costs that is based off of current calculations so if we have another Bull Run or gas prices get higher greater demand for Block space that number can go up um they also prevent Roll-Ups from being strictly like cost competitive or better on cost than altel ones um for like simple uh transactions sometimes uh there might be cost competitiveness depending on demand on all of these chains um but as you can see like generally for average transactions um a lot of these Alto ones are still slightly better uh than existing Roll-Ups and that's gonna you know harm adoption because users really they don't really care they don't really know the difference between a side chain and an L2 a lot of the times users and even application developers want to go wherever is cheapest wherever there's adoption Etc they're not super aligned with ethereum in general um and lastly and I think this is an underappreciated point about the current ethereum roll-up space and the status quo is that we do have a d8 bottleneck which limits the total throughput across all Roll-Ups that are currently built on top of ethereum these are some calculations kind of rough back of the napkin math from Calvin Victor who works at optimism he has a blog post called TPS is dumb this was a little bit of a sidebar on that blog post but basically you know even assuming like relatively uh you know reasonable assumptions around call data compression Etc like current ethereum d a only supports 360 transactions per second and that's if we're using all of the ethereum's network all of the gas throughput just for posting call data for l2s and this is like based off of uh the current Network so pre 4844 pre-dink sharding but this is global across all rollups so even though uh for the compute we can horizontally scale ethereum right now via rollups eventually we're going to run into this bottleneck and so if you look at a lot of these limitations you'll find the thing that we keep going back to is d a right a lot of these on-chain fixed costs are actually d a which is uh surprising to some people because da is often thought as the variable cost but there's still a ton of metadata that needs to get posted to ethereum uh there are uh relatively High variable costs you're paying da when you're sending transactions and of course there is this bottleneck when it comes to Da limiting the total throughput of all ethereum Roll-Ups uh and so we have Our Saviors um all of whom I believe are sponsored of this event Celestia eigen and Avail basically projects that are focused on providing cheap data availability and at Caldera we were founded we're really you know even since founding like we're really excited about these we saw these uh projects as being the major uh unlocks for an ethereum-centric roll-up future and so we were one of the first teams to integrate all D.A into traditional ethereum roll-up Stacks um so with Celestia we launched the first test net of an OP stack plus Celestia roll-up and effectively you know at a very high level what it does is like we're posting data frames to Celestia now rather than ethereum natively um thus you know alt D.A and we're only posting references to those frames that are posted on Celestia to ethereum so that means that we're turning that variable cost which was uh sending all that data to ethereum D A into a fixed cost we're just sending a reference um this is a diagram from uh from vitalik's blog um just wanted to put this here to say we're not really changing much of the roll-up protocol at all you know we're still posting State routes to the roll-up contract we're still posting batches the only thing that changes is I was told not to stray too far away from uh there but we'll live um is this part so these transactions that data is being sent to Celestia there's a little bit of of changes made in this logic to post references but effectively the robot protocol is still the same we're just referencing data on Celestia rather than ethereum um and it's live so if you guys want to be some of the first uh to launch something and play around with an OB stack plus Celestia test net you can go to our bubstesnet.com or and we did we're also really excited about this we recently launched a test net with Manta Network and these guys are super early adopters yeah they're great there's Kenny in the back from Manta Network um they're as far as I know the earliest adopter of Celestia plus op stack for Roll-Ups on ethereum so they're going to allow their users to experience way lower transaction costs than any existent roll-up on ethereum plus they've also integrated a lot of ZK friendly uh application Level ZK functions and so if you're interested in developing on the first network to use Celestia for da go check them out go talk to them they've got a strong presence of this event so find them afterwards um and yeah thanks uh feel free to contact me at any time if you're thinking about launching a roll up if you just want to talk about the design space always happy to chat um and yeah stay tuned I uh you're not rid of me yet we're doing a panel here uh on the Roll-Ups of service space which I'm told might get spicy so stay tuned thanks [Applause] excellent yeah the spice is just starting to heat up that was great Matt and thank you also for Miracle of Miracles running on time uh with all of that great content I'm excited to go in and start playing around with the op stack on Celestia myself it's my pleasure to introduce Tracy do we have Tracy here who's going to be moderating the Roll-Ups as a service uh panel that's coming up so yeah you're not rid of Matt yet Neil's going to come back up and I think that we've got a couple others joining us as well Wisconsin oh is it in order you can sit are you sure yeah okay well everyone good afternoon thank you so much for joining us for our rollups as a service panel I'm Tracy Wang I'm a deputy managing editor at coindesk excited to moderate because we have four Roll-Ups as a service projects all on stage and so um you know hopefully nobody starts fighting but uh but why don't we just start with you know if we can go down the line and have everybody introduce themselves kind of a little bit of your background any other previous projects you've worked on that are notable and you know kind of how you got to where you are and just like a 30 second intro yeah sure um hello if you haven't if you weren't just here for my talk I'm Matt I'm the founder of Caldera um got into crypto um back in like 2012 2013 um bounce kind of in and out of the space did a lot of stuff around startups some performance engineering for things like games um and operating systems and found my way back into the space working on relative service trying to you know unlock scalability for novel applications on ethereum everyone Yoshi here from all year so um I actually I started my research by in 2012. many consensus protocol and also privacy mainly publishing uh sort of research papers but in back in 2016 and 17 together with some clicks we started to do research on scaling mainly sharding at that time so we co-founded silica and uh basically push the midnight for the sharding protocol and later on I also working on some multigen approach and then around two years ago we started earlier to build this decentralized service protocol for application to quickly spin of a roll up and skilled their applications hey I'm Neil uh great to see some familiar faces here founded eclipse and prior to that I was working at Citadel as a Quant researcher in the Commodities group but I did like power gas electricity and then I left I was briefly building an evm for the cosmos SDK so people here might know like ether mints or Atmos and stuff like that so what this was instead was you take the regular webassembly virtual machine and you try to run evm by code through that and the advantage of doing it that way is you get better Atomic composability between evm smart contracts and walls and smart contracts so that was the thinking my main reason for doing that at the time was actually Tara because Tara had a lot of momentum so when Terra d-pad I just scrapped that project and I went back to the drawing board I was chatting with the Celestia folks for a while I was chatting with some folks at CK Xerox Park and finally like ended up building Eclipse because we wanted to address this Gap we saw on the market for really highly parallelized high performance as burlaps uh hey everyone my name is kotok uh kind of started building uh on ethereum in 2018 but then I got the AIML hype of that time but then like I realized it was not for me and uh back in 2020 that came back came back to the space and uh started uh learning uh reading and researching more about scaling in general uh I I worked with the ethereum foundation uh uh in the PSE team a little bit working on uh the Hubble roller project and the BLS wallet project and uh also uh work with live pair for a little bit move the protocol from maina to arbitrum and I think last year uh I took inspiration from Hubble and like spin up uh spun up a stacker and it was uh basically a framework for building uh roll ups and yeah that's pretty much about me all right thank you so we are at modular Summit and so if you guys can briefly talk about kind of how Roll-Ups as a service kind of fits into the modular vision of of the world and also if you can give like a very very high level definition of like what a roll-up as a service is for any of our new joiners that might not know and uh I want I think there is this uh you know similarly that some people use that like Amazon web services is to web 2 as like Roll-Ups as a services to web3 I don't know if that's a you know directly like a good comparison and so if you can kind of explain what Roll-Ups as a service is and kind of how that fits in the modular vision of the world uh why don't we start with uiq oh great so uh for your best service right so um I think we are talking about modular a lot um today and probably tomorrow so as we know right um like uh two years ago like Mustafa mentioned about these uh Celestia and also modular at that time we are trying to move from this uh monolithic blockchain model to this modular models in that case we try to decouple the monolithic sort of a design from these execution layer settlement layer D layer into multiple multiple like modules like Celestia handling is Da and execution basically belongs to different Azure Labs like we know the optimism arbitrum all different zq relapse and then we also have the settlement they are typical women uh we mean like the ethereum so in that case right when we talk about modular for your library Services midnight for us um like we mainly focus on this execution layer like really run find the show labs for the applications so that's sort of the definition for the modular when we talk about the usual app service but as you mentioned right for uh if in limit terms it's really like AWS or cloud services in the crypto world so people can really just Define the primary charge names and just click a button and then quickly either use us or some of our like projects like platform to quickly launch azola for their application it's either like sort of evm compatible or it can also be wasn't compatible even svm compatible or even like JavaScript compatible right it's really like in general execution layer but mainly for a lot of these decentralized applications um sorry my explanation a little bit long it's it's not as short and like like as the number one yeah snail do you have anything to add or take issue with no iq's answer yeah I like that analogy AWS for crypto that's very flattering I'm going to use that um yeah what's I feel like what's uh interesting well I won't get too much I feel like what I'll just say but what's interesting about all there is that it's reducing the fixed cost substantially by making it a short-term roll-up that's kind of the idea the ephemeral roller but yeah roll up to the service it's like managed infrastructure this way you don't have to actually do the deployment yourself and more than that you don't have to maintain its reliability some other team and you're Outsourcing that to them though I think where it can go wrong is when the roll up as a service is spending too much time on consulting or things like that because that's not scalable Revenue in SAS terms and I mean Ras the whole name kind of like tries to piggyback off the connotations of SAS yeah of course uh so also I think it is nice to make a distinction between roll up as a service and roll up Frameworks for now uh so as uh Neil mentioned low uh it's basically managed infrastructure for rasp projects uh so for us it's mostly around like the framework model so it's uh it's interesting that still it can be thought about as AWS because aw has other services also that yeah you can use to build uh the cloud uh project as well so for us we think of it more in terms of like building tools uh for uh creating those State machines and creating those roll ups instead of like having a chain uh which you can deploy applications on but yeah the AWS example still works well I guess the reason why that AWS example doesn't quite work is because we don't own the hardware ourselves at least I don't think any roll-up as a service at this point owns it and that's why AWS works so well because they get economies of scale when more people use AWS their data centers grow or whatever it's like the whole Amazon flywheel and maybe that is the direction that Roll-Ups the servers can move in they start to like vertically integrate even further yeah to build off of that like I think the if for a technical audience the example I like to give her like platform as a Services it's like a Heroku or like render Railway there are a bunch of these that are built effectively on top of AWS or gcp um but then offer services on top that's effectively what I think all of us are doing I suspect none of us are running our own Hardware we're all on top of a public Cloud um I think that the definition was was good so I don't have too much to add the one thing I'll say is like I see ropes of service as like the distribution layer for the rest of the modular stack right so if you you have like the roll-up Frameworks themselves right stacker being one of them um you have like da shared sequencer networks Etc when people you know but who are like the people and the projects that applications or people who want to build chains are going to come to they're probably going to come to us and so we get to act as kind of like the top of funnel for all the amazing projects lower in the stack um and help them Reach adoption as well yeah the one thing to keep in mind is like Heroku never became a huge business though because as a result like when a company got big enough they would just move off of Heroku saying that's something that distinguishes Roll-Ups to service which is that you want to build in something that makes it a little stickier or like builds in a network effect into the whole deployment um if we like let's back it up a little bit and kind of talk about you know do you think that like kind of roller system service only makes sense if we exist in a world where there are like a lot of Roll-Ups do you this is a two-part question one do you think like we need Roll-Ups or whether you think that there will be a future with a bunch of Roll-Ups and why do we need them as a service yeah I'm happy to go um so uh I think honestly like there's less of a distinction between whether we need Roll-Ups versus like whether we need block space um like you know really like Roll-Ups are on some level in implementation detail and the reason why we've seen a lot of you know proliferation of Roll-Ups as a service versus like side chains as a service right which could have been done back in like 2017 2018 and kind of was done with like Enterprise blockchain but didn't really go anywhere is that with like Roll-Ups it's much easier to provide them as a service the model makes more sense and it's easier to be more aligned with a chain like ethereum um and so that's kind of one of the reasons why we've we've seen proliferation of Roll-Ups of service and the motivation behind that is just more block space and varying types of block space uh on blockchain network so like we've you know all of us has probably spent some time talking about like fully Unchained Games on-chain social high throughput applications High latency applications um all sorts of blockchain applications that are you know continuing to further like blockchain is this platform for like General compute if you see those Trends moving like you need some way to scale and roll up to the service I think are just the easiest way to get there and then the question is like why Roll-Ups have service versus just like Roll-Ups in general or hosting it yourself I think it is similar to like the cloud services model where like you could run things on bare metal there was a time when people did that I remember an anecdote from like the early Facebook years like every time they added a new University they like physically went into like a server farm and like racked a new server and like added that to their platform so like you could do that with in a Roll-Ups you know real world without needing role at the service it's just adding another layer of abstraction on top uh also uh to add on top of that you mentioned like do we need so many Roll-Ups and stuff so I personally see roll ups as more on uh more on the application side of things than chain side of things so uh I think uh the the whole uh theme for today has been at least in this room has been like roll up should be as easy to deploy as smart contracts right so uh over to uh like right now we are building smart contracts our applications are smart contracts but in the future uh if if you have like better tooling and better infrastructure on that we can just start building applications as a roll up so instead of the applications being deployed on a roll up application becomes a roll up in itself so I think one of the most prominent examples is dydx uh so dydx is like uh just doing uh before that uh before it moved to uh its own chain uh it was basically a stack x uh app and that's something which I see happening more uh once we build uh better infrastructure to deploy apps like that yeah all right so that point on like the block space being the reasoning I guess what's interesting to me is like there's a lot of commodity block space to l1's out there I think they're far from saturated so I actually think of the biggest reason why people deploy their own chain is economics and that also explains why we never saw side chains as a service because the fixed cost for a side chain for it to actually be secure is much much higher for a proof of stake chain you actually need some amount of stake probably millions of dollars to secure that chain and on top of it you need like 100 validators Each of which is burning some amount of money every month so you're burning millions and millions of dollars whereas for a roll-up the fixed cost is very low because you only need a small number of sequencers so what you're inherently doing is you're you're reducing the fixed cost and the trade-off is that you've increased the marginal cost because now you have to post every transaction to an L1 you have to pay for DNA but the upside is that when there is execution congestion and things like that then you actually share in that upside so you're going from being a rent Seeker to being like more of a homeowner so that's my thinking uh and yeah as far as why Roll-Ups the service I I'd agree like it's just too Commerce it's not something that I think application developers should be thinking about if they're as far as like running their own stack reminds me of like when people used to have their own in-house data centers I said it all we used to have that actually and it was it was actually much cheaper than using AWS if you don't account for the engineering time the wind into maintaining that whole system So eventually we pushed everyone to AWS that confused a lot of the portfolio managers because they're like what like the in-house thing is so much cheaper that's considered I wasn't really doing the accounting properly they should have been Amber they should have been properly attributing the engineers that worked for the reliability team and and trying to like average out that cost as well uh actually I can provide some extra real world examples um because we all talk about this blog space in theory right so we know that your life can provide much cheaper block space and also at the same time uh if we can provide for our proof of validity proof we can still derive the security guarantee from the L1 select ethereum but beyond that we need some real world example right one of the example I can give with that we are working with one of the biggest gaming Partners right now so the thing like they got a lot of ips from Sega Ubisoft and some of them so the thing like the uh they couldn't really do this manual Consulting one by one for their Partners so what they have right now like collaborate with us and later use us to launcher July for the games that they can make it scalable like for example instead of assigned like 10 people or 20 people team like consulting company and to talk to different like sort of ips right now the can just use us to quickly just click a bunch of buttons and quickly launch that multi-sequencer with fraud proof like roller for them for to to serving to serve their customers in that case like you can quick realize uh like just skill the business not just like talk to them one by one but really like once they got the deal and then they can quickly spin off the rollout for them that's something I believe like probably if like all of us like especially in the room right we believe in the web 3 future we must probably eat the pie of uh internet industry right so in that case definitely we we have to Envision like in the future more and more the movie applications will use blockchain in the future right at the back end so in that case we definitely need a much more scalable and high performance like infrastructure so what we can provide this panel for the developers to use yeah got it thank you um could we go down the line and kind of talk about I mean now we're all convinced that roles as a service is the future like why is your project uh the one that developers should work with yeah great question I think this is going to lead to some interesting answers um for us we're really focused on providing the most mature Stacks that exist so op stock optimism and arbitrum orbit and also we have a really really high focus on customizability anything from like changing the chain parameters easily using Altier choosing which stack to use all the way down to like custom stateful pre-compiles we've been working on interfaces to allow developers to do that more you know all the way to uh you know potentially like additional VM level modifications as well we have a big focus on middleware I think one of the things we've realized is just like as uh what it takes to produce a viable chain doesn't stop at the sequencer we're really focused on providing additional infrastructure looping in folks we work with with other infrastructure Partners creating a broader ecosystem of modular services and you know modular infrastructure and we you know our focus is just on devx ease of use and getting people to through the market with a viable roll-up in the shortest amount of time so on our side we're a little bit more crypto native like for most of the team members join the crypto space since uh 2016 building these public blockchains so for us right we are mainly focused on these decentralization and security so the staff you can use earlier where our dashboard you just click button within two minutes you can launch a roll up but what you can have is really a decentralized sequencer you can choose the number of sequencers you have and also also multi-vm support right now it's uh evm and wazam compatible and beyond that we also have our own proof system so it's you can choose the settlement layer like ethereum or the evm chains and later like if there are anything wrong you can have a challenger verifier to do the challenge for the proof so that this sort of like the most of the uh like I mean advantages we have is really to highlight the decentralization and the security so that's why we spend like almost so two years on the implementation for the this multi VM and the proof system yeah yeah I guess my idea is that like all the roll-up Frameworks to some degree are in their infancy and that especially optimistic rollups none of the Fall proofs are permissionless or enabled so to me what distinguishes like different roll-up Frameworks or Roll-Ups to the service is what they chose to focus on and consequence that consequently what they could not focus on and because that implies the trade-off in terms of their positioning so for us we focused on one was high throughput and high performance and the trade-off there is that the nodes are heavier so they're beefier nodes but they're very powerful so you could run like just an unheard of number of transactions and we have games that are posting literally hundreds of transactions per second on chain and it would only be possible with a parallelized evm so that's one reason and then the other thing is avoiding vendor lock-in and that's something that also implies the trade-off to some degree because it means that there's no strict allegiance to any ecosystem you can actually pick which ecosystem you want to roll up to be aligned with but as a result Eclipse itself is not really aligned with the specific ecosystem it's more like people when they deploy an eclipse chain they choose the positioning for it and they have to to make that positioning known so that's kind of how I think about it uh trying to think if there's anything else that really distinguishes because I feel like all the Integrations things like that like everyone has to provide any block Explorer you have to provide Bridges these are just necessary conditions to having a viable roll up uh so for us I think of EV stand at a like a little different from all the other projects right now over here so our focus is mostly on like uh developer experience so we want to build a system so that you have like a very web to style of building web3 native applications and that's what we are going towards so it's not a chain that we are providing it's it's a toolkit that we are providing it has a bunch of Library functions so you can think of it as like how you develop a react uh react front ends or something like that you have like a whole component system you pick and place components and you just place them so that it just like builds like your own State machine so that's that's the thing that we are focused on like uh building uh making develop uh making uh people uh easy uh give the give them access to build their own custom State machines and those custom State machines we are calling it as microvelops because they are like literally what you want them for uh to do so if you'd want to do like you want to build a token transfers uh application you just pick and place the components required to do that if you're building a gaming application you just taken like a ECS system and you just build a state machine out of that so that that's the that's the mode that we are trying to build in and provide yeah so moving over to economics like how do you envision uh you know roles as a service kind of monetizing oh I guess we'll start with Neil well I I don't think that there's like anything realistic Beyond like fakes plus variable the question is just like what is the variable fee charged on is it on like the size of the transaction or is it based on volume or something like that and then the question is how much is that fixed amount and it should be some function of the Mars the cost of running nodes uh it should be some function of just like the mark it depends on like where the Surplus occurs whether it's the producers consumers uh heart but some some variation of fixed plus variable so I actually I really like the data new and also uh matte just presented uh in the talk as we know right I also give a talk at ECC on the first day so the thing like we have to have the breakdown of all the roll ups either for the general purpose roll up or the application specifically roll up so in general it's like we all discussed right so three parts one in the execution cost so you can charge this part of fees from the users right to cover your L2 operator costs and probably also sometimes we impose the data either to Da or to the L1 so this kind of average cost beyond that they are also like regular you know data to Da right so for games and I probably always prefer like a cheaper price so then it's a Celestia eigen da and it will probably add a better solution but in the end like I believe probably for all of us we we are trying to make it as mobile as possible for developers and the project that you can choose what kind of solutions or pricing plans they want but for either it's like sort of the normal pricing plan different tiers or we make it like pay as you go but in the end it's sort of like after uh the cost from the uh from the running infrastructure plus the service fees we can charge from these developers or projects beyond that I think one good thing like for all of us that if some of these roll ups are quite Successful by running these sequencers or executions right we can sort of have some premium on the lo2 fees either from the users or from the projects yeah but so how many different pricing plans do you guys have then uh no I just give one example it's sort of like the multiple ways right like like you can try pricing plan or this uh PSU world as different like models but in general we need to cover the cost for the L2 I mean in France yeah there's a lower bound on the case yeah yeah wait so if you're talking about like hypothetical pricing plans I'm curious like what your project currently is charging oh for me um I to be honest it really depends on the uh like sort of customers so I can give you one example like because we are providing like different types of products right one is so-called flash layer so for some rft mint and also some games the spin of The Flash layer for a few hours and then they tear down we roll up all the iot back to the L1 like ethereum polygon so in that case uh it's like a one-time uh charge just for this flash layer and another one is like a relative like a persistent one so in that case uh it sort of like depends on the number of sequencers you choose and also the da so on our side we can charge like sort of the infrastructure cost for the number of nodes you run but at the same time if it's really successful there's a premium like sort of from the fees we can get yeah something like that but but still right uh it reads his back is some game providers I mean we work with them they don't charge they charge nothing from the users yeah they zero gas we provide and and basically that in that case we can only charge the fees from the game providers yeah it's it's really case package at the moment yeah yeah so gasless transactions are interesting because how do you prevent spam with that specific architecture um so uh so so for for these games right uh they have typical they have the wireless yeah have a wireless for users basically so that's why I say it's a really it's my case I mean a lot of these web tool applications um probably a stacker has similar experience so their requirements are quite different from the crypto native applications they don't really know how to install metamask they don't really care like you tell them like 15 minutes 15 seconds two seconds they don't care they just want 100 milliseconds yeah so what can you do we have to make it very fast but at the same time you need to fulfill their demands on all this stuff that that's why it's uh it's just some examples but in the long run definitely we can choose our customers right if it will be coming very big yeah well I guess like once you have a self-service thing though then you can't do it so like Case by case you have to have some like standard pricing yeah if I might jump in here I I think like one of the the interesting things about the rasp space in general is like any given pricing structure has like certain kind of failure modes right like if you're if you're charging like you know a flat fee for hosting maybe a small amount per transaction you might end up securing like billions of tvl making like a few grand a month on the other end like you know if you're trying to charge based on tvl or Bridge volume you might be supporting like an on-chain game with no activity uh for very little so I think like pricing models um yeah like it it does sort of need to be a little bit bespoke when you're thinking about different types of applications um and like really like at least for us like our North Star is just like we want to price it so that the user feels like they're getting a fair deal like with the value we're providing and that might be different for different types of applications yeah that's an astute point about the failure modes of pricing models and actually offering different pricing models makes that problem worse because then like the amount you make is the minimum of all those you end up with like a it's like not a great outcome actually you want yeah you have to kind of accept the failure mode of your pricing well it's it's like something of like an iterated game right like like yes they're like you you could find like someone could act adversarially here but like you could just like presumably you're actually providing value to them they have some value you know that they're willing to pay for well yeah like you can at least assume people are economically rational or they're gonna pick the best deal for their application so if you have like two pricing structures people always pick the one for their specific application that's more favorable for that app sure but but like you know if like the company ultimately has the decision like the power to make a decision there right yeah yeah like like I mean like like us take the one Roll-Ups no I'm saying that the Robeson service company has the decision of how to deal with oh right yeah yeah you don't have to offer multiple options yeah yeah yeah yeah um I mean it's just like typical Enterprise sales right also like uh uh it's a question from from you guys like how we see uh things differently on the experiment side but how do you feel like uh the company is running the application like putting putting it uh the charges on to the user like how does uh how do you see that happens it's just like uh what are your thoughts on that oh that's a good question um I think in certain cases it makes sense like like you mean basically charging users transaction fees like it makes sense in general um we as a company were very skeptical on business models that are entirely dependent on that on user paid transaction fees just because there's like pretty massive incentive incentive misalignment there right like you know we there are some folks like working in the space who are like you know they're taking some percentage of fees that users are making and like it makes sense now and you you'll see a lot of like VC tweets talk about this with like optimism or arbitrum right I don't know if anyone in the audience has seen these tweets like you know once 4844 gets merged in like the margins that optimism and arbitrary are going to make are like going to go to the moon like what's actually going to happen fees are going to come down margins aren't going to go up right margins are probably going to stay roughly the same well it depends on like how that's yeah plus is distributed right when costs go down for a business yes you can also make more money or it can be completely passed on to the customer that's that's yeah that's that's true but like historically what we've seen is that these get competed down to like to very little um I think that's because optimism and arbitrine though offer commodity block space like the the user or the DAP developer doesn't care about whether they're deploying to one of those or the other and therefore like they compete directly right yeah that's that's correct um it depends on how you view like the the robes as a service space like do you view like on some level there's there's differentiation I think like like we we know that like when users talk to one of us they're talking to like most of us uh and so like on some level there's commoditization yeah I agree with that yeah the biggest benefits which is economics are are common to all chains yeah all right um um let's move on to developer pain points what are some of the you know Common pain points that you know teams that you work with bring up and kind of how do you plan on solving them and then also I want to leave some time for questions from our audience after this question it's got to be a liquidity fragmentation I think and interoperability and that's a tough one to like answer because for a lot of apps the right answer is that a roll up at this point is not quite right for it if it really needs to do heavy composition especially Atomic composition and even through shared sequencers espresso had this awesome Workshop yesterday on shared sequencers and they gave this toy example about a bank and the bank contract is on Two Chains it shares a sequencer so that sequencer produces full blocks for each of the two chains and what you want to do is you want to put usdc on one side and get die out of the other and the tricky part is making sure that it doesn't fail and it doesn't like you don't put usdc on one side and the die doesn't come out on the other side or vice versa die comes out and usdc does not go in and that basically relies on the Builder providing a block which is uh which is correct which because the Builder can execute all the transactions they know if the block they submitted is going to revert or not so you want to make sure that Builder is acting honestly so they said oh you can just give have the Builder put up some stake you can slash the Builder and that to me that was like a fun example but but after the at first I was like it seems reasonable but then for like an hour after the talk I was like there's so many failure cases for that actually because I mean if the bank could lose out and there's like collusion issues the stake size it was like the devils and the details there and also how do you prove the transaction failure or do you like use the L1 for this maybe this is a tangent but um but my point is that Atomic composibility is really hard to achieve between Roll-Ups so as a result you basically have to kind of focus on apps that don't rely on that so much across change okay I I will continue uh using the real cases like we we handle uh recently I think the major like like issues right now is still about technical uh issues uh we we have some uh back to the like sort of the panel right they ask us to have this kind of latency you can have a try it's like you must provide this less than 100 milliseconds and basically you play a fully engine give every move on chain but at the same time it's seamless and no latency that kind of the ridiculous uh requirement like asked by our partner so the deal is like can you achieve it if you cannot achieve it then then uh forget about it so we have to spend a lot of time a few months to really like optimize and re-implement the execution layer ourselves to make it like even compatible but to achieve these last 100 millisecond latency but this is something like a extreme case right one one case like this another case that I we also got some crypto native partners that you want like um super decentralized like sort of Joe lab system um the the they don't care about latency but they want it as decentralized possible and as secure as possible the better you have a lot of sequencers but at the same time you must have a proof system otherwise we won't use it because this one is used for public good or something that so it's really from one extreme with another extreme like is this includes a lot of these technical development to to tag a lot of technical challenges which the existing general purpose out to having like so solved yet but as sort of like uh um I mean I mean a provider we have to solve this technical question probably ahead of the these the big players in L2 space that's why I highlighted a lot of technical challenges here but do you think it's worth it I believe so because we all dream like uh probably for the next 10 years it's a word for web 3 right so we want to handle like billions of users to use uh blockchain for in in the normal application so in that case latency we need to solve it decentralization security we also need to solve it these are all the great properties for blockchain but at the same time you can see right uh I feel like we're still in the early stage it's not like we are talking about Russ and we feel like we already have uh four great companies but at the same time there are a lot of new problems we need to solve um and I believe it's too early and and we we really together fix like all these solutions for that yeah so um also uh VEC uh developer experience like building in web3 itself as a developer experience problem and uh that is also something we would want to optimize for so like uh if you're building a game you you write some component in solidity then you write a front end in some other language and then you connect them and like they so they just like it's just hard the integration is just hard and also like like you mentioned like the latency issue so uh we kind of categorize a two different things uh the developer experience and the user experience and uh it kind of like optimizing for both so you get like both both like the uh web 2 experience for for building with like I've been saying that over and over so uh that's that's the kind of thing that we are solving for uh on the experience side of things it's not just the developer experience but although the user experience that needs to go along with uh while building applications yeah I want to lose some time for questions so I won't I won't rehash what they said all right do we have any questions from the audience no um in the case where you have applications that are seen as killer applications do you expect that you have to compete between the two the four of you and on offer sort of concessions to them to get them to build on you instead of some of the other people that are there I think there are cases when a roll-up framework is uniquely suited to serve a particular application and to me things like virtual machine compatibility actually result they actually represent a reduction in fixed cost or one-time cost for a user to use your best for example like if you have svm compatibility technically a chain or a gap coming from Salon it doesn't have to use you right they could use an evm chain rebuild all their smart contracts and evm and that's what's funny when I remember when stockx or stockware was um built writing the contracts for dydx and Cairo people were dunking on that a lot but actually they were interpreting to me Stockport was doing exactly the right thing all they were doing was it could have been built by two idx or it could be built by stockware but that's just some cost that's being incurred by someone they're just saying we're not going to pass it on to you we're going to we're gonna encourage ourselves so I thought that made sense uh but but yeah there are cases where uh where yeah definitely we'll be talking with uh with a few different like we they'll even just tell us hey we're talking to these other folks these are the models that they've given us like could you just like highlight the differences rather than giving the whole rehash yeah I I think it's I mean you mentioned concessions I think people are less focused on concessions when it comes to like pricing and business model um than they are on like which service makes the most sense for them like this is for a lot of applications like the biggest infrastructural architectural decision they will like ever make at least for like that version of the product um and so like typically we find it's like it's more on the fundamentals than on like price or anything else um should I just shout out thanks uh on some level obviously you're all kind of competing with each other but I wanted to ask who you view as your biggest competitors maybe in kind of an unexpected way you know is it is it no no no pick someone to cage fight amongst amongst the four of you no um is it like uh apps looking app developers looking at like the cosmos ecosystem um to have more modularity and control over their Stacks is it other l1s like what what are the Alternatives that your customers are looking at outside of launching their own Roll-Ups it depends on the stage of development that the application is in it depends on the vertical and things like that but overwhelmingly the competitor is actually the status quo just whatever they're already doing because because it just is cost for them but they have to put in a lot of effort to switch to another chain they're not necessarily even going to have their own chain I find that usually it's not between like Cosmos L1 versus rollup I find that that's not as common as I would have expected and I actually thought that we'd be competing with Solana more initially uh just because they're also a high throughput chain and then I guess the line is kind of fell out of favor became totally irrelevant oh they are no they're then I think it's a lot I'm super like long like totally and those guys I think they're really smart uh yeah but that's that's just uh reality like who who we typically find we're talking to yeah I think uh to his point like the stage of uh which the project is at it's it's the most important thing so some some may want to spin off of our existing L1 protocol to uh to a roll up as a service or some uh some projects which are just starting out might just pick a chain to just build offer for a framework to build off of so I think that's that's very important all right I think we're out of time now but let's give a big round of applause to our panelists and a round of applause to our moderator please [Applause] like unrest because like I I feel like like you know we'll eventually work together yeah thanks all right all right testing testing Can You Hear Me all right and we're back all right please settle in take your seats thank you for sticking around we've got about one more hour and one last segment of speakers here coming up please settle in if you're still in the room take the conversations outside in the peanut gallery thank you all right we've got one more segment here of talks before happy hour and it's going to be great so settle in thank you it's going to be on interoperability in the modular world and first up we're going to be hearing from Jim Chang on the role of relayers in the modular ecosystem so Jim come on up [Applause] okay awesome well thanks for uh the Celestia team and uh the maven team and all the other sponsors for uh for having me up here um really excited to be talking about something that I don't think many people uh actually talk about uh in the interoperability space and that's relayers and how relayers are incredibly important to kind of the Cross chain ecosystem but also incredibly important as we scale into a modular world and there's more and more kind of modular layers that need more coordination uh and before I start uh just a little bit about me uh I'm Jim I'm the co-founder of catalyst which is a cross chain liquidity network if you guys are here for the rest panel earlier uh they're talking a lot about liquidity and interoperability and how that's really important to kind of this role as an ecosystem world and so we're trying to solve that I'm also a defined Dell Builder and so I've been building the space for coming up on six years now most recently I was a product manager at Ave and I've contributed to a few dials like pleaser and get coin as well so kind of uh have loved and known this space for a long time and I'm also a cross chain Enthusiast which I don't really know that means but I read a lot of blog posts a little bit about Catalyst although we're not going to talk too much about it today uh we call it permissionless cross-chain liquidity for the modular future uh basically what that means is we have Sovereign liquidity that lives on different Roll-Ups and they're able to actually coordinate uh permissionless cross chain transfers one another and we can connect all ecosystems so not just evm not just Celestia not just move we can collect all uh connect all of it quite trivially and we do that through integrals and other kind of complicated math but not going to kind of go over the details of that today instead we're going to talk about relayers and and why they're important and so a little bit of context uh I have liked relayers for a few years now I think it's probably the unsung hero of really you know cross chain and interoperability broadly um relayers uh are called a lot of different names you can call them agents solvers Underwriters what have you uh but basically it's just an entity that moves packets and coordinates any sort of off-chain data in between two different blockchains and so pretty important in the context of moving between blockchains as you can tell uh but why is uh why are relayers important and why are they going to be even more important um it's because of the modular blockchain stack right I think all of you guys are familiar with module blockchains hence why you're here uh you know splitting up all these uh different kind of tasks that a monolithic blockchain does into three separate tests but I think now there is a bit of an evolution on the thinking of it and it's less about you know there's three different tasks but it becomes four different tasks right you have transaction ordering uh using shared sequencers and so now there's four parts of the modular blockchain stack but uh oh what do we have here uh if you guys were here earlier in the week and you guys attended polygon today you would have seen that polygon kind of unveiled their stack and their modular blockchain stack has a few other names they have things like staking and proving and interoperability and so if you look at holistically and you see kind of the modularity of blockchains and more specialization more specialization it starts to look a little bit more like this and so we started off with three things that modular blockchains could do now became four things now become six things or seven things right you have proving you might have liquidity slash staking slash restaking you might have interoperability and that gets a little complicated right and I think what becomes more complicated about it is as there's more and more modularization and more specialization of these blockchains there's more complexity in the verification right if you're trying to send a transaction from one chain or another one roll up to another uh you actually have to verify all the different pieces to ensure that this is a valid transaction right to verify the state verification so it used to be okay you know just moving from chain a to chain B but when you go to a monolithic blockchain you have to make sure this da proof with a shared sequence series that makes sure there is a transaction ordering proof as well and it gets more complicated now you need execution proof you need impediment proof you need interoperability all these things need verification and how do you do that I think the simplest way to do it is just to have native verification I.E you have you know like clients that are poignant to one another and so if I would had to send one transaction in this new modular World I'd probably have to have six forms of verification and that gets very complicated very quickly and how do we you know pass all those like client header updates uh to all those different layers how do we actually coordinate the communication between these you know execution layers of one another it's with relayers and so you're starting to see okay wait relayers are super important they're going to become more important and they're kind of everywhere uh and so is it all relayers when you look at the modular blockchain stack not quite but yes and I would say it always has been and so at catalysts when we think about Building cross-chain Solutions we think it's really important to build a really good relayer system in fact we've had the privilege of working with every interoperability protocol assessing the relayer systems and seeing that it's not quite good enough and so we kind of took it upon ourselves to think about okay what is a really good relayer system and how do we bake in the incentives for a good relayer system into this cross-chain Sovereign liquidity Network that we're building at catalyst so a little bit of a public good A little bit of a side quest so to speak but something that you know we love and feel very nerd sniped by and so what are good requirements for a relayer system uh one calls always arrive it's good when you have things queued up in the outbox and you actually receive those messages uh two pricing is transparent and fair uh you actually know where you're gonna be charged and you know what the margins are going to be charged right now I think a lot of relayers are public goods in the sense that they're lost leaders you have foundations that run them at a loss but I think at scale you probably want to bake in some economics to it and then lastly relaying sufficiently decentralized and it's not decentralization for decentralization's sake there's actually a really important reason why we need that and I can talk about that a little bit later in the presentation and so the first thing you know double clicking um you know we think a lot about what are the big questions behind designing a really important relaying system and then when you break down you know the requirement of having calls always arriving um you realize that there's kind of two pieces to it calls need to arrive but calls need to arrive quickly right they need to arrive within a reasonable time span or else you add latency and therefore what is even the point of of having this happen uh and so at Catalyst you know we were kind of under the assumption that things were just relayed right they just happen uh and you know if you're in testnet that might be Excuse Me Maybe the case uh but if you're in production if you're on mainnet uh not typically a case right and so a little bit frustrating there uh and so we realized that calls don't always arrive within a reasonable time span so how do we incentivize this right are we building a system in which relayers are penalized for not timely having timely delivery messages or are we building a system in which it's more of a kind of a willingness to pay users have a willingness to pay some sort of bid ass system in order for relayers to be relayed we're kind of still designing the system and the second piece is what if calls don't arrive in a timely manner right and so calls should be able to be canceled or timed out but what happens when a message gets stuck do we need to implement some sort of recovery system do we Implement some sort of bidding system how do you design a mechanism in which people understand or users rather understand or applications understand when relayers are taking too long and you just need to pull the whole plug and try it again and so that's something that's really kind of top of mind for us when we think about designing a good relayer system at catalyst the second piece is pricing being transparent and fair like I said before relaying is free right now well not free but free for the user it's being paid by someone and it's usually the core teams of these interoperability protocols or the foundations or subsidized by the validators or what have you but I think in the end State uh it's really important to to have some sort of economic system for this and so when you're implementing economic system you want it to be fair you want it to be transparent and and people want to know how these routes are actually priced and so there's a couple ways you can actually think about pricing uh a a route for a relayer system you can have it be an algorithm right you go okay here's all these different factors of you know this is what the gas limit is is what the gas price is this is what the consumption is this is what the congestion of the network is you spend out a number right and people just take it that's totally fine another system is having a some sort of bid ask kind of order book so to speak and so users have Williams to pay relayers have willingness to accept certain services within a certain threshold and so it starts looking a little bit more like an order book which has of course Mev implications that I'll talk about in a second um or you can have user determined bounties right and so uh I think this one's pretty popular within the IBC ecosystem you have a standard called ics29 that has you know this kind of user escrow Bounty where you're saying hey the the user knows how much they want to pay for a cross chain packet and they'll put it up and then the relay will take it right uh and kind of the the criticism of that is like how do how do users know how do users know they're going to pay one dollar two dollar uh it's kind of hard to say and you're kind of leaving a lot of money on the table in that regard uh the second piece is prepaid versus pay at the end right are you going to kind of load up a balance and have someone withdraw from it are you going to actually um kind of pay them at the end once they do this delivery if so there's all sorts of implications right one is what token do you pay it in do you pay it in the origin chain depending a destination chain do you paint usdc what is the price risk of these relayers um and if there is kind of a price risk how is that fairly priced right what is kind of the Oracle in order to have some sort of mid-market price in order to do the swap let's say if it's from usdc to ethers from E thematic or or what have you and so you're starting to see that like okay so a very very simple uh kind of idea becomes very complicated very quickly you're like oh yeah like we should price relayers and now you go down this rabbit hole and you say okay actually it's pretty difficult to do so right uh and then the last piece is how is gas handled right how is gas estimated page running destination and as I'm going to talk about in two slides um it's actually a pretty pretty big trust assumption that you have no matter what kind of system that you're architecting and so what are the assumptions on on that last piece right uh so the most important question when you think about gas estimation is who is doing the gas estimation who's calculating that and so calculating gas on An Origin chain is is pretty straightforward right it's what any kind of client does or interface does um but doing it uh for the destination chain gets a little tricky right and so you can obviously have some sort of trusted solution you can ping an RPC or you can have some sort of somewhat trusted solution you can use some sort of gas Oracle but the question though is who's making a gas or a call are they taking the margin on the quote if so how much is it solely fine but I would say from our experience of using all these different Primitives is that it's pretty opaque someone's making money user doesn't know and that is not really ideal for us as we're designing our relayer system and there's also trust assumptions on the delivery right let's say everything's perfect you have this perfect price that everyone feels very comfortable with you're leaving no kind of leakage in this economic system um you're still trusting someone right and so many protocols they Pride themselves they're like yes we have an one of n relaying assumption uh but the reality is uh it's not one event it's it's typically more of a one-to-one and why do I say that uh it's because users have to trust the relay they're paying at any given time and so if you are trust if you find a relayer you want to pay them they're going to send the message you give them the money how do you know they send the message right oh as I think as a kind of caveat you could probably pay a lot of different relayers but now you're you know instead of charging one dollar to deliver one message you are holding up five dollars for one of those five relayers to deliver a message and so I think the takeaway here is lots of trust assumptions on this real building the message uh and there needs to be some sort of mitigation for that and so I'm posing a lot of questions with with no answers but this is probably the closest answer uh that we have so far and we call it conditional payments and so it's basically a one-time payment on the source chain uh with some transparent pricing in mind uh and we try to make it as trust minimized as possible and so the flow for this is is is you know as so so there's a price quote that's generated for the relayer right let's say we're using some sort of top-down systemic pricing algorithm uh we actually use Catalyst as this kind of price Oracle and so we're able to calculate how much gas is on a destination chain and what is the actual Fair rate between the origin and destination chain gas tokens for the swap the user's payment is an escrowed on the source chain with a Time Decay and so there's incentive for these wheelers to go very quickly in order to actually capture the full amount of this escrow and then a relay it must return with some information from the destination chain in order for the escrow be released and so we're talking about round trips here not just one One Direction but One Direction and then sending an acknowledgment back that something actually happened with the necessary Mercurial proof in order to prove so uh Enzo one of endodyne because this bounty is open for anyone to claim and so we think that this is a pretty good start on what we think is a much more trust minimized and much more kind of robust and transparent relaying system and then over time we do want to Overlay Mev to this and so like I said one way you could do pricing is have some sort of um you know kind of badass system or order book system which begs the question whereas the Mev kind of coming to that and so I think the Holy Grail that people like to talk about when they talk about relayers and when I say people I mean me and for other people in a telegram group because no one's really talking about this uh is is OFA which is order flow auctions right as folks may be familiar with with uh with mempools and and flashbots and uh and uh private Med pools and so OFA and so you think about this there's an OFA for An Origin chain and they're actually queued up in some sort of auction and then you have these relayers actually bidding for this order flow right and why would they do that because then they have the exclusive right to be the relayer for that order flow and then extract what we call Rev which is just relay extractable value and they're able to bundle this uh order flow and have some sort of sandwiching as well from socket kind of talks about in the screenshot here in the right and they can extract value from it right and there's this kind of additional element that we call censorship Mev which is okay what is the willingness to pay of a user if you know there is it their transaction um that spans two different domains has a lot of Mev to be extracted if all the relayers coordinate and say hey we're actually not going to pass this message right and so a good example of that is that you know you have a position that's about to be liquidated on Ave you have some collateral it lives on a different chain the relayer recognizes that and says hey you're only paying me one dollar for this hundred thousand dollar liquidation position I think you need to be charging me a little bit more or else we're not going to be delivering that message and so really really big design space as we look at censorship Mev and relay extractable value and again me and four other people on telegram just nerding out about it um so the short answer is yes Mev is going to be really important for incentivizing relayers and having sustainable economics through relayers but we're not quite there yet in terms of having you know sufficient transaction volume or messaging volume in order to justify it and we think that there needs to be a really kind of robust way of doing what we call self-relaying which is if there's no Mev being generated by this specific message you gotta have to reel your own message right because in this Paradigm no one really wants to deliver your packet if you're not generating sort of economic value on their behalf and so before I get to the last piece I just want to say you know we're thinking a lot about exactly what a super robust relayer system looks like we care really about the time we care a lot about the timely delivery of these messages we care a lot about the transparent pricing and the incentivization and overall the future proofing by including Mev into this but lastly and I almost think more most importantly we want to think about the sufficient decentralization of these things and so again some interop protocols have this kind of one-to-one relaying message delivery it could be overtly like layer zero right where even before you deliver a message you have the specified relayer or it could be more tacitly where you have this kind of 101 payment assumption you already pay the relay or you hope they do something but you don't know for certain like what I talked about before or you have this kind of one of n system that's slightly more robust but the end is really small because realistically it's just these core teams are running relayers and so the N is more two three four or what have you and not quite as robust as what one of n sounds like when people say one event for a mechanism design and in self-realing can always be a fallback I think it needs to be much much more robust I think this is a very similar narrative than to what the roll-up folks call forced inclusion for Roll-Ups right there's censorship from the sequencer you want to kind of submit into the settlement layer um I think this is a pretty good analogy I think self-relaying needs to be much much more robust and have a lot more research behind it and we a catalyst think a lot about that think a lot about all the different pieces of of a relayer system and why is it important to us because ultimately we think that healthy relaying will equal a healthy modular world it's really hard to have modularity really hard to have state verification between d a layer standard attacks and ordering later execution layer and eventually all the other you know fun layers that kind of come out in the future like a staking layer proving layer what have you they need relayers right and so not necessarily the core focus of catalyst our core focus is liquidity which is something again that all the RAS participants in the last panel said was top of mind for them as a major pain point but relay relaying and decreasing the latency and decreasing the truss assumptions between moving liquidity between Roll-Ups is super important for us too therefore we think a lot about relaying and we want to make it a mission for us in terms of research and a public good perspective to push forward to thinking on relaying research so thank you guys so much for your time thank you feel free to follow Catalyst uh for more updates on that thanks thank you so much Jim that was awesome and up next we'll be hearing from John of hyperlane on more on interoperability in the modular world with a different take different approach thank you Jill all right let's get to it let's see how do we go now you can see my face and you see it live and you can see it on the picture which um we need to do something to get the slides up there we go we've had a lot of slide skipping all right let's get to it so today we're going to talk about modular interoperability or sorry modular blockchains and interoperability specifically permissionless interoperability so if you think about why you guys are all here today we are here at the modular Summit because for whatever reason we'll get into that very specific reason we think that the modular construction is an ideal solution to a lot of the issues that we face with blockchains so over the next 20 minutes or so we're going to get into that we're going to cover the different moving Parts what needs to happen what is feasible and what is not and so at hyperlane we like to talk about this concept of The Interchange Highway what's that it's kind of like a big word it's something that we like to think of as a safe somewhat fast path to connect between the ever increasing and ever expanding Universe of chains and the modular universe is one where we're going to have an increasing number of smaller chains smaller than the monoliths that we've become accustomed to over the last few years specifically when we talk about how permissionless interoperability and modular security help us create this concept of The Interchange Highway so with blockchains we have these really cool internet computers right they let us do all sorts of things from starting with Bitcoin that gave us Sovereign and permissionless money moving on to ethereum that gave us permissionless access to computation right I think it's one of the coolest things in the world that pretty much anyone here can access this permissionless substrate and run any computations they want on it there's some magic in that but with these internet computers the way that they do this magic it's primarily by introducing the concept of scarcity into the digital domain we've never really had scarcity in the digital domain before blockchains became as common as they have and this visualization here we have on the screen is something I really like it treats uh each block as a bus and I think this is a really effective visualization because if you think of a of a block Well there's almost so much space in it and if a bus has a certain amount of seats so does a block has its size well so every little person you're trying to get on the bus it's an incoming transaction and they take up a seat but unlike a bus that has a fixed number of seats and once it's full it's full our buses introduce a mechanism of surge pricing and so what does it mean for the bus to get filled up it means that the thing that by and large all of us are here to bring about right like to increase the amount of demand for these internet computers well if we end up looking like the bus on the right side right we got a lot of passengers to get on we're going to introduce the surge pricing and so this is where when that magical uh scarcity introduces a big big problem and all of us probably sometime in the last years have felt the anguish that comes from the surge pricing right when you're trying to do a transaction and suddenly you're met with like a seventy dollar uh fee on ethereum just to do that 21 000 gas of a basic transfer on each right the gas just gets too damn High and modular blockchains seem like an ideal solution for this again if we're here it's probably because we think there's some some efficacy in this premise of ins you know we need more buses we need more seats and instead of just creating creating one massive bus that would be some magic monolithic chain we're gonna have a whole slew of smaller buses and smaller bus lines think of each one of these as being a new roll-up a new chain and that's where something like hyperlane comes in right so here the modular summit we're talking about all the different ways that it's becoming easier and easier and easier to launch your own chain to launch your own rollup in fact with some of the participants who are here today folks like Caldera and conduit and eclipse and ALT layer they're making it as easy to create your own chain you know such that you could really get something going within 10 15 minutes but if you've done that in 10-15 minutes how do you connect to everybody else you need something that you can support yourself and this again is where hyperlane come in I like to think of hyperlane as something that through its introduction of permissionless interoperability acts as the final layer the layer that completes the modular blockchain stack right if we broke up execution settlement consensus and data availability for us to actually have practical benefits from that our modular chains need to be able to talk to each other if to enable that talking to each other you need to go and convince someone on a permissioned interoperability team to add your chain right so you spun up your new chain in 10 minutes but then you need to spend the next 10 weeks convincing someone to add you that's doesn't really cut it and that's to the extent that folks have been playing around in the cosmos ecosystem the magic of IBC is its permissionless nature it's the fact that you can spin up a tenderman chain you can spin up a you know chain on the cosmos ecosystem and through IBC you don't have to ask anybody for permission but it's become harder and harder you can't really do that outside of the confines of IBC and so we need to find a way to extend those confines and there's a number of people uh working on this problem so what is this problem really when it comes to modular blockchains it's this problem of permissioned interoperability it's the fact that you need an interoperability provider to add you to add your chain so that your chain can communicate with other chains on their Network I think and certainly other people might disagree but the reason for this is that by and large most interoperability protocols they have coupled the product that they're providing right the ability to communicate between chains or the messaging interface they've tightly coupled it with the security model they've made those two effectively into just one thing but it doesn't have to be that way right it could certainly be decoupled you can have that product the way to communicate between chains that interface on one hand and you can have security be provisioned on the other hand and that's what we do with hyperlane we really believe that modular chains need modular security so we're going to get more into the specifics of that but at a high level I imagine most of you have had this experience of going to your bank when you try to get a nominal sum say a few hundred dollars out the ATM will let you do that with just your PIN number don't really ask any questions beyond that try to do something a little bit more intense try to withdraw forty thousand dollars fifty thousand dollars try to make a large wire or if you dare try and close your account at the bank and get all the money out of it in that same day they're going to run you through a much more serious line of interrogation they're going to want to see your ID they're going to want to know who else is on the account with you they're going to ask you do you recognize the last 10 transactions um see or I you know see your social security number and if the U.S if you're in the U.S so what does the bank really do it the bank is looking at the context of what you're trying to do and they're running you through a different security protocol and that seems to make sense you know most people don't really object too heavily when the bank is trying to run them through a much more stringent process when their action is going to have a much more significant impact on the account don't really do that in crypto crypto you try to move a hundred dollars or you try to move a hundred million dollars we run you through the same the same exact system might want to think about what that why that is it's something that often doesn't really get questioned for us we didn't think that necessarily needs to be that way and so the introduction of module security really really lets us do that and so we could talk briefly about like different forms of interoperability to understand this concept a little bit better the best way to verify state if you can is to leverage what some people call native verification in this case you're just leveraging the existing consensus between the connected chains I'd say IBC is probably the gold standard in inoperability until today and IVC gives you native verification when you connect two chains through IBC you're really just trusting the two chains that you're being connected which generally is a fine assumption right like if you're connecting between you know say ethereum in an arbitrum let's say or say ethereum and Avalanche if you're using both of those chains you're probably comfortable with the security models on both so the fact that you don't need to introduce anything else is terrific but the issue with Native verification it is that you need to rec uh it's a very costly method because you're basically replicating the consensus of one chain on another and doing it in a place where that was not constructed for that as is the case in the UVM world is incredibly costly the other mode is external verification not too complex right so we're still trusting our a and RB our ethereum and our Avalanche but now we need to introduce someone in the middle and hence the name external verification so this kind of looks and feels like an oracle if you're familiar with the Oracle problem I imagine most of the people here are and that's because right like external verification for interoperability really it's just a narrow scope of the Oracle problem instead of oracleizing any type of information in the world you're just oracleizing state from another chain that makes it a slightly easier problem to solve but it's still at the end of the day it introduces a third element of trust and this is where a lot of things can um can certainly go wrong so now let's move on to modular blockchains right again we're here the modular Summit because we believe in this concept and I personally believe that with modular blockchains we're not going to have a singular hub we're going to have a number of hubs from which we see an increasing number of smaller blockchain smaller computers again think of these as small smaller buses smaller bus lines and so ethereum becomes a hub Celestia becomes a data availability hub Cosmos is already a hub think of these little guys here in optimism and bass and arbitrary they can become little hubs too we're going to have these hubs everywhere and more and more chains that come out of them which would be there we go they need a way to connect with each other and every time you create another another new little computer and a little bus how does it communicate with everything else so you do need permissionless and are probably you need a way that this increasing Universe of chains can connect to each other and can do that without having to ask anyone for permission without having to ask anyone for help we're in this space because we value our sovereignty we value our freedoms and we want to be able to act without being gatekeeped and so a world of permissioned interoperability where we're just waiting for people to add our chains to get the support it doesn't do much for us it doesn't do much for anybody and this is what we built hyperlane for so how does it work this little schema here shows you the life cycle of hyperlane message as it goes from a chain a to a chain B let's say again Ethan Avalanche Ethan you know pick your poison there are three critical parts to hyperlane there's our mailbox simple contract that just sends and receives information transfers bytes and codes them helps verify them then we have our security modules think of it as like some logic to run to run a test on to basically say how do I how do I get comfortable with what's been relayed to me from a different place to that we could use system of validators we could use an optimistic system with some type of Watchtower could use ZK magic when it becomes available because who doesn't love DK magic it's the best I'm a big fan or we could even use some type of committee based approach and lastly we have a relayer relayers open roll you just heard Jim talk about all the difficulties in relayer systems there's a reason why they they are working on it because it's a hard problem and the relay on hyperlane is no different right a lot of those open questions are things that every system with relayers need this needs to think about so how does it really work you have a contract or a user starting on the source chain they send the message to the mailbox they tell it they have the message body the bytes that they're trying to transfer around in those bytes you could reason about oh I want to move this asset I want to deposit this thing in that liquidity pool I want to borrow from this lending pool the mailbox takes in the information about what needs to happen where does it need to go and then come in one of our security settings so in hyperlane we talked earlier about this concept of modular security so instead of being forced to use a specific option you're always able to choose from a set of security modules don't like them you can build your own not everyone wants to do this it's not a easier fun thing to do but it does open it open the door to a security Marketplace in fact where we are today is that external teams teams outside of the hyperlane core team are building different security modules talk a little bit about ZK magic in fact there's one team already leveraging their ZK proof mechanism to create a hyperlane security module and so once your chain oh sorry once you're message is ready to get to the destination the relayer comes in and the relayer always observes the mailbox really is a fairly simplistic operation think of it like just a basic bot that looks at the mailbox and sees what you're trying to do it sees that the message is there and it's waiting to be processed it sees that maybe you're kind and you want to pay them for this service so you've included a little tip in there for them maybe you didn't and maybe then the only reason that they would relay our messages because as Jim talked about earlier is you might have some Mev opportunities for them to take take advantage of as they take your message to the mailbox on the destination chain they ready it for processing and during the processing is when the logic is tested Against The Interchange security module so there you can do some really fun stuff we talked about the bank example where the bank treats me different when whether I try to withdraw 100 or if I'm trying to wire out 50 Grand you could configure your app in such a way that when a message is received you reason about the message a little bit and what's this user doing well they're just trying to send say 100 in a small swap great send it through the fastest um running through the fastest module that we have no need to have maximum security because it's a hundred dollars what's the Worst That Could Happen 100 could be lost someone's now trying to move a hundred million dollars let me ask you anyone ever see a nine figure transaction that wasn't actually an exploit rarely happens it's always an exploit so a transaction of that size we can now run it through a very slow path a very secure path Maybe the optimistic path which doesn't allow for the message to be processed for a very long period of time set by you as the integrating app and during that time anyone can observe that transaction and if it doesn't look kosher shoot it down you don't have to take it and once it's passed through this the ism The Interchange security module it's ready to go arrives at a destination and so what did we just see we just saw how we use hyperlink to communicate between chains in the interest of time I won't spend too much time on this slide here but the the key concept is that with hyperlink you can choose how you want to secure your messages because there is no insurance security module you're able to leverage Economic Security in the form of staking you're able to leverage that optimistic security that we just talked about and when you're just getting started when the stakes are low you could just have a multi-sync committee and you can imagine that multi-sig option it might actually beneficial even when the stakes are high maybe there are certain actions that you want specific set of people to have to approve maybe it's your team your company maybe it's the key portion of your community the folks who are emerged as the most influential players think of this as something that can be used like the emergency switch in makerdown right we all hopefully we all know that there's an option in maker to shut the system down never been used but it's there you might need to hit that switch one day and so how does hyperlink compare to kind of regular bridging generally speaking most bridging today is done through this form of like an Omnibus Bridge you have one contract and it takes all the assets from all the people and they all sit in this thing and it kind of looks like a nice honey pot and this is how we end up with more than two billion dollars in different Bridge exploits because the more people use it the more appealing it becomes because they're all there in the same place but if we're talking about modular chains like why do we need to have this Honeypot shared between everybody so why not use this concept of modular bridging why not leverage when in hyperlane we call the war proud concept that lets you to have individualized path for each asset and each path can have distinct security settings so you might want to have different settings coming into your chain whether it's usdc or maybe when you're bridging your own native asset you want to treat it slightly differently and that's something that you can do once you leverage modular bridging so what can you do with something like hyperlane so these are some of the obvious fun things that you can do you can have interchange swapping right so why do we do bridging for the most part because we want to have the assets go from one place to another and we want to do something with it at the edge but if the thing that we want to do is swapping we might not need to move it after all if the thing already exists on both sides why not just transfer the logic of that action and say hey John is on ethereum and Dave is on Avalanche and Dave's got 500 USD usdc and he's willing to use it to buy some of John's ethereum well great so John you get rid of your ethereum Dave you get rid of your usdc and we send that logic to something like hyperlink there's also the concept of interchange accounts which will be familiar for anyone who comes from the cosmos world hyperlane recreates that in a broader context some key differences there that we could get into if you want to talk later you could also bring interchain oracles so we just released this just the other day with hyperlane now you can bring chain link feeds to your chain permissionlessly so this is a problem that a lot of modular chains a lot of Roll-Ups face because they need access to chain link data or other trusted oracles and so you can do that another use case I like talking about but I'm running out of time so I'll be kind is The Interchange margin now what does the end game look for something like hyperlane we could think about internet inner roll-up networking where we have created all these roll ups well they need to talk to each other more easily and like what network effects can you create from that then relaying services that security module Marketplace that I mentioned and ultimately this concept of interchange intents but that was all the time we had so if you want to learn more you can go on the docs docs.hyperlanexyz you can join our Discord at uh just Discord slash hyperlane follow us on Twitter or you can just find me here reach out on telegram or you know generally pretty friendly so thank you all for having me [Applause] great thank you John and uh coming up is the last panel of the day which you can probably guess is going to be on the topic of bridging which as we heard in the Roll-Ups as a service panel is one of the most important issues facing uh Roll-Ups and the modular ecosystem so with that I'd like to welcome mads from maven 11. come on down and I'll let you introduce the next panel thank you hello perfect thank you um thank you for making to the last panel of today I'm glad to see so many friendly faces um we have three very very or four very smart people on this panel uh brush my slight change uh so we have Bo from polymer we have fig from squid and then we have Richard from oblabs and then I think we had one more um we have Jim from catalyst a quick change so hey Georgios [Applause] so I think I would like to start with a small intro if you can do what you're working on as well yeah I can start hey guys my name is Bo I'm a co-founder at polymer we're working on extending the IBC protocol to all chains I'm fig and co-founder of squared and we're doing cross chain swaps and transactions across the cosmos and evm uh soon to be many more I'm Richard I'm a co-founder of orbelabs and we're building a chain abstraction stack I'm Jim uh co-founder of catalyst we're building Sovereign liquidity for the modular future thank you very much I think we often hear a lot of different words when we talk about bridging so I think we hear a transport layer question matching protocol question router token Bridge could you sort of explain maybe take one each and explain what that specific topic is a specific thing is I'd love to talk about the transport layer I feel like it's a it's something that's not really considered in in Iraq I feel a lot of people talk about the state later they talk about security they talk about how do you verify something that happened on one chain on another chain transport layer deals with encoding of the network topology of the entire network on chain all the paths between chains all the paths between all the smart contracts I want to talk to each other this information needs to be encoded on chain IBC does it very few or basically no other Internet Protocol does that I can talk about routing um and what squid that's what squid does essentially the routing is when you look at Cross chain just from the lens of connecting applications between chains so we take the view that there's liquidity all over crypto that just needs to be connected and we use General message passing and different infrastructure layers to use axler to um access that liquidity and so a user should be able to interact with any application on any chain in just a single click and it's a little bit like Google Maps but if you could teleport soon we always find you the way to what you want to do but it should happen as soon as possible yeah and I think with messaging Crossing messing at least the focus is more so passing data from one chain to another and Bo is right the reason why most matching protocols don't focus on the connections is because it's possible to have connection less interoperability where you don't need to know the direct paths beforehand and still pass message from chain to chain and so you'll find that for most messaging protocols establishing those connections at least beforehand if not the main focus and I guess I can take token Bridges if I think that that was something you said right yeah as an option um so token Bridges uh I think is a pretty archaic term um at least how I Define it where you know I think several years ago there was a need to move coins between the kind of home blockchain to a new one and so Bridges were kind of made as a primitive in order to enable that and so bridges for me are some function of um wrapping a token or minting a new token on these kind of new destination chains in order to get access to this token and it's backed one to one to kind of this Vault of the original tokens I restored on the home chain um and so literally a bridge right it's like you're just kind of shooting an asset from its home to another location thank you I think what you all sort of touched upon a bit was standardization to some extent um so we hope you have a lot of different token standards how do you bridge one token standard to the other and also in messaging so how do you view sort of standardization and how do you think we should sort of go towards that my long-term view on standardization is that at some point chain developers if you relate them to operating system developers are going to want to enshrine something into the blockchain kernel itself what that is we'll probably be open be an open standard be net neutral be decentralized I mean I I slightly disagree with Richard here on the need for encoding uh these connections on chain because I think that if you don't encode this information on chain you cannot prove anything about the network in fact you cannot prove that you have a smart contract that is bound to another smart contract across any number of chains so I think that when they these chain developers do come to make this decision IBC is is the best candidate here I think you're going to realize but we're not going to be going back and forth we tend to have very different views on interoperability um but I think going back to standardization um I'm very pessimistic as to whether it will have all the developers at getting underneath one standard simply because um it's in your best interest not to if you think about a world where there's uh even 10 chance that there's a different interrupt standard that sort of like makes interoperability slightly better for some other chain that didn't choose to enshrine a particular Bridge you're probably going to want the option for that sort of standard to come to your chain um and so what we're probably going to see instead is we're going to see some sort of wrapper protocol that comes and bundles up all these interop Solutions and gives applications on top of these chains the ability to move seamlessly from chain to chain um but yeah going back to the options between connection based or connectionless interoperability um I'm pretty sure it's still possible to make it very easy to pass messages without sort of like storing and encoding all that data on the change that you're going to partly because most of that data is also already encoded in the security layer um or the state layer which what would call them um so yeah that's the general thought there any more thoughts on sanitization or I think um what we're seeing right now is uh there are some projects that are just brute forcing it right um I think we can all agree in this panel that there is like pretty kind of uh there's a pretty locked High degree of heterogeneity uh in the ecosystem as it pertains to varying standards or varying protocols that not only span General message passing but also as we were looting before kind of the the token level as well and so there are projects like socket and live fire that are just saying hey like we'll just kind of put the man hours to to aggregate all these things and then abstract in some sort of off-chain way right um what I have been seeing is while that works and I'm sure will continue to work there has been kind of a deliberate effort to make their jobs a little bit easier and so you know there's this new ERC I'm blanking on the name that Arjun from connects kind of offered that is kind of championing that right and so it's good to see a lot of the um the liquidity networks like connects and you know our team at Catalyst included seeing that there needs to be some sort of standardization how we um wrap tokens when we bring into different chains and so we allow for not only more interoperability um but also kind of more um more shared agreement on the security assumptions of that wrapping if you sort of touched upon the bit in the end here sort of if I'm a Dev and I'm building application I need to choose a question missing protocol or a bridge or whatever it might be what kind of trusts and security assumptions should I be looking at and what they need to consider I can go um just in the standards piece as well um I think it depends where we are in The Innovation cycle because I agree that we there's going to be experimentation if um if something if there's a chance that something's going to work someone's going to go for it and build the build the product but potentially with bridging for example that's quite an old technology now and we can start to standardize it and people are like the Canucks guy um looking at ways of like abstracting it in a way so that you can standardize it for everyone but our job at squared is a little bit like the the aggregators where we can we integrate protocols across different virtual machines like different chains different gas models and we have to deal with all of that complexity um I don't know if we're anywhere close to getting standards in a lot of these places but um so there's there's just going to be a ton of work um on our end I think to to just deal with that for now um I don't yeah I think we could end up as like a temporary standard and then hopefully the ecosystem like Finds Its Own Way to like to become very similar across the board but for now we just we need to make things usable and um Evolution will play its course so will the most sort of with the best standard win or are there other reasons why I stand that might win I don't think so I mean solidity is the standard now so and I don't think many people agree that it's like the best and JavaScript maybe the standard it's um it's just gonna it's gonna play into a lot of different factors probably non-technical ones okay perfect um we heard a sort of modeler ecosystem day um and we're obviously Celestia as a DA layer how do you guys think that you know sharing a DA layer might help in bridging between Roll-Ups or chains or whatever else it might be go first sharing a DNA layer allows you to have trust minimize interoperability between those Roll-Ups if you share the same da layer let's say they're optimistic rollups you have the security of that da layer saying that I can make this data available to anyone to be able to generate a fraud proof that means that this Economic Security the da is shared among the rollups on top yeah and I think even going back to the general idea behind um Roll-Ups so Roll-Ups in many cases at least for L2 real life and ethereum um get the states for all things happening on ethereum sent up to them and so in the case where you share its da layer you can sort of like run like lines that sort of like look at the state coming from the da layer and even compute a full note that computes the state of all the blocks that are basically being broadcasted down to the DA layer and through that you can extract the message you need um so how that differs from like lines that sort of like rely on well separate the um layers is you run into the problem where it's possible for the da layer to fork and you may have sent over a state from some other chain showing a fork that ultimately was deemed invalid so I guess comparing shared DA's with like lines to not share deals with like clients what you have is just a slightly more robust system for passing messages from chain to chain perfect any more thoughts on that yeah I'm not going to talk about the security properties of it um I do think the benefit of sharing da and depending on how you you know use the underlying da layer you might also use it for canonical transaction ordering um you do allow for soft confirmations of the state verification of the messages being passed with an execution level and so with that um you know you have quicker finality right because you're essentially saying that because this data is made available because you know either there's a canonical ordering of the transactions using the transaction ordering layer of this da layer or even if you're not doing that you still have the data made available so that you can have fraud proofs or so that you can reconstruct some of these validity proofs um you are you're basically allowing for soft confirmations at the Cadence in which blocks are produced at the da level and so for sasia like several seconds right and so that is a sufficient user experience even if there's latency introduced at the execution level for True finality okay perfect maybe more of a question for for fake and and Jim here as well I think you've talked a little bit about the ux problems that we run into with bridging um and how do you foresee sort of how do we fix this can you know a help can intense help like what kind of future do you see in terms of ux um I mean the data availability is uh what the what everyone was just talking about is a good example of ux where we just found out that I didn't know this that op the optimism token is minted on on the optimism roll up and not on L1 and so there's a bridging problem like how do you how do you Bridge op without it being like fragmented now because they could have just minted it on ethereum and then suddenly you have all these canonical versions via the insurance Bridges but is going to be a mess and I think you're going to need these that's what we do we'd have these abstraction layers where you can just get whatever token you need for an application and even if the application is supporting the wrong token but technically you can get that token use the app in one click and intense uh this idea that you just have something that you want to do and you you send it off into the into the world and someone magically solves it and I think what we're doing is is sort of like a proto-intent system where we're the only solver but um and we have we have a mod uh a feature called boost which we're really excited about we just launched in the last week which allows you to essentially declare your intent on the source chain and then that will get finalized over 20 minutes or however long the bridge takes and anyone can fulfill that transaction on the destination chain immediately and it's fully generalizable because it's using general message passing it can be a swap you can buy an nft a cross chain you can do staking across chain and that's the user experience we want we want people to do anything in any application in one click as soon as possible um and yeah I feel like we've we've gotten there we've started just with something which works and then you can decentralize that more over time and um I think yeah really excited for intents and to integrate them into squid as well yeah I don't have too much to add as it pertains to intent I do agree that um you know routing systems uh like squid and um the the ability to have kind of a sophisticated entity provided liquidity for fast kind of um for fast liquidity slash confirmations of those transactions is really awesome right I think that that augments the ux considerably um I do think we still even in that Paradigm well two things I'll add one is that I think intents are really interesting but I don't think people talk about solvers enough so what if they get the Squig team and and doing kind of the boosted feature what they're doing there is a is really kind of starting the conversation of how do we have infrastructure that is not articulating intense but actually fulfilling or providing the liquidity or providing the tools for these entities to fulfill those intents uh so I think that I think we need more kind of um advancement and more investment focus and into that piece and I think where we come into the picture is kind of the second piece where even in that Paradigm in which we have really robust infrastructure for solvers to fulfill these intents um we still kind of face what I think is a cold start problem when you look at new chains and so I think it's pretty kind of consensus now that there's going to be lots of Roll-Ups right hundreds of thousands if not Millions within that kind of framework like if you have a brand new chain there's it's a really difficult problem it's a really difficult problem to try to inject liquidity into a brand new chain that's basically a Barren Wasteland and so how do you solve an intent for a new chain when there's no liquidity right and so that's that's a big research question that we think a lot about Catalyst and so we're we're hoping to slot into kind of this re focus into the solver problem space do you think most of the conversation around intents currently focus a lot on a very defined problem which is swapping one asset for another but there's a big question on if intents are going to eventually become let's say the end game of interability then we're going to need to find ways to generalize intents um to almost every possible transaction and I think that problem is extremely difficult um and maybe the main bottlenecks ever Us Ever Getting to this final statement probability partly because intense in many ways are invariant programming you basically have to well configure your system to check against maybe an infinite number of invariants to make sure you don't break things um and yeah that's not an easy problem um so I think we're going to see a lot of maybe proto-intendent systems that combine transactions and intents for quite a bit and then eventually perhaps after several years of thinking about the problem more we might get to a generalizable intent system anything on that bow yeah since we're talking about intense kind of on a tangent now but I would love to kind of talk a little bit about the work that a Noma is doing and how we can apply generally at the interoperability level so if you think about the research that they've done to say allow chains to combine or take the union or the intersection of the validator set between multiple chains bootstrap a temporary chain they call it Chimera chains and be able to create cross-chain Atomic transactions if you were able to standardize at the networking level so at the interoperability level let's say IBC everywhere hypothetically speaking and you and IBC were to have access to the consensus mechanism of all these different chains you could about you could apply the ideas of heterogeneous paxos and do essentially cross-chain Atomic IPC transactions across all IBC enable chains I think we'll see some of this but I think it'll take like probably quite some time to to get to this end state all right perfect some of you have talked about a world of hundreds you know thousands of different chains you think we end up in a world where there's like one aggregator aggregating all kinds of different question messaging protocols token Bridges whatever else it might be so how do you force this sort of Education working out well yeah definitely be squared they'll only be one and everyone will use the squid SDK to build their apps and there'll be some squid widgets which everyone uses in all applications everyone all the wallets will have us installed so I I think yeah I mean it's going to be like there'll be a few winners I think in in all cases like there might be if you interrupt winners there'll be a few aggregators it depends what you end up focusing on as well like we we try to not take the approach of you we're aggregating everything we're just doing swaps and then you can pair a swap with something so it's more like a payment Slayer maybe you have nft aggregators and as we find more actual use cases for crypto then they'll be more solutions that might be the winners but um yeah I mean I think aggregation theory that a lot of people talk about either on their mirror blog posts or you can look at like strategy is probably going to play out where you see kind of like a power law distribution where there's going to be a handful of short Channel suppliers for aggregation and they might say they're differentiated but the real I just have to use five of them to get access to everything and that's fine I mean I think I just have the economics plays out I do have a bit of crunch version to take though I do think the intent future or at least intent future envisioning is directly counter to this aggregation future partly because once you introduce solvers to the mix solvers are way more sophisticated than your end user and they will more than likely explore a wide variety of possible different places to get the app that they need to basically optimize or maximize their profits and so we could see a world where irrigation doesn't really take place but we have a fast a number of well liquidity networks and token bridges that people just generally go through from one to one just to make sure they get the best possible profits and these layers will be fighting based off of well who has the lowest slippage who has the cheapest gas fees who have like the fastest times and so on right do you have anything to that bow or yes once again I'm going to talk about the lower layers of the stack while everyone does talks about tumblers um I would say that I think at the lower layers of the stack we're going to see some consolidation probably in the 10 to 20 year time frame I know people don't really talk about 10 to 20 years in the crypto space but it's about how long it took for the world to kind of converge on a roughly this you know a consistent networking standard TCP in fact in the early 70s 80s there were a number of proprietary uh I would say like company owned protocols that were kind of seen as these de facto standards of the time maybe like a layer zero for example and over time they congregated because if you're you know apple and you've implemented Apple talk Microsoft might not want to implement Apple talk but Microsoft would be a little bit more open to implementing uh TCP per se so I think like the world which will converge to IBC in the long term time Horizon but in the short term we'll see a lot of aggregation at all layers all right perfect so maybe to move to thoughts towards um I think a big difference in some of you and other bridging providers as well is the fact some might be using a state or a middle chain to verify messages some some don't let's say or for example or and others as well what is your opinions on having a state middle chain do you think the sort of crypto Economic Security provides is good or bad some might you know say that or what are your opinions on that so I think the idea of a stake middle chain uh comes with some baddage I think it comes with a baggage of generally these protocols Implement some proprietary cost and Gateway protocol nothing wrong with that but some other protocol that you know the chain or the team in that owns the chain controls I think having middle hops in network topology makes a lot of sense I think if you want to scale Network topology and you have a lot of heterogeneous infrastructure you do need middle hops that being said I think long term you still want to converge to a to a single standard have middle hops in between obviously you want these to be secure as well ideally you want them to be trust minimized if you can prove the execution of an entire path for a particular packet then you can remove trust minimization trust on these middle hops in the long term time Horizon so I think that the stake matters a lot now but I think as technology advances I don't think it will matter as much for security um I think right now they're tick and time bombs um partly because if you think about it the whole idea that economics will always make it well not profitable for a malicious party to basically exploit those chains but as more and more chains connect to various chains as hubs take like axelr polymer which are trying to become hubs for IBC um it may just end up being the case there's way too much value built on it that like even the validators don't have enough economic incentives to keep the network as robust as possible and the only way that changes is a world where um the like clients they're using for passing messages from chain to chain are no longer necessarily just checking their validators to see if they provided the right signatures and more so running complete State transition proofs of all the transactions happening on those chains and the pretty much you get to that particular level they're no longer they don't no longer need to be validated in Chains they can just become Roll-Ups and do the exact same thing um so yeah I think we're probably going to see a world where all the value-based networks effectively um start to do the exact same thing World Upstate in order to become robust or very secure or they're just going to employ because the economic security no longer holds and I'm assuming you have some thoughts in this as well I think yeah sure yeah no I agree with you what you guys are saying for sure um a temporary solution that will upgrade into a more trustless solution when when the technology gets there but for now we needed we need a solution that we can connect um the like unusual chains into like other networks which are maybe more interoperable with each other like ABC and then you know IBC is developing and like over time it will get get more capable but for now we want to connect ethereum to the cosmos for example so that the cosmos can get some users and and build build up business relationships um I think the economic security honestly is that's a ticking Time Bomb but with the with the number of users at the moment it's more about um I think there are so many other things to be worried about with security and bridges it's you know we've The Nomad hack for example was just at the Smart contract layout in fact I think the Solana hack was was it Selena with the Wormhole hack was similar 300 million dollars and it wasn't anything to do with economic security but definitely centralization is going to be the cause of a lot of hacks and X are having 75 validators compared to say I want name names but in the five or six range in a lot of cases it's yeah it's completely different and yeah so much heart attack and then these chains become like polymer and Axle become take on a different role in a future where everything is trustless they can be routing hubs they can potentially have um a programming environment where you can build network uh you know Network Logic for specific applications like um gas networks but for example um they're a way that you can program into the into the networking layer and yeah that's it yeah one tiny rebuttal on the on the point of well the number of validators being the main thing that sort of like keeps things over alive I do think it's a combination of the holidays and air Stakes um and when you compare most of the chains that well do have these diverse sort of like values you still find that the states um the stakes aggregate into some sort of like few hands um just because well for the most part you'll probably find that it's probably the team that's running most of the validators on chains like yeah maxillar I do think the bigger point though that stands is um for us to get to a world where we sort of are comfortable with these hubs they're eventually going to have to change or switch to some variant of a light client system that depends almost entirely on state transition proofs as opposed to wealth of validators um that way we sort of like move the security away from the validators and it Stakes to well math and whether we're running the right computations are you in agreement Jim as well kind of um I do think um proof of stake or leveraging Economic Security is not as big of a ticking time bomb as my fellow panelists may think um it's a coordination problem right like let's say you move more economic activity than your underlying stake which surprise ethereum does right it's like that's where decentralization like decentralization matters it's like okay like let's say you're using vanilla tender Mentor I guess Comet bft um they call it now um it's a little coordination problem for all these validators colluding actually um you know have a erroneous State transition um occur um but I I do agree that um we're probably going to move away from that model um not because it's a taking time bomb but because it's just inefficient right having a committee of validators run full nodes of God knows how many chains right I would say you could probably depending how beefy your nodes are run 200 chains like Which is higher than I think most people would probably say uh but anything more than that then it's not going to happen yeah so what he's saying is that each of the validates will have to run a full node for all the other chains they support yeah precisely and I guess also incentivizing sort of developers as well it could also be a problem too we've heard a lot about CK bridging I think over the last couple of months and years do you guys have any thoughts on using ckps in bridging making either for trust minimization or for batching block headers or transactions into ckps I'll I'll start mainly because I'm the least qualified so I'll give the most high level opinion about it um I think they're important um I think there's still a lot of open questions on what that looks like um when you have you know heterogeneous proving schemes when you have latency on um you know posting proofs on chain and verifying them um but like what Richard was saying like that is the end state right it's like we can't be verifying the consensus or set differently we can't be snarking um just the signatures of these validators of underlying uh execution layers but um we need to be actually verifying or proving the the computation of the actual State transition occurring right um I think the solution to this kind of the open questions that I'm talking about is two pieces one is there still needs to be a hub right it's like heterogeneity of all these proving schemes all these different Roll-Ups you probably want an approver aggregator or proof aggregator or like using some sort of recursive proof system in order to make sure that they become homogeneous right and you probably still need a router uh honestly like you can't have millions of chains all talking to each other in pairwise kind of permutations right uh and then like what Beau is mentioning snarking the actual path of that packet becomes really important um and then on the cost piece I do think optimistic ZK right like I had a tweet I was saying like I think everyone's talking about how off chain is the future uh which is kind of ironic but optimistic zks is interesting which is where you snark something you don't verify it on chain but you could verify it on chain it becomes like one of n like fraud prover kind of setup oh I have a quick one I know too much to say on ZK Bridges other than excited for when when they come live and we'll use them but um I wanted to correct that axolotl's team doesn't run any of the validators and it's a permissionless network that anyone can join and run a validator it's that's the big difference between it and say multi-chain which just got hacked a couple weeks ago like which literally like it was an MPC protocol where the the CEO owned all the instances running all the NPC notes which was insane but yeah yeah the state middle chain approach is definitely more secure than uh multisig agreed yes uh on the topic of ZK clients I would say that there's obvious performance issues that you want to work through and you know that will improve over time on the front of proving the entire execution path is something I wanted to drill into so one advantage of encoding some of this network topology on chain is that now you have a subset of the keys that are owned by one to each and every particular path so you can Shard proving of the execution of one particular path and split that separate that away from proving the path between for communication between another set of smart contracts and you can do this on a smart contract to Smart contract basis if you don't have this information on chain it's very difficult to scale proving anything to add on that Richard as well um I don't know how to completely buy that but I think I have to think about it more um but I think um yes likewise will be the final statement drop ability and I think coming to this event I've realized that a lot more people think that it's further out than it actually is I think most of the tools needed to build extensible like clients currently exist it's just a matter of well assembling things like Lego blocks and once we do that we should be able to have like clients for most of the I guess popular networks and Frameworks we currently use so if we're in a future where all change support like clients do we just not use Smart contracts at all and just like clients for bridging um no we will still use um perhaps some optimistic system partly because the latency that comes from more proving East chains um I think perhaps the end state of bridging would be optimistic with like clients for dispute resolution if anything so imagine a world where someone below states that something happens on the same chain and some people just monitor this particular proof and if no one disputes it then hey we're fine and if someone disputes it we check the like clients to make sure that they're not lying it makes more sense given that well until the hardware becomes really good and the proving software becomes really good we're still going to be looking at perhaps three four five minutes sometimes even up to 12 minutes worth of latency for passing messages from chain to chain and um people aren't that patient so yeah I'm going to take a quick second to show the work that we're doing at polymer so so we're working on since we're on the topic of optimistic ZK uh approach to interoperability and for me that connection uh we're working on optimistic ZK IBC connections at polymer so we have working ZK IBC connections and we're working on overlaying optimistic verification on top and we expect to have that and hopefully testing in a few months so yeah cool so we've talked a lot about how we can solve intervability so in a world a dream world 10 maybe five ten years from now what kind of applications are you looking forward to seeing like what kind of cool applications can you build when you have a thousand seamlessly connected chains with relatively decent latency I think a lot about uh the idea of um borderless Finance where everything that we own becomes kind of aggregated within one single interface irrespective of where it lives and this goes beyond an on-chain context right and so my shares of certain companies that aren't doing too well right now um or my cash assets or my real estate um it's all in the same view as my crypto assets and there is ample liquidity uh in moving between all of those in whatever action I want to prefer and so interoperability obviously is on chain right now but I do think that there is a lot of research underway of how we kind of uh you know rather through the use of of CK snarks or what have you bring real world assets into it as well and uh it becomes a lot more delightful I think to own Financial Assets in the meat space very cool what about you I think um when all is said and done the main product that we'll see enabled by interability will be some variant of a cross domain intent protocol I think the end state of viturability would be the chains themselves sort of disappear they only become a thing that the developers care about very similar to webtoons many ways right only you care about where you deploy your application only you you care about where your software sits users just care about be them being serviced and yeah until we have that um we're probably not going to cross over that well million or billion Mark that everyone keeps on talking about when it comes to users yeah I agree with that um we just need a a way for people to build projects and be able to add I mean at the moment I feel like the only use case we have is payments but you can imagine uh also making the web 2 example I'm really excited about um how you can potentially bring AI into the um into the intent system like we've actually built a proof of concept in Squid and we're working with Dora who are in the audience on it and they they've built a thing where you can just they're like a search engine like the Google of um of crypto where you just type in what you want to do and then it goes through the squid SDK and it finds say you just want to Mint an nft it finds the nft somewhere builds the transaction packet so you can buy it from anywhere and you've got your nft so you can potentially imagine a world where you have a Google like just a search bar which is your entrance into getting anything or at least finding an application and then interoperability makes allows you to access that in one click from anywhere I love what everyone said um you know borderless finances is very important some of the early applications in crypto have you know our financial and have priced out some other applications me personally am very excited about gaming I'm a huge nerd and I love computer games so I recently saw a post someone had tweeted about uh having on-chain like ovariant of Warcraft if people are familiar with like real-time strategy games like Warcraft Starcraft these are kind of like your I mean AJ Empires as well there's there's a number of them because some of your like classic real-time strategy games but having these on-chain games and be able to prove it is very interesting use case to myself personally I would love to play these games I'd love to be incentivized to play these games as well all right very cool I think everyone is slightly Beyond schedule so I don't think this is correct and I know there's a happy hour outside so thank you very much for joining a great panelist today as well [Applause] [Music] all right foreign [Music] [Music] thank you [Music] foreign [Music] [Music] [Music] [Music] foreign [Music] [Music] [Music] [Music] thank you foreign [Music] [Music] foreign [Music] [Music] [Music] thank you 