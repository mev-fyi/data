hello everyone oh okay i should be okay medium range hello everyone uh i am artemn and um i'm a phd student at stanford third year i did an internship at celestia last summer it was a great experience and um today i'll be talking about a recent work we have now put onto eprint it's light clients for lazy blockchains and this is joint work with my colleagues dionysus zindros lei young and my advisor david chair okay to understand light clients on lazy blockchains we should first understand the light clients on what i will call eager blockchains which are the traditional blockchains so these traditional blockchains combine transaction verification and execution with the consensus protocol so this coupling ensures that only valid transactions are included in the canonical or the finalized chain typical examples can be thought of as a bitcoin ethereum and now let's see a run of these consensus protocols and observe this coupling in action so this is the genesis block in these protocols new proposals come on top of the canonical chain that could either be the finalized chain or the longest chain depending on the time of the protocol and transactions are included in within blocks these protocols are maintained by validators and these validators have actually two roles within the protocol they are responsible for the execution of the consensus protocol by proposing blocks or voting on the blocks but they are also executing the transactions within blocks and the reason they do this is because these validators they want to vote on or extend only blocks that contain valid transactions so in this case transaction one is valid i think colors are not showing very well but i'm just gonna point them on the transaction one is valid so they vote on it and then this block becomes finalized and so the same happens for transaction two but now as you can see transaction three is invalid so there is a proposal with an invalid block there is a proposal of the invalid transaction so these validators who are also full execution nodes they execute this transaction they notice that this transaction is invalid while attempting to execute it and then they will not vote for this block and this block will not be built upon and it will not become finalized so what they do instead is that they perhaps vote on proposals that are forking out this invalid this block with the invalid transaction from the canonical chain so a beautiful feature of these protocols is that you can just look at the chain and then see what the ledger of valid transactions is so we see that we if we just look at the chain of our finalized blocks we will immediately see that the ledger of finalized the ledger of our valid transactions is just tx1 tx2 skipping tx3 tx4 and tx5 okay so how do the lazy blockchain protocols differ in this regard so these protocols separate execution from consensus as a result there can indeed be invalid transactions within finalized blocks or that lie in the canonical chain the biggest example as everyone here might know is celestia and there are also like more um academic there are other protocol examples from the academic world so i will again quickly run or go to an exit protocol execution that exemplifies a lazy blockchain protocol so in these protocols the validators are only the consensus nodes they do not execute the transactions so they they think of their themselves as responsible for the ordering and perhaps the availability of these transactions but not maintaining a state or verifying their validity so as a result now what will happen is that our invalid are blocked with the invalid transaction tree will indeed get finalized and it will enter the ledger okay the validators are not executing the transactions but someone is surely doing that right because someone is maintaining the state so this someone are the full nodes that are different from the consensus nodes that are executing the consensus protocol and these full nodes they look at this ledger they sorry excuse me they look at this sequence of blocks that are finalized they extract out the transactions within these blocks here's the transaction list and they start executing these transactions one by one by perhaps applying them on top of the latest state they notice that transaction three is invalid so they basically sanitize this list of transactions and then obtain the ledger but this is done externally by the full nodes and this is not done by the validators who are maintaining the chain that's why the chain could indeed include the invalid transaction okay now like clients on eager blockchains or like traditional blockchains as prominent example as the simple payment verification on bitcoin or ethereum so i don't want to say it's easy but i would say it's easier than a lazy blockchain protocol to design a like line on an eager blockchain and the reason is when you look at the sequence of blocks that are finalized you know that the transactions included in them are valid transactions given some honesty assumptions on the validator set so now let's consider a client this client is a car dealer so this this client has a buyer this buyer is claiming that um it has paid this um car dealer some amount on the and then this car dealer basically wants to verify whether this transaction that is paying it or the car it's selling is included in the chain and then only afterwards it will send the car to the buyer now this like client is a light client because it does not have the capacity to execute all of the transactions in this chain or um verify download all the transactions from all of the blocks so it it asks around and then it asks a full node is this transaction to valid and it's part of the ledger so the only thing the full node has to do in this case is to point at this transaction within the canonical or the final thing because we know that in a eager blockchain every transaction in the canonical finalized chain is valid so it can just be pointed at in this manner and then now our dealer is happy it can send the car the question is answered now suppose this buyer who is buying the car is a multitask buyer and then it sends a double span to another car dealer now we don't want this other car dealer to be handing the car over to this malicious buyer so we don't want this car dealer to think that this transaction three is a valid traction any part of the ledger we wanted to reject this and fair enough the full nodes will not be able to show any block on this um canonical chain or the finalized chain that contains transaction three because the only block that contains it has already been forked out so this is basically how a simple payment verification on a very high level works so can we use the same logic on a lazy blockchain because well because i'm asking this question the answer should be no the reason why we cannot use this is as follows in the case of this client it's it's indeed the same um a full node can point at a transaction 2 within the finalized chain but now we have a problem and malicious full node can point at transaction 3 within the finalized chain because in a lazy blockchain the validators who are executing the consensus protocol did not check for the validity of the transactions so the invalid transactions are also included in this sequence so now we have a double spend issue so it looks like the simple payment verification that we have just gone over does not work in this case okay so this brings us so this is a now a problem and the rest of the talk will be trying to solve this problem and the solution is the title which is like lines on lazy blockchains so the solution starts with again a like line so to simplify things a little bit let's forget about the account model or the states let's think of our states as just like a set of utxos and the transactions are transactions that are spending utxos and then um this light client basically the queries it has is it's it has a utxo it thinks it has a utx so it's asking is my utxo in the latest set in the latest state of the world now this like line has a couple of peers that are full nodes and then these full nodes will send answers back to this like line suppose one of his peers sends the answer yes indeed your utxo is in the latest state it's included within the latest set of utxos here is the commitment to this like maybe a latest set of utxos and here is a proof of inclusion for your utxo and then now the light client could be perhaps happy well the light client if the like line hears the same response from all of it is peers and then here we will be assuming that there is at least one honest period that the like client connects to it's not like all of his peers are malicious because if all of his peers are malicious then this like client is at this point doomed so we will assume at least one of them is honest and if all of them returns the same response then the like client is happy knows that the returned responses is the same as the one that was returned by the honest one so it should be correct but the problem starts when one of the peers returns a different response because the issue here is that is that like client does not know which of its peers is on us it knows that this one of them is honest because if it knew which one was honest it would have just asked up on it wouldn't have even bothered to connect other ones it does not know which one is honest and then now the light client will try to figure out which of my peers are honest and which of the answers are correct so that's the question the light client is asking and i would like to just formalize things a little bit before i go forward even though the theorem says it's informal so the lazy like line solution ve provide has the following guarantees for this like client who is who is asking which of my peers is on us which one of them is like lying or telling the truth so suppose that our like line connects to at least one honest full node the identity of which is unknown to the like line and then network is synchronous and let l denote the length of the ledger which is like 10 million transactions on ethereum perhaps today then our light client solution ensures that the light client can find the correct answer to its query it can find which of them is lying and which of them is honest amongst its peers in a logarithmic number of rounds in the size of the ledger with logarithmic communication complex there so this statement is what justifies our solution as a solution for like clients because the like client needs to do this either in constant time or logarithmic time it needs to be succinct it does not have the resources to download things that are linear in the ledger size and then the site benefit is that uh the response the this the responsibility these impulses on the full nodes are also linear in the ledger size so it's not blowing up their responsibility beyond just downloading the transactions as they usually do as full full nodes and finally so i have been very vague here and i've just like talked about a single example of a like line asking whether it's utxo is in the latest state or not um there is a formal formalized definition of what it means for the state route obtained by the light client to be secure so far if you are more theoretically inclined please check out the paper okay so how does the light client figure out which of these full noises telling the truth or lying to do that it runs a challenge protocol sorry so in the in the challenge protocol the full nodes are obliged to give some more information to the white client to be able to convince the that the other party is lying or to be able to convince likely that they are the honest party and what is this extra information and this extra inspiration is what i will call a dirty tree so these honest full nose that are peers of our light client construct this 33 so to construct these 33 these full nodes that are the peers of my like line they look at the the sequence of finalized blocks the canonical sequence of blocks and i will call this canonical sequence the dirty ledger because it is looks like a ledger of transactions right but it contains invalid transactions in them so it's kind of dirty so these full nodes they can they are capable of executing this sequence of transactions and that's indeed what they do they apply the transaction they see on top of the latest state so they might start with a genesis state apply transaction one on top of that then they obtain state route one then they obtain state two they obtain state three so here they are trying to apply an invalid transaction on top of the state so if this transaction is not applicable we can define like a rule which would say that this state will be the same as the previous one because the transaction was we were not able to apply that invalid transaction okay so they keep doing this and then this way they obtain an augmented dirty ledger so in this 30 ledger we again have the invalid transactions but at least each transaction is now augmented with the state that is obtained after applying this transaction so now the state could be very large because here we are talking about full nodes that are trying to obtain a dirty tree um so in this example you can think of this st5 st6 sd7 as the root of the state which is succinct okay so as the name indicates they will of course construct the merkle tree out of this augmented dirty ledger so in our merkle tree the entries of the augmented dirty legendary the leaves and then they construct this merkle tree and that is what we call the dirty tree okay so are there any questions so far about how the dirty tree is constructed because that is a crucial part of the architecture yeah yeah they individually construct this yeah so um suppose i call as a likelihood i contact like eight peers and they return me some responses i tell them justify your responses then as part of this justification step they need to give me some extra information and this extra information is a dirty treat which they construct individually but so it's basically to construct the tree you look at the whole ledger which is the 10 million transactions here this sounds a bit unpractical but what happens in reality is that you can construct the three on a rolling basis right and whenever there is one transaction added the amount of work you need to do to update your tree that you currently hold for future queries is just logarithmic it's like so you can have it constructed on an ongoing basis but for simplicity here i was just talking about a light client uh sorry a full node that constructs is on the fly when the light client asks it but in practice it can be constructed yeah yes yes uh well i'm pretty surp yeah well there might not be any invalid transaction there but uh we only need to assume the worst case for security and like we will assume in the worst case there might be invalid transactions in this dirty ledger and as a result this is the augmented 33 legendary tree okay so so what information does our full nodes send to the light client so that they of course cannot send the whole dirty tree because it's huge it's constructed with the all of the transactions in the legend in the dirty ledger so far so these full nodes the peers they sent to the light client first the root of the directory which is just one hash function second they sent the merkle proof of the last entry which is this one okay so this is the setting now so our light client which i will hear after call a verifier because trying to verify whose response is correct or not and then the full nodes are here after called approvers because they're trying to prove to the right client that their response is correct and the other guy's response is incorrect and then now the provers has so far supplied to the verifier that the the state route sd7 the proof of inclusion we can forget it for now and then the dirty tree root and the dirty tree proof so this dirty proof is basically from the latest state route to the root of the dirty tree so if i go back one slide so it's from here to the root and now the verifier is going has this pre information and it sees that okay so can the dirty three routes be the same now the response is no 33 routes cannot be the same because this last entries claimed by disapprovers are different as a result the another question in the eye of the verifier has been reduced now it does not worry about the the latest utxo state rule anymore the question has been reduced to talking oh sorry the question has been reduced to finding out who is dirty to re root is the correct one or who constructed a dirty tree that is correctly constructed that is that's the question the verifier is asking to figure out who's adversity okay is there are there any questions okay so now i will show something called a bisection game which the verifier can use to figure out whose dirty tree is constructed correctly so this is this bisection game has been explored in previous lines of work so there is this really nice paper referring delegation of computation that is where it first appeared so in this bisection game one of the provers act as a challenger and other prover acts as a responder the goal of the challenger is to find the first point of this agreement in the responders directory with respect to its own directory and then using this first point of disagreement to convince the verifier in a very succinct manner that the responder should have been lying all along so during the bisection game challenger sends queries to their responder and responders replies to these queries so it's like a communication runs happening over time and these queries go through the verifier so verify looks at each query so challenger can send a query to the responder it reaches verified and verifier forwards it and then responder replies back and the verifier replies back to the challenger this is how the structure of the game proceeds so in the now i will go into the bisection game the next slide so in that slide you can i will just focus on challenger and the responder their queries but you should be keeping in mind while looking at that slide that every round of communication goes through the verifier so verifier is inspecting all of these messages all along okay so as i said the goal of the challenger is to find the first point of disagreement on the responders dirty tree with respect to its own directory so before anything let's first look at where is the first point of this agreement so the first point of this agreement is the first three entries are look good but the fourth entry is different because this responder has tx3 prime and then it has st3 prime whereas challenger has just tx3 and st3 so we will be will count ourselves as successful if the challenger indeed identifies that point okay to identify so far the challenger also only knows the responders dirty tree root because that's what the responders send so far so the challenger knows that the responders directory route is different so it's going to tell the responder hey reveal the two children in your tree of this route then the responder reveals these two children and sends them back to the challenger now the challenger and the light client check if we hash these two children does it equal to this original route if not then it's obvious that the responder is lying it's like sending the wrong information then we immediately identified as malicious and the game is over but now responder could be smart it will maybe send correct children now this hash to the root everything is so far good now the challenger checks do these two children of the root whether they are they the same as mine or none so now in our example suppose they are both different this tells to the challenger at the first point of this agreement on the responders tree with history should lie on the left-hand side of the 33 of the responder now then the responder queries the different child on the left-hand side sorry the challenger queries it and the responder again reveals these two children and then now suppose the left-hand side actually matches the left-hand side on the challenger's side and the right-hand side is different as a result now the challenger knows that the first point of this agreement lies to the right of this part it should lie on this fight so it's not going to query the two children of this node the two children are queried and it turns out these are these are the same and this is the different a result now challenger has identified tx3 prime st3 prime as the first point of disagreement between its 33 and the 33 of the responder and it has also identified this one tx2 s2 as the last point of agreement well the last point of continuous agreement okay so these these informations are also witnessed by the verifier who is witnessing all of this communication now let's go back to the verifier so verifier has been told by the challenger that the first point of disagreement between the challenger and the responder is tx2 to tx3 prime and sd2 the sd3 prime this transaction sequence and this state transition that's the first point of this agreement and it seems like the responder is also agreeing with this assessment because the replies of the responders seem to indicate that this is indeed the first point of disagreement between them so now the task of the verifier has suddenly become very simple the only thing it has to do is to check if this transaction tx3 prime indeed follows tx2 and if st3 prime indeed follows sd2 so if if if both of these transitions are correct then it means that the responder should have been the truthful party because the challenger should have been must have been challenging the responder for no reason but if there is actually a mismatch here then it means that the responder has constructed this directory incorrectly so now in this example is as indicated by the color red the responder is the malicious party and then tx2 is followed by tx3 instead of tx3 prime and as a result the verifier understands that the responder is lying and then the correct 33 root is h as given by the challenger and challenger is telling the truth so the correct answer is yes so this is basically the how the protocol works so we have also implemented the protocol uh on like 17 improvers that are globally distributed on some aws instances and then we assume ledger sequence of 10 million transactions and so m equals 300 is a degree of r33 it's not two it's 300 i will come quickly by such a large degree and then there are four rounds of interaction per game because the height of the three is uh approximately i guess it would be something like four and then um each light client runs 16 games why is it not only one game because you don't contact one or two two appears that you contact like eight peers or like more peers so this fight runs 16 games we have a tournament that determines how many games it should run and then this verifier we just assumed a college laptop like a with the summit with some college internet connection so it's 300 megabits per second downlink and 10 megabits per second uplink and it turns out these 16 games run in 18 seconds and then this could of course be improved so we have some improvement uh ideas on how this latency can be further decreased for this light client but many blockchain protocols also um confirm things in like tens of seconds and then this is the latency as the ledger size grows so it's not linear it's like a logarithmic because the scale is logarithmic on the x-axis okay so why the 300 degree it sounds like a ridiculously weird tree uh the reason is we made some calculations and it turned out like the minimum expected latency for the given uh for the given bandwidth and given three sizes is as shown here and then we also made some measurements and it seemed like the latency is minimized when we set the tree size to the degree of the tree the number of children per node 300. and yeah so this is one of the first like client constructions for lazy blockchains so this is a table of summary so as you can see the full node needs to download all of the headers and download all of the transactions execute them whereas now we can only download the the headers and we don't need to do have download l transactions we can have logarithmic communication complex for a litecline the c can also be further reduced to loxi using an interesting idea called super like lines and for details please check out the paper [Applause] now are there any questions i'll be happy to uh yes uh these are worst cases yeah this is uh susceptible to those um we discussed this in the paper well our naive solution is like what everyone else uses which is maybe the like client can um blacklist the the provers that are like dosing it um that is one solution and then yeah like many like many optimistic solutions are this is like if you think about it as like an optimistic solution because we have existential honesty assumption one honest peer assumption plus the synchronous assumption for the network so like other optimistic solutions this is susceptible to dosing and could perhaps be improved by research on how to avoid dosing in these systems um to completely avoid then you can go all the way to zk so you can one part potential solution for the same like client approaches using recursive snarks or recursive stocks i don't know if they exist but yeah cool i i guess there are no more questions thank you 