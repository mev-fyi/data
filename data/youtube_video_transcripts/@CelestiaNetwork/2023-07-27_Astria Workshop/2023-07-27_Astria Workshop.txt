I'm Jordan I'm the CTO uh co-founder of Austria we're building a shared sequencer Network which uh just like well not just like but similar to what espresso has been showing off lately and gonna walk us through here what we have and and what that means and really what we're trying to show is you know we talk about this this thing deploying a roll-up should be as easy as deploying a smart contract and so a big part of what we're demoing here today is how you can use a shared sequencer and how this can be possible um that there will be a part here that in theory you could walk along on your computer but as I get to uh in just a bit you'll see it probably not practical given Wi-Fi restraints but um so when we talk about a shared sequencer this was pulled directly from uh uh our Josh's talk earlier about what a shared sequencer is and so the the first thing we want to do is we want to get this shared sequencer we want to get a singular roll up running on top of it because without anything you're not sequencing anything um and so the question becomes like what does the architecture look like this is a nice pretty diagram but we're going to go a little bit more technical here it's like what are we actually doing underneath the hood in order to make this possible um and so this is more of an internal architecture diagram of what we're going to be running we have shared sequencer where the the sequencer here is a comet bft tender mint depending on your preferred terminology base chain and then we have a relayer which runs and it participates in a gossip Network and it also takes the transactions and writes them to the data availability so our sequencer here is running on approximately one second block times where slush is running at 15 second block times at each one second block time there's a there's a gossip that's created of the of that block which our conductor piece over here can read as a soft commitment to execute inside of the chain additionally at the end of every Celestial block we submit the data for all blocks that have occurred since the last to write to the DA which what we call the conductor as well can read off of that d a what the job of our conductor here is is to it's the drive of a roll-up so similar to what the beacon chain is or the engine API for a for ethereum or what op node functions in the in the op stack this is going to be executing via a API where I have here that's pretty simple to drive the deterministic execution of blocks it does this in such a way that is blockchain agnostic it doesn't actually know what ethereum blocks are it just knows that it receives a hashback in return and we have a modified Geth node which consumes that API and is able to send those through to our shared sequencer and in the end you hit it as a user get a completely processed transaction there's a little bit of tooling here that we're I'm going to use to spin this up locally and show you like how all it works um we have a whole bunch of devops tools so if you were to do this on your own machine you would need Docker and you know kubernetes tooling and uh we use Helm and then some just for some some commands here to make our scripting easier and then if you were also following along these are the two GitHub repos I'm going to be interacting with we have others but these are the the two for kind of demonstration purposes our Dev cluster repo has all of the configuration and whatnot we also have like a monorepo for most of our rust space code um and then those are going to spin up a whole bunch of Docker images I put this list here because this is why if you were to grab your computer and go to run things it would need to pull all of these images and uh the Wi-Fi is always great at conferences and I think that even just having 12 people in this room pulling a list of you know eyeballing it 15-ish Docker images might be a bit painful um I've already pulled all of these locally so I'll be able to walk through kind of how we how we spin up this whole system as well as how we interact with it and then we can go through and kind of demonstrate what's happening underneath behind the scenes all right that said let's actually like deploy this thing so I'm going to go over here into let's clear this um So within the the dev cluster repo I referenced earlier we have a whole set of kubernetes configuration pieces to deploy things thankfully you don't actually have to know how to use kubernetes in order to get deployed because that would be a terrible experience for someone trying to test this the first step to create this would be to create a cluster I'm not going to actually run this Command right now because I have already spun up my my kubernetes instance because this starts all of the image pulling um and then once we get this done this is all in the readme of our repo as well in terms of what it takes to basically get things spun up the first thing we're going to do is we're going to deploy Austria local cool this is going to spin up a couple of Docker containers which I can and containers and kubernetes which we can see here uh yeah there's gonna be some the magic of kubernetes is that these things will reboot until they come up um So within our our sequencer yeah yeah let me see what I can do to uh is that a little bit better here let me make it even bigger here there we go okay so now what we spun up when we do this we have two things we have a Celestia local network and then our sequencer just came up online so if we go back in and reference our slides here I've spun up this data availability which we have a Celestial local network as well as the sequencer and the relay these all exist in one let's just leave that up and slide over so in our sequencer here we can see that we have a comet bft based chain we have the sequencer and then we have the relayer that I alluded to if we look into account bft here we will see that we are producing blocks rather quickly there's nothing going on in these though we don't have any chains added to it right and if we look in our sequencer we'll see there's nothing happening because there's no transactions going through this is the app side of our chain we are built on top of instead of a cosmos based chain on top of tenderment we have a rust that is built on top of uh the ABCI interface and then the relayer here you can see submits blocks the data availability layer handles the sequencer blocks and every time every so many blocks it will write to Da when there's another Da Block there was another one great let me zoom in on this one too so oh cool um all right so we have that deployed now we want to deploy a rollout well let's uh do this the simple way it shouldn't just deploy roll up and we're going to deploy a whole bunch of stuff now we can go back over here and we can see we have spinning up we have three different things we have the what were this gef container which contains what I called the conductor again the derive of our rollup as well as an instance of Geth and then we also have a block Explorer as well as a faucet so if we go over to our browser here by default it deploys a chain at this address we can see in metamask that I'm connected to the wrong Network let's connect to localnet yeah we have 300 tokens in this by default this account is funded let's see 300 and nothing we can go here we can go to our faucet and let's send some funds here this will be come from our other account that I have linked here we're just going to send through request and then it should show up here but metamask is sometimes buggy if we go over here we can do a cast balance and we can see that we have a transfer transferred money pretty quickly there additionally like we just did a very simple account transfer right if we look at uh let's see if I do a cast balance okay this other account you can see that it used to have some paid some gas and paid for some tokens additionally like I mentioned before we have a block Explorer so we can just go to use we have block Scout configured to load on this we can instantly load see our transaction here in Block Scout and that's all fine and dandy Additionally you know we have some some test scripts here we have this like evm test data script that we created so we can just um let me say it's uh Cree trying to remember what my command is for test data generate transactions yeah so we can generate some transactions here this will start running through Foundry script we'll run through we're going to do you know like 30 transactions runs it usually about one every six seconds or so here um it's going to going to go through we can go look at our block Scout instance here and we can again see live these transactions showing up creating some token minting creating contracts just populating us with some with some test data here um this is all fine and dandy we have a Geth based roll-up that functions generally like Geth but we promised you a shared sequencer um you know we go forward to we go here it's like there's one but what we actually wanted was was this right we wanted to see that we have two sets of of rpcs and two Roll-Ups here that are running so why don't we go back here and while you know we have all these transactions executing we can go here and we can say oh I want to create a new roll up so let's deploy a roll up and we need to pass it two things one is a name um anyone want to give me a random name just to show that I didn't pre-program this GM all right and then uh everyone got a favorite number you have to seven I'm gonna do how about seven sevens we'll do some sevens there cool uh so this would be a roll-up name in our network ID these will be distinct we'll be able to send transactions to both of them and see that they go through without impacting the other so if we go back here to our kubernetes setup we can see we had we have two distinct things that are deployed here we have two different Roll-Ups that the faucet will come up is good there we go so we have a whole other instance of block Scout a faucet and uh this you know GM and we'll be able to access that now if we go here we had that cast check the balance this is going to be at so our one of our accounts has zero there and our other account has our same initial balance as we had before we have transactions running over here let's go ahead and do the same thing here as well we're going to adjust generate transactions on GM I think it was five sevenths cool so now we have transactions going through on both of these chains we just about finished here if we look at this initial one we'll see we freeze it 32. I can go here let's see our instance here populating so we've we've truly said as easy as deploying a smart contract it was one call we deployed a roll-up we have transactions going through if we go and we look into our logs of our Geth node we will see transactions coming through here we can see in our conductor that we're getting blocks both let's stop this from going through we can see that uh we have two things going on one is that there are blocks being received from the P2P Network as well as we have these finalized block calls which are being made as soon as we see the data in da so things are being executed as soon as they come through but they are also being finalized as soon as they're visible in the da layer and if we look in our single sequencer here see if we can see what's going on here transactions going through we can see we have quite a few blocks we're limited in our transaction throughput at this point by the speed at which Foundry is actually sending them not by the speed of the blocks that are actually coming in I can yeah I can yeah let's see if we can get that yeah I have two screens here so we can this will go and execute again on our default roll up so we can see them coming through on this roll up they're still going through here we can easily monitor well there was a log I don't know if it's showing up right now let's see if we set this up to auto scroll if we can see as one in one name space so we we have the list of like how many namespaces are contained I think one of these uh commands may have finished so we're only processing on yeah so that was kind of the the demo I realized I went through it pretty quickly here but um does anyone have any questions about kind of what's going on in the stack anything I can answer um yeah I think the the reality of like this is a demo is that it's kind of early to say um in terms of latency here um I it's going to be Network effects right it's going to come down to how how well connected and how close you are to everything if you're a the propos if you are running a sequencing node and you're running a roll-up node like you can theoretically like have Network latency decreased um is like 1.6 seconds so again it's like sliding tail right off the most optimizing an algorithm um is they have Hot Shots like fail if you get a type of window and don't have two birthday coding um but like you know in this demo for example we could run with a lot of times if you said thinking somewhere in like the two seconds um but again like it's kind of terminals to try to shape and get like more performance on delay or whatever but like like Enderman is a trumpet database a lot of parts are using it right I was like two seconds just like well within the capacity to do okay losers um and you can do that foreign so there's an arrow missing on here as well which is that this this re currently in our current architecture this relayer has a gossip nut that starts up via lib P to P that the conductor is also connected to to derive so it gets soft commitments from from the relayer as well as reading firm commitments no yourself from various sources in this case right in our case with the centralizing sort of like the moment that sequence that would be Ed stage would be when like for their case like ethereum gives it and osteopa and then um final would be when you pass sends himself technology already we present the transaction s yeah yeah so it's what's happening like in our actual Geth node here is you know we alluded to like the fork Choice Rule and this is to an extent this is up to a rope developer the way we've done it and this is that every time a soft commitment comes in you get a new head and safe block because the sequencer gives you a strong commitment to ordering but it doesn't give you a firm commitment that everyone has been able to see it once it's seen in the da we update it as final so so that there's like roughly the shared sequencers bottleneck is like someone like the limitation so if we say it's a long time the work bandwidth feet of the throughput of the DNA ire what the nicely is that the Notions order it um computationally maybe like more expensively doing an abstract problem of calculating and there will be okay we'll say we have the a layers of elimination broadcast never again I usually refer to uh metallic has a post on um quite a bit of detail on various compression mechanisms like per transaction uh that stands to me um is going to be one megabyte of data how many transactions that's going to be defined by what state machine you use and how much of that you could potentially put exterior life at individual sequencer and then your your what is your serial relation format you do like a broadly gzip whatever progression right for like losses compressions um relatively large yeah what I one of the things I was going to show here in terms of showing like we're not actually executing is that like the chain ID which is what we call like what you could every each person similar to a namespace on Celestia you just pick some set of bytes and you post your data to that it's just an array of it's a vector of u8s and then the same thing with the data like this this whole set is just a whole bunch of bytes that we never process or do anything with it's just bytes let's go to that one sequence right so there's we're actually working on a new component to throw in here that's like just not quite ready which would basically as long as you are running because like this this process of like throwing the transaction in here is is fundamentally an argue like kind of flawed um which is that like now we have to have like a direct submission we're working on is this this piece that will kind of capture and encapsulate what we call the like Mev piece which is with the way a Mev Searcher today works is that it reads over some RPC mempools and then does some stuff and then can work with Builders to to build the blocks so what we'll be doing is if you have something with a you know an ether PC you can connect this to it it'll be able to read your transactions directly out of it instead of being submitted and then process those and submit them itself down to the shared sequencer so you don't actually have to have your your roll up have any sort of special submission logic I think we'll transfer that we assume we have one megabyte block to look at 99 360 block or whatever and there's potentially a 10x Improvement and whatnot um but you know somewhere in the light well at 10 000 PPS um a lot of times and that would presume the data layer at 15 megabytes clock but that's like the ball or like that's like the worst case transactions format again assuming 15 don't think if you're young or so I should have planning to have a launch Florida yourself the soft commitment again right is like I guess you can it's pretty flexible here right and there's like a question for life does the shared sequencer give it at a consensus level responsible for posting data to begin that is like a opinionated like question of like whether it's responsibility also when so if the naive assumption the shared sequence are always post all the data later immediately you must pose locks immediately um theoretically you could have like lag on that or whatever you could have block space features market right um you could see that like pressure mechanisms there could be like some like long retirement right the the role okay guys I had a lot of good kind of acquiring 95 percenters strong opportunity for me from over to the layer to like charge the share payment terms I'll send for you unless you pay because I know that you're very close to the Limit as I block you for one block you can't catch up there's a big design space around like what are the margins of like safety from my sequencer if there's any Roblox data on the biggest layer on this architecture and so the design space very well so when the soft commitment perspective but naive case is that to be like yeah your overall so fundamentally you've got to be limited by what is what is the throughput and the d a layer most optimization the total data and width and the reason why I should n't is to let you both look like other info on this but like EA layers generally in the ratio of a team they use scale better to have larger and slower blocks so potentially like the da layer could get to a 128 megabyte blocks but that may require them to say go to 30 second lockdown again it's like more you need to have like soft commitment prior to that but that includes the overall bandwidth o'clock now we have 10x more a half a lock speed right now fundamentally you will look it's always going to be explained by the throughput of the base right um we um the third commitment if the sauce commitment is giving them a guarantee that it will eventually negative yeah it's like an open question we haven't committed to because there's a question of should one be a layer or multiple VA layers if the shared sequences a guaranteed support s that will post always to one da layer right then you have kind of try chairs VA so when you look at like optimism optimism has to go or whatever um you know they had like 80 000 somewhere like the age US dollars worth of like how two people they have to pay out somewhere in the mall of like 50 000 so like that's the insurance there are relayers that do this no one pays for people No Deal not not yet because there's many designs but they all have as many did you have another question although like it is posting together yeah and expertly I guess like semantic down below right left assuming data is posted to a DA layer as it is I mean the roads are like getting data through this posted between they're the security that a robot wants to give theoretically we assume right and Roll-Ups want to be able to apply clients that can then receive fraud prints or like any papers right but they have the data of that proof is easily like final retrieval and again the benefit of like Celestia right through data availability sampling you know you could have a very large amount of that right so these 128 megabytes but no way people you can prove that like you get a proof was for now that was present in that without having to store all of that because it would now have a relatively High backward system right and we're looking at like call it like 256 megabytes per minute right but it's not that much bad words but it's not nothing so in this like this this deceptive thing you mentioned like a generous like DNA is already like and your sequencer can't afford whatever reason is how do you catch up in that scenario area yeah advantage of some other question of like what is the ratio of bandwidth Secrets or needs relative to the EA right like if some degree English model to add an uba layer and again you have these censorship attack right same thing as this one like roll up on a period today but yeah we know who the designer for the sequence or the relay or whatever of Optimus Prime and we're just going to send your messages right they usually usually the ratio ratio a bachelor away frequently so they have a relatively like low ratio of like needing to buy a real traction over now or whatever um but again it's all that ratio yeah if we run into something where like this sequencer in order to like surpass it has a layer you get in this kind of awkward question of like what if you fall behind there's just like a structural question like how you handle that is like generally you would assume that you would take a relatively conservative position relative to like the overall throughput I mean they like it just makes more sense they're like the grown-ups themselves figure it out and like if they value you know they'll pay more rather than trying to force everyone it's a little bit of like my assumption right but a lot of it is also like this is the large premise way of like you know we usually we believe so there's a lot of questions like I want to create a roll-up how many of my problems am I liking it all all your problems yeah some fundamental trade-off to any opinion right yeah which may mean that like okay you know sequencers or relayers like for the shared sequencer to the a layer would like presumably hold the large quantity of the VA layer base asset different explanation the price of that asset um we obviously have seen you know there is a like a gas cooking but like the system but like I can say like I know that persistently in the future yeah I would like to acquire one megabyte of data every single one in the future I would pay the um or how you acquire guaranteed the purchase in the future and how important in the market um 