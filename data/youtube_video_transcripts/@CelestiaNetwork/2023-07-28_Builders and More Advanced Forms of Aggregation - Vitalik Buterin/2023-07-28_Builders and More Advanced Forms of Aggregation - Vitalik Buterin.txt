but I had to ask since tanning's memes were cut so would you please give us a PBS meme to make it up a real-time meme challenge this is difficult I I do not claim guaranteed success so to get right into things um yo dog what's up who here thinks it's a ceiling who here thinks it's the ceiling that's up who thinks it's the sky who thinks it's like a cryptocurrency okay well let's just talk about aggregation um okay so the aggregation basically the core idea here is you have N Things and you're trying to take N Things and turn them into one big thing which is less than n times as hard to verify right so sorry it's it's hard to speak and be yelled at for my poor microphone performance at the same time but okay so no one more reprimanded I'm throwing this out and you'll have to listen to me speaking quietly okay so what is aggregation right it's uh converting end things and turning them into one thing which is less than n times is hard to verify now why do we want to do this well because we care about scalability we don't want to pay like 88 dollars a transaction or even 0.80 in transaction and we want to like cut down on chain verification costs right there are a lot of different use cases of aggregation and so in the ethereum consent this way or for example we have BLS signature aggregation and there's many kinds of aggregation that we'll have in the future so some specific areas where we are thinking about aggregate we might have aggregation erc4337 right so this is this off chain protocol by which um users can send in user operations that have validity conditions that are different from the yeah the validity conditions of irregular ethereum transaction you might have a smart contract wallet validation it could be a multi-sig could be some custom winter knits the Lamport signature could be whatever and those conditions get verified and it's this kind of off-chain ecosystem for like basically making these custom Smart contract wallets work but these um user operations all have to be wrapped up in a transaction right because ethereum the base protocol only accepts transactions now before erc4337 in the dark old days we would have protocols but which every single user operation would get wrapped up in a separate transaction right so I send a user operation and then whoever I send it to would have wrap that user operation in exactly one transaction and then the transaction would go on chain every transaction would have a a 21 000 gas overhead so it's not very efficient it also was not a very open protocol in erc4337 we have a custom mempool where users send user operations into the mempool and then bundlers exist in that mempool bundles grab up all the user operations they can see in that block and then they publish that on chain right so this is a form of aggregation right because the object that went in the cost of verifying that object by itself would be n plus 21 000 right and whatever the cost of the user operation is 21 000 for the wrapper but if you take like let's say K of these and you put them together then the cost is just going to be n times K because you still have to process all the user operations actually sometimes a bit less than n times K because you can benefit from like warm uh cold uh storage reading gas stuff but and then plus 21 000 only once right so there's some pretty significant gas savings from taking user operations and putting them all in the same transaction this is a type of aggregation and you know this is something that's uh actually being done even in the Builder ecosystem today BLS aggregation so this is a thing that actually has been recently a kind of in proof of concept mode it's been added to erc4337 there's a piece of code called BLS wallet that actually does this but the basic idea is we instead of using ecdsa signatures we use BLS signatures so why what do we want to do this this is especially valuable in Asia roll-up right because in a roll-up the computation is done off chain the data is still done on chain right and so the day the computation becomes vastly cheaper the data does not become cheaper at all and ecdsa signatures on their own are 65 times n bytes okay fine I'm using answer refer to the number of objects now and then with a BLS signature if you use G1 points for the signature then the signature can be 48 bytes four in arbitrarily large number of operations right um and so if you have like a hundred of these per block then for each one of them the amortized cost will go down from 65 by its per operation to like half a byte per operation on the computation side it actually does get a bit more expensive because instead of doing fairly easy elliptic curve stuff involving ads and multiplies um like I think at ecdsa recover as like something like three multiplies or somewhere in that range um but and instead you do a pairing which is like pretty heavy duty stuff but as I said on roll ups computation is cheap data is expensive we're saving on data and it's great right but how do we actually like do BLS aggregation right because the ethereum protocol does not currently have an execution layer BLS capability right and so if you imagine and different users each of those users is going to send their own BLS a user operation and their own individual BLS signature that they created separately is going to be 48 bytes long right then what we want is we want the thing that goes on chain to be 48 bytes we don't want it to be 48 times n right and so there needs to be some kind of actor that is grabbing up all of these user operations going into the user operations grabbing out the BLS signature adding them all together see that's uh let me know some kind of you know mechanism in the middle it's a big plus and you know create one aggregate signature 48 bytes and that aggregate signature can be verified against the aggregate public key which is created by taking all the public keys of the individual users and also adding those together right so this requires two types of weird stuff right the first type of weird stuff is the off chain Adder the second type of weird stuff is the mechanism for verifying these signatures we're basically instead of doing what ethereum protocol does today where you verify each of the signatures in sequence the protocol or whatever super protocol we use somehow would have to take these signatures then when you walk through each one of the yeah one of the user operations don't immediately just like verify pass fail it but actually record the BLS signature like first of all you'd verify it locally make sure it verifies individually if it doesn't you throw it out right but then record it and on and then if you're doing this inside the block here you just recorded right then keep walking through all of the user operations add up all of these signatures and then at the end do the one check at the ends right because adding two signatures is like very cheap it's like hundreds of times cheaper than um you know even and ecdsa operation right so the this requires like a different workflow where it's like walk through the operations then do a check and then execute everything now erc4337 actually already now has an extension to do this but this is again a type of thing that I call aggregation synark aggregation so this is the future right so BLS is like very specific what if I told you that in the future we're going to be able to take existing ecdsa signatures potentially even signatures that are made with existing tools and replace them all with a snark so it just says here is a signature and here is a proof that or or rather here is a proof that there exists valid signatures for all of these things right so this way you could replace an unlimited number of ecdsa signatures with like one snark and you can even apply this technique to other mechanisms right so um who here has used a privacy protocol um privacy Protocols are good right Now privacy protocols cost a lot of gas those cells one of the bigger challenges hampering their broader adoption right because inside of one of these privacy protocols every transaction requires you to have a snark that goes on chain now the synark 500 000 gas 20 times more expensive than a regular transaction at current gas prices that's going to be I guess about 20 gray multiplied by yeah 500 000 gas so that's uh you know 10 mil 10 million way which is uh 0.01 each multiply by 1900 19 transaction fee who here is willing to pay an extra 19 to make your coffee more privacy preserving I'll do it as a gimmick you know um yeah so you know this is like not good it right and so but what we can do is well we can use a snork to prove the validity of all the snarks right and so even if you have a hundred different users using privacy protocols within a block you just take their proofs you prove them all together and you have one proof of the proofs and now you have like all of the proofs of all the private stuff within a single block right now what does this require it requires aggregation right you need to have some actor in the middle you can that it basically takes all of these objects and replaces them with an object that proves the existence of all of those objects so this is all really nice this all increases scalability and this is all really good right so what does this all depend on it requires a builder ecosystem by the way he remembers the cartoon character that this meme is based on Bob the Builder yay oh no he gets see him Bob the Builder needs more love you know like well you know we have like Barbie these days and you know we have like you know what else yeah there's all you know all the Barbie songs and like you know we need a bulb to Builder movie like can we do like an Unchained Bitcoin bouncy for for a Bob the Builder movie and then like your zoo pool to vote on the best one you know real world crypto applications please so yeah you know we need uh I mean we need Builders right Builders are you know the heroes of uh of ethereum block production right so okay final see I wonder if I this style of my coding is better um so the block building ecosystem is actually really big right like we all kind of know that you know Bob the Builder is an abstraction and in reality you know there's like dozens of construction workers and then there is the people driving the trucks bringing resources over to the workers and then there's the janitor and then there's a whole bunch of uh other pieces of uh infrastructure and there's like really big teams that make up a construction company right so black building ecosystem looks pretty similar to that too right so basically you have a bunch of Searchers and Searchers all have their own different strategies for creating uh bundles that contain different types of transactions and then they all go together to a block Builder right and then the block Builder creates a block and then publishes it today to relays in the future directly to validators and like this is roughly how things work right now right and so one natural question to ask is well you know if we have a a builder if we have this kind of ecosystem then like who's doing the like who's gonna do the snork aggregation or the BLS aggregation or erc4337 aggregation all of these things the most natural guess for the long term is like we'll have specialized Searchers right so we'll have like a Searcher that speaks the 4337 protocol and then we'll have a story show that does BLS we might have you know a Searcher that does a snork aggregation they might even end up talking to each other there might even be some multi-layer ecosystem where you know first you do the aggregating for the 4337 or for the BLS and the snarks and then you put that together into a bigger 4337 um Aggregate and that goes into a block along with non-4337 stuff but like I expect it will move towards something specialized like that but I also expect you know in the shorter term there's definitely going to be Builders so just like do this stuff directly right and there's like I expect it going to be a growing array of these aggregation sub protocols that gather these kinds of aggregate messages so challenges in these ecosystems right so we want an open mempool meaning a protocol that anyone can participate in right not um you know open in the sense of um like anyone can um you know see your stuff and use Advanced machine learning algorithms to like figure out when um okay what what should I even say here okay you know figure stuff out about you that you don't want to figure stuff out about yourself um you uh right you know we want a protocol that anyone could participate in for both users and for Builders and sergers right we wanted to be open for users to send in their user operations we want uh it to be open for Searchers to participate and we want it to be maximally open for people to bring in new aggregation protocols now that does require them to kind of accept permission from one Builder or one Searcher but it should not require like Global permission from this from the yet ecosystem so that's a goal um and you know we want to try to avoid centralization and if centralization happens we want to avoid censorship now one of the challenges is that economics is weird right so in particular the issue here is that a lot of these types of aggregation that I talk about they have a high fixed cost and they have a low marginal cost so what do I mean what I mean is that if you think about like synark aggregation right if you put a snork on chain the cost of a snork is about 500 000 guests now that's not can represent lots of things if that Stark represents one thing it's 500 000 gas if this narc represents a hundred things it's also 500 000 gas right it's fixed cost now the other thing part is that it has a low marginal cost the marginal cost does exist right because if you're approver then you have to like run more proving Cycles right like if you have to prove five more things the cost of doing the proof is five times bigger now this is you know if this is a cost but generally the uh these off-chain costs are I believe already lower than on-chain costs and I expect those these costs to continue to Trend lower as we have more specialized proving techniques as we have more specialized hardware and all these things and I expect gas costs to be much harder to be much harder to reduce right the amount of gas on the ethereum L1 has increased by a factor of five over the course of seven years but the efficiency of provers has increased by a factor of like thousands over the next the last like maybe four years right so when you have things that are high fixed costs and well marginal cost like economics get annoying right it's like public transit systems right like when you have a fixed cost to run a bus and it's like even like sometimes it might even happen that like the system can't pay for itself even if it makes total sense for the system to run because the system has to charge one price and it turns out that if it charges a high price it excludes uh too many people and if it charges a low price it doesn't capture enough of the value right and you're stuck right and so you know you have like weird things like this and unfortunately these kinds of like fixed cost to logical marginal cost economics do tend towards centralization and sometimes centralization may be an argument for saying like we want to give up on this whole higher layer ID and we want to just like protocolize it but the problem is like this stuff is so early that it doesn't make sense to protocolize it and like how do we navigate that trade-off in the meantime right is basically the challenge um another really fun use case proof aggregation for ZK Roll-Ups so let's say you have a roll-up and actually here is a part of a roll-up team um who here is part of a roll-up team different from the roll-up team that the person over there is part of um we're here as part of the roll-up team that's different from both of these roll-up teams okay I can see I I see a few Rays stands yeah so like we have at least three roll-up teams here right so the uh problem is each of these uh Roll-Ups are going to have to submit proofs on chain and submitting a proof on chain is itself something that has a high cost right so if you look at Ezekiel rollup it has to submit as you get snorkeling chain 500 000 gas if you're a stark then it's like closer to five million gas and this is expensive what if we had multiple Roll-Ups and these multiple Roll-Ups could cooperate and basically replace all of their individual proofs with a proof of the proofs right so you just have one proof that proves that all of the proofs that they want to submit are actually correct right so this is kind of what the diagram says right you have like three different Roll-Ups and they make three proofs of three state transition functions and then you just make this kind of multi-proof which just submits as a public input the claims that the three proofs that are coming in are making and then it sends it off to a batch Handler and then the batch Handler basically just tells the roll up so like hey yo dog I have a proof of this I have a proof of this I have a proof of this and let me know the Roll-Ups accepted right so this like is a pro a kind of Layer Two middleware protocol that could actually be really useful and it could be like a lighter way to achieve the goals of uh reducing costs for Layer Two is that's lighter than um you know your threes and some of those similar ideas and like it could be you know it's more minimalistic it can be made to be more permissionless I mean I I believe like within the star choir ecosystem there's a version of this running already right but it would be good to have this as an uh potentially open you know protocol that's kind of shared between an even larger piece of parts of the ethereum layer 2 ecosystem and this is again a type of you're supposed to say the word yay okay perfect so the the goal of this is the proof Singularity right so basically my you know my dream is we have a block and the block contains a proof oh and the proof is a proof of proofs and each of these proofs is itself a proof of proof of proofs and each of those proofs is another proof so imagine the proofs at the end could be just signatures then the some of them some of them are signatures some of them are privacy protocols then the proofs in the middle are going to be aggregation proofs then the proofs on top of those are going to be layer two proofs and then with the way or two proofs you have a merged protocol and then it all gets into so it gets into one proof and then maybe over and above that you know you have a layer you know you have like one big Master proof to prove them all and that one big Master proof is uh just going to be a ZK AVM right so this way you know we're going to be we might actually be able to get to the point where we literally have like you know blocks coming in once every minute that just that prove everything and everything in the ecosystem is going to be super efficient and super uh super optimized right so this is um you know what I hope for the ecosystem and it would be amazing to see and um you know Builders are a yeah going to be a very important part of making this all happen um so this concludes my presentation thank you all for listening um yeah thank you thank you for the meme uh and we have one time for one question but I could uh also ask our next speaker to ask the question if you have one um extremely exciting talk about the future of blog building um my question would be these new protocols how should implementers be thinking about the complexity of the implementations and about shipping them in a timely manner that can fit um I can make sure that we don't end up in a dystopian centralized the future how do we think about implementing these protocols I think like just standardization is important and like cross ecosystem collaboration I think is important so I feel like we've been having a lot of that between layer twos which is good I would love to see more of that happen between wallets I would love to see more of that happen between privacy protocols like I think we just need to you know Identify some of these kind of verticals and in some I think you it might even be the case to like per vertical we might need like some an intentional effort to try to like really um you know figure out which what actually makes uh makes sense to do and to like try to sort of uh front run some of them some of them more centralized efforts at solving the same problem 