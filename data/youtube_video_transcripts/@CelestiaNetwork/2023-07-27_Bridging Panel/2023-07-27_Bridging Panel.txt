so I think I would like to start with a small intro if you can do what you're working on as well yeah I can start hey guys my name is Bo I'm a co-founder at polymer we're working on extending the IBC protocol to all chains I'm fig I'm co-founder of squid and we're doing cross chain swaps and transactions across the cosmos and evm soon to be many more I'm Richard I'm a co-founder of orbelabs and we're building a chain abstraction stack I'm Jim a co-founder of catalyst we're building Sovereign liquidity for the modular future thank you very much I think we often hear a lot of different words when we talk about bridging so I think we hear a transport layer question matching protocol question router token Bridge could you sort of explain maybe take one each and explain what that specific topic is a specific thing is I'd love to talk about the transport layer I feel like it's a it's something that's not really considered and in in Arab I feel a lot of people talk about the state later they talk about security they talk about how do you verify something that happened on one chain on another chain transport layer deals with encoding of the network topology of the entire network on chain all the paths between chains all the paths between all the smart contracts I want to talk to each other this information needs to be encoded on chain IBC does it very few or basically no other interrupt protocol does that I can talk about routing and what squid that's what squid does essentially the routing is when you look at Cross chain just from the lens of connecting applications between chains so we take the view that there's liquidity all over crypto that just needs to be connected and we use General message passing and on the different infrastructure layers to use axler to um access that liquidity and so a user should be able to interact with any application on any chain in just a single click and it's a little bit like Google Maps but if you could teleport soon we always find you the way to what you want to do but it should happen as soon as possible yeah and I think with messaging crochet messing at least the focus is more so passing data from one chain to another and Bo is right the reason why most messaging protocols don't focus on the connections is because it's possible to have connection less interoperability where you don't need to know the direct paths beforehand and still pass message from chain to change and so you'll find that for most messaging protocols establishing those connections at least beforehand if not a main focus and I guess I can take token Bridges if I think that that was something you said right yeah as an option um so token Bridges uh I think is a pretty archaic term um at least how I Define it where you know I think several years ago there was a need to move coins between the kind of home blockchain to a new one and so Bridges were kind of made as a primitive in order to enable that and so bridges for me are some function of um wrapping a token or minting a new token on these kind of new destination chains in order to get access to this token and it's backed one to one to kind of this Vault of the original tokens I restored on the home chain um and so literally a bridge right it's like you're just kind of shooting an asset from its home to another location thank you I think what you all sort of touched upon a bit was standardization to some extent um so we hope you have a lot of different token standards how do you bridge one token standard to the other and also in messaging so how do you view sort of standardization and how do you think we should sort of go towards that my long-term view on standardization is that at some point chain developers if you relate them to operating system developers are going to want to enshrine something into the blockchain kernel itself what that is will probably be open be an open standard be net neutral be decentralized I mean I I slightly disagree with Richard here on the need for encoding these connections on chain because I think that if you don't encode this information on chain you cannot prove anything about the network in fact you cannot prove that you have a smart contract that is bound to another smart contract across any number of chains so I think that when they these chain developers do come to make this decision IBC is is the best candidate here I think uh you're gonna realize well we're not going to be going back and forth we tend to have very different views on interoperability um but I think going back to standardization um I'm very pessimistic as to whether it will have all the developers at getting underneath one standard simply because um it's in your best interest not to if you think about a world where there's uh even 10 chance that there's different interrupt standard that sort of like makes interoperability slightly better for some other chain that didn't choose to enshrine a particular Bridge you're probably going to want the option for that sort of standard to come to your chain um and so what we're probably going to see instead is we're going to see some sort of wrapper protocol that comes and bundles up all these interop Solutions and gives applications on top of these chains the ability to move seamlessly from chain to chain um but yeah going back to the options between connection based or connectionless interoperability um I'm pretty sure it's still possible to make it very easy to fast messages without sort of like storing and encoding all that data on the change that you're going to partly because most of that data is also already encoded in the security layer or the state layer which what would call them um so yeah that's the general thought there any more thoughts on sanitation or I think um what we're seeing right now is uh there are some projects that are just brute forcing it right um I think we can all agree in this panel that there is like pretty kind of uh there's a pretty locked High degree of heterogeneity uh in the ecosystem as it pertains to varying standards or varying protocols that not only span General message passing but also as we were looting before kind of the the token level as well and so there are projects like socket and live fire that are just saying hey like we'll just kind of put the man hours to to aggregate all these things and then abstract in some sort of off-chain way right um what I have been seeing is well that works um and I'm sure it will continue to work there has been kind of a deliberate effort to make their jobs a little bit easier and so you know there's this new ERC I'm blinking on the name that Arjun from connects kind of offered that is kind of championing that right and so it's good to see a lot of the um the liquidity networks like connects and you know our team at Catalyst included seeing that there needs to be some sort of standardization how we um wrap tokens when we bring into different chains and so we allow for not only more interoperability um but also kind of more um more shared agreement on the security assumptions of that wrapping yes we should have touched upon the bit in the end here sort of if I'm a Dev and I'm building application I need to choose a question missing protocol or a bridge or whatever it might be what kind of trusts and security assumptions should I be looking at and what they need to consider I can go um just in the standards piece as well um I think it depends where we are in The Innovation cycle because I agree that we there's going to be experimentation if um if something if there's a chance that something's going to work someone's going to go for it and build the build the product but potentially with bridging for example that's quite an old technology now and we can start to standardize it and people are like the Canucks guy um looking at ways of like abstracting it in a way so that you can standardize it for everyone but our job at squared is a little bit like the the aggregators where we can we integrate protocols across different virtual machines like different chains different gas models and we have to deal with all of that complexity um I don't know if we're anywhere close to getting standards in a lot of these places but um so there's there's just going to be a ton of work um on our end I think to to just deal with that for now um I don't yeah I think we could end up as like a temporary standard and then hopefully the ecosystem like Finds Its Own Way to like to become very similar across the board but for now we just we need to make things usable and um Evolution will play its course so will the most sort of with the best standard win or are there other reasons why I stand at my win I don't think so I mean solidity is the standard now so and I don't think many people agree that it's like the best and JavaScript maybe the standard it's um it's just gonna it's gonna play into a lot of different factors probably non-technical ones okay perfect um we heard a sort of modeler ecosystem day um and we're obviously Celestia is a DA layer how do you guys think that you know sharing a DA layer might help in bridging between Roll-Ups or chains or whatever else it might be running sharing a DNA layer allows you to have trust minimize interoperability between those Roll-Ups if you share the same da layer let's say they're optimistic rollups you have the security of that da layer saying that I can make this data available to anyone to be able to generate a fraud proof that means that this Economic Security the da is shared among the Roll-Ups on top yeah and I think even going back to the general idea behind um Roll-Ups so Roll-Ups in many cases at least for L2 rules and ethereum um get the states for all things happening on ethereum sent up to them and so in the case where you share its da layer you can sort of like run like lines that sort of like look at the state coming from the da layer and even compute a full note that computes the state of all the blocks that are basically being broadcasted down to the DA layer and through that you can extract the message you need um so how that differs from litecoins that sort of like rely on well separate the um layers is you run into the problem where it's possible for the da layer to fork and you may have sent over a state from some other chain showing a fork that ultimately was deemed invalid so I guess comparing shared DA's with like lines to not share deals with like clients what you have is just a slightly more robust system for passing messages from chain to chain perfect any more thoughts on that yeah I'm not going to talk about the security properties of it um I do think the benefit of sharing da and depending on how you you know use the underlying da layer you might also use it for canonical transaction ordering um you do allow for soft confirmations of the state verification of the messages being passed with an execution level and so with that um you know you have quicker finality right because you're essentially saying that because this data is made available because you know either there's a canonical ordering of the transactions using the transaction ordering layer of this da layer or even if you're not doing that you still have the data made available so that you can have fraud proofs or so that you can reconstruct some of these validity proofs um you are you're basically allowing for soft confirmations at the Cadence in which blocks are produced at the da level and so for sasia like several seconds right and so that is a sufficient user experience even if there's latency introduced at the execution level for True finality okay perfect maybe we'll have a question for for fig and and Jim here as well I think you've talked a little bit about the ux problems that we run in Seward bridging um and how do you foresee sort of how do we fix this can you know a help can intense help like what kind of future do you foresee in terms of ux um I mean the data availability is uh what the what everyone was just talking about is a good example of ux where we just found out that I didn't know this the op the optimism token is minted on up on the optimism roll up and not on L1 and so there's a bridging problem like how do you how do you Bridge op without it being like fragmented now because they could have just minted it on ethereum and then suddenly you have all these canonical versions via the insurance Bridges but is going to be a mess and I think you're going to need these that's what we do we'd have these abstraction layers where you can just get whatever token you need for an application and even if the application is supporting the wrong token but technically you can get that token use the app in one click and intense uh this idea that you just have something that you want to do and you you send it off into the into the world and someone magically solves it and I think what we're doing is is sort of like a proto-intent system where we're the only solver but and we have we have a mod uh a feature called boost which we're really excited about we just launched in the last week which allows you to essentially declare your intent on the source chain and then that will get finalized over 20 minutes or however long the bridge takes and anyone can fulfill that transaction on the destination chain immediately and it's fully generalizable because it's using general message passing it can be a swap you can buy an nft a cross chain you can do staking across chain and that's the user experience we want we want people to do anything in any application in one click as soon as possible um and yeah I feel like we've we've gotten there we've started just with something which works and then you can decentralize that more over time and um I think yeah really excited for intense and to integrate them into squared as well yeah I don't have too much to add as it pertains to intent I do agree that um you know routing systems uh like squid and um the ability to have kind of a sophisticated entity provided liquidity for fast kind of um for fast liquidity slash confirmations of those transactions is really awesome right I think that that augments the ux considerably um I do think we still even in that Paradigm well two things I'll add one is that I think intents are really interesting but I don't think people talk about solvers enough so what if they get the Squig team and and doing kind of the boosted feature what they're doing there is a is really kind of starting the conversation of how do we have infrastructure that is not articulating intense but actually fulfilling or providing the liquidity or providing the tools for these entities to fulfill those intents uh so I think that I think we need more kind of um advancement and more investment focus into that piece and I think where we come into the picture is kind of the second piece where even in that Paradigm in which we have really robust infrastructure for solvers to fulfill these intents we still kind of face what I think is a cold start problem when you look at new chains and so I think it's pretty kind of consensus now that there's going to be lots of Roll-Ups right hundreds of thousands if not Millions within that kind of framework like if you have a brand new chain there's it's a really difficult problem it's a really difficult problem to try to inject liquidity into a brand new chain that's basically a Barren Wasteland and so how do you solve an intent for a new chain when there's no liquidity right and so that's that's a big research question that we think a lot about Catalyst and so we're we're hoping to slot into kind of this re-focus into the solver problem space you think most of the conversation around intent is currently focus a lot on a very defined problem which is swapping one asset for another but there's a big question on if intents are going to eventually become let's say the end game of interoperability then we're going to need to find ways to generalize intents um to almost every possible transaction and I think that problem is extremely difficult um and maybe the main bottlenecks ever Us Ever Getting to this final theorem of durability partly because intense in many ways are invariant programming you basically have to well configure your system to check against maybe an infinite number of invariants to make sure you don't break things um and yeah that's not an easy problem um so I think we're going to see a lot of maybe proto-intendent systems that combine transactions and intents for quite a bit and then eventually perhaps after several years of thinking about the problem more we might get to a generalizable intent system anything on that bow yeah since we're talking about intense kind of on a tangent now but we'd love to kind of talk a little bit about the work that a Noma is doing and how we can apply generally at the interoperability level so if you think about the research that they've done to say allow chains to combine or take the union or the intersection of the validator set between multiple chains bootstrap a temporary chain they call it Chimera chains and be able to create cross-chain Atomic transactions if you were able to standardize at the networking level so at the interoperability level let's say IBC everywhere hypothetically speaking and you and IBC were to have access to the consensus mechanism of all these different chains you could about you could apply the ideas of heterogeneous paxos and do essentially cross-chain Atomic IPC transactions across all IBC enable chains I think we'll see some of this but I think it'll take like probably quite some time to to get to this end state all right perfect some of you have talked about a world of hundreds you know thousands of different chains you think we end up in a world where there's like one aggregator aggregating all kinds of different question messaging protocols token Bridges whatever else it might be so how do you force these sort of Education working out well yeah definitely be squared they'll only be one and everyone will use the squid SDK to build their apps and there'll be some squid widgets which everyone uses in all applications everyone all the wallets will have us installed so I I think yeah I mean it's going to be like there'll be a few winners I think in in all cases like there might be if you interrupt winners there'll be a few aggregators it depends what you end up focusing on as well like we we try to not take the approach of you we're aggregating everything we're just doing swaps and then you can pair a swap with something so it's more like a payment Slayer maybe you have nft aggregators and as we find more actual use cases for crypto then they'll be more solutions that might be the winners but um yeah I mean I think aggregation theory that a lot of people talk about either under mirror blog posts or you can look at like strategy is probably going to play out where you see kind of like a power law distribution where there's going to be a handful of short-terrail suppliers for aggregation and they might say they're differentiated but the reality is like from a user Behavior perspective you just end up using the three of them it's like when I get a hotel or like when I want to live like stay somewhere let's say for for ECC I just end up checking like five platforms now they're not differentiating anyway they're just I just have to use five of them to get access to everything and that's fine I mean I think I just have the economics plays out I do have a bit of controvers to take though I do think the intent future or at least intent future envisioning is directly counter to this aggregation future partly because once you introduce solvers to the mix solvers are way more sophisticated than your end user and they will more than likely explore a wide variety of possible different places to get the app that they need to basically optimize or maximize their profits and so we could see a world where irrigation doesn't really take place but we have a fast a number of um well liquidity networks and hooking bridges that people just generally go through from one to one just to make sure they get the best possible profits and these layers will be fighting based off of well who have the lowest slippage who has the cheapest gas fees who have like the fastest times and so on right do you have any Dead bow or yes once again I'm going to talk about the lower layers of the stack while everyone does talks about double layers um I would say that I think at the lower layers of the stack we're going to see some consolidation probably in the 10 to 20 year time frame I know people don't really talk about 10 to 20 years in the crypto space but it's about how long it took for the world to kind of converge on a roughly this you know a consistent networking standard TCP in fact in the early 70s 80s there were a number of proprietary I would say like company owned protocols that were kind of seen as these de facto standards of the time maybe like a layer zero for example and over time they congregated because if if you're you know Apple you've implemented Apple talk Microsoft might not want to implement Apple talk but Microsoft will be a little bit more open to implementing uh TCP per se so I think like the world which will converge to IBC in the long term time Horizon but in the short term we'll see a lot of aggregation at all layers all right perfect so maybe to move the thoughts towards um I think a big difference in some of you and another bridging providers as well is the fact some might be using a state or a middle chain to verify messages some some don't let's say or for example or and others as well what is your opinions on having a state middle chain do you think the sort of crypto Economic Security provides is good or bad some might you know say that or what are your opinions on that so I think the idea of a stake middle chain uh comes with some bandage I think it comes with a baggage of generally these protocols Implement some proprietary question Gateway protocol nothing wrong with that but some other protocol that you know the chain or the team in that owns the chain controls I think having middle hops in network topology makes a lot of sense I think if you want to scale Network topology and you have a lot of heterogeneous infrastructure you do need middle hops that being said I think long term you still want to converge to a to a single standard have middle hops in between obviously you want these to be secure as well ideally you want them to be trust minimized if you can prove the execution of an entire path for a particular packet then you can remove trust minimization trust on these middle hops in the long term time Horizon so I think that the stake matters a lot now but I think as technology advances I don't think it will matter as much for security um I think right now they're tick and time bombs um partly because if you think about it the whole idea that economics will always make it well not profitable for a malicious party to basically exploit those chains but as more and more chains connect to various chains as hubs take like axelr polymer which are trying to become hubs for IBC um it may just end up being the case there's way too much value built on it that like even the validators don't have enough economic incentives to keep the network as robust as possible and the only way that changes is a world where um the like clients they're using for passing messages from chain to chain are no longer necessarily just checking their validators to see if they provided the right signatures and more so running complete State transition proofs of all the transactions happening on those chains and the pretty much you get to that particular level they're no longer they don't no longer need to be valid in um chains they can just become Roll-Ups and do the exact same thing um so yeah I think we're probably going to see a world where all the validate-based networks effectively um start to do the exact same thing Roll-Ups do in order to become robust or very secure or they're just going to employ because the economic security no longer holds and I'm assuming you have some thoughts in this as well I think yeah sure yeah no I agree with you what you guys are saying for sure um it's a temporary solution that will upgrade into a more trustless solution when when the technology gets there but for now we needed we need a solution that we can connect um the like unusual chains into like other networks which are maybe more interoperable with each other like ABC and then you know IBC is developing and like over time it will get get more capable but for now we want to connect ethereum to the cosmos for example so that the cosmos can get some users and and build build up business relationships um I think the economic security honestly is that's a ticking Time Bomb but with the with the number of users at the moment it's more about um I think there are so many other things to be worried about with security and bridges it's you know we've The Nomad hack for example was just at the Smart contract layout in fact I think the Solana hack was was it silent no the Wormhole hack was similar 300 million dollars and it wasn't anything to do with economic security but definitely centralization is going to be the cause of a lot of hacks and rexella having 75 validators compared to say I won't name names but in the five or six range in a lot of cases it's yeah it's completely different and yeah so much heart attack and then these chains become like polymer and axler become have taken a different role in a future where everything is trustless they can be routing hubs they can potentially have um a programming environment where you can build network uh you know Network Logic for specific applications like um gas networks but for example like they're a way that you can program into the into the networking layer and yeah that's it one tiny rebuttal on the on the point of well the number of validators being the main thing that sort of like keeps things alive I do think it's a combination of the holidays and air stakes and when you compare most of the chains that will do have these diverse sort of like values you still find that the states um the stakes aggregate into some sort of like few hands um just because well for the most part you'll probably find that it's probably the team that's running most of the validators on chains like yeah maxillar I do think the bigger point though that stands is um for us to get to a world where we sort of are comfortable with these hubs they're eventually going to have to change or switch to some variant of a light client system that depends almost entirely on state transition proofs as opposed to wealth of validators um that way we sort of like move the security away from the validators and it Stakes to well math and whether we're running the right computations are you in agreement Jim as well kind of um I do think um proof of stake or leveraging Economic Security is not as big of a ticking time bomb as my fellow panelists may think um it's a coordination problem right like let's say you move more economic activity than your underlying stake which surprise ethereum does right it's like that's where decent generation like decentralization matters it's like okay like let's say you're using vanilla tender Mentor I guess Comet bft um they call that now um this is a coordination problem for all these validators colluding actually um you know have a erroneous State transition um occur but I I do agree that um we're probably going to move away from that model um not because it's a taking time bomb but because it's just inefficient right having a committee of validators run full nodes of God knows how many chains right I would say you could probably depending how beefy your nodes are run 200 chains like Which is higher than I think most people would probably say but anything more than that then it's not going to happen yeah so what he's saying is that each of the values would have to run a full node for all the other chains they support yeah precisely and I guess also incentivizing sort of that all that is as well could also be a problem too we've heard a lot about CK bridging I think over the last couple of months and years do you guys have any thoughts on using ckps in bridging making either for trust minimization or for batching block headers or transactions into ckps I'll start mainly because I'm the least qualified so I'll give the most high level opinion about it um I think they're important um I think there's still a lot of open questions on what that looks like um when you have you know heterogeneous proving schemes when you have latency on um you know posting proofs on chain and verifying them um but like what Richard was saying like that is the end state right it's like we can't be verifying the consensus or said differently we can't be snarking um just the signatures of these validators of underlying execution layers but um we need to be actually verifying or proving the the computation of the actual State transition occurring right um I think the solution to this kind of the open questions that I'm talking about is two pieces one is there still needs to be a hub right it's like heterogeneity of all these proving schemes all these different Roll-Ups you probably want an approver aggregator or proof aggregator or like using some sort of recursive proof system in order to make sure that they become homogeneous right you probably still need a router honestly like you can't have millions of chains all talking each other in pairwise kind of permutations right uh and then like what Bo is mentioning snarking the actual path of that packet becomes really important and then on the cost piece I do think optimistic ZK right like I had a tweet I was saying like I think everyone's talking about how off chain is the future uh which is kind of ironic but optimistic ZK is interesting which is where you snark something you don't verify it on chain but you could verify it on chain it becomes like one event like fraud prover kind of setup other than excited for when when they come live and we'll use them but um I wanted to correct I axolotl's team doesn't run any of the validators and it's a permissionless network that anyone can join and run a validator it's that's the big difference between it and say multi-chain which just got hacked a couple weeks ago like which literally like it was an MPC protocol where the the CEO owned all the instances running all the NPC notes which was insane but yeah yeah yeah the state middle chain approach is definitely more secure and uh multisig agreed yes uh on the topic of ZK clients I would say that there's obvious performance issues that you want to work through and you know that will improve over time on the front of proving the entire execution path is something I wanted to drill into so one advantage of encoding some of this network topology on chain is that now you have a subset of the keys that are owned by one to each and every particular path so you can Shard proving of the execution of one particular path and split that separate that away from proving the path between for communication between another set of smart contracts and you can do this on a smart contract to Smart contract basis if you don't have this information on chain it's very difficult to scale proving anything to add on that Richard as well um I don't know how to completely buy that but I think I have to think about it more um but I think um yes likewise will be the final statement of drop ability and I think coming to this event I've realized that a lot more people think that it's further out than it actually is I think most of the tools needed to build extensible like clients currently exist it's just a matter of well assembling things like Lego blocks um and once we do that we should be able to have like clients for most of the I guess popular networks and Frameworks we currently use so if we're in a future where all change support like clients do we just not use Smart contracts at all and just like clients for bridging um no we will still use um perhaps some optimistic system partly because the latency that comes from while proving These Chains um I think perhaps the end state of bridging would be optimistic with like clients for dispute resolution if anything so imagine a world where someone well states that something happens on the same chain and some people just monitor this particular proof and if no one disputes it then hey we're fine and if someone disputes it we check the like clients to make sure that they're not lying it makes more sense given that well until the hardware becomes really good and the proving software becomes really good we're still going to be looking at perhaps three four five minutes um sometimes up to 12 minutes worth of latency for passing messages from chain to chain and um people aren't that patient so yeah I'm going to take a quick second to show the work that we're doing at polymer so so we're working on since we're on the topic of optimistic ZK approach to interoperability and forming that connection uh we're working on optimistic ZK IBC connections at polymer so we have working ZK IBC connections and we're working on overlaying optimistic verification on top and we expect to have that in uh hopefully testing in a few months so yeah cool so we've talked a lot about how we can solve interoperability so in a world a dream world 10 maybe five ten years from now what kind of applications are you looking forward to seeing like what kind of cool applications can you build when you have a thousand seamlessly connected chains with relatively decent latency I think a lot about uh the idea of um borderless Finance where everything that we own becomes kind of aggregated within one single interface irrespective of where it lives and this goes beyond an on-chain context right and so my shares of certain companies that aren't doing too well right now um or my cash assets or my real estate um it's all in the same view as my crypto assets and there is ample liquidity uh in moving between all of those in whatever action I want to prefer and so interoperability obviously is on chain right now but I do think that there is a lot of research underway of how we kind of uh you know rather through the use of of CK snarks or what have you bring real world assets into it as well and uh it becomes a lot more delightful I think to own Financial Assets in the meat space very cool what about you I think um when all is said and done the main product that we'll see enabled by interability will be some variant of a cross domain intent protocol um I think the end state of adorability would be the change themselves sort of disappear they only become a thing that the developers care about very similar to webtoons many ways right only you care about where you deploy your application only you you care about where your software sits um users just care about be them being serviced and yeah until we have that um we're probably not going to cross over that well million or billion Mark that everyone keeps on talking about when it comes to users yeah I agree with that um we just need a a way for people to build projects and be able to add I mean at the moment I feel like the only use case we have is payments but you can imagine also making the web 2 example I'm really excited about um how you can potentially bring AI into the um into the intent system like we've actually built a proof of concept in Squid and we're working with Dora um who in the audience on it and they they've built a thing where you can just they're like a search engine like the Google of um of crypto where you just type in what you want to do and then it goes through the squid SDK and it finds say you just want to Mint an nft it finds the nft somewhere builds the transaction packet so you can buy it from anywhere and you've got your nft so you can potentially imagine a world where you have a Google like just a search bar which is your entrance into getting anything or at least finding an application and then interoperability makes allows you to access that in one click from anywhere I love what everyone said um you know borderless finances is very important some of the early applications in crypto have you know our financial and have priced out some other applications me personally am very excited about gaming I'm a huge nerd and I love computer games so I recently saw a post someone had tweeted about uh having on-chain like ovariant of Warcraft if people are familiar with like real time strategy games like Warcraft Starcraft these are kind of like your I mean AJ Empires as well there's there's a number of them because some of your like classic real-time strategy games but having these on-chain games and be able to prove it is very interesting use case to myself personally I would love to play these games I'd love to be incentivized to play these games as well all right very cool I think everyone is slightly Beyond schedule so I don't think this is correct and I know there's a happy hour outside so thank you very much for joining a great panelist today as well thank you [Applause] 