what's up coordination how you doing this episode of green pill podcast is number two with daniel schmachtenberger we are talking about the metacrisis you should check out episode one of the series that we've done together which was all about what is the meta crisis we're doing a four part series together first one was what is the metacrisis this one is one of the considerations for governance that can solve the metacrisis and then we're going to go into specific web 3 projects and take a look at how they're doing for addressing the metacrisis address the metacrisis not solve the metacrisis so a very brief recap the metacrisis is being stuck between catastrophes and dystopias so basically catastrophes are coordination failures our inability to stop climate change existential risks like biodiversity loss and crispr and nuclear war and runaway agi risk are catastrophes and they've traditionally been solved by creating dystopias governments that are authoritarian and can regulate the uh human activity are usually meant to prevent coordination failures and with daniel in our first episode we talked about how do we build a third attractor so basically something that can solve for catastrophes and coordination failures but without centralizing corrupt systems of governance and surveillance on top of them so looking for a third attractor a governance system that is decentralized but can solve coordination failures you can maybe see where this is going if you've been listening to the podcast for a little while coordination so again four part series what is the metacrisis was the first episode you should listen to that episode but if you didn't i've just given you a recap of what it was about and then we're going to talk about considerations for addressing the meta crisis that's this episode episode number two of our series with daniel and then we're going to talk about web3 projects and how they are solving for the meta crisis addressing the meta crisis excuse me so in this episode we talk about is tech values values neutral what are the values that technology imbues in the systems that it it is within we talked about infrastructure social structures and superstructures and we also talk about conflict theory and mistake theory one of my favorite episodes that we've done so far daniel is just so lucid so articulate he's thought so much about these things and i really enjoyed this episode with daniel schmokenberger the first episode that we did with him was one of the ones that i've gotten the most positive feedback on so far and so i think that you're really going to enjoy this second episode so without further ado coordination i give you daniel schmuckenberger enjoy the opera crypto browser is the world's first web browser built for the crypto community with web3 support and a non-custodial wallet opera lets you access defy apps quickly and easily the opera wallet has buy sell and swap features and of course lets you view your beautiful nfts but the browser still lets you use any crypto wallet extension you prefer giving you the choice and flexibility for the web 3 world opera lets you view and manage all of your assets across all the blockchains all at once and offers seamless multi-chain support between ethereum bitcoin polygon binance strain and other evms and layer 2's but opera goes even deeper than that opera has a built-in home page for crypto natives with the opera crypto corner with price charts news feeds nft updates to make sure you are always on top of your game and it even has discord and telegram integrated natively into the browser that's crazy opera is truly building the battle station for the crypto world check out opera both on mobile with android and ios apps and on desktop too refi summer has arrived and cello is here for it cello is the layer one blockchain for the regenerative finance movement it's fast planet positive and built for the real world cello has committed towards producing a sustainable future from the very beginning and is the world's first carbon negative evm compatible layer one blockchain cell has become much more than a technology a currency a community or even just a layer one cello is a movement to create conditions of prosperity for everyone you can soon engage with all of this via green asset uniswap pools on cello benefiting reforestation and other regenerative products through the toucan protocol moss and more refi is also about the health of communities and resource network is creating bankless infrastructure for circular trade and mutual credit networks to benefit small businesses and local economies all on cello follow along on twitter to learn more about how cello is accelerating refi summer for a positive impact on people communities and the planet if you're attending ecc visit the cello saloon to learn about what's happening on the front lines of refi from industry experts hey daniel thanks for coming back excited to be back yeah likewise i so we're doing a three or four part series together the first is what is the metacrisis this episode is gonna be about the considerations for governance that can address the metacrisis and then we're gonna in the next episodes get into addressing the meta crisis possibly with web 3 and web3 based systems so let's maybe dive in on considerations for governance that can can solve the the meta crisis how do you think about about that design space yeah and i think most people who are listening to this and working in web 3 are probably not thinking how do we solve the meta crisis meaning how do we solve civilization writ large but it is important in whatever area you're working on to understand how that relates to the other areas you aren't working on in the context of the world and if we if we if you're working on some other area and nuclear war starts looking more eminent you might be like oh that that's that is relevant to the topic that i'm addressing and so obviously we happen to live in a moment right now where uh nuclear-equipped superpowers are in actual armed conflict for the first time in a long time and climate change and ai and biotech and all the other things planetary boundaries and stuff we talked about so that can't not be part of the context if you're thinking forward kind of at all and uh and i know that here the reason people are with you at git coin as opposed to other places in the crypto world is the topic of public goods which is where does the economy where do the incentive systems of the economy not rightly orient us based on both the ownership and the kind of incentive for extraction and externalization built into currency not rightly orient us to solve certain problems and where do the structures of governance not readily orient us and can we build a political economy meaning can we build an economic system whose incentives are more aligned with the actual world we want to bring about and where the governance and the coordination are more aligned and so that's why we started with the big picture we did last time and then this time it's definitely not like here we're going to give all of the necessary and sufficient criteria for how to design a political economy solve civilization like we're not that's more ambitious than what we're going to do but there are a few high-level frameworks that are really important particularly for technologists who are thinking about building coordination technology right like how do you actually design technology that can mediate economics and mediate governance so we're going to talk today about things like the intersection of technology and basically our kind of text accurate large and our social systems and our value systems and the world we're embedded in and what are some of the ways that those connect that need to be factored into the design of the tech to have it facilitate the right kinds of things so um yeah just kind of calibrating i i know there's a bunch of interesting projects happening and can we do a better job with governance if we apply quadratic voting or this type of dow structure or whatever and in the next talks we'll get into specific things there and so here i just wanted to share a few more kind of structures of thought that are important to think about at the intersection of the tech that mediate social systems this that's one of the areas that's so interesting is for the most part what a social system is trying to do is to uh actually help the coordination and regulation of tech right and yet the tech that is mediating the social system itself is a unique class of tech it's not um mining even though that term gets used i mean it's not mining of the physical substrate of the earth it's not waste management it's not transportation it's not the other things where you need to be like oh maybe we need to regulate that to not have certain destructive purposes it's what is the tech that would facilitate a social system that would in turn regulate the rest of the tech so it's a very interesting class of things so uh yeah that's what i'm looking forward to getting into today nice yeah i mean i think that i got a lot of positive feedback about the first episode just people really enjoying the framing of the metacrisis as catastrophes and dystopias and how do we find this third attractor towards something that um can solve coordination failure but doesn't have the centralization and maybe the like the corruptness of of of the centralized government and and i re and i really uh i'm just i'm just so happy that we're kind of starting to drill down for considerations that can address the meta crisis and appreciate you saying that we're not going to solve civilization we're not going to address the meta crisis here but it's it's a useful thing for builders to have in their back pocket as they're moving forward in in building this technology so um you know it feels like a great place to start might be is the technology that we're building does it have values embedded in it is the is the tech values neutral in any way or does it create a slant in the social systems that we're creating in this space in some fundamental way yeah obviously um partly this question arises because we just published a paper on this with consent's project and sent it to you and i think it'll get linked in the show notes here and uh yep the title kind of gives it away technology is not values neutral um but here what we're looking at is the way that technology affects psychologies and then affects cultures um we could also look at how it uh affects social systems but just to kind of let's just zoom in on this part about um does tech embed values and does it affect values directly so think about this you put a camera around your neck it's a technology right it allows you to take things in your visual field and capture them as pictures when you have a camera around your neck or in your hand it affects the way you perceive the world and it affects your intention because it extends your actuation capacity in a certain way you can now make photographs so all of a sudden the little piece of grass growing through a crack on the sidewalk that you'd have never noticed or thought of maybe that's a weed i gotta get rid of now you might think of zooming in and seeing this beautiful picture of the tenacity of life going through you know the anthropocene or whatever it is and so and the birds all of a sudden get more interesting and so you can see how literally just holding a piece of tech changes what your attention is drawn to and kind of the meaning that is made on it and then what you do similarly if you're walking through a forest and you have a spear you have a whole different set of attunements than if you don't have a spear right if you have a chainsaw trees mean something different right the moment you're walking around a forest with a chainsaw versus you're walking around with tree climbing shoes trees mean something different and so it's important to get that you could say oh tech is value's neutral chainsaws can be used to cut dead timber and support the forest or to cut live trees it's the values we bring to it kinda but that's also really just profoundly naive simplistic thinking tech increases our capacity to actuate that's right it's an extension of our actuation capacities and it might be an extension of our sensory capacities like a telescope or whatever but um and we can connect that all but i'll start with the actuation side there's a way that evolution selects for our sensory processes what we take in about the world our sense making how we make sense of that to inform choice and then our actuation process being in a closed loop right evolution only selects for the closed loop between the information input information processing and actuator output because if i evolved some capacity to act but i had no ability to have sensory process informing it like it doesn't matter how high i can jump if i don't know when i should jump or towards or away from what right so evolution would never select for that evolution would also never select for a sense that i couldn't actuate like oh i can see something that's going to harm me but i can't do about it like so evolution is only selecting between the relationship between those so of course if you have some new actuation capacity it's going to direct your existing sensing capacity to pay attention to the things that can be actuated right and so obviously the chainsaw and the tree climbing shoes are going to give you a very different sense of trees and um just to give one good example and the reason that i'm going into this in a bit of depth and why we actually took the time to write a paper on it is um there is no metacrisis without tech right like cavemen cannot destroy the world chimpanzees polar bears or cause other apex predators can't destroy the uh environment and you can't destroy the world even with stone tools and even with bronze age tools you have to get to industrial and then post-industrial right and once you get up into nuclear and exponential tech you kind of can quickly and you almost kind of can't avoid it if you aren't being very careful because that much power especially driven with embedded growth obligations and and multipolar traps and stuff makes it very likely so ultimately it's not that tech itself is the problem the tech is extending human capacities for choice we're making choices that are problematic but it's not just extending our capacity for choice it's also predisposing it and so it's important to understand any solution to the metacrisis is going to involve a fundamentally different relationship with tech and it's not just that we need to bring better values to how we use the tech we need to recognize that the nature of how the tech is designed affects the values of the people that are involved so obviously a news feed that automatically selects for maximum social interaction score and time on site is going to outrage and polarize and appeal to shorter attention spans and do all that it's the way the tech was designed now that doesn't mean the tech called network based media had to do that you could design it differently right you could design it where it used uh the same types of capacity to see what would have super majority support and up regulate that in the news feed it could specifically put in front of you the things that were most likely to connect you to people outside of your existing network clusters and across mimetic tribes but that's the tech design right the tech design will predispose patterns of human behavior so i want to go a little bit deeper in this because this is a group of tech designers and the way that tech affects the world and creates kind of these recursion loops is a critical thing to understand so at first you know we we design technology for a specific purpose and it's usually a fairly narrow purpose there's one problem we're trying to solve or maybe a cluster of two or three problems we're trying to solve the word externality is a word that is now pretty well known it was what was not previously but it typically means it started with economics right the idea that your value equation had um revenue and expenses and there was profit but there were some of the expenses some of the costs that were externalized to the value equation meaning if i treated trees as a natural resource i didn't have to reproduce the trees i could just extract them from the balance sheet of the commons because the commons didn't have a balance sheet right and i can turn into pollution in the balance sheet of the commons but basically i was just stealing from nature's balance sheet it was an externalized cost where if i actually had to pay for the real cost of that waste and pollution to be processed in the unrenewable resource the cost of the thing would go way up um and so that's the idea of externality in economics and it's related to externalities and tech right externality in tech is you're building something for a purpose but it affects other purposes that you had not planned for and that's where you get an unintended consequence or side effects obviously when facebook made that algorithm choice to maximize engagement for advertising revenue it wasn't trying to polarize the whole population and break democracy and make people believe crazy stuff but it did that was an externality of the design of the tech so one of the things that i want all technologists in every field to be thinking about particularly those working on the most fundamental technologies that could support coordination meaning like the actual choice making of everybody writ large is to be thinking about the externalities in their design you're designing it for these purposes what else will it affect that you didn't think about how do you think about that better and then how do you notice it afterwards and internalize that into the process the first type of externality that people are used to is a physical externality physical externality is you make a pesticide that is intended to help crops uh and it ends up killing all the pollinators and going into the water and messing up ecosystems and that kind of thing right it's mediated via physical causation you make a laptop that's easier to carry around than a desktop and the externality is everybody gets bad necks from looking down all the time because of the ergonomics built into the portability right and so physical causation creates physical externalities but there are also psychosocial externalities and psychosocial causation and that's the topic we kind of introduce in this paper that i want to intro here which is it's not just the physical tech will do a physical thing it's also that the tech will incentivize humans to behave differently because using that tech in a particular way confers advantage that not using the tech doesn't confer so it's actually tech is a incentive to behave in the way where the use of that tech confers advantage in changing the pattern of behavior you end up changing the encoding of human mind and that's where you have a psychological effect and if that starts to happen at scale you have a social effect and so we can obvi we can see the most obvious examples of that with you make a social media thing where the more likes people get the more it gets up regulated you start to put instagram filters on it and you get the psychosocial effect of an entire culture becoming more body dysmorphic and narcissistic well it's kind of clear that you do actually like you can breed narcissism and body dysmorphia in the entire  population literally because of the design of the tech right the combination of the incentive and attention capture and the picture emphasis and the like that's that's pretty bad like the amount of effect it had psychosocially that quickly compared to the amount of psychosocial effect that any religion ever had it just dwarfs it rightly no meme otherwise outside of the tech could have spread that much change to psychologies and cultures that quickly so um but there are ones that have done it that deeply because they were very significant they just uh as tech is accelerating obviously the um meaning as tech is getting to bigger scale and you can create things like facebook that become dominant in a very short period of time relative to say the internal combustion engine or something else the effects are faster and bigger but the example i want to give because it's so illustrative and the way i'm describing it simplifies a lot but it's because it gives the gestalt of it to the plow i want people to think through the example of the plow because we can talk about the printing press the printing press kind of ended feudalism and ushered in everything from science to modern education to democracy because now it didn't cost the equivalent of a hundred thousand dollars to copy a book of someone having to do it by hand who had a very rare skill set everybody could have text books everybody could have newspapers everybody could have their own bible so the lutheran revolution we didn't need the priest to interpret the limited bible for us so we can see like wow that was a technology that this radical effect right and so the sovereign individual and biology and many other people are looking at the way the current info tech will usher in new social changes the plow is such an interesting example because it wasn't just that it changed our social structures but our cultural systems in a way that the world is is still so fundamentally influenced by and to just think about it and before we had the plow we had other agriculture we had horticulture and using digging sticks and the plow was not equal in all environments some places that used horses or donkeys that were also used for transportation are different than the places that used buffalo that turn into aux but let's just simplify it and say the moment you can start to convert in animal's capacity they can eat food that we can't eat grazing and whatever and then they can do all this tilling and they can convert a whole area to food production uh the plow meant that the caloric output the culture that was using that could do compared to hunting gathering or just the human labor digging stick was so much greater that of course the moment that technology emerges it kind of starts to become obligate because the culture any civilization that uses it stops dying in famines and they grow their population way faster with the caloric surplus which also means that any other puppy any other culture that doesn't is a lot more likely to lose in tribal warfare um with a smaller population and things like that so that's that's actually one really interesting insight is once if a technology confers a lot of capacity it also converts in theoretic advantage in a rivalrous context so if anyone uses it everybody has to use it or some comparable thing or they lose so there's a way in which text starts to become obligate it doesn't assume that exact tech but it means some the tech stack as a whole has to be competent to be able to deal with the rivalry of other groups and so um so some types of changes do become obligated obviously if you uh any group develops a new piece of military attack it does obligate the other militaries to do something in response um [Music] so we see that the plow kind of became obligate because it made so much more food production capacity um but then you also see that and this is the thing that i think is so interesting about this example if i have a animal let's say an ox that is being used to draw the plow it doesn't want to do that right so we have to yoke it meaning put the plow around it and then beat it all day long to do that thing that that requires me changing my value systems around animals so if you look at hunter-gatherer tribes around the world in any continent they were pretty much all animistic they talked about the spirit of the whale the spirit of the buffalo the spirit of everything they uh were cognizant of the great cycle of life that maybe they kill the buffalo now but they'll be put into the ground when they die which will great grass and their ancestors will eat it and that whole kind of thing so they could have a sense of the sacredness of the other life and be part of the cycle of life but i can't be animistic anymore if i've got to beat the buffalo all day long right yeah all day long so now it's like then the memes change from the uh men are not the web of life we're merely a strand in it whatever we do to the web we do to ourselves in the great circle of life it changes from that to man's dominion over nature the animals were put here for our use you know that kind of thing and of course it's just a dumb animal it's different than us it doesn't have feelings it's not that different from that to slavery identify a difference remove empathy and see other sentient things as utilities for your advantage and then a whole kind of cultural system that sees everybody else as a utility rather than a subject to various degrees so so interesting as you can see that the introduction of the plow actually ended animism changed value systems to a more utilitarian relationship to other sentient things the plow couldn't be run by women because it required more upper body strength and women would miscarry when they were doing that and so uh men were now hunting and doing the plow the gods changed from male and female god distributions to largely um all just male god distributions this was covered in ken wilbur's sex ecology and spirit that has little footnotes in there and um and then it gave a huge amount of surplus more the type more surplus than there had ever been which started to lead to more capacity for wealth inequality and needing to formalize ownership rather than the tribes of the larger populations plus the ability to store huge amounts of surplus started to mean wealth inequality and all the things that came with that which started to mean hierarchical organization like wow everything from the commodification of nature to changing whole ecosystems to turn them from forests to row crops so the beginning of the anthropocene to patriarchy to um extreme wealth inequality to hierarchical governance systems were the side effects of a technology that met some seemingly good purpose to feed the people and so then you're like wow okay how do we really think through if it does a thing and it then for the people to do that it has to code patterns of belief that go along with those patterns of behavior um and then it's not just one technology because then you have to have the baskets to store the grain and you have to have the threshers so it's also part of an entire ecosystem of technologies every you get a you get a laptop but then you also need the external camera and the modem and the satellites and the whatever right all those things so technologies emerge in ecosystems the whole ecosystem of technologies ends up predisposing a whole world so this is the topic of a psychosocial externality that the technology is affecting our psyches inexorably all the way from what we pay attention to to what we value to what we believe is as real and this is where what i want people who are technologists to think about is the physical externalities i.e how much energy does it take to run the ethereum world computer and how does that affect climate change and all that stuff physical externalities but also the psychosocial externalities and internalize those externalities into the design process which means if we build a tool that that provides some advantage where people using that advantage are behaving differently how is that coding minds and then how does that code cultures and where does it do that in ways that might be destructive and how do we think through that better and then design better right you know one of the things i think is most interesting about this is that i kind of grew up or maybe wanted to think that our our values are what's designing the technology but the way you frame it it almost feels like we're rationalizing our values to fit the technology that has the the the the evolutionary advantage or the economic advantage in the web 3 space so this is half true and now we'll move so um if people haven't read marvin harris cultural materialism it's really uh important and great work that basically says what you just said like the the thing that really obviously changes as new technological capacities those technological capacities required and they both enable and require changes in social systems and ideologies and cultures but the other ones are always playing catch up to the tech i don't think that's true that's what he's arguing there i think it's a part of the truth i think it's true that we can use culture to shape the way we do tech it's also true that tech in turn shapes culture so it's a recursive process and you can have kind of virtuous or vicious cycles but one way of like this is a real politic kind of assessment but the the dominant ideology or the dominant narrative of a culture is the apologism for the power structure of that culture right it kind of has to be and so of course if you have a crusades that are spreading christianity around the world um including with violence and destruction other cultures it also happens to be making certain kings and emperors very profitable and have a holy roman empire that covers lots of territory or whatever um but everybody feels good about it because the belief system of we need to spread christendom because this is what god wants is good apologism today it's like techno capital capital optimism in um you know pinker rostling gates et cetera sense that tech makes things better and capitalism makes things better so keep doing more of it obviously that's the winners of the current system making a value system where the thing they're doing is the right thing to do and everybody should want to do more of it so um so i would say critical theorists are kind of very attuned to is the dominant narrative just a trope for the power structure and um if so who isn't well tended to by that power structure which is why typically this is why the justice movement is actually um an epistemic and a design movement too it's it's those who got most marginalized marginalized and  by the system who are mo the most capable of seeing where its narrative is lying um or if not lying at least missing something not true so then they can be like oh this looks more like apologism for power dynamics and it does like a clear assessment of how a civilization should ideally work and so then that has the ability to either just try to tear that system down or hopefully offer a critical perspective for how to improve it um and so what i hope happens here is as people are looking at how do we design fundamentally new political economies it would be how do we make sure that every stakeholder human and non-human life that's going to be affected by the second and third order externalities the physical and the psychosocial ones how do we make sure that we're in conversation with them where their fac where their perspectives are being factored and we don't get that it's an ideology of winners in something that is also creating losers and externalizing harm and so yes it is true that the generally the values we have are justifying the use of the tech but it can also be true that we can have a value system where we're like no there's something we really value we want to codify law to actually bind tech and not use it in a particular way right we actually don't want to let the chainsaws and whatever logging technology cut down the national parks so the values of the people are going to uh instantiate wall that then binds the technology and the private incentive from not doing a particular thing that would be an example of the causation going the other direction and um or like weapons ban even though the text can do the thing we actually have a value system where we just don't want to let that thing happen um so now this comes to the framework that marvin harris put forward that i would like to just um making it a little modification of he following kind of marx's analysis even though wouldn't come with marxist he said you can think about a civilization in terms of three major ways of kind of dividing it that all necessarily interact what he called the infrastructure the social structure and the superstructure and the infrastructure was the the whole tech stack by which the people did the things they needed to do and all the needs were mediated so the modes of production transportation waste management energy all that stuff and obviously if we're talking about a hunter gatherer tribe they have a tech stack they have spears and they have tools that are used to be able to make spears and they have storage vessels and they have shoes and they have clothes for the to be able to be adapted to environments that they weren't biologically adapted and they couldn't operate without that tech stack right and as soon as you move to a agrarian culture you have a plow and you have yolking devices and you have fencing technologies and you have storage vessels and you have whatever all these types of things so um that's infrastructure the social structure is the collective agreement field so governance law economics primarily the and the institutions that mediate it and the superstructure is basically the values of the people the religion the ideology the um how do how do we do meaning making of what the good life is that we want to orient towards and what marvin harris was kind of structuring is that the changes in infrastructure drive changes in social structure and superstructure that without a printing press you couldn't have had democracy because you had to have everybody be able to have access to a newspaper and everyone have access to textbooks and be educated um and that not only was that capacitating for democracy but it was also destructive for feudalism where the concentration of power in that way also required the concentration of knowledge where that new tool changed it and it's interesting to see that where the printing press uh that was a democratizing force it gave everybody access to something that only a few had after a while it also became an even more powerful centralizing force right where you have these few major broadcast stations they could now broadcast information at a much wider distance than anybody had ever been able to for larger populations you see that with the internet it was like everybody's ability to upload their own video is going to be democrat this massive democratizing force and get over broadcast consolidation except when there's a billion videos on anything the video player that can put them all in one place and determine which ones i see ends up becoming that is what sorts it so youtube and google and facebook become the new centralizing force that are even more powerful than the biggest broadcast media station was before in general all tech all major changes in tech tend to be decentralizing at first because they they break the existing power structure and then they tend to become centralizing over time because some people are better at it than other people and you they get these recursive loops of the better that they get um and so to say any tech is inherently decentralizing you've got to think through that really well so what i would say is that infrastructure social structure and superstructure all three inter-affect each other if you if you changed the economics fundamentally where certain costs had to be internalized into the cost equation certain technologies would not be profitable to create and they wouldn't proliferate and other technologies would be profitable and they would proliferate if you make law that bound certain things again certain types of tech wouldn't proliferate and other ones would if you change the superstructure of what people actually want and what they're willing to engage with uh it would and so we're not saying that the value systems and the social structures can't guide the tech we're saying that the tech also in turn changes them so what we want is people who have a more inclusive value system that's starting at the level of superstructure to start to design and build technologies where the other people's use of those technologies will also support the growth of those same values and where the social structures that get created how does the law work how does the economics work in turn are also aligned with the proliferation of those more inclusive values beautiful um you mind if i recap for a minute please cool so been taking some notes here uh from the top tech increases our ability to actuate uh and also to sense so we're all in these kind of like ooda loops observe orient decide and act and tech increases our ability to observe and to act um but tech doesn't just enhance our ability to do those things it also kind of slants by embedding our values into things it affects psychologies and cultures so there's physical externalities so if i look at my phone i'm going to hurt my neck psychosocial externalities tech is an incentive to like tech has an incentive to use it which confers an advantage and then it becomes compulsory uh the other psychosocial uh externality that i wrote down is body dysmorphia so like outrageous the facebook example that uh it's designed to keep me on site longer and so that creates an algorithm that as a side effect creates more outrage that polarizes the population so for myself and the web3 ecosystem as uh systems designers we want to think about externalities both physical and psychosocial um and think about how to confer an advantage to systems that solve the meta crisis um in order to make that kind of tech advantage um especially in a network age in a high-tech age where the question is existential sticks and stones may break my bones but they're not going to blow up the world in a nuclear catastrophe so uh the the how big the the problem is has gotten bigger with with bigger and bigger tech so to me this uh leads to this question of like what does the internet do and what does ethereum do how does it code minds and how does it code cultures and and how can we in conversation with everyone in the system both humans and nature as we're designing a system that can build and and and solve the metacrisis and then of course infrastructure social structure and superstructure are all intertwined if we have values of building and funding digital public goods solving coordination failures those are the people who should be building building this infrastructure uh those are all the notes i wrote down i don't know if there's anything i missed or is that directionally was a good recap okay cool so uh where should we go next i think next on my notes i have conflict theory and mistake theory to get into next but i'm curious if there's another uh place you want to go yeah let's come back to that i want to do one more piece regarding this unique category of tech that is the tech that the the aspect of the infrastructure that mediates the social structure so notice if we say what is the technology that enables facebook and obviously whether we're talking facebook or tick tock or youtube or whatever they there are certain things that are in common across all of those but it's not it's not video player tech it's the ability to take my online behavior when i'm particularly when i'm on platform and record it record my mouse usage and click patterns and stuff like that and then be able to have ai do pattern analysis for pattern prediction and then have it be able to give me split tested stuff to be able to up regulate its pattern prediction to be able to develop a predictive model of behavior that is fully personalized and then be able to put specific pieces of content in front of people to affect their behavior in specific ways all driven by a profit motive in which the user is not the customer the user is you know ad sales and so the customer uh being engaged to spend more time on site engage with the content more so that more ads come across them and the right type of ads come across them is what that data is being used for and so we can see that like of course at the superstructure level human belief and values and emotions and identity are going to be conditioned by what we're paying attention to you can't pay attention to stuff and have it have no effect on the nature of your mind and our experience and this is why you know every culture has some version of a statement like you become the average of the five people you spend the most time around and the mimesis of learning we learn language simply by watching we also learn belief systems and all those things by watching what we're surrounded by so if i can't observe the world because there's too much of the world so now i'm observing a subset of the world that is customized for me that i am i can't not take as the world right because it's what i'm actually taking in and it happens to be being customized for me um based on things that will commodify me yeah and it happens to be that my emotions commodify me better than my rationality so it will appeal on those things and my identity being part of an in-group will commodify me better that the design of that tech meaning the incentive economic system plus the way that suite of technologies are used is changing culture it can't not it can't not change culture and the one thing i'll add here is that we're talking about a a super computer that is trained on hundreds of millions of data sets and it's pointed at our brains when we're using these essentially so we're way outgunned it's like a hot knife through butter and changing our attention yeah we already were saying as far as the kind of like voluntaryism idea oh it's the market so you don't have to buy the thing it's just a gibberish argument one it's like saying do you have to use dollars well no i could try to just barter right like but i'm going to be so radically disadvantaged that i and since there's a monopoly on the creation of currency i pretty much have to participate with that monopoly if i want to be effective at all when like you know when like do i have to use the telephone lines when there was a t ran all the telephones like pretty much i do if i could so to say that i am voluntarily engaging if i don't have an authentic choice to still be viable in society if a small business doesn't advertise on any of the major platforms it's pretty hard to be a viable small business right and then as we were mentioning with the plow case if any civilization starts making if any other country starts making ai weapons do we really have a choice not to yeah not really right we're probably going to do that thing because otherwise we kind of obligately lose so it's important to understand that the voluntary voluntaryism argument is there's a lot of places where we would pretend it's more true than it is um so if tech confers a bunch of advantage some people will start using it and then that will be used for conflict theory and then it does require the other people to either use that or some comparable thing or they stop mattering and um and so we come back to the facebook thing you were saying you know this is this huge uh ai super computer directed at our brains um now we also have a situation that one we don't really have the capacity to choose to not engage with the whole suite of those technologies and still be effective at certain domains of society and then the other thing is that it's like saying well it's voluntary whether or not we engage with ads and whether we purchase a thing i don't actually get a choice in those environments whether or not i'm exposed to them nor do i get a choice of if my personal data is harvested and used with ai type dynamics to compel me to do that thing and the asymmetry of it is so  much that it's like okay this is why we wrote in that paper about the topic of undue influence now that was actually a different paper in the constraints project where we talked about that undue influence of like someone is choosing something but they're under some type of cult mind control or like why it's not okay for a professor or a therapist or a priest to be in a relationship with someone is the other person really there's so much power asymmetry they can't consent adequately that even if they're consenting um the asymmetry of power messes up the integrity of their consent yes that's we'll link that article in the show notes i just found it put in there so um you know we would propose that if information about you that enables from your behavior that enables a platform to predict your behavior better than your wife or therapist or lawyer could that that is privileged information that does enable undue influence that that needs to be in a fiduciary contract a principal agent binding contract where whoever is using that is using it for you not in any way against you and so that would mean that those tech platforms had to actually have a fiduciary relationship with you the user to only use that information aligned with your interest where you had full visibility in settings and could change all of it um that would of course require a change of business model probably where you were the customer or the state that is representing you or the commons that is represented is um so as we get into tech that is more powerful the asymmetry of those who are using it relative to everyone else also becomes a bigger deal and that affects the nature of social systems radically is when there's such radical asymmetry of information processing can you really still just say buyer beware when the buyer can't begin to deal with weight all of the things uh that the other side that's using an ai and we're not can factor right does this get into to sort of like the political theory in such a way at least with the facebook example where facebook's management is optimizing for the shareholders instead of the customers and so no it's optimizing for the customers as well it's just the customers of the advertisers not the users right that's actually the point is that the users should be the customers well i guess what i'm getting at is like there's this idea in political theory that the consent of the governed is the only legitimate basis for governance as opposed to like the the divine right of kings and what if the facebook users were owners of the platform and had you know like management had to to sort of like optimize for them in in a little bit more of a like you said a fiduciary obligation kind of ways like that's very sweet otherwise the people are actually the thing being extracted from like we used to extract from nature now we're extracting from human minds the particular kinds of behavioral predispositions we want for the extension of power um but should facebook have the customer the user be a customer yes but should it go further should it actually be a public good and um that if it is if it has that capacity to affect human behavior at scale what the should drive that right and this well and should everyone should the consent of the governed have some say in the governance of a thing that is going to have ai's pointed at their mind and so then you're like oh well it should be a dao of some kind and then you're like well isn't that what the government should be and now that it's not 1776 technology with a town hall but can we actually similarly have a process because when you say the consent of the govern what you're saying is that superstructure needs to be the basis of social structure right the social structure law specifically if it is not an instantiation of the will of the people it will be tyrannical for it to be an insensation of the will of the people then the thing that really matters is not only how do we actually listen to what the values of the people are but how do we make sure we're developing people that have better sense making and and deeper and richer meaning-making um so that the because the will of a very uneducated xenophobic audience is not a great thing which is actually why kings made sense in low development environments um so how do we develop superstructure to have an increasingly considerate population and then how do we have that creating the laws that both utilize and also bind guide and direct the technology and i would say what's happened is we've got exponential curves in infrastructure during the digital age but we have not got exponentially faster governance or exponentially faster growth of morals virtues and epistemology and culture and as a result the effects of infrastructure influencing the other ones have radically increased and the effect the integrity of the social structure influencing or of the superstructure the culture influencing the social structures to bind the tech has radically decreased and got hollowed out and i would say it's that direction from the values of the people from the superstructure to a healthy social structure that has the ooda loops that has the capacity itself to buy and guide direct the technology to be in service what the superstructure wants it in service to what the collective will of the people does that is the critical direction that we must increase to make it through meta crisis so that means we have to be both thinking about human values and and how we support the proliferation the development of human values how we encode those in our decision making systems and how we make sure that our tech is not only bound by those decision-making systems but that the use of the tech that the psychosocial effects of it are in turn in service of a enrichment structure immutable x is the layer 2 platform for crypto gaming immutable offers massive scalability with up to 9 000 transactions per second an instant transaction confirmation no more gas fees no more waiting around for your transaction to clear immutable's zero knowledge roll up finally unlocks the world of crypto gaming immutable x is the only gas-free nft minting platform with over 26 million nfts minted all with zero gas fees with the power of immutable gaming developers don't also need to become smart contract developers they just need to plug in to immutable's api and instantly start unlocking the full potential of crypto assets inside of games this is why world class companies and projects have decided to deploy unimutable x like gamestop ember sword planet quest eluvium tick tock and many more behind the scenes so start building your game on immutable x two day at immutable.com coinshift is a leading treasury management and infrastructure platform for dows and crypto businesses who need to manage their treasury operations every crypto org needs to manage their treasury and coinshift offers a simple flexible and efficient multi-chain treasury management platform built on top of the extremely secure gnosis safe with coinshift your organization can go from primitive single-chain treasuries to expressive flexible multi-change features such as global user management global contracts proposal management and many other features that can be shared across an entire organization coin shift layers on powerful treasury management tools on top of the proven security of nososafe allowing users to save time and reduce operational burdens and gas costs coinshift even has data tools like account reporting across the seven chains on which it operates used by industry powerhouses such as unit swap grants balancer consensus and missouri coin shift is speeding up the coordination and efficiency of the organizations that use it in d5 you have to keep up with the frontier and coin shift makes that easy so sign up at coinshift.xyz bankless so let's go into conflict theory and mistake theory next uh curious curious to pull that thread yeah um so we're talking about externalities and typically we think of an externality as a mistake we didn't intend the laptop to hurt people's necks like that wasn't a built-in thing it was just an unforeseen consequence or something that we yeah and um similarly nobody intended climate change they intended to build their businesses and their businesses required energy and the cumulative effect of everybody doing that cause climate change so we think this is not like an intentionally created problem it's a problem that is a byproduct of solving some other problem and um but obviously there are places where somebody causes harm because they want to invade that area and get access to those materials or that um port or that whatever it is or they so whether they are initiating conflict on purpose or uh or at least they know that it'll cause harm and they don't care right maybe it's the intent or i don't care so there's a there is a blog post on the les wrong blog i think with this title conflict versus mistake theory and it's a subset of a very large conversation and um kind of social theory about what percentage of the problems in the world are the result of simply not being able to factor all of the second and third order consequences and what percentage of it are the result of uh things that are being in initiated knowingly uh i think the article does a good job of discussing considerations on both sides but the thread is particularly interesting of comments afterwards um michael who's a very interesting thinker in there specifically uh goes into that the existence of mistake theory ends up being used as a cover for a lot of things that are actually conflict theory meaning that we can knowing that i can say later oh that was an unintended consequence we could have never predicted it i can hide the fact that i actually knew that thing was going to happen or at minimum not try really hard to figure it out because it's against my incentive to try to figure it out so then i have i have mistake theory as plausible deniability that i didn't intentionally do a up thing yeah and so i think when we're thinking about tech design and social systems we want to think about conflict theory what is the underlying basis of what gets humans into conflict with each other individual humans groups of humans and humans as a whole with the environment and how do we resolve the underlying basis of conflict and obviously um economics is very core to that it's not the whole of it um marx says his analysis of conflict theory gerard has his analysis if anyone wants to solve any of the problems of the world that's one of the things to go deep on is what are the various things that initiate human conflict and what would it take to create a system that addressed those more fundamentally um not just conflict mediation but conflict uh conflict generation mitigation how to mitigate that um and because the mistake theory part we can do a much better job procedurally of that if we had the incentives um meaning if we had the motivation incentives and deterrence and intrinsic values so uh can we predict all of the effects of a new tech no of course not can can we do a much better job than we've ever done easily and so can we predict all the effects is the same as predicting whether a ways out in complex systems you end up not being able to predict beyond a certain point um but uh for instance just even thinking through with a framework like physical externalities and psychosocial externalities and getting a group of people that represent different stakeholders that would be touched by the system and they represent different expertise and just say let's think through all the possible externalities based on patterns of the of human use using this and based on the supply chains that it'll take to make this thing happen all of a sudden we anticipate a lot of stuff we wouldn't have anticipated and then we say well if those things happen what are the externalities those produced to get a third order right and so then we start thinking about that and saying how could we design it differently to internalize that and similarly thinking about something like the relationship of infrastructure to social structure and superstructure you get to start to think well what are the effects of this on the systems of human governance and social structures what are the on the superstructures and obviously all of that is embedded within the biosphere what are the effects on the biosphere so these are frameworks for being able to consider externalities better then of course there will be some things that you didn't predict so you want to create monitoring systems and you also want to create tests right how do we test this at a small scale what we call a safe to fail probe and dave snowden's terms and um then be able to observe what are the things that happen including stuff since we don't even know what to predict how do we make just very kind of wide observations and notice new stuff that starts to emerge and then be able to factor that but then of course what we need is that let's say we make it technology and it's off and running and we did all of our good upfront assessment we still need to be watching what are the other things that it does and we also even want to be incentivizing a decentralized intelligence to show us unintended consequence right and then we'll need to figure out how to solve that in terms of a recursive design of the technology or a design of the social system i.e a law or something that will affect the utilization of the technology and then we have to actually be able to enact that so you can't move from the tech designers to now the you know ceo and board of directors have a fiduciary responsibility to maximize return on shareholders and it doesn't matter if you create an externality you don't ever get to change it so you actually have to build into the governance protocol of the thing the ability for ongoing recursion that internalizes extroverts when they're found but the underlying reason not to do that because procedurally what i just said is not that hard no it doesn't it it's not obvious but once you hear it it's kind of obvious um and it's not perfect but it's like so many orders of magnitude better than what we do um but then you're like okay well the other issue is the conflict theory the the perverse incentive so let me explain the perverse incentive that is underneath much of the problem here is that i'll specifically talk about market applications there there is much more incentive to focus on the upsides of a technology than the risks there's much more of an incentive for a technologist and a funder and a lawmaker and a politician and whatever who can bind themselves to those upsides right so let's just say for the technologist if i say oh we're going to make this ai thing and it's going to like do protein folding and solve all these diseases and do all this amazing stuff and everybody wants it for those reasons yeah well but what about all the risks of the really terrible things that'll do oh no it's not it's not going to do those terrible things of course whoever focuses on that moves faster gets first mover advantage in the market gets the race to network dynamics you know massive adoption of their thing whoever goes slower to say hey wait we're not sure we're in this protracted process of anticipating second and third order negative effects and we found a bunch and we're internalizing those into the design so we're iterating the design a lot those people just get out competed by the other people who just rushed to market so the the incentive is to pre is to not look for where it's going to harm things or to do a job where you do some box ticking thing that says oh we did due diligence but you really don't want to know anything that's going to mess up the speed to market and so this is where things that are actually conflict theory get to hide as if they're mistake theory and this is where you have to factor the relationship between the those topics well but when you're thinking about new technologies in say the web 3 space you want to be able to think about what new types of conflict theory dynamics does this actually enable like where does it enable the people who are better at this technology to have more game theoretic ability over the people who are less good at it where does having this type of spear or chainsaw incentivize thinking in certain ways you know what are the effects of those things does this how can this increase or decrease the underlying basis of conflict in the space um and of course when we're trying to think of governance tech how do we how do we make it to where there isn't this perverse incentive to not focus on externalities well you could do things like really tight attribution where everything in your ecosystem actually does have to pay for the externalities that it finds that are found later and so it becomes catastrophically unprofitable whereas right now the company gets to privatize its gains and socialize almost all the losses yeah could we make a system where the externalities have tighter attribution or internalized and so it actually affects the cost equation the incentive we have a situation where you actually do regulation from something like a dao first right you create some new governance protocol and before a new technology is rolled out the people actually have to see that it's risk analysis was good enough so it's not the technology rolls out and after we see that it ruined everything like ddt or cigarettes or whatever then we try to regulate after the fact which once you're an exponential tech it's too late to do that you can't let out self-replicating biotech and then after ruin everything say oh we should regulate that it's too late or ai so we actually have like say before tech gets released into the market is this safe did it actually pass enough you know appropriate process which of course happens in some areas the fda is supposed to before getting authorization to you know ensure oversight of drug safety but that's not the case in like almost anything in software uh for these purposes but that is showing have even bigger effects on culture than any particular drug would yeah and we've got the saying come out of the valley move fast and break things it's almost the exact opposite culture of of what you're talking about remember how we said that the dominant narrative is apologism for the power system yeah move fast and break things oh we're all we're all about disruption and coming up with innovative new stuff and we're going to like fail and be these great innovative it's just like what you what you're talking about is having privatized a ton of gains and socialized losses because what you broke was the social contract of the entire  country and the epistemic commons and the ability for anybody to do anything to solve climate change like if what you broke is the biosphere in the country no that was not a good thing to do that was really stupid yeah i think it's really interesting to hear about the conflict theory which is kind of like initiating harm via conflict on purpose maybe there's a scarcity of resources and the mistake theory creating harm via an externality of not knowing and then the plausible deniability of really being in conflict theory and but treating it as a mistake mistake theory in order to get away with it uh is there anything more to say about that in the intersection of what we've talked about yeah i would really love to see web3 developers taking mistake theory super seriously and saying what are the negative effects psychosocial particularly effects of this technology proliferating how do we incorporate it into the design and then where are the incentives of people to over emphasize the positives and move fast and they might break things because where they have an incentive to be focused on the upside they are probably in conflict theory they're going to blow past preventing mistake theory they could have and so you really want to look at where do the incentives give people less orientation to pay attention to real risks second third order consequences and risks where does the incentive landscape and deterrent landscape where they'll be able to socialize the harms later or have plausible deniabe they didn't really cause it or attribution issues and so for the web3 world to say let's really look at the incentives well and make sure that there aren't ones that are up our ability to think through the effects and then let's look at what do we what are we really trying to serve are we trying to serve as right thriving biosphere in a thriving human society if so we don't want externalized harm anywhere we know these technologies are going to be powerful how do we really think through what that power is doing and where the trade-offs are and whatever is being benefited what's being harmed so how do we hold more procedural rigor in doing that and how do we identify where there's incentives not to do it to both try to change those incentives and to know where to be dubious of um certain claims right so i mean i guess you know you and i are gonna wrap this episode soon but for episode three and episode four we're talking about how web3 can help address the meta crisis i'm almost imagining uh a scorecard here in which we can take a couple of projects hold them up to the prism of of ways of what we've developed here looking at each project within the lens of conflict theory and mistake theory recognizing that tech is not values neutral looking at the narratives that have been manufactured by each project looking at how they intersect with the infrastructure social structure and superstructure and then also looking at whether or not these projects confer an adapted advantage to their participants or at least not a disadvantage is kind of like my scorecard for for something that's going to work and is something that is going to help address the meta crisis but you know uh i don't know if there's anything to add add to add to that list um the scorecard involves things that are qualitative right not just negative so you can't make the decision based on just expected value calculus where you've converted everything to quantitative and then the same metrics so that means actually something like human wisdom is still at the center of the whole thing yeah um earnestness and honesty and wisdom to be able to factor because as soon as you get into the okay well here's the trade-off and if we do this thing we can solve this problem but it'll cause this other problem then i have to say how many dead whales are worth how many tons of co2 are worth how many abused children and if you just any version of doing that ends up turning into somewhere between nonsense and evil and this is one of the things i really want the web 3 community to get is that you cannot convert the world into quantification there's a lot of qualified stuff that cannot be quantified and there's a lot of quantified metrics that are uncommensable and that if you make them commensurable you do it at a disadvantage to reality and so what that means is there's a lot of decisions that cannot be made in a metrified way which means they cannot just be automated and computed they actually do require adjudication and discernment and so how we actually grow populations capable of holding that complexity and the qualified things and the uncomparable things and making wise choices has to stay at the center of our focus and so that scorecard is not a metrified one like there are some metrics but it's it's asking like are they you know where are the incentives a lot of those will be squishy because some of the incentives will be like status or you know whatever um and like did they do the risk analysis well yeah it's gonna be you'll get an index maybe but you're not gonna be able to do a perfect quantification because how do you know what was not included that maybe should have been included yeah um and so a scorecard on process was there earnest and deep and rigorous process yes and it won't be perfect but it's directionally right a com a pre-computable thing but considerations that we would like the web 3 superstructure the web 3 culture to hold very deeply where people like one thing i'll say about the future is that if we are to have a future where we make it through the meta crisis we will be less focused on design systems of extrinsic incentive and more motivated around intrinsic incentive associated with a deeper connection to life [Music] and if i am deeply connected to nature and to people that connection informs an embodied ethics that intimacy informs an embodied ethics and the systems of extrinsic incentive are basically how do you control people based on their selfishness because they don't have ethics or to even override them and so i actually want people to do based on incentive and reward much less and i would like to be able to enable people to have needs met and have then a deeper existential development is what of what is actually meaningful and worth doing with our short lives here you know it's interesting uh the east barcelona conference just happened and they had every speaker come on stage and touch grass they literally had grass up on stage which i guess grounded them a little bit of nature in in the heart of the city something yeah it's a start um i'm also imagining this like i'm in an imperfect vessel for this conversation because i only have a certain vantage point on on even get coin like it's gotten so big that i don't even know everything that's happening and it almost feels like a distributed intelligence question of in mapping all of the externalities you almost have to look at it for the hyper structure from all of the different vantage points of it happening i mean i think we can take a we can take a stab at it in episodes three and four but the real thing is empowering the everyday citizens of the web 3 space to have these conversations and almost to create a hyper structure that can like rate projects on their ability to solve them at a crisis and help them find the externalities and like this is why the diversity perspective is important is because if nobody in there actually lives in an industrial zone like physically and knows what it's like to live in industrial zone or if nobody actually lives in poverty or any of those things and there's just types of experience they are completely unclued to and they just can't academically clue into the reality of it the way that anyone who lives there can and so you know the question of like hey do you have people from other classes do you have people from other races you have people from all the genders you have them there as well they have different experiences and their experiences are like hey you're designing civilization for who you're designing a thing that's going to affect a lot of things through all the second third order effects do you have everybody who's affected by it weighing in on it and it's specifically what you just said is that they can anticipate some of the externalities differently because they experience it differently because they're in a different part of the system so if you think of sensors if you think of this as like a human internet of things sensor system then of course i want a wide distribution of human sensors all giving the feedback of what they're sensing in the various aspects of the system to design a better system yeah and so then rather than so often we design a thing we take it as very precious we don't want to criticize we fight for it no that like design a thing and then ask everybody for what's wrong with it knowing that what they're offering you is the gift of how to make it better that you couldn't have seen and then ask them how do i make it better how do i factor these things so let's say you start having red teaming the design not just the security but the design from an externality point of view identify all the externalities here and then that be something that is proceduralized and even incentivized in a descent way and then okay we've got all these things now we're going to incentivize anyone that can come up with solutions for them that don't cause other externalities in the process that's how you get a decentralized collective intelligence thinking about the right things and actually synthesizing its intelligence i think that's a great place to end for this episode um we've got we've got uh some great conversations set up for episode three uh maybe one last question i'll ask you before we break is you know how should we select what projects we discuss for episode three i mean obviously i have a lot of knowledge of and experience with web3 on ethereum and git coin is a project i founded but you know it's now a big dow um you know what kind of projects do you think we should put it hold up to the lens uh in in the next episode that we do you know we can certainly pick ones that either are some of the um most prominent or possibly most promising ones or talking about some design aspects that are pretty fundamental which we can do and if you want to open this up as you put it out there for people to say hey what what about this projects or specific technologies or ideas anything that you were particularly interested in would be fun for us to have a look at great yeah i think accepting submissions from the uh from the crowd would be great is there anything i didn't ask you daniel that you want to say not in this time i'm looking forward to next time and this was a fun round two yeah um so enjoying the series that we're doing together you're so lucid you're so articulate you're many steps ahead uh thinking in so many different things and i'm thankful for this collaboration with you so thanks again daniel i'm excited about thinking about you having a whole community of people that can actually build stuff that are incentivized to build stuff and actually care about things like public commons taking these types of considerations seriously and starting to have conversations like okay well let's take this podcast as like a book club and then let's talk about a dialogue and set up processes and actually make a collective intelligence that has some of the deeper theoretical framing to inform the building that's actually really exciting to me that's why i'm happy to be uh you know it's the uh synthesis of theory in action i think and if we can bring those people together that'd be that'd be really great thanks man thank you so much [Music] you 