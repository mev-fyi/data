hey bankless nation welcome to another live edition of state of the nation today we're going to talk about the xero knowledge evm the zk evm david got us through this is going to be formatted a little bit differently in that after the intro i am actually stepping out so who do we have on the show how are we formatting this and who is helping us out today oh we've got my good friend ben jones from optimism uh and ben is gonna be our technical co-moderator here to help us unpack the zk evm ryan you and i i think we're pretty smart but there's way smarter people in this industry and there's way more technical things in this industry that we just kind of need some help unpacking and so we're bringing in some extra help uh from the optimistic roll up world to help us unpack the zk side of things uh so coming in in the second half of the show once we get once we get there we'll have alex from zk sync and yay from scroll and ben is going to help us guide us through this conversation to understand a little bit more about the world of the zk yeah it's a world that's heating up i think the title of this episode is the zk evm wars and i think uh you know appropriately it was like three weeks ago all three zk evm announced something big the exact same week so the zk wars are heating up david also got to tell him a little bit about our friends at uh florida and i think this is um really important uh that we talk about tools like florida right now because since did you know since 2021 138 web 3 projects have been hacked and that's cost victims a total of 2.3 billion dollars and of course yesterday david we just saw the latest bridge hack 190 million dollars out of the nomad bridge and so we reset the clock it's been now it's been zero days since the last incident uh tell us a little bit about how florida is uh trying to fix this yeah we can all do our best with uh smart contract audits and formal verification and blah blah blah blah and everyone should be doing that but you can also do an additional layer of protection which is real-time mempool monitoring uh and so the way i like to explain this is there's that game in like the 90s where like asteroids were coming in and you would shoot the asteroids before they hit the earth this is like that but like smart contract exploits so you like zap the malicious transactions before they actually execute uh and this is what florida provides for the world real time monitoring of your defy app your nft project your dow your treasury anything that's at risk that's in the world of ethereum uh this is a a missile defense system for your smart con that's a cool analogy david look who they're protecting here 36 billion dollars compound balancer liquidy instep maker lido all of these folks use florida so if you want to learn more go check it out the florida network at florida.org there's a link in the show notes bankless dot cc slash florida all right i'm going to ask you the question i ask before every state of the nation wait before we get there ryan i wanted to talk about a little bit about just some intro stuff uh because we've got okay and so before there's going to be a bunch of questions that i think we don't actually necessarily have to uh ask every single uh participant here in this uh in this stream so we're gonna get some beginner questions out of the way uh and ben's gonna gonna help us with that here so ben i wanna start with uh this very first question which is what is the evm and why is it important and then we'll get to what does it mean to zero knowledge evm oh good question and thanks for having me on y'all okay what is the evm what the heck does that mean okay basically it is a way to interpret ethereum programs or ethereum smart contracts so basically a virtual machine is this notion that you map a bunch of basically numbers right everything in a computer is expressed as a number and you map certain numbers to certain instructions section like add or like divide or like call when you want to go and call another smart contract this is the basis for how you construct smart contracts on a theory write some solidity code what happens behind the scenes is that's taken from text it goes through something called the compiler that turns into a bunch of numbers which is all the instructions that implement the program that you wrote that's the evm very important it's like crucially important it is one of the things that makes ethereum ethereum okay and so we have that that's what the ethereum layer one is uh what does it mean for to have a zk evm why are so many people hyped on a zk um yes so i think they're hyped for scalability it's very interesting because zk evm right this is what is the zk there it's zero knowledge right and interestingly um it does use these things called zero knowledge proofs arguably zk isn't the most important part of the zero knowledge proof right so when you think of a zk snark right maybe this zero knowledge succinct non-interactive argument of knowledge a really key letter in that acronym is the s is the succinct because the point of these proofs is that you can basically prove something in a very short manner so a zika evm is about taking the evm and converting it or running it inside a zero knowledge environment that lets you prove things so what does that mean basically it means you can take the evm and you can write a proof that says the result of these 10 transactions is x 8y right you prove the results of the ethereum virtual machine but what's interesting about this is you could make that not 10 transactions but 100 or a thousand and still the proof size stays the same so you can see why this might be very compelling and can i just uh bake this down into kind of layman's language here so the evm thing that's the thing that turns ethereum from a calculator into a computer and the evm thing is the thing that bitcoin does not have and the reason it functions more like a calculator you can't run programs on top of it right and then the zk part makes the evm thing the computer part of of ethereum much more scalable because it compresses it into this very tiny size yeah i think that's a good way of thinking about it there's a little more nuance in terms of like you know for example if you're posting 10 transactions versus a thousand transactions and you're still rolling those up right if we're talking about his pull-up right then there's still some costs there that fundamentally can't be compressed in quite the same way it compressed quite a bit but it doesn't like disappear um there's more nuance but that's absolutely what would you say why are people so stoked on a zk avm why why is this such a important thing to fight over why are there so many teams like racing today right yeah i mean so there's a few reasons at the core of it though is that the evm is what powers ethereum and it's what has all the network right so i work at i'm a co-founder of optimism which is optimistic role protocol we spent a lot of time making the optimistic pull-ups work with the ev why did we do that it's because that's where all the applications and all the developers live right so to build a good scaling solution we want to do that and it's definitely been a limitation of zk scaling solutions are that they can't go ahead and take advantage of this i think people are excited because there's potential with avm build on that network one last question before we get analysts ben what are you hoping to get out of this conversation what should listeners pay attention to listening to this what are you also hoping to learn here um good question so it depends on who the listener is right i think that one of the things obvious listeners would be like a user of these protocols right so i think you want to listen to what are the security properties like that you're interacting with what is the roadmap of this thing that you're interacting with i think if you're a developer then really what you want to be thinking about is what does it actually mean practice application um there's different ways that you can go about implementing there's different levels of support for different building and aspects that you'll have access to and so i think that's two bits of framing as for what i want personally oh man everything under the sun really i feel like but including those questions um i'm secretly most excited to hear how we can get it into that's a whole nother can you guys um i'll also go over so i'm gonna be grabbing the popcorn here and just and just watching as a bystander but just throwing throwing my one question in is can you guys talk a little bit about bridges i know that's not um typical like exclusive to zk but it's it's kind of like a rollup type technology and i'm um i think a lot of people listening are probably increasingly concerned about the security of bridges from one chain to another or from the main net to roll up from a mainnet to an alt l1 so i'd love to hear a bit more about that and guys we're going to get right to the episode we're talking all about zk evms but before we do we want to thank the sponsors that made this episode possible rocket pool is your decentralized ethereum staking protocol you can stake your eath in rocket pool and get our heath in return allowing you to stake your eath and use it in defy at the same time you can get four percent on your heath by staking it with rocket pool but you can get even more by running a node rocket pool is the only staking provider that allows anyone to permissionlessly join their network of validating ethereum nodes setting up your rocketpool node is easier than running a node solo and you only need 16eth to get started you're getting an extra 15 staking commission on the pooled eid that uses your note to stake you also get rpl token rewards on top so if you're bullish e-staking you can boost your yield by adding your node to the decentralized rocket pool network which currently has over 1 000 independent node operators it's yield farming but with ethereum nodes you can get started at rocketpool.net and you can also join the rocketpool community in their discord you can find me hanging out there sometimes in the chat so i'll see you there arbitrome is an ethereum layer 2 scaling solution that is going to completely change how we use defy and nfts some of the coolest new nft collections have chosen arbitrary as their home while d5 protocols continue to see increased liquidity and usage you can now bridge straight into arbitrary for more than 10 different exchanges including binance ftx kuobi and krypto.com once on arbitrome you'll enjoy fast transactions with cheap fees allowing you to explore new frontiers of the crypto universe new to arbitrome for a limited time you can get arbitrary nfts designed by the famous artist ratwell and sugoi for joining the arbitrary odyssey the odyssey is an eight-week long event where you complete on-chain activities and receive a free nft as a reward find out more by visiting the discord at discord dot gg slash arbitrary you can also bridge your assets to arbitrarium at bridge.arbitrum.io and access all of arbitram's apps at portal.arbitrum.one in order to experience defy and nfts the way it was always meant to be fast cheap secure and fiction free make your dow is the og d5 protocol the first d5 protocol to ever exist even before we called it d5 maker dow produces dye the industry's most battle tested and resilient stable coin using maker you don't need to sell your collateral if you need liquidity instead you can spin up a maker vault and use your collateral to mince die directly with maker the power to mince new money is in your hands and there's something new in the maker dow ecosystem every time a new maker dao is opened the owner can claim a po-out which contributes funds to one tree planted an organization with ongoing global reforestation efforts creating a world where digital participation and the health of our environment can live side by side soon maker will be present on all chains and layer twos bringing the biggest and best d5 credit facility to everywhere there is defy so follow maker on twitter at maker dow and learn from the oldest and most resilient dow in existence and we are back i believe we fix the audio issues so chat make sure let me know if we have not in the top right corner we're talking to alex glockowski from the zk sync protocol alex welcome to the show cheers and then in the bottom half in the middle we got yay from scroll yay welcome to the show so uh beautiful before we get into some of the technical details of the project i just want to kind of go through the context or the the background the genesis of each of your guys's respective teams alex could you kind of just walk us through the history of zk sync where did it come from like bitcoin ethereum and then all the schools hang on okay i know i know that this is not audio issues i just had you guys muted uh so we're gonna start over again [Laughter] okay in the top right corner we got alex glockowski from zk sync alex welcome to the show uh hello everyone very excited to be here and then in the bottom half we got yay from scroll yay welcome to bankless hi thanks for having me okay third time's the charm uh before we get into some of the technical details i just want to go around into the background of each of your respective teams just to get a little bit context about to where each one came from so alex we'll start with you uh where did zkc come from like what's the genesis story what's the background can you kind of walk us through that absolutely very habitus so i i'll start with my personal background uh you might know that i was born in soviet ukraine and i grew up kind of like after the collapse of soviet union and uh i uh i i was very impacted by the the thing economic and social collapse and all the things that were going there and it brought me to conclusion that there is nothing more impactful you can do in this uh in this world today than increase freedom increase freedom of society this increased individual freedom and that is what brought me to crypto like part of that is is the the uh you know um the potential of crypto to enhance freedom which i think is unparalleled with anything else uh and the second part of my motivation was uh the technological challenges and i have a software background i was cto for uh last couple of years before moving into the space uh and i i just was looking at like it was three and a half years ago uh ethereum was just getting started all the protocols were just being built and there were a lot of issues around invisibility and security and like everything was missing and i looked into kind of what's going to be the end game i i was always interested in the eon game like how do we get this thing in the hands of everyone in the world and it was clear that all the problems that are very apparent are going to be sold very soon by some teams except that except scalability that that seemed like a really big black box uh so i looked into what's going on in scalability space and there was plasma and uh and i i i know you were working on plasma my co-founder alex lasso was also working on that uh so i met him at uh defconfree yes in in prague and we we came like from we we both like encountered the idea of zero knowledge proofs of six single knowledge pros and we both had any immediate thought that oh you can apply that to plasma and solve most of its issues and actually get something that will work and bring us to mass adoption and back then crypto protocols were not like um zk particles were not as mature as they are today but it was pretty clear that over the course of next two three five years we will get something that is workable in production but we actually got there a lot sooner uh a year later sonic appeared and two years later we got flunk and that was something very very useful and uh stocks appeared around the same time and all the protocols are now getting converged towards like very you know like everything is going in the same direction and we will have uh incredibly fast protocols provers uh you know all the uh mature tooling around that to get us to scale ethereum with decay in no time and before i hand it over to uh yay from scroll alex zk sync has been around ethereum for a while i remember using zk sync to like pay for bitcoin grants in like 2020 or something can you just like speed run us through how zk sync has integrated itself into ethereum over the last few years uh sure so we we when we started out uh the project we built the very first working zq roll up on ethereum it was like we called it back then ignis but we had to rename to the kissing short afterwards because of conflict and uh it took us two more years to build the the uh like fully productive magnet version for simple payments and swaps it's live on mainnet for uh for for three like no so it was it took us to what one year and it's now live for two years and uh after that it was very clear that most people will need smart contracts and simple application-specific secure roll-ups or roll-ups to scalability systems are going to be very very niche and you really need this generic you know generic programmability with your incomplete programs so we set out to build what is now known as the kabm the generic evi-m compatible framework that is scalable under sdk conditions uh we launched the internal test net over a year ago we opened it to the public with uni stink work of a unislope demo last fall and the testnet is open to the uh everyone since over half of half a year and we just announced a few weeks ago that we will be live on may not 100 days uh and it's now a day um 87 days for me i'm sure alex that you wake up every single morning and be like there's 87 days left we don't have a huge counter and it just goes all right uh let's turn the conversation to yay from scroll yay can you explain a little bit about the the background behind scroll because scroll is newer on the scene and so this is uh something that's new for a lot of listeners and including myself can you just explain a little bit about the background of scroll where'd scroll come from yeah yeah sure happy too so scroll started one and a half a year ago we have three co-founders including me hai chen and sandy we were actually introduced by our mutual friend in the east community so before that i was doing ziki research it's pure about crypto and jk stuff about math and crypto not you directly related to cryptocurrency and i was working on the proving algorithms and the hardware acceleration for the owner proof because years ago the proving is the biggest bottleneck for using xeon proofing practice so that's the the problem i work on like how to make prover more practical and faster and how to support a larger circuit and hai chen is an expert in building robot systems he got his phd from university of washington he has years of experience working amazon building very complicated systems like based on compilers programming language and gpus so he has tons of experience of how to you know build a make a system more practical and run in real world and sunday is more you know like because three of us like diverse a lot in our background sunny has been in a broader crypto space for many years she has been doing investment in crypto since 2017 she has incubated many application level projects and also institutional facing project like products she was attracted to to eastern more strongly due to the rapidly growing community the ethos of of ecm and also like innovations from from dev developers and when we met it was you know instantly clear that we we share the same vision on what was important and uh there was nothing more exciting than us to you know scaling the base layer ethereum and onboard the next billion of users for ethereums because for a long time it's it's what wasn't very clear that whether the key ram would even be technically possible and previously the key route can only support like payments swap rather simple applications using some fixed circuit but recent innovations because we are working in this area we know that recent innovations have made that finally possible and we all want to build something which is truly impactful for the whole econom community and also we were joined by our common vision to use this you know combining with zika research advanced technology we really saw the scalability issue of the ethereum so that's basically the genesis of growth and although like we are new but we we have grown really fast we have 40 people in our team now and 30 are engineers and researchers so most are just strongly technical focused and we have an incredibly strong technical team with mostly people has a strong math and crypto background and this background is is immensely useful for understanding the backbone of the key vm which highly relies on during the proof basically all maths and crypto stuff um and many of many a member of our team had years of blockchain development experience and has been you know active contributor to a lot of open source reports like foundry and stuff like that and because our region is aligned with ethereum of being decentralized many members of our team are also like you know quite global and decentralized we work remotely we have people across asia us and europe like including like china singapore new york bay area portland ukraine australia a lot of other places so i'm very proud of you know our current team and we are super focused on on building like although we are we are installed like previously and we want to build the the best like user and developer friendly qm solution and we work well together as a remote team and also we have been very careful like in how we we grow this team by bringing on the colleagues who are highly value aligned with high integrity and also the right motivation to work work with us in this space nice yeah beautiful all right david i want to ask some questions can i get into it go for it let's do it okay okay okay okay so all right i think the first question that i would like to ask um the both of you is it's very clear that zkbm to your point in your intro questions to me david is like you know it's like been a problem on the horizon that we've been thinking about for a very long time and like when we first started the zk scaling stuff we did not start with the evm right because it's a very very hard problem so obviously there's been huge strides made to your point earlier alex and i have a suspicion that there are different approaches being taken to solve this problem right usually when there's a hard problem you get a few different strategies strategies or ways yeah so what i'm really curious um to hear from the the folks on this panel are what do you think are the unique things about the approach that you take what and what are the things that are shared between um the different approaches and notably right we have two panelists here there are a few other teams building cke vms as well so i'm really curious to hear from you guys what you think the lay of the landscape is and what your strategy in particular is to tackle this in some unique way and alex we'll start with you uh sure so the pro which we are taking uh goes back to how we think about the strategy of building speakers and that goes back to the mission our mission is to accelerate the mass adoption of crypto for personal sovereignty and accelerate means move faster we believe that it's coming no matter what but like we wanted to to arrive not in in 10 years in two years and to move faster you need to be very pragmatic so with where we like how we what we learned from building the first version is that you're much better off launching something that works and then gradually integrating over that then like waiting for a perfect solution trying to construct this abstract uh beauty in in vacuum so like where where i have this picture which you might know like this is how we operate right with building gradually and not trying to get perfection uh and how we started actually we we initially there was no real way from the limitations of brewers and like before from the protocols themselves to build a turin complete version of evm so we tried to build a non-turing complete version of smart products and we had to construct a new language called zinc uh so we had to build a compiler team and we we like we took rust as a base not just not the solidity because we thought like if you have to learn a new language which is gonna have a lot of this internal limitations it doesn't really matter you need to learn from scratch so let's take something that is more familiar to like broader audience uh we quickly learned that it's gonna be very problematic to force people to relearn the language and like to adopt the uh developer tools everything like that that's just going to be a mask for adoption that's not what engineers want on the one hand on the other hand there were some breakthroughs in the cryptography like in plank recursive long uh in improved efficiency for certain gadgets for certain cryptographic functions that are required to build something like a vm that we thought okay we're going to take on the challenge and actually build the full zk video something fully compatible with ethereum where you can take existing smart contracts written in native solidity or viper and you just pick them and launch them on this thing and we looked again like what's going to be the fastest way to get there so our head of engineering anthony rose is actually coming from spacex he used to to be in charge of the satellite factory there and we borrowed this concept of the critical path from spacex like what's the the shortest possible way for us to get to the to the goal and it turned out that we can reuse our compiler skills and the and build something very similar to what we now know uh stock was doing with cairo namely create a virtual machine that is optimized for probability under zero knowledge groups it's specifically optimized to be very efficient under snacks and then create this virtual machine with all the conventions of solidity and dvm so that like all all the calls all the uh interactions all the you know interfaces are exactly the same as if yeah but you just have a different set of codes underneath and then we can use the compiler to take the code written for avm and bringing it over here and this is the approach we're taking as far as i know no other zk evm team is working in this direction stuck with doing this for cairo but you have to relearn it like the current language they have some uh to to transpile code from solidity to cairo called volar uh but you actually have to maintain the code entirely you there is no way for you to keep solidity as the source of truth as your basic code and it would be very very hard to keep the same code base between layer one and player two or between different narratives that that was something that was not acceptable to us we wanted the code base to be exactly the same executable as well in magnet as in in anywhere that's our approach uh alpha ordinance ben does that generate any follow-up questions or should we throw out to yay um okay wait let me just okay so let me just make sure i'm following right alex so basically what we've said is we talked about in the intro of the show that we have this thing called the ethereum virtual machine it's how you interpret you know smart contracts in ethereum mainnet basically what you've written is a virtual machine that's very similar that's meant to be like very mappable and like close and related that is optimized for zk proving and then you can basically relatively easily take solidity code that is meant to go to the evm target and compile instead to this other target is that right that is correct so we are actually not just we don't have a native compiler from solidity we are using the solidity compiler to produce the intermediate u uh representation of and exactly we and then we're going from dual to uh to our virtual machine which is a lot easier to make that step and in between we're using llvm as our compiler framework which is a very mature very uh well tested possible tested uh uh framework with a lot of tooling a lot of optimizations so our code is actually a lot more optimal that what solidity uh compiler natively produces for evm we have three times less up codes in the final result and yeah so this approach is the fastest to bring to to production uh and yeah we started working on this for like since two years still like we have something this is very very mature in compiler it works in like you know we have we're covering all the tests from ethereum uh data suits and uh it's running in a very stable way on our test that which is public like a lot of teams are deploying there we have hundreds of teams already working on tesla everything works really really well uh but the the most important thing is it will produce the uh resulting virtual machine by codes that are very optimal the the execution the proof generation for the uh zk vm for optimizing kvm is going to be orders of magnitude less than approaches that try to mimic evm at the bytecode level so we are we were talking about like very very low cost per transactions uh if we can scale to both support the high load of d5 uh nfts but also like very broad use cases just gaming and like oh you know all the new things that are coming to blockchain once we can actually support the scale of dance hundreds of thousands tps uh and in those cases it really matters like if your transaction costs like 10 cents or 0.1 it matters a lot you cannot just like this is the quantitative step that unlocks qualitative difference uh in what you can actually build and execute and run on in this networks beautiful all right let's turn to yay from scroll yay can you talk about the competitive difference that scroll is bringing to the table how is the approach to the zk evm from scroll side of things unique from the others that you would find in the same landscape yeah yeah yeah sure i think technology wise there are like only two two differences one is on the the qm side and the other is on the infrastructure side um firstly on the zikiram side so our goal is that we want to have the deepest level of compatibility with ethereum down to the client implementation so by saying that like we are not only being compatible with the solidity at the language level like either you are you or like any error we will like be compatible with evm itself as a bytecode level which means anything else right you can use the existing compiler to compile down to the evm bytecode and we can prove that it's correct and also like by saying client implementation we are reusing the existing ecm node indentation called guess to generate our layer to blocks so this is pretty similar to what optimism is doing like just try to reuse the implementation from ethereum to inherit the the performance the security and also like you know use a long upgrade like we will be more aligned with ethereum so there is no compiling there's no interpreting in between so it brings us another level of compatibility more than just the the rpc interfaces but it's a deeper level of you know like compatibility on the implementation side and for users it means they can do whatever they can on instagram using the same ui and ux and for developers they can reuse all the ethereum toolings even include some debug toolings like where you definitely need to down down to the barcode level like for example you need to like look up some stack information and things like that and they can migrate their code to scroll without any modification and also like you know this brings us another benefits like where our implementation will be the most closest to the end integral of ethereum where the key vm can eventually be used to prove for layer 1 magnet blocks so in that sense we are not only building for ourselves we are not doing like just for layer 2 purpose but we are actually computing this for the future of ethereum because you know it is very beneficial for ecm in the long term so that's from the the compatibility and the ziki website and another thing i want to mention is that on the infrastructure side we have designed a decentralized approval network so there is both a technical difference like innovation there and also a strategic difference because you know a big problem mentioning like by maybe optimists they grow up or other other teams is that the proving cost is large because you know generating proof is usually slow and considered to have you know very high high cost it's very expensive but we can actually solve this problem by allowing many people to generate proof in parallel and also this can drive the efficiency of of proving hardware to the to the extreme and eventually even have zk86 to support this proof generation like anyone can just use this type of hardware or use general proper gpu or whatever they can to generate proof for us for our platform and it's very you know we are prioritizing this because this is also like not only the technical like advantage but also strategic differences because you know uh more immediately especially with the east merch uh miners could potentially just be be our approvers they can they can reuse their gpu machines to their improvers and join our ecosystem if they don't want to you know switch to another work chain so that's you know both like technical innovation and also a strategic move for us so yeah let me ask okay so i want to do the same thing and make sure that um following so basically what yes said i think correct me if i'm wrong is that you uh effectively have a program that is written is i i would assume that's written in a um that's running in some sort of lower level zkvm that is this turing machine turn complete machine and then you're running an evm interpreter on top of that basically is that right so we are not even having this you know middle layer we are directly like so for example if you you receive a transaction you execute it on gas and then you output some information like the execution trace like which op code you are actually executing and then you use this twist as a witness like to feed into this circuit and prove that it's a valid tree using a very simple proof and then this proof like i'd rather you have this proof it means oh this this trace is valid so this you know the transaction is correct so there is no like middle step you just reuse every information from the existing client indentation yeah got it and that circuit i guess what i'm getting at is that circuit so when you feed in when you okay so it makes sense to me that you run the transaction on geth like vanilla thing and geth has a wonderful thing called the transaction trace which will give you sort of a step-by-step set of these instructions of the ethereum virtual machine that we talked about right geth will like break that down instruction by structure it went here and then it went there and then it went there so that all makes sense but then what is actually running when that information is transferred to the improver what is the circuit running is there some sort of turing complete thing that is then running the evm on top of it is it have you actually written like an evm like circuit for all this what is that part of the stack yeah yeah so basically what we are doing to handle this is that for each op code we will implement some sub-circuits to prove it's crack for example if if you are add up code and we prove that this this number adds to this number equal to this number so we have a specialized sub-circuit for each upcode it's a one-to-one mapping and then like because and then like evm circuit we compose those sub-circuits together and then open or or like you know or like using some selectors we call that selector in circuit but basically if you meet with this op code you open this certain constraint and you if you meet with the other op code you open it next and then like you know you prove that this is this is correct yeah and by constraining each code i'm interested i'm really interested to hear from you alex on this like it's interesting i know i've been on a panel with you and you love paralyzed proof generation as well i think all the zkrs do it i totally do as well but it also seemed like earlier you said you had a bit of a different approach um for performance reasons so i'm just curious like to hear what each other's perspective is on these things like is the performance of zk proofs an issue or not i feel like i get conflating answers sometimes um that's a great question yeah that that's a really great question so i i don't see that we have different strategies here like all dk teams will eventually work towards decentralizing the uh the prover uh we are working on this definitely from like this is very important to us we don't want to be any single point of failure we don't want to run any operator that controls like the validation of the uh transactions going nuclear to one or the generation so it will be decentralized uh it can we can reuse uh ethereum miners indeed we we've been working on the gpu prover hardware for the last two years as well and we have some pretty amazing results like the the gpu approver that we have on that runs on ordinary consumer gpus is something like 50 times faster than like 50 times cheaper than the uh the uh fruits produced on cpus and for the broader concept it's really important to understand that whenever we talk about the prover efficiency we always are talking about the aromatized cost per transaction prover is always distributed like it's always done in parallel no one is running a brewer on a single machine like if they do they it will take them hours to generate visible proof like uh what we're doing and what the probably other teams are doing as well is like we're on it on and as as many machines as we need in parallel uh and since the structure of the circuit is that we kind of regressively combine many circuits together uh our latency to generate proofs with gpus is going to be like less than a minute so we will be able to like really to get the blocks really fast so what really matters at the end is like what is the cost of this generation divided by the number of transactions what is the cost per transaction and that is where the differences will materialize very significantly with our approach or like with starcraft building versus uh what uh scroll like this very ambitious goal of scroll to make evm circuit like circuit level compatibility that is going to be like several orders of making a little higher we're very curious to see what the numbers actually are but that that is very complex and that is very complex also to maintain so uh huge uh respect to the team uh for for trying to make this like we we didn't trust ourselves we we went for much soon for simpler approach because we know that the more complexity you add really like it it grows non-linearly with the number of systems you add and with the number of layers you have to which system you just think explodes at the end so uh so this is with regard to gps sorry now finish up the alex and i'll ask my next question uh no so this is with regard to decentralizing the broker and gpus and you just want to add that we decided explicitly not to reuse gaff uh as like not rely on on standard nodes for a transaction uh for the block building for deciding what goes into transactions because geth is known to have very strong limitations on throughput that it will bring with itself and we decided like if we're just building a system that should be capable of running tens of thousands of transactions per second we should redesign the node from scratch and we're writing it in rust uh it's highly optimized where we also have a very strong engineering team uh working on optimization of uh of the node because we don't want the node to be the bottom i think i think alex you just opened up the the conversation to the evm compatibility versus evm equivalence conversation but before i wanted to go back and just make sure we really knocked down the decentralizing the prover for the layman because that part of the conversation made me feel like a dog driving a car um can you ben can you walk us through why is what does it mean to decentralize the approver uh like why is that significant for just like the average user to pay attention to sure so i'll talk about this i'm i'm not the zke experts like these folks but i have a i have a rough sense so basically when you construct these zero knowledge proofs right that is an operation called proving right unlike the operation called verifying which is like in a ck role what the smart contract on chain does what all the nodes do then downstream like that so in general what you have to do basically when you produces your knowledge proof is a bunch of extra cryptographic moon mathy computation that will give you some fancy numbers that allow the verifier in this succinct manner right in this short you know constant or logarithmic sex manner to check whether or not the proof is valid right and so this is a computationally intensive operation to do it in the zero knowledge succinct manner that we're talking about you basically if you want to prove something it's kind of like you don't just run the computation because that's not a proof that's just you doing it you have to run the computation in some sort of circuit zero knowledge math context that gives you some cryptographic steps along the way that you can sort of combine and aggregate and get a and get this succinct proof okay i'm guessing that's the doing the zk stuff is like adding like an order of magnitude of difficulty upon the computer yeah these guys can talk about those numbers much better than i can but it but it adds overhead for sure for sure adds overhead um and is that like the cost for like a train when a transaction fee happens on like a zk roll up is that is that the cost of this thing is that related are these related so it will be related right i think i i think i haven't looked into the details of either these folks fee markets but that is i think what would be a very reasonable thing for a free market to do i think probably a requirement there's additional costs right because even in a zk roll up you're still rolling up that data right which means you're posting into ethereum or whatever right i know at least um alex has like other more plasma type things that don't require that so it's going to be a chunk of the cost absolutely okay okay cool so anything that ben and i just said like stand out to you guys that you guys want to add on a comment too that's good to me cool yeah yeah all right uh so we definitely got to talk about evm compatibility and evm equivalents because i think that's really uh alex you said that geth is really just not optimized for some of this parallel proving magic uh but but yay from what i've gathered scroll is really going after what alex call like the very ambitious task of figuring out how to make geth and a zk roll up work together so i think that's where we want to take this conversation next but before we do that we got to talk about some of these fantastic sponsors that make the show possible there is a brand new staking feature in the ledger live app today we all like staking the assets that we're bullish on and now you can stake seven different coins inside the ledger live app cosmos polka dot tron algorithms tezos solana and of course ethereum with ledger live you can take money from your bank account buy your most bullish crypto asset and stake that asset to its network all inside the ledger live app through a partnership with figment ledger also lets you choose which validator you want to stake your assets with and ledger is running its own validating nodes offering a convenient way to participate in network validation and it even comes with slashing insurance ledger live is truly becoming the battle station for the bankless world so go download ledger live if you have a ledger already you probably already have it and get started securely staking your crypto assets the brave browser is the user first browser for the web3 internet with over 60 million monthly active users and inside the brave browser you'll find the brave wallet the secure multi-training crypto wallet built right into the browser web 3 is freedom from big tech and wall street more control and better privacy but there's a weak point in web 3 your crypto wallet and most crypto wallets are browser extensions which can easily be spoofed but the brave wallet is different no extensions are required which gives brave browser an extra level of security versus other wallets bravewall is your secure passport for the possibilities of web3 and supports multiple chains including ethereum and solana you can even buy crypto directly inside the wallet with ramp and of course you can store send and swap your crypto assets manage your nfts and connect to other wallets and defy apps so whether you're new to crypto or you're a seasoned pro it's time to ditch those risky extensions and it's time to switch to the brave wallet download brave brave.com bankless and click the wallet icon to get started the layer 2 era is upon us ethereum's layer 2 ecosystem is growing every day and we need layer 2 bridges to be fast and efficient in order to live a layer two life a cross is the fastest cheapest and most secure crosstrain bridge with a cross you don't have to worry about high fees or long wait times assets are bridged and available for use almost instantaneously across his bridges are powered by uma's optimistic oracle to securely transfer tokens between layer 2s and ethereum across its critical ecosystem infrastructure and across v2 has just launched their new version focuses on higher capital efficiency layer 2 to layer 2 transfers and a brand new chain with polygon all while prioritizing high security and low fees you can be a part of across the story by joining their discord and using a cross for all of your layer 2 transferring needs so go to across.to to quickly and securely bridge your assets between ethereum optimism polygon arbitra or boba networks okay welcome back y'all we're back in action so okay we we just had a really interesting discussion on you know some of the differences in these approaches and one thing to your point david that came up just before the break is understanding um the role of i think the i so i take some guilt for creating this term which could be very confusing but evm equivalence is like a wonderful term that we use at optimism to describe how we kind of try to move towards using death as much as possible and this has been a matter of debate and there are differences between our two panelists here and what they do so i'm really curious to hear from you guys how you think about um the developer experience we talked a lot about the approaches sort of from a proving architectural cost gpu type of a perspective but there's also the side of developers and what they're going to experience so i'm curious to hear from you guys from the panelists what your different approaches to this developer experience are what does it really look like for developer to be implementing on on one or the other and um how do you think about that long term is the other question are you at a place where you're comfortable are you trying to move in a specific direction what's the take so maybe we'll start with yeah and developer experience which means we will provide exactly the same execution environment as ecm layer one so developers can pretty much reuse all the you know developer tools around like including the debugging tooling like if you want to go into the stack and look up some information you can still use that and because as far as know like many gas developers many many even application level developers they are very familiar with the gas implementation so that is easier for them to debug and uh and like you know have some in-depth security analysis so i think we we have some advantage on that because we are using a fork of gas to generate our blocks and uh and also like uh because you you are compatible with all the developer toolings so developers are very comfortable with you know every tool links they use on on layer one they don't need even any extra plugins or any to link to any external compilers they can just reuse whatever is there so in the long term i think it's more like secure secure way because firstly evm has two tests of time like what like the the design philosophy of each op code this stack based virtual machine it's it's security is has two tests of time if we we just reuse everything from evm it's very easy to audit our code like because uh you know our execution environment will make sure that the the circuit will behave exactly the same as evm like if you make mistakes there then you you can make mistakes here so if but if it's cracked there then like you know because they behave exactly the same but i think that's that's important like in the long term why you reminding this um you couldn't say it's important and also secondly as i mentioned like if you you are more aligned with this implantation for the further ecm upgrade like you like people are doing experiments over gas for eips for different improvements you can directly use the same code base to improve your layer to design and also like even sometimes give back i think that's part of the motivations why optimism is going into that this approach so that's why like you know our our design philosophy for this part and again like because we are actually giant like standing on on top of the the the giants because when we appear like the breakthrough already happened we know like the the overhead is already affordable so that's why we directly go into this by the code level like compatible approach instead of building some some other virtual machines to make the proving or head more manageable what's makes sense yeah let's hear from you alex uh sure so for uh we are also on the mission to make the developer experience as easy and pleasant for developers as i possibly can have like an absolute top um and uh it's important to see like what is the actual developer experience is like what what what you expect as a developer from from the environment what you expect is that you don't have to modify your code and you can use the existing tooling so you take your your whatever you have uh written in contracts and front-end and tested tests use et cetera and you port it and it just works just just work like one click you know stripe like experience where you don't have to to do any movements that is exactly what we're gonna bring we're not gonna bring it at the op code level but we're gonna bring it at all the interfaces like your uh the code does not need to change you do not need to do any re-audits your web3 api works out of the box your all the coded conventions work all the toolings on chain work we have um the graph or chain link uh a lot of other projects already integrating already running on on our test net uh ready to provide this experience so things that will not work because the op codes are different are like low level debuggers uh but those tools can just integrate we can work with them there are not many of them you can work and make them be as compatible and then you you use the same you have your tenderly experienced you have your remix you have your common line-based debuggers and they provide the same output the same experience to you like you as a developer do not need to to do anything and like the surface of changes is is really minimal but what is ultimately important to you as a developer is that your code works smoothly but everything is fast so the the one way to think about zk evm equivalence versus cvm uh compatibility is like what would be the analog of like the of these things in in the real world in in in the normal computing imagine you have some some piece of software written for one operating system for specific architecture i don't know like if photoshop running on windows now you want to run this photoshop on mac with m1 processor right you have two options either you recompile the code for m1 and it runs super fast and you know you you like the experience or you run a windows simulator on your mac and then you run this photoshop in this simulator you can already sense like if you run uh just some some programs written for the older version of mac and then you try to run them on m1 without optimizations you already feel the difference right like it's huge but if you run it in in an emulator it's going to be a lot slower so your your developer experience is tightly coupled with your user experience as well that is what matters yeah very very very interesting yeah i i want to take a careful spot here david to be your co-host because i'm very opinionated as as the folks like coined the term evm equivalents like i feel like i'm at an interesting position here i'll just say i'm very curious to see how it plays out i definitely very much vibe with many of the um things that you said there alex some of them i became less of a fan of once i had to run a non-evm equivalent system practice you guys are also building a different space right you've got these zk requirements it's a little bit of a different world so um yeah it'll be very interesting david to see how this plays out i'm a huge fan of developer experience and i think that uvm equivalence is the way to go there but we'll see alex any comments on that or not uh i'm i'm also very i'm really happy that we have multiple approaches competing we have our bet like based on on our analysis how like what what's going to be the optimal for developers at the end uh but it's like it's really great that we have this race and and uh let the thousand flowers blossom uh yeah any a comment you want to add before i turn the conversation to something else yeah yeah i think it's it will be a just uh like you know winning like like eventually like offer all good for ethereum like different tries and uh like you know evm you couldn't environment or this compiler-based one and but i think you know in the long term it's you know like like if you have actual need for compiler you have to also upgrade like you know your compiler and both your compiler and your circuit at the same time which actually adds the the overall complexity because you you you need to you know those two parts are coupled together and you need to upgrade like with each upgrade but for the key answer case all the compiler stuff you know those can be reused and those have been tested you know years of time so that's why like you know we we want to handle this more complex stuff on the circuit side but we don't need to handle like you know anything besides that though i want to hear from alex on that yeah that's a really i i i wanted to add that indeed like the the uh what we're what we're building here is the future and like let's imagine is evm gonna be ossified and be this standard that will be there forever and like will not undergo any modifications like like imagine that we we have the very first version of pc with like 80 86 architecture is this thing gonna be like immutable and never change like that is hardly imaginable right so like we will have some evolution in my opinion like you you might you you you feel free to disagree uh but i think uh with with the compiler uh one thing that gives you uh that the a separate compiler specifically llvm based compiler gives you is it an option to have like developer experience beyond just cvm you can port in any code written in all the modern languages that support the llvm like rust golem python uh you know with c plus plus whatever you take that you compile it even javascript you compile it to llvm and then you can use it as libraries or we can also define some contract interfaces and then you eventually can write smart conflicts in those languages and i think that is going to be incredibly powerful because it just opens this massive code basis already written in this very expressive languages with generics with with all the uh cool cool stuff that is not yet possible in solidity and that have stood the test of time for like many more years before solidity was even created uh so i i find that recently really really fascinating okay wait alex i've gotta dive into this more though so i okay i first of all totally agree if the reader has not heard of lvm it is one of the modern marvels of like computer engineering absolutely fascinating go check it out with that being said there's a key there's a key question here that i don't know if i heard an answer to which i want to dive into alex which is since you have developed a vm that is the zkvm that like is like related to the evm and maybe has some of the same semantics but is different how do you deal with upgrades right so like i totally agree we're going to like have upgrades to the l2 vms in this are you basically uh like is implicitly there a commitment to this particular zkvm that is the that like your current compiler outputs and like is it your goal to maintain that going forward and just build more um solid circuits around that or do you have the ability to improve that vm in the same capacity it's that question that is a great question yeah i yeah i i think we will have iterations so like in the initial versions of all the roll-ups we'll have to work a lot on on upgrades and do changes that it it will be important to work with the source code and not with byte code and i i don't think we will have like an ossified code in in any near time so eventually we will have a newer version and yes you will need to redeploy your contracts there uh okay i see so you're basically going to enforce the requirement that you have source code accessible so that if you upgrade the underlying zk vm that is not evm you can recompile and regenerate the byte code for it that would not be a hard requirement so like whatever you launch like if once we have a stable magnet we will guarantee that this maintenance will will run for a long time uh and then most likely you will you will have a like well we we need to see i i i don't know exactly how this process will work but like yes i believe that we'll there will be progress in both the evm world and ckvms and eventually will come we will converge more and more with the world of generic computing we'll reuse the tools like ovm static analysis uh all the debuggers that that the uh traditional systems can bring and i just think this process should be gradual and smooth could not be like a breaking change for you you have to stop immediately and you cannot support your previous code you can always emulate like it's quite um quite easy for us to add byte code compatibility in zk sync because now like imagine we have the lvm compiler we can do we can write code and solidity and rust and it compiles to this very very efficient low-level virtual machine we can just write the contract that executes native evm byte codes we're either in solidity or maybe we just compile our rust implementation and we pollute it on zkvm you know like that that will give you the same overhead or maybe even slightly lower overhead than what scroll or or hair mass are building uh but it's it's a gradual process you don't have to wait for this final step you can already start using importing your contracts to zika sync written in solidity because you recompile them and the moment we have this contract live you can just start porting your your bytecode if you're willing to take the this massive overhead and into account if you want full efficiency you just compile natively to you fascinating more comments on this like you know i think there are two points firstly that i agree that you know uvm may not be they they undergo like you know in maybe like 100 years like we are not always stick to evr model but the reason why we firstly go into this evm you couldn't approach is that because we know that the the urgency for ethereum is scaling right it's not for you know finding some new computational model at extension but it's it's more for migrating all the existing apps securely through a layer two so that the congested problem can be solved so that's why we want to provide the evm equivalency environment at the in the first place because you know you have to handle with those problems and then you can sync up the further problem for new vm or any features so that's one one thing like you know that's just our starting point and we will also definitely consider more like developer friendly you know vm or or something like that and the second thing is that to build this um so there are some arguments around like evm versus vm but the problem is that uh they i think they're concluding most likely that either you become you build a totally new virtual machine or like you you just reuse this evm and the tree equivalency because if you you modify part of that it's nearly a new vm but you you can't just benefit from a totally new design from this virtual machine so that's why like we are thinking of two approaches one is that adding more features to this evm for example we can upgrade according to our community design like some new pre compiles specifically to our layer 2 and using the existing evm structure securely and secondly that we are in parallel we can explore some more efficient wiki vm to open this design space for more developers so that's something that we are also exploring but we believe that that's also driven by the developers needs instead of you know just reusing the compiler and just reusing the same virtual machine because it's fundamentally different i think the last point is that use reusing the lvm is very ideal like to support all the programming language but you know if you dive deeper into the lvm for very high level like language like rust python those touring complete language with many features you will find that the lvm ir in the middle layer is very complicated it's it's even much more complicated than building a ziki evm like adding support for all those upgrades because they have very complicated type they have very advanced features if you want to support all of them you need to sport a very complicated ir layer it's not just the solidity or or anything like you know yeah so i think you know even if you have this levr or it's still like you know take a very long way to go to support all the features of ross but if you only support the schematic of roth then i think it's you know still like less useful for developers because they still need to change a lot of code and so that's you know like maybe three points from our perspective so we're also exploring but that's like why we win this at our first step i'll take that challenge let's see how fast we can support trust all right yeah yeah yeah okay forward awesome guys well uh like i said earlier i really like this metaphor i feel like a dog trying to drive a car so i'm gonna zoom out this uh conversation and get something i think uh the users can understand i think a little bit better and every single layer two team has their sort of like vibe if you will like it's their culture it's their branding and that's often really how like users ultimately come to like determine whether they feel comfortable with a particular ecosystem or not is like what what are the values or the ethos that each team appears to exude even though they can't really comprehend some of the very technical words that are being said uh so i'd just like to get uh each of your guys's perspective as to like what do you guys think about values or culture or vibes when your guys's internal uh like uh just like communication as to how to build something and maybe you can share that perspective with uh the the broader world like what is what is the vibe of your particular project what's the do you guys have like a an ethos that you stand on and yeah i'll start with you sure yeah that's that's actually a very important like aspect of scroll and you can check out more like on we will have posted arc like articles talking about our vision value our technical principles we want to up code when we are designing our whole architecture but from the ethos and the you know like the the the vision side we are more open we are we are open we have been building in the open source way from day one like you you know the totally open source the event circuits where anyone can run anyone can and just you know even pr some code and most parts of the zqm circuits are actually co-built in collaboration with a privacy and scaling exploration team at ecm foundation under permission lace license so we are we are actually co-units together we like a lot of actually credit also comes from this community and uh because we have this permission list license which means anyone can use this repo and build things on top of that and also we encourage the broader community to do so because we firmly believe that you know building in this open source way leads to more secure and resilient code and help us to foster a broader community of developers and they can check our progress in a very transparent way because you know there are some over claims right they can just directly fact check our claims of for example like whether we have proofs or not and in that perspective we hold ourselves very you know to a very high standard that with all our claims we made for example we actually have live leaky proofs in our test net now can be checked and we are focusing on building and shipping shipping our shipping new features our test net and we are not doing endless prs but instead we are you know writing articles explaining what we are building and what our architecture look like and how to put more educational articles which is beneficial for the whole space it's not directly you know like finding each other but but more like for educating people why this is important and what we are building and i'm glad that you know even if we are doing a relatively stealth model there is still a circle of ese and ziki researchers who have recognized our work and given us credit where it's due and we are actually finally ready to welcome a much broader community and i'm happy to see that we have received over like 25k signups within two days of our pre-alpha testnet announcement and if you want to be the first batch of user just sign up at signup.scroll.io yeah beautiful thanks yay and alex i'll say the same question to you what's what's the overall value or vibe of zk sync uh so zk sync is deeply mission during project so this this mission that i mentioned in the beginning to accelerate the adoption of crypto for self sovereignty is hugely important we've written a lot about this we have a team handbook that walks the new team members through the values we are extremely aligned with ethereum on on the on the approach towards those goals and every technical decision we make is uh matched like we it is balanced against the the the principles of freedom resilience inclusivity um like from escape hatches to the way we decentralize the prover to the way we approach decentralization of the sequencer uh to the way we uh we approach the standardization of the code bases uh we are we firmly believe in open source everything we do is gonna be released under permission the software license uh just like we did for version one with version one we made some uh interesting experience that made us reconsider the approach to a complete openness because we we opened like we were leading the protocol development completely in the open and then there were people who just forked the code made modifications that they did not understand took part like they copied some they off some box and they also changed things that led to more problems and they they tried to front out or front run us with regard to the token so like there are powerful incentives for people to just rush with some underrated code and try to publish it that's why we're taking like a more conservative approach now so we we're opening everything to independent researchers we actually next week we will announce uh uh some people we opened it with who are highly credible in this space and then we're gonna gradually open it more and more and more uh until we have all the audits and all the uh testament the testimony testimonials from the white hats where we feel comfortable the code is safe then we're going to open sources beautiful nice thank you too yeah coomboy uh called cryptoculture baby okay alex you did you did just raise something that i really do want to get in before the end of this panel which is a question for both of you okay all of the zk i mean realistically almost all pretty much all of the layer two teams out there right now have upgrade keys right so there's some set of small number of people that own a multi-sig that can be used to upgrade the system and that includes upgrading it to something that is malicious and takes all the money from the system this is obviously not ideal you know i don't want to like rehash why that's necessary because i think we all agree that it is and we understand that that it needs to happen but my question is at what point can we cast those upgrade keys into the fires of mount doom like from both of your perspectives what is the point in time in which like obviously it makes sense that now for you to launch something you can have some level of um you know trust that it's at some level productionization but it's a big shift to say okay we're throwing away our upgrade keys if someone comes to us as a bug in the future we cannot solve that bug so i'm really curious from you guys perspective like what is the timeline and what is the like concretely the criteria that you think has to be fulfilled to be able to turn off your upgrade keys and alex well i'll start with you again sure this is a huge problem uh we're thinking a lot about we i i published a tweet where uh we offered the uh bounty for the best design solution that can help solve this problem and for the broader context the the the problem here is very different in l two space compared to l ones because if you have a problem with a one you can always away the decision to focus ultimately with with the people who run the nodes so you never depend on the honest majority and that is the superpower of public blockchains like like truly decentralized blockchains like bitcoin and ethereum and i can't really think of any other ones that fall in this category but [Music] um you don't get this at least because the player is you you have all the funds like are locked into this one contract on layer one that someone needs to control someone needs to like this contract must objectively know like who is now like what what code is not canonical like what shall we execute uh the solution we came up with was we have a team multisig that can initiate upgrades and those upgrades are subject to a time lock period of multiple weeks and then all the users who are disagreeing with with those upgrades can exit and we have permissions mechanisms for exit uh escape hatches like um first block proving et cetera but um if there is a block and we really need to accelerate we need to act now and just fix an immediate problem we must go and reach out to an external number of people who we call a security council those are highly prominent people from the ethereum community very rich and famous so like they they like it's very unlikely that they will all collude to try to steal this funds and they must approve an immediate upgrade now this is this is not the perfect world because like we we don't want to to expose those people to like political uh struggles and you know to some like non-monetary incentives that might force them to to do things um ultimately what we can do is have multiple layers of protection in in our systems that like all of the checks must be made before like something happens so the simple example would be if you we just have a second factor and we have a roll up running like a zika [Music] and then we have number of validators appointed by the users who have to approve transactions uh and then you would have to break both the consensus of this validators like or corrupt the stake and find a problem in the zk circuits to to to try to exploit it uh but that could compromise the liveness of the system if the proof of stake is or like this valid dataset is compromised uh so another option would be to have multiple implementations of roll-ups like maybe if your physique roll-ups or maybe optimistic plastic here we combine those together and we put them uh on chain and then we we use governance only if they if they disagree and this is something that vitalik posted last weekend uh on twitter which is a very interesting idea uh but ultimately we just need to wait for those systems still to become mature like if something is running for a few years with billions of dollars worth at stake and nothing has happened then those funds were not stolen and you had honeypots running in the open with like much lower barrier much lower threshold of the capability and those are also safe and those have had millions of doors uh stake in them that the attacker could just grab if they found like much much easier although to penetrate then uh i think then we can say okay we those systems are like plausibly secure and we can rely on them and we can remove them this is roughly how i think about it maybe there are some ways where we could rely on the governance of player one maybe we could declare some roll-ups as like really important like systematically important for ethereum and we can say like if something goes wrong in those systems then we would just rely on the votes of the general ethereum community uh and we actually we don't need to declare them anything special we just need governance mechanism that can rely on this external uh a voting power of brother ethereum maybe something like this so like all the ideas are really appreciated yeah you want to take the same question just uh the overall security of scroll and your guys's thoughts and plans around it yeah yeah yeah sure uh i think we do have like security plans and security definitely you know the first priority for first grow because you know like stakes are locked in smart contract and for us we do have security plans and so there is no like antidote for repeated and the most wrought auditing but besides that we are going to have an in-house security team and the team will you know keep an eye on our code like all the time and also collaborate with external auditors for 60 as well and also like it's it's safe for now because all the transactions will be executed using this you know existing client indentation we don't even implement a new zika executor to execute our transaction so it's very hard for any attacker to to attack our system since they can't run this you know sequences themselves that's the first place secondly that is existing implementation and also they they have no chance to generate fig proof or for these fig trees um and that's that's one one aspect and secondly that as i mentioned like you know there are definitely trade-offs be like between open source like very early or very late but scroll is built on an entirely open source foundation even including the proving stack of of halo 2 which is you know like many eyes on that including the z cache and for example like community developer from xero park and even faircoin you want to reuse the same like pulling stack and even like you know sometimes reuse it the keyboard code base so more broadly we believe that using this community standards will be the most robust way to write security code and secure our whole code base and security the system of the security of our or like oral system and for the upgrade case uh i think we will implement a sufficiently robust system before the sequencer is decentralized like some using some time delay like which make sure that users will have enough time for you know before this smart contract upgrading and in the long run we will progressively add this decentralization and uh like more become more permissionless like it but it's in a long long run like because you know decentralization is at different levels like first we decentral approval and then we consider the overall system well gentlemen thank you so much for all of your time i know we've gone a little bit over ben do you feel like you've got all of your questions answered oh my goodness i had all the questions answered they spawn more as they always do david but it feels like a goodest place to pause as any well i think the the story of the zk evms uh is going we're just at the very very beginning uh so there'll be plenty of zk evm content as the as the story progresses so alex yay thank you so much for joining me and and also ben my my technical co-moderator here to helping us unpack at the very start of this very long story of the ckevm so thank you too thank you david yeah thanks for hosting us thanks alex of course of course go for it yeah just wanted to say see you guys some minute in 87 days oh yeah yeah absolutely absolutely uh well actually like before i sign off can we just speed run through the road map for each of you uh alex made that in 87 days is there anything else about your guys's road map that you wanted to talk about uh we we're now completely focused on on uh launching mainnet maintenance destination is is up if you want to be one of the first projects launching the main and we're gonna follow the fair launch policy you should get on our test right now and start building and for the next features that are coming there are some really interesting things and i can talk about them yet but i will just say that layer 3 is a lot closer than many people think well i can see that very slight smile on your face so that's getting me excited there alex uh yay what about you and scroll what's the scroll team's like high level roadmap can you speedrun us through that yeah yeah yeah sure i think for our release philosophy we are progressively releasing more functionality to test so we can fix any bugs and any ux difficulties early and often towards a more robust like you know infrastructure test of time so currently we had at the stage of pre-alpha test net it's running internally right now with real live wiki proofs and we pre-deployed some applications like swap for user to interact with they can see their transactions being processed on layer two and then finalize on layer one with a proof rule and explore and if you want to be the first batch of users again like sign up our testnet.scroll.io and the next step will be a more permission list alpha testnet where developers can deploy their smart contract and anyone can interact with with applications on scroll it doesn't need any signup you can directly use your mental mask to interact with scroll with using any interface you you like and you are familiar with and we are testing our functionalities for now and it will be released soon and also like in further release like anyone you will be able to run the provers at home to to provide computation power for us and yeah so that's roughly our plan and yeah will there be a scroll token yeah that's a that's a good question so we are focused on building and we are thinking on long-term skill and want to be extremely thoughtful about you know how to foster a sustainable community of users and developers and i think you know we can learn a lot of license from optimism and polygon which is the only two layer tools which you know already launched their tokens but currently we have to focus on building the the best solution technically yeah okay uh and then alex same question to you is there going to be a zk sync token there might be a kissing token indeed i had an idea awesome thank you guys so much for joining me uh of risk and disclaimers of course crypto is risky ethos risky bitcoin is risky layer twos are risky we didn't get to the conversation of bridges but bridges are also risky uh but they're less risky if you go to a cryptographic bridge rather than a cross-chain bridge but you can still lose what you put in we are heading west with this is uh we're on the frontier it's not for everyone but we are glad you are with us on the bankless journey thanks a lot you 