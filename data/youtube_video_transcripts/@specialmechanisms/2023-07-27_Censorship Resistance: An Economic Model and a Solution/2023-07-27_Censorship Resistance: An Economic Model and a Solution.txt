[MUSIC] Let me jump in. So like the traditional understanding of censorship resistance and versions of this were some of your basic versions were like valid transactions, make it onto the chain. And the blockchain guarantee, at least in the idealized world without OFAC and without compliance departments and so on, is that valid transactions make it onto the chain eventually. Now the question you might ask yourself is this enough? If we could guarantee this, is this enough? Can we just go home and be happy? And our claim, at least our point of departure, is that for some valuable transactions, this is not enough. So the fact that something makes it on eventually is not enough for whole-pointed transactions that rely on timing. So I think it's something like frequent order, the one thing might not be happy if it doesn't get on on time. Time-sensitive financial transactions, hard liquidations, there's been a bunch of DeFi hacks that have relied on keeping those transactions off chain. And more importantly, as we get around to the end, being able to guarantee timely inclusion might open up stuff that we're not seeing on chain in DeFi right now. So stuff like new mechanisms, on-chain auctions, faster fraud windows for L2s. When I got started in sort of thinking about crypto, people told me that anything you think about, Vitalik, thought about it like three or four years ago. And then after writing the paper, I started googling, which is the way economists do it, we read later. [LAUGH] Should first ask questions later. And then I found this paper, The Problem of Censorship, on a blog. The date was actually eight years ago, so there you go. And just to walk you through the thought experiment that motivates both our paper and his blog post and so on, and maybe a lot of you. Imagine you want to do options on chain. So I write to a European option that expires on block X. So a European option is just an option that we can only exercise on the expiry date. And it's, for instance, a call option on the price of each. That means that I wrote it to you at a strike price of 100. You paid me $10 for that option, that's some. What's your PnL? Well, as the price of each rises above $100, you can exercise that option and pocket the difference between $100 and the price of it, right? Now, here's a twist. This option, the way the contract is written, is to exercise it. You have to submit an exercise transaction in block X. So you have to put in a transaction saying, hey, I'm a lesh, it's time for you to pay up the price of each. It's 110. You've got an option at a strike price of 100, so you owe me $10. And what happens when that block X comes around? Well, to exercise that option, you're willing to pay $10 to get that, up to $10 to get that transaction on chain. You could pay $5 to get that transaction on chain, you'd take home $5. That's great. The trouble is, I'm willing to pay $10 to keep that transaction off chain. I'm willing to pay $10 because anything, because I owe you $10 if that transaction hits the chain. If you're both gonna bid up, if me and you are gonna bid up sort of the market for inclusion, you're willing to pay $10, I'm willing to pay $10. In a proliferative, somebody's paying $10 either to get the transaction on chain or to keep it off chain. And all our money, all that value from the transaction is going to the proposal. If all the value of our interaction, this is just an abstract sort of option, but if all the value or a lot of the value of the stuff we're doing is going to the proposal, why do we defy it all? All this value we were hoping to make is just one of the proposal. So this is sort of a side story, is this is a problem on any abstract blockchain. But a side effect of PBS, which we all love and talked about for like six hours with 400 more people in this room somehow yesterday, is that it has one dark side, it sets up a market for censorship. Most blocks are auctioned off for the highest meter, which means in principle, a motivated sensor could offer a block without the underlying transaction with a higher pay. And this wasn't just a theoretical possibility. So we did a simple version of this at Special Mechanisms Group, we made a bit of a splash, a bunch of haters and a bunch of Twitter followers and all that. But we did this, we literally fired up a builder, made a block. You can see the block on chain, this is the block. It contains nothing other than a link to our paper and the name is the first sensor of Rome. Okay, so the block graffiti is the first sensor of Rome, one transaction, $100 and two hours of dev time. Now, this is, yeah, whatever, you'd say, how long can you do this? Just keeping up, you're just putting an empty block on chain, 12 seconds, blah, blah, blah. The thing is, we did this and we told everyone we did this. If we had just left one valid transaction on chain, you could have had no freaking idea that we left one valid transaction in the mempool and just subsidize the block a little bit to get that block in. So what should we do now? Okay, so we were on the Twitter space about this and Sreeram came up and Sreeram is super eloquent and had wonderful things to say. Sreeram said, if you can't measure it, you can't improve. And turns out that that goes for the back, so far back as Lord Kelvin, the Kelvin scale. We wanted to come up with a measure of censorship resistance. And our measure of censorship resistance is going to be, we're going to abstract away from the machinations of a blockchain layer. So all these complicated pictures that we've drawn about how stuff gets from the transaction all the way over to the blockchain. And it just when you view the blockchain as like a public bulletin board, just sort of a public bulletin board with two operations. One operation is read, read always succeeds reads everything on the blockchain and can do anything it wants to it, do some computation, make whatever. But the important transaction for the public bulletin board is the write. Write takes two arguments, data, whatever it is that you want to write to the bulletin board, and a take t. And it either succeeds to write this data to the bulletin board or fails. So this is our primitive, this is our primitive, like really trivial abstraction of a blockchain. And now we can give you a definition of censorship resistance from our point of view. The censorship resistance of a bulletin board is a function phi. That is phi of t is the amount it would cost a motivated sensor to cause the right operation to fit. So if you wanted to write data of phi, phi of t is the amount it would cost this party to, it would cost this sort of motivated sensory party to stop the transaction. Ideally, in some ideal world, we're not worrying about spam, we're not worrying about DDoS, we want phi of t to be infinite. We want anybody who's willing to tip anything or any tip above some marginal cost, whatever. We want the ability of a motivated sensor to keep it off the blockchain to be as large as possible. What is it actually in practice? Well, what depends on now what do you mean by bulletin board? What is the relevant measure of, what is the relevant measure of did rights succeed or not? So if you have a single designated block, which is the relevant public bulletin board, think back to our option example, where there was just a single block that you had to get the transaction in or not. In this case, phi of t is phi. If it was worth $10 to you to get the transaction on-chain, if you tipped some amount less than that amount, I would be willing to pay to keep it off-chain. One simple observation is that EIP-1559, the sort of burn, actually makes the censorship resistance worse. So if B is the base phi that is going to be burned, the amount the proposer is getting for a given tip t is actually t minus B. And that means that the amount you have to pay to censor is actually less than the tip because the rest is being burnt anyway, a proposer would be willing to take that and censor the transaction, at least in principle. Now you could go another direction. You could say, suppose the bulletin board is K in consecutive slots with K independent producers. In this case, phi of t is Kt. Why? Because for the right operation to fail, it can't make it onto any of the K blocks. So a censor would have to pay K successive proposers, P each, to ensure that they fail. For K large, this is going to give you excellent censorship resistance. The cost is that your effective bulletin board right time is the length time, is the time it takes to make K blocks. So we made another Twitter splash. Wartigwad tweeted about us and said that we might be AOC slash the Bernie Progressives. So our sort of Bernie request to you is end the proposal monopoly. So here's sort of our solution. So two parts to our solution. And there's a bunch of stuff. I mean, there's a bunch of engineering work to think through this, but there's a little bit of incentives and economics that we think makes it interesting and worth thinking through. So suppose instead of having one block producer in any given slot, in some sense, a lot of sources, the problem for me as an economist is that why we have many validators, we keep saying, oh, there are 10 million validators, one million validators, or whatever on key. At any given point in time, there's one proposal. And that the fact that for that crowd seconds, they're the only proposal is a source of monopoly power. Believe it or not, economists, except when they're being paid by them, don't like monopolies. So we would sort of one thing that could make this better is to have a bunch of concurrent block proposals. Each of these K concurrent block proposals produce blocks simultaneously. And a right operation succeeds as long as it makes it on one of them. Now, if you just do this with the same boring tip, then you'll achieve the same sort of KT censorship resistance, but without the time cost. Let's make this a little more interesting. To make this a little more interesting and add some incentives, you could allow for conditional dipping. So suppose the tip associated with the transaction was two dimensional. That is to say you submitted two tips, little t and capital T, with the interpretation of the way the voting board is going to work. If multiple proposals include the same data, then each of them gets paid little t. If only one producer includes the data, then that proposal gets paid capital T, where capital T is some number that's much larger than little t. You could have both of these people choice of the person submitting the tip. Now, what's nice about this? What's nice about this is that conditional dipping sets up a prisoner's dilemma among the block producers. So if I'm a producer, one of these K concurrent block producers, choosing whether or not to include a given transaction, I have a choice. I'm thinking should I include or not include? But my payoff depends not just on whether I include or don't include. It also depends on how much other people produce. So this is a standard two by two normal form game. But first, there are two producers here, a role player, which chooses which role they're playing, whether they include or don't include, the column player who chooses include or don't include. And the two-dimensional payoffs are the first number is the amount the row producer gets paid, the second amount is what the column producer gets paid. If both of them choose not to include, then nobody gets anything. If the other person is choosing to not include, but you switch to choosing include, capital T thing, capital T is larger than zero. So you want to do that, you want to include. But given that the other producer is including, remember, and you're not including, you're getting zero. If you switch to including, you get little t. So little t is still bigger than zero. That is to say, including is a dominant strategy. Many of the, many all whatever of the current producers will propose it, current proposals will include it. Note that now you have this interesting thing, which is to get a transaction on chain, you have to just, because everyone's including it, you have to pay little k times little t. But to keep it off the chain, the sensor has to pay every person not to include it for any given sensor. Their willingness to not include a t is sort of how much would it be worth it for being not to include the t if everyone else is not including it, which is capital T. So the censorship resistance of the transaction is much larger than the amount it costs to be included. So that's sort of the high level point. In the paper, which I'm not going to bore you with, it's been a long day for everyone involved. We work through the equilibrium revenues and bids in a formal auction model of independent product values with n honest bidders and one censoring bidder. And the main findings are sort of with low censorship resistance, this auction does not function as you desire. That is to say that the auction will produce low revenues. The censoring bidder makes off like a bandit, and the proposer makes a line shared as a surplus. With high censorship resistance, you return to the classical happy grounds of economic theory and the auction functions as intended. That's just sort of the high level paper. I'll have a link right at the end if you want to read it. What we're trying to propose is a normal measure of censorship resistance that's sort of economically motivated. And this and other measures of censorship, and make this slide before I knew what the order of presentations was, optimizing on this notion of censorship resistance will hopefully allow blockchains to reliably implement mechanisms that currently run off chain. So a whole bunch of stuff that we might want to do on chain, because we believe that we want to do everything on chain. We're currently moving it off chain because we don't know how to reliably do it on chain. And some of that is about compute and some of that is about logistics. But some of it I would suggest is about the concerns of, the concerns of can we reliably get all the inputs that we need to run our mechanism onto the blockchain in time with our censorship concerns. We're not trying to sell this as the only notion. We think this notion makes a lot of sense for DeFi. But especially for the rest of the salon, I'd be super interested to hear what are other definitions of censorship that we should be interested in. And then how can we optimize sort of the mechanics of our blockchain to get that to work. I want to, I mean, it sort of stuck with me. I've heard it before, but when Sreeram said it, it stuck with me. If you can't measure it, you can't improve it. And we're currently not measuring it. We're not measuring it in many ways. Firstly, censorship resistance by itself is something very hard to measure because it's really hard to see what isn't making it on chain. It's only easy to see what's making it on chain. It's easy to see if like DeFi protocols are self-censoring in some way, are they choosing suboptimal mechanisms that are the only ones available to them because they're not sort of confident in what the blockchain is able to provide. That is to say that providing censorship resistance will not just provide censorship resistance. It will also allow protocols to choose mechanisms that have better, more efficient outcomes. For instance, you might be able to get away with a much faster fraud proof window for L2s because you're not concerned about the fraud proofs being able to make it on chain and be adjudicated. You might be able to pick more efficiently five protocols. Auctions is one example, but you could think of so many others. The work is on that link, and feel free to read the paper and we're around today, and also for the rest of the week. Thank you. 