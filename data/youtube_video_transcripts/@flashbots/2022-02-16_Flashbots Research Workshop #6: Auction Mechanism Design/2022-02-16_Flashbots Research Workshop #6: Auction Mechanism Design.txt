i was just like why am i going to play games just sing on this mic um i could sing on this mic take over this call not with singing i don't okay what kind of input method do you have um it's going i mean this is not a great system i'm using a focusrite scarlett uh let me look at it 2552 no 2i2 i don't have i i mean i take i take this stuff kind of like you know i'm like a pro amateur like i i i want to use stuff that isn't horrible but i also don't want to spend money on a real system that i'm never really going to fully utilize but i'm it's going into a windows machine and it turns out that the focusrite drivers so my i had another focusrite device and its drivers for windows 10 were hot trash so i bought another focusrite device and its drivers are also still hot trash so it's a driver issue but it's not a very good interface because of that i see well it sounds sounds good maybe the problem is that window is trash well yeah that's what i yeah that's what i meant yeah all right uh on that note uh thanks for sharing uh the alpha leak on the latest update right um so uh yeah welcome everyone to uh our mev research workshop uh just like every other flashbacks research workshop um sorry for the late notice uh it's going to be unfortunate uh the uh the nature of this because we have so many um great research questions to explore and it's always hard to figure out which ones are the best one to for this particular session so for this one um we're going to dive deeper into auction mechanism design uh and our mev fellow from our first batch of mmb fellowship um uh soraya uh please um go ahead and i believe you have uh uh done some preparation i've got some slides i could talk about but but first i wanna sort of like introduce i think the overarching question that has come up as i think the driving force and behind you know behind realizing what an mvv geth auction would look like so one of the issues that i think tina and alex have really identified comes down to what do bot operators want to actually you know come on board and and take part in such an auction so as we all know right now you know a majority of these auctions take place in the mempool in the form of pgas where you know like all the information is public and where you know bot operators over time can adapt their strategies to how others are behaving now you know the the the general theoretical holy grail of what you know most of what most of what most auctions end up and end up being in the crypto space the second price uh sealed bid off sealed bid auctions but it but it has become clear that really what bot operators want is to not have to you know is is to not be subject to the sort of you know truth telling and you know paying the most paying really what they what they you know what's what other people value what they want is more transparency in the auction to actually be able to observe other people's bids other people's strategies and then bid according to that so with that i will share my slides and hopefully this will lead to some good discussion let's see i'm gonna do this [Music] okay can you all see this yep yep okay cool yes so the so the first question really that um that's on the screen now is exactly this right so do we care more about you know having a sealed bid second press auction where you know where the incentive is truth telling and where we can at least attempt to maximize the revenue that a auctioneer or in this case some miner might receive or is it better to really um you know use is an alternative where where you know where sealed bids are not where bids are not sealed where we release information about how people are bidding um perhaps in the form of rounds and this sort of i think leads to the the next more important question really is that you know uh a problem in this space really comes down to you know auctioneers can also be malicious right so if i'm a bot operator my concern is going to be that if we're dealing in dealing with sealed bid second price auctions in reality the auctioneer the miner in this case wants to you know of course earn as much as they can can always can always inject their own second highest price bids and sort of influence how much everyone ends up paying right so from the point of view of um bots who are actually you know uh taking part in these auctions there's a concern there that miners can arbitrarily influence the auction and and so they they they end up paying more so the question really comes down to is do we want a second price auction or do we want us to perhaps sacrifice on um on minor revenue for the sake of having a first price auction where such sort of a manipulation on behalf of the auctioneers is no longer is no longer no longer possible and um you know under certain cases the argument can be made that you know for example imagining that all the bidders and valuations are sort of drawn from a uniform distribution one can say okay like an expectation both in first price and second price auctions the x like an expectation the miner will earn the same amount of money right but of course you know that assumes that these valuations are independent and if they're not then of course second price will yield slightly higher auctioneer profit so from there like if we do think that you know first price auctions are the way to go where where bots can have a little bit more more trust more faith in the system then the question moves to okay if we're going with first price auctions should we consider a touch auction so the trade-off there are really are quite simple actually i mean in first price auctions auctioneers really have to don't have to do any work at all right like they they just have to wait and select the highest bid and they're happy in a touch auction though the miner has to do slightly some extra work in in setting you know the highest price does the starting starting price of the auction to be high enough that it's more than you know any the maximal extractable value of some you know of some transaction ordering opportunity but has to be you know not so high that these options take forever to actually yield some sort of a winner and of course as we know in practice like even though in theory the dutch auction first price shock first price auctions have you know had equivalent strategies in practice you know touch auctions actually yield higher revenue for miners so with that i think the main questions i want to try i want to drive the discussion from here is is you know is whether this you know this concern of malicious minors is is uh relevant whether it is significant and whether that and whether it's worth considering non-second price auctions and taking the hit in terms of how much actual how much actual revenue miners are going to earn and this all just and this all sort of i think the high level question is we want to move as much of the auction behavior out of the mempool and into the mov guest auction where and so how do we encourage that adoption the most and you know once we have adoption of course you know we can update the the how the auction works but at least at the start these concerns are worth addressing for um bot operators so i guess maybe before we can start with is is actually addressing this concern of transparency and whether you know um malicious auctioneers or something worth considering and how do we work around that i before i i would just have a one context expression because like um i mean before we talk about what auction strategy i currently don't know exactly what we are optioning off so is it is it uh is it the right to produce one block that is oh sure yeah let me see is this yeah or is this like a block next week or or i mean what about exactly yeah yeah let me set up the problem then so what we have here is imagine there's a block um you know some number of blocks in the future this can be yeah and it's exactly it's in blocks in the future it can be at the scale of hours or maybe even even days right and so what we have is the imagine like an oracle update is happening on the block right so what happens is a a single bidder will say here's a reference transaction that's going to be in the block and i want to submit and i want to submit a bundle of transactions in this order either before or or after this reference transaction and so the goal there is that bidder is trying to inject their own transaction right after or right and before this reference transaction and they are trying to extract some value out of it so then so they will want to bid you know less than how much they they value but you can consider the game to be there's a single reference transaction and multiple bidders are trying to bid for um uh their transaction either before or after this after this preference transaction so uh okay yeah sorry go ahead yeah so i i i have oh martin's still going i'm sorry go ahead martin sorry it's still still okay to me i mean there might be there would be two options so one one would be i can miner could could say well i'm expected to mine five or five blocks in the next hour or something like that and i option off those future blocks and you don't really know kind of what what transactions will be there in the mempool you don't really know it's it's more like an than it would be the average expected value of one block that would be one option what you could option off or you could auction off something kind of in real time where you see kind of right now with the given memphis with the given state with the given arbitrage opportunities you could try to do this in real time so i'm still not sure what about what of those two options we are talking so from the current uh like implementation i guess this is more of a question for um uh alex and maybe anyone else on the engineering side who's still here are the current mav like in the current like implementations are these auctions live for the next upcoming block or are they four blocks several blocks in the future right so currently you have to resubmit for for every block okay so live auction on the on the current upcoming block exactly so so people it's a first price auction where every bundle that is submitted for that block is competing with one another and they're paying a tip to the miner in terms of the block that using the block.coinbase uh so currently it is different bundles that participate in this first price auction and they they price their preference with the tip that they give to miners so it is competing opportunities and it'll be the one that pays the miner the highest that wins is that does that make sense martin yes yes uh i'm just saying kind of there could of course be other ways so you could say a miner could say well i have uh i have a track record of having so much power so i will likely produce 20 blocks in the next hour so i i'm kind of auctioning off 20 blocks already and kind of you can buy them already for the next hour and then i mean i don't know exactly whether i will deliver those 20 blocks but well maybe then it takes me an hour but an hour 10. um and then kind of for those blocks and you don't know yet yet which is our which those are but then kind of this one bot operator has exclusively already the right to well they already know they will get this block or well i mean they of course only know when when it's mine but you know if this minor mine's blocked then i will be able to build it yeah i think i think this kind of highlights the the same question that i had which is like the need for maybe like a meta framework stating the various different problem approaches so i think the first thing we talked about which is the like auction off clear future block x mev is like similar to probably the layer two mev auctions we're gonna have so i'd imagine probably the optimism uh system is gonna work like that um in terms of the layer one stuff it's it is this like more real-time continuous thing right now um so i wonder another question there is like yeah how would you how would the like fungibility of the various kind of uh arb transactions or or the various bid transactions people want to place affect the auction right because like you may be able to for example have two of these bids uh that are are satisfied together in like let's say the clearing of whatever auction you have um but it may be the case that like bid a cannot go through if bid b goes through those two are mutually exclusive et cetera so you might have like a very complex set of constraints on this like real time system so i wonder like i know the gnosis uh team has thought about this but there's obviously like a trade-off there between like computational clearing cost and i guess fairness and the various constraints you can affect and how long the auction takes these are all i think dimensions so it might be good to like articulate this and i think we do want to think about all these different types of auctions but i think um so yeah i think i think we do i don't know whether the ideal solution is the same or different for these like block future auctions versus the real time ones probably this slightly slightly different yeah so i that's very similar to what my questions were going to be just so for clarity's sake it uh well phil just said it i mean we need to be clear on exactly which sets of problems we're trying to solve with which auction solutions and then related to that and related to what phil said and related to gnosis the miner has a benefit in trying to form a block from the previous lost auctions it benefits everyone for them because the the computing of the block is going to be actually very comp expensive and complicated for the miner and so if they can uh cache that result and get more rewards um that's better for everyone and that needs to be a parameter that's addressed in the bundle itself like does this bundle absolutely need to be in this block or can it be in the next block or something like that and then um and so also another thing that i thought was interesting in your presentation and and thanks for giving it is that um we actually uh oh this is a this is a broader question about about how folks see me v geth being deployed um if each individual mining pool let's just call them pools for the sake of sanity um they should be uh they should be the auctioneers that are competing directly with each other right so their honesty is going to be you know it's an open market so uh we should assume that they're going to be you know we're going to make one of these economic rationality assumptions right where they can sort of cheat quote unquote but we expect them to be able to compete on price as well um one thing that uh maybe worth mentioning for that dutch auction first price uh first dutch auction example if you're putting the the computational weight on the miner in the sense where they have to propose a price i fear that it might be uh beyond their their uh capacity because it sounds like it's a very hard computational problem right so asking the miner to like suggest maybe they will do it naively at first and then i guess the market gets more efficient as they find like better ways to find a price but what you're essentially asking them is like finding all the potential muv and then that that's like the the like initial price or something yeah so it's actually along that line one thing i wanted to bring up was i think in the in the conversation in the past one possible outcome that we did foresee was that there would be these intermediaries who would run essentially auctions for smaller transaction bundles and then these intermediaries are the ones who actually take part in the auction with the actual with the actual miners submitting these larger bundles that they sort of you know that do their own auction they've sort of created and one concern there to me really is that is that there is extra revenue there to be extracted which which i would wholeheartedly expect miners to try to capture as much of that revenue as possible and does that mean that such intermediaries in the long term would eventually all just exit this system in in favor of minors performing that task to you know maximize how much they can actually extract so so here's an example um i kind of have right so imagine we have two intermediaries right that run their own network of um auctions right on small and small transaction transaction bundles matter now imagine network one has two bids right one is uh a bid of let's say ten coins the others a bit a bit of eight coins now imagine network two that has you know that's being operated by somebody has a bid of five right so now each of these on networks will report their own highest bid right say 10 and then five and so now the the the the top level option the miner will say okay the you know if i'm gonna run a second price auction i'm gonna say okay the winning bid is the network that submitted a bid of 10 but they pay only five now within their own network right the auction if let's say network one that had actually had the had the bids of ten and eight now they are paying only five coins but they internally can charge their bidders their second highest price and which in this case is eight is eight coins so they so i wonder if there are if if the i wonder if them if such opportunities for intermediaries to extract revenue exists and whether miners i think would would uh you know would value the trade-off of doing extra work to essentially remove the need for any intermediaries and extract that revenue themselves i just thought i have a slightly a little more vague than um it is probably half baked at the moment but um because that's just something i just read this morning in a paper about intermediaries and how they work in that auction so i thought it would be worth bringing this quest bringing this scenario up i i don't think that in this model you can have an uh intermediary any intermediary besides the mining pool for a couple of different reasons one of the reasons is the simple alpha leak right the intermediary will be seeing your bundles and so the intermediary will be able to to your point extract revenue before you even get to the um to the minor um and then so i think that that just from a privacy perspective uh is difficult and also in a similar vein from a sort of um i don't know what what the proper word for it is but the contract between the bundle submitter and the miner you you can't really add another agreement in there because then you lose that coupling right and so i think what you're really getting at uh is that the nature of the um mining software the the pool software will have to change and and the argument is that the pool operators themselves will need to have more cpu and of a different type necessarily than what they currently have to propose a block so right now a miner can propose a block with like a laptop or something right it's very low cpu but now um in order for a minor to to maximize the revenue and the blocks that they're proposing they're going to need some specific hardware configuration uh to be competitive um and so i think that that's actually fine um because it's going to be a little weird but uh but i think that ultimately um that's fine and it's also interesting because that that hardware can't be distributed um uh oh yeah i mean i i don't want to get started about 1559 whoever i didn't see the name on that but yeah let's pretend that 1559 doesn't exist for the moment because that uh that complicates things to a certain extent and then um i had one other comment uh with regards to i think well i don't remember it but yeah that's it so uh i i guess i have two comments uh or three i guess one of them is towards rick's point it would be good to generally develop a framework as maybe part of this deliverable and add this to the frp of like how do the very low level system details affect our choice of auction and like do they require or impose any constraints um especially in the layer one versus layer two case i think that would be that would be a good thing to study um i also yeah so i wonder i think i think it would be cool in general to to because i know you've been reading a lot of ad papers i would love some like summaries or insights or pointers to cool papers if we kind of finish once we finish this discussion but that's probably a longer term uh kind of question um and i also wonder like how is eth arbitrage unique like economically like it seems like there are for example like uh certain use cases and maybe we should enumerate in our mev taxonomy maybe this relates to like the taxonomy of mev but let's say like hacks or something what you have with hacks is like a very like uh sparse uh distribution of like a lot of value so like you very rarely get like a very big kind of mev opportunity uh for something like uh like a dutch auction where you need to have like some sort of price estimate um maybe let's say rolled over from before or something it seems like those kinds of shocks would be um would interact with that mechanism and like kind of uh yeah so yeah i think it would be good to also just enumerate in addition to the low level details just like maybe plug into the mev taxonomy somehow and say like are there any specific details of these mev types that mean that we can't or must use certain auction types um i guess the only other comment i have is that i don't feel bad for bot operators who want to see like order types i think we're going to have privacy eventually anyway so yeah that's actually a good point let me um i should be taking some notes let me just write that down real quick oh wait no this is all recorded right now okay yeah i think we're fine yep can i can i ask more basic question again what is currently the expectation that i mean miners could just like run from the bot operator right i mean like basically use something like a generalized front runner and whatever submission they they get they if i mean fill the example you brought with the hack where it's super juicy where it's kind of a thousand times higher than than what the auction is paying what prevents miners from them just uh running the front row yeah i mean i think one of the things that we would like to build uh at flashbots is i guess that privacy component so last roast we had some proposals for how to do that none of them are fully fleshed out yet but i think eventually we will have such a technique um in the short to medium term i guess it's like a trust relationship of like which miners you choose and monitoring them over time which is very sub-optimal so i think you know my guess is within the next year that tech piece should be done uh it doesn't it's not terribly a complicated thing to do i don't think at least to have a basic solution for that works well enough uh for this use case um but yeah i don't know i it is a big problem you're right um i think i think my concern with with auctions that are in the clear like uh what the bot operators really want more pga style auctions is just that there's all these weird politics around like latency and who peers with who and uh miners get lobbied to like sell their order flow and weird things like that and i just think that if we have privacy we can we can probably have a more efficient marketplace without any of that but that's just a hypothesis i would love to hear if people here disagree yeah um while you were saying that i was sort of working through and you know i'm jumping in sort of late so maybe someone's already answered this but it seems like once you're in the private network of the miner and you're submitting bundles you i don't know why a price time priority auction would be the wrong auction to have so there's this interesting question about actually forming the block and and um you know the interference between the transactions which is again a very complicated in the general case an extremely complicated problem but uh let's just say again for just so we're have a clear discussion topic i have two competing bundles the miner needs to form the block as quickly as possible that's still a requirement for them so they they say every five seconds i'm gonna pick a winner and that's what's going in the block and if you get in with the highest price within that five seconds you get in the block and there's not much else to you know really sort out and those batch auctions need to be very fast in order for the miner to facilitate the gossip that it needs to facilitate to get its block included so i i think that and until on the privacy side again i think practically speaking there's just going to be phil is absolutely right about you know a blind uh bid or some other sort of system um i think in the moment it will just be the sort of nasty well the the bots are peered with the miners and they trust the miner and they you know i don't know just go you know disparage them on twitter or something if they cheat i guess you know i think that's about where we would be um for a while so um but even i'm sorry i i i want to bring up maybe like a a a practical point of feedback that we got from from flashback to users already is that you know um should two users submit two bundles that are non-overlapping in any way it's a shame that currently there's only one bundle that's including the block when both could have been included for for the from from the flashback user perspective would be nicer for their bundle to be included they're not overlapping and from the minor perspective there's more possibility from taking two bundles in instead of one right so if you could it i i i understand that actually solving this in a general fashion would would mean finding a way to find like non-overlapping state or or something like this but maybe there's like naive bundle merging uh uh solutions we can start with and then kind of you know iterate on that so that the the the auction is more efficient in the sense where you know the tide rises for everyone then in my view ideally you would communicate with your bundle uh in some to some degree what what parts of the state your bundle is touching uh and if you well if yeah if you don't yeah i mean if or in many cases you can pretty precisely say okay only those uh seven contracts or so seven contracts are read from or written to and and then if yeah another bundle doesn't read or write to those contracts they definitely are not as they they definitely could be included both of them could be included and i know that you can even do this with static analysis or alex alexey knows much more about it but there are yeah you can just be looking at the transaction and looking at the up codes of the contract they're calling you can already get good knowledge about what state will be read from yeah so i mean like even in the current uh flashbacks like implementation or sorry the enemy guess implementation i think like an even more naive approach can just be right like that in the upcoming block there are essentially for any number of and you know any um for any reference transaction right like the options to submit a bundle around that reference transaction as long as uh you know can be considered just completely distinct auctions altogether right like if i have an oracle update and people are people submit their bid saying okay you know my reference transaction is this oracle update transaction and i want to be you know in in this location relative to that transaction and somebody else submits you know saying okay this other transaction i want to be you know in this location relevant to this other reference transaction transactions so even a naive solution can be that for any for all the possible transactions that will be included in the block treat you know treat um each of them as sort of um as sort of a preference transaction and and that just becomes like an independent auction so you can have essentially several auctions ongoing for different reference transactions the problem there of course is that you know you're going to run out of block space eventually so you do need to so the block producer doesn't need to at some point consider right which ones can even be included and so there it like it just becomes whichever whichever of these of these reference transaction auctions yields the highest you know the highest revenue for them um one thing i do want to say and go back to rick's point was that even with privacy you know like you say like you're saying that these um bot operators can go on twitter and complain that's you know some some minor is not acting is not acting as it should and just you know and basically rely on just trust in the minor but my concern there is that with sort of high privacy in the auction can such you know malicious minor behavior even be detected let alone you know somebody going online to complain about it and it can be something as simple as miners in checking their own you know um bids into an auction in order to inflate the price um i wanted to just suggest that um you know obviously the problem of computing generally kind of what affects what which transaction affects what is is large or larger i mean i wouldn't say intractable but it's very computationally intensive so um one thing which could be tried is to reduce the the space of all transactions that are kind of accepted for the auctions um for example to see whether this reduction will still um give bring the same value to to the users but but this reduction may allow much more efficient computation and so one specific reduction i would suggest first as unfortunately we haven't implemented this yet is that essentially when you are looking at any transaction so you try to execute it in a slightly modified version of evm in which it basically most things runs as they do except that the s load and extort instructions work in different way so as store essentially does pretty much nothing uh it blows up if the address value is undefined so we basically in the stack of evm values could be either concrete or let's say undefined something like this so the store store basically blows up with address is undefined but otherwise it does nothing and just remembers that okay this particular cell has been written so which basically populates the right set in the other hand s load also blows up if the address is undefined but if it's if it's defined then it also does almost apart from putting this undefined value on the stack and remembering that this cell has been read so this particular execution does not touch any state pretty much and can be processed i mean pretty quickly in parallel if you have enough cpu power you don't have to have a state so um i wonder like the the class of transactions that are that could be run like this without blowing up on those undefined addresses i mean probably quite rich and then if you have uh transactions which are in the same in this kind of class you can pre-run them in this particular modified evm and you can figure out their reads and write sets and you can figure out which ones are affecting the others and then you can basically figure out which ones could be done in parallel which ones are could be reordered and stuff like this so but we don't know yet whether this reduction actually removes uh some usefulness for the for what people are actually doing with mev so how does i don't know how these reductions they affect the mvv because if the auctioneer or somebody else or intermediary if they wanted to have a more efficient uh system they could they could offer to the users okay look guys we are only on a little acceptance which could be run like this but hopefully this is still good for you but we can basically process them in much much quicker fashion an idea maybe it already works like that i didn't know where this that indeed it's only one a bundle that can be included in a block at the moment but perhaps a quite a trivial improvement can be that to keep some kind of a stack of the mvv that the bundle extracts and order them in in the order of how much nav does the bundle extract and every time that you include the new one uh replay the bundles and kick out if one of them suddenly returns zero maybe or whatever all returns a value low and low enough that it's not no longer profitable to to include it and i'm not sure if that's uh how it already works or if it's is it a complicated or it or uh to implement it like that i would say that if you're if you do it in a sort of in general then we would you say quadratic complexity is that if you already have certain number of transactions in a bundle let's say a hundred and you try to test another one you have to re-execute all hundred again and then you then the transaction comes you do another hundred in the approach of reduction that i just uh talked about you don't have a quadratic uh it's basically uh it must be it probably would be linear or um and log n because what you do is you're ready for those 100 transactions that you have you've already computed their read write sets and all you need to do is to run a new one figure out the read write set and compare them and so this this effort is actually not going to be quadratic yeah that makes sense and another thing is that it doesn't require access to the state which is also not uh it's actually quite a big deal so we're going to talk on newman's family yeah i guess there's a few things that come from so i agree that that this merging is a big open question i don't think like only having one winner per block is the optimal option i think we can make that argument pretty easily um i wonder a few questions number one like would it be better to have multiple auction types where let's say one is like you just have one winner for each block and another one is you can have multiple winners but they have to conform to this kind of static criteria where you provide the state up front or like they're easily statically analyzable or whatever it might be and then you kind of have these multiple auctions that like form a meta auction that like fit against each other where like maybe one block this like transaction which really has to happen by itself is just way more mev and that's fine but like another one these like 30 dexarbs together kind of that don't conflict with each other override the like one mega thing that like screws up everyone's state so i wonder like how multiple option mechanisms together kind of um interacts with this and your second question i forgot it while i was saying my first one i was hoping no one would remember but i wanted to i mean i don't know the answer to this question but i would suspect that it is is still kind of lucrative and profitable then i would suspect the some kind of ecosystem are springing up in here because as we are as you just said uh feel that you know if there are different sort of reductions if you if there are different constraints that you can place to make your stuff more efficient and then you can uh announce these constraints to the users and users will say okay you know what is the the tightest not a constraint that my use case still works with uh because i i probably the tightest constraint would leave to the most efficient auctions and then i will go there and so each user will choose whatever the tightest constraint that it can satisfy and go there so for example the super general one would be where everybody can fit but it's going to be very inefficient and maybe they will only get a slot every like once every 100 blocks but the ones which are super efficient they might get a block like pretty much ever like immediately or something like if you win the auction you get straight in but you can run only very restricted uh types of transactions um so yeah maybe that's how but we cannot i think predict from that from the start what these all different types would be so i guess people have to figure out and compete about it yeah so i think building a modular system and experimenting is definitely something we're trying to push for so maybe that's a good also first approach is also figuring out figuring out like what data we want to gather from experiments in this first round because we kind of have this system and we can deploy these multiple types plus we have auctions that are already running that we can get data from uh so it might be worth just figuring out uh as another deliverable syria not to pile on but i guess that's what these calls do uh is like what metrics do we want to measure and publish and like have people exposed to researchers and things like that um and i remember my other question is just like i wonder so so in this adversarial environment we have if we have this constraint-based auction system that uh kind of alexi and and that we've all been talking about in the last few minutes i think you'd also need to have some mechanism to like enforce these constraints so you'd probably need like a wrapper contract where like if your block if your transaction is mined but the constraints are violated you don't end up paying anything um so that the miner can't kind of like steal your fee payment i don't know there's all sorts of concerns like that and also that you don't like lie about your constraints right so like if you lie about your constraints you should somehow be penalized for that too in this auction system because otherwise it's a dos uh vector yeah that's all that's quite kind of interesting yeah i also wonder not on the spot sorry go ahead uh yeah i was just going to say not to put you on that ben i know you guys are building an auction and i wonder if you've thought about these things or what your internal thinking is uh you don't have to say anything if you don't want to i just you know it's all library it's definitely everything y'all are saying it is vibing surviving hard um it's interesting this whole notion of the static analysis and sort of um uh you know multiple compatible bids being included in a single block it's actually notable that they think that like this approach has implications for scalability too so we're like doubly thinking about this because the same property that would allow you to have an access list um you know checker that allows you to to make sure that transactions don't intersect can actually allow block verification to happen in parallel too even outside of this like bidding you know gas strategy um so that's one comment and another thing that um is interesting that's been coming up here in discussion that i haven't considered in the context in which we're building which is layer two is this notion of the fact that we have miners um [Music] individually running muv geth syria one of the questions that you started with was like what are the like basically talking about the desirable properties of of pgas now and this is a this is an unknown hypothesis to me but my suspicion is that one nice thing about pgas is that they're a single marketplace um and so we we similarly have the ability to build a single marketplace for layer two it strikes me as an interesting problem on layer one that like to do like all the miners running mev guests like am i dan you brought this up as well am i bidding to every single one of them and like if not am i just like losing out on you know whatever percent of the hash rate i'm not bidding you know towards well you know i think uh i think that is a problem you guys will probably have to deal with also because there may be multiple layer twos and it might be the case that like whoever's bidding in your layer two might also be bidding in other layer twos and they might be placing their bid based on how much they expect to be able to extract from like cross layer two arms on like multiple competing systems so probably understanding yeah be important that's an interesting point yeah um i guess that would be would you think that would be suspicious specific to these strategies because one thing we were saying earlier is that like it makes sense to have auctions that are like sort of confined to particular strategy types like it makes sense that there's a front running style auction where you're just carrying to get a transaction in before right before another one versus like the versus like the hack thing where you're like i mean maybe you're still trying to get in before but it's just like this big opportunity that comes up um so i wonder if there are first order uh things that can prevent that problem because like front running is front running and it's on one chain and you're beating the liquidity at this one you know point in the state space yeah no i think uh i think that that that's an open question i don't know uh that's a that's an interesting thing to say the other the other thing the other thing that i will opportunity oh yeah someone go go go use serious laptop while it's still uh logged in um the other thing which i'll throw out just to share um some of the layer two context that we at optimism are coming from we honestly have like two layers like two considerations going on here one of them is that we have a layer two system and we have the ability to auction off like on layer one the ability to produce blocks and the second one that we have is once someone has that ability to produce blocks it still seems probable that the person who's best suited to producing blocks and like doing those layer two things would still want to go to front runner it's like you know front runners and other like you know bot operators and say hey can you help me choose this ordering in a profitable way um so we've like published more on the former which is like have some sort of auction system that makes you become a minor or at least what's a minor in the context that we've been talking about here um so i just thought that's worth throwing out we kind of have two layers of this we have like something that's replacing mining and then we have the same problem that you guys are working on at the layer of mining yeah so i i think that you uh uh so i think that there's a different there's actually a different slightly different problem for the l1 uh optimism on l1 is that you actually want to have a long-term contract with a miner that guarantees that they'll include your your transactions right you want to be able to have some sort of proof that um who who whichever operator submits the transaction that miner or some set of miners will guarantee the inclusion um because that will like stop a whole class of attacks and that's like i think a very different contract than what uh you know a pga uh participant wants um it's like to the point where it's worth you know call calling them out um and then uh by my other comment was oh phil was saying or ben you're you're talk i don't actually i'm not sure who was saying it that one of the benefits of um the existing pgas is that it's one marketplace and i think that like very literally what we're talking about in this conversation like the whole point of mev guth isn't it is an acknowledgement that that space is fracturing right that it's necessarily going to fracture and like that's that's like essential to the discussion is that the different percentages of hash power are now basically claim you know we're converging to a world and i will mention 1559 here because i've thought about this um if you add 1559 and you add mev geth uh people there will be uh there won't be any more transactions in the mimpool you know any transaction of any value there'll be weird cheap bs in the mempool and anything of value is either going to go to a is going to go to some minor and so um i think that you know i don't know that everyone's really thought through uh obviously this is a call we're probably more you know more than the general population we certainly thought through the implications of that but that but that's the direction um that we're going in and i i yeah we just have to accept it basically yeah i totally uh agree um i think the only reason that it's one marketplace is that that's just what the software does out of the box but the incentives are definitely there to change it and uh that is starting to happen and it's been happening and uh i expect it will continue to happen so yeah i think we definitely i think it's more about understanding the emergent properties of this like already chaotic marketplace and like understanding like what happens if we can introduce privacy and uh how can we reason about these channels and how can we if we do introduce privacy can we still somehow create a single marketplace out of these multiple smaller marketplaces um like my hypothesis is maybe like if you have kind of private bids that can be passed around the same way mempool messages can be now um i think your advantage as a large trader is to use a network like that to access more hash power if you trust it to work um it's better than the mempool where like anyone can front run you i think that's that's yeah but but we could also easily end up in the universe where it's just like a bunch of miners having their own fiefdoms and uh yeah i i would personally like to prevent that but it's possible i think yeah i think with the with privacy in there i think the more the hypothesis that i probably think is most likely is exactly that it becomes a single marketplace where you just distribute your your bids over as much as as much as power as you can as you can and then you can essentially simulate the mental environment without the with that front running i think that's probably the most the more likely outcome than just having you know like like you said minor fiefdoms that sort of are and that sort of split the market up all right sorry go ahead can i ask us maybe a slightly naive question from having missed conversations about how this privacy works um like what is there a straw man for how you would implement this privacy and like why does introducing privacy not not like nullified the whole product like won't users use that privacy to keep themselves from being front run by these spots you know in the same way they're preventing each other from being far around yeah i think they will uh they will do that there will still be space for bots to do things like there will still be bots that for example respond to market conditions and things like that or otherwise have like inferences on user order flow the same way you have them in like the traditional market where like it's not the case that every bot on the stock market can see your order book before it hits like the new york stock exchange or your orders which is like kind of the eth world of like an open mempool setting but at the same time they can there's still opportunities to take advantage of asymmetries and other things kind of uh that don't directly come from just seeing the order before it's placed uh that probably will still exist so i'd imagine yeah some to some extent users will do that and like part of the bundle combination and all this stuff we've mentioned will be part of that but there will still also probably be some cases where like there will inevitably be bots like liquidating ease is a good example of something that's on the network today that like you know uh anyone can do it but like still only one person is gonna end up profiting from that so there has to be some like mechanism there to make that happen um sorry go ahead oh i was just going to say are are we considering like some sort of like zkp based block formation in terms of the privacy stuff because i'm i'm having i think i'm kind of with ben i'm having a difficult time imagining um how this privacy stuff could work and also um isn't it sort of a base layer protocol change like it's great that we're all talking about the protocol layer and i am happy to stay there but if we're talking about a privacy mempool how how do we achieve that and i and to ben's point i assume it's not sg i i would assume it's not sgx actually so i'm curious i think sgx is a good straw man so we had a few different alternatives that we discussed in the last roast i don't know which one of them are feasible like the ideal would kind of be like a mpc like with the miner um possibly with like a neutral arbiter who could like ensure data was available basically the problem is the user wants to place a bid to the miner they have to prove that their bid is valid and they have to prove how much the miner is going to get paid from their bid and the miner wants to know that if they actually mine this hash that the the block will not be useless that like a it will be valid and b the data will be revealed quickly so that they can profit from actually mining the block and they're not penalized on the network uh you know i i encourage you guys to to join these conversations but i think sgx is pretty much the only only solution that works without economic bonds and like crypto economic assumptions um uh honey badger could work you would have to run a whole eth client in it and the problem is that like any penalty on the miners uh kind of uh uh latency is is is a is a penalty on their economics and so the mev would have to be really high for them to take that um i will say that i think you can design a network with sgx or trusted hardware such that if that piece breaks or is compromised the only thing you will do is like fall back to pgas um so like that would be the ideal that's the straw man like assume it works uh but i would love to have more conversations like i don't think i don't want sgx in the network long term personally and like maybe maybe a solution is like a more specialized smart contract language that is like more natively suited to zero knowledge proofs of of like validity or some other static proofs of validity that maybe will come anyway from like various scalability changes uh might make this easier i don't know long term i think this is very much an open question but i think one straw man is use sgx you can do it you can develop a private system that as long as sgx doesn't break it works and uh you know i think that will still probably be more efficient than uh than the mempool and then individual minor auctions but i'd love to hear your thoughts um and also i have a hard stop in nine minutes because i have to catch the last chair lift so i really love these conversations but uh just just for the record i'm not leaving because i don't love you guys that's flames i i have lots of thoughts i'm i'm i'm i'm muted with with with thoughts um i agree with your argument about sgx in the short term i think that if we're going to add zkp's at the protocol layer to make assertion make this sort of composability assertion that we're talking about we might as well just fix the evm i mean that's it in some sense it's a it's a it's a back door into saying well we need to fix the composability in the evm right because we're really talking about why is it that these transactions don't have to take semaphores uh in order to mutate the shared state right so um i think it's a that's a really i'm like i'm still i can barely speak that's i think it's a really deep question because essentially what we're what we're acknowledging is that um you know we're we're at a point now where we're like okay the the shared memory of the evm is really broken to the point where it breaks like everything we have to go back and fix it i think that might be a point that sharding will maybe take us to anyway because i also just don't see like uh like i think things get really weird with like pgas and like uh dynamic memory accesses and r bots x like sharding x like possibly shard gentrification um x like whoever decides ordering of transactions between shards or like which cross-chart transactions get priority i think there's a lot of like really ugly edge cases that will have to be looked at so i think you're right that like long term that might be the only solution is to like think about composability more generally which is which is to be fair what the bitcoin maximalists said would happen um so maybe maybe they deserve some credit for that but i think that was yeah i don't know if exactly uh i don't know exactly what the memory overhaul is that will be a solution like i don't think it's as simple as like just go to the utxo model uh because i think that there's a lot of trade-offs there that need to be thought about but yeah i think this deserves like a much deeper longer conversation also about the law yeah and to to prevent rick from getting started at raging at the evm any further and to catch you before you go phil i do have one more question to loop back on an earlier comment you made when i asked about privacy so i definitely it definitely makes sense to me that like there's lots of slow market arbitrage opportunities even in like a very private mempool regime um i guess but but i guess my question then is like um to me it seems like the current mev guest implementation is very much not is not very well suited for slow market arbitrage um you know like strategies or like like preferences um so i do wonder like um how careful we have to be in trying to design for something trying to design a system for privacy when if the system has privacy it like fundamentally changes the uh like the preferences of the participants how does it change the preferences of the participants say like you know using mvvgf now when they submit their transactions the miner can't can't see the content of their transaction before it's mine how would that change the auction for example or um yeah i guess the the example that i'm thinking of then yeah correct definitely correct me if i'm if i'm off the mark but an example i'm thinking of is just like okay let's say there's a private mempool now i can't front run a uniswap trade so the the way that i'm going to extract value from uniswap is i'm going to look at the price of off chain exchanges with lower latency and try to arb against those off chain prices i expect with where the off chain price seemed to be in the previous block when i could see it right so i i think to some extent having a privacy system makes market a little bit less efficient where you're pushing the efficiency back to the next block you still have different liquidity pools within d5 and if you have like a price dislocation and a new swap pool then someone would arg between that sushi swap pool and unit swap pool but instead of front running in order uh sandwiching it or back running an order you wait till some kind of like price efficiency and there would still be opportunities there um for people to do so but to some extent with a fully private system to me it seems like you're pushing efficiency back to the next block in a way if that makes sense yeah i think so okay i'll have to think about that more i think that's just like a generally open like fascinating question to me is like in a you know in this private regime what mev opportunities disappear what one's up here and like what ones remain yeah i think definitely you won't have like microneedling yeah i mean you might have dynamic backgrounding where like you spam transactions that like check dynamic backgrounding conditions kind of on the chain but i think that is definitely like we need like a 4d matrix of like mev types x like auction mechanism x like layer 1 layer 2 x like evm internals and like how do all these things kind of interact in each box um so i think that that's definitely a clear deliverable is somewhat forming i totally agree i think you're going to select a statistical art right where uh maybe there's like patterns you can discover in like price discrepancies or even like oracle updates and then you can like submit those without having a view of the actual transactions in the mempo so maybe there'll be like strategies there yeah i imagine there'll also be arbs of the form like i send this bundle i don't know how much money the bundle is going to make it could make one eth 10 50. um uh but you know i have some model for how much this will make on average so i'm going to bid according to my model and kind of subsidize that so those kinds of bids could also be could exist one day and more probabilistic like on chain logic style arbs i think that's worth considering in this taxonomy also um i want to maybe bring up another question again bringing it back to searcher feedback we go in the so bring it back to like the current system that doesn't have privacy and privacy is not uh something that it seems that is implementable in you know the short term i think if you're running a you know flashback searcher and you're using a flashback system the the you know the main recurring question is like how do i set my my tip right because uh a normal bot operator is used to looking at the mempool looking at other transactions and then you know reactively bidding uh and doing this this kind of pga activity that phil described in flashback 2.0 um in that system you know it's a first by seal bid auction and they don't necessarily have a way to determine their bid my answer so far has been like you can look at similar transactions historically and the tip you know the successful flashback button and the the tip that was given and then you can maybe from that make an edge but the where they don't know if they could have bit lower or not and they don't have a lot of information for for them to understand that i think so uh yeah just bringing bring that up see you phil by the way i enjoy the scheme thanks guys do you do you have already some empirical data on on the options that have been running so far so i mean like is the is the tip is it like the average gas price or is it 10 times the average gas price or it's 100 times or just just very roughly what's what's going on um we have some data there's there's nothing that i can say conclusively i don't know is scott on this call scott if you're here show yourself uh if scott's not on this call it's this is definitely something we can dig the problem is i'm on the call um yeah i mean there's right now the number of searches we have is is uh you know it isn't so large that i think that there's a lot of competition especially for the same opportunities um you know we've we've been really you know ensuring that we have a wider support for mvv strategies than than competition so i don't think we have a full picture of that yet you know i mean they they all they are taking mbv opportunities that are available on chain and i think we could probably get some data about that because there is some information asymmetry for those that are participating in flashbacks that they can they still need to beat the vanilla ordered block and so yeah it might be interesting to get some of that data about how flashback users or even tai chi users might be benefiting from this you know seeing the bids of of standard transactions while others can't see their own oh yeah we haven't looked into that yet right so as scott was saying naively the the minimum bid you need to submit is enough so that the flashbacks block is more profitable than the vanilla block than a miner would mine right but then that's in the case where you're the only one submitting a bundle for that particular block as soon as you have multiple bundle submitters um you know what do you bid do you just you know increase the bid and hope it works or if it doesn't work do you just keep on increasing until it works i'm not sure uh um i mean i'd like to have a better answer for for operators and something that's also uh more helpful to them than just yeah just just basically like through a dart in the dark and hope it lands i think that's just more to the point why like current level i'm mempool pgas are sort of you know why they work right i mean like that and that being able to observe others others betting strategies seems to be something very important to operators you know even to the point i would argue that you know without it they would likely um you know stick to memphil pgas over you know some sort of mvp get auction so the interesting question there is the miners would i think it doesn't i mean if the if the if the people can if the bots want to uh try to stay on those um on that hash power that that's a fine option for them but if more hash power moves towards privacy it sort of happens regardless of what the what the bots want and i think that they'll just be um there's certainly certain types of arbs i mean i think that people i think that bots will end up paying maybe not the majority to their minor but a significant amount um and there's probably some interesting game theory there uh given the you know the the distribution of hash power so i i think that ultimately the effectively what will happen is the mev supporting miners and the searchers will be colluding against the non-cooperators to push them out of the market one thing i will add to that as something that we had fought before is it's definitely kind of to be expected that the tip for the the you know as as the markets become more efficient and a strategy becomes more known or an arb in particular or discrepancy becomes more widely known the tip will increase right because uh you'll you know more people will compete for it and so they'll be willing to give more and more uh of their margin to the miner but then what we imagine potentially happening as well is because miners select the most profitable bundle you could bundle several opportunities within your bundle one like the for example the the one that's widely known you give 100 of it and then you you have another one in there that's less widely known where you get a smaller tip right so you might be included several several opportunities within one bundle uh to just uh maximize the bundle profitability and so you have you have these weird potential because i mean a bundle still has a fixed size right it's still i guess limited by but you can't submit a bundle that's larger than a block so there's only so many strategies maybe there's like a churn or like a a cycle in in you know tip going from like 100 to maybe less when there's other opportunities that are more profitable and then coming back and and like the bundle mixing um just putting it out there yeah i think there's also the question of or to your point about that that oscillating price that's also a reason why um miners might uh offer a side deal to reveal the previous uh bundles to uh other bundle purchaser you know other bots right i think that's something else that we have to put into the model is even if it is a commit reveal you have to assume that the miners are going to turn around and sell that data um to competing uh operators competing bots it's actually a fantastic point i think that's probably going to be that seems probably actually to be quite likely um i want to ask you rick on a point you made i think two points ago about about miners and and bots sort of working together to to push out non-cooperating bots can you elaborate from what you um how exactly you define non-carpeting bots are you saying only those who end up like sticking to measurement pgas versus actually adopting like um adopting mv death and performing those auctions yeah that's that's exactly what i meant yeah so if you if you're just in the pga auction you're going to be revealing um you know there's this whole other group of people that are effectively in this very odd way cooperating against you yeah you're revealing data to them and they're not revealing data to you so yeah i get it okay that makes sense yeah [Music] um so i think for um like for uh we're going to summarize i guess some of the tldrs from a lot of really cool brainstorming uh from today but uh i would love to follow up with a lot of our um uh new friends on the call um especially alexi um martin rick and um everyone and sam everyone here um for uh your uh your your comments and actually uh i think we would like to host another uh more structured uh discussion on block space auction design at some point in the near future to kind of pick up a couple of the i would say more of the low-hanging fruits and also do it in a more systematic way maybe mapping out the 4d chess as a starting point before the call so that we could kind of dive into it and weigh the trade-off within the design space i wonder uh how does everyone think about that idea to kind of uh in the next couple weeks find a time to dive deeper into uh into this question so that we could actually come up with i would say a more uh holistic v uh rather than um just open-ended questions i mean i would definitely prefer the uh kind of the the discussion about specific topics uh you know this the the the the the more narrow the topic the better um obviously uh but yeah i i try you know not to have too many goals but definitely i could spare one hour or something like that over the next two weeks but yeah so we basically yeah i think it's fine for me [Music] yeah that would be uh that'll be fantastic uh to to have you guys uh i think we uh will be able to uh like we'll we'll draft the agenda and share it with everyone before the call to see because i think everyone here on this call brings a very unique angle um and in particular i think a lot of us are a big fan of work uh from um you know uh by the turbo gas team as well as big fan of work from the open ethereum collective et cetera so like i think a lot of uh we haven't really been able to uh uh dive deeper like uh like we would love to kind of have more of that exchange uh from essentially the creators like builders who are actually providing these uh core uh instruments that uh the current block producers are using so i think that's a very unique angle and so yeah thank you guys for being on this call and uh and we'll follow up with you um i would like to um if you guys are not in our discord group um we can share it afterwards or can find um any of us on twitter um and uh yeah whatever is the best way if you're not already within our community cool okay well all right um so ryan any uh closing thoughts um my clothing thoughts were are actual i've been sort of trying to write them out in the chat as well i think i think two points to really take away and think about and think about for i think maybe next week or the week after some research workshop is one is is what a lexi had brought up with these sort of smaller constrained auctions and using them to aggregate you know as many uh target as many bundles as we can into the block you know based on what sort of you know state space they touch i think that's probably worth exploring for um a future call and just sort of you know trying to flesh out that direction as as best as we can and also the 4d access that still kind of i identified for classifying not only the auction mechanisms that will work out but also how they're how they're impacted by low level protocol evm constraints i think that i will probably talk to phil more about um after the call is over after he's done skiing and i'll try to you know maybe flesh out such an axes for our next research workshop that might sort of illuminate you know more precise design choices but besides that that's i think only clothing thoughts i have i think yeah the uh the smaller auctions constrained auctions is like in my guess i think probably the most fruitful drew correction to at least explore [Music] thank you thank you all for joining this was this was great yeah thank you so much thank you thank you bye yeah thanks i had a really really good time right here thank you you 