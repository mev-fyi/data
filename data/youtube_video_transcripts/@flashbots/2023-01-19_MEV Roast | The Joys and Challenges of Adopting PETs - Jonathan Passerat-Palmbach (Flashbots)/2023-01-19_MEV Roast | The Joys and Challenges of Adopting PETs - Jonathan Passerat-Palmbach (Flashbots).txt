hello everyone it's going to be a bit high level uh I'm not going to go into too much details it's mostly about uh giving you a flavor of like what's possible as of today uh I think it's gonna Echo uh what Robert just showed you in terms of like uh run time and like challenges to get uh to get things uh up and running and uh what we could expect uh what we could do to improve the current situation so first of all had a previous enhancing Technologies this representation is like something that you know we've agreed upon in in the in the past Community uh basically speeding them into three different categories depending on like what uh what is their main feature do they protect the privacy of the input the outputs or are they more of a of a governance uh technology um and you see that some of them are kind of like overlapping uh but what I think it's important to understand from this representation is that we tend to con to to to to to mix sometimes the notion of a privacy confidentiality and all these kind of things uh so in the World of Pets we try to stick to using privacy uh for for what we mean as like output privacy so technologies that guarantee that uh the results of an application remain private uh well or at least do not disclose any any any information about about the input so that's kind of like the guarantees that a differential we give you for example which we're not going to address in this talk and similarly you've got overlapping text like I'm not going to address Snorks because I think it's probably like the most familiar piece of technology you have in in this community so we're going to stick to to the technologies that that provide confidentiality I'm mostly going to cover Tes NPC and nfat for that matter so in terms of like the applications of privacy at flashbots um I think a good reference to like the the use cases we that are listed on the left uh so mostly we're going to be working at applying privacy to to these use cases it's like it's very high level uh I think Robert's presentation was like one uh component within uh within the other blockchain for example um quintesses Talk could give you more details and I think in general it's a it's worth exploring the the writings website as well as the Forum uh to get a better thing of these uh of each of these problems but that's basically that the context to which we want to to apply these privacy texts and basically um it's not about providing privacy I think uh probably like a lot of us are very keen on like uh privacy as a right and those kind of things but we need to see beyond that we need to understand that privacy is actually a mean to unlock new use cases but it's also a way to increase the decentralization of the of the services that flashbots have been providing for a while uh and that the community has trusted flashbacks to provide so by injecting privacy in in the services we're hoping to increase their their resilience increase their decentralization but also to Foster collaboration between actors that would normally not uh have the incentive to collaborate into performing a Joint Task together that might even be considered to be in competition when trying to perform a touch like I'm thinking of block building for example where if we want to hope to have distributed black building we need to we need block Builders to share information that they would not have any interest to share normally um in terms of like the requirements that that we're expecting from these Technologies we we want a lot of things actually uh we want speeds uh in order to not be too constrained by like the The Flash transactions we want to be able to scale uh to a large number of users um of course we want uh the maximal security guarantees uh for the minimal assumptions and especially we want well-defined assumptions that's going to be important in uh some of the text we're covering but we'll see it's not always extremely clear uh what what is the threat model um maybe something we've not addressed too much today when when you start applying these uh this kind of like Technologies and PC and FH in particular uh you might lose some uh Precision in the calculations you're making uh I my my take is that this might have an impact and we need to be extremely aware of that too uh the one thing we don't need and that's good because like tends to be changing as well sometimes to provide is for secrecy so we know in the case of uh of uh trying to implement an encrypted mental for example or or private smart contracts like uh Andrew presented everything that we are manipulating as like sensitive data is short-lived uh in in the sense that it's not it doesn't remain sensitive forever once the competition is done and the information has been processed and the transaction ends on chain it doesn't really matter if like uh the this competition can be can be disclosed afterwards uh at least uh we I don't think we need uh forward secrecy um in terms of the roadmap itself I think you've understood by now that uh in the short term we're pretty much focusing on on Intel sdx um again I want to to to make it uh very clear that we're not uh we're not like sgx Fanboys uh we just like taking the pragmatic stance of like what is the most easy thing to deploy and the most ready thing to deploy uh today that can like bring us closer to the air to the end game uh but definitely our goal is to phase out sgx and even maybe like Hardware uh dependencies in general and you've seen you've just seen like a first item in doing so with Robert's presentation on the background um by any means that doesn't mean we committed to to this path either we exploring like multiple python pilot and you're more than welcome to join us in this journey um without further Ado just diving into each of the texts out we've heard a lot about uh about tea so I think a great reference to that is of course endless presentations sgx as a te is by far like the most popular of the of the two years of today uh which is it's good in a way because like it's received a lot of scrutiny you've got lots of of papers about it so just to summarize what it is technically it's just a set of like CP instructions uh that allow you to to create uh enclaves uh what we call like initially what was uh trusted portion of an application and that I've grown into sometimes being like whole applications containers uh and maybe not even like whole virtual machines and the idea is that you'll get confident total confidentially of your data during the computation so anything that happens within the same slave um cannot be seen by any external party of the of the system not even like the the rooted me spreader the cloud operator if you are in a cloud setting uh so it's very much like these protected environments um and we know that sdx has received a lot of bad press uh it's been broken over and over again by various attacks lots of academic papers uh in these in this direction so I guess that the interesting question today is uh why uh so we've started to touch upon it as in uh it's received a lot of scrutiny because it's been one of the first uh tees that was available and and one of the probably like easiest to uh to get your hands on it was just an SDK just extending like that C plus plus so it was relatively easy for people to start developing with it my take on that is that the the problems that we see repeatedly with sex um are mostly due to to the way to be designed so it's been designed by Intel on top of uh of Intel CPUs which means is that it's sharing various components uh like architectural and microarchitectural contents like cache lines for example uh that you know a lot of uh of the side channels that we've seen against sgx but it's also sharing uh all the components of the system like uh um the the memory address bus Which you know make it uh pretty hard to to defend uh thoroughly into in against against some of the attacks so what's the problem the problem with that is that it was not maybe not like um what Intel wanted to to see from uh from from these technologies that initially was not maybe meant uh to have to have this kind of applications so we've seen a move by Intel recently uh since the ice Lake uh generation of of uh of intense CPUs that answered one request from the community to have larger enclaves uh you might have uh quotes from endless presentation that the first generation of sgx and Clays uh could be as much could could get as much as like 128 Megs of memory uh and Intel decided to lift this this uh constraint another like you know multiple hundreds of gigabytes of memory the trade-off for that is that we've lost uh we've lost the Integrity in in memory so we don't really have like the same uh security guarantees from these uh previous generation of sdx to the new one and the way inside uh defended against that is that they they repurpose sgx as a cloud only technology or a cloud-first technology so it's not meant to be uh massively deployed on on desktops or laptops anymore which of course like hurts decentralization and you know maybe pushes us even further to try and find uh Alternatives and and what could they be um of course we've we're going to see like the pure software crypto uh but maybe in the meantime uh before they get like ready for for the prime production um we can also explore uh other teas that might not have like the same design flows as sgx has uh so I'm thinking for example um Keystone uh which is very interesting project uh could put together by uh don song in the team um maybe we might want to to design a custom Enclave even if that would be even more uh challenging in resource demanding I guess um one notion that would be interesting as well in the context of decentralization is to is to try and see uh whether a heterogeneous network of of tees uh would make sense uh bearing in mind that the main challenge is that they do not have a Common Thread model so it doesn't mean the same thing to have a name clay we've kind of call it an enclave running an sgx or SCD for example uh let alone TDX and like all the other Alternatives so that that could be an interesting challenge to to see if we could if we could Define like this Common Thread model right switching to uh software crypto you've just seen a very interesting application of secure MPC uh with Robert so I think you've understood the global ID so you have uh input data here the five and we're basically splitting into different shares and due to like the whole morphic properties of these shares we're able to apply uh operations before recombining these shares to obtain uh the the result that you would expect so it kind of works well until until basically um you need like more complex operations so when you start from a general purpose secret sharing either like additive or show me a secret sharing a protocol you can you can do these kind of things now if you want to if you want to get to get to better performances usually what happens is that you want to design custom protocols right as soon as you want to start to to do custom functions and the interesting thing when you start designing custom protocols is that if you look in the literature and uh in in this presentation like most of the examples are drawn from the Privacy preserving machine learning literature there's two reasons for that a and that's my background uh so I've got a few papers uh and readings on that and the second is that it's probably like a it tends to be like very large problems that requires a lot of of competing time in in memory so they tend to set like a higher bound an upper bound of like what you should expect from the behavior of the custom protocols as well and and in particular what I like to to note in like these um in these two in these two uh tables that you've got on the right is that you you can see that um MPC has to be considered into different settings uh we we tend to We tend to just like in experiments uh just reports the the things that we've done that we've run on our local infrastructure but if we think into the context of flashbots or any other decentralized application we should be more interested in like how NPC applications behave uh in uh one setting so across the internet with like uh longer latencies the reason why is that um that's we the domain the main bottleneck of of NPC Protocols are um is communication it's bandwidth uh so the the goal basically the the game uh in in NPC to to improve the performances uh is to is to try and address uh this communication bound problem so either reduce the amount of communication that are required um or uh redesign uh the protocols to make to make sure that they can uh the degenerating like less data or have less rounds of of communication for example um another of hope uh in this in with this regard is that uh in this uh in this page it is from uh that is that is uh you have a diagram on the right um You can see that uh with the right custom protocol um with a problem side problem size growing the author has been able to basically switch the the natural problem of MPC uh from being communication bound to being computation bound uh so it means that with the right uh right designs we can potentially uh go beyond this communication bounds problem with MPC and then focus on like accelerating uh the computation and and kind of like Get The Best of Both Worlds that's kind of like what I was hinting at in in the chat before uh when when Robert was like making this suggestion uh this there's quite a few protocols uh in NPC that also try to that that use uh morphic encryption uh natively within the protocol to reduce uh the amount of communication rounds that are required so it's we'll see that it's pretty important to to not see these all of these Technologies uh as Standalone but as like pieces of a of a bigger jigsaw Maybe switching to homorphic encryption Okay so same thing I'm not going to go into into nitty-gritty details about how fhe works we should I mean we could do that uh another day maybe uh because we're definitely going to go over time way way over time if we do that what's what you get from fhe if you've not uh code that yet is that you're able to um perform uh alphabetic operations on ciphertext and when you decrypt the ciphertext if you've done things right you basically obtain the same results you would have by performing the same operational sequence of operations on Plain texts um so you you once again have like these problems expressed as circuits as we have in stocks and and as we've seen uh in the in the MPC context as well what's interesting with uh homophoic encryption what is it desirable especially in all kind of uh of fields uh is that the security assumptions of most schemes are relying on on that is today's cryptography so which is believed to be uh post Quantum secure uh so you know there's like a lot of conversations about um about about the state of cryptography and like uh quantum computers coming and breaking everything uh at least uh we have like stronger guarantees in in the world of uh homophic encryption um we have like uh different types of schemes uh that tend to manipulate different uh different data and the like data um so schemes like focusing on on manipulating uh binary data um like just booleans [Music] um others typically like in the in the machine learning space there's a strong appeal for uh schemes manipulating floating points but also integers um they can be combined so again you can come up with like more uh interesting protocols by by doing these kind of things there's two things uh that we need to pay attention to uh when when dealing with horrific encryption um I think Justin hinted at the fact that um there is this notion of depth uh in in the circus three buildings are what's uh what's to be considered really is like what we call the multiplicative depth so what is the maximum number of multiplications we need to go through in order to reach the the output because like in in homorphic encryption um in order to protect the ciphertext from being uh from from uh from being like revealed uh basically we're adding noise to this ciphertext and uh whenever you put some operations the noise from the two ciphertext that you're adding or multiplying uh combined uh when you perform additions the the combination of these noise is like relatively easy to to to to keep under control but when you perform multiplications the noise grows uh exponentially uh so that's why you want to to make sure that the the multiplicative depth of your circuit uh doesn't go too far otherwise you have to go uh through an operation called bootstrapping uh to reset the noise of your circuit but that just introduces like uh computational extra computational overhead and the second point that we need to pay attention to that is uh often uh not uh not evokes we just like tend to focus on like the the runtime uh there's uh ciphertax tend to be big with her whole food encryption in some schemes uh the ciphertext to plain text ratio is like several others of magnitude larger uh which is called like ciphertext expansion so it's definitely an area that uh we want to pay attention to uh with fhe in terms of like what's possible of today uh I've got two uh again examples drawn from the uh privacy preserving ml literature so on the left uh you've got a pure software approach uh that's the I've drawn from a company called Zama uh they are building a an fhe Library called concrete and they've introduced like a very nice trick uh in in this bootstrapping when they're doing these bootstrapping operation that I was mentioning before they make the most of it by either way for this thing like look up tables in there that allows them to encode very complex operations and as you can see like by doing so they came up with a scheme where even for relatively large number of operations in your network evaluation they only have a 100x overhead which is you know pretty impressive compared to what we were used to before uh for homographic encryption and on the right uh we've got the hardware version of that which is a program by DARPA called deprive whose goal was to reduce the other head of homework encryption to just 10x so just a load of magnitude as far as I know it's going pretty well I was pretty pleased to see that as of yesterday or two days ago a company called Duality was awarded a contract to enter phase two of the uh of the of the D Prime program so that means that at the same time we have uh Innovation on the on the schemes and also Innovation on the hardware side uh which you know makes me pretty confident in like uh make me wants to to to to put to take the same bet as Justin was saying before that it's not crazy to think that app specific fhe is either within within rich or it will be soon in in a matter of like a few years I think and again bearing in mind that these workloads uh are probably like way uh larger than that what we'll see in the in the type of applications that we've uh discussed today except for maybe uh distributed block building which might be in the same order of magnitude in terms of like how much data it needs to manipulate and how much how many uh operations it needs to go for in order to to get to uh results okay so what's next in uh fhe so as we've seen like uh working on on scheme level optimizations uh either improvements like the lookup tables uh by by Zama or even like brand new schemes that would uh ideally like work on like reducing the size of stock text I think uh hot vaccination is coming uh you've got these uh D Prime program by DARPA and something pretty interesting that I've seen recently um there's a demo of like a fully homophicked chip like imagine like a CPU that is fully homomorphic which could be interesting because like we've had this discussion at Defcon around uh uh sh EVMS uh so maybe like some inspiration to draw from there uh that reaches like 250 uh megahertz which is you know uh not too bad like for for those that those of us like that was used to pension twos and and like these older CPUs uh kind of like goes to these kind of performances and I'm sure that's uh I think Simon's in the the attendance and you could probably like add to this conversation about what can be done in terms of like Hardware acceleration um another thing that's pretty important uh tooling especially compilers uh that you know will make all these drinks uh available to to to to most developers and something we've uh that is like very often discussed as well in the zika community is uh how do you perform a security audits when these Stacks tend to be more and more complex I think there's a a discussion ongoing discussion on how do you edit like ZK ATMs and how do we are we confident that this could work um okay so maybe a final book uh is that you see this trend of like compilers uh I think it's it's getting pretty obvious that you know it's important to it to improve like the ux for developers but also to make sure we make the most of the hardware and uh what I like is that we see a similar Trend in like different privacy texts uh you start to see compilers uh people like working on on compilers and ndsls for ZK uh but also for horrific encryption and in particular you've got like three I think very strong candidates um in in like Microsoft Eva uh concrete from from Zama that we discussed and and a transpiler jointly worked on by Google and Duality uh so it's what makes C plus plus into into HG circuits okay just a final reminder that you know we shouldn't see these Technologies uh as standard components uh if you remember these toys from uh Power Rangers like you know the small ones they were very useless on their own right but if you put them together they make the big robot on the right uh whatever was his name and it's it's it's very much the same thing here if if we consider uh pets uh on their own we're not going to go too far they're just like Primitives they're just like building bricks uh what's interesting is like the protocols that we can build uh to address uh their shortcomings so for example I didn't mention that but homophic encryption uh doesn't guarantee that the computation was done the way you intended uh so it's pretty pretty interesting to see how you can combine it with stocks but you know not in a like naive way where you would like plugs snarks maybe on top of fhe or the other way around but maybe you know verifying that the data was encrypted decrypted correctly uh and and like combining that with other tools uh to make sure that you know you've got some kind of like privacy in-depth approach uh to this kind of stuff right um so as a summary um you know please bear in mind that these these Notions are different uh privacy confidentiality verifiability uh and that's it's mostly about uh collaboration it's about like using privacy to Foster collaboration that's pretty much the Takeover of this talk I think um we need to combine these Technologies so yeah that's uh that's the other takeaway I think like collaboration and like uh putting them together to get to very interesting protocols and that that can achieve our design goals thank you very much I hope I didn't go too much of a Time thank you Jonathan um yeah at this point only the true enthusiasts remains we've had three hours of content already um one one thing that kind of uh I didn't completely appreciate is you're mentioning sgx kind of had 128 megabytes of memory and then that grew to to hundreds of of gigabytes of RAM and yeah so we lost something um yeah it was Integrity um and that as a consequence meant that we you know we could only really use sgx in the context of uh of trust semi-trusted Cloud providers what do you mean exactly when when you say so the first version of sgx was kind of like um this dislike very nice uh primitive because it was giving you uh confidentiality of the inputs because like of the of the inside guarantees but what you were getting was that by combining uh the remote attestation mechanism that Andrew talked about when you when you do a remote attestation what you do is that you guarantee that the The Enclave the program is like in the state you're expecting it to be uh when it when it when it starts uh so you know that you've loaded the right program uh that that you were expecting to run now that doesn't mean that um the the execution of the program is not going to be tampered with by the underlying system because remember in sgx we're not trusting the EOS we're not trusting the machine itself we're just trusting like the the the CPU uh and uh and and the and the Intel would have trust so what's what used to be uh the reason why they had this limitation of 128 Megs is that they were using I think a miracle tree uh under the hood to verify that whenever um whenever the the memory Pages were encrypted or decrypted in and out of the CPA registers uh they were not they were not modified uh from one use of the of the memory patch to the other so that's what I mean by memory integrity and and with this mechanism what happens is that you start from these known uh initial state that is guaranteed by the remote attestation and because you know that the execution cannot be tampered with the memory cannot be modified by a malicious Factor on the system you know that you're going to go through all the way uh and and obtain the reason that you should obtain uh regardless of where the application is running so that kind of like gives you a similar feeling to to what DK proofs gives you uh to what's not gives you uh these verifiability of the computation but now that they've removed uh this memory Integrity feature because the key to unlock like larger enclaves was to remove the metal trees uh which was like taking too much space and maybe like also interesting like coming up ahead um you can't really trust uh what's going on uh on on the machine you don't know that the or at least I've not seen anything yet that says uh and maybe you know Android Tom can can chip in there if you've got more information than I do but at least as far as I know you don't you can't really guarantee that the pages are not modified uh when they're not uh when they're not being processed by the by the CPU so you've lost these memory integrity and by by such you've lost um the verifiable computation feature that's uh the first version of sdx used to have 