[Music] so my name is henry i'm gonna be talking to you about um some ideas for minimizing mev with uh sealed input batch swaps and so for context it's maybe helpful to explain sort of you know how i got here um because it's a little bit different from many of the other people at this event right so i'm working on building a project called penumbra and that really came from kind of more of a privacy background or perspective rather than for defy than from defy um and so i've kind of like stumbled backwards into this like mev mitigation thing by accident and as a result what the design that we've ended up with uh i think looks pretty different from a lot of the approaches that are coming sort of evolving the existing d5 model on ethereum to be more protected um and so it's maybe useful to kind of get to to that motivation right so the motivation is basically this question of like how do we provide useful functionality on a private ledger so i used to work on zcash and around the time of the d5 summer you sort of have this feeling of like cool like there's all these people who are like you know doing stuff and finding a lot of value in actually doing things and all of the privacy projects that i'm working on like you know are not really as useful so how could we fix that um the idea is to build essentially a private proof-of-stake l1 uh that works as a cross-chain shielded pool and has a private dex in it so that's like giving people sort of a positive reason to you know use this thing um [Music] that's not really the point of the talk the point of the talk is to kind of get into what is the main challenge there uh and how does that inform the kind of design that accidentally has some interesting properties around mev mitigation the challenge there is the state model so if we think about the normal kind of state model for any kind of like conventional transparent blockchain right you've got this big pile of global state and then there's like all these transactions and every transaction just sort of says like here's some changes that you're going to be making to the state and to execute them you just like you know take the transaction execute it against your state you get a new state you get a new state and you just sort of roll this forward but in order to have a shielded chain you need to have a composable state so you have this collection of state fragments this is kind of like a uh you know more of a utxo style model but i prefer to avoid using that term because it carries a lot of baggage from bitcoin that we could maybe just like not have um and the idea is instead of just like any transaction can be executed can like edit whatever you know part of the state you say you have these state fragments and every transaction is going to compose together its input fragments and then produce some new state fragments and those get appended into this like big collection of state fragments and why would we want to do that we want to do that so that we can have private state transitions so we're first going to take all of those state fragments replace them just with commitments to state so now we've moved all of the actual chain state off chain and then we're also going to move the execution off chain by saying you just have a zk proof that oh i have you know proved that i've consumed these state fragments that were valid i've produced some new state fragments and i did all of that according to the chain rules um and the reason so that's like all very cool and everything right and that's why everybody today is like entirely using private blockchains and they've like taken over the world no okay so what's the problem with this the problem is that this only works when there's no shared state and why is that it's because if you look at what's happening inside of this transaction there's so there's two problems the first problem is the execution has to be early binding and not late binding right so when i make a zk proof of a valid state transition i'm basically doing like you know like a little roll up like a micro roll up of the entire sort of actions of that transaction right like every zcash transaction for instance is this like little micro roll up um and as a result i have to know all of the data that was used as part of that state transition i can't do like if and that's totally different from how you know any part of d5 works right like when if someone makes a transaction to uniswap they're not signing like here's the output price that i got from the pool because that's not known until it's actually executed and you have this in a in a more traditional uh setting you have this mix of here's some data that is bound early when someone is signing the transaction like their input amount you know their address whatever and then there's these other slots that will just like they'll take what they can get as it's executed on chain and you can't really do that in this model the second problem is that the prover has to know the entire state transition right so whoever is actually doing this proof needs to know all of the relevant data and that means that if you're ever having something that has two people's data either one of them has to tell the other or they both have to tell some trusted third party right so like a zk roll up does not actually really provide you with privacy because you've just introduced this like new trusted third party that's doing the roll-up proofs um and so the where we get to this is like okay we we've sort of thought of like oh wouldn't it be cool if we could do this thing but there's this bigger problem of like how do you actually build you that like useful functionality that works privately and what i think that this problem reduces to is a slightly different framing which is how do you have private interaction with public shared state so if you think about basically any kind of useful thing that you could do on a public chain that has to have some kind of public shared state for people to interact with but you want those interactions to not reveal you know that person's entire history um and i think that a general kind of way to think about this problem is you have sort of value that is serving different roles in some protocol or some application and you want to be able to have transactions that cause value to flow between those different uh pools or or areas but without revealing what each individual entities contribution to that uh flow is right because if you can see oh here's like you know this amount but the total was this before the transaction and then after the transaction it increased to this amount like you just do a subtraction and you figure out exactly what the transaction did um and so we have this problem of like how do we hide the individual values while still revealing the kind of aggregation of everybody's private uh interactions um some examples of that writers like how do you hide trade amounts while revealing the amm reserves um it's not possible to just say like oh well we have the amm state and that's like you know public but the trades aren't you can work backwards so there's you know there's also some bridging tie in um but basically just fast forwarding a little bit the point is that there's two basic strategies for how you can um conceal this information so they work in kind of opposite directions one direction is you have some flow and you're going to split it up and the other is in the opposite direction you have a bunch of flows and you're going to bash them all together so looking at splitting flows to start right this picture is like okay somebody has some secret amount they're going to split it up into some randomized sub amounts and then they're going to create some like different transactions you know send those off to the chain at different times or something and then they're gonna hope that whoever is like looking at this doesn't know statistics um so this is like kind of sub-optimal right like you you're basically you know maybe better than nothing but not something that you want to build a whole protocol around and the alternative right is batching and in this case you have a bunch of people who each have their own private amounts and what we're going to have them do is encrypt just the integer amounts using um a construction that we've been calling flow encryption this is essentially um additively homomorphic encryption for integers but then without a bunch of extra properties that makes it actually useful in a blockchain right like you need robustness for the decryption you need to have some kind of end-to-end verifiability of all the ciphertex that people can't inflate value but whatever the idea is that you want people to be able to encrypt here's my contribution to some sort of flow of value between different parts of this protocol and then have the validators be able to aggregate all of those encryptions over some interval and do a joint decryption just of the batch total and why would they want to do that that's because then you can take that batch total and you can feed it into some public on-chain computation so there's this kind of general picture of how you can use this to solve the problem of private interaction with public shared state at least in some limited contexts and the the basic flow right is somebody's going to start off with their private input and they're going to do some transaction and as part of that transaction they'll you know do whatever other stuff they're going to do but they'll also produce as one of the things in that transaction this encrypted input another thing that that transaction is going to produce is some kind of private state nft that privately records details about how they were participating in this protocol as that transaction is going to be included into a block it will get batched together with some other inputs and then the validators can jointly decrypt a batch total feed that into some public computation and commit the output of that computation into the public chain state and now all of those outputs are accessible for a future private state transition where the original contributor is going to consume effectively their their receipt and prove that whatever further actions they're doing are consistent both with whatever they did to to contribute in the beginning as well as with the public computation that's based on everybody's participation so you have this kind of multi-phase protocol but you can actually have a private interaction with with shared state in this way and if you kind of follow this through to its conclusion you end up with a kind of slightly different or well actually fairly different state model which is this this idea of almost like frequent batch transactions right so each kind of smart contract or piece of application logic is going to execute exactly once per block but it's instead of taking every individual transaction it's going to process all of the inputs in one batch and it could do whatever it wants with those but it has to process all of them at once so you give up some things like for instance you can't do um like a kind of atomic composability of different smart contracts so you know that's sad but there are upsides like the resource cost of executing this contract gets to be amortized over every input and so you can potentially have significantly more uh complex logic in the contract because you know that you're not going to have to be calling it like a thousand times a block the batching means that there's no ordering in this system right and if you think about it right in a blockchain you have these transactions people are coming to consensus on transactions and the minimum sort of unit of consensus is the block right until something is part of a block it doesn't exist from the perspective of the system and the minimum increment of state change at the x like the consensus level is the block so if you build a mechanism that relies on some kind of higher precision notion of time or ordering then like of course you're going to create all this like mechanical arbitrage but you just could you know not do that um and i mean okay there's reasons that you might want to do that but let's yeah um and and the other thing too is that assuming that the rest of your transactions are operating in a sort of zcash style shielded model if you think about what's accessible to the block proposer um there's no information there's no real metadata in the transactions other than a description of you know what type of action they're doing their particular contributions are all encrypted up until the point that the block has actually been voted on um and so the users are also going to be able to get some long-term privacy unlike a kind of commit and reveal scheme for well we'll just encrypt all the transactions individually and then decrypt them so we can execute them you know assuming that you have some sufficient batch sizes but that's that's an inherent problem so it's in a small text as an example of of how you could do this you know just to finally kind of tie all this together um to back to the original topic of the the talk right here's kind of how you can use this to do some sealed input batch swaps and i think that this design is actually pretty cool um even though we've sort of stumbled into it backwards so you have uh some block uh you have you know all the the input trades you have the consensus system just groups those inputs by their trading pair and then batches up all of the encryptions of the inputs decrypts the batch totals and now the application has sort of this global view of all of the trading intent that has been expressed in this block so you could take those individual trades and just say like oh we'll execute you know each one in sequences a different trade but that's sort of like you know how would you pick you know what order to demand how do you like net out flows that are in opposite directions and it's much cooler to just say well why don't we take all of these um batch in input totals that are representing the aggregate trade intent put them into this like graph of all of the possible uh asset pairs and then just like globally resolve all of the trading intent simultaneously using optimal arbitrage and we can do that because we're only doing this once per block so we don't have to pay that cost for every single transaction and the result is that then you know you compute all your clearing prices and everybody who had submitted their swaps can like mint the output assets of whatever type they have so that's basically the design um have to have any questions [Applause] hi thank you for the talk um so as one of the previous speakers mentioned batching of transactions uh has like results in a higher price impact right uh yeah so my question is then uh if uh um if there's a like a whale trade in the batch uh is there any incentive for the like a small users to be part of that batch or so in other words how do whales how can whales swap uh like privately if there's no incentive for regular users to be part of those matches um yeah so i think that the the the optimal way to interact with this is to so okay just to back up a second exactly as you mentioned there is definitely execution risk in this system um i think that on average it's actually going to end up substantially better because there's a lot of noise in trading you know in the non-whale case right like that just kind of cancels out and you get better execution um and so i think that the the kind of optimal move is at the user agent or wallet level to have a way for people to express here's my time preference and based on that uh have the the client sort of like split their trade into like randomized sub amounts and commit those or submit those at sort of randomized intervals to like spread that execution risk over multiple batches and if you do that well you can also increase the anonymity set of the whole system [Music] you 