alrighty um so I'm going to be talking uh about minimizing Mev on penumbra as a kind of like high level as like a kind of like a high level perspective of um you know where we're coming from and where these sort of thoughts are coming from two kind of framing questions the first is like what is med about um fundamentally I think that this is uh a question or or the whole field is fundamentally about like how do the economics of an application interact with the consensus system that's being used to execute to replicate that application in some decentralized ways that you can execute it without a trusted party um and a perspective uh that I have that comes out of that is that um properly handling Mev fundamentally is is going to require a vertical integration between the economics of a particular application whether that's I I say app and that kind of big General sense you can imagine that being like a single smart contract or you can imagine that being like a constellation of contracts that someone wants to interact with um but you know whatever that kind of like high level application is um somehow needs to have its its economics integrated with the consensus mechanism that's actually executing it and so my opinion which people may or may not agree with is that I think that app specific chains or Roll-Ups are going to in the medium to long term outcompete general purpose attempts uh uh sort of dealing with Med um because ultimately the Mev is is linked with like what is the actual application that you're doing and so if you if you can integrate that with the consensus mechanism you can be more powerful you can do more things and I think that at least for applications that are important enough for people to build some specific thing that'll kind of out compete the second question is like okay well where does Mev occur it's going to occur wherever the miner or proposer has um actionable information about future execution one one term that I really don't agree with is you know rebranding Med is like maximal extractable value I think if if you don't have a block proposer in a privileged position then you're not that's just Arbitrage and you know we have a word for that already let's not sort of dilute cuts and so from that perspective you can say well we can minimize Mev basically in in two words or in two ways corresponding to those two words either you've reduced the amount of information disclosure you're probably not going to ever get sort of perfection on that front but then second uh how do you do mechanism design so that the disclosed information that you do reveal not actionable in a way that uh in a privileged way by the the block producer so all of the other talks here so far as far as I know are about general purpose solutions for uh arbitrary programmability uh which is the case Criterium the thing that I'm going to be talking about instead is okay well what could we learn instead from building one single application um so I'm not gonna you know claim that this is like a solution to all problems but what I think is interesting about this approach is that although you can have um although you're taking a very narrow scope of like what the problem is um within that narrow scope you can have a a complete solution to the problem right so what when people talk about say you know the Mev supply chain I actually would say instead like that should just be considered like end-to-end protocol design right like when you're designing a decentralized protocol the the design of that protocol should start from like the actual end user and they're like you know Key Management their custody solution their client like all the way through that whole pipeline out to The Ledger where the execution happens and then all the way back to to where the client um learns about it and if you don't consider that and you end up with sort of re-centralization in all the places that you missed like infuro um so what are we building we're building penumbra it's a private proof of Stakeout one it does this like interchange shielded pool with IBC um and it has a private decks so the the motivation for building a private decks is that you know if you're going to pick one application that you're trying to zoom in on um this is a really interesting one because every Market is a market also an information and so we have this idea that you know privacy can unlock Capital efficiency and maybe you can have a situation where a private alternative can out-compete uh transparent ones so coming back to this idea of like okay Mev is about um it is occurring where there's actionable information let's sort of zoom in on those two pieces first the information um on penumbra we have base layer privacy um I personally think that you can't really hope to solve Mev without having private see at the base layer and the reason is that I'm trying to see thought of as being control over information disclosure you can't ever undisclose information at a higher level that you've already revealed at a lower level and so if you have a a transparent based system you have all of these problems where you're like paying fees you know you have like who's paying for the gas there's all of these accounts like it's a it's a lot harder to kind of retroactively layer on sort of a fix to to metadata that's that's revealed at a lower level so what we've started with is a multi-asset shielded pool that's similar to zcash and all of the value uh unlike Z cash is recorded privately in that shielded gold so when you do like a cross chain transfer in it you know just records that in the Shipley pool and this means that everything is happening in and out of that common private base layer um so you have like no accounts there's no other transaction metadata the fees are all paid privately and the super powerful thing about building in privacy at the base layer is that it allows transactions to have precise disclosure for interaction with public state so even if we just stopped here and said like oh and we're going to have like a completely transparent you know like deck state or whatever um you know there's still Med problems that will come out of that but from a privacy perspective you've already achieved you know each individual transaction is only revealing you know the specific interaction with the public State and not all of this other metadata um and once you have that you're in a good position because every you know useful blockchain revolves around having this public shared state right that's that's why people want to use these systems um and so the question really is about how do you allow people to have private interactions with that um public shared state so we have to sort of I think that there's two kind of like ways that that breaks down um One Direction is to try to do uh splitting of flows the other is to do batching so with splitting let's say you know there's some uh action that someone wants to do they want to affect some change move some value around on the Chain um if they split that value into randomized sub amounts and spread that over distinct transactions then they can privately reassemble all of the output effects but this is only actually possible if you have a shielded base layer right if you're doing this on a transparent chain you're just like you know see where all the funds going and this is is completely useless um the other approach is trying to do batching um what we've uh been thinking about is rather than trying to say oh we'll have threshold encryption where we're gonna treat this transaction if this totally opaque uh object um if what we're actually trying to conceal is like what is this transaction specific contribution to a particular kind of like round of of public interactions uh public State changes then we don't actually want to be doing threshold encryption for the entire transaction because the entire transaction already is is shielded because we have this shielded base layer all we actually need is the ability to encrypt uh individual um individual contributions to the the public uh State and so what we do instead is have uh threshold encryption that works just on Integer amounts and has uh additive homomorphism so you can have the chain um aggregate all of the encryptions uh in some interval and then have the validators jointly decrypt that batch total and do some public on-chain computation so that's sort of how we're thinking about the the information side on the actionable piece of uh Mev um this is about sort of the like mechanism design so how do we make a uh mechanism design that that minimizes the impact of um a block proposer messing around with with transactions so um again we're focused on like very one very narrow use case which is building a decks on the the market taker side of that we have sealed input batch swaps so the idea is that some user wants to swap some amount um they have their private input amount they encrypt that using flow encryption uh to a threshold is controlled by the validators um and because this is going to be bash they don't know uh what that the output price is going to be right so you need to have some mechanism for doing late binding of the uh the execution to do that they make a private small pen of T to themselves that commits to exactly what their private input was you know what the trading pair was what address they're going to claim the funds to and so on um is that once the chain sort of gets this batch of swaps whether that's in a block or a longer interval they can aggregate decrypt only the batch total and then execute all of the swaps with a common clearing price um and once that data has been posted to the chain each user can consume their uh private swap nft to privately mint their Pro rata share of the output um so that's kind of the the market um uh taker side but from that perspective you know how you actually do that execution is is sort of a black box on the the market maker side you know what is in that black box we have a concentrated liquidity mechanism where effectively every position is its own little amm but it's a an amm of the simplest possible form which is just you know a line and this means that the optimal routing problem is easy because you're it's basically like a uh the closest thing to an order book that you could have um so you can walk along this graph um and because all of these positions are created out of this private base layer and returned back into it any individual participant can privately approximate whatever trading function they want by creating you know various different liquidity positions and although you have transparency of what the aggregate state of the market is you don't know which positions correspond uh you know to which users to which accounts uh because they can all be created through these distinct unlinkable transactions um so when you put these things together the the mechanism design basically is is a frequent batch swap system so there's multiple phases at the end of each block um first you open all of the positions that someone has requested to open and in some transaction in the block and you execute all the swaps um ARB all of the positions uh into having a consistent prices with each other and then close out all of the positions that were requested to be closed this is pretty cool because because you're only doing this execution uh once a block you can afford to be uh considerably more sort of computationally sophisticated because you're amortizing that execution cost over every transaction in the block so you can do routing on the whole liquidity graph and because you have uh all of your liquidity and you know all these different little concentrated liquidity positions um you can have liquidity be sort of like active passive or or anywhere in between like if you want to simulate say like a uni B2 tool you know you can just do that um but all of that liquidity is kind of on a common footing and the chain is capturing all of the internal Arbitrage of you know is this price consistent with this other price um so when you put these things together it's kind of the implications are um the batching means that there's no ordering uh of effectively of of transactions within a block right so if you actually look at the data structure sure there's like a list of transactions but um the actual execution is happening in a bash and so the ordering of transactions uh has no like economic value so there's no real sequencer the proposer is only choosing whether or not to include or exclude transactions and because of the the way that the mechanism is designed um their decision of whether or not to include a transaction or not only has um a marginal effect on the outcome because there is an ordering um in order for for a block proposer to you know prevent anyone from doing Arbitrage on you know a specific trading pair they'd have to censor like many more transactions and and sort of only have theirs uh be be present they can't just sort of play games with like individual transactions and even if you you know you try to censor like one specific training pair because you're doing this kind of graph routing um the the the the proposer's ability to like block people from doing art is limited by the way that the the ARB will sort of like flow through the the liquidity graph um it also means that the Dex is going to step between discrete sets of of consistent prices I mean whether I I when I say consistent I mean internally consistent um but that means that you don't have to have um you know a bunch of uh Seekers who are like competing to like race in some kind of mechanical Arbitrage you just do the mechanical Arbitrage um relative to yeah like like automatically uh as part of the protocol um and the external Arc against uh reference markets ends up being shared uh Pro rata among Seekers so there's a kind of interesting paper on this um by the the uh bing cat crypto research team did I uh have like a small part uh in in helping with um but it turns out that the game theory of of this type of game is that um uh uh The Seekers just like share uh programa uh Arab against external reference markets so um I think there's a bunch of interesting pieces here um it's obviously a very um application and use case specific uh for the moment but I think there's some interesting um design pieces or or lessons that might be useful for either uh other application specific Solutions or for building general purpose applications um and I think some of the pieces that we built in the longer term will will end up um being useful for for more General kind of contract interactions so um here's a bunch of links if you want to find out more and otherwise happy to just um answer any questions that people have thank you Henry um I guess what one question I have is on on the previous slide around the internal Arbitrage profits being captured by the protocol like is there a reason to not give them back to the users I guess well I guess when I say capture I don't necessarily mean um uh and this actually goes back to points that was made like a while ago in the uh the chat during a previous talk I think it was yeah it was Phil saying you know there's no free lunch like you know it's coming from somewhere um and what I would say is like yes that's true but if you capture it as part of the protocol then the protocol can decide um how to to distribute that right um so one option which is I think like the simplest is to just uh do a like a a burn like our burn mechanism um but you could also you know try to direct it in various ways I think you could try to rebate to to users who swapped or or to LPS um actually doing that I think is kind of tricky because once you're redistributing that value now you need a way to you have to like convince yourself that that mechanism itself is like not going to be gamed um but yeah when I say capture I don't necessarily mean um uh sort of like permanently held but just uh you know captured and then like okay you know now to do what with well we'll figure it out okay so just to make sure I understand um is there some sort of Global convex optimization going on because that's uh yes but for um uh a very like specific um special case of the problem right so like the the liquidity positions are made to have the simplest possible form so that the convex optimization problem is uh easy or easier uh there's actually a bunch of interesting questions there about that that come from the fact that you're doing that um routing in a batch one thing that is more difficult about that is that you lose the ability to have um like precise accounting for uh resource use right um like if somebody makes like a bunch of sort of like like dust uh trading positions right like how do you avoid that like blowing up the the complicity of the routing algorithm um because you don't really have a way to like impute that cost to a specific um so the approach that you have to take essentially is just like get good and like make it fast and have heuristics that um bound the the size of the optimization problem even if you don't necessarily get like a perfectly optimal solution I think we're out of time there is one more question in the chat um from Andrews maybe uh to be answered yeah long-range leakage attacks um yeah it's a problem um there's not really a great solution to that um on the other hand uh if you look at sort of what role does the threshold encryption play in penumbra relative to in um you know some other protocol um even in the situation where you have like no flow encryption at all um well like exactly how much information are you leaking while you're leaking just the amount uh that someone contributed to a batch and you don't have the there's no possibility to leak you know the account the 