[Music] uh hi everyone hope you're having a nice afternoon i'm christopher i previously worked on ibc for the sort of cosmos project at large now i work on enoma i'm going to talk a little about using uh distributed key generation and threshold decryption system for some notion of fair ordering and i'll talk about what that notion is and whether it might be a notion you want or not and i'm just going to sketch some like early thoughts on cross chain mev and given that you know we've seen a lot of practical experimentation with single chain muv because there are a few really popular block chains like ethereum and the cross cross-chain design space is very nascent can we use some of that like information about how the economics of markets evolve to try and design cross-chain mev systems that work or are they like probably not going to work so one disclaimer before i start here um i am pretty new to the mev discourse uh of course i worked on cosmos but cosmos does not like have you know some cost of sophistication must be reached before mev is worth extracting so even if cross chain maybe is possible in principle i don't think we've seen a lot of it yet at least in that ecosystem and there's some sort of terminological mapping to do which i will try to do as best i can but some discourses remain slightly diverged also a big thank you to niketa and and i hope that i'm pronouncing those names right and justin drake for discussions over the past few days which have been very helpful to me so i think an interesting research question that one might want to approach when one is kind of designing architecture from scratch is what kinds of maybe are possible and which kinds can be motivated in principle like developing a sort of taxonomy that is general and if you want to develop a taxonomy this general you have to reason about it on the basis of sort of information theory like what what are the agents when are they making decisions when are there different events where different agents have different information and if you derive a kind of structure in that framework then you can be pretty confident that it's not depending on specific properties of some particular system so a very very very very simple information theory taxonomy of mev that i was coming up with a few people and tried to put in a diagram is that we have kind of two two systems we're just going to call them information systems one of these systems is the ledger the blockchain that advances in this kind of quantized time step there's like block one block two block three block four blah blah blah maybe it's stag but still quantized then we have the world which is like everything else so cross domain mev problems uh are kind of you know the crop the other domain is the world right but the world also includes other things which you could consider you know are like things happening in nature that you might use to inform you know hedge fund trading decisions right those are also part of the world in the general sense and the world uh advances in something we'll just call real time of course there is no such thing but probably close enough for approximation then broadly we have two classes of actors we have transaction authors who are like crafting a transaction which uh may do something which they care about related to the blockchain state may take that state as input may take prior state as input um or may depend on the state at the time when the transaction is executed then there are transaction orders or groupers these might be like you can split this role apart or not but someone has to make the decision um or you do everything in batches and then there's no order within the batches but still order across the blocks variously these orders or groupers are called proposers uh you know now in say a system like tendermint the block proposer chooses the order of the transactions and historically in most blockchains ethereum bitcoin the miner choose the order of the transactions right but in sort of like the flashbot style architecture these roles are more split so like in the proposal builder separation architecture uh proposers builders and sequencers are all separate so they're like three different you know nominally three different roles which could might or might not be performed by the same sort of real world entity but either way there's a difference here in events so the first event is this transaction authorship where the author of the transaction has access to like the states which they can read at that time so they have they have access to the blockchain state it's this particular like block which they can currently see maybe they're using a light clients they can see which blocks have been finalized and they have access to the world state at whatever like the current time in the world is then that happens first and the second event is this event of transaction ordering and block creation which might be split into some sub-events whoever however is doing the ordering if there's ordering uh even just like choosing which block to put a transaction in in a batch system has access to more information about blockchain state so they have like maybe maybe some blocks have passed since the transactions authored that's some information they could have but they definitely have a set of possible transactions to include and possible orders for those transactions the order also has access to more information about the world state because time has passed so this is like kind of the cross-domain mev problem at large then you can think of mev as the information asymmetry between these choices between the user who is choosing to author that transaction at the first time and the decision maker or possibly multiple decision makers who are deciding to order transactions and put them into blocks at the second time so if you uh try and diagram this in an extremely simplified fashion where arrows are information flow so someone in blue blue diamond is choosing to author a transaction they have information about the world at this we'll call this time t equals i they have information about block one on the ledger then that transaction along with a bunch more transactions and more information about the state of the world is available to uh the blob of either singular or many entities who are sequencing transactions and creating blocks and some blocks may or may not have passed on the ledger in this particular diagram i said some blocks have passed but you could also you know tie transactions to specific blocks so maybe there's just more transactions and more info about the world so from this taxonomy we can kind of characterize like what are the different aspects of mev that we could aim to reduce and how would we have to go about doing it so one question uh that might arise is can we reduce the information asymmetry about the blockchain state and one this is maybe the easy problem uh because there are ways we could reduce this by requiring ordering decisions to be made without information about transactions contents so you know our approach falls into this category with uh threshold decryption i think a project earlier today called shutter network is doing something like quite similar with threshold decryption but for rollups instead of l1s but it's sort of the information theoretic structure of the problem seems to me to be the same of course penumbra is doing something more with batches which had to be explained so i won't try and re-explain it and get it wrong but the other question which seems to be much harder to answer and which makes the cross-domain problem quite hard is can we reduce the information asymmetry about the world state basically the answer is no because time is passed so if there is more information about the world accessible to the person who's making the ordering decision uh simply because time has passed uh then like they're you know we can't encrypt the world unless we like pull the world into our encryption scheme so we can try and pull the world into our encryption scheme that might be what i talk about later secret hint but we can't really like do anything else except we can try and reduce the latency so the physical the real latency of this does matter like in terms of number of seconds if the kind of mev we're concerned about is based on changes in the world state so how do we use cryptography to reduce this first asymmetry a um there are like different i i think there's a there's one component of a threshold decryption setup and another component of like the settlement setup and the settlement component as far as i can tell is pretty orthogonal what we just care here about the is the ordering component but we happen to have the sort of vertically integrated system so uh the system we've built is a dkg and threshold decryption system set up to work with tendermint tendermint has uh bft consensus it has usually is used in combination with a proof of stake system um with regular finality two-thirds thresholds things you would expect so we generate in our system called fairview a threshold key which has the same share distribution as proof of stake which allows us to do this guaranteed decryption which is very important if you use threshold encryption um and encrypt all or some of your transactions but don't necessarily have the ability to decrypt then then someone can withhold data or like you know uh say that they're like not able to decrypt things um if you don't you know if somehow there's a misaligned misalignment between when you finalize how you finalize the order and how you decrypt the transaction so that it's possible for you to finalize an order but then not be able to decrypt some of the transactions you don't want that right so for that reason we need to uh like integrate these systems very tightly and in the case of the tendermint architecture and tendermint um votes are broadcast around uh and we include in those votes the decryption shares such that when you have two-thirds votes which is like a commitment to a block you also have uh two-thirds decryption shares which is exactly what you need to decrypt the transactions so you will atomically either finalize a block and be able to decrypt the transactions or you will not so this is like poor man's witness encryption because we don't have witness encryption yet but we can fake something similar to the model except that of course those of the validators could collude and decrypt the information uh you know out of band so uh just a basic like flow order to explain this from a user's perspective when you author a transaction in the system you write whatever your transaction is you encrypt it to the threshold key the proposer only sees these encrypted transactions they have to commit to an ordering of or the other entity who's ordering things has to commit to an ordering of encrypted transactions that block is finalized uh with that order finalized and then transactions are threshold decrypted and then executed so this is not a scheme for like transaction privacy you could separately make parts of transactions private in another way and you could like re-encrypt them in the scheme it would be fine but the scheme does not provide any sort of long-term privacy it only provides temporary privacy so this helps with the first information asymmetry and that now the proposer doesn't isn't able to search this computational or the ordering decision maker isn't able to search this computational space of which transactions can be combined in which ways and make a state insert their own transactions sandwich things usual maybe stuff they don't know anything more about it than the transaction author asterisk um and the asterisk is what about gas limits but just in case uh you're interested in a system like this we've implemented it and you can find it on github so there's one slight problem here which is that we have limits on what we can pack into blocks and those limits might be based on different resources um they could be based simply on gas they could be based they could be like multi-dimensional like you could do multi-dimensional eip1559 but either way as long as you have limits on what you need to pack into a block then you need to give the person who is putting things in a block uh information about what those limits are otherwise they will like not be able to ensure that the block has less than whatever the limit is so these limits of course leak information about the contents of transactions if transactions are doing arbitrary programmable execution then uh you know if you look like identify you know this specific amm transaction always cost like 120 362 gas even if that transaction is threshold encrypted you have to put the limits in plain text and so that gas amount will pretty clearly identify to someone what the transaction is doing it's more just statistical information to correlate and there's some potential mav there it's hard to say exactly what it is without specifying a specific case that you're interested in application wise uh however you can sort of there's a continuum here where you can give up some accuracy and block packing in order to get better uh privacy and less mev in this sense you can buy quantizing gas so in ethereum or most systems right now gas is very it's like well not very but it's moderately um uh moderately like quantized in the sense that we have like 120 000 gas 120 000 to 1 gas um small changes in like the evm you know if you use an additional evm up code in a transaction it will change the gas costs but if we make gas less granular by sort of rounding everything up to like the nearest uh you know the nearest multiple of some constant that we choose like we can round everything up to the nearest hundred thousand so we have 100 000 gas 200 000 gas 300 000 gas then we're revealing less information about the contents of the transactions and there's less of an opportunity for me uh just to like note it you might think that ckps could help with this problem but at least directly they don't i mean if you're doing private transactions where you're pinning to a previous state um then uh you know you don't you're not leaking information in this way but if you just use zkp's to try and like prove something about the gas consumption you still have to reveal what the gas consumption is and that's it maybe how do you avoid this um you have all you basically give up the kind of generality here you have to make all transactions out of identical encrypted sizes and execution costs even if you're just using like if you're even if you're just doing sort of data availability sequencing and you're not executing transactions on chain if you're ordering on the mon chain um and they have different sizes and you use this kind of threshold description scheme that still reveals something um when the order is picking which one's too good still um even with gas limits leaking some information this seems like it's probably better than the status quo in terms of mev so what do we do about cross domain mev um let's see here's the dial right cross domain mav if i go back a few diagrams okay so we have on the bottom of this we have our ledger and on top of this we have our world and when we have cross domain mev we're kind of talking about different domains which are like different ledgers and if we don't coordinate anything between those domains it's just like the other domains are part of the world so then it kind of reduces it to this thing uh that problem is of course you know if a lot of relevant information is happening in other domains that would cause there to be mev opportunities like price changes on other exchanges on other ledgers um that could you know that will create a lot of mev here based on the real time which passes um that can be exploited on one right but if we coordinate a bit between the domains we have more uh opportunities so in particular if we're using this kind of threshold decryption scheme we can coordinate on not necessarily like what exactly uh you know who is doing the encryption or decryption but we can coordinate on when we do it so if we have this if we look at let's say a cross-domain system of three ledgers and we have transactions being created then we have some kind of shared deadline and some interval between a deadline and a shared decryption so all of the ledgers have to agree one way of agreeing is to use like timestamps like real world timestamps and hope that those are measured correctly uh but you could all you can kind you could do like uh send messages between the ledgers but that's more complicated and introduces some live disassumptions so maybe in practice a reasonable way to coordinate is just by using timestamps then if you require that you know in order to be um included uh all of the transactions must be created by this particular deadline they must they're encrypted they're like all the ledgers commit to ordering them in a particular fashion then after some slight interval uh they're all decrypted and executed then you get similar properties um at least in the sense of transactions on one ledger not immediately creating mov opportunities on another ledger the nice thing about this approach is that we don't need to agree on the specific encryption scheme or key set or date availability layer or execution layer we just need to agree on the fact that we're doing threshold decryption and we need to agree on the clock what this does not solve is cross domain message passing mav ie cross chained x's might not work which is that if you are making state changes on one chain and those cause messages to be issued to another chain um uh in those messages like reveal information then you can threshold decrypt them all you want as soon as you decrypt the messages which are going to be sent to another chain that creates the mav opportunity and there will be some competition to fill it uh in the next like round or so to speak uh one saving you know not exactly saving grace but interesting corollary uh that at least you know i've come to in thinking about this is that this problem just has nothing to do with security you know unless your bridges fail if your bridges fail then life sucks but that's not really an mvv problem unless mev is making it like more profitable to uh bribe people who are doing your bridges or something so you have to reason about that but mostly this is a concurrency problem and if you have like a single chain with different rollups on a data availability layer you have exactly the same problem with cross roll-up messaging and you will like face the same design constraints uh yeah it doesn't seem like there's really anything can be done about that can be done about world mav uh luckily physical change is slow uh if you're you know if you're looking at processes occurring in nature and something from one second to the next changes in ways that would radically change like the price of an asset that would be concerning maybe or create mev opportunities but it's not clear what those changes might be to me at least i'm interested in if anyone has ideas also another corollary is that real world latency matters like the actual if there is world mev the actual latency from when you submit the transaction to when the decisioning about ordering is made really matters like if there's more latency there's more interview the last thing i would say is that at least in the last few days i have become aware of many projects which we're doing you know for example shutter and penumbra which we're thinking about very similar problems from slightly different angles and it seems like there are lots of places where we can if not standardize everything at least standardize modular components and we would love to help out with this in any way that we can uh if you have questions please hit me up on twitter email or person thanks hey so i guess that uh from what i understand correctly uh the the big problem is just finding a reference point right like a reference time for all of this to match so it's like uh uh finding like a like a proof of history is that correct um yeah i guess like in some sense uh what you're doing when you uh send your unix timestamp to the blockchain is like uh proof of history of course it's not you know that's like a distribute that's like a consensus oracle usually for what time it is and you measure that by like your crystal in your computer so in that sense yeah history that's like the coordination involved is that was that your question or no yeah okay i mean the essential part here is coordinating like when information is available to whom and for that you need some shared clock you had mentioned this thing about the amount of gas that it takes to use an amm but that's really just like a portion of information that doesn't necessarily tell you which pool or which tokens you're using um is it such a big problem or just something to be wary of uh maybe it's not um i think it depends on you know you have to model the adversary and if the adversary has other information like they have information about timing or they have information about data out in the world and they can correlate that information with the information of the gas limit of your transaction maybe they can guess more you know guess more or will be more likely to be able to guess what's in it but you can trade off packing efficiency and privacy by having less granular gas limits there's like some there's some control there you can apply to maybe make it not very profitable to attempt to do that thank you [Applause] [Music] you 