wouldn't talk can you hear me audio's good you your good questions should I test uh sharing my screen hello let's see hello hello sorry my my Firefox crashed and I tried to share my screen let's try that again hello hello so I think we will give our first Speaker a two-minute grace period to figure out the audio and then we'll get started can you guys hear me and see my screen yes yes to both yes to both okay great I can't see anything and my camera is not working um but but we all love Linux anyway uh so do I have the the green light to go do I what's the story Sarah um let's do a quick so um hey everyone uh thanks for joining us delighted to bring back the flashbots tradition of the Emmy virus so today we are focusing on privacy and our Roost Master will be Justin Drake um Justin I don't know if you want to introduce the topics at all or if we should just go right into it and our first speaker is quintus no I think we can just just go into it um I think my role is to just ask hard and spicy questions so I guess I also encourage questions from from the audience if there are any I think we can get started with uh okay uh excellent um please interrupt me if something goes wrong technically um and there is time allocated at the end for for questions so that should be good okay uh with no further Ado uh I'll be motivating why we're having this roast in the first place um and my name is quintus and I'm from the flashbots research team uh right so why do we want privacy in Mev when someone asks me this question I kind of feel like there's two two points to the to the answer to my answer at least one is cooperation right in particular we want cooperation between entities that don't trust each other and that might have like conflicting incentives and I think this is particularly difficult in Mev and I'll sort of expand on on why privacy is important for that in a second and the second reason why um privacy is important mov uh is because it affects user outcomes and now this is a very broad term I realize but um I think it's broad intentionally because um it's not exactly clear what the outcome should be it depends on the on the application but an example you can you can keep in mind is like a uniswap swap for example um the user's price is is a measure of outcome um but then you might have some other outcomes like for example a payment you receive um via an order flow auction or something along those lines well looking at cooperation first what what do I mean by cooperation you know what are some examples of things we can think of um and really if you think of the sort of The Primitives the building blocks um no pun intended that we see in the pun intended in the um mov supply chain um is we see bundles bundles of bundles and blocks and really what's Happening Here is we have some like end output a block um or a sort of a an ordered list of transactions which represents some sort of utility to multiple agents that contributed the transactions that that make up this ordering um and so if we think about it we have a bunch of agents who want to submit transactions into a block um and somehow they have to all get their transactions together into a single block but in order to like to to build this final block they need to share this information these transactions and some other information um perhaps to um you know actually have the transactions executed but this is more difficult than um it seems on the surface in part because information is very valuable right and what information am I talking about I'm talking about transactions on one level uh so um a basic example is someone is executing some complicated Arbitrage with the transaction or a series of transactions and if someone else sees sees these transactions they can just copy their strategy which significantly reduces the profitability um of of the trader or the Searcher or whatever you want to call them but then there's also like meta information that's important right so for example bids um if the coordination mechanism you're um you're using uh requires you uh to bid to pay someone for something um having someone know what you're bidding especially when they're competing with you is that like you know obviously a disadvantage because they can just put Epsilon more uh and suddenly you're down in the dumps and so um clearly privacy is important and one um sort of mapping we can think of uh one uh sort of different use case that seems very similar is uh high frequency trading in traditional Finance right and these firms are known to be super secretive to um you know not even be willing to tell you how many members they have in teams and these kind of things because even that little bit of information can be uh you know Alpha it can be um very profitable for someone else and and uh you know profit for someone else often means a loss of profit for for these firms um but but why do we care about cooperation right um seems very nice but can we be a bit more specific about what's what's nice about it if we look at the Mev supply chain we can see in particular um between the search and build and validator that a lot of this sense of information is is being passed around um but um passing the sense of information around means that there's a a barrier to cooperation or they can be because there's a high degree of trust required if they we don't have the proper mechanism for cooperation and the risk here is that this barrier to cooperation means that the sort of most efficient outcome is just these entities being Amalgamated into one large centralized entity um and this is not something we want and I I can give a couple of reasons why um so we want to avoid decentralized entities because we think often um or there will likely be monopolistic or oligopolistic in the sense that they'll only be a handful of these ones of these decentralized entities um that uh because the market can only support so many um right and the reason you want to avoid this is because you want to avoid rent seeking for example right if there's not enough competition then these entities can internalize a lot of the value that we might want to direct elsewhere we want to avoid regulatory centralization right a centralized entity is probably based in some sort of jurisdiction and we don't want a sort of credibly neutral um blockchain to be to be subject to the whims of of a you know some government and then also we want to avoid uh undue or disproportionate influence over protocol incentives um blocks are very valuable or can be um and they're also a very key component to blockchains obviously um and so having one entity or one a handful of entities controlling this process can be detrimental to the system but where does privacy come in right we've talked about cooperation but what has privacy allow us to do well like I hinted at earlier privacy allows us to lower the barriers to cooperation right which means that um the market can sustain or rather I should say in order for entities to work together we we don't need um to build trusted relationships and we don't need to maybe sign legal agreements um we can have a permissionless system right where you where entities can interact with with each other can coordinate without requiring um you know this massive overhead or or someone's permission and what's nice about this is that permission the systems mean that agents can join whenever it's profitable to do so which um hopefully means the system is more competitive and like I said earlier this avoids rent seeking it pushes value back into the um into the chain to the validators or perhaps back to the users um but it also hopefully allows more entities to participate in this system making making it more decentralized um what's also nice about cooperation is that it might unlock additional value um what do I mean by this um I think maybe the the most basic example we can think of today is that many searches building a block together or aggregating meeting different bundles together into one block might see that block being more profitable than the block than that any individual Searcher could produce um right and how is this being done at the moment well some of the proposals or some of the implementations thus far have just been trusted private channels right Mev Geth was an example of this which allowed such as a miners to cooperate without such a bundles being stolen we had build rpcs at the moment there's another way for Searchers to submit bundles privately without other searches seeing them but obviously they're very heavy trust assumptions involved here similarly commit reveal schemes um like me the Boost have been implemented right MVP mov boost allowing validators and Builders to cooperate um without the Builder worrying that the validator will steal their their block um so that's it for cooperation yeah what about user outcomes this like sort of very abstract term I referenced earlier um what's an example of this well a very easy one is sandwiches right I don't really have to explain this too much we're all very very familiar with sandwiches um and so uh maybe moving into onto another example we have generalized Front Runners so a generalized FrontRunner um is one of the first like performers of Mev that was um spoken about when MVD became popularized in the dark Forest post um you know if you accidentally leave some money available to the world in a smart contract and you try to get that out with the transaction through the mempool or probably not going to see that money again um then a slightly more intricate example than order flow auction um so maybe leaving out the implementation details we can imagine some some order flow auction where um or some black box called the autoflow auction where uh users and and Searchers both participate and the output supposed to be some bundle which you know is beneficial to the use of According to some rule right so the user's execution is good their payment is good and we can imagine the output maybe being like a user being Background by a Searcher but if we have the wrong privacy uh sort of environment in the OFA and more information is exposed than we would like a social could for example um act outside of the order flow auction outside of the rules that the order flow auction can enforce to um effectively for example sandwich the user which could end up with and the user execution being much worse than anticipated and they're actually having been a much better um you know way to execute the user strong action maybe just without the bundle who knows but the point is that it's very hard to reason about what's good for the user within the autoflow auction if agents are also acting on the same information outside of it right and why do we care I guess why do we care about user outcomes should be a bit of a silly question I think most of us probably agree that it's a very important thing to do but but maybe just a motivate it a little bit we can say that we want to make trustlessness appealing again a very general statement but we believe in in blockchain with cryptography and all the incentives with um and the centralization going into this we believe that the trust assumptions and the applications that we're building are better than the trust assumptions in the traditional world right like a DEX versus a sex for example however we don't want this trust to come at a very heavy cost to users in the form of worse prices or higher fees or these kinds of things um similarly um one can argue that blockchains were invented to address Mev and this is a bit like a bit more of a philosophical point but really what I'm trying to say is that when a like when but when Bitcoin was created we're trying to disintermediate uh remove this very powerful intermediary that can impose their objective function and extract value from users at the user's cost um right and if we think about what Mev is often this is basically the the same thing because of validator or a minor whoever is in a very powerful position um and they're sort of intermediate between all these other users who want their transactions executed and they're able to extract value often at the cost of users and so addressing Mev is in keeping with a sort of philosophical tradition of blockchains which is uh arguably a good thing in itself but but also I think can teach us many lessons that hopefully can be applied outside of the you know very specific case of like sandwiching or whatever it is um maybe that's a bit too abstract but I'll just say bottom line uh if we like many people have this same utopic vision of what blockchain can accomplish for people um and in order for us to reach that I think most people would agree that um sort of in order to reach a world where users outcomes are improved we need to improve user outcomes uh um right and then how has this been been done um how people propose to do this uh right so again trusted private channels um protect RPC is an example of this where users can submit their transactions directly to like flashbots Builder um so it's not seen on the main pool and then um this transactions sort of end up in a block without anyone else seeing it until it's executed um there are many cryptographic proposals as well uh threshold encryption mempools commercial real schemes trusted execution environments and I'm sure we'll hear about all of these in the next in the coming talks they're also non-private approaches right so decentralized sequencing uh trusted marketplaces Etc um I I should mention that all of these are um all of them have their benefits all of them have their drawbacks and I you know each of them merits its own talk so I won't go into them individually but maybe to motivate that this is a very interesting problem and that we um that the most naive solution definitely isn't necessarily the best one um I'll give this example right so um why can't we just stop an encryption scheme on top of this to stop the the validator to to act on it or maybe why wouldn't we want to right um one one reason is the specific challenges you know challenges specific to the scheme if you have a commit reveal scheme how can you ensure a reveal after the commit was made or something along those lines but I think um another question that's maybe more interesting to me is that the outcomes in an encrypted environment if the encryption is successful is that the outcomes are blind in some sense right uh what does this mean well um if we assume that the outcome is blind we assume that the the transactions are ordered roughly randomly right but how does a random ordering compare to something which is um like a buy sell Buy sell with regard to swaps right especially if the random ordering ends up seeing Buy Buy sell sell where um the second buy and the second cell uh revert because the prices aren't aren't um you know within their range um this is obviously not desirable and now obviously we can go into the nitty-gritty here we can say well actually the ordering wouldn't be random because people would be spamming the chain to try you know sort of compete for a jockey for um uh beneficial positioning and these kind of things but that's not the point I'm trying to get to I'm really just trying to say that this is a hard problem and um you can't just make uh Mev private and then we've saw the problems and so I'll introduce a buzzword before I I close off um which many of you hopefully have heard of program privacy and it's just basically this idea that privacy doesn't need to be binary it doesn't need to be public or private but rather there's this very large design space in between the two where users can choose maybe some components of the information as public and maybe only to some entities and maybe only under some conditions and playing around with this is really something that we've been thinking about and that might solve a lot of the the problems in mvv and hopefully will so before everyone goes into a very technical uh talk later on I'll finish like a hand wavy abstract conclusion um which is to say that we can think of the Mev supply chain as a negotiation between these many different entities who are trying to um you know go from all these many different entities some who could do the execution and some who want execution to be done according to their specification and what we've seen is a imbalance of power where some entities for a variety of reasons including the information they have have been able to draw um an advantage at the cost of of of um other users and so what we're trying to do is we're trying to provide the tools to users to enter this negotiation and get uh sort of the best possible outcomes for themselves and these tools um We Believe of ways of expressing or choosing how the information is is exposed so that they can get the best outcomes themselves um without other agents taking advantage of the information they've exposed so I I hope that that made sense I think it's a q a now I actually don't know if you guys have been listening to me for the last 20 minutes I hope I haven't been speaking into nothingness um yeah cool thank you acquaintance yeah we have been able to hear you um anyone that has a burning question that I'm I'm mindful of the schedule we only have two and a half hours um so we might only have time for for one question I mean one one kind of small yeah go ahead I can ask a question uh that's uh that's a bit spicy so has anyone looked into like how would it look like with privacy on and off like is this something that can be Quantified in some way besides the general motion that we what we all understand that is that more privacy is better I I I mean I'd love for someone else to jump in here but uh you know my understanding is that it's an open open research problem and there are people working on actual implementations and so um I guess you know we'll we'll tell with experiments but also um one of the things we're working on on internally and I think full will sort of touch on this in the next uh in the next talk is uh how do we sort of theoretically understand the trade-off between um privacy or like the relationship between privacy and the sort of economic uh state of the outcome or foreign I do think that there's a a trade-off from I think that's what people will hopefully touch on the next talk I mean that's the title of the talk who knows okay great fantastic uh thank you quintus um I guess Phil are you ready for for your talk I am can you see my slides okay yep we all right amazing so perfect segment we're going to be talking about some open challenges and indeed trade-offs in Mev privacy hello everyone I am Phil um so all of this is let me minimize my little Zoom here so all of this is kind of going to be uh in the backdrop of something you all may have heard of which is something we announced recently at uh the last epcon which is the system we're building called Suave and this is kind of the next step for black bots so I'm going to talk for two minutes about Suave just to give you some background in case you weren't present for that announcement and then kind of dive into privacy specifically um so Suave is the next step for flashbots it stands for the single unifying auction for Value expression it's an Mev awareness encrypted AKA private with programmable privacy uh shout out clintus mempool for users and wallets it features Progressive decentralization so one of the goals here I'm going to be talking about is iterating towards decentralizing the chlorine Meb boost Market as well as the flat plots relay and other components kind of more than they are today it can also provide a turnkey decentralized block builder for Roll-Ups so the aim is to kind of build the best Mev ecosystem than we can on each so that other domains and other chains can both interact with that as well as kind of take some of the lessons for their own systems um so to do this we are creating kind of this fully decentralized block Builder this is the mission uh we want to develop this in the open so this is part of why the rose series uh are kind of being restarted and pushed again but you know not the only reason uh and we want to be kind of 100 open and transparent about our r d where we're at today where we're going and have people come and comment and participate in the design because there's a lot of questions we haven't answered yet so this talk is going to be kind of about one of these big questions that I hope you all as our community privacy aficionados and experts can help us answer um the system is going to be native uh it's going to have evm kind of scripting that's going to be relevant in the rest of the talk we're going to aim for optimal user execution harnessing Mev to give users kind of the cheapest possible price or the best outcome for any trades or other transactions they're doing and this is again going to be one of the key goals we're going to talk about privacy serving today we're looking for kind of full compatibility with flashbots info today so that Searchers can continue searching and validators can continue validating uh with kind of a generalization of course to cross and multi-chain if needed and this is really the key point of the design goal for this system which is to maximize both the competition within the system and also the geographic diversity of the nodes in the system by creating a protocol that doesn't let's say overly Advanced latency in any of the extraction or anything like that um and the last two things are we want to enable open order flow so this will be kind of a key part of privacy uh is how do you ensure open access to users transactions and kind of step away from the need to permission execution to certain Searchers or protocols to get ideal Mev outcomes we want truly permissionless execution where people can send to any number of protocols and any number of actors can kind of optimize against these transactions in real time and we want programmable privacy so that's what I'm going to be talking about next so these are some trillion dollar questions that I introduced at uh talk I gave at uh Columbia uh kind of event a few weeks ago and we're going to be talking about here this first question which is what is the Privacy slash efficiency Frontier in Mev extraction basically if you allow users to select much more Rich decryption conditions and predicates at Mev search time which is as I'll describe what we mean when we say programmable privacy how much info should they reveal when should they reveal it and what are the trade-offs of their ability to internalize the value of this private information against the execution quality um kind of of any options they participate in or anything like that other topics that may be relevant here include Geographic diversity censorship resistance how to escape sgx so we're going to be talking about one possible sgx solution but of course we know the problems with sgx stay tuned for the spicy panel later the feasibility of things like MPC and fhe in these contexts how this relates to the limits of minimizing Mev and actually the act of minimizing Mev itself that's going to be kind of later in this talk and also meta met on swab so how to use swap Mev to kind of Drive the system itself okay so that's all for Suave let's talk about privacy now finally um so we're going to be talking about privacy in service of two concrete goals here separately the first concrete goal um as kind of clintus talked about in the last presentation is to continue to reduce the requirements for trust in the flashbot system as it is today to decentralize the role of black spots today and to remove kind of centralized choke points in the system and maintain the decentralized Mev market we've built prevent further centralization vertical integration Etc um the second thing we really want to use privacy for is to allow the user to internalize the value of their Meb so this is what flashbots means when it says democratize uh you know um sorry distribute I chose the wrong keyword my bad I was making these slides very early this morning so this should be distributed but uh we want users to be able to internalize the value of their Meb and of course there are other reasons you might want privacy um you know alluding to some here but uh I think we're gonna kind of not talk about those in this specific presentation maybe we should have a separate uh roast on censorship resistance uh inclusion robustness and things like that if that's kind of of Interest um all right cool so here so we want privacy we want programmable privacy what do we mean what would be a useful abstraction for privacy so this is a presentation I gave uh two years ago now about uh kind of the best privacy abstraction that we could use in decentralized building and what we want to build towards so I'm going to give you kind of a thousand foot View and then we'll zoom into the details of how this is actually works in swab so wouldn't it be great if we could create this thing I'm calling a proof of private transaction which was basically an execution proof inside the eat consensus rules that a certain mix of public and private transactions um executed in a way that was consistent with a certain witness or here I'm calling it a hash of the proof so what this would allow you to do is basically prove that executing some private and public transactions in a given State uh resulted in a certain outcome and kind of proved certain properties of this outcome without leaking uh what's in these private transactions this is um kind of a standard notion of basically programmable uh encryption um so then if we had this magical abstraction what could we do well instead of having a relay or a builder like we do today at flashbots we could have a whole network of nodes in between the validator here and the Searcher Trader user or whatever on the other end over here um and the flashbots relay which currently kind of validates transactions for spam control and protects the privacy of bids and things like that in Flight as it was the rest of Med boost would kind of almost cease to need to exist the trust guarantees would be much more distributed and we could build something more peer-to-peer than the Federated Meb boost system um you could imagine also multiple kind of uh private transaction proofs floating around his peer-to-peer Network as well as an ability to take two of these private transaction proofs and combine them into a new private transaction Group which eventually kind of crystallizes into an ethereum block so this would be the ideal way to use privacy to decentralize flashblocks today instead of sending the relay your bundle you just create this proof about your bundle send it to this peer-to-peer Network where it can be trustlessly permissionlessly without losing privacy combined with other bundles um into eventually what becomes a block and this all kind of magically Works hand wavy hand wavy fully decentralized and we don't need the the relayer Builder today and we sidestep kind of a lot of the issues we're seeing in the Meb boost Market so this is really what we want to build towards this is the ideal abstraction but how do we get there um so um to get into that we kind of need to lay some technical groundwork to talk about swab a little bit and this may be interesting to some people also who have kind of asked and been curious about uh swab this stuff has all going to kind of be part of a swaps back that we're very actively developing and looking to roll out very soon uh people people were very angry at me for saying a timeline last time so I won't say one but soon TM um so swab is a staple system staple distributed system essentially you can consider basically Suave States as a sequence of States Through Time S1 s2s3 and we can denote the current state by lowercase s and the set of all past valid swab States as capital S these are basically states that are confirmed by the swab consensus algorithm um and transactions on this system are called bids and bids basically represent preferences and preferences map future states of the world to utility functions to the bidder um represented in basically computation so what do these uh these bids preferences transactions actually look like well you basically have a program or a smart contract on swap the same way kind of each each transaction executes some code this is this is the same idea and it is also evm as I said before evm compatible such that when you execute the bid in some future State that's this should probably stay S Prime to not be confusing but this is a different s when you execute the bid in some future State um or in any state really you get this output where uh the bid or the program outputs kind of the value of that state in its model um so this B is kind of the the value of reaching this state s for the amount that's going to be paid to the executor and the bid also outputs an address where basically that address uh is the executor that executed the swab transaction kind of computed dynamically that's a little tricky so not expecting kind of this to be fully grasped right now or all that really matters stateful system bids evm transactions they're also Oracle contracts so the way these bids are actually executed in the future if they do kind of come to fruition so let's say I want to bid for an empty Block in 1000 blocks I can submit this bid um and then by basically creating the transaction but then the transaction will actually output a payment if the Oracle essentially tells it that the state of uh other domains has transitioned um such that the payment should be made um so here's some example the Oracle can kind of be any flexible smart contract Oracle we've certainly seen a number of these on Ethan and other systems and it can be used here um but you'd have something like essentially okay block one on the Chain this is the block hash here's a log hash and here are the transaction hashes that are confirmed in this block body and this actually having this Oracle plus this distributed system is already enough to decentralize flashbots bundling so here are some example preferences you can state in this system um you can say okay if a transaction comes at position zero so the top of a block hey the sender of position one some some amount so this assumes that if you have someone that can reliably kind of place transactions in blocks they can kind of steganographically tag uh their their doing so and as long as your transaction here that you want Xerox Cafe ends up being mined at position zero that person gets to kind of trustlessly claim this 3E bid against the oracles another example is you can have kind of a list of transactions to come in a specific order so this is what's known as a bundle now you can say Xerox Cafe must come before transaction 0x deadbeat that must come before transaction 0x00 and let's say that represents a sandwich and that's where three eat to you so that would be the the B you would pay essentially the following sender uh steganographically tagged again some amount for landing this sandwich for you you can also use this to bid for empty blocks um you can use this to bid for certain execution Labs so you can just say look this is the state I want create a log transition to the state I want I'll pay you for it and kind of fully generalize this to to more bridge style transactions as well um so um how do we decentralize watch Bots using this well uh we basically create this relay um which uh or sorry not crazy like we create a swap the system where Searchers can submit these bids to um and we allow other actors just on the network Mev Bots other validators whatever it might be that we call executors which may or may not be L1 validators certainly it's a more efficient optimization if L1 validator is natively plug in here but also you could have pgo actors or other such actors kind of competing to fulfill this execution end of the Meb Market um uh so this allows us again to kind of bypass uh the relay I'm going to skip over some details um here um essentially this what this slide is saying there's two cases you can have native plugins for this where validators directly listen to bids um and kind of automatically switch over bids that they're able to parse and understand and control and other actors kind of translate these bids into bits that validators can control or you can have validators that totally don't use swab and the actual execution happens over pgas or some other kind of third-party Channel we've seen both in the MVP Market in practice um great so now let's switch gears a little bit and talk about really the meat of the Privacy problem which is not just to provide this proof of private transaction that allows us to decentralize the relay that allows us to decentralize the Builder into a peer-to-peer network but there's more value to privacy that still hasn't been unlocked in the world yet and that comes in and when you really kind of dissect the Mev Marketplace and the trends in the med Marketplace and where they're going in the future um so where is Mev going uh so any of the market has two sides there's the user and the validator the user or our Trader whatever else Searchers even can fall in the middle that can fall on either side here um wants to make transactions they want to purchase block space they're a consumer of block space validators want to get paid as much as possible for providing this block space and engage in kind of a business doing so um and the Crux of the med Market is essentially interfacing these two parties using Mev as the utility optimization function um so users want to minimize the amount of Mev they release and want to minimize their payments validators want to maximize the amount of Mev they extract they want to maximize their kind of received bids um so how do we allow the user to internalize the value of their Mev or private information and again this should say distributed not democratize well there's two possibilities the first one is we can use what we've seen before in various order flow auctions that have been proposed that are executing various other kind of domains other than ether experimenting with these you can use what's called basically permissioned execution so you can auction off the right to execute your transaction to a specific protocol to a specific Searcher to a specific set of parties you can set Futures on your critical that's essentially the same thing I also call this an information auction uh the advantage here is you kind of get a clear payment and a clear rebate up front the disadvantage here is you're actually disincentivizing competition on executing your transaction right so like you have to decide one party in advance that party can't efficiently price your transaction and in the real-time Med optimization you're losing the ability for other actors to economically provide input into what is your best execution what is the best optimization of preferences here on the other hand you have programmable privacy which basically lets users fine-tune uh how and when they release their information to various parties and leverage that in in negotiations for Meb so we strongly believe this is the better route of these two uh for scalability reasons because it allows for more permissionless extraction and because it doesn't lead to a pfop style Market uh closed permissioned order flow or the need to kind of trust certain Searchers or the need to kind of forfeit additional rent between when uh kind of the auction happens and the transaction is executed so for many reasons we believe this is the best option uh maybe we'll have a separate roast where we go deep into programmable privacy and why this is the best option um here we have basically um a more formal description of a bid in swab which is going to come from our documentation so stay tuned for this please don't read this whole thing now you'll just get a little bit confused because we're kind of limited on time but what matters here is basically in this bid if there's two things the users can provide an execution predicate this PMS uh or three things sorry an encryption product good Q of s and a set of peakers signal so this is kind of the control knobs on our programmable privacy inside Suave itself it allows the user to provide a set of transactions and say okay this is when this transaction will be decrypted when this condition on the world State against all these oracles are met this transaction can be decrypted and this is when this transaction can be executed if only if these conditions on state are men so you maybe can say okay I only want my transaction to execute if it's first in a block otherwise it should fail you can say Okay I want to reveal certain data but only under certain world State transitions so what does this allow you to do it allows you to partially decrypt transactions to allow Searchers to execute them but also keep private various aspects of your economic preferences now this gets really powerful when you combine it with this concept that we call a fee escalator internally which is basically signing transactions that increase any of these subsidies over time so you can think of this as like let's say users increasing a gas price over time having a vdf based Mev release function or anything like that so in this world you can actually start with a negative Mev subsidy where your transaction basically requires some Searcher to fund your account in order to be executed and you can slowly increase this Mev subsidy over time to try to find kind of the optimal Supply demand point where your transaction becomes profitable to mine now if you do this and you keep this curve private and you keep information about your transaction private that you allow Searchers to kind of Brute Force optimize this against other bundles using the type of merging we talked about in the proofs of private transactions earlier you can actually back out the guarantee that a user gets optimal Mev execution while having permissionless real-time access to their order flow so without the needs of permission who's going to execute their transaction and this is super powerful it only relies on kind of a competitiveness assumption around the Searchers and validators participating in this market so this is what we consider the core of kind of programmable privacy and why we care about it okay now the last thing I'm going to talk about is kind of the trade-off here and this is the kind of trillion dollar Mev question how much information to leak when you make a transaction as a user so there's the most extreme case of privacy which is that Searchers validators Etc learn nothing until a block is signed and confirmed um you can only possibly reorder emerge in cryptic blobs but maybe even not do that and that you learn no information theoretic output on this data of course in this most extreme world it's very hard to Mev optimize these transactions and get optimal execution for the user against Meb kind of find the right point on this curve uh the least extreme is you send it to the mempool you have no privacy but there are lots of middle grounds here so if you have a unisoft transaction maybe you can reveal that this transaction uses the unisoft contract you can reveal what pools are being traded you can reveal the direction of a trade or something like that which will help Searchers find and computationally optimize your Mev without leaking the valuable trade data that's allowing you to find this optimal trademark Point um in in our kind of analysis so this is the trillion dollar question here we're between a rock and a hard place between inefficient Mev with full privacy and mempool which provides no leverage for users so we really need to optimize this better and find a same middle ground in the context of these programmable abstractions we've created and look forward to your help here uh come join us on our forum and help us build this uh out of time so sorry I had to rush through that a little bit hopefully it was interesting and Illuminating please reach out if you have any other questions all right thanks everyone thank you Phil um I mean on in the next talk which is uh my talk I guess I'm going to push back a little bit on this trade-off space I think we can you know have our cake and eat it too um I guess the one kind of spicy question that I have um I'm happy to open it up is um on the the s in in Suave the the single like is it is it necessary for flashbots to you know want to take over the the encrypted mental space uh can there be multiple competing man pools or does it have to be like a single unified uh encrypted mempool so I think there should be multiple mentors I think the interesting question is like where to optimize the boundary the S is a little bit of a troll to appreciate you for picking up on it um I think what it means more is the intent to kind of provide and maximally decentralize all possible features of an encrypted mempool like in the long term not necessarily that like there won't be Computing systems there definitely will be in fact it will be competing with the centralized systems that exist in the Meb boost Marketplace today on day one so already on day one it won't be the single option and it'll need to kind of Reason about how to interface with these systems uh so yes I believe there's space for many encrypted mempools but we would like to try to hit the optimum trade-off point in our opinion on like what is the best option if you had to choose one that being said there are also some Network effects and advantages of having one option specifically when it comes to privacy so the more you can get within privacy zones that can be optimized against each other for Mev so again stepping down from this full privacy and like having this Mev optimizable privacy see I believe the better execution the user gets so like if if I can also optimize my transaction without revealing its information against many other trades and like liquidity provisions and arbitrages on uniswap I should be able to get a better price than if that transaction is not optimized with an awareness of like the semantics of Mev in mind um so there's like a network effect of privacy that like having more people in a single single zone is better uh for those people and also same with cross chain Mev for like validators cross chain you got super linear rewards and like the cross chain kind of uh buy-in you have to any single option so for those reasons like there is kind of some pressure there we also truly don't want to be the single system for obvious reasons because then if things break everyone's like all salty and stuff like that certainly we've seen that before so uh it's a little bit more of a troll than like a serious product goal but hopefully that answers the question thank you Phil uh any other question for Phil we have time for one more question all right it was super clear okay great um so I guess we're we're happy to uh embark on part two how do we provide privacy um and the next talk uh by me uh we will be basically trying to give an overview of uh of the design space for encrypted man pools foreign in three parts um first I'll describe you know just the basics of of what is an encrypted man pool and and the the design space I'll talk about the the motivation in part two and and then kind of the the fun part part three uh the more technical part where we talk about uh metadata because it's it's all well and good to encrypt the payload of a transaction but really all the metadata that comes with it also needs to be encrypted foreign okay so what what is what is the the simple framework of an encrypted mempool um really the key idea is that you want to encrypt your transaction off chain uh before it it it it it it it goes on chain um and you want to have some sort of of commitment to to the inclusion to The Ordering of that of that encrypted transaction before you decrypt so you have encrypt commit decrypt and then execute um and you know one of the questions you might ask is does this kind of add latency to the whole user experience and the answer is not necessarily like you can do all these three steps uh in one slot all in one go behind the scenes so one of the uh important things that you need for the encrypted man pool is some sort of encryption scheme that guarantees that the the ciphertext will eventually be decrypted um like commit reveal doesn't work um as quintus alluded to and there's basically five different uh families of of encryption that I've I've identified with this property so you can have basically a private end-to-end encryption where you have a a a centralized entity that um you know maintaining this this encrypted man pool so that would be flashback protect you can have Enclave based encryption where you're you're you're trusting you know the Integrity uh of sgx um there's a threshold-based encryption which seems to be the uh the the most popular approach with with orbit firm shutter and and various others there's delay encryption uh that uh stockware is is looking into um and then this witness encryption with this encryption if you're not familiar with it it's a very very powerful primitive which allows you to have arbitrarily um you know complex and flexible uh decryption predicates so you could say decrypt if something happens like for example you can you can have a snock of an arbitrary statement be a decryption so one one example could be if the chain has finalized the chain that includes the encrypted transaction has finalized then decrypt and so you can think of witness encryption as being a generalization of all these other decryption mechanisms now in terms of Readiness um you know we already have things like flashbot protect and I believe you know that we're you know where the technology is like fundamentally ready sgx is there to have things like Enclave based encrypted mentors and and threshold encryption is is is is also um you know pretty much there um delay encryption one of the hard bits there is that you you need a vdf Asic um we actually by we I mean different foundation and protocol Labs actually went through the effort of of designing an Asic and we have samples so we've we've manufactured samples um and they're going through the process of being packaged right now and they'll be tested in a few uh in a few weeks and the witness encryption is basically this this Moon map um piece of cryptography which which is not at all ready right now now one of the important things that I want to highlight here and this is where I kind of disagree a little bit with with Phil and quintus is that um you can have perfect encryption basically as a user you can leak no information but you can still be um not blind to user outcomes so basically the the encryption system itself can be aware um of of the transactions that it's manipulating and it does not have to randomly you know include these Cipher texts or blindly include them on chain it can actually kind of look under the cover of the encryption in such a way that the user doesn't have to to leak any information so that's called like like homomorphism where basically you're you're you're given um ciphertexts encryptions of messages and one and M2 and you can compute functions on on these on these functions on these encryption uh on the ciphertexts and it's actually trivial to do um you know homomorphisms in the in the trusted context right so if you have a a an encrypted mempool like like flashbot protect they get to decrypt privately um the the transactions and they they can run the functions on on that and it's the same thing for sgx right sgx you have the in-flight um encryption between the user and The Enclave but then the Enclave will have plain text access to to the message um but then you know as as you as you become more and more sophisticated in your encryption mechanism the the homomorphisms become more and more uh complicated okay so uh motivation on why why do we want uh encrypted man pools I think there's basically uh two right two reasons one is is front running and the other one is is a censorship so front running is is easy is this idea that uh you know if if you if you can't see uh the payload of a transaction and you and you can't see the metadata then you you can't kind of meaningfully uh front run transactions so for example you know a sandwich if you want a sandwich or transaction you need to know which pair is being um hit you need to know that it you know it is a trade in the first place um you need to know the the size of the transaction etc etc um but a kind of a related aspect is centralization so one of the one of the the bad things of Mev is the centralization force and we can ask ourselves um you know why is there centralization and basically this the centralization because some sophisticated entities can have an edge in in in in producing in producing blocks and being part of this this Mev pipeline and if we can remove sandwiches as as an edge then basically we we we we reduce the the surface area to be sophisticated and we reduce the the surface area to uh for for centralization so in in this slide basically I distinguish multiple types of Mev there's kind of the the positive Mev which you know Arbitrage and liquidations basically things that uh the designers of the application actually want me the extraction to happen because it leads to to outcomes for the decentralized application like prices being um being arbitraged but there's the the bad stuff which is which is moving so it's kind of a a great coincidence that um you know encryption kind of removes the bad stuff and and keeps the keeps the the good stuff and also helps with centralization now and the other um thing I want to highlight is around uh censorship so one of the kind of counter arguments that you might have around encrypted mentors helping with censorship is you could say that some entities in this Mev pipeline will say I will just not include any encrypted transactions or at least I won't include them unless you tell me that um that they don't touch certain addresses so you can imagine for example a block Builder saying I will only include your encrypted transaction if there's an accompanying snark saying that it it's ofac compliant and the one one of the things that we want to try and do is basically make make encryption the the default in such a way that um the if if you if you want if you want to have this very naive strategy of saying I will I will not include um uh you know I a certain type of transactions then you need to not include all the encrypted transactions and uh the the the the reason here is that if you include an encrypted transaction you don't know whether or not it it passes your your your filters so you have to you have to remove everything and so you have a massive handicap as as a as a sensoring builder like the only thing that you can see in the clear and you can you you you you can really um have an edge on this these Arbitrage transactions but you lose basically the the the the tips uh for uh for for for for transactions okay so now the the the final part on the the metadata so one of the things to realize is that when you make a transaction there's all this data is being leaked so there's IP address uh of the sender there's the size of the transaction there's who the sender is the the tip the the amount that's being paid um there's the gas price uh for the tip there's the the the the gas limit that's the nonce that's the signature and there's even like more set of things like the the timestamp the moment in time at which you post a transaction and my claim which is maybe a rather strong claim is that you can you can prevent uh all all leakage like you you can basically um have have no no privacy leakage whatsoever for any of these things and really it's a matter of going through them one by one and and for each trying to find a an appropriate solution to not leak the the piece of metadata so for IP address we have tor that's kind of a an easy one um for for for for for for the signature well one of the complications here is that um I mean usually signatures don't really leak information it is there are some significant schemes that do leak information but here it's more um about uh transaction validity so you you want to somehow convince that your transaction is is is is is valid um your encrypted transaction is added to to the Builder who will include it in in in the block and one of the things that we can do here is basically use uses a snock and a snock has you know several parts to it so it has a public input it has a private witness and it has a statement that's being proved in zero knowledge and so um for the signature what is the the public input basically the the user is saying here's my transaction ciphertext it's part of the public input and here is the state route of of the of the ethereum blockchain which is which is also public and then the what the user wants to do is try and convince them that the encrypted ciphertext has has a has a valid signature and so what they'll do is that what does it mean to verify a signature it means that you go fetch the associated Pub Key you validate it against the state route with a macro proof and then you prove in zero knowledge within your stock that your your your your your Merkel your Merkel proof is valid um and and and and uh and and that the signature is valid and then basically you can do you can do the same thing for every single piece of metadata um so for the for the Gas payment it's a very similar thing right you um every account on ethereum has um has a balance and you want to go authenticate this balance against the the state route and prove that the the macro proof uh is added and then what's specific to the balance is basically you want to prove an inequality you want to show that the sender balance is is is is is is is sufficient uh to pay to pay for the uh for for the gas costs for example the the four the full gas limit uh given the the the the the base gas price again same thing for the knots right like every account um not only has a publicly Associated and the balance but it also has a non- same story here foreign subtlety here um around the replay tag so one one of the the reasons that we have done says is basically as a anti uh dos mechanism um we basically don't want uh one uh one address to be spamming you know millions of transactions we only want basically one address to be able to broadcast only one one transaction and the way we do that is with with the nonce we basically uh will only broadcast in the in in the peer-to-peer Network a single a single transaction for a given address and a given nonce you know per unit of time for example so you can only increase your gas price for example once every second and that provides the anti a DDOS mechanism and you can get the exact same anti-dos mechanism with a so-called replay tag and one way to do it is to basically take the have like an encrypted non in a way where basically you you hash the nonsender private key and so that's going to be a unique piece of information a tag for the for your your for your address and nons Tuple in such a way that you um if you if you were to try and spam uh the the peer-to-peer Network then people would realize that the same non the same replay tag is coming over and over again um great um now one one of the the kind of the the cool things is is thinking about uh obfuscating the the size of the the transaction so one one idea here is to to path to the closest power of two you have transactions of various sizes and you know just by looking at the size you might think okay this is a uninstall transaction and this is some some a transfer for example because it's smaller um and so what if we just um pad to the to the closest power of two and I think this is a great solution that gets you you know 80 of the of the weight there but there's there's a couple um kind of deficiencies of this solution the the first one is that you get um you get imperfect packing and the reason is that you have to pay for these padding bytes these zero bytes that you that you that you have you have to put them on chain and you have to pay for the data availability so there's these little white squares that you have to pay for uh which is a bit sub-optimal and the other thing is that you have imperfect privacy because you know you even though you're padding to the closest power of two there's still going to be um different uh transaction sizes and so the the one of the suggested Solutions is basically to use homomorphism um something which is you know trivial to do with sgx and you know harder to do in with other types of encrypted man pools but let's go um let's let's see how homomorphism can help us well basically what we're going to do is we're going to apply a function which is the tight packing function the function just um takes the the the the plain text and just packs them as close as possible and then outputs a full block of the maximum size so if your if the maximum size of your blocks let's say 100 kilobytes which corresponds to I don't know a gas limit of of 30 plus well you you you're just going to pack everything within that and the the one of the nice things here is that you you get both the optimal uh packing and and the optimal uh privacy um now I don't have much time so I'm just gonna skip uh skip ahead but basically you can do the same thing um when you're packing you can also take into account the the the the the the the gas price and you can you can do prioritization based on that or based on access lists [Music] um and I guess one one of one of the things that I I only realized recently is that you we might actually be able to even hide um something a little counterfeit counter-intuitive which is the timestamp of the transaction like you know one might think that when you broadcast a transaction it's kind of fundamental to leak the timestamp but maybe maybe it's not and um basically the the idea here is that the the the peer-to-peer gossip Network can can handle a maximum number of transactions let's say you can handle a thousand transactions per second being gossiped around and so what we can do is that if at any point in time we're under this maximum capacity for the peer-to-peer Network we can broadcast dummy transactions that look exactly like real transactions because they're encrypted you can't distinguish them but um you have this kind of this magic homomorphic function that operates on on the plain text that is able to filter out the dummy transactions so as an observer of the mempool you're just observing a constantly saturated mempool um you know that's processing a thousand transactions a second but at the end of the day when you produce a block all these dummy transactions are are filtered out so you don't have to to to leak information on on when users are broadcasting the the transactions and that's it happy to take questions hey could I jump in and ask you to um say more about uh the homomorphic encryption plan you had in mind there I mean the main question I had is um who is it that has the secret key for the homomorphic encryption in your setup okay great question so here one thing you could do for example is you could give every validator and there's about half a million of those but let's let's say there's a million validators which I expect will happen each validator is allowed to make one dummy transaction every Epoch let's say um and so the the validators will be observing the mempool and they would be um signing with the validator private key and they will be able to set the flag you know the dummy flag to true and basically the stock that they would publish along with the encrypted ciphertext would say I'm a validator and so I'm I'm allowed to produce these these dummy transactions and um I and I know that they will get filtered out because the function that operates on on the plain text can just read the flag see that it's a dummy transaction and then filter it out so basically we're making use of the validator honest kind of majority like if we have sufficiently many bonus validates as producing these W transactions then the the mempool just looks like a white noise okay so it's like a threshold it's a threshold homomorphic encryption that you have in mind where the secret key for the encryption is like a quorum threshold thing held by the validator nodes and then that means that the majority of the validator nodes have the ability to decrypt every transaction but if they follow the rules then they will only decrypt the know added up homomorphic operation transaction after the fact is that the right way to think of it um so not quite I guess this this two separate questions that you can ask so I guess the question that you're really asking is what is the the the flavor of of homomorphism and it turns out the answer is that it doesn't matter it could be anything it could be it could be Enclave you know sgx based it could be threshold based it could be delay encryption it could be witness so each each of these five flavors of encryption comes in the vanilla plane mode or it comes in the advanced kind of homomorphic mode so you can think of it as a five by two Matrix where you have well this is exactly the five bedroom Matrix um where uh basically some some of these are already and some of these are not ready for homographic encryption so my my uh yeah my claim for example is that let's say you have an sgx based solution you can you can trivially do these home office and now the question that I was answering previously was around kind of who's feeding these dummy transactions um to to the encrypted mempool um and and and here is the validators but uh uh yeah the validators don't have to to participate in in in in the in the decryption process at all and if you take something like delay encryption um then really doesn't there's there's no party to trust you're just trusting physics um you know here you're trusting Intel with The Enclave here you're trusting you know flashbots maybe for Flash boss protect here trusting a committee but here with the encryption you uh you don't have to trust anyone so just to make it a little bit more concrete you know you have a thousand transactions a second that are coming in and they have the property that in 10 seconds you know they're all automatically decrypt so that's the delay part but they also have in addition a homomorphism property where you can take these transactions and kind of do operations on them in such a way that you go actually build the block while you're you're going through the process of of uh of decrypting them with the with the sequential computation I I think we need to to move on unless there's another uh kind of burning question um sorry I raised my hand um I'll just um ask I've been wanting to ask this since I saw your size from the Columbia presentation um so on um which dimension um or which Dimensions do you think are actually meaningful uh when we evaluate um privacy Solutions in the context of um uh and maybe mitigation or Mev Solutions um you labeled um I think one of the acts as sophistication um and um and multiple other dimensions but I guess can you sum it up for us technical properties economics um how do you think about this right so I mean I I would take a pragmatic approach and basically exactly as you said just follow the sophistication uh Frontier so just do whatever is we can do today um you know we've started with flashback protect I think it's you know an interesting start but it has you know obvious downsides because it's controlled by one entity um I think the the next you know obvious thing is is actually sgx and we have a whole panel to to discuss that I think sgx is like ready uh to to to to be deployed in production I think the the next front you know move after that is is threshold encryption um now the one of the reasons why I kind of put soon for homomorphic threshold encryption is because of um basically fhc so you can take an fhc scheme and you know you can just threshold thresholdize it uh by uh by by splitting the the private key basically um now the the you know one might say Okay FHA is just you know still years away and and that might be true but it turns out that for for very specific use cases um FH it might might be perfectly fine and like the the one thing that I'm especially kind of excited about is this idea of looking at access lists so I have a little um where is it yeah so here I have this uh the the this optional access list uh comment which basically says each transaction can come with an encrypted access list which will be readable in plain text by the the homomorphic decryption mechanism and what you can do is you can try and just pack your transactions in such a way that you have disjoint access lists and it it it might turn out that this is kind of good enough in practice you don't have to run the the whole evm in within fhe you only have to compare access lists and it turns out that comparing access lists is a so-called low depth um you know circuit so when when you're designing these circuits a little bit like snox you want to make sure that they're small but for fhe specifically you want them to be load depth um and and and you can do that for for Access list comparison um yeah which which might mean that fhc is is kind of uh will be ready for the purpose of building you know optimally enough blocks uh you know sooner than people might expect and then if we talk about the long term you know are we going to have an encrypted mental within uh you know the layer one if ethereum and I think this will only happen uh if we have delay encryption because that's the one thing that's like really trustless you're not you're not relying on on the committee you know we've been trying to to get rid of committees obviously the first two are not applicable for layer one ethereum because you're trusting companies uh but uh yeah delay encryption is the thing that that could be in trying in layer one but I think that's we're talking maybe half a decade away uh before things are awfully mature Andrew I think you're you're next um t uh small contracts pitfalls and best uh practices all right sure let me turn on the sugar okay again yeah we can see all right let's go for it um cool thank you for having me this is a really cool discussion um I'm going to talk about tea-based smart contracts um my viewpoint here is a little bit different than on uh I finally understand now what this point of suave was how you're viewing a flashbots on uh sgx as a way of having an encrypted mempool to you know do the Mev but this is still like going to then produce bundles of blocks that get published on ethereum in plain text when they're finally committed um what I'm the perspective I'm coming from is how to make privacy preserving smart contracts um so those who don't know me I'm from ic3 and a researcher at UIUC and I work with zcash Foundation I'm also starting a new Venture called honey badger cooperation labs and something we're doing is building uh zero knowledge credit Network application on top of te based smart contracts I'm putting out that there just so that you know off the bat you're not trying to guess where I end up at the end of this I'm in sgx nte Optimist but you'll see the the nuances and what it takes to get there even a little more background on the perspective that I come from my research directions for the past decade have all been about privacy and functionality added to Smart contract programming smart contract programming is what I care the most about but I've kind of followed this progression of doing everything we can with the simplest Technologies like just the plain text world just commit and reveal and then zero knowledge proofs I viewed this as like progressing you know down a more and more complicated stack and um of course what's been so interesting in the past few years and it's still you know booming now is just how pervasive zero knowledge proofs are through the like developers mindset on zero knowledge proof tools everyone's working on it all the big brains are doing um zero knowledge work improvements it's kind of diffused through the developer mindset smart contracts know that they're there what I've been working on though for the past several years and I'm basically all focusing on now are applications that need a more complicated platform for which the zero knowledge proofs and commitments stack are not enough and for those you need some form of threshold assumption or multi-party computation those are the same thing to me or you need trusted Hardware enclaves or possibly both and really my best frame of reference is the akitan research paper from 2018 I had a small role on that you know this was mainly uh the work of fan and Raymond and a bunch of other authors and this paper is the basis for the Oasis project although um uh ideas from here relate to a whole bunch of the other projects too so I'll kind of make some references to that as well um I'll say just a little bit because this is kind of clear from some of the talks that have come before and um I think Henry has a good way of explaining this I'll mention and maybe it'll come back later so I don't want to spend I want to get into the weeds a little bit about the details of uh sgx uh smart contracts but um I do think that there's a missing point to Smart contract developers where maybe some people get this some don't but then the line isn't so clear when is zero knowledge proofs appropriate for your application versus when do you need to make the jump to either enclaves or this NPC threshold the motivating example that I have for this is the issue of residual bids I think you could call this something like rev it's like more than multi-plot Mev but it is is kind of of that flavor you can build with commit and reveal an auction where at the end of the auction you know what the winning price was um but there's a lot of people that didn't win the auction and whatever their bids are that basically is forecasting their um you know unmet demand that might be a good predictor of their bidding strategies in the future so maybe the minimal information disclosure from an auction is just the winning price if you build a commit and reveal auction then you're also disclosing these bids that were not met and that is you know strategic information being leaked and no way that you build a smart contract on uh for like Fair ordering or anti-mev techniques is going to touch this issue at all because it's inherently about it's not even about like Fair versus causal ordering because later bids may have depended on the the previous bids inherently um but still this like unmet demand is leaking to someone like to a manager or an aggregator if you use a zero knowledge proof based uh roll up um to make this kind of application and hide this issue of residual bids you have to build your application your auction application using MPC or some threshold encryption uh or or Tes and in general um I have a bunch of other ways of making this point uh let me go to this one so in general I view this as like a framework where you know you maybe use the simplest tools that you can only move your way up to you know enclaves and multi-party computation if you really need to but from the Viewpoint of prototyping it's really the other way once you get the idea of how you can do smart contract programming on tees it gives you so much more flexibility to Define your privacy and disclosure policies that I can't even imagine going back to being stuck programming you know in the framework that doesn't provide that kind of a fine-grained control um I I think that this point kind of needs better you know explaining to where smart contract developers really see where that limit is uh I think that the way that it's explained in the penumbra protocol is pretty clear um I think I'll move on though I have kind of like a spicy comparison table that places um the te based contracts what they're capable of along with all of the other Alternatives a couple of these are worth like going into describing but maybe only in the panel or if I get questions on it um I want to really move on to basically talking about you know where we're at with development of te based smart contracts and um you know the the kind of really palpable thing is everyone's concerned about sgx attacks we'll talk a little bit about that in a moment that's a legitimate concern of course um but my view is that we have swung kind of the other way it's like humorous how you know more people know that sgx is bad than they know any other details of it and so even though um you know this kind of like developer discourse that you see between consensus protocol all's variants of proof of stake and all of that and even now the zero knowledge proofs really detailed technical discussions that are carried out throughout our developer ecosystem for sgx it's not at all yet we're basically still just scratching the surface of even um you know repeating mistakes that we already know how to deal with from my perspective a bunch of mitigations and good ideas were already presented in that 2018 akitan paper and they just aren't yet even um you know have made it to implementation and they're even the onlookers who are trying to watch these projects aren't really spotting the you know critical features that are missing so my hope is really to basically Advance this uh developer discussion so we understand some of the details of what it means to have an sgx design not just getting lost on kind of the high level trust model of sgx so to start with I'm going to talk at the kind of high level view of what the te based smart contracts are about and this is meant to be kind of you know Broad and vague such that it captures kind of all of them you know it doesn't have exactly the details and there are differences and details from them but this should give you the idea um in a nutshell smart contract tee just means you take the contract execution and that takes place in these uh secure sgx enclaves um practically what this means is that there's some secret key material that never leaves the enclaves but there's a public key that you can use to send encrypted messages to the enclaves so if you want to make a transaction in a te based smart contract system you send a transaction encrypted under the public key that corresponds to the secret key that only enclaves have um just The Enclave kind of exists you know on the processor it doesn't have that much memory available um so practically there's an untrusted storage that's sitting next to the enclave and The Enclave interacts to you know get and set values um to this untrusted uh database on the side and so this untrusted database on the side well the point of it is to be an encrypted database so all the keys in the key Value Store are encrypted all the values and the encrypted Value Store are encrypted that's the basic idea um besides just sending encrypted transactions you need some way to get you know some users are authorized to access their own account balance for example some outputs of contracts are published for everyone to see um so there's either events that get sent to you encrypted under your own address as an encryption public key or you make a query directly with um you know some interaction either way what you get back is the response from that query that would also be encrypted under your address that's the basic idea I guess the last component that that shows up at this high level is you also need some way of adding new nodes to the network and tolerating nodes that crash so it can't just be there's one you know Central Enclave node you need a network of Enclave nodes they have to have some mechanism that the new enclaves nodes that join those enclaves can get access to the secret key by some mechanism okay so that's the very high level View and that's really the only high level view of the um you know a diagram of this um that we'll get to but what I'll talk about kind of next on pitfalls you know uh uh pokes a little bit below this and I'll come back and you know refer to this um before getting to those I'll just point out a couple of details about you know what it is that the inner you know this is the the blockchain platform interface described but this is built on top of what The sgx Primitives themselves give you so you know understanding these two views is really what you need to have in mind in order to start um you know picking apart issues so um there is The Enclave um The Enclave has not the entire you know system memory available to it but um what it does is it can access more memory you know the processor has like at most 100 megabytes of memory on chip to do more than that you need to access Ram sgx has like a ram handling system so it'll do virtual memory with pages but all of the data on the page pages are encrypted there's also Integrity checks that are sort of built in by sgx so your enclave programs look like they have you know a big virtual address space you interact with an enclave by making e-calls these go from the untrusted operating system into the enclave and run some program so for example you might have an e-call for processing a block of encrypted transactions you typically will have to have an e-call that starts up a new node by generating keys to communicate with just that node and begin on bootstrapping and getting access to other key material from the the network as a whole um in order to e-calls can't just generally be processed on their own they need to request further services from the untrusted uh operating system host to access a key value store for example so those are done through oh calls those are calls out to the untrusted operating system that's typically how you interface with the disk from an enclave um the last two concepts that it's useful to know are that um uh the memory is lost if the process restarts like there's no way to load the memory from a prior process if the Enclave process crashes so for persistence even just on one node restarting you use a thing called sealed files these have like CPU specific keys and basically you can write to the file store some secret data there you can read it back but only the CPU that wrote that file is the one that can read it this gives you kind of a persistence ability and then the last component That's essential to using these for disintermediation you know to make it so that you don't have to trust the validators or you don't have to trust the Mev um you know flashbot operator is remote attestation so this is where one of your enclave e-calls outputs a report this report gets signed by Intel and then the signed report basically has output from your e-call whatever it chose to put in the report data field and the hash of the program binary that generated it so this attestation report is kind of where the you know magic happens this is where you get a guarantee that this output was produced by some Enclave running exactly this program and that's basically the you know source of your root of trust so I want to talk about um some specific pitfalls and explain them in terms of the you know high level thing that I've set there and you know these will follow along with some um uh you know posts you can read more data um about these so the first one is the issue of you know what it is that you do when an sgx vulnerability occurs so sgx vulnerabilities have occurred in the past um over years there's been you know dozens of them they range in terms of you know how catastrophic they are to like all of the Intel chips or just some Intel chips and whether you can just get like the attestation keys out of a chip that's like the worst case scenario or something more mild um what happened with secret Network and apic leak was that um so Apec leak was the you know absolute worst case scenario for an sgx vulnerability this um was publicly announced in August of last year but it had been brewing for nine months like the first disclosure from the people who found it to Intel was like in January um earlier in 2022 um so like a nine month period had had occurred um during which mainly like motherboard developers lenovos hp's you know got kind of private uh advanced notice to be able to build on you know patches against it and um cloud services were able to you know try to to make their plan in advance for um you know what to do when this disclosure would be announced when the disclosure is announced it basically means okay anyone using a remote attestation system is um you know at risk of having fake nodes that aren't even enclaves generate fake attestations and show up um really the the what's called TCB recovery is what Intel calls you know what do you do when an sgx vulnerability is found and it involves you know releasing patches that you can patch to upgrade your own processor the problem with remote attestation is that your threat model or other people on the network who have not upgraded their processor um the best response for TCB recovery is something like shutting down all new node registrations um until you can enforce that everyone has updated their uh patched code in order not to be vulnerable to this what happened with um secret network is that they had judged that none of the nodes that could join the secret Network were specifically vulnerable to apic leak um but this turned out not to be true so when we went to basically look into this like two months later um it still hadn't been um shut off it was easy to join new vulnerable nodes to the network um and then so we were able to get some secret data uh out of it another detail about this is that um the akitan paper had a bunch of Concepts on it one of which was compartmentalization and rotation these are both hardening you know at the time the akitan paper was made this had already been after the first you know handful of sgx attacks so the need to prepare for a potential sgx vulnerability was already clear to us then the basic idea of compartmentalization is that there's not just one master key that everyone has instead there's a small number of nodes that together share master keys ideally even those uh should only share them in a threshold multi-party computation threshold encryption way and then worker nodes maybe get a contract specific keys on a need to know basis uh the result of that would be that if there were this break there would be a much smaller attack surface of nodes that could leak the master key and perhaps a larger number of nodes that might have a portion of data threatened but not the whole network secret chose not to have any compartmentalization for other you know trade-off reasons sure but the result was that you know this attack enabled us to get the master key to the entire network we're still showing on this sgx.fail site you know more details about how this works and like a demonstration like we can still decrypt on their test net transactions today um part of the response is you want to rotate your keys when a vulnerability is announced because you don't know for sure whether or not the prior data uh we'll you know tomorrow turn out to someone could decrypt all of it and goes and publishes on the black market so you should at least rotate your keys so that um new people using the network ongoing transactions aren't vulnerable if the old key is compromised uh so this is something that secret uh but all is developing as part of their rapid you know response to the disclosure that we made um Oasis is is um still uh developing this too and plans to launch their mainnet without that feature in um there's more to say about this also Tom my students one of the authors of this um and there will be more presentations about sgx fail so I don't want to go more into that I'm also running out of time so I want to say a couple of other things but there's a lot more detail on the yesterday fail website I'll go really quick through the summer signer because I want to make a couple of other points but I've eaten up a lot of time here um another thing that we had wrote about it and you can read about it on this on a post on the ic3 site but um there's a centralized developer backdoor that's built into some of the code bases and that includes obscuro and secret Network at the time although they're both um uh fixing this and it relates to how the ceiling data works so sgx Nitty Gritty details there's two options I mean they're not that Nitty Gritty they show up on kind of the you know learn to use sgx 101 website ceiling has two modes Enclave mode and signer mode Enclave mode says that only the exact same program binary that generated the sealed file can read the sealed file Mr signer says that any program signed by the code Developers can read the sealed file so that means if you seal the data with mrsiner which is what secret did and what obscuro did I mean they haven't launched but I looked in their code base and that's what they had when I looked at it that means that the code signers the developers have a master decryption key themselves they could just code sign a malicious program that dumps the consensus seed they have you know the key that they need to get it that way so this is like a foot gun cell phone kind of unnecessary mistake um maybe I will end after after this next one just because I want to say it on briefly but um uh in this picture I mentioned that the Enclave boundary sort of ends where the memory begins and the uh you know disk access through oh calls begins well this means that these you need to be concerned about access pattern leakage so um you know the the secret developer documentation says that when you access the key Value Store from a smart contract okay it's a key value store so the key is encrypted and um the value is also encrypted um so that's great but that doesn't reveal the contents of the key but it'll still be apparent to the untrusted operating system if the same key is being accessed uh or not so if you write to an account balance this is something that like you know snip 20 tokens have to do what you want is that you can't tell which account is being written to but what the interface gives you is that um the access pattern is revealing that the same account is being used from one track transaction to another or not that's a problem and the only solution to this problem or the only solid solution to this problem is to implement an oblivious Ram algorithm this is something that could be added but it's something that um none of the different smart contract based systems um you know currently feature at this point um in principle you need to do this not just for your disk storage but clearly for that you do need to do it for your disk based storage but you also need to do it for your memory accesses because the untrusted operating system gets to see which pages in memory are being accessed so you could learn if smart contracts are stored in different spots in memory and you're just using the virtual memory system that uh sgx offers you're leaking an access pattern that very well may you know lead to the difference of telling which account just received a transaction or not um what else did I want to say I might cut it there so that I have five minutes for questions I have a couple of um other you know ideas that are about things that could even be um I I basically I mean let me just kind of do the summarize for this right so I mean I think that we're basically at the extremely early stage of um kind of developers awareness and understanding of the the details that go into sgx I'm sure we'll talk about the panel about the high level you know trust issues you have to trust Intel you have to be aware of the potential for further attacks but there's a lot of other kind of you know um defenses and good ideas that could be built into this um I'm really a fan of this idea but I won't be able to explain it in this talk but that is that you should be able to have applications defend their privacy rules even against the code signers and even the majority of validators shouldn't be able to make a hard for it to change the rules like the Dow hard Fork was obviously the rule change in order to cause a change to the application functionality with tees you have the ability to make applications that can defend themselves even against the tyranny of the majority of um the chain that they're running on hard forking um so yeah I'll end it there and see if we have any questions thank you Andrew very interesting technical uh Deep dive into sgx I mean one one thing that I've been wondering about sgx is um why why do remote associations have to you know go through go through Intel like why does Intel have to sign the transcript the the report like wouldn't it be so much easier if uh basically uh transcripts or reports are signed by the The Enclave key that's unique to this this one CPU um and and then Intel just tells you what the list of a valid Pub Keys um are those that that are trusted basically at any given point in time I mean that that's nearly how how it works I mean so a slightly more detail about how remote attestation works is it split up into what's called a provisioning phase which kind of necessary necessarily involves Intel but you do that once per chip you don't have to do it for the different applications that you run then there's the attestation step which in the default setting that secret and Oasis currently and I think that that's the case currently use it does every attestation goes through Intel again as well through the Intel attestation service there's an alternative called dcap where Intel is still involved in the provisioning process but um you know someone else can do the the second step of it I think that that can be made in a decentralized way but I don't know the details of dcap so well um the important thing is that um you will have Intel still be required as a kind of point of trust for at least the provisioning phase but there's no reason why Intel needs to be able to um uh say you know block some applications or block other applications or not and that's something that using the Decap alternative almost certainly um you know avoids the need for so even with sgx today you're not necessarily as reliant on Intel as the current software projects and make it seem okay great decentralized D cap sounds interesting questions from the audience I have a question uh do you have any opinion on the just recently released TDX system from Intel which is kind of like uh a separate but similar system to sgx yeah I I've heard about it I don't have any um thoughts on it yet my first question so one thing that I've noticed is that there's a kind of huge uh gap between what I want from remote attestation and ntees what we want for these decentralized applications and what the kind of bread and butter use of sgx uh is so the the standard cases it's a two-party versus three-party thing like the standard cases there's a developer and there's an untrue the cloud provider and you don't trust the cloud provider but you the developer are the one who puts the program there and gets the result and that's it there's just the two of you so very simple remote attestation can work for that and I think that TDX is a good fit for that what I care about is this three-party disintermediation world where there is a service provider in the cloud sure but there's a developer as well and the developer is also not trusted there's clients who you know don't want to trust the developer they only want to trust that the enclaves work the remote at a state nation that sgx provides fits that kind because you you don't have to be the developer you get these like portable signed reports that you can use to know that you're talking to an enclave on the network running the right program um I couldn't tell from my first look at TDX whether it supports that or not but my sense was that it doesn't if it does then maybe that would be a good fit I had a similar kind of concern in working with Sev this may I only know sgx as well I mean even that only so well so it may be that it's possible to use Sev to do this but my understanding was that you could not get a attestation report that's sufficient from SUV to provide the kind of guarantees that uh uh we want out of this for the smart contract setting and so that's my view now but I'm not very knowledgeable about TDX or Sev so that might be wrong thank you there's a there's a question in the chat maybe Jonathan if you want to ask sorry Justin yeah I'm sorry I have the second oldest Mev Rose participant here next to me so apologies if someone is crying um I was wondering about the the diagram you showed in the beginning under um on the using Tes for smart contract execution so do I have to send my or encrypt my transaction with the public key of a specific validator or is it uh say a um the same secret key public key pair for all tees in the in the valve that you're networking so it's a little more different than that but but only by a little and it's um uh there is a little bit of difference between the different systems um and I've just said these different systems but I have on my mind like a secret Network already has launched their mainnet Oasis Sapphire is an evm-based smart contract chain that I believe has not yet launched their mainnet but you can use Oasis Sapphire on a public test Network and obscuro also is meant to be an L2 for ethereum um that has this weird policy where like all privacy is canceled after one year so it's only like a temporary privacy just the policy that they have that also has a public test Network and so that's you know running adjacent to ethereum so I kind of say like those as like the the whole industry of these so with secret Network there's really only one master key that all of the enclaves share at a slightly lower level detail there's like per contract derived keys but you can derived all of them from the master public key and so you send your encrypted transaction to the public key associated with that contract but there's one master key for everything that everyone has so it's kind of you know the same as this diagram effectively and then in Oasis not only do you send your transactions to the key associated with the particular contract but the worker know that is you know proposing the block or whatever carrying out the execution for that only gets the key from the key manager knows they only get the workers only get the key for the contract that they have to process at that point so um it kind of limits the attack surface and you know the amount of contracts that would be spoiled if uh uh you know one of the worker nodes is able to break inside its own Enclave okay thank you Andrew I think we need to move on to the next talk uh minimizing muv on penumbra uh by Henry develos uh are you ready yeah perfect um share the screen please work and everyone can see um already um so I'm going to be talking uh about um minimizing Mev on penumbra um as a kind of like high level amazing oh okay there we go that's like a kind of like a high level perspective of um you know where we're coming from and where these sort of thoughts are coming from um two kind of framing questions the first is like what is med about um fundamentally I think that this is uh a question or or the whole field is fundamentally about like how do the economics of an application interact with the consensus system that's being used to uh execute to replicate that application in some decentralized ways that you can execute it um without a trusted party um and a perspective uh that I have that comes out of that is that um properly handling Mev fundamentally is is going to require a vertical integration between the uh economics of a particular application whether that's I I say app and that kind of big General sense you could imagine that being like a single smart contract or you could imagine that being like a constellation of contracts that someone wants to interact with um but you know whatever that kind of like high level application is um somehow needs to have its its economics integrated with the consensus mechanism that's actually executing it um and so my opinion which people may or may not agree with is that I think that app specific chains or or Roll-Ups are going to in the medium to long term outcompete um general purpose attempts at uh sort of dealing with Med um because ultimately the Mev is is linked with like what is the actual application that you're doing [Music] um and so if you if you can integrate that with the consensus mechanism you can be more powerful you can do more things and I think that um at least for applications that are important enough for people to build some specific thing that'll kind of out compete the second question is like okay well where does Mev occur it's going to occur wherever the miner or proposer has um actionable information about future execution um one one term that I really don't agree with is you know rebranding Med is like maximal extractable value I think if uh if you don't have a block proposer in a privileged position then you're not that's just Arbitrage and you know we have a word for that already let's not sort of dilute cuts um and so from that perspective you can say well we can minimize Mev basically in in two words or in two ways corresponding to those two words either you've reduced the amount of information disclosure um you're probably not going to ever get sort of Perfection on that front but then second how do you do mechanism design so that the disclosed information that you do reveal not actionable in a way in a privileged way by the the block producer so um all of the other talks here so far as far as I know are about general purpose solutions for um uh arbitrary programmability uh which is the case protherium um the thing that I'm going to be talking about instead is okay well what could we learn instead from building one single application um so I'm not gonna you know claim that this is like a solution to all problems but what I think is interesting about this approach is that although you can have um although you're taking a very narrow scope of like what the problem is um within that narrow scope you can have a a complete solution to the problem right so when people talk about say you know the Mev supply chain I actually would say instead like that should just be considered like end-to-end protocol design right like when you're designing a decentralized protocol the the design of that protocol should start from like the actual end user and their like you know Key Management their custody solution their client like all the way through that whole pipeline out to The Ledger where the execution happens and then all the way back to to where the claim um learns about it and if you don't consider that and you end up with sort of re-centralization in all the places that you missed like infuro um so what are we building we're building penumbra it's a private proof of Stakeout one it does this like interchange shielded pool with IBC um and it has a private decks so the the motivation for building a private decks is that you know if we're going to pick one application that you're trying to zoom in on um this is a really interesting one because every Market is a market also in information and so we have this idea that you know privacy can unlock Capital efficiency and maybe you can have a situation where a private alternative can out-compete uh transparent ones so coming back to this idea of like okay Mev is about um it is occurring where there's actionable information let's sort of zoom in on those two pieces first the information um on penumbra we have base layer privacy um I personally think that you can't really hope to solve Mev without having private see at the base layer and the reason is that [Music] try to see thought of as being control over information disclosure you can't ever undisclose information at a higher level that you've already revealed at a lower level and so if you have a a transparent based system you have all of these problems where you know like paying fees you know you have like who's paying for the gas there's all of these account like it's a it's a lot harder to kind of retroactively layer on uh sort of a fix to to metadata that's that's revealed at a lower level so what we started with is a multi-asset shielded pool that's similar to zcash and all of the value uh unlike Z cash is recorded privately in that shielded pool so when you do like a cross chain transfer in it you know just records that in the Chevrolet pool um and this means that everything is happening in and out of that uh common private base layer um so you have like no accounts there's no other transaction metadata the fees are all paid privately and the super powerful thing about building in privacy at the base layer is that it allows transactions to have precise disclosure for interaction with public state so even if we just stopped here and said like oh and we're going to have like a completely transparent you know like deck state or whatever um you know there's still Med problems that will come out of that but from a privacy perspective you've already achieved you know each individual transaction is only revealing you know the specific interaction with the public State and not all of this other metadata um and once you have that you're in a good position because every you know useful blockchain revolves around having this public shared state right that's that's why people want to use these systems um and so the question really is about how do you allow people to have private interactions with that um public shared state so we have to sort of I think that there's two kind of like ways that that breaks down um One Direction is to try to do uh splitting of flows the other is to do batching so with splitting let's say you know there's some uh action that someone wants to do they want to affect some change move some value around on the Chain um if they split that value into randomized sub amounts and spread that over distinct transactions then they can privately reassemble all of the output effects but this is only actually possible if you have a shielded base layer right if you're doing this on a transparent chain you just like you know see where all the puns going and this is is completely useless um the other approach is trying to do batching um what we've uh been thinking about is rather than trying to say oh we'll have threshold encryption where um we're gonna treat this transaction if this totally opaque uh object um if what we're actually trying to conceal is like what is this transaction specific contribution to a particular kind of like round of of public interactions uh public State changes then we don't actually want to be doing threshold encryption for the entire transaction because the entire transaction already is is shielded because we have this shielded base layer all we actually need is the ability to encrypt uh individual um uh uh individual contributions to the the public uh State and so what we do instead is have uh threshold encryption that works just on Integer amounts and has uh additive homomorphism so you can have the chain um aggregate all of the encryptions uh in some interval and then have the validators jointly decrypt that batch total and do some public on-chain computation so that's sort of how we're thinking about the the information side on the actionable piece of uh Mev um this is about sort of the like mechanism design so how do we make a uh mechanism design that that minimizes the impact of um a block proposer messing around with with transactions so um again we're focused on like very one very narrow use case which is building a decks on the the market taker side of that we have sealed input batch swaps so the idea is that some user wants to swap some amount they have their private input amount they encrypt that using flow encryption uh to a threshold is controlled by the validators um and because this is going to be bashed they don't know uh what that the output price is going to be right so you need to have some mechanism for doing late binding of the uh the execution to do that they make a private swap nft to themselves that commits to exactly what their private input was you know what the trading pair was what address they're going to claim the funds to and so on um the companions is that once the chain sort of gets this batch of swaps whether that's in a block or a longer interval um they can aggregate decrypt only the batch total and then execute all of the swaps with a common clearing price um and once that data has been posted to the chain each user can consume their uh private swap nft to privately mint their Pro rata share of the output um so that's kind of the the market um uh taker side but from that perspective you know how you actually do that execution is is sort of a black box um on the the market maker side you know what is in that black box um we have a concentrated liquidity mechanism where effectively every position is its own little amm but it's a an amm of the simplest possible form which is just you know a line and this means that the optimal routing problem is easy because you're it's basically like a uh the closest thing to an order book that you could have um so you can walk along this graph um and because all of these positions are created out of this private base layer and returned back into it um any individual participant can privately approximate whatever trading function they want by creating you know various different liquidity positions and although you have transparency of what the aggregate state of the market is you don't know which positions correspond uh you know to which users to which accounts uh because they can all be created through these distinct unlinkable transactions um so when you put these things together the the mechanism design basically is is a frequent batch swap system so there's multiple phases at the end of each block um first you open all of the positions that someone has requested to open and in some transaction in the block and you execute all the swaps um ARB all of the positions uh into having uh consistent prices with each other and then close out all of the positions that were requested to be closed this is pretty cool because because you're only doing this execution uh once a block you can afford to be considerably more sort of computationally sophisticated because you're amortizing that execution cost over every transaction in the blog so you can do routing on the whole liquidity graph and because you have uh all of your liquidity and you know all these different little um concentrated liquidity positions um you can have liquidity be sort of like active passive or or anywhere in between like if you want to simulate say like a uni B2 tool you know you can just do that um but all of that liquidity is kind of on a common footing and the chain is capturing all of the internal Arbitrage of you know is this price consistent with this other price um so when you put these things together it's kind of the implications are um the batching means that there's no ordering uh of uh effectively of of transactions within a block right so if you actually look at the data structure sure there's like a list of transactions but um the actual execution is happening in a bash and so the ordering of transactions uh has no like economic value so there's no real sequencer the proposer is only choosing whether or not to include or exclude transactions and because of the the way that the mechanism is designed um their decision of whether or not to include a transaction or not only has um a marginal effect on the outcome because there is an ordering um in order for for a block proposer to you know prevent anyone from doing Arbitrage on you know a specific trading pair they'd have to censor like many more transactions um and and sort of only have theirs uh be be present um they can't just sort of play games with like individual transactions um and even if you you know you try to censor like one specific training pair because you're doing this kind of graph routing um the the the the proposer's ability to like block people from doing art is limited by the way that the the art will sort of like flow through the the liquidity graph um it also means that the Dex is going to step between discrete sets of of consistent prices I mean whether I I when I say consistent I mean internally consistent um but that means that you don't have to have um you know a bunch of uh Seekers who are like competing to like race in some kind of mechanical Arbitrage you just do the mechanical Arbitrage um relative to yeah like like automatically uh as part of the protocol um and the external Arc against uh reference markets ends up being shared uh Pro rata among Seekers so there's a kind of interesting paper on this um by the the uh bing cat crypto research team did I uh have like a small part uh in in helping with um but it turns out that the game theory of of this type of game is that um uh uh The Seekers just like share uh programa uh RV against external reference markets so um I think there's a bunch of interesting pieces here um it's obviously a very um application and use case specific uh for the moment but I think there's some interesting um design pieces or or lessons that might be useful for either uh other application specific Solutions or for building general purpose applications um and I think some of the the pieces that we built in the longer term will will end up um being useful for for more General kind of contract interactions so um here's a bunch of links if you want to find out more and otherwise happy to just um answer any questions that people have thank you Henry um I guess what one question I have is on on the previous slide around the internal Arbitrage profits being captured by the protocol like is there a reason to not give them back to the users I guess well I guess when I say capture I don't necessarily mean um uh and this actually goes back to points that was made like a while ago in the uh the chat during a previous talk I think it was yeah it was Phil saying you know there's no free lunch like you know it's coming from somewhere um and what I would say is like yes that's true but if you capture it as part of the protocol then the protocol can decide um how to to distribute that right um so one option which is I think like the simplest is to just uh do a like a a burn like our burn mechanism um but you could also you know try to direct it in various ways I think you could try to rebate to to users who swapped or or to LPS um actually doing that I think is kind of tricky because once you're redistributing that value now you need a way to you have to like convince yourself that that mechanism itself is like not going to be gamed um but yeah when I say capture I don't necessarily mean um uh sort of like permanently held but just uh you know captured and then like okay you know now to do what with well we'll figure it out okay so just to make sure I understand um is there some sort of Global convex optimization going on because that's uh yes but for um uh a very like specific um special case of the problem right so like the the liquidity positions are made to have the simplest possible form so that the convex optimization problem is uh easy or easier uh there's actually a bunch of interesting questions there about that that come from the fact that you're doing that um routing in a batch one thing that is more difficult about that is that you lose the ability to have um like precise accounting for uh resource use right um like if somebody makes like a bunch of sort of like like dust uh trading positions right like how do you avoid that like blowing up the the complicity of the routing algorithm um because you don't really have a way to like impute that cost to a specific um so the approach you have to take essentially is just like get good and like make it fast and have heuristics that um bound the um the size of the optimization problem even if you don't necessarily get like a perfectly optimal solution um I think we're out of time there is one more question in the chat um from Andrews maybe uh to be answered yeah long-range leakage attacks um yeah it's a problem um there's not really a great solution to that um on the other hand uh if you look at sort of what role does the threshold encryption play in penumbra relative to in um you know some other protocol um even in the situation where you have like no flow encryption at all um well like exactly how much information are you leaking well you're leaking just the amount uh that someone contributed to a batch um and you don't have the there's no possibility to leak you know the account the to correlate it with any other transaction history um and so I think that the consequences of that leakage are a lot less severe um than uh if you were using that to kind of hide the the private per user state right like on penumbra the private state for each individual user is known only to them uh forever and the only thing that they're threshold encrypting is their contribution in like a specific round of of interaction with the Dex Stadium okay cool great thank you Henry um next talk is by Robert from flashbots uh private searching on private transactions from covert channels in sgx to MPC and back to sgx Robert the floor is yours I guess there'll be two more two more talks including Roberts and then the spicy sgx panel I think we're just waiting for Robert to get set up uh he just rejoined the room so it might need a couple seconds to share his screen yeah hey hey everyone can you hear me yes my brother also just crashed so uh can um anyone like enable that I can share my screen it says like I'm not allowed to share my screen foreign host Sarah um can you help yes so Fred I think has the screen share abilities foreign um Can can you see my screen yes okay so let's start um I'm gonna talk about like private searching or private transactions this [Music] um uh like stuff I've been working on during the recent weeks um here so let's jump right into it um what do I mean by private searching on private transactions um I assume that users want to receive Kickbacks on the Meb to generate um but they still want to keep the transaction Secret and at the same time Searchers want to keep their intellectual property secret right they don't want to reveal their searching strategies to competitors so the question is can we have both can we is this possible can Searchers generate front running and background and or back running transactions under these conditions um since we're in the area of private Computing here like an obvious um and when I say sjx here like um I use it synonymously for a trusted execution environment so I'm just using sjx so a very simple setting here user the user's input is a transaction the input to an enclave the Searcher inputs a program the within the sgx Enclave to run the program that takes the Searcher program and executes it upon the transaction and it outputs the outputs a signed transaction signed background that is sent to the Builder so that sounds great but there is a catch to that right it's the catch is Click over channels and quickly explain what covert channels are because it's it's a very Niche topic and hardly anyone knows about it um so covert handles are ways to secretly convey information like in order to do that they piggyback on on so-called over channels and if you're coming from like a telecommunications background you can also think of covert channels as a way to secretly modulate information on an existing carrier signal it's a bit of abstract most people understand it when you conqu compare covert channels to side channels because people are usually aware of what side channels are it's just a difference in the attacker model so with side channels the attackers extracts aims to extract information but the attacker does that by observing the observing let's say for example and from outside the system for example there's an algorithm running um and the attacker can observe the power consumption I think that's a very classic example but with covert channels um that has the same goal so to instruct extract information but it additionally has support from inside the system so there's basically a colluder right so you can also see why it's a um a stronger attack here how does that um relate to the sjx thing well if you think about it um what are like potential orbit channels here um click the design background right this is the output can the can the Searcher program um manipulates the designed background well obviously obviously yes um the program could be as simple as saying well take this take the user input and um this is this is the output so in order in order to protect again instead we could encrypt um another over channel would be network communication there's the such a program could be as simple as saying well um open a network connection to a host take the user transaction and send it over to the network so we need to filter that um but it gets tricky if you think what channels in terms of CPU and memory of the host system I think Andrew Emilia Andrew Miller um had a similar Point here so how can we ensure that the Searcher program does not encode secret information in um CPU or memory access or usage patterns you can think of let's say um encoding information in how much CPU is used let's say you're using CPU for one second to code a one or for two seconds to code a zero and leak information that way and that is that is very hard to protect against so there's different ways on how to how to go about this well with this seems to be a trade-off right like how expressive should the Searcher program be versus like the existence of information leakage or covert channels we can start with a fully expressive program search a program um then check is the recovered Channel yes restricted would say we don't allow network communication unless there's still a covered Channel yes okay we I don't know we we prevent for Loops let's say but there's always the question is there any leakage left we could go the other way around say um we start um like a fully restrictive program um and ask the question is it useful right so when if the Searcher program can't do anything it's obviously useless so we say okay let's um allow editions for example is it useful well probably not the question is at what point is it useful enough it's also hard to say um or we could start start somewhere in the middle between the expressiveness level um the question is then like where should we go from there um what we decided to do is like to start with um NPC because NPC um interestingly um like guarantees that the parties cannot learn um anything but the output of the function so there are no cover channels there like as a general statement like what is NPC it lasts multiple parties to try and compute the public function while keeping the inputs secret so this is a good start to explore the design space going back to the original question like secrets searching on secret transactions how would this look within PC um so instead of using STX um we now have like an NPC backgrounding protocol right we don't know yet what this would look like um and again we have like the user imported transaction search input a program um and the output is a signed back running transaction we just don't know like the question is like what is the back running protocol or like how does it work and what is the Searcher program um and we started experimenting in the MP speeds framework it's a general um NPC framework and I'm gonna quickly present um the the current state of the proof of concept all right so first thing what is the this what is the Searcher program look like it turns out like a search language can be pretty simple so the Searcher program can just consist of like a list of constants a list of computing instructions and Computing instructions are very simple so it's additional subtraction multiplication if a square root that's another not super simple but still it's um relatively simple instruction but note that there are no loops and there's no branching we cannot allow that um there's a couple of comparison instructions and the list of references for the populating the the back running transaction so what is the what is the backgrounding protocol right here this this middle thing what is the back does the backgrounding protocol look like um turns out it's also like this is um like simplified um python-like code but it's just to highlight how it how it works on a high level um we have like a protocol internal storage um if you think about what the transaction is it's just from rlp encoded data so the first thing is to decode the dictator make it a um and populate the storage with that second step is take the constants from the Searcher populate the storage with that Next Step take the searches computations execute the computations one by one on the storage um and then run the comparisons so the Searcher provides a couple of comparisons and note here that there is a success variable and all of the comparisons must be true in order for the success variable to remain true um then in the end like the back running transaction gets populated I think the interesting part here is that um in the end the backgrounding transaction is sent to the Builder if and only if all of the comparisons were true so this is a very abstract introduction of how the proof of concept works we can walk through an example I guess this makes it a bit easier to understand so this is a an example with a real world transaction from last month a user sold 3.75 if for usdt on the units for P2 pool so first step for the protocol would be the decode the transaction and populate the storage so you can see here the non-scale limit whatever so it's the the entire transaction in the Second Step um the protocol loads the constants from this provided by the searcher um there's a couple of um going into all the details but constants for the comparison for the backgrounding amount uh and for the background transaction uh what is important to note here is that the Searcher also provides on-chain information right for example here's the the w e the number of weave tokens in the pool at that point in time or the number of USD tokens at that point in time and I think it's a fair assumption because the Searcher already knows for this for its strategy like what online information is needed and we can expect the Searcher to provide exactly that information so there's no need for the backgroundic protocol to query um the the um ebm or the if you're in P2P Network for additional information we can just assume the Searcher to provide that information so but um what is the strategy now for the for the search the right the Searcher wants to background a uni swap trade um the the Searcher kind of knows that uh in this particular trade users sold um uh if to to the to the pool so the size of the pool increased and took out usdt from the pool so the this slightly affected the price obviously in Search and knows that so that um the price of Eve went down slightly so the question for the Searcher is like how much should I put it like how much what is the amount I can put in in order to move the price up again to a certain Target price um and you can use the formula like I'm not going to go into the details of the formula but it's um important to note here it's just like a couple of simple computations you have a couple of um multiplications and additions like a division of the square root and all the information is either provided by the searcher right so the fee of the unit spot Market the Target price um the Precision is like the number of decimals for the for the we token um or it can be computed um from the info on training in the information provided by the Searcher and the users transaction for example the why is the amount of Eve in the unit swap with two pool after the user's trade and then that can be computed by the amount of Eve in the pool before the trade plus the plus the amount that the user put in minus the fee so all of this can be computed obviously like they're very important for the Searchers also like is the background profitable all right so this is also part of the strategy so this is like on a high level the strategy like I've implemented in the proof of concept how does this look like in this search language so this is not nice to read and it's just a snippet I'm only going to explain the first line here so this is like a 4 to 29 so it's this reference is just the um the fourth item in the storage two references and multiplication and 29 is the 29th item in the storage so fourth item is the amount the value and the user transaction multiplied multiplied by the in this case Searcher provided constant fee and this is like step by step um the backgrounding protocol can execute the computations provided by the searcher um obviously like it's important that the Searcher wants to um send the back running transaction if and only if um the user transaction actually is um um selling e for ustt because the strategy um the computations provided is really targeted for that and if the background is profitable so there's a couple of comparisons like it works similar way if you look at the first line it's free for 23 is um the third storage item this is the two address of the of the user transaction for in this case is the equal operator and 23 is the unit spot V2 router address that was provided by the Searcher as a constant um so it's a couple of comparisons probably the last line is the also an important one is the background profit so I'm greater than zero um so if all those transactions are all those comparisons are true then the background in transactions is created the creating the background in transaction is actually the simplest part of simplest part of that it is just a list of references to storage so let's say that like it's 40 this is the the 40th element in the storage this is nons and you have the gas limit gas price um and so on and these items are like the values are taken from this from Storage rlp encoded um this is the background in transaction so so this is the proof of concept um there's a couple of open questions with that um first of all is the search language expressive enough to be useful my gut feeling is yes but it's I'm also not a Searcher so um input on that is highly appreciated you could also see like the the search language like this is very low level and this is very cumbersome and error prone to to work with um so what would a what would a high level language look like that compiles down to this low level language um and also like how can we make this practical I mean this proof of concept implemented in the MP speeds framework um like on the single transaction a single um Searcher strategy takes uh like in the strongest security model takes like 40 hours to compute and a couple of hundred gigabytes of back and forth communication so this is nowhere practical so [Music] um so how to make this how to make this practical right I mean we could recall like we started experimenting with NPC because um we needed to restrict expressiveness of the Searchers program and now we we arrived at the design that we could um uh that is like um restricted and hopefully expressive enough so can we use that and now it now implement it um using sgx and create a practical solution um probably we also need to emulate some npc-like Behavior like execute all branches um have constant time functions but but maybe that's a Way Forward um another way would be to um go for uh application specific NPC or um with homomorphic encryption um why is that if you if you zoom out a bit um and at the um the proof of concept design basically has three phases right this extractor data from the user transaction this could happen like on the user machine so this is this is easy the user could use that and encrypt it send it over to the Searcher then the Searcher does a couple of computations on the extracted data in the sub some constants um that sounds exactly like homomorphic encryption and if you think about it like the um we only need to support like very limited um operations so maybe partially homomorphic encryption is sufficient um and if if it is then we have like a reasonably um like uh partially homomorphic encryption schemes with reasonable performance that exist already today um for me like a big open question is like we also need to enforce certain conditions under which the back running transaction is revealed and um I have no clue how to do that in a in a practical way so if you have ideas like go ahead share it I'm [Music] um yeah so so that's it click the takeaways from this talk if it's if it's just the two takeaways covert channels um I'm afraid to sjx deployments and they should be considered and private searching on private transactions um maybe possible even even though they are not obviously not practically at the moment any questions well thank you Robert for this talk uh very interesting for me I didn't appreciate the covered channels for sgx [Music] um I don't I guess I don't completely understand the how covered channels are addressed in the in the MPC case like go ahead yeah um for me like before I started with like playing around with NPC I had like the same issue like same question um the the fun thing is or for me to the the inside was like um they're just not an issue with NPC they just don't occur they're all um already by the [Music] um because you by Design you cannot leak information that's the well a very simple NPC is just the constant function that returns all the inputs uh you know without any doing any operation and that leaks everything links to whole inputs so that would have okay sorry like it doesn't leak any information apart from the output the when writing an MP speech program you still kind of have the problem that you have to do if you have an array and you want to do an index into that array that depends on some data I could input dependent lookup you're forced to either do a linear scan through the whole array which costs a lot uh or leaks something by you know publishing which value in the index you want to do and doing some kind of interaction like that so you either need to take this performance penalty or try to you could use an Oram within an MPC that's like one of the things that the you know cryptography Theory relies on sometimes um except the same problem seems to show up anyway right but this is how the proof of concept works so it uses like a the storage is like an Orem and it works on on that I think if um can you also do any distinction between like covert Channel and um a side Channel like I think that they're they're different and to me that the difference is kind of addressed by um uh remote attestation at least in the sgx setting because um you know if uh if a covert channel would be built into the code it should be visible to you know Auditors looking at the source code to be able to check and at least with remote attestation you know you have that option and and then if you um if you check that the code only does linear scans in sgx just like you would have to with MPC you'd be getting the same guarantee that it's not leaking a channel because it is on doing a data independent uh access I think that the tricky question is like can the the input to your program right that runs within sgx can the input to the program um change the program execution flow in such a way that it leaks information um and sure you can like if you analyze the program and you make sure that this is not the case I totally agree I just think it's it's very hard it's an analysis that's very hard to conduct I I guess my question on the NPC was um like how can you guarantee that the program we'll output something which is ex you know expected let's say the program is a builder program which builds a block What If instead of building a block it just outputs just the input transactions or maybe in some cases it like let's say 99 of the case it outputs a block like the expected output but then if Mev is over let's say a thousand if it just leaks all the transactions and then the attacker can just uh I can just front one I guess that's a it's an issue just maybe I want um should have clarified like the the scope for the proof of concept it's just a user search interface right so the output is sent to the Builder and the Builder could see everything in clear text and in this case like I don't bother with that like the builders seem to be trusted so let's say the the Searcher leaks the user transaction um it just it can leak to the Builder and the builders is trusted in this setting so it didn't go any further than Beyond this user search interface so it's just like the use the user transactor remains private to the user and Searcher and the searcher strategy remains private among the user in searchroom um but not among like the output is then um shared with the Builder and the Builder can see everything well you can see the output okay so you're writing the the Searcher does not get access to the output only the Builder in the content yeah yeah aha I see but the Builder is trusted right the Builder could act upon the information okay I understand that great thank you so much Robert um we're already over time for the whole event but we do have one more talk and one more panel so our last talk is the joys and challenges of adopting pets present and future applications of privacy enhancing Tech at flashbots by Jonathan from flashbots hello everyone can you hear me well yeah Perfect all right let's get started with that I I don't know I kind of feel like it might have been better to have that talk earlier but let's see I hope I'm not too redundant with like the other ones um it's going to be a bit high level uh I'm not going to go into too much details it's mostly about giving you a flavor of like what's possible as of today uh I think it's gonna Echo uh what Robert just showed you in terms of like uh run time and like challenges to get to get things uh up and running and what we could expect or what we could do to improve the current situation so first of all um had previously lensing Technologies these representation is like something that you know we've agreed upon in in the in the past Community uh basically speeding them into three different categories depending on like what uh what is their main feature do they protect the privacy of the input the outputs or are they more of a of a governance technology and you see that some of them are kind of like overlapping uh but what I think is important to understand from these representation is that um we tend to con to to to to to to mix sometimes the notion of a privacy confidentiality and all these kind of things uh so for for in the World of Pets uh we try to stick to using privacy uh for for what we mean as like out the Privacy so technologies that guarantee that uh the results of an application I remain private uh well or at least do not disclose any any information about about the inputs that's kind of like the guarantees that uh differential privacy would give you for example which We're Not Gonna uh address in this talk um and similarly you've got uh overlapping text like I'm not going to address Snorks because I think uh it's probably like the most familiar piece of technology you have in in this community so we're going to stick to to the technology that that provide a confidentiality uh mostly going to cover tees NPC and nfat for that matter so in terms of like the applications of privacy at flashbots um I think a good reference to like the the use cases we that are listed on the left so mostly we're going to be working at applying privacy to to these use cases it's like it's very high level uh I think Robert's presentation was like one component within uh within the other flow auction for example um quintances tool could give you more details and I think in general it's a it's worth exploring the the writings website as well as the Forum uh to get the benefiting of these uh of each of these problems but that's basically the the context to which we want to to apply these privacy texts and basically um it's not about providing privacy I think uh probably like a lot of us are very keen on like uh privacy as a right and those kind of things but we need to see beyond that we need to understand that privacy is actually a mean to unlock new use cases but it's also a way to increase the decentralization of the of the services that flashbots have been providing for a while uh and that the community has trusted flashbacks to provide so by injecting privacy in in the services we're hoping to increase their their resilience increase their decentralization but also to Foster collaboration between actors that would normally not uh have the incentive to collaborate into performing a Joint Task together that might even be considered to be in competition when trying to perform a touch like I'm thinking of blog beading for example where if we want to hope to have distributed by building we need to we need block Builders to share information that they would not have any interest to share normally in terms of like the requirements that that we're expecting from these Technologies we we want a lot of things actually uh we want speeds in order to not be too constrained by like the flood transactions we want to be able to scale to a large number of users um of course we want the maximal security guarantees for the minimal assumptions and especially we want well-defined assumptions that's going to be important in some of the text we're covering right we'll see it's not always extremely clear uh what what is the threat model um maybe something we've not addressed too much today when when you start applying this uh this kind of like Technologies and PC and FH in particular you might lose some uh Precision in the calculations you're making uh I my take is that this might have an impact and we need to be extremely aware of that too uh the one thing we don't need and that's good because like tends to be changing as well sometimes to provide is uh for secrecy so we know in the case of uh of uh trying to implement an encrypted mempool for example or or private smart contracts like uh Andrew presented everything that we are manipulating as like sensitive data is short-lived uh in in the sense that it's not it doesn't remain sensitive forever once the computation is done and the information has been processed and the transaction lens on chain it doesn't really matter if like uh the this competition can be can be disclosed afterwards uh at least uh we I don't think we need uh forward secrecy um in terms of the roadmap itself I think you've understood by now that uh in the short term we're pretty much focusing on on Intel sdx um again I want to to to make it uh very clear that we're not uh we're not like sgx Fanboys uh we just like taking the pragmatic stance of like what is the most easy thing to deploy and the most ready thing to deploy uh today that can like bring us closer to to the air to the end game uh but definitely our goal is to phase out sgx and even maybe like Hardware uh dependencies in general and you've seen you've just seen like a first item in doing so with Robert's presentation on the background um by any means that doesn't mean we committed to to this path either we exploring like multiple Parts in parallel and you're more than welcome to join us in this journey um without further Ado just diving into each of the texts out we've heard a lot about uh about tea so I think a great reference today is of course endless presentations um sgx as a t is by far like the most popular of the of the T as of today uh which is it's good in a way because like it's received a lot of scrutiny you've got lots of of papers about it so just to summarize what it is uh technically it's just a set of like CP instructions uh that allow you to to create uh enclaves uh what we call like initially what was a trusted portion of an application and that I've grown into sometimes being like whole applications containers uh and maybe not even like whole virtual machines and the ID is that um you'll get considered total confidentially of your data during the computation so anything that happens within this Enclave cannot be seen by any external party of the of the system not even like the the root enemy sweater the cloud operator if you are in a cloud setting uh so it's very much like these protected environments um and we know that sgx has received a lot of bad press uh it's been broken over and over again by various attacks lots of academic papers uh in these in this direction so I guess that the interesting question today is uh why uh so we've started to touch upon it as in uh it's received a lot of scrutiny because it's been one of the first uh tees that was available and and one of the probably like easiest to uh to get your hands on it was just an SDK just extending like that C plus plus so it was relatively easy for people to start developing with it um my take on that is that the the problems that we see repeatedly with sex um are mostly due to to the way to be designed so it's been designed by Intel on top of uh of Intel CPUs uh which means is that it's sharing various components uh like architectural and micro architectural contents uh like cache lines for example uh that you know a lot of of the side channels that's like that we've seen against sgx but it's also sharing uh all the confidence of the system like uh um the the memory address bus Which you know make it uh pretty hard to to defend uh thoroughly into in against against some of the attacks um so what's the the problem the problem with that is that it was not maybe not like um what's Intel wanted to to see from uh from from these technologies that initially was not maybe meant uh to have to have this kind of applications so we've seen a move by Intel recently uh since the ice Lake uh generation of of uh of intensitypus that answered uh one request from the community to have larger enclaves uh you might have uh quotes from Andrew's presentation that the first generation of sgx and Clays uh could be as much could could get as much as like 128 Megs of memory uh and Intel decided to lift this this uh constraint another like you know multiple hundreds of gigabytes of memory the trade-off for that is that we've lost uh we've lost the Integrity in in memory so we don't really have like the same uh security guarantees from these uh previous generation of sdx to the new one and the way in cell uh defended against that is that they they repurpose this GX as a cloud only technology or a cloud-first technology so it's not meant to be uh massively deployed on on desktops or laptops anymore which of course like hurts decentralization and you know maybe pushes us even further to try and find uh Alternatives and and what could they be um of course we've we're going to see like the pure software crypto uh but maybe in the meantime uh before they get like ready for for the prime production um we can also explore uh other teas that might not have like the same design flows as sgx has uh so I'm thinking for example um Keystone uh which is very interesting project uh could put together by uh don song in the team um maybe we might want to to design a custom Enclave even if that would be even more uh challenging in resource demanding I guess um one notion that would be interesting as well in the context of decentralization is to is to try and see uh whether a heterogeneous network of of tees uh would make sense uh bearing in mind that the main challenge is that they do not have a Common Thread model so it doesn't mean the same thing to have a name clay we've kind of call it an enclave running an sgx or SCD for example uh let alone TDX and like all the other Alternatives so that that could be an interesting challenge to to see if we could if we could Define like this Common Thread model um right switching to uh software crypto you've just seen a very interesting application of secure NPC uh with Robert so I think you've understood the global ID so you have uh input data here the five and we're basically splitting into different shares and due to like the homorphic properties of these shares we're able to apply uh operations before recombining these shares to obtain uh the the result that you would expect so it kind of works well until until basically um you need like more complex operations so when you start from a general purpose secret sharing either like additive or show me a secret sharing a protocol you can you can do these kind of things now if you want to if you want to get uh to get to better performances usually what happens is that you want to design custom protocols right as soon as you want to start to do custom functions and the interesting thing when you start designing custom protocols is that if you look in the literature and in this presentation like most of the examples are drawn from the Privacy preserving machine learning literature uh there's two reasons for that a that's my background uh so I've got a few papers uh in readings on that and the second is that it's probably like a it tends to be like very large problems that requires a lot of upcoming time in in memory so they tend to set like a higher bound an upper bound of like what you should expect from the behavior of these custom protocols as well and and in particular what I like to to know in like these in these two in these two uh tables that you've got on the right is that you you can see that um MPC has to be considered into different settings uh we we tend to We tend to just like in experiments uh just reports the the things that we've done that we've run on our local infrastructure but if we think into the context of flashbots uh or any other decentralized application we should be more interested in like how NPC applications behave uh in uh one setting so across the internet with like uh longer latencies the reason why is that um that's we the domain the main bottleneck of of NPC Protocols are um is communication it's bandwidth uh so the the goal basically the the game uh in in NPC to to improve the performances uh is to is to try and address uh this communication bound problem so either reduce the amount of communication that are required um or uh redesign uh the protocols to make to make sure that they can uh that they're generating like less data or have less rounds of of communications for example um another of Hope in this in with this regard is that uh in this uh in this pages that is from uh that is that is uh you have a diagram on the right um You can see that uh with the right custom protocol um with a problem side problem size growing the author has been able to basically switch the the natural problem of NPC uh from being communication bound to being computation bound uh so it means that with the right uh right designs we can potentially uh go beyond this communication bounds problem within PC and then focus on like accelerating uh the computation and and kind of like Get The Best of Both Worlds it's kind of like what I was hinting at in in the chat before uh when when robot was like making this suggestion uh this there's quite a few protocols in NPC that also try to that that use uh on morphic encryption uh natively within the protocol to reduce the amount of communication routes that are required so it's we'll see that it's pretty important to to not see these all of these Technologies uh as Standalone but as like pieces of a of a bigger jigsaw Maybe um switching to homorphic encryption Okay so same thing I'm not going to go into into nitty-gritty details about how fhe works we should I mean we could do that uh another day maybe uh because we're definitely going to go over time way way over time if we do that um what's what you get from fhe if you've not uh called that yet is that you're able to um perform uh alphabetic operations on ciphertext and when you decrypt the ciphertext if you've done things right you basically obtain the same result you would have by performing the same operational sequence of operations on Plain texts um so you you once again have like these problems expressed as circuits as we have in snarks and and as we've seen uh in the in the MPC context as well what's interesting with homophoic encryption what is it desirable especially in all kind of uh of fields is that the security assumptions of most schemes are relying on on latest based cryptography so which is believed to be a post Quantum secure uh so you know there's like a lot of conversations about um about about the state of cryptography and like uh quantum computers coming and breaking everything uh at least uh we have like stronger guarantees in the world of uh homophic encryption um we have like uh different types of schemes uh that tend to manipulate different uh different data and the like data um so schemes like focusing on on manipulating uh binary data um like just booleans [Music] um others typically like in the in the machine learning space there's a strong appeal for uh schemes manipulating floating points but also integers they can be combined so again you can come up with like more uh interesting protocols by by doing these kind of things there's two things uh that we need to pay attention to uh when when dealing with horrific encryption um I think Justin hinted at the fact that um there is this notion of depth uh in in the circus three buildings are what's uh what's to be considered really is like what we call the multiplicative depth so what is the maximum number of multiplications we need to go through in order to reach the the output because like in in homophic encryption um in order to protect the ciphertext from being uh from from uh from being like revealed uh basically we adding noise to this ciphertext and uh whenever you put some operations the noise from the two ciphertext that you're adding or multiplying uh combined uh when you perform additions the the combination of these noise is like relatively easy to to to to keep under control but when you perform multiplications the noise grows uh exponentially uh so that's why you want to to make sure that the the multiplicative depth of your circuit uh doesn't go too far otherwise you have to go uh through an operation called bootstrapping uh to reset the noise of your circuit but let's introduces like uh computational extra computational overhead and the second point that we need to pay attention to that is uh often uh not uh not evokes we just like tend to focus on like the the runtime uh there's uh ciphertext tend to be big uh with her whole figure encryption in some schemes uh the ciphertext to plain text ratio is like several orders of magnitude larger uh which is called like ciphertext expansion so it's definitely an area that uh we want to pay attention to uh with fhe in terms of like what's possibility of today uh I've got two uh again examples drawn from the uh privacy preserving ml literature so on the left uh you've got a pure software approach uh that's the as drawn from a company called Zama uh they are building a uh an fhe Library called concrete and they've introduced like a very nice trick uh in in these bootstrapping when they're doing these bootstrapping operation that I was mentioning before they make the most of it by in a way for this thing like look up tables in there that allows them to encode very complex operations and as you can see like by doing so they came up with a scheme where even for relatively large number of operations in your network evaluation they only have a 100x overhead which is you know pretty impressive compared to what we were used to before uh for horrific encryption and on the right uh we've got the hardware version of that which is um a program by DARPA called deprive uh whose goal was to um reduce the overhead of uh config encryption to just 10x so just to single load of magnitude uh as far as I know it's going pretty well I was pretty pleased to see that uh as of yesterday or two days ago a company called Duality was awarded a contract to enter phase two of the uh of the of the D Prime program so that means that at the same time we have uh Innovation on the on the schemes and also Innovation on the hardware side uh which you know makes me pretty confident and like uh make me wants to to to to put to take the same bet as Justin was saying before that uh it's not crazy to think that uh app specific fhe is either within within rich or it will be soon in in a matter of like a few years I think um and again bearing in mind that these workloads uh are probably like way uh larger than that what we'll see in the in the type of application that we've uh discussed today except for maybe uh DCB block building which might be in the same order of magnitude in terms of like how much data it needs to manipulate and how much how many uh operations it needs to go for in order to to get to uh results okay so what's next in uh fhe so as we've seen like uh working on on scheme level optimizations uh either improvements like the lookup tables uh by by Zama or even like brand new schemes that would uh ideally like work on like reducing the size of size text I think uh Hardware acceleration is coming uh you've got this uh deep private program by by DARPA and something pretty interesting that I've seen recently um there's a demo of like a fully homophic chip like imagine like a CPU that is fully homomorphic which could be interesting because like we've had this discussion at Defcon around uh uh sh EVMS uh so maybe like some inspiration to draw from there that reaches like 250 uh megahertz uh which is you know not too bad like for for those that those of us like that was used to Pentium twos and and like these older tpus uh kind of like goes to these kind of performances and I'm sure that I think Simon's in the the attendance and he could probably like add to to this conversation about what can be done in terms of like Hardware acceleration um another thing that's pretty important uh tooling especially compilers uh that you know will make all these drinks uh available to to to to most developers and something we've uh that that is like very often discussed as well in the zika community is uh how do you perform a security audits when these Stacks tend to be more and more complex I think there's a a discussion ongoing discussion on how do you like ZK ATMs and how do we how are we confident that this could work um okay so maybe a final remark uh is that you see this trend of like compilers uh I think it's it's getting pretty obvious that you know it's important to it to improve like the ux for developers but also to make sure we make the most of the hardware and uh what I like is that we see a similar Trend in like different privacy texts so you start to see compilers uh people like working on on compilers and ndsls for ZK uh but also for homographic encryption and in particular you've got like three I think very strong candidates um in in like Microsoft Eva uh concrete from from them that we discussed and a transpiler jointly worked on by Google and Duality uh transforming C plus plus into into HG circuits okay just a final reminder that you know we shouldn't see these Technologies uh as standard components uh if you remember these toys from uh Power Rangers like you know the small ones they were very useless on their own right but if you put them together they make the big robot on the right uh whatever was his name and it's it's it's very much the same thing here if if we consider uh pets uh on their own we're not going to go too far they're just like Primitives they're just like building breaks uh what's interesting is like the protocols that we can build uh to address uh their shortcomings so for example I didn't mention that but uh homophic encryption uh doesn't guarantee that the computation was done the way you intended uh so it's pretty pretty interesting to see how you can combine it with stocks but you know not in a like naive way where you would like plugs snarks maybe on top of fhe or the other way around but maybe you know verifying that the data was encrypted decrypted correctly uh and and like combining that with other tools uh to make sure that you know you've got some kind of like privacy in-depth approach uh to this kind of stuff right um so as a summary um you know please bear in mind that these these Notions are different uh privacy confidentiality verifiability uh and that's it's mostly about uh collaboration it's about like using privacy to Foster collaboration that's pretty much the takeaway of this talk I think um we need to combine these Technologies so yeah that's uh that's the other takeaway I think like collaboration and like uh putting them together to get to very interesting protocols and that that can achieve our uh design goals thank you very much I hope I didn't go too much of a Time thank you Jonathan um yeah at this point only the true enthusiasts remained we've had three hours of content already um one one thing that kind of uh I didn't completely appreciate is you're mentioning sgx kind of had 128 megabytes of memory and then that grew to to hundreds of of gigabytes of RAM and yeah so we lost something um yeah it was Integrity um and that as a consequence meant that we you know we could only really use sgx in the context of uh of trust semi-trusted Cloud providers what do you mean exactly when when you say so the first version of sgx was kind of like um this dislike very nice uh primitive because it was giving you uh confidentiality of the inputs because like of the of the inside guarantees but what you were getting was that by combining uh the remote attestation mechanism that Andrew uh talked about when you when you do a remote attestation what you do is that you guarantee that the The Enclave the program is like in the state you're expecting it to be uh when it when it when it starts uh so you know that you've loaded the right program uh that that you were expecting to run now that doesn't mean that um the the execution of the program is not going to be tampered with by the underlying system because remember in sgx we're not trusting the OS we're not trusting the machine itself we're just trusting like the the the CPU uh and uh and and the and the Intel would have trust so what's what used to be uh the reason why they had this limitation of 128 Megs is that they were using I think a miracle tree uh under the hood to verify that whenever um whenever the memory Pages were encrypted or decrypted in and out of the CPA registers uh they were not they were not modified uh from one use of the of the memory patch to the other so that's what I mean by memory integrity and and with this mechanism what happens is that you start from these known uh initial state that is guaranteed by the remote attestation and because you know that the execution cannot be tampered with the memory cannot be modified by a malicious actor on the system you know that you're going to go through all the way uh and and obtain the reason that you should obtain uh regardless of where the application is running so that kind of like gives you a similar feeling to to what DK proofs gives you uh to what's not gives you uh these verifiability of the computation but now that they've removed uh this memory Integrity feature because the key to unlock like larger enclaves was to remove the metal trees uh which was like taking too much space and maybe like also interesting like coming up ahead um you can't really trust uh what's going on uh on on the machine you don't know that the or at least I've not seen anything yet that says uh and maybe you know Android Tom can can chip in there if you've got more information than I do but at least as far as I know you don't you can't really guarantee that the pages are not modified uh when they're not uh when they're not being processed by the by the CPU so you've lost this memory integrity and by by such you've lost um the verifiable computation feature that's uh the first version of sgx used to have okay understood well maybe that's going to be the first question the spicy sgx Channel all right any other questions for Jonathan okay it looks like we have no more further questions thank you so much Jonathan for this uh thorough overview and next we have this spicy sgx panel um with Andrew uh Jonathan you're still with us and Phil so I guess I'll just go ahead with the the Segway so um I guess the fact that we don't have this this Merkel tree kind of memory Integrity with the new versions of sgx is that kind of a deal breaker almost for Suave whereby uh you know survive is meant to be reasonably decentralized and trustless and now we're saying that the the enclaves might need to be run in Google cloud or what what is going on here I mean even if there's no Integrity checks it's possible to do mitigations from the applications that are using it but that would require being um very careful about it um and it's not really just Integrity because if you could you know uh tamper with the memory while in Enclave program is running you could end up tampering with um you know some access control things that it's doing so it could affect privacy as well as um Integrity in that case too um but I've been a broadly that's something that can be mitigated I mean you're kind of line of defense would be to add your own Integrity you're kind of checking you know from registers that don't get paged out the the kind of related question to this I kind of most was excited to respond to is about like um the kind of difference between uh like the cloud use cases and the client use cases so like the client use cases are clearly being um uh uh deprecated no longer supported but I mean the original or the origin of sgx was like for um like Blu-ray players and digital restrictions management you know anti-user technology I mean so that was the first time when everyone began hating um trusted platform modules Richard stallman would have huge rants about this so like everyone hated trusted Hardware from you know before then because of that really despicable use um so I think good riddance to the client side on you know sgx ones the cloud services though are like really getting a lot of use out of this and really want it so I don't see that going away like Xeon processors are still going to be supporting sgx of some kind they really need the Integrity checks you know too so that's not like a thing that's just not on their radar at all um and I don't think that the I think the real challenge is how the decentralized blockchain applications will be able to like blend in with the cloud use cases and act like good customers and and not do something that gets them on you know cleft out uh from uh the kind of support that the cloud services get yeah I mean I do think in terms of suave like obviously any product change to Intel sgx like affects the the plausible deployments um I will say like Suave does not require perfect privacy or Integrity necessarily the goal of using sgx and Suave is like partially as defense and depth to iterate the status quo um it's not the same as let's say using sgx for consensus or something like that in that like if you do manage to to Break sgx um and perform any of these attacks like you'll be able to kind of get an advantage in Mev which certainly might be profitable for a short term until people notice um but it's not the not really the same as having your secrets kind of permanently leaked to the world or uh uh you know your consensus protocol falling over and losing billions or something like that um I think this is like part of the loss of subtlety in like the sgx world is people love to have like very binary views on sgx like either it's broken or not either it has Integrity or it doesn't either like you can use it or you can't either it's applicable to blockchains or it isn't and to me there's like a lot more subtlety in terms of like what specifically are you using it for and does it kind of stand up to that use case um so a few things is like number one in in terms of blockchains I do think there are still blockchain use cases specifically in stopping a lot of these actors that like you know maybe are a little bit stronger than honest but curious like rational but curious actors uh from kind of uh having as much incentive to get an edge and I think for that it actually could work really well no matter even if the barrier is small even if the iterated game is messy like it's still still could work well and even if that kind of guarantee fails once in a while if like a really kind of sophisticated attack gets pulled off so that's like my general answer for Suave for like all of this um of course as Jonathan said in his talk we aren't like sgx Maxis or anything it's just part of Defense in depth would love to like explore other tees would also love to have fhe and you know although I think you know some some separate spicy panel to be had there on like the gap between kind of where we're at today and where we need to be to like actually in my opinion be usable so maybe I ran to Too Much I guess one more thing Andrew's question about how blockchain slips into the cloud stream like I don't see why we wouldn't be able to do that it seems like a lot of what people are looking at sgx for is like privacy preserving machine learning um and things like that um there seems to be an analog in like this real-time Financial optimization to like Cooperative AI to like privacy preserving AI so you could possibly see all these use cases like converging in some way and also I think the nice thing about and uh Mev specifically is it's like a constant real-time problem so like whereas a machine learning problem like Android key swipes or signal contacts or whatever other machine learning problems you might have you kind of like do it once or like do it a few times or once in a while here you have to be doing it constantly and the more computation you have the more you're doing it so really Intel should love that in my opinion if like their business is to sell Hardware um so maybe that's how we like slip in uh by just kind of making demand for their product real yeah that would be welcome I guess because I I think like one of the pragmatic chat images as well is that you know it's pretty much only Azure uh as of today that that gives you uh the the all the flavors of it that you would like uh so it's not it's not great either for for decentralization to just like take it from the ends of Intel to put it in the hands of yeah you did you did lag a little uh Jonathan I don't know if it was just me but uh I think yeah yeah I I agree with the the sentiment uh um and people are lazy and love clouds but there's nothing stopping you from uh getting an Ikea rack and hosting your own Xeon Processor it's not like they're completely out of range yeah and if you're an Mev Searcher and you want to do a lot of this like local like wide scale optimization it seems reasonable to like in the long term uh you know you're basically an infrastructure provider for crypto uh so having like some server grade Hardware seems reasonable to me um again not to say it's the ideal status quo where obviously we'd have magical encryption but I think maybe this is another spicy take uh like it seems like all the alternatives to sgx introduce other gotchas for blockchains to me so like MPC being the most practical example uh MPC has like scalability issues and like the size of the committee it has like a really high bandwidth requirement and also it's like much more efficient if you have low latency or if you can like co-locate um so all these to me seem to be like equally bad to like sometimes uh breaks if like Intel screws up and or someone spends like a few million for on some like really good phds uh but maybe I'm wrong that's just my spicy tape Robert covered a bunch of those um in his talk some of those challenges with it I mean the um a lot of the most optimized ones um and this is kind of the thing that we found we've been doing this retell project there's a post about it that's like our MP speeds on uniswap kind of a amm and it's an amm because that's the most complicated thing we can basically get to work that's practical with MP speeds like a really simple operation and it was you know a challenge even to do that and you know we wanted some notion of like robustness like availability so that's just what you expect with a you know a blockchain system but that's not the most desirable operating system NPC people tend to prefer the maximum privacy and they'll have very systems that just topple over if any node fails so all of like the really hot interesting uh protocols where they're making the big speed improvements are mostly in the dishonest majority or and out of end sharing setting and then those just aren't applicable if you want something that kind of acts like a blockchain with its uh redundancy and a fault tolerance on the topic of photos I have a question for Phil about survive like presumably there isn't like one Master T that's you know running throughout this uh like some amount of redundancy and in that context um if one of the t's is is compromised and breaks privacy like how do you detect which and we observe front running happening how do we you know narrow down who took account of the the committee of of T operators yeah so this is a great question and the truthful answer is we don't know yet so we have kind of like the Privacy abstraction for Suave and like a few deployment scenarios with trade-offs I don't think we know exactly what we're going to go with so we'll probably have more kind of community conversations about what makes sense there uh you know the trade-off kind of being from like more distribution but like less attribution and like wider attack surface to like more centrality and or layering even like reputation or committees that would in my opinion be bad but you know we'll put it on the table so like these are like the ranges of like options you have on who to run it certainly one Central party is not good so like we might as well just not I mean I guess it adds a little defense and depth to trusting flashbots but we definitely want more than one um and they should be like different economically uh kind of uh separate parties that that provide like competition and diversity uh so that would be like the bare minimum ideally we distribute it so like everyone's phone runs a swap node and like the whole thing is like this chaotic Global process uh same with ethright like the dream is to have that phone validator and like practically you probably land somewhere like in the middle as you like strive for that thing I would imagine okay I understood I really liked with Suave that um you know that Suave has this goal of using um uh you know enclaves for this disintermediation goal like you really want to use it like you'll run this in order to prove to all the people that are using the system that you don't have the ability to you know tamper with it um I I think that's really cool that that's kind of rare in the sgx I think kind of application where like people seem to be really satisfied with just getting their own data results back and not trying to um you know prove that they don't have these uh uh centralized controls left so um uh it's just really cool to know that that makes me think that the sgx based like blockchains and you have that as a common goal and maybe you know some progress can get done I think no one's really done this kind of end-to-end job of looking at the entire like chain of validation um you can't just say there is remote attestation you have to have some process by which people in your community are actually looking at the remote attestations uh for the sake of a spicy take care right the the same issue is like with um arbitrum and other l2s like they're built around a very complicated um you know audit protocol that handles the edge cases when something goes wrong and you need to process a fraud proof but it's hard to go find like visible you know examples of that and follow that process and see it working that's something that's not unique to the sgx space but that you know everyone should probably do a better job of you know validating their their source code and Publishing their transparency information where it's usable but it's especially needed for this use of um of sgx and maybe you'll solve these problems if you need them for Suave and everyone else can use them too I have a have a fun even spicier take which is which is a little bit of a troll take which is that like luckily we have no on-chain privacy in ethereum so you can also use like funds flow to do a lot of your you know statistical analysis and stuff like that like that's how you back out centralized exchange is cheating so like you would have these same Tools in Mev land like if you were getting bad execution uh you know you could see like who sandwiched you on a chain or like you know who was accessing perhaps in some cases it may be non-attributable and then like you're really screwed but uh I don't know um in many cases you may be able to to kind of divine misbehavior um so my next question is around latency and I have a personal story to share so um we recently launched the ultrasound relay uh which is this kind of non-censoring relay and uh they're actually another non-censoring relay which was launched at the exact same time the agnostic relay and we basically have the same setup we're running you know the the the flashbots uh code base and it turns out that for some reason that we're still investigating we're simulating blocks to roughly 200 milliseconds slower than agnostic and these 200 milliseconds mean that we have a roughly uh a 2X penalty over agnostic so we're including on chain we're winning the the auction like half the time that we should be um and so my question is you know if if latency is just so important for ibv like how can sgx win because presumably there's some amount of performance overhead like maybe you can't do all the fancy overclocking and you can't get the the latest and greatest CPUs and whatnot um yeah I'm curious how how do you reconcile latency with sgx yeah that's a that's a great question well first of all I'm very glad to have you in the relay game uh uh so that's like amazing thank you for running a relay and I also think like part of the challenge in the future is like co-designing the protocol parameters so you can do things that like have somewhat of a latency penalty if they're like considered qualitatively better and like maybe because of the way like the the timing is structured in the protocol or something there's like somewhat less of an impact obviously there will always be some Edge to having higher latency that's like not something we can just like magic wand away completely um but yeah so I would say like number one we should minimize the uh the the latency impact number two we can lean on uh ways in which the decentralized tech is stronger to compensate for latency so if you have uh if you have this like uh um privacy kind of edge that allows you to optimize transactions better for users and like you can attract more economic activity if you have ability to optimize as cross-domain Etc in a decentralized way where people actually trust you to like do this optimization then maybe like the latency penalty exists but like it's overcome by these other factors so like really look at like what is the strengths of the decentralized thing and can we like amplify those in enough of an edge to mitigate the latency penalty because the more decentralized you get also the more latency penalty so sgx actually doesn't have that bad of a latency penalty especially if you provide Witnesses you're basically just executing the evm with like you know not that not really you can provide State Witnesses so you don't even need to do any memory swaps in like some cases um and uh that can have like fairly low overhead like you said you do lose overclocking and some other Edge enhancements um I think that's within reason like there's already a lot of overhead in the building simulation process to kind of get this decentralization and get this merging of many different Searchers from around the world with different edges into the most valuable block so like we're already kind of used to paying this latency for Network effects penalty and I think sgx specifically is okay um I do worry like as we push it more towards fhe or something like that and or even if we want to do like we have some magic new NPC protocol with fairness that works like and the latency penalty becomes bigger we would still probably want to switch to that as a community and how do we make sure that those systems stay competitive I think that's like an L1 design question also yeah I think I think there's two there's two htc as well like um if ever everyone has to pay the same for killing that uh creating like a an edge to to some of the users so I think the most important thing is to make sure that you know if there is such a penalty everyone should be in the same in the same setting um and in the esgx case uh to to answer your question things to be somehow uh is you know again as long as everyone uh as long as everyone is in is like in the same setting I think it's it's not such uh of a of an issue uh yeah Jonathan your audio was a little a little shaky but uh I guess I'm saying like my connection is like really bad no worries um but I guess yeah I guess what you're saying is that if everyone's paying this penalty then everyone's uh kind of equal uh but I guess what might what might happen is that we'll see maybe a a centralized private mempool and then Suave and then someone will do profit switching between the two and then the centralized one will just always win um because it has not only maybe a lower latency penalty on sgx but also it doesn't have to deal with the peer-to-peer gossip channel the blah blah is like straight you know end-to-end TCP connection from from one point to another um but yeah it will be as you said Phil you know there's a trade-off space and uh hopefully the the the forces lean towards decentralization I hope so side note little known fact this is like one of the reasons we run a centralized Builder so that like a we're forced to compete with ourselves and be that like if we do uh release something decentralized and we like shut it down it's kind of like a statement to the community on what we think uh the protocol should look like even if there is like a slight dip in profitability for a while um so that's that's like one of the reasons so I guess my next question is around memes um sgx has this this bad reputation which might be warranted or it might not be but it's kind of there like isn't isn't that a a Tailwind for for adoption um by by Edwin sorry headwind thank you curious to hear Andrew's take on this in the knowledge yeah it is a headwind um it's it's weird I mean even in like the research publication it's a lot harder to get like a peer review paper accepted on sgx because there was a glut of papers that were really boring and just said here's existing paper we just forced it to run within sgx and didn't have so much else to say so there's even just a uh uh uh you know a headwind towards um you know getting past that I don't know I mean it's it just seems weird to me like clearly it seems to me that there's more gut reaction like overvaluing the uh concerns about it that it's it's far swung the other way I hope it swings even more like I don't know if we're at the bottom of sgx negative sentiment maybe we can go even further and uh catch the drop on the on the way up I mean it must be the I mean my experience is that there's still just a ton of low-hanging fruit of critical stuff to look at so I get the sense that like very few people are looking at this I mean the ones who are get kind of diverted and turned off so quickly that they don't even get to the good bit so um you all are here and I'm glad to see that you're all are uh uh working on it that way so hopefully we can um uh improve that all around yeah it's absolutely like a negative a sentiment but it's an opportunity too yeah I totally agree with that and also uh Alex's points in the chat um I think the first crop of sgx companies were very much like ooh shiny new tech toy like let's just like plaster this on to like every single problem Under the Sun and like try to raise money from our VCS uh which is like a common pattern in Tech it's like okay iPhone comes out with a new notification type like what old ux patterns can we just like plaster this onto and have like a new you know fad basically it's like the same idea and I also think that turned a lot of people off plus obviously there are some fundamental issues it's the same thing as with crypto right like there's a lot of people that think crypto is a scam and like f all this like it's just like all rug pulls and like the tokens are not legit they're all Securities whatever other argument you might hear they're all kind of true to an extent right like all the arguments they wouldn't be memes if they weren't at least a little true the same way all the bad sgx takes and like all those memes they are a little true but like they both things I think lack nuance and so I'm glad yeah that we're having this conversation and that there are people working on it because I think the next generation of companies is not like the shiny thing companies it's like uh we we have an actual need and like we've gone down many paths and there's really no choice for this like weird crypto intersection that's like still better than like something that's fully trusted um and I think in that Niche like there's actually a lot of practical gains to be made um again like as a company like that is that we're being very practical about this we're not like we are an sgx company this is our long-term goal is to like sgx size the world it's just like there's not really a choice and like yes there's a major headwind that's also an opportunity because it means like everyone else has the same headwind and if you're truly convinced that it's the right thing to do and you're correct and you pay the headwind then like that is what an opportunity is also so I think it's both um yeah very excited about it I had a lot of fun talking with a bunch of people that I met you know when doing this kind of uh unsolicited of secret Network so I mean it was neat to talk to the obscura folks a bunch of projects are using enclaves that don't consider themselves smart contracts but middleware of some kind so fala is one of them and it's a little confusing because even though they they're a middleware they still are evm compatible that didn't make sense to me until uh Suave is like that it's not to be a competing blockchain but it is evm man running in enclaves for something else so they're doing something um and the guy from automata uh network automata is another middleware one but they aren't um I don't think they have open source code but maybe could be talked into it so um yeah maybe invite all of them to another roast it's probably the best way to go against the headwind is to keep on doing like anything in the open uh transparent events uh making sure position is well known and like being the first critics of our own design choices I think your audio is amazing now by the way Jonathan so whatever you did work so I guess my next question is just trying to assume the the worst case as Andrew put it which is that this uh you know what what if there's a vulnerability that makes all the attestation keys you know leak um so that there's just no security uh guarantees anymore from sgx what would be the plan for us to have is it that you you fall back to the to the current model I guess and does it mean that uh yeah I mean I go ahead sorry uh so yeah I think I think I think there's like a few options that are like really practical from today uh you kind of summarize them there's like decentralized that's what we have with flashbots and flashbots protect now then there's committee based uh you could call this like the chain link ish trust assumption something like that you can layer on some staking and call it decentralized also you can possibly reuse the each validator set these are all like ideas in that camp and build some sort of committee uh where you have like some protocol that Aggregates like multiple semi-trusted kind of inputs into like an oracle um you could also do privacy that way certainly um either trusting the kind of ore of like all the people you choose to trust and like optimizing their intersection that's very easy or you can use NPC to like trust the end uh I don't know if I reverse those or not I think it's right um so those are like kind of the levels and so yeah we'll have to probably kind of go to one of those options so probably ultimately the system will be like you know some will be configured to allow you to fall back to this if like uh sgx is broken it would be sad though I'm very bearish on committees and this is why I think sgx is the only choice um just for the reason that in Mev given that the the brakes aren't falsifiable and the incentives are so high and there's a kind of positive incentive Boost from being on this committee if you're also a Searcher or a builder that to me makes me very bearish on like those trust assumptions actually holding especially under like stress so that's why we we think sgx can maybe like patch over that like paper mache over that a little bit and so I would be sad if we had to like fall back to that I guess I think that there's a very interesting assumption uh in in what you've been saying feel is that were you able to identify this new vulnerability vulnerability and act uh accordingly uh and I think that that's what happened up until now in in sux right it's mostly been uh academic or white hat hackers that like like endless Piper that went through the process of like disclosing the vulnerability to Intel so that they could act uh accordingly even though uh we can we can debate like the update process afterwards um what's what's maybe more interesting and I'm not saying I've gone answer to that is that if the stake became so large that some people do not have the incentive anymore to to go through this process and but but on the other hand to try and exploit these new vulnerabilities that they've discovered then we could be in troubles because then you you have like this asymmetry again between users that that exploit and uses that pay the penalty uh basically so and I think again like to lean back to your to your paper um it's kind of like interesting to see uh and try to to Coast uh how much it would it would be to to mount uh such attacks I think that that would be a very interesting line of research to try and estimate the cost of like you know breaking these and these aspect of uh of the technology yeah I've always said that that's what's like a few years ago that that's like what's missing from this whole sgx conversation like we don't understand the economics of all exploits like it really depends on like the marginal cost to break additional chips like whether sgx can be secure at all like is that zero for all exploits or no I don't know maybe you know if anyone's done research in this uh Andrew or Jonathan but I'm not at least aware of any it's not really my area but I'm a fanboy of all the uh uh people that do this vulnerability research uh at that level have you seen this on uh uh YouTube from Linus Tech tips Tech tips on the like a tour of the Intel uh debug lab debug lab is like the spookiest phrase in the context of um sgx because what debug lab means is they have a big laser thing that'll burn off the top of a production chip it turns a production Intel processor into an fpga they can rewire the logic of the chip by beaming it with powerful lasers in their debug lab and they gave this little tour of it to a famous YouTuber and um you just it's nice to put like a a picture of it to the uh to the myth you know the uh it must exist myth but you know that's what it looks like that doesn't answer the economics question I don't I've heard people say things like a hundred thousand dollars is what it would cost to get access to that or like the one place in University of Florida that can do it or something like that so I don't know the details um should definitely we should be trying to find those because that would fit into this kind of analysis yeah I will say like our one leverage Point here is like a lot of this can be punted to Intel so like they have PR skin in the game uh not that we should and we shouldn't answer these questions but they also have skin in the game and like if someone does build a secret sdx lab to break Mev and they succeed Intel's PR is on the line as well um so presumably you know I think the relationship between the crypto Community including uh y'all and the blockchains that are doing this I think should try to present like a United uh uh lobbying block to Intel so I mean one of the lessons in the sgx.fail paper um which like Daniel and Christina and others have been kind of tracing down this for you know a much longer time it's a much broader Point than just the the blockchain setting but um no one understands TCB recovery that well none of the you know relationships and things that you do afterwards what it takes to get early notification or not are so clear um so I I don't know my guess is that it's possible to do a better our job negotiating and informing this relationship with Intel you know by acting as a cohesive Community rather than just a one-off startup project one of the things that struck me you know when you guys gave answers is that you didn't mention AMD SUV as a potential replacement for sgx if sgx is completely broken does it mean that SUV is maybe not appropriate for for Suave model well first of all I think that the TCB is much larger so that's like regardless I like that the properties of the of the hardware itself the question is like whether you want to trust a relatively small application Enclave size or whether you want to trust the whole virtual machine that there's absolutely no loopholes that could be exploited in there um and I guess that that also maybe we should not address all of these Technologies under the same name I'm kind of like I'm not very happy about you know anything falling under the t uh name I think a lot of these texts are now becoming just like confidential virtual machines and we should we should clearly make the distinction between between them two it's it's not it doesn't mean that it's bad fundamentally but it's like we should not expect the same uh behavior and like security properties from from two different like Technologies basically yeah I would say like that being said like it could iterate into something useful like if they see a market demand and you know I don't I'm not like fully bearish on AMD or any other tees like it would be great to have more diversity if we had multiple solutions that work for the threat model maybe we could come up with a protocol that like you need to break both to get anywhere uh and that would be nice um certainly I think like in the same vein as like the the Asic for any delay encryption function that uh EF may do like maybe one day the EF or other crypto companies together build a tee that's like open source um if this actually does end up becoming critical infrastructure that we can't replace and the other avenues don't pan out so these are all like yes they're all kind of like on the the research radar but I think as Jonathan said like today uh less attractive for various reasons although we have talked to some people recently who are bullish on on uh AMD kind of eventually being enough for this use case you could also maybe even jury rig like the iPhone Tes plus like Apple's authenticity check if you do like a Network that has like enough attestations for your Economic Security maybe you could get security out of that I don't know um but yeah uh things to think about but I think less immediately obviously applicable than sgx guys thank you so much for your time I think we're over an hour and 10 minutes over so it may be time to wrap up thank you all yeah thank you thank you Justin thanks everyone that was great spicy moderation and yeah thanks everyone that was really great thank you Justin to our tireless Road semester that was awesome thanks Sarah for organizing thank you both see everyone later see you guys bye bye 