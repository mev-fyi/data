hi everyone welcome to Unchained your no-hype resource for all things crypto I'm your host Lori Shen Twitter fights medium post scammers fissures and promotional content want to get through all the noise and crypto sign up for my weekly newsletter at Unchained podcast calm to get a quick and easy summary of the top news stories every week the stellar network connects your business to the global financial infrastructure whether you're looking to power a payment application or issue digital assets like stable coins are digital dollars stellar is easy to learn and fast to implement start your journey today at stellar org slash Unchained crackin is the best exchange in the world for buying and selling digital assets it has the tightest security deep liquidity and a great fee structure with no minimum or hidden fees whether you're looking for a simple Fiat on-ramp or futures trading Kraken is the place for you in response to the challenging times crypto comm is waiving the 3.5% credit card fee for all crypto purchases for the next three months download the crypto calm app today today's topic is security in dphi here to discuss our Dan Guido co-founder and CEO of trail of Fitz and Taylor Monaghan founder and CEO of my crypto welcome Dan and Taylor hey there happy to be here yeah super excited to talk about this before we dive into the meat of today's discussion can you each describe what you do in crypto and how you came to be involved in D Phi and/or security why don't we use start with Dan sure so trail bits is a software security research and development firm we were founded eight years ago about myself and two other expert hackers in order to improve the foundation that we all build on so I used to do just plain old code reviews for folks for many years but in trail of bits we try to actually engineer software and build new solutions that others can use to kind of lift all boats so we do a lot of work with DARPA and the DoD to build really advanced tools and advanced fundamental research companies fire us to build high assurance software for them on their behalf and then we also do really detailed product security reviews and training that help engineering teams build more secure software in the etherium space this was actually out of personal interest rather out of blockchain this is out of personal interest we had a couple folks on the team that were as excited about the technology as folks or working in the field and we saw this tremendous Greenfield opportunity to come in and build the kinds of tools and techniques that other fields really ought to have adopted at their first steps but did not and that's what we did so so you know now in 2020 we have this massive suite of tools that people can use to build secure code and a vast amount of public knowledge that we've been able to communicate to folks that helps them build build secure code and that's what we continue to do to till today and tailor what about you I have a very different background you know I started out just because I was you know I was in crypto then I I accidentally as I say you know built this wallet that became immensely popular and my security knowledge and the obsession I have towards everything that could possibly go wrong has sort of evolved over time and as as I've watched things go wrong again and again and again and so my crypto is a wallet previously I built my ether wallet and you know both of these products have really they're really interesting attack vectors but also you know they're there's a lot of unexpected things that happened as I was growing these products and so today really I'm just quite obsessed with how things go wrong how we can prevent things from going wrong what steps we need to take to improve on both like the user side on the general community side and then obviously the technical side is is a huge part of it as well yeah so over the last several months defy has seen a number of security issues and it's funny because when you look at the discussions around all these attacks they're just so new that usually people are even arguing about what to call them and I think you know obviously we can safely say that most of them are attacks or bugs they're generally just ways in which the behavior of the protocol diverges from the intention of the creators and so let's start up by talking about one of the most recent one of these security flaws which was on a chick Dan you were actually involved in this one so it let's actually have Taylor describe what happened first from an outside observer perspective and then you can jump in afterwards so Taylor yeah so headshake you know the way it came on my radar was I was scrolling through Twitter as I often do and stumbled upon this tweet by then I didn't actually follow them so it was retweeted by someone you know that said there's there's been a typo you need to take this action you know warning warning warning and then a couple other tweets and then obviously you know a whole bunch of replies to that original tweet with people kind of questioning how this happened why it happened you know what exactly is going on etc and as I dived deeper into everything about this tweet and discussion I realized that there were some really overarching problems with just everything about it so the first being that they initially called it a typo which it obviously but well it may be factually correct is not it's just it's painful to watch people try to downplay issues like this and that was that was pretty frustrating right off the bat that put me in a bad mood yeah and just to clarify and maybe I'm wrong but but like essentially this quote/unquote typo is that like you know if people kept their money and that their the money would be frozen not like stolen but frozen right and so this is back in it thing I'm already in a bad mood like I'm like ten characters in I'm in a bad mood and then they like tried to clarify but they ended up saying it's not a security issue it just it just ends up that everyone's funds are locked and now I was very involved in the parody the parody multi-sig situation which was I guess two years two and a half years ago now in which all the funds were locked and it was a huge thing and so they're just kind of like juxtapose those two experiences and then have someone be like oh that's it's not a security issue I just found a preposterous and I would say you know it went downhill from there yeah yeah it was a lot of people were tweeting about how you know they should call it a bug not a typo and spelling out like could happen to people's funds that they didn't remove them so dan can you now explain how the trail of bits was involved in the headshake incident sure so in line with my introduction we try to remain as open as we can and work with everyone that wants help in the etherium in the blockchain community there are folks that are at the beginning of their journey building a product and there are folks that are you know partway through or at the end right before they're about to deploy something and there's always some guidance that we can provide so I try to keep my door open when people show up and they say I have written something and I need your help to secure it and that's what the folks behind Hedrick did they showed up they said look this is a small project we don't have a lot of money we'd like you to take a look at it what can you do for us and over the course of three days we found a large number of issues in a project that was at a very immature state of development and we described those issues to them and said here are the things that you need to do to improve the security this app now they took that and we you know it could be difficult sometimes like there's there's all these competing interests in the blockchain community around how you describe to your users that you are doing the diligence required to build something that others can rely on and sometimes that gets boiled down to a tweed sized byte of information that hey we work with trailer bits or we worked with XYZ firm whether it's you know house or somebody else and there are ways to do that that is like nuanced and correct and there are ways to do that to transfer risk away to a third party because a lot of firms that build software and we don't make any choices about how they built the software they choose what development methodology I'd like to use what build tools they'd like to use how adequately they'd like to test it the architecture of it and we just come in and we try to do our best to make sure that it gets better after we leave so instead in this case we provide those recommendations of hey here's how you should talk about your security process and they didn't do that they said look our code is all safe because trail of its used it and we're launching it today now we put out a summary document that said hey here's what the project of the hedge it looked like we did three days of work for them which is a very small amount of work and we found a large number of issues only two weeks ago so from my perspective this is a page and a half document that includes a page and a half with fairly negative information about the maturity of the product but most other people didn't read it that way most other people looked at well trilobites found some bugs had you fix the bugs therefore the code is safe which is really not the right takeaway and there's some you know things that I can do to improve that but there's a lot about the community where the way that they are invest the way that they are investigating what financial opportunities to provide their money to is kind of not producing the results they want so there's there's a larger discussion here of like what are the factors that I should use to trust a given project and how can I interpret the information that's been provided to me about the safety or the viability of a given dphi project but what is your question well I wanted to ask about something that you mentioned at the very beginning when you said you know you will work with a project of any stage because like so based on the screenshots of the emails that the anonymous developer Molly Wintermute sent to you this person wrote the letter Z for the word the and the numeral two for the preposition to and like just I mean me obviously you know I'm a journalist so the way with grammar and spelling and all this punk punctuation all those things are very important to me but you know just looking at that like that looked like a red flag even before like receiving the code you know it's like literally just the query itself to me and you know not I'm not like trying to be judgmental of like anybody who makes a grammatical mistake but this is this is like a totally different thing it's like somebody purposely you know not only thing really really weird it's really but my question is like so why not with someone like that all right because for me it would be like oh like you know this business relationship may may not turn out super well like that is what I would think if somebody sent me a message like that that's totally correct and my thinking behind that is there are a lot of strange folks in the blockchain community we've worked with somebody named Bharata Bharata before who ended up being an extraordinarily talented software engineer that helped to provide input to build to enhance the quality of a product that we've created called critic we worked with a pseudo anonymous personality over at make her down named rain he would show up on video calls as a black silhouette and never went by anything other than those works so sometimes in this community because of the privacy and kind of like very like you know crypto Punk a cyberpunk kind of approach people want to remain pseudo anonymous they don't want other people to know exactly who they are and they kind of approach their work in a in this way so that alone like well yes it's really weird it's really strange I didn't want to slam my door on working with this person because they were in in my view purposefully trying to obfuscate their identity which is a thing we've seen that language like you I don't think anybody actually types that way what they probably did is they have some kind of script that they process all their their texts through in order to create something that's more difficult to fingerprint you know you've seen this a lot back in the back in the old days when they like hacker crews and everybody went by all kinds of different handles and you try to obfuscate any of the publications that you made by processing it with some kind of you know script to eliminate the writing style that you have so that people couldn't figure out who you are there's all these techniques that come from like sty llama tree and trying to figure out who Shakespeare was and whether he's like this guy or that guy based on their published body of work you could apply that for engineering you can apply that to text files that people read on the internet and it's something that I have seen before of people trying to just avoid discussion of precisely who they are okay but I don't know like I don't know if I totally think that obfuscating someone's writing style is the same thing as switching out the letter Z for the word though but but anyway like I don't I don't want to get too far down that what taylor-wood what did you want to say so yeah there I was okay so when I first saw her I guess writing style I was I was taken aback by it and had the same sort of feelings as you and yeah I think that there's a couple different things going on one is that yeah the crypto space is just weird and so when you see something like this it's not as weird as if you're into a normal corporate environment and you get an email like this and the other is that the cyberpunk mentality and the value that these sort of cypherpunks can provide makes it so that you know sometimes we will give people the benefit of the doubt when they don't necessarily deserve it and would never get it in another you know sort of industry or situation and I think that's definitely what happened here and and Dan is not the only one who has brought up this off you see Asian you know this on purpose off you see Asian and one thing that lends itself to that theory is that hedges has a lot of writing out there that is not written like this the head Jack Twitter account does not write like this the white papers not written like this the websites not written like this and so I'm not I'm not exactly sure why this personality Molly everytime she writes there's there's the Z's and the twos um when she's obviously capable of writing in you know a normal or what society deems as normal you know it's it's yeah welcome to crypto that's all I'll say on that and those are things that we looked at too you know I've heard obviously we've been approached by people that are building pyramid schemes and it's really easy to figure out when somebody is fraudulently trying to manipulate users in that way but from the kinds of things that hedge it was talking about from the kinds of things that were documented in the white paper you know there were there were friends of mine that were following their Twitter account already so they kind of had at least some items here that meant that hey maybe this is something that ends up becoming important in the dphi space and maybe I should look at them despite this weird interaction that I'm having but you know okay well one other thing actually that I did also want to ask about was so Taylor did such a great tweet storm dissecting the audit summary where she basically says okay you know all this is written in a very professional way but here's what they're really saying and you know and it correct me if I'm wrong or correct me for me or Taylor if this was wrong but she was like oh you know trailer that's is saying like they didn't even do basic arithmetic correctly they didn't even do the basic thing of having documents so I just wondered like you know around things like documents like would it ever make sense for an auditing company to state that like potential clients need to meet certain requirements before they can have an audit I think there's never a point where it's too early to engage with the security professional like that just kind of brings up this question again of are there people that I should tell to go away from my from my queue of folks that are asking for help and I don't think that's the right answer however there are a couple things here so first off like the fact that we found like yes we found all these critical issues in basic arithmetic we found lots of like we found 10 issues that essentially could have stolen everybody's money two weeks before this project was going to deploy they fixed only those specific issues and they didn't address any of the root causes of any of them right you can see that in a public github repository and you can square that up with what we said in the in the summary report that there was no substantial foundational improvements made to that code beyond patching individual lines of code so that's something that you need to understand about these security reviews is that they're usually focused on hey we spent X amount of time looking at the code and we found Y issues if you found a lot of issues in a small period of time it doesn't mean security improved dramatically it means that the code is probably filled with bugs like big number is bad and I think most the community thinks the big number is good yeah and that's I think that there's like a couple really important things that that this is brought to light and one of them is the way that I read audits and I look at teams is very different than a lot of other people look at them I guess and the way that I look at them is what does not what does this audit say about the code but what does this audit say about the team or they're there how they're approaching the code or how they're approaching dphi and so when I was reading this you know the the review I was like this indicates to me that they're not really taking much seriously you know they went into this audit pretty unprepared there were some pretty basic things that you know they could have fixed before sending it to audit etc people on the technical side kind of tend to miss how human all of this is and people that don't have any technical experience don't realize that they can read these audits and apply sort of like the softer skills or the the culture takeaway is even if they don't understand the literal technical underlying stuff and that's one of the I think the biggest missing pieces it's like you have to have both sides like you have to fix the bugs but you'll also have to you know try to understand why they even got in the situation in the first place you know why is this code being given you know basically handed to Dan in trilobites with a chunk of money being like okay we're ready to go live except we want you know a third set of eyes on this and if you if you send it over in that state that alone to me is a red flag because you know in theory you thought it was as good as it could be so push back on that a little bit like I don't know what they're planning to do when they're sending me the code a lot of people like I would have thought that a reasonable thing to do with this code was after review from us put it on a test net and play around with it for a little bit that this is a step in their development methodology where there are many more steps they have to take until they release it's a main net but instead what they did is they shrunk all that down and they said okay it's ready to go like ship now now is when we're gonna do this because I think this would have been great if they just said like okay great we've got some feedback about the maturity of our development we've gotten consultation from experts they said that the code is not great and that they listed out all these things we should do let's show it to users get it some testing and continue to work on it and that would have been the perfect use of an engagement with us but that's not what they did well we I guess like maybe I just have a misconception around what role and audit should play and defy secure like any kind of security but you know if I sort of compare it to the way like a magazine article gets published or something like I would imagine that the audit would be one of the last steps where you would get the most bang for your buck if you put forth the best effort you can get it as ready as you can like as close to perfect as close to launch as you can and then at that point have somebody come in from the outside please don't do that do not do that I'll just point out before I let Dan finish because he's gonna say he's gonna be right but I just want to preface this by saying that the ideal way to engage with security experts is not how anyone's doing it right now and not said Dan's going to tell you how it should be done yeah sure so um a couple of things here before we get too far away from the point I do want to say that what Taylor brought up about the context around the code and kind of the organizational behaviors and their their own maturity at dealing with security stuff is a really important thing for users to understand that I don't think shows up in many of these like security reviews these PDFs that come from vendors like mine we try to do a good job at that we always list out long term recommendations that address the root cause of above being introduced not too many other security vendors do that and we do right so like we're good in that respect but I think we could do much better so some of the things that we've discussed internally since this hedging kind of blew up is ways that we can provide literally a color-coded graph around the maturity level of various controls of projects and the dphi space and the blockchain space this kind of like takes a lot of inspiration from the way that we do threat models for companies which is a different kind of service that to get back to your original question now how should people engage with a security company is they should understand a little bit more from a strategic level where their risks are and one of the ways that people do that is they use things like threat models so threat models are a technique to understand what data you currently collect and manage and process the sensitivity of it the components that do the processing and the requirements of those components to properly protect it if you have an understanding of that stuff early in your development cycle and you've got a set of guardrails that make it much harder for you to get into situations where you inherit way too much risk more risk than you're capable of mitigating you know examples are like if you engage with a security professional early there might be ways that we can discuss with you your goals and then within the context of those goals help you avoid manipulating low level solidity calls in order to achieve them because manipulating low level solidity exposes you to a vast amount of risk that maybe you can avoid and then there are hundreds of bugs that will just never enter into the code based all if you wait until the end and you've gone out on this limb and you've built all this code and that's the first time that you're exposed to a security engineer there might be a lot of cases where the codes been engineered in a way that is fundamentally unsafe and requires Ryoka textured so there's no way that I can secure a code base attached at that point all I can do is point out all the things for pad so basically there should be like multiple engagements that's not what you're saying yeah well and so there's they're sort of like so what Dan's talking about it you know when we when we get into the solidity side it can get really technical but a perfect example of this is like when I was first when we were first putting the other the first version of might if their wallet and like sending it out into the world we had assumptions you know we wanted to make this tool whatever we weren't really thinking that it was going to blow up etcetera etcetera but even down the line we never engaged with like you know someone who did this for a living who really really understand security you know fast forward to 2017 all of these things came out of the blue and just like hit us upside the face right like the phishing attacks the malicious browser extensions on and on and on all of these attacks if we had talked to a security professional at any point before that point they would have said flat out no exceptions don't put private keys in the browser it's unsafe the browser is unsafe there's all these different ways that people will attack you that you can't control bgp the underpinnings of the internet like all of this is insecure and instead because we didn't for various reasons we basically built an unsecure product that by the point we've realized how insecure it was it was really it's really hard to take steps back and move away from it and I think that's a bit of a more accessible example but the same exact thing applies to defy products to you know smart contracts to pretty much everything you know you don't want to get too deep into it before you realize that you know you're gonna have to change the entire nature of your product or your system to to ever be secure and one other thing I wouldn't ask about because this was also a point of dispute but basically it looked a little bit like Molly Wintermute wanted maybe like a week-long review and then you guys were saying oh if 3-day review should be sufficient so like what amount of time would you recommend teams seek for an audit or or or like I guess there's multiple audits so maybe you know at different points in their project yeah so I think part of the issue here is that we keep used to work on it as if it's this fundamental like scientific process where we can eliminate all the bugs from the code and Taylor and I are both of the opinion that instead this is like a divining rod that lets us figure out where hot spots are and whether there's an underlying issue that needs to get remediated or it needs to get we are ketaki or needs to get fixed somehow so in the span of three days yes we got good coverage on the code and what we found was that the code was bad that was a sufficient amount of time for us to understand the current state of the project so in those three days we found 10 critical bugs that allowed us to steal everyone's money and manipulate all the things that you thought you could depend on that is not a great result and we only needed three days to get there so the extra two days for a full week wouldn't have told us anything different it would have been a waste of money in fact so they already had now a list of things to do really what a what a security vendor like ourselves is trying to provide to people there's a backlog of activities and investments in security that you need to make so we build up that backlog there are now a half dozen or a dozen different things for you to do and we want to try to provide the most information guidance to you in the least amount of time which is why I'm not going to oversell somebody on a project when I know that I can provide the results they need within a smaller time period sounds like you're saying yeah that they were looking to you to fix all their problems or to kind of like yeah it's just where is like you're saying that really that responsibility lies with them and that yeah you can point out though you know the ways in which maybe their process or their culture around the way they're billing this you know is going to lead them into trouble but you can to be the ones responsible for the security of their project I mean they've been working on this for weeks months years there are many people on the team and just by the virtue that I looked at the code for three days doesn't mean I'm altom utley responsible for the security of their entire company and product that's that's just the bottom line there's a lot of other questions that you could ask too like there's things that are outside the actual code that determine the security of the product that I'm sure you know Taylor knows about just as well things like the owner privileges in a defined space people are obsessed with that decentralized is the application things like the Oracles that are providing feeds of information that the defy application might make decisions on how many of them are there and can I manipulate them things like upgradability there there might be changes to the code that get made after a review is done they're happy things about mongering like do you even know when things have gone wrong in the future and those could be things that firms asked me to help them with like I can help you build a process around security monitoring so that instead of the public finding out that you've been hacked you find out that you've been hacked first and can take some kind of remediation maybe immediately issue a contract migration that saves some portion of your users data or money but like there are many things that can go wrong and it's really on the owner of the d-5 projects to fully understand what those things are and they can use our help when they ask for it and I'll provide them the best guidance I can all the best practices all the new solutions and we'll bring in all the expertise we can to accelerate them but ultimately it is their responsibility to build a secure product yeah yeah this is actually a perfect moment to take a break because you basically listed a whole bunch of things that I'm gonna ask you about in the second half of the episode so here we'll get a quick word from the sponsors who make this show possible in response to the challenging times crypto comm is introducing three measures to help the community first the 3.5% credit card fee for all crypto purchases will be waived for the next three months second you could get up to 10% back by using the MCO Visa card on food delivery and grocery shopping at merchants like uber eats McDonald's Domino's Pizza Walmart and more don't have a card yet buy gift cards on the crypto dot-com app from merchants like Whole Foods Safeway Burger King Chipotle Papa John's Domino's and more and get 20% back on food and 10% back on groceries this is a global offer so check out which merchants are available in your country download the crypto comm app today today's episode is brought to you by Kraken Kraken is the best exchange in the world for buying and selling digital assets with all the recent exchange hacks and other troubles you want to trade on an exchange you can trust Krakens focus on security is utterly amazing their liquidity is deep and their fee structure is great with no minimum or hidden fees they even reward you for trading so you can make more trades for less if you're a beginner you will find an easy on-ramp from five fiat currencies and if you're an advanced trader you'll love their 5x margin and Futures Trading to learn more please go to Kraken calm that's KRA ke n calm the stellar network connects people to global currencies and assets stellar lets you make near-instant payments in any currency with anyone anywhere it's an open blockchain network that access payment rails for applications and institutions around the world and designed so that existing financial systems can work together on a single platform transactions powered by stellar are low cost transparent and fast saving both businesses and end-users the time and money associated with traditional payment networks with stellar your business can issue digital dollars or exchange existing fiat currencies without the need for complicated smart contracts or new programming languages its robust documentation tool kits and multi-language support let you quickly integrate stellar into your products and services learn more about stellar and start building today at stellar org slash Unchained back to my conversation with Tan Guido and Taylor Monahan so let's actually just now turn to another recent pair of attacks these involving imb TC on Eunice WAP and then also on the D force protocols lend of me platform hopefully the audience here caught my unconformity Qureshi on this since on these incidents because it was actually really really fun chatting with him and definitely it's a crazy story so you should check that out but essentially this that both of these attacks were caused by this ERC 777 token which is sort of like a more kind of upgraded or advanced version that has basically just other kinds of functionality that that ERC 20 tokens don't have however if an ER c77 token is used in an older smart contract that does not recognize that then an attacker can perpetrate a reentrant C attack using that token so I was wondering how you guys thought about situations like this like wait how do you think D Phi should handle situations where the technology advances but then opens up new attacks so that's it's like this is actually the thing that scares me the most about smart contracts in general like I have no doubt that at some point we will get to the point where we can write secure solidity or whatever language is gonna be I have no doubt that we can get you know the community on board with like understanding what makes a secure team etc etc but when you think about the fact that there are there are all of these systems right like there's the D for system or the ERC seven seven seven system or the yunusov system or whatever it is you can make all of the pieces secure and you can have them implemented by like you know good teams that are security minded and then you combine two of them and everything goes out the window and now there's problems and when you think about like you know just how many different combinations there are and the fact that you can combine two or three or ten of these systems it's really hard to imagine on like a purely technical level like there's no way to ever have the system as a whole every single possibility every single combination there's no way that it's ever gonna be perfectly secure a little bit of a different take on this one actually and I wonder where yeah yeah in a you know swap deep worst case they're affected by the world's most well known bug class in aetherium they're affected by re-entrance II right yeah in case people don't know what that was right it is like it's incredible it's so funny because up till this point since the Dow there hasn't been a really exploited re-entrance II attack on main net ever everyone talks about it so much but the kinds of things that are actually causing people harm or somewhere else and now all of a sudden in 2020 we have a reinsurance II that's used to steal real money that was the most surprising part of this to me and when I think of that a little bit like why weren't they aware of a basic reinsurance e flaw in a you know you know set of contracts that's I got a lot of eyes on like has actual development teams that are trying to do their diligence to build it and you look at the technologies that are being used so in in the unis whap KS VIPRE and the tools for a lot of secure development and bug finding and vulnerability discovery are written specific to solidity they you know Dan just go back so VIPRE is what is that so there's choices that you can make around what programming languages to write smart contracts in most people choose to use solidity solidity is filled with foot guns there are many ways that you can step on sharp objects and end up really hurting yourself with solidity so there's a community of people that have developed a new language that looks a lot like Python called Viper no Viper while it has a lot less foot guns a lot less like sharp objects all over the grounds that you could potentially step on there are still some fundamental things that you need to do correctly and avoiding re-entrance e is one of them so the problem here is that a lot of the best tools in the space for detecting basic security flaws like this have trouble working with VIPRE so the issues with adoption here of those tools may have created a scenario where it was more difficult to find in in a unique swab and I am BTC kind of scenario just because they've chosen to use different sorts of tech now on the other hand the d-force folks are in a different position because they did use solidity and that's simply a question of there is a checkbox yes no answer that you can get of have you evaluated your code for known flaws and ensured the absence of them and for divorce the answer was no we have not because this would have been detected immediately by any kind of off-the-shelf security scanner that exists in the space yeah and just for especially for people who didn't listen to the episode with Hasib I think it was open Zeppelin did blog about this last summer in July so it's been known for quite a while but actually one other thing I wanted to bring up about this is that one thing that has seep said was that like for instance so d-force had copied compounds code but what he was saying is the reason that this issue didn't come up on compound is because compound you know knew about the issue and like made sure that no ERC seven seven seven tokens were put on compound but like you know that happens because they have kind of more centralized control so I feel like there's this tension between like the decentralization philosophy and then you know having good security how do you guys think about that yeah common thing in the D Phi space like there is a lot of risk around composability which is I think the word we've settled on to describe all these emergent behaviors and potential interactions between things that happen on chain and the security risks that come from them when we work with projects you know we've worked with compound as well and a lot of the way that you have to approach this is by whitelisting the behaviors that you have studied well enough that you trust and slowly opening up the ability of your contracts to interoperate with other stuff so if you don't fully understand all the repercussions of working with arbitrary ERC 777 contracts then maybe you should wait until you're fully clear on what that means before you allow your contracts to do so now that's like one strategy but at some point composability is unavoidable right like I don't know an example you could buy insurance on a Martin trade that's been collateralized with die right and then there's three systems that all interact with each other so at some point there's no real way that you can avoid that composability so it's really everybody's responsibility for ensuring that the contracts and systems they use are like that the interactions they have become are safe it it's it's something that I haven't seen many defy projects fully internalize where I think most projects in the space still depend on outside experts like trailer bits or someone to come in and advise them about what's going on and what they should pay attention to next and new objectives they should build towards but there's there's definitely a point where it makes sense to have a smart security person on staff like we've talked to a defy project where they had an arbitrage contract on chain that was abusing their app and investigating that issue required them to identify the arbitrage contract download the binary code reverse-engineer it with one of our tools and then deeply understand the way that it was abusing their work like that's something that I think dphi projects are gonna need to come to terms with that they really need their own deep understanding of these issues to deal with them in the future right but yeah that still is I think a more centralized model and then but also like and this kind of is also related to the upgrade ability thing so the way I asked the first upgradability question was just about like when there's advancements in technology then what do you do especially if you you know if your project at that point is more decentralized you have less control but then another question is just like how should each system be upgraded like you know I had this discussion with Matt Luongo about TBT C the other day where he at different points in the interview like one time he was like oh we're going to you know set it and forget it kind of attitude and then later he talked about like then the next version and he was like oh yeah well actually there probably will be a v2 but yeah I just wonder like how do you think cuz I can't imagine it so let's say Andy Phi becomes a thing ten years from now we're not gonna be using so this current smart contracts right so how but yet how do we get from here to there you know while keeping in mind all these different principles like decentralisation and security and upgradability etc yeah so the way that I look at it is um right now the biggest threat is like we are writing bad code we are creating insecure systems and so in the short term I would prioritize centralization and security over decentralization that's not to say that we should just forget about to centralization and not have it be sort of part of our our goals or our philosophy but just right now the worst things that can happen can either be mitigated or eliminated by having you know say just like a kill switch you know and I really lived through the Dow and I can say that everyone who is there is in the same mindset because we've watched what happened when you try to like fully to centralize everything and you're not ready to oh wow but yeah I mean I'm sure you're aware you just made a controversial statement I mean I I do get it and that's the thing it's it's definitely a conflict within me because I'm like I'm building on ethereum I love decentralisation I love what it empowers but in the short term we're never going to be able to get there if if every single contract is the Dow and it just blows up your money and so there's some there's some really interesting ways where you can you can strike a balance in the short term and then you know as the system becomes more secure and more mature and you have confidence in it you can like ramp down Matt Luongo obviously he has one approach that's a bit bit do decentralized upfront from my days I've talked to him about this but you know like just as example you could have a smart contract where you have like a big red button where if something goes wrong you push the button and it stops everything except it allows for like one function that allows the user to withdraw their money and so now if a hacker or a flash loan or an arbitrage or comes in and starts screwing with your system in a negative way you can like prevent them from doing that you can prevent the bad things from happening but you don't necessarily lock the user out they can still go and withdraw their money and you can also do that in a way where like the user can withdraw their money but you can't etc etc etc and so these are the things that I think in the in the short term we should definitely actually be encouraging because again if everything blows up and every single project basically like launches huge fanfare and then everyone loses their money we're never gonna get to a point where timing other stuff is actually useful so yeah baby stuffs yeah yeah there's been a lot of hacks but one thing I just wanted to ask was when you said like the user should be allowed to withdraw their money but you can't when you say it what said you did you mean the developers of that protocol yeah exactly whoever like just because you know I know this is like almost a meme at this point but the decentralisation is the spectrum it really is true you know you can create a mechanism that allows you to turn all of the smart contract off and that's that's centralized right that's the developer making a centralized decision to turn it off but that doesn't necessarily mean that you have to be able to turn it off and steal everyone's money you know as the developer you can have a system where a centralized party you can turn it off but they can't touch the money they can't waste all the money and still allow in a decentralized way you know each individual user to withdraw their money from the system I I find that idea really interesting because basically what you're doing with that is you're making the risk for different of people in the system difference so like if you're building it then their risk has to be higher they have to like put more effort into making it secure but for users their threshold is like a little bit lower and you know by the same token they have more like ability to go in and out so yeah exactly and we have not seen I don't think we've seen like a defy specific product that has like exit scammed or taken advantage of the decentralized mechanisms to steal everyone's money and whether that's either like a team pretending to be good and they're actually bad or a hacker like abusing you know I lie there have been hackers that have abused like the the admin functionality of a smart contract you know but that's you know when Dan mentioned earlier like threat modeling right is the team itself good or bad are there attackers on the outside you know coming in from the outside attacking um are there users that are inadvertently doing bad things on accident or on purpose you know there's all these different parties and you do have to be aware of them you do have to try to protect against them it's never gonna be especially in the short term perfect and like secure against every single party and that's why for me personally again prioritizing the safety and the pause buttons and those types of tools yeah do that and I just wanted to ask you guys about one other thing that isn't exactly in your wheelhouse but I was so curious to know your opinion so with the d-force attacks they did call the Singaporean police on the attacker and I just wondered in general like do you think the traditional legal system should be a way to deal with these kinds of defy attacks and if so like would it be the developers of the protocol who would be responsible or like how how would that all work you're right that is a little bit outside I think our area of expertise but if it's an option for you then I don't see why you shouldn't take it I you know there are by two things that want to address about what Taylor mentioned the upgradability conversation doesn't just affect like the security of your product you can also think about like your product may be safe today but another contract on chain could upgrade or change their behavior and now their interactions with your on safe and that's where the whole flash loan thing comes in where there have been contracts that have been deployed for weeks or months or years and this changes the entire kind of threat landscape all the bad things that can go wrong are suddenly much more severe and much more likely to occur and it was through no code change of yours your your code did not change a single line but things outside of you did so that's you know other other things that you need to be aware of and have an ability to respond and I think empirically right now the level of decentralization in the defy space is very low like you can go download all the code for all the defy apps and run it through slither our static analyzer and you'll see all the owner privileges that just drop out and it's extensive I don't think anybody right now very few people are really achieving that ideal goal of being fully decentralized and I think that's okay I'm with Taylor on this 100% like you have to take baby steps to getting there and it's gonna be a long road yeah well since you mentioned the bzx attacks let's definitely talk about those I guess actually something that interested me is what you just said you kind of sort of call out the flash lunes as one of the issues but actually somebody else that I interviewed love live Nev when I had him on the show he was saying that for the bzx attacks he felt like they weren't necessarily the culprit you know obviously they made it cheaper to make an attack but he felt that you know really this this was more like actual bugs in in their code so as curious to know like do you think flash loans are a problem because there definitely were other people at that time who were saying that they are a problem so there's some nuance there like there was a specific coding flaw in bzx that allowed this attack to happen right they had a short position that should have been closed because it was under collateralized but it wasn't that's the bug right however the ability for somebody to exploit this became significantly easier because flash loans were thing so what I think most defy projects need to understand is the bar has now been raised that issues that were low severity before are high severity now and then it's insufficient to only focus on like a couple of things that a firm like trailer but just reports you that you actually have to go through and fundamentally address every issue so it and you know this gets back to like how do you actually secure a defy project or what is the process for securing a smart contract at all and like ensuring that you're not exposed and known attacks is great but at some point you have to have a deep understanding of what your own code is supposed to do and be able to prove that it operates the way that you expect and that's defining security properties and testing security properties during development that's like the next layer of a pyramid that I that I visualize of application security maturity where a third level might be all the token economics and the incentives that you've created which is just a whole other thing that very few people have a handle on in addition to all the technical issues that we should be scared of there's the whole thing where financials and incentives and economics and tokens when you start thinking about that those are attack vectors like if your token economics don't ensure that everyone is making money in the way that they expect to bad things could happen it may not be as drastic as they like the Dow but you know if you're if you're if you're promising a sustainable business and you're actually losing money every single month that's unexpected behavior and I think we are going to see way more of that come to the forefront as these more and more dpi projects start launching yeah and in a similar vein I actually wanted to ask about bug bounties because this was actually another issue with the pzx attacks where the attacker was unhappy with the amount of the bounty offered which was $5,000 where is with compound bug bounties ranged from as little as five hundred two all the way up to 150 thousand so I was wondering like how should protocol teams determine what amount their bounty should should be like what do you guys consider fair like how is that determined so I actually don't think the conversation is about the bug bounty dollar amount like there are some people for which the dollar amount is like not a thing they don't care there are good people and they're bad people in the world basically there are some people that are going to do things to screw with you and there's nothing you can do to convince them otherwise and there are other people that are good people that just want to help you and they're very receptive to any sort of assistance or acknowledge Vince or thanks or or money that you provide to a system and kind of what you want to do is you want to make sure that all those good people that are out there that are willing to communicate with you are kind of incentivized and and it is easy for them to contact you and get those issues fixed you don't want them to not know where to go to end up tweeting about it end up putting it on reddit or like wherever else you want to make sure that you actually hear all the things that people have to say so providing that free flow of information is the most critical thing for a bug bounty program and that means describing things like safe harbors where you have language on your page somewhere that says here is how you can skip the support queue you don't have to email support at whatever and like create a Zendesk ticket no you can reach our security team directly and if you do so we won't sue you and here are all the different ways that we won't go back and harm you like it is safe to tell us things mmm so that's really important yeah I'm with Dan on this one as well like the bug bounty number you know there's there's all sorts of philosophies on it but it's that's the least important bit the most important bits are everything else because if you think about like typically they're called a gray hats right there there are these people that are somewhere in between a perfectly good person and a perfectly bad person you want my sort of like you want them on your side you want them to be white hats for you and so the ways that you can do this are essentially by not pissing them off and by making it very easy for them to get you information and both of those are insanely important because you can imagine that if someone either accidentally stumbles upon something or is hunting for something and then they try to get a hold of you or they try to share it or they try to figure out what this piece how it connects to that piece or whatever it may be every single one of these steps is gonna irritate them more and more and more and it doesn't take that much to piss people off on the Internet and again the person is somewhere in between perfectly good and perfectly bad you know they may they mean either just like not just close it just like give up and be like screw this or they may be like hey I don't know what the heck's going on like but here's this huge exploit and just dump it on Twitter and we've seen this again and again and again and again so yeah bug bounties like you should have the page you should encourage people you should give them all the ways to communicate with you you should respond to those really really quickly and professionally you should have sort of your security information everywhere dan has a repo called like the security block teen security contactless if you're not on that list when say Sam son finds an exploit he has to like go into telegram and be like yo anyone know how to get ahold of AK steam and then we're all sitting there going Jesus you know and again Sam is you know this example of pretty damn close to perfectly good you know but most people aren't going to be sitting in a telegram with a whole bunch of blockchain people and you know ask for a contact and then get an answer in two seconds so the other thing to say here too is it shouldn't like so if this person was truly motivated by the amount of money that was being offered that person still should not be able to ruin your day by virtue of them tweeting about some bug in your contract like you can't depend on the fact that the bug bounty exists that no zero days we'll ever get dropped on your system so this goes back to that Security Response discussion we had a few minutes earlier where you need to have processes and procedures in place where you know what to do and you can safeguard people's money and you can take appropriate steps to respond to issues when they come out because just because you've got a bug bounty doesn't guarantee that people are always going to do the quote-unquote right thing and work with you yeah it's still your responsibility what does that process look like because with bzx there was yet another issue where like later on it was revealed that one inch exchange had actually previously notified them of a different vulnerability and then took issue with the fact that vzx did not pause their protocol during the 16 hours in which they created and deployed a fix and so user funds were basically vulnerable during that time there was a similar incident with curve and during that time they like kind of couldn't figure out you know should they alert people on what's going on because if that happens in blackhat hackers could take their money and what they ended up and in their contract actually didn't have any kill switch or upgrade ability so they ended up deploying a new version but what they did and the new version had the fix but they didn't disclose any of that and then they kind of waited until most people migrated over to the new contract and then afterward they they announced it so just curious like how do you think teams should handle bugs when they find out about them it's it all depends on the situation you know like if we the the very first parody that was like the huge conversation because the people that were discovering this situation we're discovering it all based on public information like we were all just looking at the chain which means that anyone else could discover it and of course this you know we're not the parody team and we're also not able to to like put a kill switch or or anything and again this is one reason to a fan of kills but just because you can kill it it takes a lot of the options off the plate and yeah striking that balance between not telling people and keeping things secret is and the flipside of telling everyone and knowing that you know everyone also includes people that are just gonna exploit it and steal all the money it's a really really really tough position to be in and this is why kill switches should exist because it takes that decision away right if curve could have said oh shoot and then just like press pause they wouldn't even have to go down that path because once you're going down that path there's no right decision there's no good decision you're in that situation where what's the least shitty position context certainly matters here and the first part of any kind of incident response plan is to prepare your company to deal with those unforeseen circumstances so what are the set of things that could go wrong and how will we react to them when they do you're not supposed to figure that out on the fly you should ideally have that in place while you're while you're developing the product and there are many choices that you can make some you know are gonna work out like curve in their case maybe with folding a little bit of information but then clearly explaining it after they took actions to secure their their users funds might be the right decision for them but it could be the wrong decisions for somebody else so I I don't have any like specific concerns about what they did I think that the kind of that ends justify the means a little bit in that case since you know you save them the safeguard of people's money but it really really depends on context yeah exactly and the thing is is that with with all the situations where people withheld information and then revealed all shortly thereafter I don't take issue with that it's when they don't reveal all or when the information is so available yet you know this core group is denying denying denying you know it's you know once the sort of the swing has swung you have to you have to go all in and make sure that people do have all of the information and now let's discuss Oracle's that's an area that's pretty susceptible to attack and they can also be ripe for a manipulation and last summer there was an Oracle for the price of the Korean Won on synthetics that was just incorrect and somebody who was able to obtain a billion dollars in profit with their body yeah exploiting that so I just wondered what your opinion was on Oracle's is it like too early to have reliable ones and if not are there any particular characteristics that give you more confidence in certain Oracle's versus others oh yeah this is just a huge discussion around like the security of your code doesn't just depend on like your code itself you also have to consider the environment around it the environment that it operates inside so you know when when I'm looking at judging the reliability of a t5 project some things I really want to know or how many Oracle's do they rely on and how many become trusts how many would have to be untrustworthy for there to be some kind of manipulation of the protocol in a way that abuses my funds or the intended use case so this gets into the kind of like in my pyramid little thing where you've got your known vulnerabilities at the bottom you've got your application specific stuff in the middle and you've got your economic model up at the top this is definitely a blend of like steps 2 & 3 here where you need to actually model that behavior and think through what could possibly happen there are some tools that people can use to model that that are already available but they're not purpose-built for this task right like you can use tools that come from tray lab it's like a kid NAND Manticore which are essentially a little EVM runtime written in Python and written in Haskell that you can use to evaluate your contract of you know with different environmental data being provided to it but they're really more meant for finding more like code security related issues and less about providing this feedback on on behavior of your code in response to all these weird Oracle things so I think that's a part where this the tooling and the knowledge could get a lot more mature over the next few months or a year and it's certainly an area where it's needed as this incident shows yeah I'll just point out that a lot of the exploits that have been responsibly disclosed in the last two three months have also surrounded either Oracle's directly manipulation of the price that you know the Oracle is getting the information from like that even played into the bzx incidents as well and yeah again like there are so many different ways that these systems can be you know outright attacked or have like an accident bug or be manipulated you know any of these unexpected behaviors you have to you have to think about them upfront because otherwise you know they're gonna hit you they're gonna hit you hard and you're not gonna know how to respond you're not going to be prepared and that's why you know I think the overarching theme of this conversation is we're not mature we're not ready for this what do people need to do what are the teams need to do what is the community need to do to get like a little bit better you know there's all these little things that they can do to to prevent bugs and there's these tools that you can use to write better solidity or check your Viper or whatever it is but at the end of the day like there's so much going on that at least for me what I look for is like a team that is really obsessed with security that's paranoid that understands about things can happen and that they probably don't even know what those bad things are because for me that's the best hope if a team's to prepare Ettore that's the best hope because there's so many unknowns that's my hot tip for figuring out if a company's got a secure product - is for not non-blocking software I always just pop them open and LinkedIn and I search for security and then their company name and I see how many people they have working for them that actually have a responsibility to secure their their company and if it's zero then I know that okay this whole thing is probably a garbage fire but am i okay with that so it really goes back to the same thing I was does anybody working for the c-5 project have experience that would indicate they know about security stuff did they work in traditional finance at some point to have that sort of background or do they have a past history of development or publications or at least public communication that they understands what they're in for as they're building this product and if no that's a serious concern and that's really the underlying most fundamental concern that I could have about the project do I trust the owner and that's that's a question you can ask for multiple angles like do I do I trust them not to run away with all my money and do I trust them to actually do what's responsible to protect it yeah exactly and the answer to that is not ever well trail a bits audited them therefore I trust them and that's what I think like the fundamental all of these like disagreements about audits and what they are and what they're not why the whole thing is missing the bigger picture which is there's no one thing that any team can ever do to be perfectly secure and so the rowing it on Dan's head when something goes wrong is preposterous because you're not asking the right questions and in the in the first place like you are not asking the right questions well so I might not be asking the right question here because I actually asked so it's normally obviously for like certain episodes I don't tell the guests what the questions are but here I did ask Dan and Taylor to come up with maybe like a checklist of things that they think defy protocol teams should do before launching a protocol because I and I wanted them to have a good answer ready that would be useful to the teams but Dan already warned me that he he like maybe thought my question didn't make sense so curious to know what your answers are okay yeah sure yeah so I thought about this a lot over the last few days because of this this incident with magic where it can be difficult for an outsider to understand the level of maturity of a project project and that's really what we're trying to get at is like what are the long-term steps that someone should take to end up arriving at a secured product I mean how do we evaluate those how do we communicate those and what are the important steps within them to have actually taken so on one hand we have a set of critical controls that are necessary for dphi projects to have they have to have access controls they have to deal with numbers correctly like it's kind of important the degree of centralization or decentralization their documentation and specs the kind of key management that they use their security monitoring the level of testing that they've gone through those are all kind of indicators and what I think we're planning to do for our reports in the future is rank all those critical controls from weak to excellent where each of them there's no like overall rating there's no like hey this is safe at the end of the day if you get like five out of seven then like you but it'll at least provide some information from our team in our expert view where we think they are in terms of building a defensible system now that's one way to take it and that's sourced from the threat models there's another ancient web kind of document that I love to cite so if you go back to year 2000 there's a guy on the internet named Joel Spolsky kind of a famous guy he created the fog fog bugs system one of the best bug tracking managers that people had before like get up and get you lab we're about created Trello and has kind of just been like a software engineering leader for many years he came up with this thing called the Joel test and it was a set of 12 yes-or-no questions that you could ask in 30 seconds or less to figure out the maturity of a development team building software I love that because it took something that was so complicated at the time things like the capability maturity model CMM are a kind of really rigorous way to evaluate if a team builds good software and II manage to simplify it down to a thirty second yes/no exercise so what we've done is we tried to build that same thing for a theorem and we could call it the Dan test but it's also kind of a Dan Jocelyn test since he came up with a lot of it with me but you know there are some basics here like can you compile it without warnings on the latest from Pilar that you're using do you import third-party libraries from a package manager and track their versions have you located and documented every privileged operation in the system if you can't say yes to those questions then you're probably not ready to go so I have a big list of those I'm going to publish them all next week oh great when you do that send me the link so I can put them in the show notes I'm so glad you're doing this it's it's really tough and this is what I think that I asked on Twitter two weeks ago now you know what are the things that like every developer should do before you know I having twenty five million dollars in their contract on main net you know what are the big red flags and there's a lot of like really deep in the weeds type you know type things that I think are really really important but it was actually interesting because that some of the responses were like very different but also really enlightening and so you know one thing that came out of that conversation was you know if someone doesn't have an audit that's a really big red flag like if they don't get anyone to look at their code that's a red flag you know but that doesn't just because they haven't on it it does not mean that they're secure it does not mean that they're ready for me that it just means that like you know there's not a red flag in that in that area it doesn't put a green one there it's just not a red flag and then some of the other ones that I think we're really interesting you know were around the teams and the people and how sort of like how much effort and time they dedicated to the things that weren't the literal code so a lot of teams obviously love to focus on the code they love to focus on the product they want to build this awesome system you know but did they spec out the project before starting to write that code and figure out you know what exactly the architecture is gonna look like did they document the intended behavior you know does the white paper is it like a marketing piece or is it actually you know a technical document that dives into all the different situations another really interesting one that I I can't necessarily call it a red flag today because not a lot of people do it but certainly would would allow me to have more faith in a team is if they anytime they sort of acknowledge the risks of their project or their code or their system you know if they've taken the time to especially if they've taken the time to document and share where the bad things are that could happen that shows me that they not only have like awareness around their codebase they also have awareness that bad things could happen which is something that surprisingly missing and it also shows that you know they've they've taken the time to write it down and that provides like an additional level of accountability and so you know all of these sort of tools you know there's not one thing that's gonna make a project trustworthy there's not one thing that's going to make a project secure but if you take them all together you know a team that is a team that has a better chance of success is a team that you know has documents they've written tests they have a specification you know they're engaged with the community for a long time they're open to questions they're open answering the questions you know they're aware that not everything is perfect and glorious all the time and that bad things can and probably will happen and I'll say I think the first conversation I ever had with Robert from compound I was very skeptical and I was like so you're just gonna have all this money on the smart contract and you know how are you ever gonna know it's secure and he literally just responded and he was like well there's always a nonzero risk like it's never there's never gonna be a moment where I can go to sleep and be like everything's perfect nothing bad will happen and it really it knocked me off my feet because I've been you know talking to so many people in this space where you know the answer would have been oh well we had two audits by two different auditors and then we had it really verified and you know we have a hundred percent test coverage you know but it's actually Robert that gives me more faith in his team that code the compound protocol because I know that today and tomorrow and the next day you know that that culture is going to always be on the lookout you know whether that's the lookout for other hacks that may also affect the compound system whether that's awareness of you know flash loans coming into existence whatever it is you know they have a better chance of success then you know even someone that has had all of the audits and used all of the tools right yeah that makes sense and I love it that his honesty is actually what gave you confidence all right well this has been a fantastic conversation I've really enjoyed it thank you both for coming on Unchained thank you so much Laura happy to be here thanks for tuning in to learn more about Dan Taylor and defy security be sure to check out the links in the show notes of your podcast player whatever your favorite crypto meme is Lambos unicorns or the guy Fawkes mask is probably on the Unchained rabbit hole t-shirt check it out at shop dot and podcast comm and also be sure to check out our hats mugs and stickers to unchained is produced by me Laura Shin with help from fractal recording Anthony youn Daniel Ness Josh Durham and the team at CLK transcription thanks for listening [Music] [Music] 