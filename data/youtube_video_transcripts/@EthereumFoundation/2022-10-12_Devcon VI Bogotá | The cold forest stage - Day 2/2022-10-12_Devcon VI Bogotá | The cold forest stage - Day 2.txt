insurance company where I see a bunch of interesting risk events happen thanks Ryan we have an hour wow I mean there have been a lot of security incidents so I guess we have plenty to talk about but I just realized we have a full hour uh hi guys I'm Lane very excited to be here um I have been kind of steeped in hacker culture and hacker ethos since a pretty young age kind of High School 14 15 years old specifically kind of penetration testing white hat hacking ethical hacking this kind of stuff um I sort of kind of fast forwarding to the present I was an ethereum core developer with the ethereum foundation for a couple of years and for the past three years have been working on a project which is a new layer one blockchain called space mesh based on a novel consensus mechanism so I currently lead r d at that project and just generally kind of follow the security ecosystem very closely contributes to you know kind of security response here and there and just think deeply about it in the context of my work at space mesh nice to meet you all let's see uh hello everyone my name is Arun uh I've been a full stack developer at uh bug Bounty Hunter for a few years and just generally like a very active D5 DJ I was previously lead developer at a web 3 security uh like related startup called anti-dot finance and I'm currently head of research at Marana Ventures and before crypto uh I was a scientist in systems biology where I did research in high throughput protein sequencing and uh Tom Howard who's currently stuck in traffic as the founder of uh D5 payments wallet monsendo uh crypto options exchange power trade he's an unreformed D5 degenerate angel investor and he's now got a newly formed seat fund Network zero uh he's working on building tools and infrastructure to support the network State concept that Balaji developed as sort of a successor to the nation state so there's a whole bunch of security incidents that have happened in the last three years the world was very different in 2019 and I'm sure we've all we can all remember how things have changed uh I think there's some some broad categories that we're going to discuss of things that have happened broken down by category and then hopefully for 10 or 20 minutes toward the end our views of how things are going to get better because the current state is terrifying like I I wonder how people who have very large fractions of their net worth in these in projects locked on the on chain sleep sadly every night I certainly don't and it's probably something that uh that that is not sustainable in its current level of vulnerability over time um so I think to start with one of the things I've noticed over the past like at least 12 years in the overall crypto industry is a lot of the vulnerabilities that we're seeing in crypto are actually old vulnerabilities that were either core internet infrastructure or fundamental to human nature they're not things that are really novel and new to any of these protocols they're a whole class of things they're like Insider threats Personnel issues Key Management leaky abstractions bugs versioning things like that so there's a whole range of things that we've seen that that have really affected people and I think some of the incidents that we can talk about uh clearly fall into that I mean there's a bunch that I can think of but if either of you have any that you can think of that come off off the top of your head specific incidents or specific incidents and then the kind of vulnerability it was interesting if you want to go this direction to kind of do sort of a taxonomy because there are so many different buckets I mean there's at least kind of three or four different buckets and you touched upon a couple of them right now some of them are social engineering related some of them are bugs in the code another bucket is um multi-cigs where kind of like your your vanilla Bridge exploit where you know one or more kind of keys were compromised um from where I sit the most interesting of these is kind of low-level um bugs in sort of low-level libraries that are that that live there that lurk there for years and and they're not discovered until the whole world blows up so the most obvious and Salient example of this is the the binance hack that just happened a few days ago right that was like a very low level library and it's kind of in retrospect incredible that it was there for years and that code is used not only in the binance ecosystem but also in the cosmos ecosystem and Cosmos kind of got off lucky luck very luckily in this case because the the vulnerability wasn't present there in the same fashion um I don't know we could dig into one of these or we could do a taxonomy in whatever Direction you think is the best way to go that's my favorite category of vulnerability yeah actually just to like jump on that point before I move on uh yeah it's really important to to realize that this code is very complicated and it's very new actually Vitality of a great talk a couple of days ago talking about bringing roll ups online uh so I believe it was the uh the optimism uh fraud proof I think it was the get note actually it's about 34 000 lines of new code any and any small bug in that code could lead to actually a billion dollars being lost so how do we bring these like very complex pieces of software online there's a carry bill of dollars in kind of a safe and sustainable way and uh yeah definitely looking forward to exploring that question uh Jerry yeah I'm happy you mentioned this so like I'll try to share a little bit about what the world looks like from the perspective of a core developer right who worked on ethereum previously you know this is relevant in the context of my work on Space mesh and I think just any core developer we have this notion of a TCB TCB means trusted compute base and what it means is that there's some amount of code which is 100 critical to the functioning of the network and any bugs or vulnerabilities or exploits in this inside the trusted compute base are kind of apocalyptic right they're kind of like like stop the world scenarios like like many of the exploits we're talking about here and this is not new to crypto it's not new to web3 right this concept has existed forever it's present in operating systems and things like this but as a core developer touching upon what you said a moment ago about kind of the diff you know looking at the changes that optimism has had to make to existing code like go ethereum or you know any anyone building um let's say modifying or tweaking or adding on to existing code like this is this is what keeps us up at night as core developers we want those changes to be as small as possible those diffs ideally to be on the order of like tens of lines rather than hundreds of thousands of lines because every one of those represents a very real possibility of the introduction of a bug right another principle of computer science is that there's no such thing as bug free code it doesn't matter how good of an engineer you are it doesn't matter how good your software engineering practices are there's some number and you can reduce it right you can reduce the incidence of bugs by following best practices which again have existed for decades things like code reviews pair programming there's various techniques but it can only go so low I think Microsoft or someone did research on this a decade ago and found that the most senior most experienced programmers are still introducing one bug for every thousand lines of code period one bug for every thousand lines of code go ethereum is probably on the order of 100 000 lines of code right and let's say some of those bugs have been found but there's still bugs there for sure so anyway it's just as a as a comment as a core developer like this is literally what keeps us up at night we want to minimize the number of changes and that's very very difficult when we want to add features and bells and whistles you know add new OP codes to our VM um what's another good example uh a lot of blockchains are using webassembly as a VM now this is actually what I worked on in ethereum this thing called ewasum which was a candidate to replace evm after after the merge um webassembly is a whole complex ecosystem and if we start putting webassembly-based smart contracts on chain then all of a sudden the compilers and interpreters for webassembly are now inside the trusted compute base so you've added 100 000 lines of code or something to your trusted compute base so one I'm jumping ahead here but one potential mitigation strategy is to like really minimize the number of changes the number of things you add minimize the size of your trusted compute base on that front I mean the concept of a TCB is something that I read about in the rainbow books that were the the nsa's security guides back in like the they were written in the 80s so this is a very well understood Concept in theoretical computer security unfortunately it's kind of theoretical because a lot of systems there's two classes of errors here one there's bugs in your TCB two there's not identifying what really is the scope of your TCB correctly there's a lot of the the craziest things I've seen like uh the Yuga Yuga hack where a moderator's uh account recovery credentials for a Discord server were essentially um used to cause like 200 like a crazy like multi multi-billion or multi-million dollar loss uh like 200 million dollars or something like that um so yeah yes there was I mean these things happen you know in in all companies in all Industries but it just just your point about credentials being stolen this is what happened with that massive I think it was Uber right about about a year ago or something someone got credentials of an administrator by a social engineering and then got inside the slack and got inside you know yeah so we have to be careful this stuff too yeah this is actually happened a good a crypto quite a bit uh now mostly with Discord and Twitter um actually Zack xpt a couple weeks ago had like a really interest Twitter throughout talking about someone having access to a admin Twitter panel and basically that was what allowed them to take over all these prominent Twitter accounts uh yeah I think one of the main issues is we're using essentially consumer tools like Discord telegram Twitter things like that for large Financial applications and um the people supporting the applications that we're using are not building them for the use case they're being used for they were built for gamers talking to each other about um progress in a game and things like that so expecting them to provide the level of security needed for a trillion dollar ecosystem for security just doesn't make sense and it's unfair to them to to really blame them in any way and we need better tools we need better tools no so I interesting I think I agree very strongly with what Ryan just said the situation has gotten a little bit better pretty much everything has two-factor authentication now and if you ask any CSO any security expert in the world what's the one thing you can and should and must do immediately to increase security it's not only enable but Force to factor authentication on everyone um so it's a little better than it was like five ten years ago like when the Discord didn't previously have two-factor authentication now they do and I think it's I think it may even be on by default um but I guess I'm kind of I'm curious I don't know the answer to this do we think that those tools that we use to coordinate communicate Etc need to be custom built or do we think that we can adapt existing tools to those purposes yeah I'm a big fan of not reventing the wheel if we could take from the let's say 50 plus years of security research in web 2 and adapt it to web 3. um yeah there's no brainer we definitely should do that yeah I mean I think most of web3 security is actually web 2 security so these lessons have already been learned by Enterprise users uh I would go a bit further than just saying two-factor I think we should be using single sign-on Hardware keys that are not fishable like the whole concept of getting hacked because one of your emails clicks on an email and goes to the wrong URL or is message something unsolicited on telegram instead of signal or telegram instead of Discord where they routinely come with someone go to a URL that's a phishing URL click on something and then boom you're out 500 million dollars is crazy like that's the vulnerability of the system not of the individual that clicks on a link and the the idea of mandatory phishing training for users is woefully inadequate for protecting your systems if it's possible to have a button that you push right next to another button that you push every single day and you push the wrong button and it destroys the world like the problem is not the person pushing the buttons the problem is the person who designed the buttons and put them there so you really need to have a single sign-on so you can revoke credentials for an employee if an employee here like it's very common to have a laptop lost in a bar or have a cell phone stolen which might be unlocked and things like that you want to be able to immediately revoke everybody's admin credentials so I think essentially if you have administrative credentials for any project which includes public publishing to social media doing any sort of action on Treasury anything like that and you don't have the ability to revoke those credentials remotely on loss in a single like in a like five minutes after the event is reported you are making a big mistake and if it's possible for a user to go to the wrong URL by accident or by phishing and lose their keys or use their keys incorrectly you're also making a big mistake so single sign-on and a hardware enforced key credentialing are the way to go but luckily the the broader security industry has largely accepted that and we now have things like pass keys on iOS and we have uh like the the 502 ecosystem and everything else so the key management in the traditional Enterprise security world is getting a lot better we also have great open source SSO tools as well as commercial tools so so that world is getting better but the the problem one of the biggest problems with security is the um the attacker can find any vulnerability the defender needs to be protected against everything and you get a lot of cases where I mean everyone knows as a team like you have a certain number of hours in a week for your people and you want to spend your resources on building the product because if your company fails if your project fails no one uses it because you don't have any features that's that's also very bad so if you have one hour to spend you probably want to spend that on working on your product and not locking down security so there's a lot of cases where the uh the floor of security is not a uniformly high enough floor there's a vulnerability and things like that so I think making tools better making things secure by default is really the solution there so one thing I want to touch on with adapting web 2 security practices to web3 is that one thing we have in web 3 do it on web 2 is these systems need to be uh sensitive persistent and that's like a very important factor and that's one reason why metamask doesn't have 2fa I mean part of the reason is also because of the way aoas work and you can have multisigs with 2fa but if you want like an uncustodial wallet built on top of the ethereum platform there is no real way to do a 2fa on the OA you have to have a spark contract based wallet which I think people are kind of moving towards in the future but like one example would be for instance the mango Market hack last night um people always say after these defy hacks well why don't you have let's say like some kind of circuit breaker something that says okay if you're trying to withdraw 50 million dollars from this bar contract maybe you have a human being involved in that process and one reason why we might not want to do that and I I say with an asterisk because uh in the end if any smart contract which has the ability for an admin deposit is not decentralized so most smart contracts and most deeper protocols don't really we have a true decentralization as of yet and I think that's probably a good thing at this stage but I guess like assuming that that wasn't the case and the smart contract was truly decentralized um you can put a human being in that Loop because that introduces a point of attack for regulation and a point of attack for uh for other kinds of compromises like you mentioned so how do we do this in a way which is which is programmatic and sensitive persistent so I think there are going to be need to be some new design patterns in in defy and you know there's things you could do like for instance you could uh for instance maybe even help like an open Zeppelin kind of like smart contract library that that kind of like meters and says okay like don't let you you shouldn't be able to withdraw more than like one million dollars worth of usdc every like hour or so and I think that's fairly reasonable although maybe for example cases it might not be and it also might be difficult to do in a generalizable way given that if you have for instance Oracle attacks the smart contract might necessarily know what the value of the assets being withdrawn are so you need to be careful about about that code yeah I agree with that stuff I mean we're kind of jumping ahead a little bit to like mitigations and solutions um I'll just add one more comment on that and then Ryan you can steer us in one direction or another but uh so you know the title of this talk is notable security and since since Devcon five so obviously if we're talking past three years A lot has changed in the past three years you know three years ago I would say best practices along the lines that you're describing were just emerging they didn't really exist we were still at that point struggling with basic things like re-entrancy and I think now we have a much better what's that we still are yeah we started this is true this will be a thing forever um but you know we have libraries that you can include now from people like open Zeppelin that protect against common classes of attacks like re-entrancy that's just one example um you know basic things like not having ever a single point of failure which is to say like a single key pair or something right you and and as as he pointed out you know uh externally owned accounts was just to say just simple basic key pair based accounts in ethereum are a single point of failure you lose the key your host there's there's no getting it back so having multi-signatures um having cool off periods or delays right both for governance as well as anytime you're moving funds right having tears so that you can kind of move a certain amount of funds instantly but something over whatever that amount is you know requires a delay of two days three days um I don't know if people are familiar with this but the reason the Dow hack the Dow of 2016 wasn't worse than it was the reason that the the white hat hackers were able to recover the majority of the eth was because there was a delay actually multiple delays baked into the protocol right so it could have been far far far worse yeah in general you have the the frequency of an attack the potential value at risk the amount that is actually stolen which might be limited by all these other countermeasures and then any sort of recovery procedures that are possible and we've definitely seen a lot of progress in the last three years on both chain analysis and a lot of you ah cool cool great okay uh so we've seen a lot of um uh positive uh changes in the overall ecosystem where we have uh now some chain analysis tools we have a huge ecosystem a security audit and infrastructure existing in the world we have probably hundreds of audit firms both coming from the web 2 world and dedicated to web3 Smart contract audits so a lot of these vulnerabilities are are bugs in code and I'd much rather find a bug in code in an audit that I've just paid a couple hundred thousand dollars for rather than in the wild we also have more of a culture of bug bounties and Reporting so if there is a bug found I can legally make a couple million dollars as a bug Bounty and be a good person and also build my own reputation and do it publicly everything else rather than just exploiting it and probably taking 20 30 million dollars plus in dirty money and being a horrible person and having to hide it and everything else and no one learning from it so there's a lot a lot of positive changes that have happened the counter argument to all this is just the whole ecosystem has continued to grow so if a vulnerability affects one percent of the ecosystem or vulnerabilities affect one percent of the ecosystem the total dollar amount and the total number of users affected just goes up as growth goes oh um yeah just a couple quick thoughts to add to what Ryan said the tooling that Ryan was alluding to has gotten really powerful and and a lot of it is open source right so like folks like trail of bits have multiple libraries multiple tools that you can use to do inspection and Analysis at various layers of the stack and I would actually say I wonder if you guys agree with this um simply running these open source tools today will probably get you more than you would have gotten if you paid six or seven figures for an audit three years ago so there's really powerful stuff I mean it's it's depends on your your threat model like it may not be sufficient you should still do audits copy item tour but there are very powerful tools out there yes Slither is quite nice um one thing I want to say about the existing models is I do think they're they're fairly insufficient like I I don't think that uh aside from a few auditing firms have very style reputations like let's say trail of bits or or daub most times when I see an audit I'm not necessarily thinking like oh this code is safe because we've seen many times the audits are are faulty like they're humans are being human code people can miss bugs either way another thing about bug bounties is actually that uh the system is is just not really working very well um as a bug Bender I can tell you uh ironically it's often you make more money if you if you hack the smart contract and then hold the fund for ransom and then keep 10 versus just reporting the bug which is just insane but so that's an argument for possibly increasing the amount like there's a whole calculus of if you offer people too much for um reporting bugs then you end up with uh bugs get reported through that channel and possibly introduced and you have people problems I used to do security Contracting in Iraq and Afghanistan and there was a concept of like paying people if uh U.S forces caused a um uh injury to someone or death and there was a crazy guy like I would obviously say you should pay as large amount of money as possible but um if you make that amount too much there was an argument that people would intentionally cause innocence just to get the county which is terrible but you have the same risk with insiders like one of the whole categories that crypto companies do not address um really at the level that traditional finance and everything else addresses is Insider threat you can have a team if a team is a few people that have started a project together and have worked together for a long time that's one level of trust but if you've got a team that's hundreds of people you're hiring people using like LinkedIn and whatever else somebody joins you don't really know uh what people's motivations are they could be incompetent they could be nation state Affiliated they could be criminal Affiliated everything else they may introduce bugs intentionally and then exploit them they may discover something in the course of their work and then pass it off to a friend externally who exploits it there's all sorts of stuff like that traditional Finance solves this by having separation of Duties so no single person would ever be able to have a vulnerability that would ideally that would be able to exploit things but that isn't really compatible with an ecosystem where stuff is being built as you're as you're going you have a trade-off basically you can build new stuff or you can prioritize for extreme safety and resilience against this kind of Insider threat and I don't think it would be good for the ecosystem if we became so paranoid that we didn't allow Innovation um so yeah right our final speaker has arrived for your panel come on come on down welcome welcome sorry about that learning about Bogota traffic this morning getting ddosed on the road um cool yeah I'm Tom uh I founded a D5 product called mosendo a few years ago focused on D5 payments I also co-founded a crypto options exchange which is a centralized exchange so dealt a lot with custodial risk and then have been an investor in the space for a while and just started a seed fund called Network zero so uh I've actually been following the mango markets hack uh even on the right over here there's some interesting developments will be interesting to get to at some point and so one other point just before we move on was the the interesting argument about decentralization the binance hack that happened a couple days ago they were able to mitigate their loss because they were able to just stop their chain which is crazy from a centralization perspective but did save them 900 million dollars so that's the counter argument against uh proper decentralization also the hacker Bridges some of that money into usdc which immediately got frozen which is a centralized stable coin so yes that's cool so yeah okay so actually for that binance side specifically uh I would argue that was certainly change sovereignty is an important factor and social expense is important factor of mitigating loss for sure and that's something that for instance protocols which have strong Bridges to ethereum don't have because if that theorem bridge is hacked basically they have no ability to roll back changes in ethereum to recover that money but with the buyer stack in particular the hacker had about three hours to wreak havoc and he didn't so that was almost like an issue of hacker and competence I think that binance could have lost quite a bit more if the hacker was a bit more competent in that situation yeah one of the things that I think Tom's a particular expert in is a lot of the D5 vulnerabilities which in a weird way are some combination of software bugs and economic vulnerabilities and figuring out exactly what's what in that space is difficult the main value of having a taxonomy is because you can then identify Trends and underlying risks and assess them so I don't know if it's worth trying to figure out which of these assets which of these risks are more economic versus more software bugs and how to mitigate those but if you want to talk about some of the defy issues that you've seen over the last three years yeah we've gone over flash loan attacks yet okay not yet oh excellent uh so I find that very interesting because it's like this novel attack that no one imagined uh this and this has not possible in any other ecosystem right it's not yeah uh it's uh and it's new since the last Defcon right uh flash loans only came into existence in late 2019 early 2020. and then we had the first uh flash loan attack happened in 8th Avenue 2020 in February I remember the bzx team being quite excited about their products and then that day they got flash loan attacks and I'd like to not assume a ton of prior knowledge it might be worth explaining what a flash loan is and what a flashlight is just as a starting point okay yeah so flash loans um flash loans are interesting and actually you probably only hear about them in negative context but they're actually a net positive for the ecosystem they're actually very useful so flash loan basically allows you to borrow a nearly unlimited sum of money without having any money yourself uh but you have to do it within a single transaction so at the end of the transaction say there's multiple lines that make up a transaction you have to repay that loan at the end of it so people use it a lot for Arbitrage Bots or keeper Bots liquidation Bots these keep financial markets in order because uh coder who has the skills to run these things but not the capitals who can use Flash loans to say borrow a million dollars to Arbitrage a position across markets into place so I like to say that ethereum's superpower is composability permissionless composability right the fact that you can build a smart contract that calls into a smart contract that calls into a smart contract kind of ad nauseum actually quite quite a few layers deep and yeah flash loans are just a form of Leverage right so they allow you to pay a very small amount of Interest I mean it probably amounts to thousands or tens of thousands of apy on an annualized basis but because it's for the span of a single block time a tiny amount of interest and just it's just just just jack up to a very high level a very high amount of Leverage the amount of funds you're moving around and using in that single transaction and that can flow yeah some of the most sophisticated loans they touched dozens and dozens and dozens of different contracts they go you know 20 30 layers deep it's kind of fascinating to unpick them as a developer very I just want to distinct make a distinction between composability and atomicity uh because you can have composability over multiple transactions but the atomicity of a transaction is is what is the key distinction here with flash loans Arun you wanted to say something yeah yeah just to kind of like add a bit to that point um what's about flashlights for profile perspective is basically riskless I can lend out any money for my my protocol and get repaid back by any transaction it could roll back to already paid basically there's no down to the protocol and it makes the markets more efficient but yeah I think the issue is it it provides like asymmetric ability for for hackers to kind of wreak havoc it's definitely like a very powerful tool I remember at one point last year Dai was considering having the ability for people to Mint arbitrary amounts of dye in a transaction and then repay a data transaction and you can imagine just like what people can be capable of they could just like mint Billy and die and then repaint another transaction that would be kind of insane at least with the current flash loans if the guesses aren't in the smart contract you can't use them so there's only 100 million dollars of usdcfr contract I can only use 100.360 but if I could literally create like a trillion dollars of die out of thin air and then repay it that's a lot more dangerous yeah yeah one of the the issues is you could certainly do this with most of these exploits would be possible without the flash lens you'd be able to if you had a large pool of assets uh exploit something that requires a large bowl of assets to exploit it but the set of people who have a large pool of assets lying around is much smaller and it's very hard to move 100 million dollars on chain anonymously and then the whole chain of moving stuff to and from and everything else so this opens up to potentially any attacker in the world can can exploit one of these vulnerabilities and not simply the people who have very large pools of capital lying around so the the key to these flash loan attacks is that you basically have one smart contract system which is doing imperfect accounting on some other smart contract system and when they're coding it they think oh nobody could ever possibly have that amount of money to manipulate that imperfection they make assumptions but those assumptions are not checked basically right so after flash loans happen I kind of view it as like the immune system of defy like if coders are taking shortcuts and they're they're taking these assumptions and being imprecise in their calculations flash loan attacker will eventually find it and exploit it so it actually encourages people to be more responsible with their coding practices yeah and we were talking earlier about how much more mature things have gotten in the past years since stepcon four basically got five sorry this is difficult six um but yeah I I think it's like a fascinating category of of attacks because uh they're not exactly bugs like code was kind of working as intended uh but like yeah they were able to get like insane amounts of Leverage uh the other way that the flashlight attacks are commonly used is for Oracle manipulation so uh the most common attack is uh say you've got some protocol that uses some asset as a collateral uh and say that collateral actually has very illiquid markets and maybe there it's only one unit swap Market uh so they can use the flash loan to just wind up that market to pump up the value of that collateral uh deposit that collateral into say some sort of lending market and then withdraw assets against the value of that collateral and then they unwind that because they have to repay their flash loan and so that um collateral becomes worthless again um so that's been another common Vector of attack but that's been uh there's ways to mitigate that um with instead of using a you know just a unit swap pool as an oracle there's some proper Oracle practices to fix that but that's been quite interesting as well I I just want to point out these this this class of attack if you want to call an attack is really interesting and really fascinating but I think it's very important to make a distinction between this and other forms of security incidents because I'm inclined to actually put these sorts of attacks and again I'm using scare quotes um into the Mev bucket right it's as you said a moment ago it's code working as it was intended and it's this is not new I have a background in high frequency trading right we just call this Arbitrage right it's people finding mispricings or um yeah it's exactly like you said when there's some sort of a mispricing orness or an assumption that's baked in at the interface it tends to be at the interface of two different kind of systems or something and and taking advantage of that um I'm not sure I'd call that a security incident like an actual bug in core code or something so it's important to make that distinction and by the way we should talk more about Meb because Meb is also really interesting this is why I've been using the word attack instead of hack okay cool yeah uh I just want to make a point that uh like more generally speaking because smart contracts are immutable um when you write smart Contour code it's it's very unreasonable to imagine like I have to write this code so it's a cure for the next hundred years against any future Innovation that could possibly happen in D5 like like a lot of these archives written before flash loans lots of came along you'll kind of support these smart contracts uh so how do we get around this well it's like really difficult right because uh as we've seen protocol upgrades um sure the devs can be responsible and kind of upgraded after protocol in response to like uh new developments but they're still like money and assets in the old protocol that can't be withdrawn and a huge class of attacks comes from people just like not being up to date on what's Happening and not withdrawing their money from from still protocol so I mean one very classic example was when when the whole Terra Luna blob happened there were so many missed pricings everywhere because everyone had some assumptions about the price of Luna on many different chains because everywhere and then people just reaching Havoc uh I remember Venus Marcus got here pretty bad by that one yeah I think we see a large number of things where in the traditional security world you you hear about like the zero day versus the the well-known exploit that's been out there uh things like the profanity key generator that yes if we were the first person like one you should have reviewed it two if uh you were the first person to fall prey to that yeah that sucks but everyone else who suffered from that and hundreds of millions of dollars lost after the well-publicized exploit existed and clear way to mitigate it existed uh that is a failure to stay up to date on on threat intelligence and and act quickly which is a problem of not knowing all the components of your ecosystem like your asset inventory and um having a procedure in place for handling this kind of crisis I don't know if we want to get into that more because the Luna uh X not even exploit the Luna threat was known for four years publicly and people chose to ignore that and some people weren't informed on that but I don't know if I don't know if it's worth exploring that but I mean a lot of very prominent folks among them like investors security researchers had were very vocal from you know months or even years prior uh about about this class of of economic attacks we're talking about economic attack now uh and in fact there were warning signs right because there was um there was a I don't remember the details but there was an attack six months prior or something against um one of the other coins or assets or something in the Terra ecosystem and the price kind of It kind of deped and then went back so there were like warning signs ahead of time as well yeah what I found interesting because I've talked to a lot of people about this incident because it affected a lot of people um so can we can we recap the inside yeah sure so it is a notable security it is a notable security incident so um it basically uh this Terra Luna um uh design protocol was basically it had a mechanism to mince a a so-called algorithmic stablecoin uh where you burn the The Sovereign asset uh Luna in order to Mint uh UST which is supposed to be packed to a dollar and the idea there is that you'll always be able to redeem it for a dollar's worth of luno which then gets minted um if this sounds like circular logic it's because it is it is uh so many including myself have been vocal publicly about the death spiral uh inevitability of this design and I don't think anyone expected it to get as big as it did but what I find quite interesting is that um not only did I would say people who are less informed in the space who it is not their job to maybe know better you know okay it's understandable that they didn't understand that would happen uh um and they were kind of sold a risk-free thing that wasn't risk-free um there was very professional Traders um and other people in the industry who also thought that this would not result in a death spiral they thought it would work and they were in it um it's like it's like looking for a perpetual motion machine you know it kind of keeps moving until it stops yeah so this was I think another this was actually I think more example of like the the hubris of success of the bull market where everyone was like oh we've like solved like we stopped money financial problems we've solved the perpetual motion machine it's going to work it's working and it got just like really big um and it was It was kind of just destined to not work but um so so something else that's new since the last Devcon which and this is actually the the aspect of the Terra Luna situation that I find the most interesting this goes back to composability which we talked about before it's the intertwined nature right it's that we have now assets built on top of assets built on top of assets and so when one failure occurs right three four years ago if something broke it didn't cause this Cascade effect throughout the ecosystem and actually in the case of Terra Luna it was across multiple ecosystems right I mean Bitcoin began crashing and there's a whole reason for that they had this Terra Luna Atari Terra Foundation guard um uh treasury that held Bitcoin they had to start selling Bitcoin to defend it but this um uh what's the word for it this uh uh contagion yeah the contagion that spreads throughout like this is a new class of economic risk that didn't exist before I think we need to understand it better because it will happen again but I think contagions existed in in tradify for quite a while people are well aware of of contagion and but you have something like like Central Bank to kind of like perhaps contain it and and uh and limit it which arguably is not good for the long-term economic uh viability of traffic markets and perhaps it's better uh with D5 for these to kind of play out and just kind of like it's almost like a forest fire Just Let the Fire Burn everything and then regrow everything versus just kind of keep these like sick trees alive forever like we have it in web 2. um so one thing that I want to kind of touch on with the hotel incident is because we're touched on it's this idea of like the illusion of like security uh which is actually very dangerous we had the lfd reserve we had people like jump and Delphi and many prominent people kind of saying hey we know about debt spiral we have a handle we have six billion dollars of BTC we're going to buy everything and it's going to be fine and uh I think many people looked at and said okay well jump has a lot of really good quantitative researchers I assume they did that kind of modeling I assume they they run numbers and we're like okay this is probably work when it turns out no one knew what they were doing so how exactly do we do we like mitigate this particular uh class of like issues I think it's very dangerous when you have a situation where people know an issue can occur and then people also think that other people who are very smart also know this quicker and we see all type of spark contracts like when Alameda jumps into the smart contract I think people tend to assume that because they're in that spark contract they've audited it and they they know what's going on they put 100 million dollars into it they probably does happen in reality there's like several examples Alameda is GTO spark contract for yield and there's been critical bugs in that spark contract which is just kind of insane uh and it just kind of goes to show you that like yeah you really cannot rely on like reputation Authority in this space to make your decision making and that makes things very difficult I think for the average person working in D5 because people who are not experts in systems rely on Experts and those experts have been showing time to come and again to not be doing proper due diligence on their own there's a range of attacks that have happened where the system as designed was a good design and even as deployed initially was a good deployment there was uh forget which Bridge it was that had nine separate validators that they collapsed uh Ronin sorry running yes yes they collapsed it down to smaller than the the blast radius number and well they so there was four four validators controlled by the foundation and five were independent and then there was basically it was a usability problem so uh withdrawals were happening too slowly so one of the by the way the four run by the foundation were like all in the same AWS machine so they were basically one and then uh they convinced a fifth one to give them like temporary permission to like sign for them so basically five of nine were running on one machine which got compromised um yeah so that was like okay we started with good practices and then like we the the I think the term is the normal normalization of deviance it's a concept from like aerospace engineering so one of the interesting things about crypto is and a lot of people I talk with uh come up with the same thing is uh if you're deploying an immutable smart contract and there's reasons why you want to be immutable um protection from Forced upgrades uh malicious Insider of everything else but if you're deploying in a mutable system you're really in the same safety regime as Aerospace nuclear engineering everything else not something similar to normal software engineering and you need to have procedures in place for for that kind of ecosystem where traditionally you have more way more design work than you have implementation lots of review you have review of your review process feedback on that and it's very different than normal software engineering and that's not really how stuff is built in the broader ecosystem super briefly as a developer to speak to this this is really hard right most of us I'm going to say us I mean core developers also application developers we don't have this background or this training um these practices have begun to spread a little bit through the industry and we do now have folks contributing to projects like ethereum who have backgrounds and things like Aerospace but we need way better education around this stuff I really strongly agree with that to that point and to an earlier point about Trad Phi uh in the tradify world there's something called ratings agencies this doesn't exist in crypto in in Trad fi you pay professionals to evaluate the risk and give it a rating of a financial asset not even a security not even security wise there's also security ratings and certifications as well um but so we're missing that in crypto there's no uh professionals that are actually actively monitoring even the economic risks of these various systems the thing that defy has that tradify doesn't have is real-time transparency and auditability so if you look to the uh 2008 housing crisis that was basically you know a series of packaged and repackaged and repackaged debt instruments that uh eight layers deep nobody could see through to what the underlying was and they just trusted that the ratings agency that gave it an A plus that everything was a plus turned out there was a bunch of you know F through a uh debt within that package which caused people to basically buy risk that they didn't know they were buying with D5 we have that real-time transparency but what we were lacking right now is uh basically professionals that evaluate that risk and give ratings on it or give metrics on it so I'm seeing um the beginnings of that happening I'm seeing a couple of projects that are focused on becoming this risk Oracle risk engine um so I'm excited for that in the future because you know we will combine this transparency and D5 with uh the the various ratings mechanisms or risk evaluation mechanisms that are coming up massive massive massive opportunity seriously anyone out there who's interested in this stuff who has a background in finance who's inclined this stuff is sorely needed and there's huge lack of the stuff in the market today it's a huge opportunity like work on it talk to us we'll we'll help you make sure you're talking to the right people yeah actually funnily enough uh like talk to him yeah yeah so so Auntie which was the project I was briefly Dev on is essentially trying to do this in a in a decentralized way um I I think that one of the issues with having uh kind of like centralized risk Auditors um is the fact that they are foul we're not saying decentralized earthquers are perhaps better it's just the entire system as a whole I think uh is fallible to some level of human error and any kind of appeal to Authority I think is kind of dangerous I mean just because we have Moody's this period doesn't mean that tried fly is is immune to like contagion stuff like that like it'd be it it it definitely isn't like like these companies uh I guess like the issue the thing you haven't tried fight of in D5 sorry I'm kind of rambling at the here is you have this kind of like Fail-Safe mechanism the Central Bank who's able to kind of rescue everyone in case everyone gets a bit out of control uh and I I am not sure if if like Moody's makes things like that much safer uh it's probably better than having nothing at all but it definitely is not like ideal solution and it probably is is not going to work uh that well for for D5 where we have no safety net we probably need to be a bit more robust so the big problems with rating agencies is that they don't have any skin in the game so what I'm really bullish on is Insurance uh and other types of systems where they're underwriting the risk rating that they're giving um so there's lots of different ways you can do that whether it's with a regular insurance company which is what ever toss does or various defy mechanism designs this is something that I've researched very deeply and seriously if anybody wants to work on this come talk to me because uh yeah they're I'm aware of some very interesting things there yeah we do underwriting for a lot of problems for technical risk and projects for practical risk and things like that and the problem with how much can you trust a software audit or a software Security review Auditors actually hate the term audit when applied to their their work product uh but um how do you trust different firms and honestly every firm I've talked to can do great work the the thing from an insurance and a Reliance perspective is you really need to look at the the like the the worst work that they'll pass and make sure that that is high quality because if you're going to just blanket trust the security review performed by a firm you really care about their internal Quality Control process and knowing that if somebody's it's a new system where they're not already expert in it or where perhaps they don't have their they're very busy one of the biggest problems in the security review industry is it takes three to 18 months to get queued up for a security review at a lot of these firms and as a result there's a huge pressure to ship and then get your review done while it's in production or get your review scheduled before you're finished building it in which case you haven't reviewed the system as it's deployed so one of the critical things that we absolutely as an industry need to improve is better tooling but also more Security Professionals in the industry so that we can do more of this stuff in parallel because every project out there needs to have this work done and it's a contended resource and you you absolutely want to be one of the ones that gets a Security review and not one of the ones that's waiting while you get popped I don't know if we want to touch on something that we've kind of uncovered which is that technical Auditors are basically expected to take on this role of doing an economic audit as well and they're actually not the best people to do that right they've they've categorized the known economic attacks but um for instance the mango Market attack which just happened yesterday was a blatant Financial Oracle manipulation attack they manipulated if you're not aware mango got drained for about 100 million uh the attacker increased the price of the mango asset by manipulating the price of mango across various markets and then borrowed better assets than mango against that unrealized position um and like the a technical auditor could have looked through the mango code and the mango team is super smart uh and and you know everyone involved like is you know knows what they're doing um but like this was a uh this is a very uh you know weird Edge case that somebody with a Financial Risk perspective would have been the only one that would have caught that just to be clear there are folks who specialize in the financial side of things so shout out to Gauntlet shout out to block science right they have tools uh they're experts in this but those are the only two I know of whereas there's dozens of Auditors who are like you're describing technical Auditors who I think would not have the sophistication to catch this category of bugs so again yeah yeah uh yeah so so one thing touching on the economic audit I do know some auditing firms that now do this kind of auditing separately and actually there are like for instance compound and Ave will will retain people to do ongoing economic Audits and I think it's very necessary to be able to adjust the parameters of your protocol uh it's subcategy centralized way of course to it to adjust for the changing kind of parameters of like what's actually in that protocol because otherwise you get into situations like for instance mango markets um if you're not aware this is a very Capital attempted attack it took I think around five or ten million dollars of the user own Capital to that attack and the thing is like I think most people looking at Mega markets are like oh this protocol has 10 million dollars in it when it was audited is Oracle attack is going to be very expensive to pull up it's not worth it once that's 100 million dollars in it suddenly Oracle tabco very viable so you actually need like a real-time update of these parameters over time to maintain the safety to the protocol and that's something that's kind of missing except with like kind of like a tier one or S tier protocols in defy right now yeah I would say another interesting thing that's happened over the last three years is the rise of the consumer nft space which is bringing a lot of new people into the space that that really are they're from an art background they're not people who are software engineers in a lot of cases who think about systems failures even if they don't think about it from a security perspective they think about software bugs uh so there's a lot of people who really don't have the um the background or the the experience to to know what to be afraid of just sort of like naturally and we haven't built as an industry the right tools to make it safe for people to do things without understanding all the details of how it works like there's a lot of people who drive cars who don't know that much about how airbags work and seat belts and everything else they just know if you do it you're probably okay within certain parameters we are nowhere near that level of uh professionalism and reliability in the in the space and we'll see all these people that are that are new to crypto because of they've come in through the nft world and they fall prey to the same issues that that happen to early regular crypto users uh 10 years ago and are largely mitigated by Community knowledge and tooling that there so it's kind of scary that there's the the high end of these D5 vulnerabilities are showing new classes of attacks but some of the most basic things are happening to a new class of users right now as well so I think a notable security incident along these lines is like owners of board Apes revealing their private keys to social Engineers on their Discord and losing their Apes um you know I think you're right Ryan I think like it's incumbent upon us as designers and builders in this space to like build better tools and and install some of those safety rails or airbags like you're talking about but I just want to highlight that as someone who thinks deeply about this and has been working on this for years there's a tension here right because the easiest way to install safety rails is centralization right is to say yeah you know for my grandma like maybe she's not gonna really effectively manage her private Keys maybe she's not really going to understand a ledger or a multi-sig so maybe the best thing for her to do is keep her crypto on coinbase and and Outsource custody to someone else and that in some respects is antithetical to like the whole reason we're here so there's no easy solution to this but I just want to highlight that tension and that's where I approach this as a protocol engineer as a developer yeah I think kind of a good balance between this is that the base protocols really stay true to like the tenets of crypto it should be decentralized such a persistent uh permissionless all this stuff so Bill can build it on top of that and I think that it's kind of on us to educate people on the right right on board themselves like Grandma should not be probably creating a metamask wallet I think that's generally something that is is uh is difficult to secure I think for the vast majority of people uh and in the current situation as we see with the Mt space that uh like there's no way we can onboard a billion people into crypto with the current state like people uh like it's just like it's just gonna create like a Feeding Frenzy for the Piranhas that are constantly looking for ways to steal people's money so we need to figure out these more robust wallet systems for these people uh and I think that's probably uh a better compromise we want more people through like let's say a kind of abstraction wallets or or some kind of like non-custodial wallet solution with the hypervisor protocol layer which manages signing and policy networks and then we keep kind of like the more bare metal like quote-unquote riskier but more permissionless wallets for people who need them but one of the things that scares me is while these these losses might be relatively low a small dollar values relative to the larger G5 particle hacks and things like that uh the number of victims is very high and politically if you have a lot of victims that individually like lost event of any kind and it makes it very easy for Regulators to point it at like a grandmother who's lost something or it otherwise unsophisticated user who felt prey to some some system or possibly was scammed and then pushed for regulation so we have the centralization risk as a as a the potential to use centralization as a countermeasure to a lot of this stuff is a risk of centralization but also acquiring a very very bad public relations nightmare as well as regulatory nightmare is also an existential threat to the the overall industry cool do we want to open up for Q a five minutes yeah yep three minutes okay we have time for a couple questions anyone have any questions how are you excellent well you talked a little bit about the counter instruction uh so he wants to know if you talk a little bit about that because I think that it's like their solution to have like easier Coastal systems without depending on I mean self-costal systems without depending on centralized entities so what do you think about that and how we are advancing and when do you think we will be able to have that for the General Public so I think there's like two classes of fraction um so just to define the term very generally kind of abstraction is essentially when you make no distinction between smart contracts and a little while it's on ethereum right now individual wallets are fundamentally different than smart contracts because individuals are our public private key pair smart contracts are are derived very differently and I don't say I tend to go into that right now but in a kind of abstraction they're basically the same smart contracts individual or smart contracts and we have the ability to do that right now with things like like multi-six which obviously are somewhat valuable and in the future we may eventually end up doing uh doing away with the distinction entirely so people with roll ups were trying to do that but eventually ended up deciding not to because uh you know making these kind of protocol level changes just made it very difficult for ethereum developer to kind of compose and build on them um but nice thing about kind of Attraction the design space is is very wide people could do things like multi-cigs they can do things that are much more complicated like have like off-chain oracles that you know involve human beings process and do basically kind of the sky's the limit in terms of what people are kind of building gear one interesting project that's kind of uh actually never mind up yeah sorry that's not quite a yeah so we built this for space mesh okay we built a cat abstraction I think we may be the first layer one maybe the second near has something similar uh it was really really really really hard to your point it had very deep profound implications and ramifications on the protocol uh but it's a very powerful primitive and it means that the really simple way to think about this is every account by default is a multi-sig and there's always multiple Keys associated with it again this is also the case in near so shout out to near for kind of like pioneering some of this work it's a very important primitive and I think it will go a long way towards addressing some of the kind of classes of attacks we discussed here one last question maybe we have time for one more last one uh so I would like to ask which security incidents in your opinion was the most impactful not in terms of value lost but in terms of sending cripples across the ecosystem which was the most impactful not necessarily in terms of the assets but like on the overall impact of the ecosystem okay the first one that came to my mind this actually touches upon a point that Ryan made a moment ago which is that it's not necessarily as you said as well about the total amount of funds um but it has more to do with the the number of people impacted and the sophistication of those people um there was a hack in a Solana ecosystem wallet about four or five months ago does anyone remember the name of the wallet slope wallet thank you uh and what happened here was a bug in the wallet that exposed the private keys because of some Telemetry kind of tooling uh very common I think it was called Sentry or something I think we actually use it in in space mesh as well and the reason that I find this one so impactful is because this was the actual total number of funds was very small and I think it was eight or ten million dollars worth or something so it was like maybe even less than that but it was thousands of users who were impacted and each of them had a very small amount of money in their wallets and they woke up one day and their funds were gone that I don't think has ever happened before that particular class of attack and everyone was panicking and no one knew yeah it was a very scary attack even scarier about that is no one knew which wallet it was because a lot of people were reusing seed phrases across multiple wallets so they thought it was a Solana base level vulnerability or something it wasn't even localized to a wallet it was very scary watching that in real time just PSA because apparently it needs to be said do not log private Keys into your logger and also use Hardware wallets okay this this classic attack is not possible with a hardware wallet that too um I think probably the most impactful on the space has been the combination of the UST collapse which led to the three arrows collapse which led to an entire uh collapse of the crypto credit markets and has really raised a lot of red flags with Regulators like we've seen a lot of regulatory pushes because of that combination of UST and three arrows um and that has impacted a lot of uh you know non-cryptonative folks who have sold a risk-free USD interest rate um so it did happen to be a large dollar value but it's having heavy political ramifications we're out of time for the final remark Aaron uh plus one for UST plus one for Solana thank you this was really I learned a lot I hope you guys did too thank you very much to everyone else on the panel give it up people for Ryan Lane Tom and Aaron so and if there's anything to take away for your own products remember one Buck per thousand lines of codes yeah um I'd like to call forward shrey Jane with the longest Workshop title of the day working towards a plural public via common knowledge and designated verifier proofs give an Applause for our next speaker people [Applause] now working that's good okay perfect okay all right yeah about a month ago I was at a dinner with my parents at an Indian wedding and we were eating the food but there were no napkins on the dinner table not a big issue but if you've ever had Indian food you know that your hands get really messy and you need to have a napkin and as we were looking for a napkin asking the wedding venue staff we saw that the wedding party was getting really mad that there were no napkins in the venue and there was just a lot of emotion and anger being expressed at the time a week later I was with my dad at a coffee shop and we see this guy getting really mad at a barista and I said to my dad and I said napkin and because we had this shared experience of being at the wedding previously and we shared this context of what napkin meant not something that you traditionally label napkin with but something that we shared this context with I knew that he understood what napkin meant and I had this feeling that I could actually encrypt the word napkin in the physical world and only have the people who could understand it be the ones who were there for that experience and shared the context and I could actually draw this boundary around who would understand it and so I wanted you to get you all to think about some of these dictionaries that you may share with your friends your family or your co-workers that may consist of idioms symbols or these inside jokes that let you communicate incredibly efficiently with one another but not only do they let you communicate efficiently they actually have a boundary on who understands that dictionary and so if you've ever studied information Theory you may have heard of what's called The Source Code theorem and there's this concept called Hoffman Coatings and what Hoffman Coatings do is they let you take all the information that a computer needs to read and collapse it down into the minimum number of bits necessary for that computer to process the information well with these dictionaries that you build with your friends your family and your co-workers you can also communicate incredibly efficiently with anyone who's inside of this boundary and anyone outside requires much more context to interpret what you're saying but this doesn't just apply to inside jokes or idioms it applies to things much larger like let's look at the field of medicine as an example so of all the medical literature that exists in the world Colombia has said let's take all this literature and collapse it down into a set of texts that Colombian medical students will need to know and so long as they know this literature then they can communicate with one another and potentially among other assessments practice medicine in Colombia and so if I go up to a physician in Colombia and I say cardiac endoparditis I know what they know that cardiac endocarditis means something in the medical terminology and anyone outside of this field may require more context but does speaking this language or having this terminology allow you to be part of this group well no like if I read all this medical textbooks it doesn't make me a doctor nor does reading the Bible make me a Christian or reading legal textbooks make me a lawyer but what these texts are very powerful for is they let you communicate incredibly efficiently with people who are inside of these communities and so another problem that you may see is like let's put three scientists on a panel uh biologists an economist and a sociologist who are all aimed at talking about how to solve climate change and they each come onto this panel with each of their own dictionaries with each of their own peers and what ends up happening is you end up getting the most high level abstract communication possible and we don't we lose the richness that comes from each of these cultural communities and so what I've tried to do in this brief introduction is introduce some of the primers to the concepts that we'll be diving much deeper into into the rest of this talk like context collapse common knowledge and boundaries and this work is titled plural publics at Microsoft and his joint work with Glenn Weil York Rhodes and Divya Siddharth and I hope by the end of this talk we'll have a very tactical approach of how to build systems that can achieve common knowledge protect boundaries and also rebuild the context that we've lost in communication a lot of this work is influenced by some of the early thinkers like John Dewey and Walter lippman who've taught a lot talked a lot about the plural publics as well as what it means to have informed decision making Dana Boyd from Microsoft research who's talked a lot about context collapse and I've had the pleasure of working with Joseph Halpern from Cornell who's done a lot of the early thinking on distributed systems and common knowledge and so when we talk about pluralism there's many different axes of pluralism there's one that felt most right to me it's about as a builder is how can we build systems that facilitate cooperation across social differences and so the way that I'm going to structure this talk is we're going to first focus on cooperation and then we're going to tie it back to social differences at the end and so at the beginning of this talk I said something like I know that they knew what napkin meant and so what was I trying to say there well there's this concept in Game Theory psychology and computer science called common knowledge and a fact is said to be common knowledge if everyone knows that this proposition is true everyone knows that everyone knows that this proposition is true and everyone knows that everyone knows everyone knows that everyone knows its proposition is true and when I first read this it didn't make much more sense to me as to what common knowledge was and so let's walk through a quick example so I want you to imagine we have two generals here a general on the left called General a and a general on the right called general b and their goal is to attack in the valley of this mountain in a coordinated way and the only way that they can communicate is through a messenger and this messenger has the possibility of getting lost in this Valley and so let's let's say General a says to General B let's attack at 6am do they attack no because General a doesn't know that general b got the message let's say General B acknowledges the message do they attack no because general b doesn't know that General a got the acknowledgment let's say that generally acknowledges the acknowledgment General a doesn't know that general b got the acknowledgment of the acknowledgment and so what I'm trying to Showcase here is that if a messenger can get lost we're unable to achieve systems that can obtain what's called common knowledge but maybe we don't need common knowledge maybe we need something as close to common knowledge as possible and that's often referred to as what's called common key belief it's a as close to form of common knowledge that we can attain in systems where communication is not guaranteed and so let's let's now relate common knowledge back to these concepts of coordination and cooperation so coordination is when you have a set of Agents take action simultaneously cooperation is when these agents take action simultaneously but also understand the payoffs that come with these actions and so cooperation studied and economics and psychology has been broken down into two key subtypes altruistic cooperation and mutualistic cooperation so altruistic cooperation which is a fascinating topic to psychologists is when I incur a cost of myself to the benefit of others and why would we do this and so we've been studying these concepts of emotions that relate to reciprocation like trust empathy gratitude and we don't probabilistically measure these emotions we can categorize them I don't trust you with 20 accuracy I either trust you I don't or I really trust you I really don't trust you and humans are able to categorically depict the set of emotions in these categorical ways but mutualism what I think is what we often talk about in the web 3 ecosystem is when I take action you benefit but so do I and this problem is not as much of an emotional one related to trust or uh gratitude it's much more related to what's called an epistemological problem how well can I measure someone else's knowledge and in a lot of the psychology and research both empirically and theoretically we've seen that not only can humans categorize emotions but we can also categorize these levels of knowledge that people have so I in an example of this I know that I sent you a message I know that you I sent you a message and you got the message I know that I sent you the message you got the message and I know that you know that I sent you the message all the way up to these rich forms of what we talked about earlier being common knowledge and in these experiments it's in the physical world that people have run it's when people have common knowledge the most rich form of knowledge that the probability of taking action is much higher and everyone benefits much in a much richer way as well Okay so we've talked nothing about web3 so far we're going to get there I promise but what we've highlighted so far is that common knowledge is a critical component to cooperation let me walk through a brief historical explanation as to why we lack common knowledge today so we we talked earlier about the common p-belief and why we lack it in the coordinated attack problem and I'm going to work through two key axes of communication right now one being knowledge and the second being privacy and so when we communicate in these physical in this physical world and I have a messenger privacy is not guaranteed I this messenger may go and leak the message they may not say the message in full and so privacy lacks and my commentary belief as we saw earlier is weak we then move to forms of writing where at least I know whatever I write on the sheet of paper is going to get sent to that person but it still doesn't solve these problems of common key belief or leakage and after 50 years of the envelope being used for uh packaging gifts in Japanese culture we finally found ways to use it to package messages this improved privacy but still didn't improve the way we communicate for common knowledge I'm going to skip through forms of radio Telegraph and move to the ways we communicate today like SMTP for email SMS for texting or xmpp for WhatsApp or Telegram we can achieve these forms of common p-belief but they're actually quite hard to do in an interface level and I'll explain why in a second and as we've seen in a lot of these centralized settings we still lack the Privacy that we want to achieve as well and so my question now is where does a distributed Ledger play a role in all of this or a distributed Ledger being the key word here distributed Ledger does not imply blockchain and so where we've kind of come to in this setting and if you've been to a lot of the talks today clearly there's something going on with the relationship between zero knowledge proofs and blockchains it doesn't mean that the you need ZK to work with blockchains you can do it without but there's a rich ecosystem of innovation going on there where does communication play a role with distributed ledgers and Joseph Halpern who laid a lot of the work in distributed ledgers has said that if we can satisfy two Key properties of a distributed Ledger then we can achieve weak forms of common knowledge the first being what's called T consistency meaning a prefix of my ledger is a prefix of your Ledger and the second being what's called Delta weak growth which means that within a Time Delta I can add some information to each other's histories but let's make it much more clear like what exactly will distributed ledgers play a role in The Next Step of human communication well the first is that they actually are easier to build an interface on to achieve common pay belief and we'll show why that's the case in a second and the second is that we can actually provide a commitment to knowledge when we communicate so an example of this at Microsoft what we did is we switched the way we communicate from emails and Excel spreadsheets for our supply chain and started to use a blockchain because at every step of the inventory process we had common knowledge about the inventory who was where what was where and everyone knew that everyone knew that everyone knew we were able to save a lot of uh retroactive issues that we normally face and in fact this led to a savings of 50 million a year and one of our many Supply chains of our Azure stack what are other examples of where we could use this well we could use it for reporting for Social Action social movements or reporting on sexual assault cases whistleblowing whenever you need to have these coordinated attacks and it's really important to have common knowledge it's protocols and distributed ledgers that do this in a really nice way with these two properties that I commented on earlier and the second part is that blockchains sorry today in communication we lack a commitment to knowledge communication is very accessible very free in a way that is good but also with cooperation purposes leads to extendious extraneous amount of communication to get something done what's really interesting about what's being explored in the web 3 ecosystem is how we can program these commitments and the way we communicate and so there's a protocol that was a while ago called ethereum whisper some of the core team there went and Built This research project called the VAC P2P Network where they reveal part of the vector on an elliptic curve from your public key to your private key as you start to send messages over a threshold limit to prevent spam and so there's an actual programmatic commitment that you make with every message you send we're starting to see Community currencies or tokens with regards to governance play a large role and how can we use these tokens to stake when we want to communicate with regards to cooperation purposes okay so what have we said so far clearly common knowledge is a requirement for cooperation if and if we want to cooperate we need to do so in a very rich way and we've walked through this historical example and now we can see why there's a case where we might want to explore with distributed ledgers to communicate for cooperation so now we got the cooperation box checked let's now figure out how can we do it across different sets of people but if we want to cooperate with another individual the first step is being able to recognize who are we cooperating with and in the web 3 ecosystem decentralized identity is its own Suite of problems so earlier this year we put out a paper that tried to exhaust a lot of the work being done on the decentralized identity Frontier and we looked at different Primitives and we look at what what needs to be done to identify an individual what becomes even harder is how we identify a set of individuals how do you put a boundary around a group of people and so let's talk a bit more about why we've lost boundaries today in the way that we communicate so in the past we had these very rich forms of tribal Dynamics whether it was literally we were part of tribes or was religion and we had a very clear sense of who was inside of a group and who was outside of a group and these strong tribal Bonds were quite good with respect to communication communicating quite efficiently and we understood each other's dictionaries quite well but these tribal Dynamics were quite oppressive to certain subgroups and so we started to find ways to liberate these individuals but some would argue we've gone so far so that these individuals now feel lonely alienated and are communicating on systems that try to rebuild these bonds like social media platforms that have done so in a way that lack context and so what is context here it's I'm communicating to this invisible audience that lacks the context to understand the dictionaries that I communicate with with my peers and the thing that we like in communication today is collective disclosure we talk a lot about I choose to disclose I disclose this I do that we don't have enough of we collectively can do things with strong guarantees so now let's talk about some tools that we can use today to go and do this so I want to introduce to people if you're not familiar with what's called designated verifier proofs there are a set of proofs that say instead of proving X let's prove Alice will prove the statement either X is true or I am Bob again it's one of those things that takes time to sit with so let's walk through an example to make this much more clear let's imagine we have two dials the CIA Dao and the KGB dial and the goal of these dials is to prevent a double agent problem so meaning that I don't want my agents if I'm the CIA to be spying on myself for the KGB and the KGB wants the same things happening for them let's develop a scheme that makes us much less accessible to the agents so let's say I'm the CIA and an agent wants to go and turn on me and I am I'm unaware of this and they want to go to the work for the KGB so agent a goes to the KGB and says hey I'm part of the CIA and I want to work for you naturally what does the KGB need to know they need to validate this information it's very critical that they validate this information with high validity but we want to mitigate the CIA that this agent can go and do that so how do we do this so we're now going to walk through the designated verify approved scheme we're not going to go through the technical details here but if you want to you can come up to I and someone who I'll introduce in a second in a minute but the way that this works is we have two two inputs the first is that the CIA now actually makes a claim agent a is part of the CIA and so they have this registry that exists of all the agents that are part of the CIA and so they can pass it through this circuit with and signing it with their private key that they're part of the CIA the key thing to recognize is that there's an or gate here and so this constraint can be satisfied by either the CIA actually making this claim or agent a private key can also make this message and so let's walk through why this is so important so again the CIA can make this claim or two the agent a can make this claim and we won't know which one it is but agent a knows that the CAA doesn't have their private key so if this if this circuit satisfies with the output of one then it must be the case that the CIA made this claim and the agent a is not lying and so to a third party they don't know who made this claim whether agent a is lying or the CIA actually said this message so the only person who's persuaded by this information is actually agent a because they know the CIA doesn't have their private key and so what's the bigger part of all of this well you can't ever prevent someone from sharing information but you can prevent that information from being persuasive in its shared form so we can mitigate the belief that this has in its shared form and so um what we start to move towards is what's called Collective disclosure and so let's work it through a much more web 3 example of this now let's say that I'm a Dao and we have a secret that we want to keep within the Dow Dows today are quite leaky we lack systems to communicate and put boundaries around communication and so I tell a secret teacher the members of the Dao I say hey we have a secret but we want to make make sure that the Integrity of this information is withheld with very strong guarantees within this Dao and so we issue a DVP to every member of the Dao with this secret and let's say for example here agency wants to go and communicate this to another doll but because we issued this through a DVP that third party won't be persuaded with high guarantees to that information but now let's say we want to collaborate with another group what we can do is we could have some internal proposal to say hey do we want to share this information with agent D if so let's issue a DVP again with our our wallet and they have agent DB part of that claim so now agent D is persuaded because they are part of the designated verifier scheme so I also want to credit here Enrico potatzi who's here and it works for polygon ID and we worked for through this and built some open source tools that allow people to go and build these schemes today as well and so what we've tried to highlight in this talk is that we have systems that can be built to achieve common p-belief but they're not as attainable as they are on distributed Ledger Technologies as we've started to see and we want to keep experimenting on that the way we've tried to rekindle these bonds between people to build and re refix context collapse has been quite weak and we need boundaries so that we can have these forms of intelligence and collaborative work across communities and so some experiments that our team wants to run with the communities is let's go and build a protocol where every claim for a DVP is with every claim within a dow is issued through a DVP so we can start to have some structure and maintain the Integrity of information within Dows let's play with other commitment schemes with Community currencies revealing vectors on an elliptic curve for how people commit to knowledge let's also build tools for anonymous reporting where if I want to come forward about a case I can do so in a way that first of all can leverage their knowledge technology but also attain common p-belief so I know that other people are also going to come forward and they know that I will come forward but do so in a very protected way where we have a boundary around these claims and Via DVP and this can apply to things like social movements as well and so what I've tried to walk through in this talk is that there's something clearly quite powerful about blockchains but none of this had anything to do with staking Community currencies defy it was literally all about achieving knowledge and I think there's something really interesting about these cryptographic Primitives and something quite powerful but we've yet to understand how we can interweave these Primitives with the value that cultural communities can add to the community and so that's some of the work that we're trying to be building and working with the community to do that and so thank you foreign [Applause] we have a few minutes for a q a are there any questions from the audience don't be shy yeah in the middle over there um how was what has been the process for connecting with communities yeah I think right now because it's so early the work it's been I think Enrico and I only release a lot of the DVP stuff in the past two weeks so it's been small Outreach to the communities that we're part of but part of being at Dev con was like reaching out to Dao's here and talking with them to see is there an interest in working with these DVP schemes and again I think part of even me speaking here today is to have the audience or people who watch the recording to come and work and find us to find ways that we can just be of value all of the work we're doing is an open source and so the goal is to just see how some of these ideas can facilitate some of the outcomes with the communities we're trying to work with and so we would also like guidance on how to work more with the community as well and are you focusing on dials then and crypto communities or also outside of crypto I it's really anyone who's like very motivated and as we can see with people here these web3 communities are very interested in experimenting with these tools so naturally it's a very nice vehicle to explore with a lot of these ideas and so the the Target right now has been webbed through communities yes okay anyone else and if there's oh I see another question and if anyone has any of the more technical questions I would love to work with everyone we're going to be in the ZK Community Hub on the main floor as well later in the afternoon so we can come and chat more about some of these DVP schemes as well there foreign I was thinking how is that applied to ethereum conference so I think there's a context there's commitment for example when I go to buy the ticket for the for this conference uh is sold out within seconds later very fast but at the same time I have no idea how many ticket was been sold and so there's any uh anything from your talk that can help the ethereum foundation to to organize a better conference in the future yeah it's uh it's an interesting problem I think I'd want to think a bit more about it and if I do I'll relay it back to the community but I think in general anything that applies to a large group of people taking actions simultaneously so it feels as though you have teams or organizations that are all trying to get tickets how can we do so in a way that mutually benefits everyone I'd have to think more about it but I'll get back to the EF if I figure out a way that we can apply some of this to that problem foreign I I was just wondering if you could give a few more real world examples of this being obliged besides the KGB CIA Dow yeah I guess um I think like one example is like let's look at reporting internally in big tech companies in general for like sexual assault cases we want to make sure that when we so for the common knowledge scenarios I want to make sure that if I come forward other people are also going to come forward because the risk is always on that first individual a much greater degree than any individual that follows so if we can coordinate in a coordinated attack way on a protocol that facilitates common knowledge the probability of each person taking action simultaneously will be higher but in the context of let's say what you're talking about with the KGB for dvps being a bit too strenuous even if I take any communication channel for any celebrity or any person who's high profile um let's say I'm the president of a country and I communicate with my peers I may not even be saying anything that's secret or relevant to National Defense or putting other people at risk but saying this information to an outside Community can be interpreted with the wrong context and so the only people I want to be persuaded by this information is by the boundaries that I draw on the people who have the context to interpret it appropriately and so I guess it's any communication Channel where people lack the context to interpret information and we want to mitigate persuasiveness to the third party foreign what happens if somebody submits false or mistaken information so if you submit so again like the point here being is that if I am lying then I'm lying and then the third party is not persuaded by I'm lying to myself basically but if the CIA let's say in this example lied there's no incentive for them to lie in the scheme if that lie unless there's like a broader set of incentives Beyond this like actual member registry or secret and so if I lie it doesn't do anything to the scheme because I'm just persuading myself in that scenario one final question in the front here g'day great talk uh in the KGB example uh does the CIA then not uh reduce their ability to assert their authority to the general public then well the point being is like yeah in that scenario yes where we but we maintain the Integrity of secret information within the CIA with high integrity yeah yeah thank you with that I'd like to call on everyone to give our Applause for our speaker thank you everyone thank you sir thank you and with that I'd like to call forward our next speaker of the day we have with us Isaac pataka to talk about exploiting inattention and optimism in daos let's give him a warm welcome forward back [Applause] see ya all right hello everyone I'm Isaac I'm a the co-summer of the logo style and I'm also a research fellow at uh at medigov and today I'll be talking about some real world examples of how Dows have been exploited uh one by me uh based on proof of inattention and just generally a lack of monitoring infrastructure so I'll be detailing how I was able to steal some money from a Dao how other people are attacking them even as much as like last night and how you should be protecting your infrastructure from this type of vulnerability so I've been referring to this as like proof of inattention um so attention is really the most scarce resource in Dao's um and so governance tooling should be designed accordingly there's all sorts of optimistic uh architectures out there that rely on people to actually pay attention and that sounds pretty simple but like people paying attention is not something that you can actually assume is is happening um so safe snap is uh an example I think is one of the most widely used optimistic architecture Tools in Dows which uses reality.east to bring off-chain gasless votes on chain for execution but molok towers are also have a lazy or optimistic consensus mechanism where there's no minimum core for proposals to pass thankfully they do require a sponsorship but these are just two cases of things where people could very easily sneak proposals by into Dao's while people are not paying attention so the main thing that I want to highlight today is about reality.eath I'm called on to set up many Dows and often people are like well why can't we just have gasless voting and use reality.eth to execute our stuff um and I think the assumption is that it's this like magical thing that brings reality and Truth on chain but that's not uh that's not inherent and so the way that reality.eath works is that uh anybody can ask a question of the Oracle that's like hey did this Dow vote to pay me twenty thousand dollars and then that goes in this really confusing uh format to reality.eve that you can see in the middle which is like almost impossible to decipher and then if you put down yes and nobody says no Then that just happens and so like it's not anything that actually relies on a vote having to take place reality.eath is a general purpose Oracle that you can use when attached to a gnosis safe to uh to take money so this is just a configuration of how that architecture usually works many Dows have noses safe which has multi-sig signers many Dows including things like one inch I think shape shift a lot of dows out there have that use a lot of voting on Snapshot have added this reality on each zodiac module when you add a zodiac module to your gnosa safe you're basically giving it super user privileges it can shortcut all signatures it can do anything with any assets in your safe and so you have to be very confident in how you've configured that so reality.eth is the separate application which brings the uh which brings the decisions on chain which get executed on your safe so anything in your safe the nfts the uh the assets the interaction with other contracts it can all be executed by the reality module and anybody in the world can ask questions of the reality.eth module so when you're setting something like this up there's a bunch of parameters that you can use to configure and it's important to understand the impacts of every single one of these because if you misconfigure one of them then you can make yourself significantly more vulnerable to an attack so when you set up this Oracle you want to set up a timeout this is the duration during which people can answer questions if it's 24 hours then your question is live for 24 hours and then whatever the answer is at the end of that period becomes the truth if it's a week then you have a week to answer the question cooldown is like a grace period after it but after the truth comes on chain but before it can actually be executed expiration is how long until it can how long it maintains stays valid and bond is how much you have to put down to put to make an answer and there's other configurations but I have some nice timelines that make this a little easier to understand so the way that we intend for this to work that a lot of dows intend for this to work is that they host a they host a vote on Snapshot um and then once that voting period is done there's a little button on Snapshot which says ask like uh bring like execute this and so that brings the that asks reality.ether question and then it goes to the pool of uh people that sit on reality.e and answer questions unfortunately there's like three people that sit on reality.ef and answer questions so usually it's the main person asked the question that also answers the Oracle and they tend to answer honestly and then execute so this is the intended scenario where you've got you've had your gasless vote you've minimized your on-chain transactions and then everything executed um according to plan so there's also the dishonest Oracle scenario where any attacker can pose a non-existent proposal to reality.eth and submit their own fraudulent answer so you don't even have to go to snapshot you don't even have to make the vote you can craft the transaction that's like hey did this snapshot vote which didn't really exist pass and then you put down a bond and say yes it did and then you wait the grace the vote the then you wait for that cooldown period hoping that nobody's paying attention and then congratulations you've been able to steal money from the Dow the there's a few different ways that Dows can protect against this there's of course overriding the malicious answer so reality.eth Works in a way where you put down a bond to answer a question you can put down double the previous person's bond to correct their answer and that can kind of continue Forever Until It becomes not profitable to put down those bonds so the best way to do the the easiest way to do it that reality.eath wants you to do is just correct malicious answers because you'll take the bond if your answer becomes the truth on chain um you can also request arbitration so if a dishonest question is posed anybody could trigger arbitration but what I've found in surveying a lot of dows on uh on reality.eath and snapshot most of them kind of skipped electing an arbitrator or they set the arbitrator to themselves and so like these very simple misconfigurations can make it so it's like uh well now we don't have an arbitrator so if we're not paying attention for a week all of our money is at risk there's also the opportunity to veto if there's a cool down period surprisingly also I've found that a lot of the Dows that I looked at in doing this research just skipped cooldown they were like now like let's just execute this as fast as possible so these are all things which may seem like logical when you're setting up Dao assuming like we're all going to be paying attention for our nft investing Dao all the time um but then uh people go on vacation your multi-6 signers go to Devcon they leave their ledgers at home and now you're pretty vulnerable so each one of these can be misconfigured and is often misconfigured so if your timeout is too short then it makes it too hard to catch a malicious transaction if your cooldown is too short you have no opportunity to veto if you have a low Bond it's trivially inexpensive somebody could put down a ten dollar bond for a fraudulent answer if you have no arbitrator then you have no final safeguards against that and and a absent or negligent multi-six signer removes The veto or opportunity all of these are actively being exploited even like yesterday as I was saying like this is a on a very much ongoing issue so first I'll detail how in the springtime I noticed a vulnerable Honeypot uh actually called like the image like Honeypot Dow dot ether something where I wanted to figure out how easy it was to actually exploit this so a little over a year ago notice put up this bounty they're like reality.eth is this great new module let's put fifty thousand dollars in here and see if anybody steals it if no one steals it then we can feel confident that this is uh safe but like so many things in in crypto it just kind of went under the radar no one really noticed so this thing's at dormant I have the address here and I'll share this after is that dormant for a little over a year no activity and so uh I I decided to try to exploit it but I was doing it for research purposes so I live tweeted the exploit to make it good and not um illegal so uh so what I figured out is like how to craft the exploit using the ad proposal feature on etherscan where you craft a transaction and in this case I was like okay I want this Dow to send me like 19 420 die and so I crafted the transaction locally and then hashed it and included it on the either scan link now a quirk of this is that you could looking at this proposal you actually don't know what my transaction is because it's only a hash of the transactions that gets asked to the Oracle so this is another of another scenario where like if you see a malicious proposal you don't even know what the attack was trying to do they could be trying to take one dollar they could be trying to drain the whole treasury but all transactions are hashed so that you you have absolutely no idea how what's going on so in this case I submitted a fraudulent proposal and then I went on to reality.eth and I paid 0.1 eth as a bond to say yes this is true it was fine for about 24 hours and then I saw a tweet from Oren I I uh cheekily called my proposal ID nothing to see here because I kind of wanted it to get detected I could have put a proposal ID which Blended in even better but I put like you know nothing to see here or found that funny I guess and so Oren and uh some of the other folks from gnosis were like hey it looks like somebody's actually trying to drain our our Nosa safe we should veto this um but much like the Nosa safe table earlier this morning nobody was present to veto the transaction so this is just and being a Honeypot Dao they set this up as like 24-hour periods whatever it'll be fine um I'll go back to my funny slides for pictures thank you but it was too late so uh at this point I was like on another call with another thing and people were like asking me questions I can't I can't talk right now I need to finish stealing this money um so I went on I executed it and I tweeted about that as well that I successfully drained 19 420 die from this gnosis safe um on uh nicely offered to give it back they said don't worry about it um so it was too late because arbitration could not be requested because their arbitrator was set to the zero address the cooldown was too short and I think one person was on vacation and nobody else on reality.eth was paying attention to refute my answer like Oren refuted me once but then I refuted him and put a higher Bond so I actually got his honest bond in addition to the exploit and so like this system yeah it's not perfect but then uh it was like quiet again for a while until like two weeks ago when people actually started using this to try to steal money so some folks from the Opium Network thankfully had some monitoring infrastructure set up on one of their safes and noticed that somebody was submitting um fraudulent proposals to try to drain their entire treasury um but being nice people that they are they were like is this attacker doing this to anybody else and what they actually discovered was the attacker first went over went after this like really easy target it's this Dao called like Lolly Dao it's never been used it's like one person but there was seven and a half Ethan of the treasury and they had reality.eath configured 24-hour voting periods no arbitrator no minimum Bond and so the attacker snuck some money into a fresh wallet I think they withdrew from like Aztec into a fresh wallet put down a bond and within 24 hours had stolen seven and a half eth so now they had seven and a half like uh stolen eat that they could then use to put down Bonds on other things and so there's this like nft collecting GAO called um there's this nft collecting framework called Seasons which uses Dows that set this up and some of them have like you know hundreds of me bits or like a bunch of stuff uh in their Dows and so the attackers started going after those so they used their eth to place Bonds on all of these other Dows saying did this pass did this pass did this pass and at this point like you could very easily flood the reality.ethui because it's like web3 UI and takes 10 minutes to load when you go to the page and it's really frustrating to use um so they put these like six proposals down they put down uh thankfully the seasons folks have done some really good configurations where they had a minimum one eth Bond a seven-day voting period And so that gave us enough time to defend um and so I was uh just like some of this was going on in the East security telegram Channel and chatting with like the seasons folks um I was able to actually go in and put down like eight eth in bonds to overcome the four eat that they put uh for theirs if they then came back and like put down 16 being like no I really want to steal all these me bits then I would have had to start like calling up some friends and be like can you guys please donate some e so that I can like defend these these safes from this attack thankfully they got scared and ran away and took their three Ethan profit and the attacker went away but this is continually continuously happening for the next week I basically had this screen open on my computer refreshing like every hour to make sure that the attacker wasn't coming back so uh it's uh it was a bit of a stressful time until they finally really gave up and I was able to claim their Eve and put the and make sure that the honest answer made its way Unchained so there's hundreds of millions of Dow treasuries that are at risk of what I would say are inattention attacks and in fact like reality.eth is like the one that I've been highlighting but there's molec dials that are vulnerable to the same thing and I want to include some links to uh so Skye sent me uh from for like a metacartel sent me a proof that he did of a molecular and attention attack where you know if you're in some molecules maybe you're in one maybe you're 10 maybe you're in like 60 of them and oftentimes like uh they go dormant for a while there's no monitoring infrastructure in place and so any member could be like um like sneakily submit a proposal while everyone's at a conference uh and I'm saying this to try to scare you to like look at your Dows and make sure no one's trying to take things from you while you're sitting here um I think that attacks like this are only going to start happening more and more frequently so beyond smart contract audits we need configuration audits it's not just enough to have the core logic right it's a matter of how you stitch together all of these composable pieces into something that is also audited and safe and so configuration audits are something that I really want to see become more prevalent in Dao is like whether it's uh the gnosis safe uh the no the safe app where it's like hey if you add these modules you might be vulnerable here or like hey you have like a green check mark this this configuration seems pretty safe for you and I know it's early but like these are things we should be adding before we have some sort of like trauma of like a bunch of safes getting drained so I have some tips on how you can protect you and your Dows from people like me and other and people that are worse this is a bunch of texts but I made this to like kind of uh take pictures and I'll post this out later um I think it's as somebody that has went through like a sock 2 audit with a startup before crypto stuff there's actually a lot of stuff from those processes that I think Dallas could adopt they make you think about what's your resiliency plan what's your continuity plan who has control over this administrative thing um who like is there some random multi-sig somewhere that actually holds veto power to the Dow that we're just too lazy to get rid of there's a critical need for more monitoring infrastructure so I know a lot of people are working on dashboards for individuals like track their portfolios and stuff but we really critically need more info like monitoring infrastructure for Dow tooling that can like you know wolf style I don't know ping you everywhere every time there's like some some sort of big transaction going on there's cool automation tools that I think are underused as well open Zeppelin has a tool called Defender which I really like for identifying dangerous scenarios setting up alerts and then actually submitting triggers to like pause contracts you can create these like Defender bots on that tool that look for like a malicious proposal or like maybe your Dow is going into sleep mode and you want to set up something where it's like okay if anyone tries interacting with a smart contract this pause transaction is going to go out and you can like pre-sign a transaction pre-load it and like have all these defense mechanisms ready to go for your communities uh I think it's also really cool to see that simulation tools are getting more used because I don't think I've seen an attack like this but I wouldn't be surprised if somebody submitted a proposal at some point that was like hey we should submit my monthly payroll but then they just add a zero to their paycheck uh that would be pretty hard to detect and most people that are like on a bunch of multi-sigs or like a proof approve approve approve but thankfully safe has added like tenderly simulations where you can just say like okay what would happen if I actually approve this and you can choose to say okay is that person getting paid one thousand dollars a month or a hundred thousand dollars this month simulation tools and Dows are are critically needed as well we need to conduct regular configuration Audits and detect when configurations change all the things that in like Legacy companies are really boring and they have entire Departments of people for things like change management are actually needed uh in like composable governance settings we should always minimize cross-chain communication anytime you're using a bridge you're probably just waiting to get exploited we need to implement spending limits and transaction guards everybody should use Hardware wallets not back up their stuff in and that is just like general purpose like house housekeeping stuff but like uh but a last one that I think would be cool is if we could set up some sort of like on-call ships and rotations for people that are on like 60 multi-cigs to make sure that they know that hey this person's on vacation these six people are in Bogota we need to like keep track of what's going on so I mean in conclusion composable governance tooling is why Dows are going to be great and powerful and transformative but we also need to be very careful about how we configure things or else we are just going to start seeing like uh floods of militia proposals coming in and people are just going to get overwhelmed so take care of your Dows and protect them thank you thank you thank you Isaac for that inspiring talk are there any questions from the audience I see some in the back over there in the middle yeah please talk into the mic because of the stream yeah um is it possible to set up prevention rather than monitoring because I just see like if you would have a lot of money monitoring Tools in your Dows then what makes it so different from the traditional Financial system yeah does that make sense it does make sense and I was trying to chatting with some folks earlier about better architectures for this kind of stuff where proposals should actually be minimized in Dows where you can set up different governance architectures that are much more like set it and forget it like the folks at protocol Guild the way that they are and also like to build Guild the way that they have their payroll set up is like it's just streams which are set up until they're not and so like I think that more things like that where governance is a you set it and you only have to do governance when you want to change things versus like constantly having to do proposals uh makes it so that you could have like much longer voting periods much more safety and I think that like generally architectures that prioritize that over um over like active like attention-based governance would be would be better and then we're not just like flooded with notifications which is not necessarily better right so that means that there's a huge opportunity for ux and designers in the space right for sure like the ux and also like ux of like the ux of the governance itself and like uh thinking about things on time spans and cycles and uh attention and stuff so for sure really interesting thanks uh you mentioned sending out alerts when uh there was a possible attack going on have you thought about um somebody trying to exploit those alerts and creating many many false positives so that people stop paying attention to the alert and then it allows somebody to yeah notification fatigue is like yeah it would not necessarily be better because then we're just like okay which of these alerts is real which is not so uh yeah it would be similarly bad foreign you've mentioned earlier about arbitration and that some of the dollars are basically setting themselves as the arbitrator what are the other options and how would that process work if like you get there and you need an arbitrator yeah um so some dials have like Claro's Court set up as arbitrators um hello which is cool uh so that would be a great option um or other other systems that have uh or just any other system where somebody can be like here's an independent board that your arbitrator also needs to be responsive and so like that's why it's kind of good to go with a protocol versus an individual because if you have like a one elected individual arbitrator people go on vacation people go away um so yeah I would say like using um like other consensus mechanisms like that would be would be ideal whether any further questions for the audience um I might have my contact info on the next one yeah um always feel free to reach out to me on specifically telegram is best um if you are identifying issues with Dows or configurations or like hey is this vulnerable um this is what I enjoy uh helping with so Reach Out no one more question sure thanks we actually had a final question over here yeah yeah quick question this logo style use reality.e uh we do not oh uh but I that doesn't mean that I would never use reality.eth I just think that you have to apply it carefully and it's not a like Panacea of like wonderful gasless voting for everyone um it's good for specific use cases when it's well configured uh but we do not currently use it thank you thank you again Isaac for today yeah and with that uh thank you again yeah this ends our morning uh cycle we will be back at one o'clock with an AMA with the guest team in the meantime be sure to get some food and drinks on the first and second floor and I'll hope to see you again at one o'clock here [Music] foreign [Music] [Music] thank you [Music] foreign [Music] [Music] foreign [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] thank you [Music] foreign [Music] [Music] [Music] thank you [Music] [Music] thank you [Music] foreign [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] [Music] thank you [Music] [Music] foreign [Music] thank you [Music] [Music] [Music] okay yeah [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] [Music] [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] [Music] foreign [Music] foreign [Music] [Music] [Music] foreign [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] thank you [Music] foreign [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] thank you [Music] [Music] [Music] thank you [Music] [Music] foreign [Music] [Music] thank you [Music] [Music] [Music] [Music] foreign [Music] foreign [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] foreign [Music] foreign [Music] foreign [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] thank you [Music] [Music] thank you [Music] [Music] foreign [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] thank you [Music] [Music] foreign [Music] [Music] foreign [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] thank you [Music] [Music] foreign [Music] [Music] [Music] [Music] foreign [Music] [Music] thank you [Music] foreign [Music] [Music] foreign [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] [Music] foreign [Music] foreign [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] foreign [Music] foreign [Music] [Music] thank you [Music] foreign [Music] [Music] foreign [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] [Music] [Music] thank you [Music] foreign [Music] [Music] [Music] you know [Music] thank you [Music] [Music] foreign [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] foreign [Music] foreign [Music] [Music] [Music] foreign [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] for joining us for the session with the guest team today we have here we have Peter we have giome we have Matt and we have Marius to answer all your questions uh in this session please give them a warm welcome and Applause foreign [Applause] thank you for coming we have no idea what we're going to do for the next hour so [Music] um maybe I don't know maybe we should start with introducing ourselves or something okay I'm I'm Marius I've been with the guest team for two years now and that's it what were you doing before you were in the guest team oh I was working on payment and state channels and uh actually mining software um before that but I'm I'm not I've also worked on the merch so I hope that like kind of balances out okay uh my name is Guillaume I've been working on the guest team since 2017. uh initially on a project called whisper uh didn't work out so I moved on to uh more core development and I'm currently working on the topic of stateless ethereum and vertical trees uh before that I was an engineer at a various non-crypto related companies and I'm very glad not to work there anymore hail I'm Peter I've been on the gas team for about eight years now I started working on whisper and figured out that it won't work out in about two months but yeah and uh yeah I uh essentially ethereum is my first real job so fun hello I am Matt I've been on the guest team for four months I've been working in the ethereum space for about four years it's also my first real job I worked on the quilt team previously doing various r d efforts on future ideas for ethereum and now working on the Json RPC for the get team cool so this panel was supposed to be an ask me anything so it would be super nice if you have any questions starters go for it I tell you okay hi I'm olaj we woke up with the news of arbitrum acoustic acquisition for prism how do you how your team looks for an acquisition and do you think prism will be a leader consensus clients for ethereum so I actually just heard it two minutes ago before we went on stage so I didn't really read anything about it or made up my mind about it um as I said I I think consolidation is um it's always this two side of a side of this of a coin right we want to be as decentralized we want to be as distributed as possible and that also means that the team should be independent um on the other hand if you have uh like a bigger company working on different things they can achieve stuff faster and so let's see what the future holds for for Arboretum and prison plus just to add to that I think the ethereum vision long term the idea is that the clients will be or the most important clients will be maintained by fairly important companies whether those companies grow out of the ecosystem or our external companies that's I mean out for debate but I think in general it's good for ethereum if you have solid well-funded teams behind them so whether this particular case is good or bad I mean that's Up For Debate but the idea is okay all right I have a question for you guys right here so thank you for being here you guys are rock stars so this is a question for the you know the ones I have been here many years about the what is your most memorable experience working for Geth I remember Defcon 2 the Shanghai attacks so I don't know what's your experience about that so I would like to know what's the most memorable experience for all you for what is the fundest experience working with the get team oh hard question no no I was just going to say and totally unpredictable as a question we yes we are very well prepared what about the merch like how do you celebrate it is that was that a happy celebration was that full of anxiety where the the merge celebration was basically okay it's done now let's let's move on um so for me that the I think the most memorable I've haven't been in this team for for that long uh the most memorable thing I think was the uh Greece interrupt um where we worked on the merge together with all of the different client teams uh consensus layer client teams execution layer client teams in a really nice hotel in Greece and we spent like the whole day sitting in the basement hunched up over our computers uh working while there was it was like 30 degrees outside and after the third day I I made the decision that after dinner after lunch I'm going to take one hour or two hours to go to the beach to enjoy life a bit between working uh in in the basement you stole my answer hello hi uh I'm Jeff and uh as a I'm in a space around five years so as I'm a co-developer I had opportunity to read your code and participate something in your Discord um but after the years passing I I was feeling that less and less maybe or you're so occupied or with less support I could saw you less and less in Discord I also the documentation will become more and more outdated now after I saw Peter's I think last year one of her tweets that say oh we need more support the other stuff did you get some support for the ethereum foundation to support your team maybe to hire new people to help the documentation and the stuff because you did an amazing work go is still being a good platform for for beauty stuff but to see a lot of people say okay I'm going to use the rest other stuff but you you have a we have a very good base knowledge in goal that you guys built so how is the future for gef so basically this is my question yeah so that's actually a very good question and I'm kind of happy that I have a positive answer for that is that um well in the past we've uh most of the documentation that we wrote or stuff we we published were all written by us and I mean that's kind of nice it's kind of we have to be the origin for those but uh we didn't really have the capacity to do it and uh for the past couple months we've actually had somebody on the team who helped write documentation I kind of feel that we still don't help him enough but we're trying our best plus it was seen as initiative to actually revamp our entire website which will come in a few weeks months I'm not entirely sure but there again we kind of a huge shout out to the EF essentially theorem.org website team because they are the ones uh doing their our new website and so we know that there's a lot of things to improve but there we have received an enormous help from the EF towards improving it I'm sure there will be a lot of things that still depend on us but it things are getting better Also regarding support on our Discord and and everywhere I think with the increasing complexity of ethereum and the the increasing demand of shipping stuff um just being there like our time being spent on supporting individuals in the community is very limited and we need more people from the community to take over to to help educate uh educate others about how to use Geth and this kind of stuff uh yeah I just wanted to answer the question about the future of the guest team uh so far people were were quite positive and upbeat so I wanted to be the down here Downer here uh I think I mean it makes sense that so much of ethereum has been relying on the guest team before uh there's been an effort like the help also comes from other teams like for example uh the the client sorry the consensus layer clients are taking part of the the trouble the burden away from us there will probably be this kind of uh of other efforts in the future and hopefully we can just become a bit more uh redundant in a way and uh this this is this excuse me that would be uh true decentralization and he's got he wants to answer as well uh also talking about support uh if you guys have experience with get and want to help us with the Discord yeah we're really looking for for people who can do it although I know if you guys can work with guests like you have experienced then you probably get better jobs elsewhere but you know just yeah for technical support yeah this is Cena by the way he's also part of the guest team [Applause] yeah so Cena didn't want to be here but uh thank you for being here but Cena gave a good lead into my question which is to ask everyone who who's in the Geth team either on stage or off stage where do you most need help individually like in parts of projects you're working on whether it's like strategic stuff for the future or like something right here right now is there anything you can share with us as Community to help us better support what you guys are doing like can that work the first thing that comes to mind is please be polite on PRS yeah so I guess with the guest team our bottleneck our single actually single bottleneck is pull request reviews we have a lot of very nice members on the team who can really churn out code super fast maybe a few people way too fast like Gary and we can't keep up with him and the the and we also have a lot of external contributions and there's the problem is that the code is super sensitive so it kind of always boils down to a couple people having to review everything and having to do a lot of context jumps to review them and unfortunately this is our Achilles heel because we have absolutely no idea how to solve it definitely more people on the team more reviews help but it's not an easy to solve situation because we can't just hire somebody to do code reviews since I mean the entire network kind of depends on it so that's uh we're really open for suggestions on how to solve that I think two things also come to mind for me the first is helping create better onboarding mechanisms for people to contribute to Geth right now it's kind of you know look at the code base find something to fix look at the issues find something to fix I'm taking you don't like your onboarding experience no I think my onboarding experience has been excellent it has been such a fun time working on the kids no but I think seriously a lot of people have talked to me saying I have no idea how to start working in core development and you know some people like work through that filter themselves and they find issues and they start contributing and they end up in that position but I think that we could build some mechanisms for more people to contribute and I had this idea that I've started working on a little bit is like having some sort of like capture the flag that has like basic flags for people to capture where you do like a core development task like add a new OP code or fix some sort of bug or go through an invalid trace of the evm and you're able to resolve it and run a program and verify that you did it correctly and so that's like a very you know binary system of like I did this right and so now I can move on to the next thing and then once you go through that then it's a little bit easier to come into the whole getth process and figure out like okay why did they not like my PR how do I get this PR to be accepted and everything so I think that would be a cool thing for people to contribute if that's something you want to contribute to I'm happy to talk offline about that and the other thing that I think that we could use help with I think like all of the X execution layer teams could use help with is working on the Json RPC so that this is an interface that's a little bit more standard across all clients I think the ideal world is that a client is just simply a black box and no matter what client you're running you can always interact with them you know almost exactly the same through the Json RPC and we're trying to get to that point but we're still not quite there and it's just generally one of these things that's not as high interest for a lot of people and so it gets put on the back burner for the most part and I guess one more thing I would add is that uh no shade for the other execution clients but very often I do feel that we the guest team is driving a lot of the changes a lot of protocol changes networking changes so it's kind of a bit asymmetric in that we are the ones bringing the for example the networking eips to the table and everybody else just well okay if it's backed out and if gath implemented it then we'll just roll with it and I mean that's perfectly fine just it kind of means that our our tax tasks are always not only to maintain gas but also somehow to try to advance the execution layer features whereas the other clients are kind of I feel that they are sometimes just playing catch-up and this is fine for them which is less fine for us um I think that that also goes that not only goes for features but also for uh the testing so a lot of the testing efforts uh right now are driven by uh bright by Geth and um we're currently trying to build out a new team within the ethereum foundation uh for specifically for testing for cross-client testing um so um yeah in the in the past it has been Geth is the majority client and we have to take care of the network so we have to make sure that everything is really well tested and we can create we can create tests for that can also be used by the other clients but in the future we would like to get to a state where researchers and the testing team create tests for everyone and so we don't like and they don't have to rely on on us doing doing the work for testing uh yeah and something uh kind of uh in this area is also um there's there's Geth guess is uh its own monolithic piece of software um but there's a lot of I feel there's a huge gap still between the solidity development world and Geth and I I would really love to see a lot more tooling developing in between like to bridge this Gap so I don't really have any suggestion about such tooling but I I feel there's a there's a gap here that would be great to to fill all right um I have to think of a question because what I really want to do is just use this as an opportunity that I may never have again to say just how sincerely appreciative I am of everything you guys have been doing our list a couple years [Applause] um from one developer to another I know that sometimes that doesn't come through as much as it needs to and I it's just what you guys have done has really helped me um help me personally and get me involved in the ecosystem so uh if I came up with a question right now I guess it would be uh does clef have any future so first of all it's pronounced clay [Laughter] no no clef that was perfectly pronunciation so whether it has a future or not um I would say so clef was one of those projects which we really think would be very very useful however I kind of feel that we as developers kind of took it to a point where it's uh secure and it's highly unusable because it's very very console based and and everything and the only way to make clef more usable or friendly at even the least bit is to actually turn it into a product and unfortunately I will admit that that is way outside our capabilities because they are you would probably need a UI team you would need a completely different team to to do that work and whilst I do think it would be super awesome it's uh again the question is I we could hire somebody or multiple people to work on it we could maybe get an EF to work on it but there are a lot of other wallet software out there and the question is is it worthwhile to try to compete with them I'm not sure so I would say clef isn't going anywhere but I don't really see it going into a product quality either so it probably it will be a bit in this limbo space for now but something that we're currently thinking about retiring is the the personal namespace and the the the wallet within uh within gas and so if you're depending on that we're sorry no actually there's a discussion to be had but we would really like to get rid of this stuff yes so definitely that's direction we so Geth is kind of like this huge monolithics monster and that was kind of borne out of the necessity of when ethereum launched there was no other software so everything the clients had to do everything but obviously having your accounts managed by a node is a bit wonky that was partially the reason why we built clef and we will definitely try to take clef up until the point where we can remove account management from Geth and hopefully it should be as easy to manage your accounts via clef as if you were managing it via Geth but I think that's the that's the threshold where we will probably stop and if somebody picks it up awesome if not then it will be used as kind of as a developer tool in the future so a long time ago there used to be a very nice proof of concept run and get on Android and I feel that now after the merge maybe it's more relevant and it can be actually useful that people are running their own clients on on Android is there any work being done on that on on what sorry Android oh yeah so did let me answer that so originally we when we shipped a guest for Android um we shipped it as a full node which obviously doesn't work anymore then later jealous shipped the light client it's still I wouldn't call it really production ready but it kind of worked however it turned out that uh the pre-merge light client is still too heavy for a phone so now that we are post merged that's actually an interesting discussion to be had whether we could just somehow pick this thread up again I think it definitely would be interesting however usually with mobile phones and Android you have very very strict limits on how much I mean okay on iOS you have very strict limits on how much your background process can run Android is a bit more relaxed but you're eating still eating battery very very fast so I could imagine some Alias clients or some like client on demand where you just whenever you just want to interact with your thing then very temporarily just pull some data from the network and and that's it um then I think the the post merge world is kind of compatible with that so I I think that would be interesting however at least using the gath code base I think it will always be a bit heavier than ideal so if you if you were to really so the get light client even if we ship it as production ready we're probably more cater towards running on a laptop and if you want to run it on a mobile phone in a production ready environment my guess would be that it would take a different team maybe a slightly different approach to to get there no so it's it's like an additional thing that we have to maintain and we would I would actually like to get rid of this uh the the Android stuff there's there's a the thing is like this this go to whatever Android users cross compilation is always broken and there's always something some issues there and so it never really works and sometimes is a bit clunky the code that that gets produced and so I think another team just building a a light client from scratch for for mobile phones especially after working would we will definitely some sees some stuff there and I hope that at that point we can just get rid of this uh wait so um there's also a bit of a road map issue here it seems that you know uh now the direction for ethereum is to have all of the day-to-day operation happening in Roll-Ups and having the core layer be something more not gonna say inaccessible but maybe not the thing you do on a day-to-day basis um if that is the case if that Trend continues I don't think it makes sense to to worry about mobile because no one is going to try to access access the layer one from a mobile one more thing I would add is that it's an interesting twist post merge world that before the merge even a light client had to have a lot of connections I mean you either connected to a trusted server which kind of Beats the purpose or you had to connect to multiple light servers so that you kind of got the ground truth kind of follow the correct chain based on proof of work now post merge you don't really need that because you have the signature so in theory post merge you could connect to an untrusted web 2 provider and download the necessary data and you could still verify it so this kind of opens up a bit of a different design direction for making ethereum trustlessly work on mobile phones hello so what's your take on the parity open ethereum Saga and what can the community do to make sure that good clients don't die again can you repeat the question yes this level is good so what's your take on the open ethereum parity Saga and what can the community what can we do to make sure that alternative good clients don't die again I think that um I think that's inevitable so in my opinion good clients will die it's a I mean look at the gas team gas team currently has is about 10 people now I would say that out of these 10 people you have probably four to five people that are kind of more familiar with the very very internal details now should these four or five people leave it is very very hard to find replacements for them and this is essentially what happened with parity okay they're leaving it was a bit different but the idea is that if you actually manage to simultaneously lose enough of your main contributors then it's very very hard to onboard enough people fast enough so that the the project survives and I think that it's uh as bad as it is to lose a client I don't really see what you can do I mean the same happens in open source software too that um eventually you have a couple maintainers that just I mean life happens they go do something else either because they get bored or whatever reason and um I'm not sure that yeah so I I I think it is a very real chance and it will definitely happen that good clients will die there's always a I mean one way to protect it is if there's a very very good funding behind it maybe a large corporation but again if there's a large corporation behind it they can always decide that it's not worth it to keep going so it's a I guess that it boils down to the fact that you need this is why we would need client diversity because that kind of affords us good clients occasionally disappearing and and I think within the guest team we're trying to prevent this by onboarding new people and making sure the the uh the new people that come in get familiar with um a lot of the different parts of the code and so but it's very hard for us being relatively new um to meaningfully contribute because there are so many just invariants within the code that are not explicitly stated and so sometimes it happens that we break an invariant and it's usually Peter who has all of the invariants in his head and and says okay we're breaking in invariant here don't do this this is going to to to fail at some point and it just takes a long time to actually learn all of these invariants that are implicitly in the code um plugging back to one idea I was talking about before just the fact that for example we kind of spun off consensus if another one of those steps happens in the future like maintaining a client becomes easier and easier so that would be a good uh I forgot the word but uh it would be a good way to make clients not be at risk of dying but until until we do until we simplify the protocol it's uh yeah it's going to happen and one thing that I also really like on the roadmap is these uh uh the perch where we try to get try to eliminate some of the um all outdated stuff and uh so for example history expiry would allow us to delete all of the rules that we have for executing all transactions and um at some point if there's a way to execute them in a different client and and and all of these caveats but it would make maintaining a client a lot easier um another issue that we always run into is that someone wants a feature and we don't really think about it and care and implement the feature and and merge it in and two years later or sometime sometime later we realized that this features not really used by anyone not and and we cannot change something because we would break this one feature and at that point we have a decision to make either we like either we just don't do anything or we delete the feature and someone is going to be upset and we don't want to make people upset but it's inevitable I think with the with the way get this right now again I guess just one final thought there um Mario said that if we Implement The Purge and get rid of a lot of features then that would really help other clients get up to speed I think if we So currently it's very very hard to write a client and starting a new client is essentially impossible because ethereum is moving so fast that you you never catch up but I guess once we reach the point when when ethereum starts to ossify that would be a nice place when actually new client developers can join in because then you can actually say that well I want to make a client just specifically for iOS that has this and this and these properties and they can work on it for three years without the protocol constantly changing the invariance and I think my expectation would be that when we reach that point of stability we will have the original clients be quite marginalized by new clients that are very very focused to some specific sub task or sub some use case so thanks again for caring so much of the ethereum ecosystem on your shoulders it's a 10 people that's insane the amount of value that sits on top of 10 people it's crazy can you hear me yes okay so the question is um what is the current sustainable business model and the follow-up question is the what what is the current yeah sustainable business model for get and probably other clients that want to copy that and the follow-up question is what is the plan to do something similar to what's been done for the core protocol right we want a certain percentage of of it to be staked as a security um a percentage of the total value right so is there some sort of research going on on how do we get certain percentage of the development effort in the ethereum ecosystem to be going towards get security well to answer your first question uh it absolutely makes no sense to write a client so I think it's uh there's no business model behind it it's currently most of the clients are funded by I mean we are fully funded by the EF we have absolutely no income and I'm assuming other clients usually how they try to fund themselves is that many clients get grants from other projects so that they support different blockchains different layer tools different scaling Solutions that's one way to somehow try to build a business model around it but at the end of the day since ethereum is kind of like this public platform client as a client you cannot really make money out of it it's a yeah so that's there's no business model behind uh creating the client itself um the only thing that I would say is that uh there's the the Proto what what's the protocol protocol Guild yeah exactly um that allows projects for example D5 projects to allocate a percentage of their token distribution uh to a pot and out of this pot uh client teams get right now they get bonuses um uh and this is the the general idea behind it was not to fully fund client teams but to provide an upside that they wouldn't have if at that they currently don't have and that they would have if they were to switch to be uh to to defy uh because we've seen a lot of uh good client developers uh just say okay I can make 10 times the the money if I if I create the next token um and so the protocol support a protocol Guild thingy is like a way to give some some of that upside from the default projects yeah appreciate like I was wondering if you can start experimenting with things like maybe code Arc funding towards PRS right there's you said there's a big backlog of PRS and only a couple of people that are capable of reviewing but you could imagine that with some sort of codewriting funding you can't hire or at least bounties for other people to layers of developers to review and write tests and integration your tests before it gets to a core developer so I guess um this depends on the granularity generally people do do that at the EIP level so famously uni swap is pushing certain eip's very very hard and I'm assuming they are actually funding the people who are doing the necessary research doing necessary presentation etc etc to get an EIP through now that I don't think that really works at the client level because we've tried for example at some point we gave out a couple bounties for some work the the place where it kind of backfires is twofold one of them is that you usually get contributions of not the greatest quality because a lot of people see that oh there's a I don't know one ether bounty on this so let's just jump on it so you will have 10 different implementations all just kind of trying to hack it as fast as you they can to get the bounty so the code is not the best it requires a lot of effort from our site to somehow try to fix it up or try to try to guide that person and the other side is that after the bounty has been paid out since this was a bounty work they just disappear and maintenance is our problem so we kind of have more problems than gains with uh funding PRS at that level the what we have done previously is we have funded the research teams for example to who have helped us on the Discovery protocol the Discovery V5 we I think Felix was managing a small research team at I'm not entirely sure which university and the EF was funding them for a year or so to just investigate find possible solutions to different challenges write some papers that one works so that definitely works but at the client level I feel it's um it's the wrong granularity I just wanted to say to the original question of like how what is the business model for clients I agree like no there's no reason to build the client there's not a lot of money in doing this it's always going to be like considered a public good but I think one way of making it sustainable is like Maria said this protocol Guild project in a way that people can like help make this sustainable for the long term is whenever you're developing new projects to consider adding a small allocation to the protocol Guild in your initial like token launch if some of these are if this would have been something that was around in 2018 or 2019 when a lot of these Blue Chip D5 protocols were starting we would have over 100 million dollars dedicated just to core development and so I think like going forward it's like a good thing to consider because you want ethereum to be around for a long period of time and the best way to do that is to make sure that the people who are making it happen continue having the funding that they need to do it yeah and adding to this we not only do is there no business model for a client but I don't think there should be because otherwise you would kind of adapt your strategy to increasing their revenue stream and you lose your Independence basically yeah okay hi everyone so my question is related but with what Marius just said and well I'm still a student and I'm still trying to figure out what I want to work on after I graduate so I see their stuff that you guys do and I think it's amazing and I still see something bar on the application side of things so my question is really why did you decide to go to core development and stay in core development instead of going to something higher in this in the stack because it's way more fun and way more interesting and so for me the the big thing is also I want to work on something um that makes sense to me where I have the the the the feeling that I'm doing something good for the greater of humanity and I don't think difa is a lot of the D5 stuff is is this and so that's why that's why I I was so interested in in working on the merch and and helping push push the merge um because I felt like I'm this is like the biggest thing that I'll ever be part of regarding um like the CO2 consumption and everything um and so just having this big level of like my work can my small work can have a really big impact that was something that was pretty magical from the beginning and uh yeah that's that's that's why I am in core development I don't know about you guys it's it's not the money I mean I would that so my answer is kind of boring because there was nothing when I started working at ethereum so I think Matt's answer would be much more much more interesting since he did have the choice of picking one or the other picking one or the others and I mean working on protocol versus working on that player stuff right I mean you know I originally started working on the DAP layer like when I came out of University I was very interested in how you know the types of applications that you could build on ethereum and I was very interested in like dispute resolution because I had done a lot of like e-commerce and buying and selling things on the internet growing up and I was like frustrated with the way these systems were built and so I was very excited about this as a application on on the protocol and so I joined consensus and I was working on something pretty similar to this and just immediately realized that you know a the user experience for ethereum at that time and like still today was too bad to really on board like hundreds of thousands of users to you know have this kind of dispute resolution system and even if 100 000 users decided to show up tomorrow like we didn't have the scalability to support that many users on the protocol and so that was kind of like where I started getting really interested in protocol development it's like I was like this is broken we need to fix it so that we can build an application on it and I've just like slowly become more and more indoctrinated in the idea and now I'm kind of at the point where I feel like I would rather be a small piece of a very large puzzle that I feel is going to become extremely important and impactful for Humanity rather than trying to build an application that may or may not have any kind of impact for anyone uh so I guess your reasoning for joining platform development plus you guys suck I'm gonna fix it myself naively maybe so um yeah I don't do that for Humanity sorry you guys suck no yes of course uh I think also it's uh it's where the the biggest problem I mean like the impact indeed is going to have uh like reverberating consequences in the future so that's that's where it's the most interesting but uh it's also simply because uh yeah you want to have good tools to build better societies to build better companies to be better software and I think simply the core I mean if you want to work on your tools you always end up working on the core no matter I've worked on on Linux kernel before it was the same thing you get dragged into the you can get dragged into the protocol as long as you want to to improve your tools okay hi there um I have a question about databases the underlying database and Geth as being viewed as a database you guys have talked about Geth as being a monolithic and wanting to remove or modularize components and I was wondering um since database throughput had been traditionally uh kind of constricting aspect if there were any changes to that coming up and this question comes from seeing a remote DB option in the command line options and not being able to find any documentation with respect to that so that's a very nice technical question so one um one aspect I'll touch I'll ask a previous question a lot of people sometimes ask us on on social media why did we pick level DB and uh that was actually also my question when I joined the team and Jeff's answer was because Bitcoin was using it so that's uh that's essentially how guests started out using level DB we've actually we've tried switching databases many times generally what's not so visible from the outside is that databases are kind of built up have two components they have a storage layer which is kind of like this very dumb layer that just has some very primitive ways to store data and retrieve data and then they build on top various transaction mechanisms journaling all kinds of stuff and most people kind of convolute the two and most people don't realize that level DB is essentially a storage engine it's not a full-fledged database and there have been databases built on top of level DB which have all the bells and whistles now the issue is that the moment you are adding uh if we were to use something higher level then essentially we're not only paying the costs of the storage layer rather we also have to pay the cost associated with running running the transactions running indexing the tables etc etc so at this point since gath was kind of architected from day one to just use a storage layer as his database if we were to plug in any full-fledged database instead of it everything becomes just insanely slow because Geth was not architected to use these high-level Primitives get always assumes that it has more or less direct access to the data and because of that it's we've tried we've have a lot of PR's trying different databases and they always crashed and burned one thing that we currently are working on uh actually Jared is working on it is to switch out level DB to Pebble pebble is kind of like a Next Generation version of level DB but it's still just the storage engine as for remote databases the problem is that one of the bottlenecks of ethereum of running an ethereum node is disk access i o operations per second now the moment you move the data away from the node the actually the bottleneck is getting way way worse so it's uh instead of making making things better you are making them a lot worse since accessing I mean usually you have if you want to access an SSD a modern SSD can do maybe half a million i o Ops per second that's not the high end SSD that's a payable affordable SSD you cannot do 100 million round trip times on the network per second so it gets a lot slower if we go down that path of course you could always say that why we could create an ethereum node architecture which has a remote database and then you could have multiple clients using that same database that's a very interesting architectural decision but that is essentially writing a completely new client from scratch so it you cannot really retrospectively retrofit get to use it it would be its own new client hey guys seconding all the previous comments thank you for the incredible work you're doing in the ecosystem you guys are the unsung heroes of ethereum um quick question if you were to hypothetically re-architect Geth from scratch today knowing everything we know factoring in the merge what would you do differently uh I think we would at least I would be more careful about the features that that we accept into the code there's some uh stuff that badly anyone uses but it's it's still used um and uh something that that kind of bugs me is that we write a lot of like small tools and instead of having them separate from the client they end up somehow in Geth um and uh yeah I would I would have like a stronger policy of uh not including them for example for example the ABI gen stuff should in my opinion be a different thing um but I I I already know what Peter is going to say but then you need someone to actually maintain it and if it's not in the client it's not going to be maintained if it's not in our code base no I actually agree with you no so I uh I just wanted to add what Murray said previously it was brought up that the problem is that one get was started we had to be this monolithic thing that does everything and this kind of makes it leaves its mark on the code base and it's very very hard to get rid of stuff and I mean we could get rid of stuff but some people somewhere always depend on it so I think the if we were to start over get from way back eight years ago we would end up in this exact same situation because uh we would need to make the same tools and we would and so I don't think the fact that we have a lot of Legacy junk in the code base that's not a bug it's just the way the ecosystem evolved so I don't think that would have been preventable if we were to start over now then all of a sudden you can rely on all the awesome tools that people created and that allows the client to be a lot slimmer hey um I think it's a lot of stuff changed over the last like one year and a half but especially what's changed significantly I think it's that a lot of other networks appeared that actually locked a lot of billions of dollars like somehow that actually are like get forks with some changes and was it somehow like useful for you to take a look on it are you somehow monitoring what is happening over there and if so were there any cases when you somehow wasn't like inspired by some changes in these clients and you want like to bring them into the Gap like the original Gaff and like some cases when some bugs were opened in like get Forks that actually are pretty close to the average as well um so about features or changes um don't have anything to say about that one one thing I would wanted to say is about bugs so whenever we find a buck in gas then there's usually a lot of different uh clients that are um that are also vulnerable to this and so we're looking into them and making sure that they are not before we actually um before we actually fix fix the bug and and publish it um the problem there is in which in which layer ones are we going to look and are we only going to look at uh ethereum Alliance uh layer ones or or not and so I think the way we handled it up until now is that we um kinda look in the biggest ones and um just sent them an email that hey you should expect an announcement at a certain point and then we're going to make a public announcement because we don't want to be king makers we don't want to say which client which which Fork gets the bucks first over of another Fork um and yeah there's also been bugs that have been exploited on other networks before they were exploded on ethereum uh and uh we're kind of like not really monitoring the the other networks but we're trying to be in with in on good terms with uh with the other client uh client devs I guess one one kind of satellite question here would be that um way back there were a lot of um drama around when it turned out that we fixed a bug and we haven't necessarily announced it other networks had a problem with it people very often asked us why don't we have a standardized way of reporting bugs reporting vulnerabilities have um usually what big web 2 companies do is that they have their own little private consortia where they share bugs and then when they publish it everybody in that consortia already updated and we people were always very very vocal that we should do the same thing we kind of felt that that's a bit problematic because in in the blockchain world if you if we were to create one of these consortia it's not really clear whether everybody in that group would be friendly or how friendly they would be so usually what we try to do every time we found a hairy vulnerability or bug is that depending on the nature we always try to announce external people or give enough details to external people external teams to minimize any potential damage now for example in the case of ethereum what we did is that if we knew that we are going to fix something that um that only affect minors or if the miners are good then the words that have cap happens for average user is that their note crashes usually what we did is that we just gently pinged a couple of the bigger mining pools that hey we will release a release you really want to be on this release nothing more just a gentle reminder that it contains something that you want to run and by having the majority of the hash power updated the network is kind of safe and there's not much damage that can be done but this is kind of a completely arbitrary bug by bug decision on how best to proceed how best to minimize any damage to anybody in the either in the ethereum network or or the external blockchains that use ethereum so we really try to be as friendly as possible within the limit of keeping the ethereum network live yeah thank you hey it's me again I just want to add that apart from the people sitting here and some of us off stage we also have people watching the stream from the team I want to give a shout out to Martin who is from far away who couldn't make it unfortunately and uh yeah who's from far away trying to contribute to the conversation so somebody asked about the remote TV flag I I have an answer to that so it's basically um it does the low level at database get over RPC so basically you can have like what you have a node on a server and you can have your like local node connect to that to the remote one for some like only read operation so for example if you do DB metadata command locally then it would basically get give you the metadata of the remote node yeah that's it okay we have 37 seconds left so if anyone has one short question for three minutes here okay hi I'm Chris sorry um you go first but really short and then Chris okay um I'm Josh uh do you see Snapchats as the for the solution for the state database lab for the first the evil future sorry what was the question I missed it uh do you see snapshots as the get as get solution for the state database layout for the first yoga future uh yes thank you yes you got the last question one question we are in this beautiful Columbia South America Bogota I just want to know what each of you have like most loved about Bogota so far hiking in the rain at the waterfalls I actually I actually really liked working from here uh it was it was uh it was really fun with uh like we had some workshops uh a day with like all of the client uh devs and today we had a really nice working uh session in the morning yes if you haven't noticed Marius is the new workaholic on the team it was really nice just getting the the the people in the room that need to be in the room and work on some of the uh interesting things that are coming up and I'm really really really excited about the new stuff that is coming for ethereum I also enjoyed the hike quite a bit that's the only time I was at the hotel besides coming to here so I heard different math I heard different I also really like the energy at Defcon it's been a while since we've all been together and I think it's easy to forget that the community is so large now and there's so many people excited about this protocol so I found that very energizing for myself oh yes uh Jared tells me the food the food uh no yeah it's uh the food has been nice uh I like the hotel as well no but uh I don't know uh I I saw the the center the other day when we went when uh looks looks quite interesting uh I guess we will Explore More this weekend after the work is done one last question who from the team is not on stage today besides Cena who from the team is not on the stage we have Jared beside you so shout out huge shout out to Jonathan in the back uh Felix who's uh in Berlin Martins in Stockholm and and a giant uh actually a giant shout out to Gary who wasn't able to make it to any of the guest meetings for the past three plus years due to him being stuck in China and the Chinese rules on leaving the country and coming back due to kovid are super super strict so and insane shout out to to him for still tolerating us and working for us without all the upsides of having the fun like we are having now also congratulations on getting married he's getting married next week do you want my social security number next I think we have to cut it off there thank you so much for today and Joseph and Joseph who's doing the website yes yes Joseph thank you big round of applause guys thank you so much [Applause] okay and with that I'd like to call forth our next speaker thank you which will be John Kane providing a session on better solidity support in vs code by hard hats John welcome to the stage please give me a warm welcome [Applause] oh please I'm sorry okay can I just kick off go okay everyone um welcome to better self the support and vs code by heart and we're going to be covering that's going to be like a jaunt I'm quite an easy joint through uh the different virtual Studio code extensions for solidity there will be shelling of the extension I work on and then more interestingly we'll move on to a couple of the technical blockers that are holding us back from giving you the solidity experience you all deserve and then you know a plan for getting around those blockers so my name is John Kane I'm from the nomik foundation you probably knows as the heart attack people and nomik is a not-for-profit foundation pay for by donations with a remit to improve the ethereum developer experience heart Hat's a big part of that but the rematch General and we've identified a gap in editor tooling and that's why we have built and released a vs code extension called solidity by the normal Foundation of which I'm the the team lead so you can find me on GitHub or hang around our Discord server particularly the heart attack vs go channel so if you want to come and chat or suggest some features or you've got a really detailed book report on a matching PR come chat come chat great editoring let's kick off by addressing the Microsoft branded elephant in the room right why are we focused on vs codes and the reason is we have good reasons to believe the vs code is the main way that certainly is getting developed today so if we take a look at the most recent uh solidity developer survey you can see the vs code is dominant right in fact the 60 Visual Studio people we suspect actually meant Visual Studio code rather than the venerable.net IDE similarly the remix and that's an online solidity editor about booze in key components from vs codes right so you're actually down at then before you're not talking about vs code or vs code adjacent right and we suspect that the solidity developer survey skews towards those who are deep in the ecosystem right those are on crypto Twitter and and click on the survey link when it goes out but another way it's over representing this long tail it's over representing the shadowy supercoders who are doing their development and then and a teamwork session over a VPN to ambulatory satellite that they repurpose for the day right I said let's just test right hands up anyone who when they do do solid development they do and vs chords okay good and hands up if you're a shadowy supercoder who's doing it within all right see that's a track no shadowy supercoder within that right and actually hands up if anyone any of the two emacs users uh are are in the room because I'll buy them a drink my mind having my toes I've created the wrong incentives here right and I'm not immediately going to renege on that promise right well it'll be a lesson on uh solve promises and the value of escrow right so by a Pareto analysis vs go to Japan I'm nvs code and what I just wanted to development I'm looking at the marketplace what should I do and I'd say that there are free options if you have a different setup get in touch I want to to hear it but those would go down as solidity by Juan Blanco solidity by the wrong Foundation and trouble for vs code right and we're going to say go through all three of them quickly and if we were doing it by installs we would start with solidity by Juan Blanco but as I work on this one and it's my talk we'll start with mate um uh as I'm a coward I'm not going to do a live coding so here is uh earlier John to run you through the feature set and our type projects arranged and organize underneath packages so if we jump into our solid City contract as you can see we have table Stakes so syntax highlighting we also have Diagnostics or otherwise known as inline warnings and errors you can hover over variables or functions to get useful information note that currently we're not showing documentation though I will come back to that we have code completion on local variables or more sophisticated examples where table permission is required completions or can say though import statements as well both at the file system level but also direct Imports so in hard Hat's case I was looking inside of npm modules in terms of navigation we can find usages similarly we can jump definition and this is working across the different packages refactoring includes rename which obviously you shouldn't use to do any key role though we have implemented undo we have a set of quick fixes which appear in response to Salty warnings and errors you find them under the bulb icon so let's bring back public possibility sure that we set the overrated specifier these are small annoyances with function signatures but we have more complicated quick fixes for instance we have a contract that needs to implement an interface or multiple interfaces we can Leverage The addressing functions from interfaces quick fix and this will do some of the heavy lifting for us it is scanned through the inheritance hierarchy of interfaces and these contracts and figured out what the smallest set of functions that needs to be stopped for salty to to stop shouting at you if I push play this is going to play again ah good they've affected by it I want to add three caveats to that video gravity number one uh like any suitably advanced technology is indistinguishable from a rigged Tech demo right and what you just saw was a reg take demo you didn't see all the places where jump to definition doesn't work or you you're aiming for completions we didn't resolve the type information so you get the default set of completions caveat number two or just re-emphasize that the documentation against function wasn't appearing on hovers and there's a technical box that I want to come back to right and fee is the biggest caveat which is there are some key features in there actually like um Diagnostics and quick fixes that only work inside of a hard hat project right and that's a problem that I want to come back to again but let's take a look at the LR extensions quickly and solidity why Juan Blanco this is the OG it's been the Workhorse facility development for years um with uh over 800 000 downloads relative to ours uh let's just see we know how then feels it provides syntax highlighting integrated formatting and it has navigation and Diagnostics and the default structure assumes you're organizing your contracts under sourcing lib so setting it up for heart attack is is difficult um but it's going to work better if you're doing boundary or adapt tools or or Browning um and next we have truffle for the escort this leverages solidity by one Blanco for the syntax highlighting Diagnostics Etc that adds a layer of UI Integrations into the Truffle tools Suite right so that you can run compile through um the the UI through the tasks subsystem in vs code for example right um and that's great for onboarding if you're new to truffle or you prefer the UI to the CLI right one other really cool feature is integration with the Truffle debugger just wanted to mention as well this isn't from General development but the diligence team at consensus has a set or Suite of extensions that are security Centric so they're going to give you analysis and visualizations when you're doing that smart order okay so plenty of options for solidity then lots of great programmers pushing the ecosystem forwards but I don't think any of us would claim that we're yet in the same league of editor support as other language ecosystems like dotnet or rust or typescript right so how do we move from where we are now to that best-in-class experience and one of the answers is just a time and resources right but there are a few technical blockers I'm going to spend the rest of that stock taking into those first off feature fragmentation so we have features which are cycled by editor and also cycled by development framework the others feature productiveness right can you rely on the feature to always be there and to do the right thing and for fragmentation clearly extensions we have built-in vs codes um maybe the lack of support and then is why there are as many people using them right if they had those Advanced features in film they would be using them right so that's one form of fragmentation the other form of fragmentation though is in developer framework not all of the features that were listed there work for all development Frameworks right if you're working on a truffle code base you're probably using truffle for vs code and if you're in a hard type code base hopefully you'll use the normic extension and if you're in Foundry you're likely using one blank course extension right and that makes sense for some development specific features but there are core editor features we should just work across all of them right you're going to want rename and Foundry just as much as you're going to want it in hard hat but currently it's siled in hard times right um so how are we going to get around this this sorry there are multiple reasons for that and one of the reasons is is just Conway's law so if you've got four teams working on compiler and then you're going to end up with a four-phase compiler the code structure matches the communication structure of the teams right and the development teams that are uh rating editor support it's easier for them to add it for their own development framework it's easier for me to harangue the other hard hat devs or cajole them or convince them or go crying to the CTO to try and get it changed than it is for me to convince the entire ecosystem to just do what I see right but there's on another aspect that's uh part of solidity right which is that solidity doesn't specify how import loading works or sorry or doesn't specify that part it leaves it up to the development framework right so if you so we've got an import statement here pulling in other solidity codes so C requires a custom loader to actually resolve that and it has to be provided by the development framework and if it's a relative path the development framework is probably going to do that as relative to on the file system right from the current file but if it's a direct import then there's multiple different interpretations which make sense right and hard hats we would interpret this as uh look inside of node modules and then find open sample and resolve the rest of the path read the irc20 soul file and that makes sense right heart out Leverage is GS including node modules but that doesn't make sense for a Foundry right that's going to uh resolve this based on remappings in either The Foundry Tomo or remapping txt right and that has profound implications for editor telling right so say you're on irc20 that's token here and you wanted to jump to definition the editor can only resolve that if it understands this open ziplin import line right that implies the editor has to understand the import loading logic of the development framework that this file has been dealt with under okay so how are we going to walk around these fragmentations and editors and different editors and fragmentation across development framework I'm going to in two steps first we're going to use the language server which is um language servers the technology that came out of yes codebit tries to deal with the fragmentation you get across editors right so instead of each editor implementing language features for each language we gather up the language features under a Daemon and we have the editor put that Daemon up ask which features it provides turn those features on in its UI and whenever the whenever it was a requested by the user it delegates them off to the Daemon and the communication between the editor and the demon is covered by uh clearly specified protocol language server protocol and that's what we're doing in the nomic extension today right there is a a language server which is encoding all the completions diagnostic servers um that we that we provide today and there's that is embedded in vs code but there's nothing is stopping us from exposing that out so that other editors save in can take advantage of it right but what about the uh important or more difficult form of fragmentation right between developer Frameworks if you have a language server an economic extension already why is it that I don't have uh Advanced completions in Foundry right and the reason because that is because currently the language server is really a hard language server rather than a solidity language server we are all through the code base encoding hearta assumptions to deal with things like the import loading that we saw earlier right so and the reason that we've done that is we use bits of the hardware code base right which allowed us to get up and running quickly we can make our tap dance right and subtraction is hard right but we are uh looking now to refactor the language server to isolate out these particular points the development framework uh particular Parts behind and adapter interface will have a heart adapter but we also can then have the implementations for Foundry truffle brownie right and in that way we can add feature once and have it available across the ecosystem well our point I just wanted to mention recent versions of South C have a language server built in right so why don't we leverage that and we're big fans of Livery the language servers to the northern area but the South C language server is embedded in a particular version of Soft C right and heart attack code bases can have versions that are older than the ones that provides the language server and suddenly we have many complex code bases and Hardware code bases which have multiple cell C versions right and we need the language features to just work across those versions so so that's why right but just to summarize the nomic extension has an in language server and that we are making development framework agnostic and then we're going to make Standalone so it can be used in other editors and that's how we can build a feature once and leverage it across the ecosystem okay feature Platformers right this is about uh quality the edits are just doing the right thing so when you um to jump to definition you can do jump to the definition of the places you expect and actually goes to the right place anatomic extension has blind spots right there are lots of places where features don't quite work as we would like and there are several areas that we need to work on this and but I just wanted to focus down on one in particular today right and that is that we are not getting the best experience when people are annoyingly trying to use the editor to make edits right just to walk through so you're popping about inside of the inside to the editor you're doing navigations you're exploring the code base yeah jump back again right and then you start making an edit and you remove a semicolon right shame on you shame on you but um suddenly drop the definition doesn't work right and why is that okay so the video just showed you a change in the document and that change dot gets passed to the language server right and the language server does a parse um and it builds and Abstract syntax stream right and that's a data structure which represents the syntactic elements in the in the code so our nodes might represent our whoops the chord might represent our function and then sub nodes would represent substructures like the function name the parameter list the um the function body right a note as well that the parts produces an abstract syntax tree right so some trevia is thrown away stuff that isn't strictly necessary like white space like comments right because they are not typically used in later phases by for instance the parser right and that's why um when we do hovers we don't show the documentation the abstract syntax tree it's abstract because it's thrown those elements away and because the ASD doesn't have it we don't have it so we can't provide it in a hover right but we take the the language server takes the St and it combines that EST with the asts of all the other code files right and then we do a further analysis stage we overlay it with type information we also scan through the nodes and we find uh definition nodes and usage nodes right so our definition node may be a function declaration and a usage node might be a function notification right and we layer on top of the AST that extra information these extra links so that you can see which nodes it's connected to which other node and so I change so that when the user requests I'll jump to definition the language server receives that request including the cursor position it looks up the nodes underneath that particular or underneath the cursor and finds a function and location right and then looks up that pre-calculated link to find the definition node and we return that location right in terms of its file uh line column actually both to start and the end and vs code then jumps to that location next the user makes an edit and introduces a syntactic error okay the change dot comes through we do a part and it feels and why did the powers feel well we like other projects in the ecosystem leverage uh solidity parser right for parsing but solicit parser is it's a JS library and it's designed to give binary answers to the question of is this syntactically valid right so if if it's syntactically valid we produce an EST otherwise here's a list of errors and and that makes sense right most use cases of a parts are stop if there's a syntax error you don't proceed onto compilation or uh generation steps if there is a syntax error right but um editors have have other needs right and the editors case we want both the list of errors but also the syntax tree right or as much of the syntax tree as possible at the same time right and that's not what standard parts are is designed for the way that we get around this in other languages is by building specialist parsers that are more tolerant right and they're designed specifically for that editor use case and that's what we are building now at nomic through our slang project the the slang parts are one of the components of that project looks to leverage best practices from other languages right from from Rosalind from rust right things like uh red green trees and the goal is to always produce and put always to produce a syntax tree right even in the presence of Elders it's just that sometimes the syntax tree will be valid and other times it will not but hopefully slang's error recovery will mean that a missing semicolon and one function doesn't mean we don't get the syntactic structures in all of the other functions so that we can take advantage of those and extra features right one of the other advantages of building a parser specifically for the editor is that you can include that trivia that's normally missed out the white space right the comments so that we can show the comments and hovers for instance right or we can do Advanced formatting or sorry uh refactorings right right now we're blocked in refactorings because developers probably wouldn't be too happy on doing a refactoring we stripped out all the comments in the file right that's probably unacceptable but with our partial design for the purpose we have that information and we can make sure it's there okay so what we're doing here is swapping out an excellent but general purpose component with our components specifically designed for the editor and that's how we drive up feature quality all right to summarize okay if you're using Hardware and you're using vs code we think you should give strategy by nomic uh goal and we think it represents an excellent set of features you've just heard how we're driving up the quality of those features by building um editor-specific components and swapping out the general components that we have and we are looking to make those features available across other development Frameworks right we want a credibly neutral language server and we're doing the refactoring and putting in the work to or putting in the workforce attraction to support that we also want it to be a standalone language server so we want to pull it out for being embedded in vs codes it's going to lead to a a small amount of cleanup this is actually one of the easier things we need to do and but hopefully sometime soon uh shadowy super coder will be able to hack away in solidity to the heart's content okay so that's how we're going to improve the solidity developer experience for everyone thank you very much are there any questions for John before you have room for a few does anyone have any questions hello oh are there any analysis tools that can benefit from this improved more robust a abstract syntax history sorry yes sorry so the questions are there any other tools that can take advantage of this and we would hope definitely yes the Swank parser uh we're building a component that could be used in devtooling across the ecosystem right and it's going to give more detailed information and work across uh different uh solidity versions right so it should be giving you rich information cross versions other parts of the solidity project also intend to add other components to write even more information so usage definition would be the next one that we're where we're looking to tackle so yes hopefully lots of analysis tools will be able to leverage these components and for a final question at the front hey thank you very much this is awesome um so two questions real quick uh it wasn't clear to me at least if the slang parser is being used right now by the extension and the second question is uh is there any um intention from you guys to support uh cock.nbeam which is like a yep yep so right now we do not have this line parser we're using the solidity parser and As and we're looking to dog fit the slang partner within the vs code extension um I I'm not giving her estimates maybe like it's not up to me but um yes we're hoping to pull in the slang parts are in the near future in terms of Venom COC and that's part of making the the language server Standalone and then COC would be the first Target for making it work with that and that's something that is within just teams rematch so hopefully that should be in the near future thank you very much are we having any more questions or room for one more okay go for more short one oh yeah here the front when it's sling parser comes out how do we install like is do we need to install it or is it already built in how how can we get access to it will be available it's a separate library and I believe it's written in Rust and we but we'll make it available in node and JavaScript as well okay thank you that was the last one I'd like another round of applause please for John and while we're setting up the stage yes I would like to welcome our next guest who will be presenting which is Rob stupi I have seen him yeah oh he's already here look to discuss what's new in remix Rob are you ready yeah yeah okay there's gonna be more welcome I got this ah look at that so this one goes forward nice okay and backwards yeah okay okay yeah yeah perfect so are these are all the remix fans of uh Devcon welcome welcome and get ready for our new features we're going to be whipping through about a quarter of a million slides so wait a minute I'm on the way here that's better uh like move back a little bit so um new features are everywhere and we'll be going through all these sections like the file explorer you can now clone or get repo in the file explorer right now there's this little icon we added a new little icon right over there you click that uh and but soon it's going to turn into a little hamburger icon and you click the hamburger icon and you can clone if you click the Clone button and then you get this modal to come up to ask you for the address of the mode of the repo and then it comes in as its own workspace uh so you can bring lots of code in to remix really fast or easily no um and then when you click the workspace pull down you get the get icon on all the workspaces with a git repository associated with it and you can manage to get repo in Degen of course you could before but maybe actually have any of you used the git before oh there's one and it's uh it's important uh yeah you need to be able to push pull and do all your git commands so you click the it's a plugin and uh you load up the did he get plug-in stands for decentralized get click click that and then over here if behind the chair or maybe on your screen you'll see the init push pull all the normal git commands and oh it's over there and then um you're good to go and then we've got new templates in the workspace if you add click the new template a new workspace button and then you get oh look it's over there you can get a create new um workspace I look at looking at this uh and then um what happens uh you can choose a template come on oh yeah but first you can initialize a repo any repo you want to become a git repo uh so now you click the default or that pull down menu and you get uh all the different workspace templates and now they're all the uh open Zeppelin templates or some coins opens up on templates and Xerox project and if you click one of the open Zeppelin templates you get you get uh some of the um features that you can you click one of those and you can add a new um import to your base uh coin contract and now you can drag and drop in the um file explorer which means that your workspaces won't be so messy especially when you didn't open the right folder when you're creating a new file uh and as everyone here used remix d it's an important little thing uh yeah and because it's important because remix is not like a Google doc we get emails pretty often like I lost my files and remix when the browser crashed so you just have to know where your files are saved they're saved in browsers in the indexed VB and that's in the browser and the browser is feeble you know so if you want to save it to your hard drive you can use remix D to share a folder on your hard drive with uh remix or you can uh push it to you know some other external git repo if you want um and now as a result we made the the get uh the remix d uh command a lot easier instead of a lot of flags you just go into the directory you want to share in your terminal and just type team remix D of course you do have to download uh at first and it's an npm package so uh but it's simple uh and now you can uh load uh Slither for all you static analyzers there out there you just want to load Slither locally uh uh yep and we've made some editor updates and for the master of editor updates I give you uh Philip thank you rob um for those who who have been here at uh what what do we have the green button the big green button for those who have been here at the previous session you you know how challenging it is to to build a good code editor and as we are using the same editor as the vs SVS code does we've been able to make it do some stuff that we expect the editor in vs code to do and the challenges that we had are basically the same that the nice people from hard hat have when they are doing code parsing so we've been trying to solve this problem first of all in order to use these features you have to turn them on because by default we turn them off because you know some people might not like it or it might be all too sudden but basically what we have is autocomplete and autocomplete is a very complicated Beast as we know because when you're typing you want stuff to happen so we have designed some custom part parsers we use three in total to parse the code while you're typing so what does it complete it completes globals Mutual solidity stuff it completes dot uh it does dot completions on globals from solidity it also completes anything that you have inherited from other contracts and uh anything that's available to the specific location where you're typing so that all of that also takes into account uh feasibility of certain functions or variables that are being imported through the Imports basically it also other completes functions from other contracts so that when you type approve for example it will pre-fill the variables for you and in a in the editor it's still very limited but it's getting better as we go along it's an experimental feature it has some stuff to it but we try to make it fall taller tolerant so that when you're typing and you're completely messing up it tries to make sense of what what's there and I think we've done a pretty good job uh it's for you to try out and to see if it actually is it is what I'm saying it is the dot completions are a thing that I think is specifically useful for when you're doing complicated stuff with contracts that you import here we have also a nice little feature that we built in order to complete a possible Imports when you type import basically we have some uni Swap and open Zeppelin pre-loaded so you can easily find and search files that you're looking for if you're looking for some kind of interface for an erc1155 you just type in you just go to the open zap lens slash and you type in 1155 and it will just show up in the list it's easy to import it that way you don't have to copy paste it anymore from other locations and the Imports will be available the imported classes are import contracts sorry will be available for you as other complete objects when you try to extend the contract and anything else so these things are all being taken into the attitude and into the editor these are things that we believe are important features for people to develop quickly and that any editor should actually have um we also include gas estimates gas estimates are simply returned by the by the compiler right and we need to display them on the places where the compiler says that there is an estimate sometimes there is not an estimate if you don't see the estimates that means that the compiler hasn't been can make sense of what you're doing and then then some suddenly things stop right so you see the gas here if you hover over it you see some more information because the gas is more complicated uh business we go along then we have just as in vs code we have jumped to definition and references we also have the peak function so that when you click here it will just open up this editor within the editor and you can just jump around through all the references and definitions that you that the thing can find we try here also to be fault tolerant if your file is messed up and you have errors in it it will still be able to find the uh the functions and the the definitions it will always show you all will also show you the net spec comments that are included into the files that you have imported so let me see if I can actually see oh yeah and then we have we tried to make something that when you actually type and you make an error you see this this quickly lines you get warnings and errors and what's the other thing I forgot and it also colors the files just like in Vegas code so when you have an error in a file you will see it turn red also on top you will see it turn red if you've made a an error in an imported file which is important you make an error you forget a forget something or something it will actually put us quickly line underneath the imported file and also it will also show you where the error is in the file explorer so you can easily say okay this imported file has an error I'll just go there and see what's going on uh the hovers are another feature that we do uh so this hover feature shows you the errors that you that that the compiler says that you've that you've made and as I said before it just shows you the definition and the location of the the stuff and also the comments if if there are any it will show them into the into the the hover and then we have a nice play button and this play button has several uh things that it does for solidity files which is compile the files and for typescript of JavaScript files it will just run the script that's the play button so Nifty new little feature that we made and then we have code formatting code formatting is something that I use all the time because you know I'm lazy and I'm not a python guy so yeah I I like to format a lot so I we did it and we will build some customization to it so you can actually customize the formatting to your own specifications or likings but for now it does some basic formatting on your JavaScript and on your typescript and on solidity so try it out and see what it does and see if you like it and if it's it's if it becomes a big match just just tell us and we'll fix it uh here in the opening screen when you close all the tabs in remix it will just show you the screen and it contains the uh the shortcuts that you can use in the editor so the important part to remember from this from the editors is to turn on all the features in the settings so that you can actually use them if there is something that doesn't work just tell us because we need to learn from the experience from people who actually use solidity a lot and so that's important uh the next part is proxy contracts and I want to introduce you to David diesu and he will talk about it thank you [Applause] okay um hi I'm David and I'll be talking about remix IDE support for proxy contract okay um remix ID allows you to be able to um deploy upgrades to your smart contracts we just introduced this I think a few months ago about a month two months ago and it was Purely Inspired by continuity of your project I believe with all at some point deployed some contracts that we might feel like making some changes to and then we couldn't do that because there was no provision for upgrades so we have that and we the remix IDE uses the open zipline ERC 1967 proxy contracts to help do this now the opens their plan um supports three types of proxy upgrades I think the uups the transparent and also the beacon for us for now on remix IDE we support you using uups and pattern for contracts upgrade um yeah okay and then it requires you having the uups upgradable that's all in order for you to work um this feature can easily be tested if you assess the open open zipline wizard you can be able to customize how you want your contract and then you select the uups upgradable and open a remix if you have that you compile you should be able to have this we also have templates I believe Rob was talking about templates towards the beginning you click create workspace you can select and customize what you want by checking also the proxy so once you have your contracts in the IDE compiled you should be able to have these options deploy with proxy or Bluetooth proxy um yeah so basically remix ID does in the background the deployment of the proxy contract so we we basically have a compiled byte code of the ERC 1967 contract which we deploy as your proxy and then we now have your implementation contracts deployed on top so basically when you're interacting with this feature you'll be prompted with a model um instructing you that two transactions will occur and then using the jsvm it's super fast so you just see it immediately after the first deployment the first display oh yeah the first deployment and then the second yeah but then um if you're using say metamax I'm deploying to mainnet or one of the test Nets to be a bit slower because one of the transactions has to complete that's the the proxy deployment first before the implementation okay next oh yeah so after deployment you have this interface displayed the first here is the deployment of the implementation contract and then this is the proxy now these two instances have the same UI but then you get to interact with the proxy you get to interact with this UI and not that and this is because the whole point of having an upgradable contract is that you don't want to interact with your implementation you want to interact with the proxy but then we still display this so that you don't get confused and feel like um something is up but um it's actually just there so that you interact with this and then this makes low level um delegate calls to your actual implementation contract okay and then we also have the upgrade so now for the upgrade you need to provide your proxy address if you use remix IDE to deploy your proxy originally then you can check this box to be able to use the last address yeah so really smooth and moving on in the future we plan on having um a list of previously deployed proxy addresses so that you can be able to pick from and not just the last deployed address yeah uh yeah I think I've talked about this it makes a delegate score I guess to your implementation contracts okay also talking about workflows remix IDE also has a git of action that allows you to be able to run your solidity test on your GitHub workflows so it can be integrated as part of your build process and you can be able to have it run on the solidity unit testing every single time there's a push or depending on how you configure it to be we also plan to have the static analyzer also added as GitHub actions so that you can be able to have it on your GitHub project we also are currently working on having you run JavaScript test with mokan chai also as GitHub actions so yeah okay uh oh yeah yeah this is a sample this is a sample workflow that can be used um yeah I guess it would be nice to check it out on the GitHub Marketplace uh moving forward I'll be handing over to Rob to round things up right in here okay okay a few more things to go over uh we got a new workflows uh for quickly working out problems so setting in the state of a contract is kind of can get kind of hairy because you gotta maybe have to deploy a bunch of contracts got to go in and hit a bunch of functions and you got to remember what you're doing each time you develop it can be you got to remember what the process is so you can make a script that does that for you and then let the script run after you do a little bit of coding uh and now we have this uh button to push so you and you uh click that it will compile the contract and then run the script and you connect the script and the contract with some Nat spec comments there's an example in uh the the default one underscore storage to see how to connect the uh the net spec comment to connect the script and the uh smart contract uh so you don't have to you hit uh compile and run all the time you could just hit it when you want to so just compile compile compile and then when you need to run it or I guess you probably could do it all the time too uh we've got a bunch of interoperability updates uh uh you can compile for a hard hat project when you share the folder you're with remix D to the hard hat project to your hard hat project uh and you can think now so if you want to uh use remix or truffle or I mean if you want to use a hard hat truffle or Foundry and uh deploy with and you can then you can deploy with remix so once you share the folder uh and then you compile a file in one of those other Frameworks then you can go to the the file to the deploy and run and hit the refresh button like that one was compiled by a hard hat and then we took the same file and compiled it and remix and it comes up with compiled by remix and then [Music] um yeah then you can deploy and run it uh we got uh heart uh Foundry remappings when you share the uh folder with a Foundry project and here's uh 27 seconds so we can have some time for questions uh of some quick uh grab bag of stuff um oh we got the advanced settings in the solidity compiler so if you click the button over here you can see example Json file that will uh run all your compiler settings so you don't have to do it by that and deploy and run there's a bunch of new providers environments and um and now for beginners it's easier to see which one is the injected web3 the injected provider and it will say the name of the injected provider uh also now like they're in the environment section the top link goes to chainlist.org so you can find the spec of the chain you want to deploy to and when you're looking at one of the l2s it will go to uh a bridge to get the funds for that debugger got wider there's a console.log just like hard hat uh uh and to get the to the to the um documentation you gotta click that little carrot it opens and then you can click the book to get to the documentation and also the little green check mark means that remix uh is uh owner of this code we have a little bit updated Viper so you can go to the Viper plug and click that and it'll download the Viper Lang uh repo and there's a transaction recorder which probably none of you have ever used but you should check it out it's in the middle of the deploying run and browse and grab if you take if you go to a verified contract an etherscan uh you just change out the ether scan for a remix and um it'll uh open it up in the editor and now questions thank you first oh for you so much yes we have questions in the back coming up already yes take a moment for the mic to get to you yeah just it's a question about I see I know there's there's already some integration between remix and swarm I'm just wondering if you have any thoughts on the future of where that might go I guess that we're in uh open conversation with them there's a right now we're adding the postage stamp uh so you could publish the Swarm the next steps uh I'm not entirely clear about but you know we like to that will be going on continuing not dropping right anyone else yeah oh here in the background in the back over there hey just a quick question um are those features already are available or do we have to wait no those are all available awesome thanks at the front here as well type it's a simple question is a way to enable Bing mode because uh right now I'm using a browser plugin but I hope that you can support the the bin mode online mobile pin mode the Bing editor so yeah we spent some time to improve the editor like an acquisitor and then I think it's on the request that we had last year and uh I mean we are looking at that it's not like something we will prioritize for now except if we would if we would push for it uh but yeah we could do it um yeah well it could be Ray push for it and we would do it for sure thanks anyone else okay in that case I'd like to thank you again thank you so much [Applause] like and just to check gentlemen Rob where can we find you later okay in the room when there are on their backup in the meantime I'd like to announce uh our next speaker it will be Lawrence breidenbach talking about improving the Oracle infrastructure on ethereum and Lawrence is in the house here somewhere we have seen him and you should have a mic as well somewhere in the back welcome take your seats yes is he not here waiting back okay okay let's give him a warm Applause foreign my name is Lawrence I'm head of research and development at chain link labs and yeah today I'm excited to tell you about improving the Oracle infrastructure on ethereum for those of you who don't know oracle infrastructure connects smart contracts with the rest of the world with the world outside the blockchain and so let me start by talking about the most prominent use case of oracles data feeds um I'll start by reading a quote we'll play a little game you guys can weather read the quote guess where the quote is from I'll give you a few more seconds after I'm done reading the quote and then I'll reveal the answer so the quote is for example one powerful use case of an oracle contract would be a hedging contract where A and B put in a thousand dollars worth of bitcoin and after 30 days the script sends a thousand dollars worth of bitcoin to a and the rest to B this would require an oracle to determine the value of one Bitcoin in US dollars sounds a little bit like defy but the terminology is a bit different from what we would say today so the solution is it comes from the ethereum white paper all the way back in 2014. so already back then it was clear that oracles are required for certain types of applications and indeed here we have an example of a you know price feed or data feed Oracle and if we think a little bit about the properties that the supply is that we need our Oracle to have there's two things that stand out so first of all we need reliability we need to make sure that when the 30 days are up here indeed the Oracle supplies the exchange rate between Bitcoin and dollars so we can fairly settle the hedging contract um and then we also need security and integrity right the price that is provided here by the Oracle will be used to settle the contract and so if the price is incorrect then we won't be able to settle the contract fairly so it's essential um that we we have a Oracle that provides these properties and I think if we if we think about the history since then billions of dollars have been stolen in Oracle manipulation attacks so Oracle security is Paramount for defy so let's have a look at how one might construct such a data feed Oracle and I'll start with a straw man construction and then I'll evolve that construction into what I would say is the state of the art today and is what what chain link does today so here in this from an example we have a data source that you know the Oracle observes in this case the data source says Hey ten dollars is the price the Oracle will sign that price and it will then provide it to a contract running on chain and then adapt contract can read price from our data feed contract but if we think a little bit about the two properties I had just mentioned reliability and security then this system does not achieve them because we have a single point of failure if this Oracle goes down or fails to provide the price then the system on chain won't work and similarly if the single Oracle here is compromised or malicious then it can feed a false price to the contract on chain and cause the contract to be settled incorrectly unfairly so how can we solve this problem well there's a few different approaches that people commonly take but I think the most common one today is to say let's decentralize the Oracle so let's have a bunch of independent oracles all provide the system together and so what we've done here is we now have multiple oracles that each federal price from a data source and then send their individual signed observations to our contract running on chain and that contract on chain stores the observations until there's efficient number of them then Aggregates them into a single price using a robust aggregation for for these data feeds the typical aggregation one would use for numerical data is to take the median because that's a robust statistic that doesn't respond to for example false outlier values or things like that and then you know once we have medianized our value we can expose it to the dab contract Downstream and this is nice because we can now handle subsets of oracles being faulty right so if some of the oracles here do not send a price um or if some of them send false data that's okay uh if they if they don't send a price our data feed contract can just handle that by ignoring a certain number of missing submissions and if they send a false price as I had mentioned we use the median which is a robust statistic and which ensures that as long as no more than half of the oracles here are faulty the aggregate price still lies within the interval of prices reported by correct oracles so this works well in terms of giving us the security properties and reliability properties we want but there's a problem here right if you're familiar with smart contract devices notice that we're sending one transaction per Oracle here we store the submissions in state and we compute an aggregate on chain all of which are expensive things to do and indeed this is how chain link used to work in the past with a system called flux Monitor and indeed that became prohibitively expensive and so we moved on to the next Generation which I'll describe now so I would say that the state of the art then is to say let's move as much work as possible off chain the less we need to touch the chain the more efficient our system is going to be but we'll want to do this in a way that preserves the security and reliability properties that we desire um and so so roughly speaking what we do here is we we again have our oracles observing prices from from their respective data sources uh but now we have the oracles communicate with one another using a peer-to-peer uh Network um and we for the distributed systems folks out here have them run a Byzantine fault tolerant protocol Byzantine fault tolerant means that they can handle arbitrary faults so any of these oracles could be you know malicious or faulty or down or whatever else and as long as you know some subset of them is affected by this depending on exactly how you set up the assumptions either less than a third or less than half of the oracles the overall system will keep functioning correctly um chain Link's version of this is called the off-chain reporting protocol and indeed it's far more efficient than the predecessor I had just showed you so we realized something like 90 on-chain cost savings um and this is good for security because it means that with the same security budget we can have a lot more oracles so we can tolerate more faulty Oracles in the system and it's also good for liability because in this system um at the end of the off-chain protocol every Oracle ends up with a identical copy of the report which is signed by a quorum of the oracles and the contract will then validate that the report is indeed signed by a quorum of the oracles and what this means is that as long as a single Oracle is able to get a transaction on chain the the overall system will keep functioning correctly and so for example during times of chain congestion this is very desirable so indeed as I mentioned right this is how how the chain link off chain reporting protocol works and it's been it's been very successful so we we designed it for powering data feeds on evm Chains It's been running reliably and securely for at this point one and a half years in production it secures roughly 20 billion dollars of value across all the various trains that chain link is active on 14 billion just on ethereum there's more than a thousand feeds across all the chains we're active on and more than 290 of those are on ethereum and I think the the reliability and secure system are also shown by the fact that we have major major D5 protocols relying on this system uh like names such as other compound and synthetics all use this cool but okay so I told you about data feeds but now I want to tell you that oracles are about a lot more than just data feeds they enable in the general sense interactions of smart contracts with the outside world that is to say you know things that are outside the blockchain or contract executes on and so they Empower smart contracts to reach their full potential because now I can do a lot more interesting things with my contract um than if I'm just isolated on the blockchain and cannot interact with the outside world so here are some of the capabilities that are enabled by by oracles data feeds I just talked about proof of Reserve I can ensure that on-chain assets are sufficiently collateralized by some off-chain reserve of funds by having independent oracles monitor that reserve of funds and Report uh how how large the collateral is secure Randomness contract Automation and cross-chain interoperability I'm going to talk about more later in the talks I won't go into them now Fair sequencing you know I can use an oracle Network to protect users from toxic Mev extraction by fairly sequencing transactions I can Outsource computation and storage so that I can enable contracts to scale beyond what the evm provides as much as we all love the evm and as much fun as gas golfing is there are some things that are just a little bit hard to do on the evm and then finally I can also enable oracles to perform real world actions so we actually had a hackathon a couple of months ago inside chaining Labs where we had contracts ordering pizza via the Pizza Hut API to people's houses so I think that's a that's a pretty neat use case that is enabled here and that would not be available to contracts natively and then finally we can also provide privacy preserving access to almost any Web 2.0 data and I'll cover that also towards the end of my talk so this gives rise to this notion of hybrid smart contracts and when I say hybrid smart contract what I mean here is a hybrid system that partly operates on chain in the form of a smart contract running say on ethereum and partly off-chain operated by a network of decentralized oracles and so this overall hybrid smart contract is now able to interact with the real world and so so this enables me to do all sorts of interesting things um and and let me you know give you some more specific details on some of these and I'll start by talking a bit about secure Randomness and what that enables contracts to do so as you were probably familiar there's kind of two on-chain native ways on ethereum these days uh to get random values one of them is the block hash op code and that sort of you know audit findings 101 do not rely on the Block hash op code for Randomness any block producer can can easily tamper with that and now since the merge there's also a second op code prefrandau which is a little bit better than block hash but which is still manipulable by block producers and so so the output of both of these can be biased so if your contract needs secure Randomness for example for running a lottery or for doing a nft mint where you assign valuable random attributes to your nfts these are not good enough and so on chain there's no native capability to get good Randomness and this is where oracles come in and oracles can provide that functionality um so we we have a cryptographic construct here that's called a verifiable random function and that enables an oracle to provide tamper-proof Randomness and let me explain how that works so we start here with our dap contract that if it wants some Randomness can request from another contract on chain that's part of this drf service some random words the contract will emit an event with you know just telling the oracles that Randomness has been requested the oracles will evaluate the verifiable random function which is based on deterministic public key cryptography that is to say the oracles actually have no ability to change the output It's deterministic So based on a given keep here and a given blockchain state which is used as the input for for the vrf we will always get the same output value the same randomly distributed output value and the oracles will then provide a cryptographic proof that they correctly evaluated the vrf will send that cryptographic proof to our coordinator contract here which can cryptographically verify the proof and if indeed the verification succeeds then finally the coordinator can send the random output here to the DAP contract which can then for example run its lottery or whatever else and this is live today in production if you are writing a contract and you need this functionality you can use it and I think there's over 1 400 unique contracts that have used this in the past 30 days it's okay Randomness is cool uh now let me talk to you about yet another use case that is live today and that you know enables contracts to do more interesting things and that is contract automation once again I'll return to the quote from the original ethereum white paper in 2014 but this time I will highlight a different part so here we have after 30 days the script sends a thousand dollars worth of bitcoin uh to a and the rest to B so how does the script do this how can the script or the smart contract send those funds to a and b contracts do not have an ability to initiate their own execution right and of course I could say well you know I'll just have my users A or B here you know call the contract after the 30 days are up and then I'll do a payout and maybe if I just have two users that's fine but now let's say I have a lot of users or I want to you know sweep a bunch of tokens from different contracts into a single pool or whatever other expensive maintenance action my system requires to run then that will lead to a very poor ux if I put the onus of Performing those maintenance actions on the users interacting with my dap um because if I'm a user I now have a non-deterministic gas price right once in a while when I interact with adapt it's going to cost me 100 000 gas another time I need to maintain some expensive maintenance on the side and suddenly it's going to cost me 500 000 gas that's not great it's also unreliable because I can't really rely on my users calling the contract at a specific point in time and so this is where where contract automation comes into play so once again here we have a set of oracles or automation nodes that are monitoring the chain and the upkeep contract here is the the dab contract and the app keep contract is just any regular smart contract written and solidity or Viper or whatever programming language you prefer and it has a special function called check upkeep and that function will be evaluated by our Oracle Network here whenever a new block is mined but it will be evaluated in a simulated environment using the say F call RPC endpoint of an ethereum node so we never hit the chain with with these evaluations no transaction lands on chain and so we can call this on every block without incurring any cost um and so then the you know the programmer of this upkeep contract can basically come up with any arbitrary predicate to decide whether their contract ought to be called or not um and you know if if the contract says no I don't want to be called no problem we just check again in the next block um but if indeed the contract wants to be called It Can indicate so to the Oracle Network which will then send a second or will then actually send the first real transaction to the chain that's not simulated um with a perform upkeep call for upkeep contract here and now this contract on chain can you know take whatever logic it wants to so for example in the previous case at this point it could have paid out our two users A and B uh depending on the outcome of this hedging contract and again this functionality is live today there's over 250 unique upkeep contracts that have been active in the past 30 days and if that's useful for your for your smart contracts then I would encourage you to check that out okay so I've been talking a bunch about data feeds and about other Oracle capabilities that are live today but I'm from research right so I'm particularly excited about the future uh and and what future capabilities we're actively working on to bring to Market and I'm going to present two exciting capabilities and both of them are in an alpha state with Partners so both of them are are already working in some form even though they're not quite ready for for mainnet production yet and the the first of these is cross-chain interoperability um so the problem here is that smart contracts cannot natively interact with smart contracts running on other blockchains um but we live in a multi-chan world now right there's dozens of chains out there it's a very heterogeneous environment some memorable ones some are l2s some use the EDM some don't and so on and so forth and so indeed there's also a lot of demand for bridging between contracts on different chains so today it's something like 168 billion dollars of value have been bridged just in the past 12 months we've seen over two-thirds of the total volume ever bridge for something like 115 billion dollars bridged um but also we have a challenge with security in this cross-chain space so to date 2.5 billion dollars have been hacked from cross-train protocols um and just this year over 70 percent of all values stolen uh in in kind of the blockchain ecosystem is from cross-chain hacks uh so I think once again this indicates that security is Paramount but that unfortunately the the current Solutions are not yet up to the task um so we at chain link are also working on a solution to this problem which we call the cross chain interoperability protocol ccip and so here we're working on a programmable bridge that enables a smart contract snap contract here say on ethereum to send a message to a contract running on some other chain and you know it could be talking to multiple other chains so here I have it sending a message from ethereum to this other chain B um and the message can carry both data so some kind of arbitrary binary payload as well as value so say tokens and again I need oracles for this because inherently the other chain b or ethereum have no way of knowing what happened on their counterpart chain that they want to talk to here and so oracles can can bridge that Gap and they can transport information about what happened on one chain to another chain to enable contracts on different chains to interoperate um this is again you know as I mentioned it's very important that this done that this is done securely because if for some reason here I were to get uh you know false information about what message was uh created on ethereum and then that could for example lead to to funds being moved uh on this other chain here when they shouldn't be and I would have a security breach um if you want to learn more details about this we just had a talk at smart con roughly two weeks ago where we went in more detail about the architecture of ccip and it's on YouTube so I'd encourage you to check that out if that's interesting to you the second Oracle enabled capability for the future that we're working on is about providing privacy preserving access to Web 2.0 data to almost any Web 2.0 data to Smart contracts and this is I think a super cool capability at first it sounds a bit unreal like how does this work how could this be so let me let me show you what I what I mean here so the the fundamental problem is that the the vast majority of data is private and is therefore not publicly accessible in the Web 2.0 ecosystem so for example my online bank account my Twitter profile my Facebook profile my Amazon account some government website none of these are accessible by smart contracts on chain because all of them are behind some kind of authentication wall right and I would argue that's a good thing I don't want my bank account information to be just visible to any contract on chain but still it would be kind of cool if there were a way to expose in a privacy preserving information just the information required to Smart contracts unchain because that would unlock I think many interesting use cases things like decentralized identity risk scoring where I can use information about my off-chain behavior to you know score how risky of a borrower say I am consequent consequently undercollateralized lending where you know maybe in order to borrow 100 worth of assets I don't have to put up 200 worth of collateral on chain or private defy instruments where I can have a D5 instrument where only the parties that are participating in that instrument uh need to learn you know what exactly the conditions of it are on what based on what condition it's settled and so on to improve privacy of on-chain trading and more things that I probably can't even imagine yet this is a very general technology and so the technology we're working on here to to address this is called Deco Deco was originally researched at Cornell University and ic3 the initiative for cryptocurrencies and contracts and since then chain link has has pushed the project forward is actively developing it and further researching it to make it efficient and practical and so I'm briefly going to describe to you how Decor works and what properties it affords first in the abstract and then by going through an example so we have three off-chain parties here we have a web server uh we have a prover or a user and we have a bunch of verifiers or oracles and so now what what Deco enables the user to do is to prove to these verifiers and then by extension to the smart contract that some data indeed comes from a certain web server so for example I can show that indeed bank.com made some statement we assume that this web server runs TLS which is the the standard protocol for securing Communications on the web today uh you know whenever you go to some website you'll probably see a little lock icon at your address bar indicating that the connection is secured with TLS so I can prove provenance so I can show that the data indeed comes from a certain Source but I can do this in a privacy preserving way where I can run a zero knowledge proof protocol to only reveal the information the minimal information that I want to reveal to the verifiers and then by extension again to the contract um and right so so the web server obviously if it's for example my bank knows my balance and my password I as the user also know my my password and my balance but the the verifiers or oracles for example should definitely not learn my password right and Deco enables me to do this in this privacy preserving way um and then finally and I think this is actually the coolest property of Deco it's compatibility so it's compatible with the existing TLS web ecosystem and that means that there's no need to get for example the data holder here the web server to change anything about their API or their stack they don't even need to know that Deco is being used to prove something and you know if you for example look at how hard it is to get the internet migrated to IPv6 you know that protocol upgrades are very difficult so it's I think a game changer here that this works with the existing Web 2.0 ecosystem without requiring modifications on the part of the web server or the user so let me let me show you an example um so I'm the I'm the approver I'm the user here my name is Lawrence and I want to show to a contract on chain that my bank account balance is greater than a thousand dollars without revealing anything on top of that um so what I'm going to do is I'm gonna Connect using TLS indicated by the green locks here to the API of my bank using TLS so I'm going to say hey I'm Lawrence my password is hunter2 what's my balance um and now the the bank API you know will respond hey Lawrence your balance is say five thousand dollars which remember I do not want to reveal uh to the verifiers or to the contract um as part of the way the the handshake works here between me and the banking API um I'm also able to just as part of this TLS exchange ensure that the verifiers or oracles here get a cryptographic commitment uh to the data that is being exchanged and that commitment as as we say in cryptography binding and hiding which is to say that if I so so you can think about it as an envelope where I put some data inside if you just have the envelope you cannot see what's inside but you also cannot switch the contents without somebody noticing because you kind of tore the envelope and this is basically a similar thing here so the verifiers hold a cryptographic commitment about any data that was exchanged within the session so I as the user cannot sort of alter the data after the fact but the verifiers do not see what's inside the commitment the commitment is hiding so they have not learned at this point any private information any information at all about what was in the TLs session and so now we get to the final step which here I'm abbreviating with zkp magic because I have like two minutes left on this talk but the the way this works is that we now run an interactive zero knowledge proof protocol between the prover user so myself and these oracles and as part of that zkp protocol I can convince the oracles cryptographically that indeed for example this statement holds so that my balance is greater than a thousand dollars but that is the only thing they will learn they will not learn my credentials and they will not learn my precise balance the oracles can then cryptographically sign an attestation that they have successfully verified the zero knowledge proof and this attestation can be forwarded to our smart contract on chain here again you know signed by a chrome of oracles and then we can verify the contract that indeed those those signatures match and so now I have convinced the contract on chain that I have you know at least a thousand dollars in my contract and I've done that without having revealed any additional information and and you know you can think about this in a far more General sense because this is your knowledge proof I could basically prove almost any statement about the data that was exchanged in almost any TLS session so this is a very general and very powerful technology I believe and I'm yeah I'm excited to see what people are actually going to build with it because I think due to its generality I personally have a hard time imagining what's going to be enabled by it so yeah thanks a lot for for listening to my talk there is there is three things um I'd like you to to take away so first of all security and reliability are Paramount for oracles um second of all um oracles are about a lot more than just data feeds I think I've shown you a bunch of exciting applications of what oracles can can do um yeah and third of all I think we we yeah have a opportunity to make contracts more exciting more interesting to empower them to reach their full potential Beyond just doing things within the closed on-chain uh ecosystem that they would naturally operate in without the native oracles so yeah thanks a lot and if you have any questions I think I'm I'm over time so just come and find me after the talk you have time actually you have time there's time allowed for your q a so there's room for questions right now what did you say there's room for questions right now there's a time allowed for your q a right now oh yeah sure I'll take a question so I see one in the front here where is our microphone other there first test okay so um oh are the guys face paid by the contract automation sorry could you repeat the question I couldn't hear you in contract automation uh how are the gas fees paid I see I see I see so basically what happens is that the DAP that relies on contract automation um oh yeah we'll we'll maintain um a balance I don't know whether it can go back to that slide no no no no more anyway so so it maintains a subscription balance with an automation registry contract that sits on chain and then when the DAP is invoked by the Oracle Network um that automation registry will keep track of how much gas is used as part of that transaction the perform upkeep transaction and will you know Bill the user's subscription for that so um and when I say the user here I mean the upkeep contract so so in that sense as long as the subscription is funded we will just automatically you know have the contract deduct the the price of the upkeep from that does does that answer your question yeah yes perfect there was another question here at the front and another one in the back we're going to the back first you're not forgotten yeah hey here oh here in the back yeah uh thanks for the talk first um I'm just wondering you showed us the diagram of like how the Oracle like understands uh the fact that the user has like more than one thousand dollars um but you also show that the user the the Oracle can see that that the transactions between the user and the bank API we don't actually seeing the balance right so sorry I'm having a hard time acoustically understanding you um am I doing there's a lot of room here test you can hear me now yeah let's try again we'll get there taking me now is it better now no now I continue yeah so you showed us that the gram where uh the user and the bank API exchange that made those messages right so this is about Deco right yeah too bad we can't show the slide yeah okay so the bank says that the balance is five thousand and uh Oracle sees that but without seeing the balance right so the Oracle does not see the the five thousand dollars yeah the Oracle just has a cryptographic commitment against which we can then perform an interactive zero knowledge exactly I'm just wondering how the Oracle then can verify that the balance is over one thousand without like showing that the balance is five thousand right because the exchange was only like containing information about five thousand and not about like one thousand right right so so my my short answer and forgive me is just gonna be Magics your knowledge proofs um basically that's what dkps are about right I can I can prove statements about data and sort of very counter-intuitive ways without revealing anything beyond the statement um but I think we probably don't have time to go into the details of how that works unfortunately but come find me afterwards and I'm happy to talk more final question here at the front yes uh so I have a question about the OCR the off-chan uh Oracle reporting protocol so with uh with the blockchain is easy for the different note Rich consensus right because I can check the uh the transaction signature the country rerun all the byte code of a smart contract by the way the Oracle uh how does the different nodes ritual consensus because uh if it's a if it's a data fade then you cannot compute right you cannot compute the weather this phase is correct or node and okay let me I'm not entirely sure I understood the question correctly so let me take a stab at an answer and then ask again if I didn't get it so so I believe that the answer to your question is OCR is a Byzantine fault tolerant protocol that is actually the same family of protocols that consensus Protocols are from right it uses similar techniques it just has a different goal its goal is to provide you know reliable and secure reports about some you know data observed from off chain to contracts on chain but it's it's similar techniques and so um you you kind of as part of how that protocol Works get that property that you know the oracles communicate with each other over the peer-to-peer Network and that some of them can be faulty and so on so you you know you you broadcast things you converge castings you use digital signatures the the usual type of things you would do in bft protocols yeah uh I mean if uh let's say if there's a ether and or if the other blockchain uh different nodes that just have to have the same similar result from the transit executing the transaction how a similar result if a two-thirds two-thirds of nodes have a similar result then can reach a consensus right but but with uh I understand with uh you can use that for the for the consensus layer but uh how could you have buy something for tolerance for the for the data field right data field for example one node say the the price of a series 1000 another node say the the price of ethereum is two thousand uh you you cannot uh how can how can reach the consensus sorry it was it was a little hard to understand unfortunately because there's so much Reverb in here but I I think what you're asking is how we reliably aggregate the data in time inside OCR is that correct no uh for like a full computation for computation tasks it's very easy to reach a consensus between different computers because as long as your as long on the result or computation is the same if two two-thirds of node uh computer agreed like the result of the computation result of one transaction is the same then you have a consensus you have you're fine you're good but uh with the data fade like let's say if uh if two if one sort of a server or node or trying to know the thing the the price of ethereum is uh one thousand I see I think I think now I get the question okay so so basically inside the OCR protocol which I did not have time to explain in detail here there is a phase where where the different Oracles um converge cast their individual observations to each other and at the end of that phase every Oracle will have a signed observation from every other Oracle so if you know we have a bunch of Oracles in here every Oracle will know what all the other oracles think the price should be and at that point I can then you know have everybody compute the same kind of deterministic aggregation function and I will end up with the same outputs and so I can reach agreement between the different Oracles does that answer the question oh yeah yeah it's somehow how many how many names sorry no follow-up questions just one just one quick follow-up question how many notes afterwards yeah that's that's just it afterwards okay cool thanks I'd like a big one Applause for our speaker today thanks everyone and as we'll take a moment to prepare this stage everyone who comes in just please settle in take your seats we will be talking about decentralized programmable programmable key pairs and for that we will have both Chris casano and David Schneider available waiting to come up the stage okay let's give them a warm Applause people yeah [Applause] good afternoon all right um my name is David Snyder that's Chris casano and as you can see we're going to talk about decentralized programmable key pairs we are the two co-founders of a project called lit protocol and to start with a big exciting hook we are living in a world where with threshold cryptography from a certain point of view you can consider that private Keys no longer exist so what do we specifically mean by this this net lit network is essentially a distributed custody programmable key and one of the key Technologies at the heart of this is something called a dkg a distributed key generation and so what lit is specifically is a distributed network of nodes that are custodying shares of an underlying private key I'll take a quick moment to talk about how security works on this network and then we'll get into some of the use cases but essentially this key is formed in this distributed key generation context and stored as shares across these nodes and then all of the nodes operations take place inside of a trusted execution environment and then there are named node operators who are staking that are running the programs on this underlying key and so now let's talk about what some of those programs can be so as you know a key can functionally do two things it can read or encrypt and write and this network provides the same functionality in a programmatic way so let's talk about how the read works first the hexagons in the middle represent the lit nodes in this case Alice let's say is a Creator and wants to say anybody who owns uh Alice's nft can see her video she would encrypt that video client side and store it somewhere in public whether it's on a blockchain or a storage Network like ipfs and then create a set of rules that says only somebody who owns Alice's nft can see that video Bob owns that nft he shows up later he signs a message and he broadcasts that to the nodes each of the individual nodes validates against the blockchain does Bob own that nft and the whole kind of frame of view here is thinking about these Public Storage excuse me public state machines as Access Control lists at which point the nodes verify that Bob has that node or excuse me has that nft and each of the individual nodes produces something called a decryption share you could think about this like an authorization those authorizations are then sent to Bob who's collecting them client-side and a good mental model is kind of similar to the way that you may think about torrenting you know torrenting you're collecting little bits of media from a bunch of nodes in this case you're collecting bits of authorization and once you've collected a threshold of those authorizations in this case decryption shares Bob can reproduce that symmetric key associated with the video or that content and decrypt that client side and so some of the applications that we're seeing this used for today are things like token gated uh social media like tokengated chat this technology is used hand in hand a lot with like the lens protocol for example where only let somebody who's following me on on lens see my posts we also see this in uh happening in the context of intellectual property whether it's token gated videos or various other content and then really excitingly there's also been a lot of stuff around verifiable credentials and selective disclosure so I'm sure you all are familiar with the notion of like signing in with Google as an authorization method for how one logs into a site what we're starting to see is some teams build this out in a much more kind of user Sovereign type of way whereby when a user goes logs into a site they're conveying decryption rights or quote the read writes to that application to see their private information and starts to become like a pretty interesting picture and we'll talk more about um what this this user-owned web looks like but in a way this is kind of one definition of web3 where the user rather than necessarily showing up to a website with their own kind of self-sovereign server they're arriving with their own encrypted Shard of the open web and then selectively disclosing two various friends or applications what information from that Shard they can decrypt or read and so this product has been out since January and we still are running all the nodes centrally and we'll have those decentralized by the end of the year and there's hundreds of applications that are leveraging this but just last week we started um talking publicly about a new capacity which is the ability to essentially do distributed custody programmatic signing and as you can see the architecture is incredibly similar but instead of the nodes reading the blockchain as an access control list they are reading programs that are stored at a specific CID on ipfs each of those nodes is running those programs and now in this case instead of producing the decryption share which lets that party decrypt some content they're producing a signature share again coming back to the idea that keys can functionally do two things kind of encryption and signing and then those shares can be aggregated and you can make a right to your favorite decentralized state machine like ethereum and so talking about some of the applications for this there's a huge list right thinking about the a key as an application development platform we kind of like think about it as a paintbrush we're really just starting to explore some of the application potential here but I'll run through a couple right now so one would be like D5 automation the state of the art for self-custody defy today is if you have some staked tokens and you have to the state of the artist to sign up for some defy alerting Service Such that when the price starts to drop you get a text you have to wake up in the middle of the night and push a button on your Ledger but in a world where you've staked those tokens from one of these Cloud wallets as we can kind of call them you could have that program listening to a feed and when the price drops have a program that kicks off that unstakes the tokens sells them for usdc on a decks and sends them to your Ledger and this is all happening kind of without a human sign or in the loop because the key is custody and is distributed context at the network level Chris will talk a little bit more about vaults but in a way what we're talking about here is making private Keys liquid so you could send a bunch of nfts and tokens to a given address and then trade the underlying ownership of that address there's also a lot to explore here as it relates to account abstraction doing things like cooking up a biometric auth like apple Pass key as the auth method into one of these Cloud keys in this whole context of how do we bring the next billion users into this ecosystem and Abstract away the complexity associated with the seed phrase this is really exciting and certainly a lot to explore in the context of cross-chain messaging and bridging as well and so with that I'll pass this clicker off to Chris thank you David uh yeah so I'd like to introduce the idea of a decentralized programmable key pair which we call pkps a pkp is an ecdsa key pair that's held as private key shares custody by the lit nodes you can create a pkp by minting an nft that represents ownership over that pkp and so whoever owns that nft can ask the pkp to sign anything on their behalf including ethereum or even Bitcoin transactions you can do this by writing some JavaScript code that we call a lit action so this is a really basic hello world uh lit action it literally signs the string hello world uh with ecdsa and what happens is this code will be run on all the lit nodes in parallel lit actions live on ipfs and are immutable just like smart contracts and I just explained that whoever owns the pkp nft can request a signature using the pkp but what's actually more interesting is that you can also Grant the ability to sign using your pkp to a lit action this is very similar to the Token approval pattern that we use on ethereum where you can grant a smart contract the ability to transfer your tokens but instead of granting the ability to transfer tokens you're granting the ability to sign anything with this programmable key pair so here's how it actually works the user can create a lit action execution request which you can see at the top there I think I had a laser cool and they pass in an ipfs CID which is Javascript code and a cryptographic signature that could come from their ethereum wallet and apple Pass key or any public key cryptography scheme they send that execution request to all of the lit nodes in parallel the lit nodes use a JavaScript runtime to execute the lit action from ipfs they check the pkp authentication by talking to a blockchain where the pkp nft lives and the lid action can also make arbitrary HTTP requests so it can also act as a kind of Oracle and such okay it can also act as a kind of Oracle um so you can pull any data in and use it in your JavaScript lit action the lit action can request a signature using the threshold private key share that creates a signature share that gets sent down to the user that initiated the request they could be using a browser or this could be like a server-side client they combine those signature shares and they broadcast that signed transaction to ethereum or any ecdsa blockchain and I'm talking about a transaction here but it doesn't actually have to be a transaction it could be any signed data like a right on a ceramic or anything else like that an interesting pattern that Lit supports is called mint Grant burn the idea is that you mint a pkp grant it the ability to use a lit action then burn the pkp in a single Atomic transaction this means that the pkp can only ever be used by that Lit action because burning the pkp makes it impossible to use the pkp for signing anything else a kind of fun toy example would be creating a lit action that takes any number as input but will only sign that number if it's Prime since anyone can check that the signature matches the public key of the pkp they know that any number signed by the corresponding private key must be Prime and the signature acts like a proof that the number is prime you end up with a kind of prime number certification system this can be used to create a proof of any JavaScript code execution and this is kind of similar to how ZK proofs work conceptually but instead of being proven by pure math it's proven by the guarantees provided by threshold threshold cryptography via the lit Network and here's kind of how that works the um the way that you interact with and Grant access to use things is by talking to a pkp Smart contract that currently lives on cello but we're going to move that to polygon soon and you mint the pkp grant access for it to use the lid action in this authorized lit action table and then you burn it all in one transaction so we talked a little bit about using a pkp as a vault you can mint a pkp then send a bunch of assets to it like nfts tokens ethereum and even ones not on ethereum like Bitcoin or Cosmos tokens then you can sell the pkp nft on openc and transfer all the assets at once you are essentially trustlessly trading a private key something that has been impossible until now this breaks Soul bound tokens because now you can trust literally sell the wallet that contains your soul bound tokens in the same way that you could sell a traditional non-sol bound ERC 721 nft this also enables things like liquid staking for chains that lock up the staked tokens like ethereum 2. you could use a pkp as an eoa Cloud wallet because a pkp can grant the ability to sign to a lit action you can create any auth method that you want as long as it's possible to express it in JavaScript you could create a wallet that will only sign if the user calling the lit action is a member of a dow you could use another signature algorithm for verification that's unsupported by ethereum like ed25519 or BLS you could even create a wallet that will only sign transactions on Tuesdays you can use a pkp for automation because the lit nodes do the actual signing you could create a lit action that checks the price of a token you're staking and if it drops below a certain price unstake the token and sell it this works across chains and could run while you're asleep you can make any sort of complicated automated trading bot without needing to have a hot wallet sitting on a server somewhere that will get hacked when you forget to update your Linux distribution and uh here's some ideas of a lot of different things that you can build I won't read them all but yeah you can check them out we could talk about uh some of these ideas I think is is worth pointing to but maybe just uh um a few more metaphors like one of the ways that I really like thinking about uh this programmable key pair notion what we've been calling a pkp in a way like the centralized equivalent is thinking about this like an Amazon Lambda function plus the Amazon KMS but in this case the KMS isn't something that's centralized it's uh distributed across this threshold cryptography based Network and these lit actions are the equivalent of the land Lambda functions and so it's this distributed system for doing the same type of operations that you would build with Lambda function and Amazon's KMS but in this case you as the application developer when you come and bring customers on board you have this kind of distributed back end where you can't get access to the keys where if you like build the defy automation bot and start selling to somebody as a subscription today you you could jump into Amazon's KMS and grab the keys and the funds out at any point a couple other interesting things that I think are really fun to think about when we start to think about the notion of kind of this Cloud key there's a lot of implications for this as a Dows key so we could talk about Dows and D Phi and and use our own social media but in the context of a Dao the current state of the art for Dows is of course to use Smart contract wallets to manage their treasury but more and more especially protocol dials we're seeing things that want to extend across chain and cross ecosystem and so to start to think about the account abstraction not at the level of the blockchain but at the level of the signing algorithm and creating the rules and the governance around this at the level of the signing algorithm starts to get really interesting because you can have the same rules around governance issuing verifiable credentials for your Dow making transactions on eth doing right to rights to ceramic all from the same underlying curve um and then yeah I think another one that's kind of really interesting here is thinking about this in the context of mainstream adoption we touched on this a little but you know there's always capacities to add different levels of authorization and security to wallets but we've been really really excited about groups that have started to integrate this with the likes of Discord and apple Pass Key and there's definitely a lot of opportunity to build really sophisticating Tooling in this ecosystem it's one of the reasons that we're really excited to give this talk like we have a core team that's super focused on this threshold cryptography component but there's all kinds of opportunities to like stick an email server inside of an enclave and use that as a methodology for authorizing this with email that's something that we're not going to build internally and so if that's if this kind of tooling and privacy tooling and mainstream adoption tooling is something that you're interested in definitely come talk to us um but yeah maybe we'll keep this slide up and uh we'll take questions for the next 10 minutes if there are any thanks so much [Applause] questions from the audience in the back I'll see you in the back where is our microphone we have a roaming microphone which is moving yeah um I have a few questions the first one is how do you establish the oh well it reverbs a lot how do we establish the trust relationship between the clients and the the notes because like anyone kind of like snooping on that can essentially you know rebuild the uh rebuild the signing or decoration key yeah I mean uh right now you pass a cryptographic signature with your request to the lit nodes so that could be a signed wallet message um like if you want to prove something about your wallet it could be any other cryptographic signature so it could be you know you need some encryption right because like you you need to keep this you don't need encryption just a signature and the nodes verify the signature and and by verifying the signature they can prove that you own that wallet yes but they're gonna send you in exchange like a key share right oh yeah yeah they they don't actually send a key share they send a decryption share or a signature share so the the key shares themselves never uh never leave the node got it okay I think that like I misunderstood this part and so the the second question that I have is essentially like can you do it for any form of uh resizing of you know this I wouldn't call it like a quorum but like you know just this uh this set oh like uh changing the set of nodes and changing the threshold for example exactly yeah absolutely yeah so we use a technology called proactive secret sharing um and what that uh lets us do is it lets the uh the nodes like new nodes join and leave the network um and keep the underlying secret the same but the private key Shares are incompatible uh between like epochs when it when nodes leave and when nodes join basically the this process of proactive secretaring is quite similar to the distributed key generation process um and you know the the secret uh is very very simply put right a line on a graph and in this key refresh process you're signing new points along the same underlying secret such that the shares in Epoch 2 are incompatible with Epoch one but they still represent the same underlying secret and that's functionally the goal of this network is to persist a shared Crypt photographic Secret in perpetuity okay I think that that ties into my third question which is how do you ensure kind of like the you know any form of like non-so like counters so that you know essentially like the number of time that this thing has been signed or like decrypted uh maybe you want to like ensure it that like you know you can decrypt it x amount of times you don't want to you know you you may want to like sequence essentially especially for vaults like operations right like the signing of like specific nonses uh or like just ensuring that like um you you don't have is essentially just like resigning operations with different announces either I'm actually curious how do you think about that yeah um so what you could do so the the lit nodes themselves are mostly stateless okay so they don't necessarily have a place to store anything like that um but what you can do in the lit actions is you can read and write from blockchains or from ipfs or wherever so um you could like at the end of a lit action after you create the signature share you could uh write to a chain to record that a transaction has already happened um and then if somebody tries to run that Lit action again it could you know check and see like you know did this transaction already happen or not and if so it wouldn't sign um and that's like how it works within the lit system uh within like you know the if you're signing an ethereum transaction for example right you would just include the nonce in the thing to be signed um when you send up like whatever you want the lit action to be signed um and so then you couldn't reuse that signature right um because it has already been brought cast with that nonce okay thank you so much yeah thank you great questions yeah great there's more questions in the front here give us a moment to come to you and you are not forgotten no maybe I missed how you explained how to create a pkp without any keys but how does that work and how does the user not have a key and how do they authenticate what things they want the network to do yeah I mean they need some kind of key um right it could be an ethereum wallet or it could be like apple passkey which is like one click and they generate a public private key pair for you that's backed up to your iCloud in an encrypted way um it could also be like potentially a web 2 auth method like Discord login um anything like that it just needs to be basically um an authentication method that can be verified by the lit nodes um yeah cool I have an additional question every time someone creates a pkp do you generate a new threshold key and where is that key stored are you spinning up new Cloud nodes to store those keys so the lit nodes uh eek node support like stores multiple key shares um so there's a million keys on the network and 100 nodes uh each of the nodes would store a million key shares representing one share from each of the underlying Cloud wallets or Cloud keys cool and what kinds of thresholds are you guys using in production in test like like the number threshold like yeah we're using two-thirds right now um that and that's like hard-coded across the network so it's not user changeable um and uh yeah and we're using uh you know ecdsa non-interactive signing on the um the signing side and then on the encryption and decryption side we're using uh BLS keys super we have some more questions in the middle area still do you mind if I have one more question uh that's our fourth one right super uh what are your plans for decentralization and how do you plan to grow this network it sounds like it's a pretty fixed set and you do no rotations well so there's this notion of the proactive secret fairing um which is not I guess not quite a rotation because it's the same underlying secret um but yeah some of our Cutting Edge work is right at the notion of changing the threshold oh it's just people makes the network be able to become like more Dynamic over time uh but currently there is the capacity for new nodes to join the network and for the key to be refreshed creating those new shares in Epoch two three four and so on and then practically in terms of the plan um by the end of the year this network will be up with a handful of named node operators and then those node operators are functionally a Dao of sorts that decide who comes in and who comes out uh to the system okay there was a final question in the middle area someone already raised their hand yes let me see let me see we're looking up someone had their hand up in the middle for the final question time's up time's up okay in that case Chris David thank you so much thanks everybody Applause [Applause] okay and now we're going to talk about python we will have Mark Garrow who will join us and we're going to talk about a little-known thing called web3.pi and he is standing ready let's welcome him to the stage with an Applause [Applause] well I already went forward figured it out happy day two feels like week two am I right everybody need a big breath you do um I think it's important to start with the why question so besides selling jpeg monkeys what are we all doing here I think we've reached a critical mass or we've gathered a critical mass of people here that I actually believe we stand a chance at re-architecting rethinking and even adopting some core level um systems that we we rely on things that touch on uh our our governance systems our financial systems and some of our social coordination systems so how we how we work together um I think our window of opportunity is unknown so ultimately we should seize on that while we've got it the success of ethereum and decentralized Technologies is um or perhaps should be measured in terms of adoption and by adoption I think that at least a couple of the things that um move the needle most our number one that we're solving real problems and number two that we are providing powerful and accessible tools for people to solve real problems and my thesis here is uh that the latter comes first and in that it is unlikely that one dap will solve all the world's problems or one sphere of the world's problems right so by by putting powerful and accessible Tools in people's hands enables them to solve their problems locally and so that's where I think I can move the needle anyway so this is the sort of the framing for this talk my goal is to uh increase awareness of a set of python tools some best practices and some other projects that I think you might benefit from being aware of sort of the template for this talk is that I'll give you just enough information to know whether you want to learn more about it and point to somewhere where you can learn some more so this is a blog post I wrote about a year ago now that I think is still relevant that digs a bit further into this call to action so this is meant to be beginner friendly sort of a series of lightning talks smushed together sound good he does my perspective is informed by five years at the ethereum foundation thinking a lot about what it takes to get people to adopt this technology starting on the missed browser team where we produced one of the first uis for ethereum when we Sunset that the team moved over to do some UI experiments on configuring and running um ethereum clients call that ethereum grid and a couple years ago I pivoted to the snake Charmers team the ethereum python team where I write some code but also prioritize creating education content in the last year and a half my life has done some zigging and zagging my wife and I welcomed triplets into our family and then while I was on paternity leave I helped establish developer Dao which is a very reasonable thing to do I'm excited about developer Dow because it's it's sort of this hive mind of of bright and passionate people all sort of focused and digging into this this solving challenges of adoption I'm proud to be part of this ethereum ethereum Foundation python team we are a small team and will be most of us will be hanging out at an impact Booth hub for a lot of the day tomorrow so if you want to come say hey meet some of the team and get some very exclusive snakey mcnake face swag come find us there come hang out uh we just welcomed our fifth teammate uh this month Linda so hi Linda welcome to the Ruckus um I'm going to take a moment to burn a couple seconds of time here that I don't really have to say that this is like a full circle moment for me um when I joined the EF in 2017 my first Devcon was uh in Cancun Defcon 3 and EV Fraga is in the audience who was on stage giving a shout out or like given the talk for the Miss browser team and he gave me a a welcome shout out so I'm it brings me joy to make this a a newfound tradition um quickly the EF python team manages or maintains about a dozen python libraries most notably web3pi and Pi VM the rest sort of roll up into those two libraries or help make those two libraries work a shout out to our open source community of contributors they also help things move along here and shout out to our the snake Charmers who've come before us that kicked off essentially all of these libraries so let's get to web3pi then starting with the Y question again why does web3pi need to exist and the same question is applicable to ethersjs web3.js and language you know libraries in other languages the short answer is because Json RPC exists or more specifically that the execution clients in ethereum speak Json RPC um to if you want to communicate with them you have to speak their Json RPC standard effectively so in a command line if you want to make a an eth call request to an ethereum node might look like this where you've got a stringified Json object that you're passing along the ethereum client comes back to you with this bit of this this blob of data which is then up to you to decode and make sense of web3pi and similar libraries give you like a human readable interface for this so you make the request for whatever it is you're looking for and ideally you get back exactly the data you're looking for um for the Deep dive into what happens under the hood there I've got another blog post for you check that out so what might you know web3pi for already um in order to communicate with an ethereum client you'll have to configure a provider this is um this is your friendly reminder that the most secure way to do this is to run your own node on your own machine and uh connect to it via an IPC socket we all know well that this is an unreasonable ask for most of the ethereum community so I'd like to plug here another project to keep an eye out on the portal network is there was a great talk given Yesterday by pipermerium about the portal Network what it is how it works what the progress is the idea here is that there is a fundamental redesign of the peer-to-peer protocols to actually allow light clients that are light enough to run in your consumer grade Hardware so your laptops your Raspberry Pi's even um that's in Flight there are three clients that are being implemented and the spec is effectively done already so hopefully coming soon in the meantime use your HTTP or websockets providers as needed and once connected to your node you can do various things like look up account balances convert between way and ether send ether from one account to another deploy contracts um interact with deployed contracts get block data or transaction data and then watch for events as they occur on chain that was intentionally quick if any of these concepts are new to you or you're new to ethereum in general then welcome to this weird and wonderful world and our docs are fairly good but I've also written a couple of introductory blog posts that will hopefully make these Concepts a bit easier so what's new uh a lot of work has gone into making async functionality just plain work in uh web3 Pi this year we've started with the HTTP provider because that's where the biggest bang for the buck is this is available today in beta versions of web3pi instantiating uh or like configuring these new providers is a little bit more verbose and that will improve over time but you're welcome to use it already uh so very quickly like an example of what some python or asynchronous python code might look like in this example we're just grabbing the first 50 blocks from the ethereum blockchain using async IOS as completed method so as each one of those requests goes to your remote node and comes back we just print out the block number that was received so you'll you'll get it in in this case a fairly random order the takeaway here is that if you spend a lot of your application doing read operations um you in particular to and from a remote node you can see some massive performance improvements like in the neighborhood of 10x moving right along ens support is not new to web3pi but it's gotten some love in the last year so you might know it best for looking up the like it's read operations so looking up the in address and address for a name resolving a name from an address or getting some arbitrary text that ens allows you to store as part of your record uh new this year is async support for ens so if for whatever reason you want to fetch the address of Shaq vitalik and Paris Hilton in 30 times in Rapid succession you can see some massive gains in performance here same async IO as completed code sample there that's the takeaway your gains are might be even more significant than the standard web3 methods let's get a little weirder web3 Pi introduced support for ccaf ccip read functionality so this EIP was introduced by Nick Johnson of ens ccip stands for cross-chain improvement proposal and read alludes to your reading some data on off chain or otherwise not on ethereum mainnet so this EIP introduced a standard for contracts to let the user know it's uh going to fetch some data from somewhere else other than mainnet ethereum the simple version of how this works or what this introduces is just a pattern for using a custom solidity error to return some metadata in of of note you can include one or more URLs where that off-chain data can be fetched from and then a callback function for [Music] um where that off-chain data should be returned to to be verified as authentic essentially this diagram is included in the EIP and we're going to use it as a quick example of what this looks like in practice so the use case we'll chat through is ens placing some or there let's say ens is some sub domain is registered on on a layer two like optimism um in our case the client is is your web 3 script or app we will be making some funk in this case is looking to resolve the domain or the subdomain of an address the contract is an ens resolver contract that says this value does not live on mainnet ethereum but you can find it on off chain somewhere at this optimism Gateway for example and that information is packaged up in this off-chain lookup revert message so under the hood without the user having to know this is even happening web3pi will go and make a get or post request to that optimism Gateway get that address back and then pass the relevant data to the specified callback function the Callback function within the same ens resolver contract then reads the signature verifies that this address came from a source that it trusts and sends back along the answer to web3pi so from a user standpoint this looks dead simple right you are just looking up the address for a name and you get a value back and this address might actually live on optimism on another L2 on somewhere else entirely so just for context here ens had to implement a protocol change of their own to support this functionality called wild card resolution if you're interested here they've they've got a full open source example of their resolver contract that supports this functionality um also of note Nick is giving a talk directly after this one and I believe he's digging in a bit further into ccip read functionality um cool little update from last week the lens protocol folks announced that they're going to be using the same feature set to supply um social graph data from from their protocol via their own ens resolvers I guess they're running if for whatever reason this functionality introduces some security concern that is not compatible with your use case you can fundamentally disable that at the provider level level or at the Contra or the the call level and then again for more information go hang out with Nick or check out his blog post if you are looking to do something outside of the normal scope of what web3pi does you have a few options the first is middleware and this is the most common um tool you will reach for effectively what it does is it lets you inject some Behavior either just before a call goes out or just when it returns so you might be using this for some special logging Behavior some data visualization some additional like munging of of data points or whatever your use case might be it's pretty flexible and then you inject that into what we call our middleware onion uh your next option is a custom method so if you're using a a client like Aragon or uh auto scan one of these I have some non-standard RPC functions you can choose just to lump those directly into the the eth module or whatever feels appropriate for you and you can use some of our data formatters and call that just like you would any other method um also of note here is that you can use this to override any existing method in the in the module so if you want to change the way that um any call or getting of Gas Works et cetera Etc you can essentially replace it with your own version your third option is external modules this is intended to be plug-in support so if you want to include an entire API within web3pi a whole set of functions uh you can do that via external modules this is very flexible as well you can our only stipulation is that you create these as classes and if you need to make use of the parent web3 module then you are or you have access to that via the the in-net method you can Nest these how you choose I think that's all there is to that one and fourth custom providers you're unlikely to reach for this unless you're creating something like a custom test tarnis or you just need to fundamentally alter the way that every request is made um I'll leave that one there finally uh I don't recommend it but if you've got a monkey patch things do what you got to do for more context done one you might reach for each of these got another blog post just for you are we good we taking breasts out there all right let's talk about the merge as a app developer what do you need to care about the good news is that not much else like not not that much has changed here so a couple things uh we said goodbye to some test Nets Gourley is still a good choice sapoli is uh still good as far as I know as well too um block times changed there's maybe a subset of applications this might be relevant for pre-merge a new block was added to the chain every on average 13 seconds with high variability uh in our new world we have a new block every 12 seconds even with much less variability and I think it might be useful to understand where that variability comes from by differentiating slots and blocks if you're not familiar so every 12 seconds a new slot is made available and a randomly chosen validator can then propose a block to fill that slot and if a validator is offline for whatever reason then we might miss that slot and you're waiting for the next 12 seconds for the next slot to fill so that's where your variability comes from this happens very infrequently but it does happen um next we've got block identifiers or sometimes called sometimes called block tags so you might be familiar with latest or pending or adding a specific block number if you want to specify when a particular eth call is made we've got a couple new ones now safe and finalized and the short version of this is that safe is uh going to give you a result that is based on a period where it is very unlikely for a block reorg to occur and finalized is one in which it is extremely unlikely for a block reorg to occur So based on your use case explore those block tags and finally we've got the beacon API which has existed for a little while within web3pi but maybe it's more interesting to you now we've got there's nothing fancy here it's a very uh simple wrapper around the beacon node restful httpi endpoint HTTP endpoint I don't know where the eye came from um that's about all there is to that ah a couple debugging tips these both revolve around East call I've prepared this little example scenario but in the interest of time I'm going to skip straight to the good stuff um what does these call you might be familiar with it um you're probably more likely to use it as attached to like the contract um object so for example you if you're going to execute a function on a contract you effectively have two options to do so one is to call call on that method or transact transact will submit that application to the transaction pool to be to get picked up but if you call call that simulates the effect locally so um that didn't feel like the perfect explanation but let's see if we can get there uh ethical simulates a transaction in your local environment so we're going to use it in isolation here to like highlight a couple of debugging tips that might help you out the second parameter it takes the first is the transaction the second is that block identifier and the default is latest so you would play out a transaction in whatever the current state of the blockchain is but let's say for example you wanted to find out why a transaction failed at some point in the history of of the chain so the revert reason is not something that's stored on chain but you can get it by essentially replaying a transaction at the time it originally occurred so in this example we've got a transaction we're interested in we build up a transaction a new transaction object to replay and then we call it at that block number -1 to replicate the state that it was in at the time it occurred and then you get that human readable revert message that you can then do whatever it is you need to do with for some more detail here another blog post but that's not all there is a third optional argument on each call at least uh within Geth and Aragon and possibly some others called state overrides this can save you some serious development Cycles if you need to get a contract in a specific state to uh perform whatever testing it is you need for example you need specific State values in that contract or you need the you want to even alter the byte code a little bit to or like the um the operations within some of the contract itself or like undo a condition for which the contract would normally revert just to see what would happen otherwise you can override that in real time within the eth call method so in this quick example I am telling I'm using the code from or the example oh please the beard is knocking off the table so in this example we are um we're telling each call that the contract that lives at this particular address I would like you to replace its runtime byte code with this altered version that I've made this version that I'm interested in testing and then we can run that and in this example we've got a successfully executing call in the last example that would have reverted for more detail here check out the blog finally last chapter we the python team know that as time goes on more and more of our users are going to be using our tools through one or more layers of abstraction and that's a good thing specifically in mind are development Frameworks that sort of package together a bunch of functionality that let users be super productive in a much shorter time so I'd like to encourage you if you haven't yet to check out our friends over at ape they are they can be thought of as like the python version of hard hat and um they are I think more and more in the future they will be our biggest or they will be the biggest consumers of web3pi as a vehicle for their users um so again this this gets us this enables our users to be more powerful to do more and to solve their local problems so that's a good thing so that's um that's what I've got for you we covered everything today uh show of hands make it a little interactive did we touch on anything you weren't already aware of is there anything that you're ready to dig into a little deeper that's like for the camera out there that's like 4 000 people that all raise their hands that's cool um cool then mission accomplished again the snakechummers.ethereum.org blog is where a lot of this lives if you'd like to catch up review on uh any of what we've chatted about today and yeah we have room for some questions from the audience one question per person in the back yes foreign just a quick comment in regards to the merge um I believe it's important to recognize that in terms of slots and block times there can be mixed missed slots where the slot occurs but there is no block so the block time doesn't necessarily increase every 12 seconds uh just a comment uh yeah thanks for clarifying though I'm not certain I I got the clarification um so I block I think we're on the same page a block can fill a slot every 12 seconds but it doesn't always correct I've been very we had time for one question that was it I'd like to thank Mark everyone we'll have to I'd like to welcome my next speaker thank you and for that we'd like to call upon Kasper Schwarz Schilling who's getting ready to talk about time in ethereum the implications of replacing our dear friend poisson is he ready he is ready give a warm welcome thank you um yeah that's kind of funny yeah kind of funny that block times were just discussed previous to this talk um I'm Casper I'm with the ethereum foundation working as a researcher at the robust and centers group we kind of work on anything incentives which is in ethereum's case a good excuse to kind of look at anything you're really interested in and centers are all over the place I'll be talking about time in ethereum and um in particular um I mean this talk title talk talk title is a bit mysterious so let me maybe a bit clarify what I intend to talk about um as you probably all know in proof of work ethereum block um production was a random process called AKA poisson process hence the subtitle implications of replacing our dear friend prosor and which basically means nothing else that other than that at a constant average rate a miner would find a new block sometimes it takes three seconds sometimes 13 or 23 but on average roughly 13 and um and today in proof of stake ethereum as we had already um blocks show up every 12 seconds like clockwork so there's no Randomness in this round time but blocktimeness doesn't necessarily uh uh that does necessarily is it's not necessarily 12 seconds but so basically um this difference in Randomness versus deterministic time um may not immediately appear as a big deal but it comes with some implications um that I want to explore there's some good and some bad implications um at first hand it might seem that it should only or predominantly be good in terms of load balancing the gas fee Market should be a bit more relaxed Etc but basically improve a stake um having these slots and a single proposal for each slot we kind of give this proposer some kind of Monopoly guaranteed Monopoly and this Monopoly power can kind of be at least screwed to some extent to the advantage of The Proposal if that doesn't make sense right now hopefully it will at the end of this talk so what the hell is time time is funny business very confusing at least for me but when I talk about time in this talk I don't intend to be clever or philosophical about it I really just mean how do we make progress in in our chain in proof of work this progress was random in time sometimes blocks come up very quickly after 3 seconds or 20 seconds but on average 13 seconds in proof of stake it's constant every 12 seconds um assuming that a block proposal shows up and basically when I talk about deterministic versus random time I talk about how we make progress in our chain that's kind of it um now how do we make progress in in ethereum today it really is quite simple we have this available chain which we then try to finalize but for this talk we can safely ignore the finality Gadget that lives on top of this available chain and just look at how the available chain grows and again we have this time unit called slots which is 12 seconds long and so every 12 seconds we slot and so um when the block proposition is up like here in slot n we um we just chug along people will vote for it next lot comes along we build on top of it and then here we have the scenario that was discussed um if the blog proposal doesn't show up that's okay the next block will just build on the previous block simple enough um but I want to kind of briefly touch upon where does this deterministic nature of time actually come from um and so basically in any proof of stake system we need a mechanism to select a proposal for a block from a set of bonded validators and in proof of work this is clearly happening randomly just by nature of it being a race every Miner tries to create a block but on average only one minus succeeded every 13 seconds roughly improved working theorem and importantly you don't actually know who will win the next round improve of stake this random selection needs to be explicit now clearly there is no true Randomness in a blockchain since all nodes must come to consensus on it and so different nodes calling random a Randomness function will just create chaos by basically outputting different results in each case so instead what we do is we generate pseudo-randomness on chain from a seed that is computed and updated as part of the blockchain and the challenge is basically to make this seat unpredictable now for the purpose of this talk we can safely treat it as a box and just pretend it works it actually does and so essentially what we do is we generate pseudorandomness on chain to sign and schedule duties and this sequence of Duties is scheduled deterministically so we as as validators we need to agree on a view of when Duties are scheduled and also of their time and so in ethereum we chose this arbitrary parameter of 12 seconds as our block time it's not completely arbitrary because obviously things like latency Etc and block processing are considered but it could have been 11 or 13 um and it would probably work just fine um now to kind of boil this down a bit more heavily in proof of work we are fed this exogenous Randomness into our system um which gives us this random block time and in proof of stake we have to generate um this Unchained pseudor Randomness giving us this notion of uh deterministic time in ethereum and to make it even more blunt basically you can think of proof of work as a continuous race you never know who will win and when could be anyone at any time whereas in proof of stake we have the scheduled sequence of Duties and this different this difference here already implies what the core of the problem is that I will talk about in proof of work there's no notion of late whereas in proof of stake there is you can basically show up late for your duties such as block proposing and you can basically show up late but early enough to still become canonical and that's basically the wiggle room that the proposer has and can abuse um so uh yeah basically um this nice graph by Martin here not sure if he's here but I saw him earlier um essentially it's it's about block time around the merge um you can easily see here um yeah improve of work obviously you have this very large variance in Block time and as soon as we hit merge we have this very boring beautiful 12 second slot time block showing up beautifully until there's one missed slot um so block time jumps up to 24 seconds once but that's kind of it now that's let's think about the implications of this deterministic time and this plot really kind of um illustrates it quite well and um I want to kind of continue on it um so vitalik here notes basically um I'm actually in the way am I not um basically it's immediately obvious that this block time is less volatile and there's less decreased volatility means that the Galaxy Market is more stable and as vitalik points out basically eip1559 works better since we hit the 2x gas limit of 30 million gas less often and basically removing this huge variants of block time leads to a more stable gas free market with fewer people overpairing compared to yeah when basically basically hikes hits the limit every time there's a block that shows up after a long time improve of Works case so basically there's another tweet here by Barnaby who's sitting right there um uh basically just visualized again it's not as immediately obvious but you can basically see um the the gas limit is not hit as often in the second half of the plot um and essentially we can just summarize this as better load balancing and I've now talked about transaction load balancing essentially but this really kind of translates throughout the stack on the P2P layer in terms of messaging load Etc so there are huge benefits to this constant progress um that we make in proof of stake ethereum but obviously that's not the end of it otherwise I wouldn't be talking about it probably um essentially proposers can abuse their guaranteed Monopoly power and what I really mean is that what do I mean by guaranteed Monopoly I mean that in proof of stake there's only a single unique validator that has the right to propose a valid Block in a in a given slot and improve of work that obviously is not the case and this guarant basically now that we have this unique proposal that is allowed to propose a block um for the duration of a slot there's this leeway of timing your block that is possible but before going there I need to briefly introduce some ethereum Basics um basically a slot there's something several things happening on the one hand we have a block proposal on another hand we have a committee of a testers voting for what they consider as head of the chain and then we have the aggregation phase which we can kind of ignore but it's just a way of efficiently packaging other stations so that we can actually fit them on chain so the honest validator spec guide basically specifies that a validator is expected to propose a signed beacon block at the beginning of any slot during which is proposal returns true so basically if you're the valid the elected proposal proposal block at the beginning of the slot um so zero seconds into the slot ideally now then the next phase is basically testing um and we have this test attestation deadline four seconds into the slot which basically the rule or the spec says um a test as soon as you hear a valid block or four seconds into the slot whatever comes first so if the slot if the Block's on time you hit after one second you immediately attest to it if you don't hear anything until four seconds you attest probably to the previous block that you heard um and in order to know what to test for these testers run our beloved Fork choice I see photos here um and basically this virtuous rule is um a function that takes us input the block tree and some previous attestations and gives you the head of the chain as output that you will then vote for or build on top of if you're a block proposal so um the foxes is a flavor of lmd ghost which stands for latest message driven greediest heaviest observable subtree which is a mouthful but it really intuitively is quite simple if you look at the Block tree here um essentially as long as there's no Fork you just yeah you just extend the the chain and here you see the scenario once we get to n plus one extending block N Easy but then comes n plus two and for whatever reason the proposal is on top of n creating a split in the block tree now that might happen if the proposal was offline for whatever reason um but now basically the committee in N plus 2 has to make a decision will I vote for Block n plus two or will I vote for Block n plus one and the lmd ghost rule basically tells you to walk down the block tree and go down the heavier subtree which means basically going down the path where more votes have been accumulated and here you can see that block n plus one actually accumulated a hundred percent of the votes in that slot and so it's heavier than block n plus two and so as the committee name plus two you will vote for n plus one so um and then n plus three sees these words and uh makes a similar decision and so basically n plus two gets kicked out of the chain um now um now we have the basics and so let's talk basically about what the proposal can do um I've mentioned it it's basically about timing their block releases um and there's basically different Notions of on time like ideally you release your block in zero seconds into the slot then some validate like notes were on the P2P layer receive them at different times probably one seconds in two seconds probably everyone has heard it um but so as long as you hear the block zero or four seconds into the slot um a vlog is basically considered on time in terms of a testing because you've you hear about the block before a validator test so in this case nothing really happens business as usual but the more interesting case is what happens if the block proposal is really late say 11 seconds into the slot um essentially as you can see here as you can see on this diagram you have this attestation deadline four seconds into the slot and because they haven't seen a block yet they will just vote for Block n now at some point block n plus 1 comes along and once we get to the next slot block n plus 2 has to make a decision on what block to extend on what basically to build on block n or n plus one you might think that n plus one shouldn't become part of the chain because no one actually voted for it but in terms of fork Choice um The Weight by is the weight of block n is actually inherited by block n plus one and so n plus 2 will extend that chain um for a good reason actually um so we have maybe to go back how does this here we go um so what basically happened here um we have a very late block proposal 11 seconds late um why is this bad this is bad because it simply unfair to the next block proposal why because basically listening time to the transaction mempool is valuable transactions have transaction fees priority fees but obviously Mev dramatically increases this uh notion of unfairness in this sense that more listening time to the mempool basically gives you more transactions to extract Mev from which basically means that if as a block proposal I only have two seconds worth of listening time that my previous proposal hasn't um that my previous proposal didn't have available to include in their blog I'm worse off um and so basically anyone following the honest spec guide will actually um have uh less Mev to extract now that obviously can lead to centralizing effects that if you're not a sophisticated proposer you uh yeah you simply earn less than sophisticated once so what can we do about it um essentially there's I think roughly three categories to think in um one is containing this Monopoly power right now basically you can release the block at the end of the slot what about making it so that we can kind of enforce a shorter time frame where block can still be released but become canonical I will go through some things in a second another one is explicitly incentivizing timeliness which we currently don't do in our protocol and the third one is I'm not actually going to talk too much about but is trying to think about how can we maybe introduce competition to proposals again in the sense of right now we have this guaranteed Monopoly maybe there's a way the protocol can introduce some notion of competition where the proposal can't rest assured that they have 12 seconds to release their block but that would require like fundamental changes to the protocol and I'm actually not entirely sure if it even is possible in a um in a world where we have attestations with thousands of attestations happening each slot um what can we do there's some Fork Choice fun that we can do today for reasons unrelated to this is a proposal boost um and essentially proposal boost is a is um is it called is is something that the fox it's like part of the fork choice where if you propose a block on time the block will be treated as if it had already received 40 of a commit of committee votes basically you have a head start in terms of fog Choice weight but only for the duration of the slot um now how can we basically use this um to defend against this quote unquote guaranteed Monopoly um here in this scenario we see block n plus one is the relatively late around the four second that it's released around the four second deadline such that some of the committee that votes um doesn't inherit in time before they test and so they vote for Block n 70 and 30 inherit before they test so they test for Block n plus one now block n plus two basically with proposal boost has an option they can choose to either extend the Chain by building on top of block n plus one or they can try to reorg it out by building on top of block n and because of this proposal boost we actually have the power because 30 greater than 30 we you can basically overpower the blog proposal of n plus one and reorg them out and essentially what this does is it enforces a kind of soft four second deadline in terms of um being able to release your block late while still becoming canonical because if you release up at four seconds at test this will have already voted and you won't manage to accumulate at least 40 percent of the attestations and some clients are actually starting to work on this I actually saw Michael sprawl made a commit earlier who unfortunately could make it to Defcon this year um Fox Choice fund that we can do tomorrow or in some time is basically a similar idea block slot voting um where we also basically soft enforce this four second deadline um here it it works a bit differently um essentially what we're trying to do is that if I don't see a block instead of just voting for Block n like I did previously I basically vote for Block n while also saying I want to vote and enshrine emptiness so here what you can see is um block n you basically in Block n plus one you vote for Block n with the information that this is from slot n plus one and um essentially what you're doing is you're creating a fork that competes with this late block then and you have the similar effect that now instead of the 60 voting for Block n um in like on this side here you have them vote on this kind of block which is not a new block as such in terms of transactions but it's just like saying I want to enshrine emptiness and now block n plus two The Proposal runs the four choices 60 versus 40 and so they will vote for the 60 um now um yeah there's some ones that I could add but I think in terms of time I I need to keep going um another idea that I mentioned briefly is that um why don't we try to incentivize timeliness explicitly today a Blog proposal is basically they're rewarded in proportion to the profitability of attestation they include in their blog so basically attestations that already exist floating around um this the fresher they are the better and so they are included and these incentives are good because we need to make create incentives for them for the attestations to actually land on chain so that we have this notion of finality on chain um but why don't we try to incentivize timeliness now the obvious problem is basically what does timeliness mean in terms of uh on chain um like how do we Define timeliness on chain and an idea could be to scale The Proposal reward by the share of same slot attestation attestations that the block receives and are included in the subsequent block now that sounds um more complicated than it has to be essentially the idea is we have block rewards as of as today and we scale them by the share of same slot attestations what I mean is here in slot n log proposal seems to be on time such that a hundred percent of the committee votes for that block um and so what we would do in this with this idea is we would scale them by a factor of one so nothing changes you're on time nice good um block n plus one for on the other hand seems to be slightly late only 90 percent vote for that block ten percent probably didn't have didn't hear it in time so they vote for Block n um now in with this idea what we would basically do is scale the reward as of today by a factor of 0.9 effectively decreasing um the reward ideas basically um to punish people for being too late um now some um like what I want to say is basically that it should be incentive compatible in the sense that the next proposal is also incentivized to include these attestations on chain um because they're fresh and so they're more most profitable and I don't see an immediate way to basically grief um one way or the other essentially another the the one problem that it does have is that Mev rewards may actually be able to dominate these timeliness rewards um that is probably in some cases always going to be true but regardless I think rewarding timeliness makes intuitive sense regardless of this problem as such it's just it just seems like it's a bit strange that we actually don't do it in my opinion um and a spicy hottake that I don't actually personally agree with would also be something like in a world of Mev smoothing where we have an on-chain oracle of Mev of the value of Mev in a given slot um we could think about using that Oracle to scale timeliness rewards to ensure they are dominating Mev effects but basically making sure that the time industry votes are big enough to fight off any kind of Mev Dynamics but honestly it seems like a dangerous path in terms of making consensus decision decisions on some Oracle like that um basically in short um we can summarize this as load stability being a good thing and a guaranteed Monopoly being a bad thing thankfully we have things we can do about it and things we can do today is things we can improve going forward even further and yeah I just wanted to kind of put this out there a bit more and I will certainly certainly be thinking about it more going forward as well and yeah thank you and if any of these kind of incentive games are of interest to you then yeah the robust incentives group is actually hiring right now so feel free to reach out and apply if you feel like it thank you foreign audience now is your chance yeah yeah over here please talk into the microphone for the Stream um thank you for the presentation um I'm just curious about the fork Choice rules like currently as a validator I will either sign something or I will not if it's too late right but if we're looking at the build proposal there are some other stays right where you will get like a 40 percent boost of the votes if you are enough in time how do we deal with time actually being subjective to validators as you understand there's no global view of time of such granularity between the validators and we haven't globally distributed and latency and all that like how does that not result in us getting a lot of chain splits um if I understand correctly yes there's no Global notion of time it's essentially a local property of your node and there needs to be some notion of being synchronized with your peers in that sense yes but it's a local property okay another one in front here over here yep I thank you um so I had two questions one was uh on the one of the later slides about incentivizing timeliness um kind of reducing the reward for uh proposure that proposes their block a little late why would we not give the subtracted reward to the next proposer given that they were the ones kind of I guess robbed of some Mev opportunity is that kind of a problem of just um you only have the current chain State and you kind of only go back to the one that already happened or I didn't catch the last but so you're saying why don't we give the the part that we subtract from the current proposal to the proposal of the next slot yeah to the child rather than the parent um you mean and the idea would be to to basically because the Block's laid but still becomes canonical um to kind of compensate for the lateness of the previous block yeah um might be a fun thing to actually think about I don't know yeah I mean to be honest this is more of an idea at this point um it's not a formalized proposal but it's more like putting out ideas um of how to think about timeliness um going forward but okay and then uh one more question is uh to better understand uh why more validators don't propose their block late uh like what is the additional incentive for proposers to propose their block on time like we're discussing potential ideas for it but I guess in the current state why do more validators not propose late good question okay thank you thank you customer thank you so much [Applause] the next presentation will be the final one of today so we will take all the time needed for the questions we will have Corey Petty ready to tell us about how to ethically build public good infrastructures Corey can I invite you to the stage please let's give him a warm welcome [Applause] so those of you who are leaving you at least got to see the speed run of the talk uh while he was answering questions my name is Corey Petty I'm going to talk about how to ethically build public good infrastructure um specifically focusing on the ethics it's not going to be as many details if you'd like more details on kind of uh our history and the current work we do at status and sister organizations you can I'd recommend watching Oscar Thorne's talk he did earlier today so if you missed that check it on the stream but for those of you who are leaving you see what a tldr exist web3's main primitive is to minimize their influence on everyone else that's the whole goal I think that what we're trying to do in building decentralized Technologies mitigating those with power and their influence on those without it and the ethics of building this stuff this infrastructure has a massive impact on our success in doing this so the process of um how we think about building these things and how we make decisions in the process of building these things tremendously impacts our ability to mitigate so a little bit about me my name is Corey Petty I said at the beginning um I started out doing podcasting in early 2015 and researched a couple years before that joint status four to five years ago it's a blur at this point doing security research and security stuff across the organization and since this year I've moved into doing uh kind of coordinating all of the infrastructure projects which we've recently expanded into you'll see kind of a start to that work uh in the later half of my of my talk you can reach me in all these different things corepetty.eath on status just search for petty and core Petty on Twitter so status is an organization that's founded on a series of principles we wholly bought into what we believe to be like the ideal ethereum principles for building public good infrastructure uh I'm not going to list them all you can see them and in some cases these things are a little in conflict with each other but as an organization that's founded on these things they serve really really really well as uh how we argue about trade-offs when implementing things or developing things or trying to understand how we'd like to do it and I'm going to do the normal thing where I give you the Wikipedia definition of something and that's public good infrastructure and that's a good in which all enjoy in common in the sense that each individual's consumption of such a good leads to no subtractions for many other individuals consumption of that good and this is Paul sentences so we're trying to optimize uh infrastructure where it's not a zero-sum game uh and someone can't take advantage of others or in the process of someone being successful that is a detriment the use or experience of someone else that has nothing to do with that work but as I said earlier exist there are always people who seek to profit for themselves on behalf of others because they don't care or they don't know um and our goal like I said in the beginning is to mitigate that influence as much as possible and I've come up with somewhat of a law I'm sure this is something more General informal somewhere else but every Community has there's always someone in a community that uh cares more about themselves than the others is willing to do things on the for themselves to the detriment of others and as things grow the likelihood of these things also grow and more often than not these people are usually very loud now what a community is is as generic as you could think it'd be it's either a blockchain ecosystem a government your local Meetup your friends Group whatever we all know kind of uh who this person is and I imagine there's probably a lot of in this building as well so like we all kind of get the idea here's some uh this is an example of what the influence of power dynamics can have on a system in which tries to mitigate it but doesn't quite successfully do so um and I want to make it a point that we're not seeking to remove power dynamics that's kind of a natural thing across Society where humans the world is unfair we each start off with a different set of uh circumstances and we change differently but uh we're really trying to flatten its effects for seeking to remove the ability some of someone with asymmetric power to impact those without it and this could be summarized by uh this kind of change of phrasing we've all heard in the beginning of Google uh their their phrase of don't be evil and we loved it that's one of the reasons why I enjoyed Google in the beginning was they had this kind of ethos and model of like seeking to not uh try and take advantage of others in the process of building out infrastructure and serving people uh and I have to give credit to Dr manibelli for introducing this exact phrasion to me back in I don't know one of the early consensuses in New York is and what we're trying to do is change don't be evil to can't be evil because we've seen what happens when the motto is don't be evil you have the option to do so it's it and you continue to have that option you get to selectively choose when it's economically feasible for you to not be evil or maybe there's a change of guard and uh everything that's set up that had that ethos changes when uh that new change of guard doesn't really quite care the way the original one did so we're seeking to do this don't changing don't be evil if it can't be evil don't give people those options and this is an example of when that fails uh uh this is a mbvwatch dot info I believe yeah I think so and this is what's currently happening as the as a result of the sanctions being put down on tornado cash now uh I'm not going to opine on the original picture of someone being held captive for in prison for a long period of time uh but what we can see is that tornado cash was sanctioned the code was removed uh and put back on subsequently but uh we're seeing ofax sanctions having a an impact on what we thought was uh Central like censorship resistant technology where this is the list of all of the blocks currently done since the merge and those of the if you look at the the gray here the gray is all the ones that are not using a service on the validators called Mev boost and those that are are the ones that are uh the portion of those blocks that are of fat compliant they're censoring transactions on the public on the public ethereum blockchain in compliance with these uh 24 cast sanctions and the ones that aren't and I think if you look at that it ends up being uh quite a bit so 32 of all transactions being put across the the blockchain network or are ofat compliant and if you look at just the ones going through is the massive majority of those are so we're seeing censorship at the base layer and this can only be done because we can see what those transactions are and you're able to make a distinction and do transaction ordering because you're able to see those details now that means you're given the ability to look back here maybe you have the ability to make a decision that you're choosing don't be evil and that can't be evil so it makes it it's showing that we need more privacy and censorship resistance well I'll get to that in a moment don't know why that moved yeah so we're seeing that we need more privacy and censorship resistance at lower and lower layers um if we can't just do everything on the blockchain layer and then ignore it on the ones below and if you looked at the talk before this you see that like that's a really hard problem to solve there's a lot of like trade-offs and difficulties you have to do to try and figure out what is good behavior and how do we make the appropriate trade-offs to then maximize that right so I'm going to take a slight turn here to talk about kind of how you can maybe think about structuring this argument and um where it actually comes into place when you're making decisions on uh like how to build infrastructure and where you need to focus your your uh your principles so this this I keep coming back to this phrase the medium is the message and it's a general idea that uh the technology you use the medium has a drastic impact on your ability to convey a given message when we try to put something out some idea in the world uh we think about it in our heads we form it in some way and we send it out into the world via some technology or formalism or whatever and it's up to the receiver to uh decode that appropriately and it's also in while in transit potentially being manipulated and and that's where a lot of that's coming in I'll make a kind of a case for that in a moment but this wonderful picture by Monica and the crowd here uh is is kind of like this example of what it looks like when you you don't take this into account and you funnel everything all human relationships into a single medium in which kind of takes out all your optionality and how you can build things so this is kind of like all of the complexity of Human Relationships and different things coming through what I would see a meat grinder everything comes out uniform in the same currently this is what I would consider centralized infrastructure in which we try and take everything that we humans do to communicate and make digital relationships and lives and what it turns out to be when we try and like mimic that stuff in a digital environment so to dive into that a little bit deeper there are three parts three layers of any message I want to try and explain what these are and then point out kind of with a subtlety and the evil comes in first we have the frame message which is the concept of uh giving information that there is a message it says hey I'm a message decode me if you can it's the ability to identify that a message even exists for you to think about uh and it's just this it's implicitly conveys in the structure of this message this is a book so you know what a book contains a message um that's a good decent example and to understand the frame message is to recognize the need for some type of decoding mechanism I've identified that there is a message and now I need to find a way to decode it to understand what that message actually is next one is the outer message which is the medium used to convey that message this is how that message was sent out in the world to understand this the outer message is to build or know how to build the correct decoding mechanism for the inner message so this is I've identified that there's a message that I'd like to see and now I need to understand that uh how can I take this message and understand what the intent of this thing is and then finally the inter message which everyone kind of understands which is the initial intent being conveyed in the first place so understand this is to have extracted that meaning that was intended by the center in the first place now this is a overly simplistic model of what a new message is but what gives you a framework to kind of give you an idea of like where things can be introduced and how to start trying to understand how you can mitigate these things so uh if we think about blockchain networks as coordination mechanisms this is we're using them as social layers to then as I said or earlier mitigate as best we can and trust a system as opposed to humans to convey those interactions and the interesting thing about them that's different from the Internet is that they have real world value which attracts a lot of people to do things that are very greedy so we have these beautiful cross-border cross jurisdictional uh attempts to be attempting to be Central uh censorship resistant coordination mechanisms that allow us all these things we couldn't do beforehand in a digital environment with digital relationships with approval value um and if we think about that earlier framework of thinking about a message it's really hard because it's layered in a bunch of different ways if we look at the kind of Stack the very very overly simplistic stack of what a blockchain network is we have networking at the bottom this is how messages get passed around so then everyone who's contributing to these things can it comes to agreement and has all the right data to figure out what's going on they then go through the process of validating all these messages that say if they're well formed or someone's doing a double spend or that gets dropped or whatever and then construct them into blocks and then we go through a consensus mechanism where we as a distributed system come to agreement like this is all the right one to then move on onto from now on right and after that we have to find some way of like extracting that data from this massive blockchain that we keep building that's a lot of messages and a lot of different mechanisms which have what would be considered an outer message that needs to be interpreted appropriately and based on anyone in this process's ability to understand that outer message and the powers they have in various places across the stack give them the ability to change that message or censor it and most of the time when we're thinking about adding security or privacy we're looking at the top two invalidation and consensus we're basically just making sure it's correct but what we're seeing now like we spent all our time on privacy in the retrieval and kind of well there's a middle layer with smart contractors so on and so forth we're seeing all of our time spinning up here when when things happen and those that the powers that be want to change stuff that go to a layer above because we didn't necessarily think about it back then right so that's kind of an overview of like kind of had to think about uh public good infrastructure its complexity and a small example of I don't want to say not thinking properly or building improperly but like as this thing is grown and ossified the interactions of not incorporating what I would consider the strongest point the strongest principles that we set out to do mitigating properly at the lower the lower layers we look to scale things too quickly and instead of providing what I think is a more fundamental requirement in order for self-sovereignty and that is privacy uh and censorship resistant we're failing to do so now in the system that's actually being adopted by many people so quick history of whisper and how we've moved from the Arlen relay and kind of statuses and now back in waku's uh uh attempts at trying to take infrastructure and grow it in the direction that it needs to grow while keeping all these principles aligned um once again there's a lot more details to all of this I'd recommend reading them the ridiculous amount of stuff we have online and watching oster's talk previously here's one tomorrow where he gives them an awesome demo of what I'll get to eventually please show up for that but this is and what the original theorem uh announced to the world this is what the decentralized stack looked like where you had smart contracts on ethereum we all kind of know what that is and then swarm and Whisper which were the other two pillars of what a decentralized application was supposed to be swarmed for file storage and Whisper for dynamic Communications or femoral Communications and with a special emphasis in obfuscating the route of uh how who sent a message and who's receiving it we holy bought into this status and we wanted to build an application we wanted to be this thing that consumed these things so that people had access to it in resource constrained or like areas in which only had access to small little number of resources like the mobile phone right we wanted to increase the inclusion as much as possible while maintaining this high level of decentralization and we had this concept of socioeconomic networks really really early you're seeing a lot of social token stuff happen and kind of the idea of that ethereum is a coordination layer we're moving past this financial applications only situation and so we incorporated whisper we used what was put out by ethereum ecosystem um and we did it naively I'd say we used proof of work because that's part of it in terms of the the anti-spam mechanism for messages being passed on the network and we killed batteries and had super hot funds use glossop gossip and Bloom filters for sending it for synonymity and we destroyed data plans for people right we tried to use this technology as best we could and read it it was a new technology and we tried to apply it in a very extreme place and then the first discovery finding peers and we had a based on the high churn of people's mobile devices popping in and out of places or turning them off and so on and so forth it's really hard to get good message reliability and so what do we do we took ownership of it because was for wasn't whisper wasn't being developed in applying resources they reasonably speaking had a tremendous amount of work to be applied to just fixing and making a blockchain scale itself and solving those problems with what resources were available at that time so Oscar wrote A Blog here along then we we decided as an organization to take ownership of this and introduce waku which was the fork of whisper and we tried to make it a little more scalable a little more usable so that status applications uh the users of the status application could have somewhat of a reasonable uh user experience so we tend to the patch whisper for our environment took responsibility and applied attention to our required infrastructure and we did this in an open way we created vac which is a separate organization to focus and research and study on trying to grow these things and the manner that's appropriate with the principles I talked about in the beginning and for all of these things you can see out in the open we try to make open specifications that anyone can use whisper or waku is for everyone we're taking opinionated versions of it and applying it in contexts we think is appropriate but it's for everyone a public good is not to be owned by a given organization and used at our discretion so we publish all these things at rfc.vac.dev join opine contribute um but we had issues we had spam for those of you who've used status in the past couple years and you go to maybe this status Channel you're going to see a lot of this why because we had no incentives we took away our ability to um mitigate some of that with proof of work because there are a lot of other issues with using proof of work for spam mitigation uh but we had a problem but what what could we what what could we have done to fix this we could have offered up a lot of centralized solutions by looking at IPS and banning them or running things through our servers and censoring or things appropriately but we tried to stick to our principles of what a real decentralized stack should look like and it was painful but we're in a scaling problem too we had multiple problems simultaneously so what did we do we chose to a plan for waku waku 2 because the way whisper was built was fragile and couldn't scale and we realized that when we tried to fix it so we wrote it completely from scratch off of the P2P and called it waku V2 that's why we call it the spiritual successor of whisper so what do we do we did a complete retooling of a private decentralized generally messaging stack on top of lip P2P uh it's modular so that users trying to use this stuff for a specific context can make the decisions it's appropriate for what they're doing uh whenever you try and make a completely generalized solid framework that isn't flexible you're going to optimize for No One so if you will provide a suite of protocols that work well together and a way for them to interact together then you can hopefully build multiple solutions that optimize for multiple applications and it's open once again it's built for generalized messaging it's not just for status that's one of the applications we use it for being used for things based on what choices you make in the suite of protocols still spam right still got problems to spend we just dealt with scaling and getting people to use it and understanding that like there's a lot of different ways you can do generalized chat and we're not going to tell you how to do it so in order for keeping with our principals we decided to build the What's called the rln relay and that is a privacy preserving spam protection that leverages zero knowledge proofs and smear secret sharing and some economic disincentives uh this is built on welcome V2 relay and this is an uh I'm not going to go through the overview I don't have much time um but uh it's a really interesting way of using novel cryptography and uh very well-known cryptography in a unique combination of uh allowing people to contribute to a network and be removed if they do bad behavior without having to really reveal a lot of pii information about themselves and so on and so forth so we stuck to our principles it was painful along the way but we got to a unique solution that I don't think ever would have gotten to or maybe much later had we just you know compromise those things and moved on to some other way all the specifications once again are at rfc.vac.dev you can see the papers of these things I'm sure there's links on on vac.dev but you can find them here if yeah it's easier if you just go to the website and click on it as opposed to trying writing it down now go play with it tell us about it we have a lot of different other research along the way once again go see Oscar you can see a live demo of this type of thing live a video of a demo of this type of thing tomorrow uh it's once again wrapping up so a principles are priority right in order to do what I would consider public good infrastructure you need to publish openly you can't do things in the dark uh especially when it's a digital permissionless system you can't have trust in things if you don't know how it works and these things should be Community Based so publish openly Implement iterate the concept of using old two tools will lead to Old Solutions if we would have compromised on our principles and done things to make status scale and kind of soar quickly we would have just ended up with the same stuff the same we have today and that's not why we hear in the first place  are everywhere and think about that think about how they can manipulate the intended messages that you're trying to send out in the world where can they understand the outer message of what you're trying to do manipulate it and change that message such that the receiver either can't get it or get something wrong and uh in general I think it's important to finish on we should be conforming technology to relationships for trying to have with the people who are trying to have them and not the other way around um and we're building a lot of this we've since expanded the organization substantially to start growing infrastructure uh and we want to do that with as much of the principles and Ethos that we started talking about in the beginning and that's collectively built to student access specifically Network level privacy you can't have censorship resistance if people can see what you're doing so as much privacy as possible with Selective disclosure in the right places heterogeneous multi-chain Network you need the right to exit it should be beholden to a single place in which you shove things and then rely on them to work appropriately uh Native private public smart contracts once you get in privacy at all levels of the stack and as much as we possibly can optimizing for resource restricted devices because you can't be inclusive if people can't get access to the devices that are required to use your software or Hardware or whatever this is what we're doing there's a lot of work to be done and we're hiring this is a QR code to go to a lot of the jobs that we've posted currently keep track of it there's going to be a lot more thank you thank you and since we're the last ones we have a lot of questions plenty of time for questions I'm happy to take them yeah take as much time as you want Corey yeah we're looking uh are there any I'm looking there's a question over there hey uh great talk um allow me to stand uh so I was curious you know you talk about your principles um and it seems like first and foremost privacy is at the top of that stack uh I think there was like an implication about the morality of the ofac sanctions like in the validators um which seems to imply that privacy is Paramount above the other principles that you try to present as like uh what is ethical for status uh that's not a judgment that's just I'm just trying to say that uh the question is how do you prioritize the principles against each other I mean you talk about inclusivity uh like with the resource uh limited devices and then how do you you know ask your community to input their opinions about like the priorities of those principles so in designing you know the future of status like what sort of processes do you use to get feedback uh on those principles good question actually um it's really really really hard uh first off I think it's that an Oscar stock you mentioned something that I've I like repeating and I like saying a lot because it really tells uh kind of powder like a general idea of how to how to frame these things and like because in the day there's a lot of principles to uphold right a lot of ideas we want to try and do simultaneously in some situations in a lot of situations come in conflict with each other uh but you can't build a decentralized framework on top of a centralized Foundation but you can do the opposite really easily coinbase is a wonderful example of that um and so when you're thinking about having one of these arguments and trying to come to a priority which is going to be context specific you need to try and um see what's most important and what removes your ability to uh have that decentralized Foundation that can be compromised with at a later at a higher at a higher leader at a later place because we don't want to make decisions for other people so how can we make the most generalized way that people can make decisions for themselves and and build appropriately for their context so that means privacy is very strong because you're not revealing information until you need to but if you're not private you're automatically giving all that information away which allows people to make decisions like which doesn't allow people you can't add so much harder to add privacy later to the same thing can't build private Solutions on top of public Solutions there are there's always going to be a way to remove that privacy to layer below and go after it right and I think like uh one of the examples I've heard uh recently is from our founder is like say you wanted to build a limited liability doubt and how can we do that today I don't think so because you can make a vote on a specific proposal and someone doesn't like it they can still see who voted on it and the whales can go after those so like there's no removal of risk in the process of contributing to something like that like that because I just go after you and you can see the lower you go the more often that happens so like it's a kind of long-winded answer to your question you have to try and have arguments that move towards a direction of uh what constraints are we applying now that are going to have implications in the layers above and is that in line with the people's ability to make decisions for themselves thank you is there a next question otherwise I have one actually um you mentioned you can build uh private Solutions on public infrastructure what's your opinion on road upston GK applied they are beholden to whatever constraints that ethereum gives them they don't have a lot of power in themselves and I really don't enjoy like although zero knowledge is wonderful it's currently being used for compression reasons and there's no privacy there and once again same thing you're just even higher above the stack uh since you're publishing all that data to the blockchain in a non-privacy preserving way it's not doing anything it's just a scaling solution so it's it's adding additional constraints that will eventually be subject to the same censorship or just like non-censorship resistance that we're seeing today but that being said it's awesome like there's a bunch of really cool technology being deployed and very very novel uh advancements in cryptographic Primitives that will be useful for scaling and adding privacy preserving Solutions in in different ways in the future so like I'm happy we're able to start to serve the amount of people that starts to compare to where we set it out in the first place like blockchain serving the world but if we keep moving in this direction it may become so ossified that we can't make solutions that keep it from being censorship resistant which is what I said in the first because the whole point of all of this if we build blockchains that are not censorship resistant that we didn't do anything we set out to do other than making I don't know digital fund money thank you anyone else if not I'd like to give the biggest Applause we have of the day because it's the last speaker Corey thank you so much foreign all of you for coming and I'd like to hope to see you tomorrow again um I would say enjoy the rest of your day and go grab some dinner thank you [Music] foreign [Music] [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] foreign [Music] foreign [Music] [Music] thank you 