[Music] [Music] [Music] [Music] [Music] [Music] [Music] so [Music] [Music] okay i've moved us over to the main screen um welcome everyone to all core devs 138 um tons of merge stuff today and then if we have time uh there's some updates to what was 4938 oh felix had a networking eip he wanted to talk about and then there's two other eips that wanted technical feedback hopefully we get through them um i guess first we had mainnet shadow fork for earlier this week uh perry do you want to walk us through how that went yeah hey everyone um so we had made that shadow for two yesterday he was hit around yes sir yeah four exactly um we hit ttd around 4 pm and it was a relatively like nothing big happened i think all the clients that were there before were also there after we added a bunch of validators to minority clients that we didn't have in previous shadow faults for example bezel lighthouse etc instead of purely displacer prism um just so that we can track attestation and uh the one thing we noticed was the netherlands mentioned that a couple of client pairs are proposing empty execution payloads so we're getting proposals but the proposal itself is an empty execution payload i know they're talking about it and potentially have a fix um i think there was a prism fix that they pushed yesterday i've updated a few notes with it but in general it was a really good run we did have an issue with aircon syncing up but that i think is an unrelated um non-merge code base related got it issue did you end up getting aragon synced i think that's still not at head i need to check up on them now yeah um yeah so we are working on a new sync mode and as fairy said they the issue is not related to the merge or like yeah so we we have a fix but it's not much related so you have a fix for the issue that we saw yes for the uh we have this news sync mode which uh which we are still um um debugging and uh like the finishing and things like that but the the old uh sync mode it works fine got it okay um cool and anyone from nethermine want to chime in about like the empty blocks issues yeah so the problem is that still the timing issue that i mentioned many times so uh for example lord start not giving enough time uh anthony boos for block production and because of that we have uh empty blocks and if we do not have empty blocks on something else it is also probably something wrong yeah and as yesterday uh i think mario's changed that behavior in gaff to be async production of blocks on fcu that would probably manifest on that code waster yes exactly so that's that's coming in guess two to have the block production async and then we should be also seeing empty blocks on guest so please uh the nimbus and lordstar or prison and lotsa i don't know the clients that don't give us enough time please fix this as soon as possible and for anyone listening there's kind of like a prepare like where you're saying hey execution engine i'm going to ask for a block and then you call and a little bit later and say i want the block and if you put those too closely um you know you just get an empty block from the executioner um anything else people wanted to um to discuss about the shadow fork itself okay and then perry as i understand it uh next week we are doing another mainnet shadow fork but instead of using the client distributions uh that mirror mainnet uh where there's obviously some like majority clients we're gonna we're gonna do kind of an equal split across cl and el is that correct exactly we're just gonna do an equal split and i think the other plans to have the configs out later today awesome okay one thing maybe worth noting just with the issue that was seen um you know if there are some amount of blocks that they do produce beacon blocks but they don't have any transaction payloads the elasticity from 1559 in that case as long as it's not the majority of blocks um would allow for no reduction in capacity um so that would almost you know be something we wanted would want to fix if we saw it on mainnet but would have been kind of a no-op for users which is nice right you get slightly slower inclusion but you know right but that would discourage um flying diversity yes yeah yeah i don't mean it's a good thing i just mean that it's not that bad anything else okay uh next up on the last call uh mikhail you had a request for comment about like an engine api status response when the merge transition block is invalid um so i believe we just went with like the third option you proposed you want to just give a quick update there yeah we just figured it out and it's now on the spec it's converged like a few moments ago so yeah in the invalid terminal ball cache is now replaced with the invalid status class play this valid hash point into all zeros block hash in this way it's like less complexity for a ceo client side and i don't think that adds any complexity to el as well and also it helps to [Music] to fix the blind spots which is mentioned in the rfc that we previously had in this pack any client teams have thoughts or comments on that all right if anyone go ahead i think i i think the change is fine it's just like i was a bit surprised that we did this change and so like these changes should not come this late in the in the pipeline and they also should be communicated otherwise i'm fine with this my one comment is to have hive test for this change yeah [Music] yeah that makes sense i agree in you know anything that is being changed right now is primarily only related to edge case errors but even in that case i would prefer to not i think it's it's at this point we really need to be halting that yes i agree but we had to have something here yeah and it's been communicated i know everyone is busy with engineering so i understand that it didn't get too much attention but anyway it's been communicated in advance and the asset will have a hive test for it basically uh one of the uh yeah when the work and test uh was like on this checklist um on the test checklist uh this blind spot has been discovered that was the initial like reason to have this kind of you know change okay any other thoughts on that yeah i just um my thinking is that when do we finalize the engine api so because because uh football like we would be finalized for robstern or for which test net because we should say okay this this is uh we have merged all the pull requests that we that we already under consideration the engine api is final like like mark will have a release give us some time to like double check that we do implement the final revision because it's otherwise some things might like with so many clients we will get yeah i i think we're at the place where we should probably put up a pr that's called a release candidate and not have anything go into it unless it's heavily discussed and noted by client teams um and that release candidate would probably stand until we're pulling the trigger on choosing mainnet but i think that release candidate should be up for review pretty much now as we're trying to make decisions on robson are there other things that we anticipate needing to change with the engine api now i think it's more or less final uh the the right cup there are a couple of things that in terms of like clarification so it's not like changing behavior whatever but i think we can do them shortly so there were a couple of requests to clarify responses in some cases and likes and uh like safe block hash set to zeros uh should not be responded with any errors this also should be clarified in this bag yeah and yeah but that's that's like that that's not the updating behavior and in design it's just clarifications i think we can do that and then cut release straight forward so we don't expect any other kind of semantic changes basically we don't unless it's like necessary change right right obviously you can find a bug or an error but um when do we think like we can have those small clarifications and then a release candidate can we do that like sometime next week or is it does it yeah definitely next week we can do this um i'll take care of these changes and then we can communicate and cut release next week i guess unless there are any other opinions similarly we'll cut a release candidate this coming week in the consensus specs as well and i don't think anything has changed in the execution specs for like four months now there's two eips in it yeah the ap is a pretty stable yeah okay anything else on the engine api okay uh the other thing that we did finalize was this discussion over the json rpc finalized in safe tags mikhail do you want also give a quick update on that sure so so there are two new blog tags that we have added to uh to the uh namespace so we have like we had the earliest uh latest and pending right and now we have all these and also uh finalized and saved in addition to the previous ones um there was a discussion to have on safe and as an a and the alias latest on safe um so yeah we we decided not to introduce unsafe at all so it's now latest will always point to the head of the chain as it's been previously all the way um and uh yeah one one thing here is that uh execution where appliance should respond with error and this error is specified in this change in this pr uh the the iel client should respond with error uh if the if safe or finalized blocks acquire it before the transition gets finalized that's one thing that's worth mentioning any thoughts comments on that okay um okay next up uh so yeah we are we are kind of getting close to test nets um and then one thing uh to note there is that while gordy has an existing beacon chain associated with it uh prater uh sepolia and roxton do not um and there's been some discussions over the past couple weeks about like how do we structure those chains um danny and perry i know you've thought a lot about this this week do you want to give kind of a quick update of where what you're thinking for for both robson and cepoli at this point uh yeah um so first of all naming wise i think we should just call them robson beacon chain it's a polio beacon chain and the unification of the networks after it's just robson that's polio that's easy um the robson robson as far as i understand will be um support would be deprecated probably after this uh in the order of some amount of months um and so doing that there's two options one would be you know have a conservative size validator set just kind of get it up get it going um with an open validator set or do a permissioned validator set with the erc20 contract based on some some discussions i think doing an open one is most beneficial to the community and we can start with just a hundred thousand validators that we control um and community members can add and it would be unlikely that the community members would add so much that it would disrupt you know our stupid stable backbone that we've added um robson i think is going to be the first test that worked so um we really should get this beacon chain up in the next couple of weeks uh and then somalia beacon chain i think the idea would be to do a 2x validator set size in comparison to mainnet today also make it unpermissioned so that other people can jump in um this would give us the chance to or was it permissioned i'll let perry chairman but this would give us the chance to kind of see if anything shakes out with such a large validator set pratter which will become gourley is about the same size as mainnet and we try to track it poorly okay um we try to track that so pretty much we need to launch two beacon chains um the robson one will be unpermissioned hopefully people will join i believe the uh sapoli one will be unpermissioned as well but i can't remember perry did we have one way or the other we were thinking there um yeah we were thinking we can use the token contract so to be permissioned but we can just open up a form for the token yeah yeah right and one of the one of the reasons we might permission that one is to do random testing on it um in the event that we want to turn up at the validators or have a more controlled environment i think the the thing that we'll do is pretty much have suggested configs have suggested uh distribution of validators and kind of make the rounds and get quick thumbs up and have the teams join us in in kicking off these beacon chains yeah the main thing that's so with robson i agree it's pretty much straightforward we can start with something that's like 100k and people can join in um should be relatively easy to set up and anyway it's going to be deprecated in a few weeks months so we don't have to worry about it too much but the one i would like to discuss and get some consensus on the sequoia we essentially have two options either we want a large beacon chain there or a small beacon chain um a large beacon chain means that we essentially saved early eta because we don't have to keep growing prata if we go with the small beacon chain for sephora then we're gonna continue to eat up a decent amount of garlic and that's mainly because we want to continue growing harder to keep up in it right so sepolia if it's big becomes kind of our main net plus testing environment exactly um and the question then would be if we have a really large beacon chain for supporter that means client teams have to now run two times a decent number of validators and have no idea how how open they are to them yeah to answer your question justin i mean i think most client types can handle thousands of validators per node i don't know uh i mean you can also throw more resources in a node and handle lots of validators for now so i don't i don't we don't have to spread them necessarily too too widely i don't think it looks much different than what you would do on crater today yeah definitely it wouldn't be that different from what we have from prada today um given we have aphroe on the call and uh you came on afri a few weeks ago to talk about the issues around gordy ether do you have any thoughts about like if we should keep prater slash boardy as the large beacon chain um if that negatively like affects gordy in other ways uh yeah sure i mean um gurley and prata is already fairly big it has a lot of users and has a lot of validators um sepolia is kind of still very unknown so there's no we don't have a beacon chain yet and uh we don't have many users building on sepoy yet naturally um we have to keep in mind that we are duplicating a lot of test nets in the coming months or years so i would be uh my personal opinion is that we should use sepolia as like a fairly stable application developer testnet because it's fairly new and we still have the time or the chance to um define how the consensus layer would look like or the superior beacon chain would look like and i would personally just keep it simple for this network and i would personally say that we should continue growing prata but that's that again it's not that easy because we have a limited supply of uh gurley ether but um putting this aside uh the main reason why we should grow prata and girly is because it's already fairly big and we have a lot of much more much more interesting uh foundation for testing and for growing this network it doesn't make sense yeah yeah if you see it as a positive i think it's yeah that seemed like the biggest like reason to not have a large beacon chain uh exactly i think that was the the biggest point if we wanted to save angola ether it makes sense to have a big one on sephora but i also agree we can have really stable permission consensus engine and have supplier to be quite rock solid yeah that was my original intuition um and then i was convinced to maybe do the 2x i i think that's totally fine to do a smaller permission very stable net something that kind of feels like clicked in users that doesn't have to unbox um and [Music] i there are a number of kind of emerging ways for us to test load across many many nodes that aren't they're more in like transient type test nets and not public test nets so if we do want to test you know 2x 4x8x we can change sizes that we might instead just kind of take it into those test environments rather than only public distance um quick question if we were to do the token beacon chain um this might interfere with withdrawal testing right or no it's independent so it's trans it's very transparent to the beacon chain it has the same interfaces as the deposit contract and then withdrawals are totally totally unrelated to the deposit mechanism so i think it will be fine oh right i'm stupid sorry but um yeah yeah but uh doing this way on girly if we were to do the the token deposit on deposits on girly we could create new girl leave we could inflate curly with withdrawals but we'd have to like hard wait what was that what was the suggestion talking about yeah but you like it yeah but it doesn't make sense to to throw away prata anyway so yes and there is a separate just don't know what i saw i guess one interesting thing though there was a suggestion to like upgrade gordy to give the clique signers a huge amount of if um i guess you can still do that even after the merge on gordy because you still know the accounts um but it's kind of weird because you're like it's like a retroactive thing um yeah okay um anything else on the beacon chains um how long would it take to set it up yeah i was thinking of maybe setting it up on monday or tuesday so clients could already bake releases but we need a we need to figure out some timelines for that as in when when does genesis happen right and yeah and and not only genesis but also how we want to run through all terror and electrics right right i would suggest on on robson we just kind of like make it happen very quickly um in the in the sequence of initial 2800 epochs um and then maybe for the sepolio one uh planet a bit more like it's an event it's a thing that's happening run your node before it happens okay for this yeah and then the gordy yeah so on robson just kind of like yeah yeah gourley we have to we'd have to schedule anyways so any anyone running currently would have to upgrade their node for the bellatrix work right and then that means that if on robson we want this close kind of uh upgrade of genesis alter electrics we need the ttd for the bellatrix upgrade correct um right i guess you would want to know it at that point in time right so if you have a single release upgraded again yeah okay yeah so if that if that is a complicating factor then you just launch the reps and network now and then then ships it to the upgrades when you know um but but i guess that that would um the distinction on what to do there i would defer to when we're having a robson upgrade conversation which i think we're having soon yeah i i guess yeah just before we we go there any other like concerns or thought about the general architecture or setup of the the two beacon chains okay um okay yeah perry thanks for the summary in the chat so robson is 100k validators plus i'm permissioned for people to join and um simplia will be more like 20k and then be provisioned um probably would have not an option for people to join as well if maybe like not as easy um yeah exactly we'd have a bunch of tokens and whoever wants to join needs to ask us for tokens right yeah um yeah but then more stable obviously um great okay so yeah i guess uh you know on the last call we kind of briefly talked about uh robston and i over over the past two weeks like i've i've tried to talk with the different kind teams and testing teams and it seems like my my general impression is like client teams are not don't have like quite stable releases yet where there's still like some kind of open issues that they're looking at uh there's still kind of some failing hive tests here and there um and so it's it's clearly not like a spot where the code we would deploy today is what would go on mainnet um that said um robsten is basically like a kind of test net we we intend to deprecate and one thing we also talked about in the past is uh because these upgrades are like uh a bit more uh hands-on for for node operators where previously they would just like download the new version of whatever kind they're running and upgrade that now they need to like figure out you know running an el and the cl in parallel um and making sure that like that whole setup works and and that uh their infrastructure still works it and what not um it might be worth moving to like drops in a bit a bit quicker than we otherwise would because then you get people like another you give people like another chance to try the software and make sure that um the the overall setup works um even though obviously like what's going on on robs what would go on robson is not what would end up going on main net um we'd probably still have like some bug fixes and whatnot um so i guess i'm curious you know how do people generally feel about that do we feel like it makes sense to do roxanne even though we're you know still kind of working heavily on testing um do we prefer to wait uh to do robson and then um the risk there is potentially you know we we might have to push back the bomb uh but that might still happen obviously if we if we find an issue a critical issue at any point in the process so yeah curious how how people feel about that so another mind is fine the only potential issue is that it will take us a bit to um release a version that we could use on robsten so depending on the date we might release version let's say a little bit late of course before the uh the imaginary upstand but a little bit later than usual okay and what what does late mean just to get like a rough feeling i think it would be in two to three weeks we can release the vas go to robston two weeks is probably doable but not like in a week not like in a few days okay so for gath we want to create a release anyway next week and if we have the ttd for robson we can bake it in there are a couple of open pr's still to merge for for for for the merch stuff um but those are only like minor issues um they were formed by by hive and so it's like not really relevant to the node operation and to the test nets and so we can bake them into the release or we can also just release them in the in the release afterwards uh peter i see your hand is also up so i just wanted to add that um also i kind of agree with what you've said previously that this hard fork is a bit special in that all operators need to do a lot of extra work to figure it out and set it up so i i am very very supportive of the idea of forking roxton let the hit the fan and uh so that everybody kind of figures out what it actually means to be part of this merge network and then uh then see where we go with the rest so i think it's it's a good idea to do four crops and early before making any commitments on the other ones got it one thing you'll also add on that front is um i think for mainnet there's a world where like the hash rate is you know potentially going down and whatnot and we may want to fork like to have the ttd happen quicker than like the blood times we set usually happen so i think that the thing we also want is like to train people in a way so that when mainnet comes they're able to upgrade relatively quickly and maybe a bit more than like in a normal upgrade just because it's hard to estimate the ttd especially in a world where the hash rate is is all messed up um um basu aragon yeah um basu similar to to geth we have a release regular scheduled release next week and if we have ttd configs we should be able to make uh robston uh merge into those configs um we also have some failing hive tests that we're working on so we want to get those as uh sorted out as quickly as possible the uh our release is planned for uh wednesday of next week so um depending on when we have ttd configs i think we should be able to get that baked in okay so emirates you're going to say something um yes it's really unrelated but i think we should think about moving the sepolia for a fork up a bit because it's relatively hard for for solo stakers to set up notes on on on on robs and girly because they have to sing so much and like giving them the ability to test on a newish test net so that they don't have to have to uh sync too much might be a good idea so you would do like cetalia before gordy or even before robson i know i would do supolia before girly okay okay we can definitely consider that yeah once we once robson has survived emerged um aragon any thoughts well next week i'm on holiday so we can um we still have quite a few things missing or like not fully implemented for the merge so we haven't updated we haven't uh updated to the very latest engine api and also we have a lot of tests failing in hive because um uh the the the what's the click mining is not set up there and also uh i haven't tested i haven't fully tested our sync performance um it's quite a few things but we can provide a kind of uh raw alpha version if the ttd is known okay and i'm curious on the on the cl side like i see there's like some prismatic people here i i don't know if there's any other cl team present there's more people that can fit on it on the zoom screen right now um but yeah anyone from the from the cl side have hot thoughts um i pretty much agree with um old with what everyone said so yeah no thought on my end the you know i don't have direct answers from the rest of the teams but we have talked uh as though this was very likely to be the next step and to happen around me now so i i don't expect much pushback for any question yeah no issue from techy side i think okay and so i guess the does it make a difference like so it seems like geth and and and basu can pretty much release something next week without too much issues um another mine still needs like a bit more time and and and then eragon uh holy literally something like right now or then also also needs more time um does it make like a difference if we choose the ttd today or like in the next basically in the cl call next week like does having one extra week before you know the ttd um and then we can put out a release which combines everything does that help people or does that not really make a difference um so it's like if we choose it now and have a release next week versus choosing yet next week along with a slot i guess for belatrix uh in the cl call and then having your release like the week after so like two weeks from now um yeah does that like move the needle for people or increase the confidence or is it kind of all the same and i i don't i don't think it makes sense to not choose ttd right now um we can always uh we like if you want if you if we want to have releases out in two weeks then we can have releases out in two weeks but um like choosing the ttd next week is just really weird to me so we should choose it right now and either decide to have the releases out by next week or by the week after but uh like artificially postponing the decision to choose to ttd um doesn't make sense to me at the moment okay uh andrew you have your hands up as well um yeah i would prefer to have a two weeks window for the release because as i mentioned next week i am on holiday and i'm not going to work on anything like maybe like on the ttg the bare minimum so another week would be helpful and that's knowing the ttd or just having the other week to ship the release like if we choose it now just another week to ship uh i release peter picking a dtd i kind of i think we can might as well do it i mean there's no harm really the only catch is that um roxanne is fairly easy to attack so to say meaning that pikachu now and somebody just starts keeping mining with say four and that tpd might arrive tomorrow or something so we need to also have a contingency on what happens if somebody goes uh crazy right so basically it's what happens if we think the ttd is gonna get hit before the bellatrix slot gets hit and then we need like an emergency ttd override the the bellatrix slot i mean we plan on just launching this beacon chain right so we just need to we need to launch the beacon chain before we hit ttv all right so but but hold on uh that's not a problem is it uh it will just mean that the client's course what would be a problem would be if we hit the tpd before we actually made the release before clients have been released so right right yeah otherwise it would be a live mass failure yeah that's totally fine yeah okay so um i guess i mean oh go ahead peter sorry so if we um i mean in theory it's time to hit the dtd before the weekend thingy but if uh if we're going to hit the dtd four days before the beacon chain launches then you're going to have so many siblings at the top so many sibling dvds and essentially when you launch everybody will be on their own little chain will there be a bunch of sibling ctds would would the miners keep mining or they would they just stop mining i mean i will make one just for the fun of it yeah but you might you right but if you're running a robston miner um it's just going to keep building on a single chain likely rather than making a hundred little fork chains around qtv so if you're running a stock get code at least then your miner will as far as i know will stop finding everyone actually that's a good question no i meant if you don't run if you're a miner and you don't run the upgrade which is the only reason you would stop you wouldn't stop no you would mind the work chain it would continue which would create a really nice stable ttd for everyone else okay um so once once we have the releases out you know there's like the blog post on the on the ef blog how long do we think we we want to give people to upgrade their robsten nodes like um so you know we're basically like uh yeah so say like two weeks from now we have a blog post that goes up um and says these are the versions for for robston um is like another two weeks before we hit ttd sufficient for people yeah i think so nobody really oh okay apologies if i offended anyone nobody really uses robstone okay so time to be a bit aggressive and do yolo with it a bit just to get things rolling mikael um on the related topic i would just like to remind people about fork next value uh if we are deciding about forking robson i think it's it's also need to be decided what to use for the fork next value oh because oh so do we so so that means you basically disconnect the peers this is like for the fork id right right and so so in theory you shouldn't make any decisions based on on the the merge fork block i know that in the past some clients have implemented some stuff differently uh like except for the focus change and so we can set the merge for block either before or after the actual fork so yeah it's also important to notice that the uh the fork next it was kind of like invented for this world where forks are scheduled at a specific block so uh it might be better to ignore like to not set it for the merch like felix we have we have a merge fork block specifically um that is not the fork where the merch actually happens but that that is only for the the to split the networks afterwards and do we want to set that before like in the release for the merge or in the release after the merges happen and we know what the actual terminal block hash yes yeah we need to know what yeah we need to know what the block was yeah don't think it makes sense to set it before um we were discussing one way one reason to set it before is it will force users to upgrade their notes because they will see that they are starting to lose connections like with other peers uh but i don't know if like this is valuable to do and i don't know if it will work as as discussed and like the downside to it is that you that you will alienate all the people that are not uh upgrading and this might include miners so my miners might be uh like uh uh forked off from the the network and so i i think it's very little gain for for for a potential bad situation uh martin i see you have your hand up yeah i have a question slash thought so if we said forklift next to a high value um that won't uh split the network with it until that high value has been hit because i was wondering if there might be an um any value in setting up or next to some high value just so that we more easily can determine on the peer-to-peer protocol level kind of how large percentage of the network is upgraded just [Music] high value meaning like i don't know six months from now no i mean like for for robson we we do the release and then we can get a kind of good estimate by just connecting to 100 pairs and checking how many signal that this new fork id next um and know how large the census network has upgraded right but i think otherwise we would have to how big do you just like how far in the future do you pick the block you just picked like a random you know that's not like i mean you could you could put it to three years in the future yeah but would it maybe be valuable to put it like plus two months past what we think ttd is so that it actually does take an effect probably more people upgrading because if we ever do hit that then we will actually cause a split so we should i mean if we use it only for that purpose then we should set it to like three years in the future so that we know that two years from now people use a different software uh where we have kind of disabled this or not have this but the point is actually to have that split the network so that's the entire point otherwise why not disable it all together until after the fork what number to set right so when we do the next release we can set the 4kd to whatever it was i mean you can just punch it and set it to i mean if you send it two months in the future there's no way you're going to reach that i mean somebody might attack robson and my two months worth of blocks that seems a bit excessive but definitely won't won't be able to do it on on any other testing uh andrew you've had your hand up a while um yeah i think how far as far as i understand it if we set it too far into the future then it won't cause a split and we already see this happening on shadow forks so for the main net i would think we should set it to something happening reasonably soon after the gtd is reached like maybe two weeks or something like one week after that means that am i right and saying that means that miners then need to upgrade their nodes well if it happens after the merge that they then they don't okay because you don't you don't pre you don't disconnect peers until that block has actually been hit correct right right well ideally you would want to set it like maybe an hour after after the merge but how can you get what if is it possible to change fork id to actually be based on the ttd rather than [Music] running into it yeah so it's designed to be a block number and we cannot change the definition now because all the other software also publishes as a block number we could make another we could make a new version of the of the sort of like enr entry and things like that like we could just create like we can create a new system that like works a bit different but then it won't really be supported by the older software so it's like the this is we know that all of the nodes right now with that implement the protocol will behave according to the previous definition and it's the this one that is given in the eip also with the rules and they are based on the block number so yeah and and we'd also be doing all of this work basically just for one time right like there's no um [Music] like we're not after the merge basically we're not gonna need this because you can keep using your block number um so it seems like i don't it just seems like a lot of work to basically solve for this edge case all right block number need to be chart coded can we just like when we finalize the transition block can we just use this as dynamic for craigie no um so the problem with fork id is that the moment the fork passes the the block number all of a sudden it gets enforced and anyone who tries to connect to you and saying that let's say they are up to date with the network but they don't know about this and so given that and you probably it probably means that you want people to retroactively upgrade the fork id kind of at the same time does it make sense to target a block number that's at least over a year out so that when we have the next hard fork after the merge we can update both block both fork ids so we can like update this fake one and we can update the real one to whatever the next fork block will be um would that this does that make sense because otherwise if you have clients like changing it right after the merge and they don't already put out releases at the same time like basically we're not coordinating your hard fork um then you might see some weird stuff happening there this is kind of what we were saying right so it's okay i think to basically let's just try and work around the fork id for the merge so the the consensus that i'm hearing is the fork id will just like it's a potential source of trouble with the with the merge and it's also not possible to set the block number so we just kind of want to ignore the fork id for the merge and like why should we set it at all to something for the merge then well like in order to to like disconnect from the nodes from from the unupdated nodes quickly after the merge if the yeah like if we were like if we were to schedule a new fork one or two months after after potential ttd then this would happen right sure but also one or two months is like way too long of a delay to fix the like yeah why not just make yeah so basically i think the fork id will not help us with the merge so basically we should try to get the fork id out of the way for this for the merge it's not it's not a regular hard fork in that sense so it cannot it should just not have the we should just not use the fork id it's not possible to schedule it correctly and we will just schedule it for the next fork again and if the merge goes really well we just schedule like the next fork very soon and i mean people will be i think very ready to upgrade their notes after the merge like i mean we will see the people who will upgrade for the merge will also upgrade for the fork after i think and this four can literally only be about i don't know probably something has to be fixed anyway and then you know we can schedule it by the block number and make the fork id and it will everything will be fine again but i think for specifically for the merge since it is not scheduled by the block number the fork id system cannot help at all it was designed with the specific goal of like providing what it does when the fork is scheduled at a specific number uh daddy yeah so i there is potential value in being able to crawl and know what nodes have upgraded and what notes haven't but we can do that with the graffitis and the and the client versions right you tell me on the client version graffiti not necessarily that's what that's what ethernodes does they look at like client if client version is bigger than x across every client yeah then that's fine i also but i also think it's not necessarily unsafe if we do want to quickly upgrade this after to just firmly put it plus three months of what we think the longest ttd would be and then you get the natural segmentation after anyway without having to upgrade the notes again i don't really care i think that that's like relatively clean but otherwise it's fine to also just do nothing uh jamie yeah um i just wanted to mention um a kind of counter of intuitive uh aspect of the fork id when it's added that was uh found working on nimbus um when you add uh a next fork id um it's not true that all of the nodes that haven't upgraded will sync up to that fork id um the block i mean of that fork id if they're sufficiently far behind they actually stopped thinking at the previous fork id so we had a situation where once london was passed and everybody else had reached consensus on london when we were running software that didn't know about london it actually only synced up to berlin and then it wasn't able to connect to nodes after that um so it's perhaps just something to keep in mind because you mentioned earlier uh that you believed all the nodes that haven't upgraded will keep syncing up until the next block associated with fork id it doesn't always work that way got it um is there is there some argument against what danny suggested just set the work id to three months after what whatever we think the longest out is well the problem is that you you'll have a lot of like we observed it on shadow folks and for some reason when you ask for a certain header by hash you get incorrectly i don't know who sends it but you you have headers from the wrong shadow fork on like from the main net when you're on shadow  and and so on so and that happens because on shadowfox uh merged emergency block uh is set uh so so far into the future that it doesn't cause a split so for if we set it for to plus three months we'll have for three months if we don't do anything we'll have this weird situation when you have fears from both proof of work and proof of stake let's see so the if understand correctly there's basically three options one we don't use 4k at all and which would still result in the same problem that you just described or we set the fork at a three months in advance in case we have three months of that problem or we do like a quick upgrade right after ttd and set it or do some sort of manual around so that we don't have that problem at all is that accurate well we can try to calculate it so that it happens like last two weeks and then that like i wouldn't i think trying to calculate it plus two weeks is is a bit dangerous because we don't want to have have it before uh the fork because we don't want the majority of miners to drop off before the fork so i would i would say let's do something like plus one month plus two months and and that's it and that's basically been the idea from the beginning uh lucas your hand is up uh yeah so we had still have this issue somewhat and shadow forks when we tried to sing we were trying to sing from wrong piers so our work workaround there was to um when we connect to the peers ask about of one of the latest blocks we got from beacon train about the hash if they have it and just disconnect if they don't so that's kind of a workaround that we disconnect uh piers i mean without those does that mean that you can't sync from peers that are currently syncing yes to some extent depends on their stage yeah sure also these issues um on the shadowfox are only this like harsh because you have like 100 notes on on each shadow fork but you have like thousands no thousands of notes on maynard um if you turn it around and like most of the notes are i actually having the canonical chain then you won't have to won't have these uh these issues uh sinking from the wrong piece yeah but i'm i'm concerned because upgrading this time around is so much harder um i have a small fear in the back of my head that we will have significantly more people that don't upgrade correctly or don't upgrade at all just because it's hard this time whereas previously as you know just update your docker image update your package whatever now it's like oh i gotta do a bunch of work maybe i'll put that off and not do it and so i'm concerned we might end up with actually a significant number of nodes not updated so to clarify we're asking only about the header so currently after the after the match um everyone starts with syncing the headers like backwards probably so that's you don't really disconnect anyone that's on the after the match train so practice just uh to kind of try and wrap this up does it make sense to try to just do nothing with the fork id on robston see how that goes and if we see that like it raises a bunch of issues we can then try and do like a plus three month thing on on gordy and sepolia and and see how that goes um i think like micah like your concern about people not upgrading will be at its truest on roxton because this is where people have the least incentive to actually upgrade their nodes um so like if you know if it's all right on robson and it doesn't cause any significant issues you would think on main meth they would also be right because the stakes are kind of higher for people to monitor that network if they understand correctly we've already actually we've already seen the problems it caused and we know there's going to be problems right on main main shadow forks though which are very different because maintenance shadow forks there's like a hundred notes that we control and like thousands of notes that we don't and so that means that just like statistically the peers we get they're all on the wrong fork from the shadows forks perspective which won't be true it might be true on props then to like a 50 50 degree but not the like 95 to 1 degree yeah i hear you're saying my my gut tells me that having two peer-to-peer networks that are incompatible with each other that don't have a way to uh distinguish between each other is likely to cause problems that we may not even foresee until may or may not hit until midnight and so i'm hesitant to just kind of yolo and just hope we don't run another thing but that's just a gut thing i don't have any actual evidence and that's exactly why we don't want to have to fork before maynet but before tgd hits we want to have the after ttd head so that we have the split network post ttd um i would just say let's let's let's shuffle this discussion for now let's just say we're not going to schedule a a a merged fork block on on robston we're only only going to do the ttd one and um i don't know get never had issues finding a good peer and sinking from them so yeah but we can like sorry go ahead yeah no i'm finished so the the only reason i would push back on that a little bit and this is pretty weak is just that if the final solution we come to involves doing something other than just setting a number like if we decide to write some extra code i would really like to see that tested on robston and so not deciding until later um kind of i feel like we'll cut out a handful of potential solutions whatever this might be yeah we we are not going to do anything except for setting this number yeah i would not write extra custom code that we're testing super late in the process on like zero of the shadow for like the minority of the shadow forks that seems like the most error-prone thing okay okay so any other strong opinions against doing nothing on robson for now and seeing how it goes okay uh sold so no no fork next value on rustin um and then back to uh the ttd uh discussion um so if we say we want the releases for robston two weeks from now um so that's like the week of may 23rd um that means we and then we give people kind of two weeks to upgrade their nodes so that means we want to like have the fork happen on robson the the week of june 6th um we had someone on our team mario not mario vega mario havel um kind of tried to estimate uh ttd's on mainnet and robsten for a while now um he tried a bunch of different models and this is just like a simple uh polynomial regression um and that seems to work the best and it seems to work relatively well up to like a month a month out um so i would just suggest that we go to like the june 8 value which is roughly in the middle of that that week um and this gives us this ttd value which i'll paste here anyone have an issue with that we can make it look like a palindrome if people really want that but otherwise also happy to just go with this estimate i'll also share the github repo in the chat here in case people want to have a look more um oh yeah good question ttd is terminal total difficulty it's the total difficulty value on the proof of work chain at which we trigger the transition to proof-of-stake um and so the one i posted in the in the chat here is the one that would happen on june 8 which is basically yeah four weeks from now and so it gives us two weeks for the client releases and then um two weeks for people to upgrade their nodes uh to a release that that contains this value so as was brought up earlier um scheduling the robson fork far in advance risks someone trolling us and hitting it you know next week or tomorrow in that case we need to do a ttd override but i don't know that there's a way we can get around this because that can be true like as soon as the blog post is out if we give people two weeks anyways it's always gonna be the same problem i mean what one option would be to just use the override exclusively for robston like we just say we're going to do an override we'll tell you what the ttd is you know three days before june 8. um i think that's really bad because then we don't exercise the the real path i see what you did there marius yes basically that's that's that's exactly exactly what we win yeah that's exactly what we did on uh what we do on the shadow forks and um i think there might be a bunch of issues there yeah okay you win i can see um andrew do you have that well my preference would be to postpone it to the ttd to the 15th of june but if like if everybody thinks that it should be the eights i'm i'm okay with that but my preference would be the fifteenth anyone have a strong preference either way i have a weak preference for 15 i i have a medium preference for eight it's basiu medium preference for the eighth um weak preference for the eighth but yeah guess as well so mary's already yeah what are the reasonings for eight versus fifteen like why are people preferring one versus other the very first test that wouldn't merge until june that's that's uh definitely getting us into territory we would need to push a difficulty bomb in my opinion uh that's probably true but uh i don't think that pushing the difficulty bomb is that bad uh it gives us more time to prepare a release a better release and more time for testing but i i don't insist if the majority thinks it should be the eighth chance all right well i would i would agree um but my view is that this is testing um if it were i don't consider robs in a production network it's a test network so so therefore i think the sooner the better because it gives us better testing for when it's for the real thing anyone else have what mine is the same as andrew i [Music] still see work before us and yeah that's pretty much it so more time we have to polish the release the better for us but life is doable and also i don't see a problem delaying difficulty bomb when we are already going to testnet so if it's a short delay but except it is a little bit additional work for and scheduling but i don't see this as a that big issue but that's just opinion that might not be correct i i guess one objection against delaying the difficulty bomb is that that it will imply that the miners will have to update and what if there is a revolt among the miners right yeah they do need to run now so from my perspective just play to the devil's advocate here a little bit um us pushing the difficulty bomb indicates that we are going to delay the merge which is good for them and so that feels like something they would be on board with fair enough yeah i i can see both sides of this um and so okay so if so if if if if we did do like the june 15 rather than the june 8 it also means i i guess both for like uh nethermine and aragon you also want to delay by one week when we actually announce the releases right because it's not just announcing the releases and having three weeks to hit robsten it's more like we announced the releases one week later and instead of announcing those releases in two weeks we announced them in three weeks and then we hit drops in two weeks after that is that is that correct uh yeah yeah yeah um there's like a week weak majority in favor of june 8th um [Music] yeah i don't know guest basu do you have any updated thoughts um still june 8 weekly healed i like i like the palindromic ttd after he's already put the effort in okay and taku would also like the june 8 um anyway i think i think ben you're the only cl representative left if that's correct uh and how about danny danny danny left i think danny favors i i can vouch that danny would prefer earlier rather than later um i don't know if that's his personal preference or the aggregated preference of like cl teams yep um so i think i would also slightly land on like june 8 and one of the reasons here is um we can definitely upgrade the releases that like clients put out um and we've done that in the past even for like mainnet if you look at the london blog post fork there's like a couple scratched out releases so i think if there are going to be some clients and like most of them that are that are ready um and if nethermine and aragon have like a release that's maybe not like the the one that they would prefer we can kind of start with those and then if like a week later um aragon and nethermine have like an updated release we can definitely like just upgrade the blog post and and communicate that um and i also think like if if if one of the things we do want to test is like people configuring their nodes um then if we do like the sooner the better i think is good there because we might find some issues that we're not aware of about just people running these these kind combos um and and it's something where like i think the fact that the release is like a bit more polished probably is not like a huge deal breaker so i my weak preferences also i would rather get this into the hands of people to like try to like combinations as soon as possible and then just like make sure that we also upgrade the release versions for nethermine and aragon as soon as there's like a new one um i don't know does that generally make sense yeah it's fine okay miraculous okay okay so thank you afree for the palindrome which i was too tired to recognize and so i'll copy paste it here i'll copy paste it here also i'll just share it in all core devs right now um so consider this the ttd value um i'll make it a proper upgrade to the shanghai spec in the execution uh repo and the thing that uh clients on the cl side need to figure out uh in the next week is basically the slot heights for uh well basically the genesis for the beacon chain and then the slot heights for altair and dilatrix uh based on this does that make sense yes okay thank you maris um okay um so there's three people who wanted to discuss eips that are on the call i doubt we can get through all of them but if we if we stay on an additional five minutes we can give them each five minutes um yeah so uh first up felix you had eip four four nine three eight yes so and this can be really quick so um this isn't already like pre-agreed um i just wanted to let you guys know that uh for formal reasons we are pursuing this eip the eip4938 is about removing the get no data message from the eth wire protocol and we have discussed this extensively with all client teams that we are aware of um that we want to make this change in geth and we have been wanting to make this change in guest for a very long time and um i can only really repeat what is in the eep um we are set on making this change because it will allow us to for example restructure our database uh to not uh store all of the tri nodes for example by their hashes and we do we do provide an alternative to this protocol message in the snap protocol and all of the existing users of get no data can be replaced by the messages in the snap protocol so it is not but so can we just very quickly can i just very quickly get from the client implementer some signal that this is okay okay from aragon no i think nethermind still uses get node data for fasting we are currently using it for healing um there is work being done to move to snap sync healing but it's not done yet and i guess peace will keep it for the other networks yeah presumably we would be keeping that for i we should probably get back to you on on that actually because uh the snap sync implementation that we have is pretty solid but uh it's not really uh production ready yet so we probably want to discuss before we have an opinion so um what should be what i wanted to say here is that even if there is no need to implement the complete snapshot algorithm to use the snap protocol for this purpose basically um this is just for us like a way to say that we want to roll out this new protocol version e67 which will not have get node data it doesn't mean that e66 will go away immediately we will keep having it 66 for a while because phasing out the protocol version it takes a good while so all we just really want to do is basically move forward and define the protocol version 67 which does not have the message and then later we will remove version 66 and then it will become unavailable so for the time being e66 will be served by uh geth and i mean i'm not sure i i guess all the other clients will serve it in the same way that they have been serving it already for example in some clients like aragon the message is not implemented so um yeah so question mark when would this go in like in the timeline and when uh get no data would be stopped serving sir won't be served well we can make some promises now uh i mean i guess we we would we would like to have it like in as soon as possible for us it is really simple to like in geth to make this change so we can literally just release like this protocol version next week it doesn't change anything it only changes that there's this new version available and then removing the version 66 will be a bigger step and we feel like yeah we'd be optimistic about maybe like the autumn or so or the very yeah not gonna happen before mars yeah definitely not for the merge this is for much later we just want to set this process in motion we have been talking about this forever and we just wanna like this is like the next step on the way toward removing this feature so yeah so in terms of defining the protocol as that i'm fine in terms of uh like phasing out eth 66 could we have a guarantee that we have a discussion before that and yeah yeah yeah it doesn't mean it doesn't mean it will go away tomorrow uh we we are not uh we definitely open to discussing it in terms of the days because we are we are planning we are actively working on it i think we will be uh ready for the autumn to uh stop using it no data uh not sure if we'll be ready to serve uh data in from for snap sync which is the the harder one uh but yeah so i'm i'm i'm fine with generally general idea direction okay okay so i don't know what this means in eep terms is it like anything needed uh i guess can we just discuss that offline for the well uh yeah but okay no objections to the new protocol we're not deprecating 66 now um yeah hey yeah this is uh basically just to clarify what gary was saying we're fine with the new protocol version it's the deprecating of the old one that gives us a little bit of pause okay and we can yeah we can discuss that well after charge yep okay moving on sorry just to make sure we we at least give other folks the opportunity to speak uh [Applause] green lucid was the github handle i'm not sure who that maps to on the call uh but wanted to discuss get feedback on eip 5022 which increases the cost for s-store when you go from a zero to non-zero value um are you on the call we're induced once twice okay i will post uh their issue in the chat here if people want to chime in and eat magicians um one thing i did mention so that the issues phrased for like shanghai inclusion i i reiterated that we've kind of paused this decisions there but then they said they would just like to get technical feedback on the eip um so yeah folks who are interested can have a look there and then last up uh we had uh i can't even pronounce this this handle belf uh hopefully i got it right uh oh well perfect walk us through your presentation we can't hear you yeah yeah hi uh my name is zion joe or victor and then a quick presentation for the question early feedback wanted for the team so basically the proposal is to get a expiration in the payload and uh one question one value available feedback i got from uh mikkel is uh the potential denier of us attack if exposed to basic someone is possible to throw a very quick soon-to-expire transaction and get uh get a propagate over the network and cause a denial of service attack now my question for the group i know they're very what does this expire by it is expired by is a block number that's uh like i'm proposed that we add a new um a field in the payload for a transaction and for that block to be valid all transactions has to not expire so expired by is a block number requirement yeah and then so if that's a block number is 100 and then uh someone throws in a transaction within 101 with a high transaction fee and so it is possible that it give propagate over the network but uh then soon too expired and then within 101 and 102 didn't get uh executed at all and thro and could that cause a deny of service attack that's the first question and uh so i put a bunch of question here first of all um is that really a problem um because for me it's like it's very natural that some of the uh some of transactions become invalid in the network uh for various reasons um and and expired by is just one of the reasons it comes not invalid and so the argument was that attacker can have very low cost to generate a crossed network attack by have a low expired by number specified but for me uh my first under uh my my argument is that it seems like if they want to attack there's also risking some fees and so that's one thing and the second thing is that uh i have some network layers of a proposal and uh my question to the implementer of clients is uh to the client authors is that whether not nodes are incentivized to adopt a counter eos approach at all i i believe they are but they don't made a an e proposal about expired transactions and i know this because i also made one uh like a year after and had forgotten that he had made one so there are at least two previous attempts on this um i don't think there's anything like dramatically uh preventing this like from a node implemented point of view saying that oh we we really cannot do this because then we get lost yeah mike may want to i just think this has not been picked up because there have always been other stuff um more interesting more interesting modifications from transactions that have been on the table and this has kind of been seen as nice to have um i'm surprised you're here to say that martin because i could have sworn you were the person that argued uh fairly strongly that um dust vectors from expiring transactions were a problem because someone can expand the network and be confident that they and not have to pay for it and be confident that they won't have to pay for it if they can avoid getting included within you know inbox no uh i don't think i meant that so there are other transaction types which i rejected because for that reason for some of the batch ones uh where you can um do this kind of thing but for expiring ones i mean we already have right now the case where there there are like big activities thousands of people sending in transactions but instead of them being expired and can be rejected and flushed out they just have to slow through the system uh in like days after this big event and they will fail they cost a little bit but they just hook the bandwidth so yeah yeah i think it would be nice to have inspired i agree that uh transactions are super useful and um i would love to figure out a way to get them in my concern which i thought was actually your concern but i will say it as mine since apparently i was wrong there is that um currently if you submit a transaction you have no way to purge it from the mempool and there are some people out there who have insanely large mempools and can store basically everything forever and so if you force the network to propagate your transaction you are nearly guaranteed you will eventually have to pay for that transaction like it is it is never free like you will have to pay for that or some other transaction replaces it later but that's going to have you know that 12.5 increase and so there's a very limited amount so given an account or a set of accounts that have just enough gas for one transaction each um you basically can spam you know once maybe twice and then the fees start getting too expensive whereas expiring transactions you can spam quite a bit if you're really good at throwing transactions in the pool that are very unlikely to mine but the nodes can always choose to not if you see that this will will expire in five seconds it can just stop relaying it sure but i mean you could just have a thousand accounts that each have enough gas for one transaction and uh they expire in five minutes or ten minutes or something like that and i mean if you're good with a base fee you can you know look at base fee history and you can do a little bit of math and figure that you know it's unlikely the base fee is going to drop you know because this is a monday afternoon and monday afternoons it never drops below 20 or whatever so i just set to 19 or something so sorry uh yeah we're already a bit over time and um so i guess if what's the best place for people to comment uh do you mind sharing that in the chat as well um yeah the best way is to share on the uh uh the um yeah is magicians which is also appear on vip um discussion too as usual okay awesome and one thing i'll highlight from the chat uh like client had two comments about like uh 43 37 and 3074s being ways you could also support this feature basically um so it's probably worth to look at those and and um yeah and and uh yeah see if they're like a good replacement because like martin was saying you know even if there are no dos concerns there's still like a high chance that um there's just higher priority eips that end up taking most of the the work and uh 4337 specifically is not the corey ip so it means that basically clients can implement it and um and and not require changes to the consensus protocol and i'm pretty sure nethermine already has support uh for this in at least one project um i think yeah that actually answered a good question of mine which is whether we need a uh a new uh transaction type or can we use to reuse the existing transaction tag and append a new one and it seems like if people want backward compatibility it has to be a new one so that some of them if they don't want to adopt it sooner then they can just avoid like avoid seeing it before using it yeah and and yeah i would recommend uh micah if you want to share your eip number yours was basically that if i remember correctly it was like a new transaction type with an expiring transaction so that might be helpful to look at as well um 27 a little um we're already over time uh so uh yeah i guess we'll wrap this up um yeah thank you for the presentation as well this is the the higher budget quality uh ufc presentations that we had um and yeah thanks everyone yeah thanks everyone for joining uh i've posted the ttd value in the awkward devs chat um so we can use that for releases on robston and uh i guess we'll we'll expect to put a blog post together uh sometime in the next two weeks um and yeah and then we'll figure out all the stuff about the beacon chains for test nets on the consensus layer calls if it's not already uh done before then um yeah thanks everyone thanks thank you thank you thank you [Music] [Music] so 