[Music] [Music] [Music] thank [Music] [Music] [Music] so [Music] [Applause] [Music] so [Music] [Music] [Music] so [Music] okay welcome here is the agenda if you're on youtube and you can hear us let us know great so we'll go ahead and get started with kiln office hours as we've done in the past many meetings um perry can you get us started with um test net topics and then uh mikhail you could tell us about kiln v2 and we can have open discussion from there sure um so merge.net 2 was launched late last week we should have all the client teams in now i think bazel is still doing internal testing but um yeah they should be done relatively soon um we're seeing something like 99.7 participation rate i think that's even just a rounding error from the beacon chain part or probably as high as it goes um marius raised a point however that by only seeing eighty percent sync high cricket participation um and it's relatively stable at that number so it could be that some clients aren't partaking um not sure why maybe some time teams can look into their notes and let us know if we need to change some conflict it definitely sounds like a uh because it's so stable it sounds like a particular set of validators that we could probably very easily see that set probably yeah um yeah just need to dig into that issue yet um i think that's about it from the test net updates i'd like to i don't know if you want to talk about kin v2 first or talk about the public can test net which order do we want to go on um public kiln would be the iteration of the devnets that turn into the test net yes um so i'd like to maybe in chat if all the client teams can just type in if you guys feel you feel that you're ready or if you need some more time in general i'm thinking about launching the test net on like the beginning of next week maybe tuesday if that works for everyone we got at least one not ready in that in the chat just to clarify this would be uh kiln b1 not killing v2 so you need to have kiln v1 spec implemented which is the same as much.net 4. the plan there is to make it a more public thing but to still do a kiln v2 test net or to migrate this over to v2 i was thinking that we just do a migration later once everyone's ready so that we don't have to rush it but we still have a newer test that people can start deploying things to [Music] you and then you're a persistent one the kiln one right exactly exactly um but yeah there's two ways of going at it either we wait for everyone to to get ready with v2 and then we launch the public test net directly with v2 or we launch it we won an upgraded mid cycle mikhail can you go ahead and talk about uh kiln v2 and anything that sure is coming out of that that might make that difficult or not yeah so trying to um trying to understand whether the upgrade is like it's gonna be smooth or not okay so for v2 we have like two things uh in general um like two major things the first one is authentication um and another one is this new exchange transition configuration um endpoints other than that we have renamed a random code to prefrontal and there are a couple of related prs to engine api and consensus text so they're just basically renaming uh the stuff um the field from random to pre-render to reflect this change in the a in the eip um so so that that's one of because that makes it into the engine api so that actually when upgrading would have to be handled with care and handled on both sides of a client combo uh whereas most of the other things could be handed handled probably transparently right so yeah authentication as we decided to to to keep an authenticated port for a while so it should be smooth uh then this new ping functionality is also like not not a requirement for the general use cases of engine api so it's just on top of that it can be uh like enabled um at any point in time when el client supports so cl clients start to support it widely yeah but this renaming probably the one thing that is not backward compatible and so if we were to move forward um and just wanted to be on the safe side getting a renaming done before we move forward might remove some of the other headaches we might have in the future but it does look like in the chat we have a lot of readies and what i interpreted as a not ready was maybe just an exclamation point of excitement yes super excited yeah sorry i read that as not yeah um i already like we we also started implementing v2 and should be good with it so we we tested jwt uh support and that was fine and i added a new method um but i still need to test it right is um when people say they're ready does that mean they're ready with authentication what's the state of authentication um tech is ready for v2 including authentication and we also deal with backward compatibility in just an option by command line so transitioning between b2 b1 and v2 will be simply restarted with a different option there and yeah that's for deals for a table first of all we have authentication implemented but we need to test it still so yeah load style is uh load storage is ready uh for jwt earth as well our authentication is working in ci with geth basically our cis has a test for working well with yep and that might we implemented exchange transition and one of our team member tested authentication with loadstar and it is working fine fine however we need to do some changes in authentication code and add web socket support so it so i see a bit of a range on the on the authentication being ready um but very close is there would be a tangible difference in doing monday versus wednesday any opinion here are we all just ready let's do monday okay will this renaming be ready by basically we what what should be done is just rename in the structure that is used for engine api communication on both sides i guess um uh inner consensus layer and even maybe like not related it's not it's not going to be backwards and compatible for the communication between clients right you can technically name that whatever you want yeah is is that renaming of random to randall done on the engine api we haven't done the renaming it last yeah we did we did it and we actually internally work with always the latest names but we we change at runtime only the api's naming to be backward compatible with we need to behave the old way so we we all in the rest api for instance we expose uh prevrondao always but in the engine api we use random for v1 and kitsuki yeah we haven't done the renaming yet but it shouldn't take too long to do that okay so we're probably a bit mixed on the name which the name will break things on the engine api uh if we do this tuesday or wednesday can we all be conforming on that name would be fine for lighthouse we'll we'll probably stop supporting kimsugi because we don't really have the ability to swap the api names based on test nets which i think is okay uh so sorry we're renaming parts of the engine api right is this in v2 [Music] this is in a pr that was noted in v2 as of yesterday i believe mikhail yep it's it's in v2 it's in the change set okay so it's it yeah it's also included in the latest release of engine api so it's now in the release before that it was like a standalone pr on top of the release so anyway it's it's in this pack and it's very tiny yes i thought but i thought uh perry said we wanted to do i said i thought uh perry said we wanted to target v1 for the for merge for kill no going to do v2 um d2 other than this name change can be kind of done over time because of the way that the uh the api port has the old one so this is the only thing that would make v1 and v2s not be able to talk to each other so i would suggest that everyone just does the name change now because otherwise we're going to have a headache name changes at this point are headaches but that api or that eip around random had the name change so it was best to probably ripple it everywhere okay so i think tuesday with name change rather than monday with uncertainty around name change or wednesday if that's what people need i think that should work on monday i can just reach out to everyone and maybe just collect some information so we know if we're ready by tuesday uh worst case we delete wednesday i'll try and get the configs out on monday as well so in case anyone's doing a last minute release they can just include the config in to make it easier to run clients and besides that does anyone else want to run validators genesis by the details if you do then please reach out otherwise we just follow the same principle as previous times i just keep some validator keys aside for testing but also basically the validator load would be handled by the ef sounds good so perry in your estimation what are the chances that as this upgrades to v2 this is what we stand up and and tell you know via blog post and otherwise for people to come test and join that's the intention here um yeah i guess we repeat everything we've done for kinsugi in terms of outreach so we get all the tooling up update all the joining documents and ask people to redeploy their contracts and and test on kiln i guess so what would be really nice would like would be to have a longer period of proof of work before uh the actual match yes i was thinking of just setting the difficulty like a hundred times more than what we've done it so far so rather than it being an evening it'll probably take a few days that's great and we can always like spin up the old mining rig exactly we can spin up more mining rig if you feel like it's too high great very exciting andrew yeah so i'd like to clarify so we all agree that we do the v2 renaming right in the test yes and okay that's my first question that's fine and the second question what about the ports because i'm very confused about the which port should be authenticated and which port should not be authenticated can can we clarify that i agree on the ports yeah mikko what's the latest on that and i'll pull up the pr to take a look as well i believe there are two ports and one is off and one is not off yeah so basically yeah let me check um so was 8550 right on an authenticated one right yeah and then our authentication we have this i don't know 85 51 right so that's probably like i don't know how it's implemented by your client clients but i think it's reasonable port numbers as they are specified in the spec so we'll just have this authentication port and yeah then we'll just decide which one to remove um yeah hopefully it would make sense to remove the the one i think it's it's not what get get has implemented right yes or is it could you confirm what what or like what what's the plan uh so what we've implemented is off on eight five five zero uh respectively eight five five one for uh ws for web sockets and uh well the other one you can choose uh where you want to put it um but we also want to make the like we want to make both calls configurable so you can run multiple nodes on your machine and but that's not implemented yet um do you have enough unauthenticated ports right now supported in get uh no we have the engine so so we have we have no unauthenticated version of the engine api oh you only have to authenticate one okay because the the spec martin wrote i believe has an auth on 8550 and auth on a551 obviously those are configurable you can move them around but to allow for backwards compatibility in the transition but that is not the case in guess in the implementation no okay can you still hit the f endpoints on the authenticated uh endpoint the port i'm not sure i don't i'm i don't know i have to look it up but we provide the unauthenticated the s endpoints on the authenticated port like this we use the fn points for getting forgetting blocks so if we presently we assume that we can get the engine nf endpoints on the same port if we need to spread those across auth and auth ports it might be a bit more working around probably a bit more work for the user as well in terms of specifying different endpoints yeah yeah i'm not sure it might we might also provide the s endpoint on on on the authenticated button like i have to look at the code yeah once again i think it makes sense for real clients to follow this vacuum use the numbers from the stack where as good defaults for sure i mean overwriting is one thing okay so andrew that the spec is in a one state guth is in a slightly different state but a configurable state um that's that's where it stands uh okay so we'll probably for the test probably just maybe enable one non-authenticated port which will be 8550 and then we'll like add authentication later yeah i think that's a reasonable path by the way is any cl client yet not supporting authentication what was the question sorry who is who not supporting yeah who's not supporting from cl clients which clients when i was we're not supporting autism okay again i guess that yeah sure okay um maybe as we approach the weekend we'll just throw a table up that has some of these you know decisions or readiness just so that perry can gather the information to reduce the load and us not have to go back and forth on the call who has this who has that because that'll also probably change very soon by the way we have milestones if we we might want to add v2 as a milestone yeah is it not in there oh yes it's that so let me check yeah yeah yeah it's it's here and checkmate okay cool um yeah these milestones still exist i don't think everyone's using it but it does help with visibility especially for perry and others configuring things yeah i mean yeah it could be a source of redness okay um perry thank you thank you thank you uh for coordinating the upcoming test net please work with perry if he knocks on your door are there anything else related to the testnet discussion as we prepare this week um mikhail is there anything else on v2 or anything else you'd like to just discuss with respect to the the spec um yeah uh not related to kiln but related to beacon apis or we'll rewrite this later i mean checking just wanted uh to check with the state of this um optimistic flag status yeah uh paul do you have an update on that one uh yeah so i think the i need to fix some ci failures in my end but i think teku has made an issue indicating they're going to go ahead with it we're going to go ahead with it we haven't implemented it yet um yeah that's that's pretty much it i'm not sure if we have buy-in from anyone else yet but i think it's kind of at the stage where no one's objecting to it so i think that that means it's gonna happen got it uh i just have the minor point we checked uh the thing about the v2 versus v1 uh we checked the current client and we're actually strict on not allowing fields in there so v2 would be slightly more user-friendly to support um gonna be a lot i mean yeah it kind of raises the question whether we should be ignoring what we consider to be an important security flag and if it's not an important security flag then why is it there right i mean semantically we are changing the meaning of the message let's put it this way should we talk about it on the pr yeah i'm fine okay uh jump in there v1 v2 discussion to be had mikhail and there's also an open pr to help better define the requisite eth endpoints that need to be served over the execution um the engine api right and that that'll probably come soon and that would be not a change but just a clarification yeah yeah that's that's not gonna reflect that's not that's not require requiring engineering i guess yeah also there is a small clarification on this exchange transition configuration stuff so but it's not it doesn't affect semantics it's just the same that cl may not send this transition block number because it doesn't have this configuration setting so that's basically it by the way on the beacon apis i guess uh every sale client has updated structures and the these structures are included in execution payload right now but and we we need to reflect this in in this back right in the beginning of the eye spec or is it already there i'm not up to date on that update does anybody know okay all right um we can circle back and take a look at that yeah let's move on uh testing discussion kurtosis which uh presented on all core devs on friday about the like simulation automation framework that they've been working on to help with testing the merge they're going to have a breakout tomorrow at 14 utc so at the same time as this call but on friday and they're gonna help people better understand what the tool can do how you might think about using it for testing uh your client maybe doing some ci integration that kind of stuff if you can send somebody who's working on testing on your side i think it'd be valuable it does maybe some things like hive but it also has its own special stuff it can handle so come check it out any other testing items people want to discuss today are we planning on shadow forking gourley with kiln v2 once that kind of gets ready yeah that's a plan we'd probably make it a bit semi-public and people can use that for sync testing if they want right it might be useful also for people that want to test it's pre-merged configurations you know for example in bureau testing that the endpoint to see it you know if the clients are configured properly and that kind of stuff if anyone has ideas for some automated tests we can run on shadow fork and please to contact me mario someone um we would like some ideas good any other things related to testing that people won't discuss in the call okay anything else related to the merge that people want to discuss on the call just to mention that uh as i as i said in this call we will be evaluating the clients um uh on on the new on the kiln network and uh i have already discussed with uh parity to know what are their main uh you know most interesting benchmarking points and we'll be contacting uh you know all the client demons for questions or to try to understand uh behaviors that we might find strange or something like that yeah are you testing local clients performance or you're testing more network performance uh local client performance got it thank you leo okay um let's move on from the merge are there any other client updates people want to share today uh there is one update i'd quickly share about nimbus [Music] so we managed to implement both the client and server for light client sync which is pretty exciting um there's a pr open there's a number of pr litecoin vrs open so take a look at those um it's a little bit wonky of course the way it works is that you uh you do the light cleansing dance but you don't have a state so what you do next is that you download the state via rest and then you can verify that that state corresponds to whatever you arrived to as head with the light cleansing so basically it takes the trusted part out of um out of the rest api so you can just don't use the rest api to download anything and then validate it afterwards how do you bootstrap nifty actually the like client committee though trustlessly um that's a good question um i didn't really check that part so i'm not qualified to answer it right what what what it does basically is that it replays the entire history of the chain oh no the weak subjectivities in history of the chain and creates light client updates um that can be distributed via b2p and then there are requests to fetch these uh like lan updates um so you request them from anybody on the network really but right now only members obviously um then you process those and you arrive at a finalized uh checkpoint and then that finalize checkpoint can be used to verify whatever you download from anyone else but i'm not 100 sure on the details so i don't want to be speaking out of turn cool okay um an update on spec stuff is that we're very actively talking about uh the different designs for withdrawals one of the big questions would be push versus pull within the execution layer and then then once you decide between one of the or others there's a number of other design considerations um it was interpreted that poll was the only viable route in the execution layer due to the specification of the xerox zero one withdrawal credentials which said pretty clearly that code execution would happen or would be able to happen when the um withdrawal landed which would then entail gas and potential failures and other things like that which can only really be handled in the same way via pull but we did do an analysis of the existing oxo one withdrawal credentials on mainnet and didn't find anything today that is is breaking if there's that assumes this this code execution um thus both push and pull are on the table and there's a bit of favoring of push push that would just do a database update kind of like coinbase rather than the triggering of code so both are under discussion um i'm doing two sample pr's on the consensus layer both push and pull um and we'll continue to update y'all there i have a small comment on that i think push is really if we have this logic where we find that this withdrawals that are uh included in the execution payload are valid if we do this on the consensus layer side um it will be just you know up to uh for el clients it will be better of opening up the balance um of a certain address and doing it in a cycle so it's not like a huge yeah complexity also uh one thing that's probably worth considering here is that we could we could discern uh withdrawal operation from application via transactions so it will be just another list in the execution block uh probably ohmers could be used for this purpose so um best to consider yeah i mean i think the the path would be to instead define a special transaction type and some rules around it and using that to pass it in the body rather than putting in the ohmers but passing it yeah passing it and doing the validation that they are correct and that the exact number that you want in there are correct can be done on the consensus layer um you mean you mean including them in the same list of transactions correct but having some validation rules like they must be at the header the head only you know call them type 10 transactions only in the consensus layer you could put them in in ssd so the consensus layer can validate that they are in fact correct and that those are the only type 10 transactions in the block um yeah yeah like the more complex implementation on the outside would be to verify um uh the proof uh link it to the pick and block root this this is this if we want less couple less coupling between yellow and cl but probably if we want this in the future we can do this in the future i mean this last coupling yeah i i where my intuition is if we're going to go with push that this isn't even that bad of a coupling it's just a additional consensus layer rule where things are dequeued uh from the queue and it's ensured that they're properly inserted into the into the block uh but there's some open questions around transactions in the execution payload and how they're typed with the union or not protocol there is also an option between push and pull where which is effectively used to update some type of system contracts minting the if further withdrawals and possibly updating some type of route of the withdrawal receipts but not necessarily directly executing the withdrawals it can still complete with the pool and that way we avoid the complexity of having to to do this minting and these other things outside of a transaction um i'm not sure i followed but yeah you you could update a system contract and then people could pull the ether out of it uh but at that point why not instead update the end balances rather than kind of and rather than just also allow the the best design which basically avoids the risk of a transaction failing than withdrawing to a construct yeah so you you push the eth into a staged place and then people can pull it out i mean that's essentially what any pole design looks like great which is exposing something in the evm that people can pull out of which can be a root or could be a more sophisticated construction anyway we're gonna have a series of some stuff to engage with uh prs and proto eips and stuff to chat about yes i can share screen if that helps um okay if you want yeah uh cool so um i just shared it in the chat um aditya and i we have been uh working on um i mean i i already gave an earlier presentation and ultimos but we now i think hashed out a a good version of the safeblock confirmation rule that we're um quite confident in um and uh and i think like uh yeah i can see that is um um and um yeah we would like to share it especially to um to get some feedback on on the implementation from the client side um we we think that uh most of the things are easy to implement and largely based on things we already have but we should uh see if maybe that's not true and if we need uh to do anything about that okay so um as a reminder so we have we we want to introduce uh this rule that um we uh as the latest um what's currently the latest block in the execution engine we don't expose like the very tip of the fork choice rule but we expose what's called a safe head and that's a block that um we reasonably expect expect will not be reorged if yeah even on that and a normal attack scenarios um and the reason for that is that um the the tip might not might be extremely unsafe the way um that ghost works now because um a proposer can balance their block they can propose it at a time where 50 of our testers see it and 50 don'ts and there are several similar attacks that are based on similar things and so um that makes the tip potentially more untrustworthy than it is even in proof of work right now um [Music] and um [Music] this but this can easily be fixed because we actually have all the information to know whether such an attack is taking place and so we can easily secure clients from ever trusting statute and that's a very useful property for many things so that's both very good for for users that will have a safe way of knowing whether the transaction was confirmed within eight seconds only of like the block being um [Music] proposed so that's not a long time at all um and that's also a great advantage for anyone who's doing bot or mav stuff because they want to know if the next block actually is going to be secure and because otherwise they run in the risk that their own block will be re-org and they might lose the mav and there someone else might exploit it and so on um okay so the way it works you basically make an assumption that the adversary controls less than fifty percent of the stake while that's uncontroversial um the major one is that we assume that the network is synchronous and the maximum delay is less than four seconds so that's the major assumption that is behind uh coming up with such rule clearly if you don't have a synchronous network then then no block without an ffg confirmation can ever be safe and we further assume that the adversary is willing to get b validator slashed um or b the stake of b validators yeah so that's the amount of stake that is uh that like the that's not the total amount of the penalty but the total amount of stake that is involved in a slashing okay synchronous means um all messages are seen by all validators within four seconds so that means if i say in aggregate attestation then i assume after four seconds the whole network will have seen it okay so um there's some notation here so uh then how should we do this edit here um i think let's uh leave the reading for async stuff and we can just skip to what the end formula looks like and the algorithm to compute this because that's more um that's why we need input from class but we probably have to introduce the vb things right yeah okay okay so let's go to the okay so basically we introduced this um this vbi notation so if you see the green block there that's that's b and v b counts votes that are in support of this block or the 12 well the chain of this block um okay and so how does this work so um the way uh the the index is um at which for um so is is indexing the chain of b or yeah um so if it's zero for example that would be would be the um the genesis and t is the height of b itself and capital t is is the latest block and it should only count votes that are in support of b in some sense and what that means is that if it's a descendant of of b then we want to count all the votes because all these votes even if they are not on the currently um winning chain do support b they will fix b um and uh and will make it harder to reorg b itself however if we look at the answers of b then this or n b then the height of b itself then it's slightly different because any anything that's a vote here and that is not directly a vote for a block like directly a vote for an ancestor of b um can actually be used to reorg b out of the um fork choice and so we don't want to count these so that's why the the orange blocks here um they shouldn't the votes for these shouldn't be counted even though they do support say the height zero and one um and so if you evaluate there are two examples see if you evaluate v b zero um you actually sum all the votes um so to reply to mika they are absolute i think they are staked the way we designed it right so they would be the steak um uh so the um so if you want to evaluate vb0 you basically sum everything except the orange one so that's the support at the origin for the chain that includes b um but some of these will will not like will not be votes for b itself but just votes for ancestors of b and we'll come later to why that is important why we need to count this and then there is vbt which is the other one that's important that's that are all the votes at height small t um and and these count that that's basically just the fork choice rate um of b in this case so that would count the votes for b and the votes for all the children and children's children and so on of being cool uh okay let's go down to the algorithm so uh wait where do we have the formula itself the unsimplified i did formula can you scroll to that maybe that's above ah here yeah so basically in order to compute whether a block is a safehead um you need to evaluate this formula and to clarify this is iterative so b is o is a safe head if this formula holds at b and the parent of b is a safe hat so you have to evaluate it from the latest justified block uh you have to do it like for every block you have to ask is this a safe hat you have to evaluate this formula and if true then you can continue to its chart and so what you do is you have v b t um that that's the all the support for the block b um plus v b zero so that's all the support all the everything that's in support of the chain of b at genesis or actually it would be at the latest justified block and then you have t minus t plus one so that's basically counting the number of blocks after [Music] after t and times w is the committee size so that's the total potential votes that you could have at the height uh minus wp that's the proposal boost and minus b that's the total amount that the validator is willing to set the attack as willing to get slashed um so that's the formula um it's maybe rdt maybe stay there for now so i guess um the the vbt we already have that that's the actual vote that's the normal stake rate so that should be easy to get for any client uh vb0 is the one so the reason we need vb0 is um the these this uh this counts the number of votes that um [Music] that aren't directly voting for b but also can't be used to to reorg b so the way this whole formula works is think about what is the best possible chain that an attacker can construct using all the missing votes and and the votes that are somehow in support of the chain of b however are not directly voting for b they they are important because they can't can at least not be used to attack um attack b so that's why this number is important however it's not currently available in clients as far as i know so so we came up with a way of potentially computing this without too many changes and too much effort so we have this algorithm here that goes into the details on how all these are computed and so the thing about vb0 um i think the best way we came up with for this is that um actually most of vb0 can be approximated by just taking vb t minus one that that counts all the votes that are 16 seconds like at most 16 seconds late and that's probably in in reality it's most people who uh who are not um on the very latest tip will have missed at most one block so that's a pretty good approximation and uh and to be clear that makes it strictly safer so you if you uh the this will only have um false false negatives in a way so it will it will never i think we made a mistake somewhere so we be t minus one should only count votes from committees in these slots so the proto-ia thing would not do this it would count votes from the slot t minus one also um but yeah i can just describe the problem so we we want to get so i'm asking is be safe or not and i want to know how many votes from the committees and slots t small t all the way up to the tip how many votes from committees in these slots vote for anything that's an ancestor of b so direct ancestor these orange votes don't come um and i think a good approximation for this is you only see how many votes from committees from slot p to capital t vote for the block before b because unless there's crazy latency going on the committees um from block b slot or higher are not going to work for some like high ancestor of b they'll probably vote for just the parent of b and so we need to extract this from proto-array somehow maybe cache some values i'm not sure how to do this we need your input here so point being is there's engineering questions around if this algorithm can be officially implemented using the data that's already in proto-array right and are those questions succinctly written down somewhere in this document yeah this uh should be covering the questions but i'll also make it explicit i'll edit it to ask the questions more clearly okay cool i would share the document and then maybe contact one or two client team directly with the question and see if it can be tractively solved and then formulate how to solve it from there is that a reasonable strategy yeah that makes sense i'm um paul here i'm happy to help with um this one as well it's 2am here though so i'm pretty slow so it won't be helpful until tomorrow okay there's also a second question that we should maybe mention so just so that we have them all listed on the justification um yeah so just for to check just a checkpoint block is safe you not only need to do this um so what we described here is basically lmd accounting we are asking if there is any world where lmd votes for competitors of b outweigh the support for b um for checkpoint blocks which are in the chain of b you need to do something special because not only do lmd votes flatter but also the ffg ones so you can get rug pulled on what your best justified checkpoint is and then the lmd votes don't really matter anymore so the way to do this is every checkpoint block in b's chain so every checkpoint block that's an ancestor of b you check that it got one third plus the attacker's fraction of ffg votes if that's the case because of the quorum intersection argument no other checkpoint at that height is going to get justified so that's a necessary and sufficient condition and this also requires some special accounting in the clients all right so this quote requires for every checkpoint block for every epoch sense justification that there's a a cumulative vote count that is accessible right hey and the keyboard count to be clear it's right there okay so do the clients cache this somehow anyways i believe that clients when they're in epoch n keep many of them keep some sort of like pre-compute about or at least cash once they've called it once about the running justification or the the running you know total participation uh from a source target standpoint for that epoch but i i don't know if after epoch and or after epoch n plus one if that's still available i see yep so um in the ideal case if the computations are already happening we can just push them in memory and take the hit there yeah let's uh circle back with paul in the next 24 hours with some concrete questions pulled out of this thing exactly but we do cache every finalized and justified checkpoint until finalization happens so for all yeah this will be before justification we are asking if it has a little more than one third support so basically a running count of the current support of any ffg checkpoint after the current justified one after meaning more recently in time yes which usually is an epoch but can be arbitrary depth and then the question is can you easily get that information not sure sorry yeah yeah i mean i make the claim that during epoch n or at the end of epoch n in in plus one the information is known and so if you don't justify that could be stored if it was not and then you can run this algorithm but so it's not a as there's not a massive technical complexity here but it you know it might not just come off the shelf for free if the data structure isn't isn't storing that information which i don't necessarily see why it would well i think the problem here is that we we actually for justification we use the state transition we don't count the running boats like to decide that hey when we we basically look at the head and then we count whatever was included there more or less it's not exactly right right but uh but the so that logic internally does a vote count right so do you do that just online do you then just count the votes or do you have that number cached somewhere like the state transition logic right now the way it's specified it just counts the votes but is that how it actually does it or does do you catch that that's the way it actually does it okay yeah i think in most clients there's a call you know get you know the attester count for some target uh and that call is cached meaning once they call it once it's you can call it over and over again at constant time but the i don't know if there's like a running total throughout that epoch um i mean that cash would then be dropped you know once you move into a later epoch probably one potential way to implement this it is to simply cache this number when you call that function and then just store that number and don't even worry about updating it because likely it's not going to increase much anyway and um this is probably fine like again that would be an optimization which makes it strictly safer like is less likely to return a safe hat but i would say that would be um well i don't even know if it's strictly less just because on on the epoch transition of n plus one if you then know you then know the max on that chain that you're going to see for n i guess but you could see other chains that would potentially increase it but yeah during that state transition you're probably seeing the max the general max yeah so it is a little bit i see but that's fine i mean i i think i would be perfectly happy if if um just doing that that state transition call where you count the tally of i think the previous and current epoch if you just store those numbers and just use those forever for that ebook all right this is a very it's a very tractable problem it's just it's still a matter of like exactly where in the engineering you grab it what exists today and that kind of stuff um i guess i have actually i noticed there is another question here that we maybe um uh skipped over a little bit so i think in order to make this work the or does what we call blocks here are actually have to include empty empty slots so you have to evaluate the set empty slots as well i guess that would be another question if that is doable for clients right now i believe proto-array constructions are generally just the block chain and are not doing anything with empty slots is that correct right i see yep okay let's take this into discussion over the next few days out of the call thank you i ditch it okay um any other [Music] discussion points research spec otherwise anything at all this past weekend with the if denver crowd we have prepared a prototype of the data blob transactions this overlaps above the consensus layer as well as the execution there we're preparing an eip and then in the coming weeks this will also involve consensus their work and i will keep you all up to date sweet and there's a is there a document on the work that you can share or is that not in a very good shareable speed state during the or at the end of the day at the end of the act on we did prepare this document outlining the changes of the spec of the execution layer prototype as well as the consensual prototype i'll share that in the chat yeah i think we're good perry we can shut down those paramount notes um well it actually be interesting to see if there were any like weird load things that emerged but uh not not super critical okay the final final reminder kurtosis testing breakout room tomorrow at 14 utc okay thank you talk to you soon let's hope so bye [Music] [Music] [Music] [Music] [Music] [Applause] [Music] so [Music] [Music] [Music] you 