foreign [Music] [Music] [Music] foreign [Music] [Music] foreign [Music] foreign [Music] this is I mean I guess foreign [Music] what's up [Music] [Music] foreign [Music] [Music] [Music] foreign [Music] foreign [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] foreign [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] thank you [Music] [Music] [Music] [Music] thank you [Music] okay good morning um can you all see the screen do should we put the lights down a little bit maybe on the screen foreign so welcome to the workshop it's going to be quite Hands-On uh if you so I was wondering how many people have laptops and they're kind of ready to follow on okay yeah okay so maybe I'll do it live as well and if you want to follow along that'd be great and do it yourself that'll be that'd be good um so the topic of the talk is to look into what an L2 transaction is in the context of arbitrim so there are a range of different l2s but the one we'll use today is arbitrim and the L2 transactions will differ between those but some of the concepts will be um passed between them so yes there's some differences some similarities uh we'll go into some of those um and I'll first give a bit of an introduction about what a roll-up is and that's what I mean by L2 in this in this context um and then we'll go into uh the workshop itself Okay so at a very high level a roll-up is a side chain it's another blockchain but it's connected to some sort of base chain by a validating bridge and if you want to read more about this there's a paper by Patty you sat in the back of a room over there um so you can get more information there um and this is a kind of rough overview of how it works so you've got one blockchain at the top which is the roll up you've got the main blockchain at the bottom which in this case would be ethereum and they're both progressing via State transitions new blocks are being made um there's a bridge contract on the base chain on ethereum and periodically an operator will take the state of the roll up front of the roll-up chain and they'll paste it into that bridge contract that once it's in that bridge contract it can be checked so in an optimistic roll-up case there's a fraud proofs that are used for checking that state and in the case of a ZK roll-up it's just a ZK proof but the other crucial thing is that green blob that I've put inside the the bridge contract and that's data that's associated with the state transition so you on the on the roll-up you need us like a minimum amount of data to be able to recompute the state transitions that are occurring on the on the roll-up so in the case of optimistic Roll-Ups that's going to be the transaction data itself and yeah it just continues in the same way and this would be the case where some data is put on chained the fraud proof is checked and is found to be invalid um yeah so this is a kind of rough life cycle of a L2 transaction so a user would create a transaction they'd submit it to a sequencer who would then be collecting these transactions into a batch when the sequencer has got enough transactions they'll compress this batch using some standard compression algorithm in arbitrum's case this is broadly and then they submit the batch to ethereum so that's this green blob is that batch there yeah and another kind of difference between L1 and L2 transactions is gas so as I've mentioned L1 turns out L2 transactions need to be submitted at some point to the L1 and someone's got to pay for that So eventually that's going to be the user and that that cost is associated with the call data that is required that is consumed by the transaction on L1 and is priced at the price of L1 gas then there's L2 gas which is basically the same as L1 gas the same gas that you know on ethereum but it's at the price of L2 right so this is just the execution of the transaction that's occurring on L2 so you pay first to put the transaction on L1 and then to put and then to execute it on L2 so there's these two different costs and we'll kind of go into that in this Workshop yeah so this is the URL so if you go to this GitHub repo and you can start following down the the set of instructions so there's a set of prerequisites that um include tools like Foundry JQ um and broadly itself um and you can start following the steps yourself or you can watch me do it as I go yeah okay yeah so I've included some useful links at the top there's some rpcs there to connect to both arbitrum and to ethereum and just some other stuff some general information if you want to read more about like L1 L2 gas and uh some of the ways in which arbitrim works that are relevant to this talk yeah so these are the prerequisites um it's just there so you can clone this repo itself we've got curl for making some requests Foundry for using cast cast is a kind of tool for helping you format um ABI style uh functions for calling calling the Json RPC JQ just for formatting some Json and broadly which is the compression algorithm that's used in arbitrimp foreign yeah so there's there's a quick setup stage I've already done this um I'll paste this in yeah just check those there okay so the first step is to we're going to send the transaction on um L2 so I've already sent a transaction which you can use if you want um in your example or feel free to like use your own like metamask connect to arbitrum and send them like a transaction on mainnet at the moment they're reasonably cheap I think so it should cost you only a few cents to do that if you want to but this transaction hash if we look at it on on Arbor scan foreign this is a usdc transfer basically so this is just transferring some tokens and that's the this is what we'll look into today um yeah so I'll set that environment variable and also feel free to like if you've got any questions at any stages as I'm walking through this just stop me put your hand up we don't have to get through all of this today so just you know let's talk about it and if you've got questions you know just put your hand up at any time yeah so first we'll kind of grab a transaction receipt for that and there's two interesting things in this transaction receipt that you might not be used to when uh looking at L2 compared with L1 transactions so this is this L1 block number which is uh the block number that the L2 sees of L1 so it's a kind of like LDL one is it's reading the state from the L1 occasionally and one of those bits of state is the L1 block number you can access this as part of the arbitrary VM and then the other thing is this gas that it used val1 and that's what we're going to look into so this is the amount of gas that was spent uh to send this traction transaction and get it recorded on L1 yeah so we're going to store that in a variable oh yeah okay foreign and I'll just Echo that out so you can see like roughly what it is so it's like 236 000 gas so that seems like a lot when you think about just what it's doing is storing just a bit of data on the L1 but the reason why it seems like a lot is because this is in units of L2 gas so this is this has been scaled for what it would be if it was on L2 and that's just to make the accounting a little bit easier inside the inside of arbitrim so this amount we need to find out what the ratio between the L2 gas and the L1 gas was at the time this transaction was sent to then try and really figure out how much L1 gas was used and from there we can start to figure out as well like how many bytes of data it might have consumed so store some of these variables as well thank you okay yeah so as I mentioned we need to find out this ratio of L2 to L1 gas so the the roll-up is is estimating at any one at any point in time what it thinks the L1 gas price is and it's a little bit more complicated than just reading the L1 base V because there's a time lag between when the sequencer processes a transaction and when it submitted onto the L1 so it does some kind of estimating and it moves moves its price up and down depending on how accurate it's been in the past um to try and make sure that it keeps even um and so there's this uh L1 get L1 base fee um function which is what was really used by the um the Arbitron virtual machine to well by arbitrim sorry to to figure out what what L1 gas prices it should charge and there's a bit more docs here if you're interested in reading about like exactly how that works yeah um and maybe we should go a bit more into that because I realize we're running quite quickly on time because I guess I thought everybody would be following along and there'd be lots of problems but I'm a skilled pro at this so it's going quite quickly um yeah so one interesting thing that happens with that with that estimation is that um you because because the sequencer is having to try and figure out what the price will be when it submits to L2 um it's kind of a it ends up wanting to overcharge to not get out of pocket itself so arbitrim has a slightly different mechanism there where um the sequencer is rewarded later for exactly how much they spent and there's a kind of a pool that sits on L2 and the ball starts quite full and then the difference between what it was uh awarded and what it estimated in the first place is then reduced from the pool or added to the pool if you're overcharged and then this is you this difference between what the pool Target should be and what it actually is is taken as a factor into the future estimate of what the L1 gas price should be um so the sequencer never ends up out of pocket they always get exactly what they paid um but there is some mild fluctuation between what users pay now and what users pay in the future so some users now might receive slightly less than what they like to get a slightly better gas price than what they expected some might get a slightly worse one but overall it's quite quite close to the average quite close to what you should be getting so we'll call that pre-compile at um at the Block Heights so that for this we need an archive node and we're going to call the the pre-compile at the block height when this transaction was sent on L2 and then we'll see what the estimate was at that time yeah absolutely yeah so so you you want to know what the what the estimate was at the time that the transaction was sent so you need to know what the state of the the node was at that time and for that you need an archive node a full node wouldn't be able to do this yeah say again exactly yeah I think I think full nodes do keep some recent uh historical States I can't remember exactly how but probably not a week's worth um yeah so so to do this kind of thing that we're doing now you would need an archive node but this isn't something that you might normally want to do this is just kind of like let's go look at some of the analytics it's not part of like you don't need it to for to send transactions or things like that and there are ways to get estimates for what these values are before you send your transaction as well so you know what you're going to spend you don't have to wait and inspect it afterwards if you want to yeah I think there was someone uh-huh yeah okay thanks um it's not it's not a snapshot it's just well yeah okay you you need you need to know what the state was at that time because this is stored in State this L1 base fee estimate so at a different block height the L1 base for years and will be different and we want to know what it was when this transaction was sent yeah uh yeah so this the sequencer has to pay some costs to put this data on chain and it wants to get refunded for that um so this is this estimate is is in the system it's under like you might say it's under consensus of the of the el2 and the sequencer is forced to use this value in its estimate yeah foreign on both of them yeah but the gas prices are different and they're moving and this is just a wave to try and estimate that movement of gas on L1 okay okay so let's make make the score yeah so this was an estimate of the base fee at the time the L1 base V estimates which is about 8th grade looks like so that's what it thinks it was at the time and we'll store that in a variable so as I mentioned we want to work out this ratio so that we can scale the L1 gas used in from L2 gas units into L1 gas units so that it starts to make sense to us again so we also need to know what the L2 base fee was at that time um and this we can do by just fetching the block at that height and looking at the base fee uh in it which is 0.1 gray so arbitrum has like a minimum um L2 gas price which is 0.1 gray um if if congestion happens then it will go above that but generally it just sits here if it's not if it's not um being used heavily at the time okay so we'll store that as well thank you and now that we have these two ratios we I mean these two um these two uh um gas prices we can use them to calculate the ratio so have I stored this already yeah that was about oops so there's the actual amount of L1 gas that we used at the time so which is a bit more what we kind of expected and if we divide why did we expect that no a bit more like not more than uh it's it's like what we expect yeah uh yes yeah it's a really great question so you we do compression over a full batch rather than individual transactions which does leave you with this problem right how do I know what um my transaction how many bytes it will use in the compressed batch rather than in in in the other amounts so what we do is we it's it's very hard to figure that out and do it fairly because it also depends on ordering and things like this so what we what we do is we compress your individual transaction when we give you an estimate for it and so if your individual transaction is more compressible you'll get a better you'll get a better estimate for it and you'll you'll be charged less but that still isn't quite the perfect scenario but that's the kind of like halfway house that we've arrived at yeah okay and so each unit of um each byte of data on L1 consumes around uh consumes 16 gas uh if it's a non-zero byte so as an estimate we can say that this consumed around like 180 bytes of data um so we can then actually go and take a look and see if that's kind of what it did consume so to do that we'll rlp encode the transaction thank you which it's got I've got an error in my script there I think um this aabcc doesn't look right yeah I was doing a bit of debugging yeah so this script what it does is a high level at a high level is just it it requests uh transaction receipts uh takes the bits out of it which are important for RL for for an actual transaction rlp encodes it and just spits out the result with the zero two prefix which is Type 2 transaction so if we do that again not sure why that's oh yeah thanks there we go thanks for Keisha okay and if we count those bytes let me see it's about the same so we spoke before about uh yep say that again that's all I couldn't quite here yep so ROP is just the format of the transaction that ethereum accepts and then we'll include rlp encoded transactions into a big batch and the batch will then be compressed with a compression algorithm so ROP isn't a compression it's just it's just serialization uh you don't need to you uh yeah because what what you so what runs under the state transition is the full decompression so when what you're when you run the fraud proof you're bisecting on the parts of the state transition so if the decompression is within that state transition then yeah you'll be able to decompress you don't you don't need an implementation of the decompression on L1 you need it on L2 and you need to include it in the state transition yeah um yeah so let's try and explore the batch um there's a uh function on another one of the pre-compiles that you can find in arbitrum to find the batch uh containing a specific block which is this one so we store the block number earlier and we'll use that to look up the batch these pre-compiles by the way are they're kind of like the way in which arbitrim customizes itself compared to ethereum so it needs to do some special things like this um and they've been added as recompiles so they can be found at like different addresses um can find at the top of the files yeah so we use cast again this is a little bit longer wait a minute oh yeah there it is so 974 was the batch number I don't know why I printed some rubbish but oh yeah it's because I copied the there we go um yeah it takes a little bit longer that one because we're doing oh no no that one's not the longer one okay this one might be a bit longer so given the batch number we need to find the transaction that submitted it and we need to look at the call data that was in that transaction because that would be the batch um so we need to find uh the transaction and we do this just by looking up uh the logs that emitted this specific batch number um yeah so this is the transaction ID so if we go to etherscan this is an L1 transaction ID this is the batch itself and if we scroll down and look at oh whoops so it calls this function add sequencer L2 batch from origin and if we look at the original this is all the batch data so it's a large amount of data being submitted in one go yeah all right yeah we can even look at this function in the code so this is the contracts which is called the sequencer inbox and it's where this sequencer submits these batches um and this is the batch data itself so we're going to try and grab that data and decode it and the way that um the way that variable size um arguments in in uh in yeah in the evm are encoded is at the end and we in there as a placeholder for them inserted at this point so we'll find this data at the end of the of the arguments list and given these little fixed size arguments um we can know the exact position in them in that uh in that input which is uh well first we'll download it actually yeah here which is 458 is the is the position yeah and we'll put it into a file so if we open so this is the raw batch data that we downloaded raw is compressed exactly yeah so so yeah this is pulled straight out of the call data and this is what the sequencer inputted so it's compressed yes exactly exactly great question and we'll explore that in step five yeah um yeah so if we open the file we can see that it begins with this zero zero at the start and this is not part of the compression this is just a a type of the data so there are some different instantiations of arbitrim one is called arbitrum one another is called arbitrum Nova and they handle data in different ways so arbitrim1 does this compression it stores all the data on ethereum optimova doesn't it stores its data with an external party that external those external parties sign that they've received it and they put that signature along with like our commitment to that data on chain and this zero zero here just tells us that the type of this data is roll-up data it's arbitrum1 data so we want to remove that before we do the compression I do the decompression sorry so we we take those off and put it into another file and then we just remove those those front two zeros and then this is the uh the commands to decompress the batch so first I'm going to convert it from hex into binary then I'm going to use broadly decompression and then I'm going to convert it back into hex and put it in a file um yeah and it outputs this uh warning because there's some zero bytes at the end which aren't actually relevant to the the compression but get added because of 30 like 256 byte words okay so if we look at that this is the actual batch data and we can look at the size differences now between the the compressed and the decompressed make that a bit bigger so we've got this one which is the uh wait what was it which one compressed which is 198 bytes and then we've got the decompressed one which is 715 so you can see the difference in the ratio there and the the effectiveness of the compression yeah yes exactly yeah you you the if the shared structure between different transactions then they're going to be included into this compression and improve it yeah um this is a bit of a um the compression isn't actually this good because this if we look at this batch data it can it includes a lot of zeros and zeros um are charged at a different um amount in in gas in the evm they're charged at four by I think four bytes uh four four gas per byte rather than 16 for non non-zero bytes and the compressed batch will be almost no zeros in it there'll be they'll be much more like a tenth of the more zeros right rather than oh the 16th sorry yeah um yeah so it's it's not quite as good as it's showing here but it's still quite good you can work it out by like doing some more complex analysis but we won't do that here uh yes we've compared those and then the last thing to do is that our transaction should be in that uncompressed batch so we'll go and try and find that so if we Echo the the rlp I think I had it in raw Maybe let's see where I have it oh foreign so this is our transaction if we go into the batch and there it is so along with a load of other transactions foreign yeah and that's basically it for the workshop so if you've got any more questions yeah yeah you can you can do that yourself as a developer so that on Auburn there's a registry where you can register address against an index and then you can substitute them and arbitrum will know that you've done that and it will then um switch them back out when it comes to execute and in that way the sequence will charge you less for your gas yeah yeah because when when you're compressing um the addresses in in a batch then it does a lot of that for you anyway like so it the two yeah it's one one was like a a legacy system where we would do that we would allow users to do this themselves and now like the whole holistic batch way achieves a better result yeah do you have the second question yeah can everybody hear the questions by the way or should I repeat them yeah sorry yeah no there's not so like optimism Muse said lip I think and we went for broadly the reason was is because we did some analysis of different compression algorithms and we found that probably performed best and I guess they did a similar sort of thing and chose settler for their own reasons um yeah I don't know I don't know how important it is to standardize this specific part of the Roll-Ups because it's it's something that users shouldn't really be interacting with generally um and I think that's the most important part to standardize um but yeah it would be interesting to to see why they chose those that as well yeah sorry I didn't repeat the question he asked if there would be uh if there's any efforts to standardize this compression algorithm across different altitudes yeah registry yes yeah so there's an address registry that you can use you you register and address against an index and then that will be used when upon execution you substitute your indexes into your transaction and then there will be de-substituted from the registry upon execution to reduce the amount of call data that even goes into the batch itself here um it should be immigration investors it doesn't mean so we used to have it in our docs we've just recently revamped them and I'm struggling to find it but we did used to have it there do you know where it might be tricky sure Fred arbitrust friendship address for industry so we've got our address table here which is the yeah so this is like a bit of documentation but I'm sure we had some more documentation about actually how to use this contract in pre-compile didn't we okay maybe we can do this afterwards as well yeah yeah yeah so the the compression the broadly compression was part of nitro exactly yeah it was one of the major parts that produced the cost previously we didn't compress at him yeah um yeah so the question was uh why the hard-coded minimum base fee um I think that's partly just to avoid like us um getting loads of State load early on for very cheap price um given that we may expect users to come on board onto the platform and the gas price not to always sit there it would be good to not the future not to be burdened by that kind of Legacy Behavior yeah yeah yeah so the question was the execution occurs on Layer Two so what's happening on layer one what are we putting there yeah you just store the data such that there's an there's enough data there so that anyone who's observing ethereum can recompute the same train State transitions that are occurring on L2 and that's important so that anybody can can take part in a fraud proof um uh game yeah uh yeah yeah we have two ways of doing it so that I'll open up that contract again uh the question was um uh in the in the contract do you need to admit all of the data that the batch data in an event or can it just be in the call data of the transaction uh yeah so there's that we have two functions for that one is uh submitting it from origin and in this case we know that the that it's being sent from the transaction origin and therefore we know that the call data is going to look like this so if we know that then the L2 can reliably grab data out of the call data if the sequencer is you know going via some other contracts or it's not coming from the transaction origin then we emit the full uh batch data in an event so in production this so this is here if if it were needed but in production it's way more expensive so it's never used where do we not need what sorry yeah so to clarify on what we're doing here we're emitting a sequence number um and what the L2 node will do is it will say okay I've got a new sequence number I'll go look up the the transaction related to that sequence number I'll look inside the call data I'll find the batch basically the same process if we as we've just done and all of that all doing all of that is part of that state transition function so it's all yeah yeah um yeah um yes execution happens online too yeah Penn State is online too as well yes sorry I missed a bit you said it was uh no so the question is does the execution also take place on layer one as as well as on Layer Two and no it doesn't we just put enough data such that anyone who's reading the ethereum can then go away and recompute themselves what would have happened and take part in this fraudproof game because correct exactly yeah yeah you need so so yeah to if you want to know what the state of the L2 chain is you need to replay the history of the chain in the same way that you would replay the history of L1 to figure out what the state of L1 is um yeah so the question is can I find out States about a specific address without recomputing the full State on L2 and the answer is no so the state only exists on L2 and that's only where you can make questions about the state uh yeah I have a question about them yeah so the question is can you sort of game the system uh take advantage of this of this minor fluctuations in L2 gas price to try and achieve a better price for yourself and then the answer is yes yeah you can uh yeah run it's the same way yeah so I think that's that the question that comes down to a little bit around your security assumptions um so in order for the state to in order for you to be confident of ethereum States uh you want a wide range of people to run full nodes such that if an invalid State transition occurs a large number of people can get together and form consensus that that was an invalid State transition that should be a rejected fork and we shouldn't ignore it but with uh roll up this there's a slightly different um safety assumption which is that if any single one person uh notices that there's an invalid State transition then that one person can enforce that the state transition is is corrected so it's you don't need a large number of people necessarily you it's a kind of one of many one of n security assumption rather than like an N of M and so this means that maybe you can afford to have less people actually running the L2 nodes yeah and and so have maybe slightly more beefy machines yeah yes um yeah yeah we can go into it yeah sure so the question is is like how how in practice do fraud proofs work okay yeah so two parties take place in uh a fraudproof game to figure out which of them has chosen the correct state and then one of them wins which is what you what you're asking about and at that point that state is that the losing state is rejected more people can challenge The Winning State if they want to but the losing state is rejected whoever chose to uh take part to defend that side of the state will lose some stake because you have to put at stake to defend a state um and the if no one if no one comes to challenge The Winning State then that will be accepted as the correct State and you'll go on from there no the L2 doesn't deal to so if you're running an L2 node you've got your if you think about a fork occurring on ethereum you've got some people that choose different rules for their node that doesn't mean that you need to stop running your node with the what you see is the correct rules and the same kind of happens on L2 I can run my node and I can see which of those two is going is going to win the challenge because only one of them is correct and I know which one of them is correct so I can continue to accept transactions validate them and we can continue to process them in that time what you can't do during that period is withdraw funds from the system so withdrawals are paused whilst this fraud proof game is taking place because ethereum itself doesn't know which of those two states is going to be correct so the funds stay in the system while it's happening but we can still progress the state as an as an external viewer yeah foreign [Music] yeah so the question is it's like if two two states are in violation of each other is people defending either side um what is the what are we actually challenging where what's the state transition that we're challenging is it the pre is it from the previous state to the current state or is it further back and the answer is it's just the previous assertion yeah foreign proofs take place in the solidity contract uh and yes they do but the way they the way they work is that there is a bisection game that the two parties play we don't want to execute the full State transition again so instead we try to decide which part of the state transition we disagree on so we take the state transition we bisect it into many parts we allow the other person to choose which part they disagree with and which part they agree with and so you always you have you're reducing the size of the state transition always keeping a point that you both agree on and always keeping a point that you both disagree on and making that smaller and smaller and smaller until you get down to a single uh op code and then you execute that single op code up um is the question that within a single state transition they disagree about multiple things or is it that there are multiple people disagreeing about one okay so if there's two two parties but they disagree about multiple things then I'll just be the first disagreement that matters because that's all you need to to slash the person out of the system and remove their their uh statement system yeah uh yes um so I think your question I think is what happens if someone includes an an invalid transaction in in the batch or yeah so so the optimum virtual machine will know what to do if someone gives in an invalid transaction it will ignore it basically so you can then choose to run a different arbitrary virtual machine that would do something weird with that and then we would end up at different states and we would like challenge each other over over the result of that but just including an invalid transaction in the batch isn't enough to like confuse uh an honest validator that something weird has happened or that they've got the wrong state or anything like that there are rules about what to do for every bite that you see in that batch yeah I think sorry there's one at the back first sorry how long do we have left uh these are great questions though so the question is oh sorry we did yeah so the the question is um given that uh during a a fraudproof game withdrawals are paused isn't there an attack you can do on the system to delay and cause problems for everyone else by just creating a challenge and what is the cost of that of creating that challenge um and the answer is dependent upon how high the stake is set um so that's yeah if you have a very high amount of stake then it becomes very costly for you to cause this delay the amount of status stake is set by the system so for in order for you to take part in a challenge you need to put up a certain amount of stake yeah so at the moment the validator list is whitelisted so it's not open to the public so to whatever amount value in there is is not really meaningful but we're working quite hard on trying to make that open and when it is open I can say that it will be quite expensive yeah uh yes if I will become with this challenge now this um malicious I could prove that I was correct so there's a separate so the question is is what if the sequencer is malicious tries to cause an invalid State transition is that a yes right and what happens when someone challenges so there's there's a separation in the system between uh sequencing transactions and generate executing those transactions to create a state to update state so the sequencer has no power over what state will be update what the state will be based on what it puts there the node software does so if the sequencer puts rubbish there the node software like um honest node software will recognize it as rubbish if the sequencer puts valid stuff there then they will process it as valid stuff but the sequencer is all it's doing is putting data onto the chain they don't enforce in any way what the state should be that's a result of that data those are the validator nodes that decide that yeah so given just some data that arrives people run any validator nodes need to decide what the result of that data would be yeah so that kind of answered the question yeah yeah and the nodes will know what to do when they see that so there'll be strict rules about everything that the the batch contains yeah exactly so the question is is like what can this what powers does the sequencer have in the system and the sequencer can choose ordering of of things inside that batch um but they can't manipulate what the output of those transactions will be yeah so you don't you don't trust them in any way for the security of the system the sequencer is necessary for lightness lightness of the system to get transactions moving Fred's like waving his hand over there like on the sequence rubbish but what can they do yeah so at the moment there aren't right so the moment we trust the sequencer to pave well if they don't then we won't be able to use the system properly the funds will still be safe that are in there and there's a secondary backup system which normal users can use so you don't have to go by the sequencer if you don't want to be you don't get the benefits of compression but you can send your transaction yourself or you can find another someone willing to compress stuff for you and put it into uh into the system for you but they they want fundamentally the sequencer is the one who chooses the ordering and you won't be able to do that um we have like a weight a time period where if the sequencer is not actually doing its job at all if it's not updating things or it's not including these what we call delayed messages which are user sent messages via the L1 then after a time period you can force those through regardless of the sequencer so that's the a kind of backstop if you need to exit the system and the sequencer is not allowing you to send transactions yeah but it's not really the validators that are involved in that it's more the users who say okay I don't like the system anymore it's not working for me and I want to just force my way out of it yeah uh yes yeah so that that comes back to uh your your [Music] um your node software right so if you if you can see that this state is correct then if oh sorry yeah yeah so the the question was it's like what how does finality work in the system given that after a fraud proof a certain state will be rejected um so the answer is if you were following that invalid State then you will basically see a reorg probably quite a deep pre-org um but if you were running on a software you won't see and you won't see any problems basically you won't see any difference there'll be no uh change yeah but you can but that does bring into the question what the finality of a transaction is in in there and as you as you pointed out you could get the steep reorg so it depends whether you're running software it depends like whether you're running node software or not you might want to wait just until that week period is off all challenges are over and then just be like okay now it's definitely fine yeah um yeah any more questions uh the question is is there an easy API that I can use to see if there are if the challenges are complete and the answer is that you can look in the smart contracts so you the smart contracts are created and destroyed when challenges exist um so you can see in in the smart contracts all the challenges that are taking place at any one time yes yes it will if you um on if you think that if you if your node software has a bug in it or you've done something malicious with your node software then you'll be following what will know will not be the canonical chain eventually and so you'll see results that will not never happen or or may happen in a different way the transactions will still be replayed so you all the transactions are on L1 so anyone who wants to run on a software can know what the final state will be but if if you're running some sort of like uh mutated software or something like that then yeah you you'd after one week's time you may find that all of the state that you thought existed didn't and you're actually on this other China the question is like like what the question is what happens to me when that challenge ends and and I realized that I was following the the wrong chain is that the question okay so the challenge yeah the challenge ends no one decides to dispute this state transition basically everyone in the world is agreeing on this state transition at this point if they didn't and they would start challenging it okay um I've got to wrap up now but thanks very much for the great questions and uh yeah hey I'll just take this off thank you very much okay foreign [Music] thank you [Music] [Music] [Music] foreign [Music] [Music] [Music] foreign foreign [Music] [Music] foreign [Music] we know okay cool are we good to start yes okay cool um I don't know if this fits in 60 minutes so we will try this now hi I am Emily I am the Truffle developer Advocate today we're going to be talking about building a Dap on optimism specifically talking about how to incorp bridging into your optimism daps just want to give a brief disclaimer I do not work for optimism nor do I represent their opinions however I really love the project truffle and optimism have been doing a hot collab and that is why I'm here today so briefly touching on the agenda I'm just going to give a crash course on l1s and l2s assuming we have beginners in the audience um touch a bit on Bridges go into optimism contracts for bridging specifically and then the best part of the demo uh I guess a live demo maybe with Devcon Bogota Wi-Fi um building adapt together so let's start off optimistic Roll-Ups here's a crash course so for those of you who don't who don't know just brief introduction right what's a layer one what's a layer two layer one ethereum Bitcoin that base layer Layer Two that a separate blockchain that's focused specifically on increasing transaction speed scalability and what's really interesting here as well is utilizing ethereum for data availability so specifically the point of posting transaction data and getting it from ethereum I do want to note one specific thing you might wonder Layer Two specifically are defined by deriving its security from ethereum so if you think about something like a side chain for example they don't so they those are not qualified as a layer two so that is like basically the key caveat you need to think about um so why do I even care about this why am I here uh again if you've been around in the space you've probably heard blockchain trilemma it's a pick two out of three decentralization security and scalability um for those of you who in the ethereum community I hope we have all agreed that decentralization and security is the most important thing right so what happens about scalability well this is something we still really need to care about because scalability right affects gas costs and gas costs is going to affect the adoption of ethereum so this is something we really need to think about and who's here to help us layer twos okay thank you right so definition again of a layer two is to decrease L1 congestion by bundling up transactions and submitting that to ethereum again uh things to note right gets its data availability from ethereum specifically deriving its security from ethereum and helping us maintain that decentralized aspect so next piece we're going to talk about optimistic Roll-Ups because that's what we're focusing on today I am not going to touch on zero knowledge there are so many talks at Bogota about uh zero knowledge so talk to them not me but to briefly touch about optimistic Roll-Ups Roll-Ups again pretty self-explanatory you roll up a bunch of transactions and you submit it and post it once to the L1 again this comes in two primary flavors right now optimistic Roll-Ups as well as zero knowledge to touch upon optimistic Roll-Ups what makes those different is they are optimistic right so when we submit these transactions to ethereum we just assume they are valid and you might say wait that seems kind of bad right well actually there have there's this thing called The Challenge period so essentially during this challenge period uh anybody can come and say like hey I think this is wrong and if they do that they have to submit a fault proof and basically the fault proof basically either validates hey actually it was correct and then it gets submitted to the chain otherwise no actually yeah some Shady person did something and this like transaction is incorrect and so let's backtrack so that's optimistic Roll-Ups uh again the challenge period is the part we need to focus on here right now for mainnet it is seven days which is kind of long which is kind of why people have started thinking about zero knowledge Roll-Ups because that is something that you just post the validity proof for okay so I think that's covered everything in optimistic Roll-Ups in hopefully less than two minutes because that's what I plan for uh so let's talk about bridges now again Bridges I think pretty self-explanatory if you've ever walked on a bridge before um connecting to blockchain ecosystems things to know about bridges right again is this transfer of assets and information so a lot of times we talk about transferring eth tokens but you can also transfer arbitrary data the other piece is you know we're moving towards a multi-chain world um basically the point of that right is to take in the pros of one chain to alleviate the cons so when we're talking about l1s and l2s we're talking about the pros of uh decentralization security of ethereum while alleviating the cons by using an L2 chain for that scalability aspect um the important part with Bridges is it allows us to call an L1 contract function from the L2 and vice versa so if I'm on like optimism contract and I say hey ethereum contract I want to call your function for just say okay we can do that um the typical way of doing this right now is this idea of locking assets so it kind of looks like user one will lock assets in a big bridge contract the equivalent amount of like token will be I guess created on the L2 and then when we want to put it back all of that is burned off and then released for the person on the L1 again big disclaimer there is no bridging standard that exists yet again a lot of research has gotten into this um I think also probably one of the reasons bridges are a little bit unsafe because it's totally a new frontier right so when we talk about unsafe or security right Bridge hacks happen all the freaking time I don't know if you're on crypto Twitter I'm like oh okay cool I mean as of August 2022 right there is a study done basically 60 nine percent I don't know if that was like fake number but um 69 of attacks have been on bridge hacks and then very recently actually like right before I was creating this presentation Finance by a BSC Bridge um rest in peace uh but you did good for my presentation because I got to talk about you on the next slide um but anyways why does this happen again as I had mentioned in that previous uh section about how bridges are typically Run is it locks up liquidity and that is like a prime centralized location for bridge hacks um so something people might also think about when creating Bridges is the idea of decentralized bridges I don't know much too much about it so I'm not going to go into it but you can kind of think about like that is a consideration you need to take and centralization is again a big part of why Bridge hacks are so intense so how do you fix this again disclaimer I have no security expert but number one learn from BSC um so for uh currently the way these Bridges identify and authenticate Target and source blockchains is through its chain ID and the BSC case specifically did not check the chain ID through the cross chain message and again something to think about so obviously if you're building a bridge maybe read up on all your predecessors and do everything they did but better um private Keys again that's something we really care about different ways of handling it Hardware wallet uh you know multi keychain system Etc and then I think something people don't necessarily always think about is there's always that web layer right so the way bridges are surfaced right now is often through a UI right we talk about hardening your smart contract uh maybe one way to also think about how you harden security is at that UI level there's a lot more uh I added a link of like some research that people were doing but you could probably just Google and then like read every single page because it's it's intense guys so anyways yes like I said bridging is hard what are we doing here we're actually going to go over optimism's Bridge contracts they have already written a few contracts as well as provided an SDK for us to do this for a simple use case um again I think it's awesome because basically Bridge contracts probably require a lot of security auditing I am poor I'm not a student anymore but I'm poor I can't do that um so optimism kind of has provided that ability for us to incorporate bridging uh through um battle tested contracts as well as an SDK if you don't want to do any solidity at all so let's actually walk through what optimism has provided so that first thing I talked about was transferring of data um so this is kind of the base level of what it looks like there's two contracts called L1 cross domain messenger L2 cross domain membership again these are pre-deployed by optimism so if you're bridging on optimism you will be interacting with these contracts you can get their addresses from their GitHub repo they will have one for each one for each chain ID so there's an address for Gurley optimism there's an address for Gurley ethereum mainnet Etc kind of diving into this deeper the way this works is essentially we have I'm going to highlight the probably the two most important functions in this interface specifically the first one is send message so that is what allows us to say hey I'm L1 contract but I want to call Contract function on L2 the way this works is uh let's start over I am ethereum contract I am calling L2 contract that's the target address so I'm going to input that in there the second piece is call day data right so if you don't know how basically solidity calls functions right now it's encoded in two bytes specifically by like the function string name as well as the inputs that go into it so in order to call it on the L2 I have to encode that function name and inputs to be passed over to the L2 contract and the gas limit actually complex it seems simple to understand but it's how much you're willing to pay so I'm going to go into the math here specifically posting from L1 to L2 requires gas on the L2 section right in order to do that optimism says we will provide 1.92 million L2 gas for you for free however in the case and this is pretty rare assuming that like maybe you actually need to spend more gas than that you actually would have to specify that ahead of time and that gas is coming from your L1 gas at a 1 to 32 ratio so in this specific example right suppose the transaction actually took 2 million gas on optimism you have 80 000 L2 gas you need to cover which is equivalent to 2500 L1 gas um I hope that made sense if not we can talk about it and I will just say the same thing over until you understand it uh on the other hand we moved from L to L1 this is going to be more expensive because there's two transactions we're posting specifically the L2 fee to post initialize a transaction and then the L1 feed to actually finalize it on the Chain so this is more expensive L1 is significantly more expensive than L2 but that's because scalability wow okay good uh next piece is cross domain messenger sender uh okay again for those of you who don't know when you call contract functions on a smart contract message.sender is how you know the address that it's calling it right but for example when we're thinking about bridging right say I'm like L1 contract calling L2 contract function message.sender is actually gonna what do you call it surface the address of the L1 contract domain cross domain messenger contract right I don't know if I said that correctly but you know what I mean the pre-deployed optimism one so what do we want to know actually I want to know my address I want to know the L1 contract address um the way this is implemented actually allows to say okay when I call X domain blah blah blah I'm going to return my address not the address of the deployed messenger contract um again the next piece here is transferring Ethan erc20 tokens this is probably the most common way of doing bridging which is why optimism has kind of put that between behind an SDK I'm not going to get into it because I only have 50 minutes thank you Dev vakoda or Devcon um but there is a really great ethereum uh tutorial written by a person um on there that actually steps through the contract step by step so if you are interested in understanding how the token Bridge works at a smart contract level I suggest going there if not I will be diving into more of the part about using the SDK itself I want to know as well there are some things to know uh you cannot Bridge every erz 20. so the way the token standard Bridge works is it identifies both the let's say erc20 token address on the L1 and then a token address on the L2 however there are many ways you can like I guess you could have the erc20 token represented multiple times on the L2 so how does the optimism standard Bridge know which one one to use well that is specified specifically in this token list so if you want to add to that token list you have to create a PR so that the token Bridge knows which contract to bridge between and then two keywords here deposit so deposit means I'm depositing eth going from L1 to L2 withdraw is going to be withdrawing so going from the L2 to the L1 uh yeah okay so let's do the build person portion uh what are we building so starting off I think one of the most common use cases where you might want to embed a bridging UI is an nft Marketplace so we're building one on optimism and I want to talk a lot about bridging because of the ux problem so if you've interacted kind of with bridging right now oftentimes it's a separate UI so you go to another website or something do the bridging and then come back we're smart here we're at Devcon we understand how to do that not necessarily the best ux for I don't know my mom um so what's the solution uh uh her name is Bridget the bridge widget hopefully you understood that pun if not I will explain it to you many times until you understand it um but anyways the point is to embed this kind of UI it is just a component so imagine if I took the time to put this on npm you could just npm download into your app I didn't do that because I don't have time but anyways this is kind of the UI what it's going to look like you can create uh and listen nft mint your nfts see what you do you can buy them and specifically one of the views is going to be that bridging component which is what we care about today so what you'll need is we're actually starting this is where the Truffle collab comes in guys okay so travel has this thing called truffle boxes which essentially create um I guess scaffold code or educational code to help you start your dapps quickly I wanted to talk today specifically about the optimism Bridge box because it is a basically a empty project that configures a project ready to be deployed on optimism in addition to adding smart contracts that will do the transfer data portion as well as writing a script that will demonstrate how to do the SDK and so in part of the smart contract portion what it does is actually allows you to figure out how do I deploy across multiple chains in one go right I need to pull in L1 L2 and then I'm calling function on L1 and I call it functional two how do you do that travel box right okay what else will you need uh we are going to be connecting to the girly test net as well as the optimism test net um because we are working with these deployed contracts um so you will need that information from inferior you'll create a project separately to that because it's an nft Marketplace we will be uploading metadata up to ipfs you can do that through uh inferior as well they have an ipf's dedicated ipfs Gateway you can create for yourself as always metamask you need that for everything uh and then Gurley East optimism Gurley East uh and specifically I was going to mention girly dye so when I was talking about the part where we're going to do the script with the SDK when we're transferring tokens uh the one we decided to choose was die so if you want to actually run the scripts you will need some die in your wallet in order to do that the process for doing it I'm just going to quickly say is take early East go to uniswap change your test net over to girly and then do the swap between girly eat and girly die and that's how you do it um so are we doing this live no I'm just gonna walk through uh all the contracts um and hopefully you will understand if not um I I can't explain it to you over and over again because the Wi-Fi is not my fault uh so so let's move forward I'm gonna go ahead and open up the first part so uh this is kind of small so yeah you're welcome um I'm unimpressed that your eyes are that bad uh first thing you would you would to me like let's not let's say we're not in this UI is a truffle unbox optimism fridge and then if I wasn't here I would have called it Defcon demo and it would Manifest this box right and so I'm going to step through what's in this box that makes it optimism compatible uh so the first part here is going to be your contracts so in a multi-chain world you're going to have different contracts we should separate that logically into ethereum contracts as well as our optimism contracts this contract is a meaningless contract we just have it there as an example for you to look at something I will explain that later migrations is this how is how we're going to do our deployment um specifically in truffle you have the ability to number your migrations or your deployments so which is really helpful for multi-chain deployments because then you can decide I care about this migration in this order Etc which is why they're prefixed by numbers um the next piece is scripts so this is just this script is actually just calling the different migration functions um or doing the different deployments I want to speak specifically to the syntax right here right so the first thing that we're doing is going to be deploying to L1 we choose a network which I've defined in a truffle config and by default actually you know what stop this is really hard to explain until I've explained something else so let's pretend that never happened and move on to this portion right here okay travel config this is the last part for configuring a optimism depth right so we have two different configs the first one is your vanilla config this is what truffle will default to if you don't specify a network or a config essentially all it does is Define your build directories whatever and then your networks I want to note one thing the default would just be like a build to normal contracts but in this case we have due to two different types of contracts we will need to specify the build path so that's build slash ethereum contracts as well as hey treffle where do I even what contracts do I use well you pull it from slash contract slash ethereum um and then here is just identifying the network and um as always specifying your private Keys uh that sucks but I'm not gonna show you but I can show you the way to circumvent it later um which is cool that's a sneak peek but anyways so that is what our truffle config looks like let's move back into our migration script now that we understand that this is the first part we're using our first truffle config we are deploying to our L1 on the network girly like I said with that one two three four uh process we actually have the ability to specify which deployment we care about in this case we clear about the first one the second case if you notice here we are choosing optimistic girly um as the network we're going to deploy to and then specifically specifying this configuration so that way when we run this migration we know hey we're going to pull our contracts from the optimism folder hey we're going to pull or we're going to build everything into this build slash optimism and again kind of this specification of whatever and then skip dry run self-explanatory you're just skipping the extra part um these two pieces as well I want to do know is kind of anti-pattern I am sorry um but this is the part where we will actually be calling the messages on each contract so if you look in the actual deployment um you can see right here we're getting the instance of like the greeter contract on the other L1 one and setting that greeting typically stuff like this where you're interacting with your contract might exist in your dap or in a separate script migrations are for deployments I just put it there to show you hey you can put four migrations in right um so it still works uh but don't do this um anyways so that that's the structure of the Truffle box let's actually now talk about how to integrate optimism contracts into your depth so let's start with the contracts this is the transfer data section not the SDK so optimism has already deployed this example contract onto their various test sets and mainnet so again you can find those addresses in their GitHub essentially this is super easy all it does is this contract which does a version exists on L1 and a version exists on L2 has the function set grading so if you set the greeting say hello and you call contractor.greet it will say the hello that you had put in there um cool and then this part here is just getting the appropriate cross domain messenger sender address so these each of these um what do you call it addresses are the cross domain Messengers solidity file that exists on each chain ID um I guess like these kind of don't matter because all of it's deprecated but doesn't matter we only care about 420 and five and then this is kind of how you're going to get the actual um domain sender so the OG contract that you care about so that sign of the base contract of what's already deployed now say we want to create contracts that interact with that so we have this greeter which exists on L1 again all it does is have this function called set greeting so if somebody calls that greeting what we care about is number one the message this is how you're going to encode that message um so this is set greeting from that whatever message you're sending in and then specifically you could put a different contract address here this is the permanent address of the greeter contract on the L2 so essentially if you call set greeting on greeter L1 it will call the set greeting function on greeter L2 hopefully you digested that L2 does the same thing again talk to me afterwards I have so much free time um anyways greeter L2 does the same thing set greeting again right here is gonna be calling um this function on greeter L1 uh and telling it hey this is my target uh blah blah oh and then guess like I said gas limit is irrelevant we have up to 1.92 million gas for free calling stack reading on optimism hopefully I'm gonna say 100 does not take 1.92 million guess so that's where we're at um essentially to run this uh we would have just done run the script I'm not going to run it but you could see the output essentially looks like this um where it will compile your contracts and then start the migrations right so this is the first one where we're deploying it um the L1 contract and then deploying the L2 contract as well as then doing the the fake part where you actually call the greetings um and what is interesting about this is it is calling the greeting on a deployed contract on the girly uh test net as well as the optimism girly test net so what can we do when that happens we can go to etherscan yay and and see it in action I'm not going to open up ether's skin I took a screenshot that's what happens we opened up one of the contracts on etherscan called the greeting function here so it says greetings from truffle I do want to know if you do follow this tutorial like I said this is a public pre-deployed address so if all of you decide to follow this tutorial afterwards and you decide to change the greeting you might see somebody else's I have definitely like gone to this and it's like all in Chinese and they're like wow web3 is global but you can just go back and find your transaction hash in the history and then be able to read whatever you had specifically decided to set the greeting as um and just to prove to you this is the one from L2 setting greeting on L1 that's what it looks like it looks the same uh because it's basically the same contract uh where are we moving on okay cool let's talk about the script so this is complex um but I'm just gonna I don't know how much time I have left so I'm just going to talk faster because that's my style uh okay so here is basically a script of how we decided to use the SDK I'm going to point out a few important parts here right so the first part is pretty self-explanatory we're just setting up all the things that we need to get our cross domain sender thing um set up so you're going to need assigner for each L1 which is L1 sign or L2 signer as well as here uh this is specifically for if we wanted to do the SDK withdraw and uh deposit functions for the erc20 so you're gonna have to pass in what erc20 addresses you care about like I said we are interacting with die so that die address for L1 address die address for the L2 is from their are uh list here and so you can find it it'll say like chain ID five die and then there's the address and that is what you'll be using in the SDK if you specifically want to do die um wanted to die okay um but anyways before I dive into the functions themselves let's actually talk about what this is going to do in the end uh super simple like I said all it sets up stuff we're going to deposit eth so just calling the SDK dot deposites SDK dot withdraw eth and then also deposit and withdraw erc20 and deposit whatever I said both already they're basically the same thing except for one caveat so we'll dive into each of the functions and then we'll discover what's different um cool so after setup uh I'm just going to go from top to bottom even though logically that might not make the most sense but that's okay I am a bit frazzled report balances okay this is just a helper function all it's going to do is log what um your balances are for your or your eth balance or your die balance um this is just for tracking purposes in the script so you can see that hey it actually transferred wow good job optimism um okay no one clapped cool so that that's kind of just helper methods we're going to actually dive into the deposit function um so specifically to deposit each super simple um you just call deposit eth and then put it on uh one thing to note here right is there are these things called statuses so the problem with bridging is it takes time to move back and forth how do you know when it's done so optimism will provide different types of statuses to allow you to know hey when it's done with relay that means it's been properly um I guess committed or posted or whatever so that's you need to watch out for the that and then you just report it before and after okay guys ready what's different here no one knows okay cool this is different here right here um so again like I said we have that caveat of the L to optimism standard token Bridge needs to know what L2 address you are interacting with and specifically in order to do this you need to give approval to say hey I approve that we are using this L2 address because if you had given it a random address it doesn't understand all that token is gone so this is a very manual step that you have to take in order to complete a ERC token transfer and then we go into the withdrawal this is exactly the same thing between the two I just want to call out specifically we've added in a new status so when we talk about going from L2 to L1 I had talked about that thing called challenge period right because that's when like things get real right it goes to mainnet so that's kind of I'm just logging that to say hey I'm in the challenge period so if you run the script uh once we get to the withdrawal part that takes a lot longer than the part where we're just depositing because we have this part where we have to wait for people to be like no that's wrong or yeah that's right so yeah that is using the SDK let's move on into actually building adapt and seeing that how we can integrate the SDK into our application wow I did so much live coding here it is okay essentially I'll tell you two things I did or I did a lot more things on two things first off right now we have a client in so when you're building like a full-end app you probably want to no not probably you should be separating your uh folders into your client section and the part you care about uh which is your contract session so essentially what I did in this process was just copy paste all the relevant smart contract or truffle code into this truffle folder we didn't need any ethereum contracts anymore because that was for the greeter example um I just replaced them with optimism contracts so this is specifically just a optimism nft contract as well as a Marketplace contract that handles all of the transfer of like lists buy Etc one thing to note here is if you notice nothing really looks any different optimism is evm equivalent so when you start writing your evm or optimism daps you can pretty much copy paste there is a caveat though with like four op codes that are a little different you might not run into them I'm not going to get into it but please be like aware I'm not preaching like the golden standard of evm equivalents it's like the golden minus four op codes equivalent of evm standards anyways um in this case right so now we actually have to deploy our contracts I hope this will work um this is the part that I wanted to say was really cool so I don't have to show you my environment Keys is specifically there's this idea called truffle dashboard um and it will open up this UI that basically allows you to connect to your metamask account well everything is so small hopefully you can see it no Annie okay well anyways dang this is loading oh okay cool okay so it's committed to my oh man this is going to take a long time how much time do I have left it's 11 30. oh dang I finished all this in 30 minutes wow we have 20 minutes for questions okay sorry um I'm so surprised it's not connecting okay I'm just going to explain what would have happened here right so essentially um oh actually I never deployed it that's why nothing has happened let me go backtrack so truffle uh dashboard this is usable with any project if you notice it is open up on localhost 24012 um I'm sorry I see someone squinting in front of me uh I I yeah whatever where is it it opens up on 24012 so if you are using like a hard hat config for example the way you do it is you just specify one of your networks as dashboard and that Local Host and it will open up this UI specifically what's cool about this here um is this my terminal oh it is my terminal nice okay I don't know where I am I have truffle dashboard open somewhere um Okay cool so you would just do a truffle migrate and then this time we're choosing Network dashboard and then the config is going to be truffle config.ovm.js [Music] and I think that's it I do want to know as part of this box that we have provided like npm scripts that you can just run but I always forget what they are dang where am I I don't know I don't remember what I'm doing here what is wrong here cannot find thought oh did I not migrate it in oh did I spell it incorrectly guys did I spell it incorrectly truffle Dash config.ovm Dot where what am I in the oh I'm not yay live coding um Okay so now if this works I have 30 minutes for this to wait guys I really want to show you this damn something else happened please check that your ethereum oh this is my Local Host died oh I did I did oh I did this on purpose so you guys know how to use it haha joke's on you you thought I didn't know what I was doing I do because I work for trouble okay so I think it's connected now and okay no what happened here oh I heard someone like trying to suggest like hey you just opened a new terminal that's why it's not working okay compiling your contracts nice okay oh wow fancy [Music] I'm so happy he's clapped without me coercing you this is awesome um okay cool and then if you notice here actually I did want to point out in this migrations contract um we are deploying both of them the marketplace contract is dependent or sorry the nft contract is dependent on the marketplace contract I did that specifically because when we mint and transfer nfts you need to add approval for it to do that I got lazy and said hey nft just set approval for anything that is a Marketplace contract and that is why that is there and that is why we have a second transaction to approve nice okay very good and then we deployed it and oh I forgot to mention one more thing when we were doing this right if you remember the first time we did it we specified the build path of contract or build slash whatever but now that we are using it inside of our client you have to replace that build path to be used in your client directory um this was a pre-configured project so I forgot to do that but I remembered and it's already done wow okay I'm not gonna make you clap again even though I really like it cool and so the client portion um this is also pretty it's a lot of code I'm not going to dive into it it is a next JS project just kind of the steps to do that would just be like a create next app and then I'm using Tailwind because I suck at CSS so that's like in it Tailwind I have instructions somewhere I'm not going to show you I'm gonna blame it on the Wi-Fi again but essentially what that looks like is we have a bunch of different pages and I think because this is going to be local I can just actually just do this cool wow local development is so good if only there was something called ganache forking that could fix this um okay anyways so this is kind of like the different views um that we have and I want to talk specifically about the Gurley Bridge um so I embedded it here what does this actually look like in terms of code right so let's open up Gurley bridge and actually let's also open up the the sky right here and you'll see the magic of how much code I did not write because of a truffle box um let's say split left so all we cared about in that bridge was transferring East between the two right so if we're here on the Gurley Bridge here's all the gross HTML stuff that I hate because I was never a front-end Dev but we have two things we care about right depositing eat and withdrawing eth so if we look at the deposit each function here and the positive function here don't they look almost the same yeah wow very cool I copy and pasted that except added some other things that you need because State matters and whatever but you get what I'm saying right it's exactly the same right and the same thing with withdrawal ease here as well or I don't know where it is uh uh Eve yeah and it looks virtually the same as well the only piece I took out here is gonna be report balances as part of my UI I pulled that out into just to get l1e gonna get L2 eth specifically so that we could demonstrate this information right here um I'm not I guess we could try okay well everyone pray for me why did I do this inspects inspect console okay so if I do something like 0.001 I deposit you can see like the console stuff that I had before was damn it oh this is something yeah okay sorry I forgot to configure some stuff so let's pretend I configured everything properly and then it understands the RPC URL and everything but I have a screenshot uh uh and that's all that matters Emily did everything correctly this is what it looks like um and this specifically is the version of like moving it from uh oh that's highlighted in blue uh awkward um okay anyways uh this is the part where we're migrating over optimism girly eth over to girly eth I do want to note one thing actually now that I remember when you're moving from L2 to L1 and you remember I said it's like more expensive because you have that double transaction right so in the script when we move it over we actually add a little bit more Ethan we directly are transferring because otherwise that would be burned as part of the process um and you would probably actually lose eth uh so that's one thing to notice but anyways this is when I did everything correctly this morning and it failed now but that's what it looks like and that is I think our full depth how much time do I have left oh good job Emily I have 20 minutes left so we can talk about what's next so what's next a crash course and what's next just kidding that is not the definition of a crash course so we're just going to talk about it um I went through this really fast right uh and this was like the nft marketplace utilizing the SDK scripts I would challenge you guys to actually take this information and build something you're on your own right so maybe like a chat messenger between L1 and l2s right because you can transfer that data um in this case uh you will be needing the Truffle stuff to be deploying information back and forth we have a vanilla optimism box that doesn't have any of these additional scripts and environment variables and everything if you don't want that it would just be a truffle unbox optimism but other things is like Bridget there's a whole bunch of bugs with Bridget I didn't do any like data validation fix those for me alternatively like it only does eth right now only on Gurley you can configure it basically to select the network um and then always like I was talking about optimism because that's what we have we have other L2 boxes specifically arbitroom exists right now uh what's in the works is actually a stark net box which is super cool um how is truffle working with a non-evm compatible language I don't know we'll find out that's in the future but it's happening and it's exciting um and then just in general I want to talk about what our plans are for multi-chain so again like I said multi-chain depths are hard complex I said a lot in 40 minutes I don't know how I did that um but what are some kind of pieces that we thought was difficult about our demonstration that we are fixing so first thing is declarative deployments so if you remember in that scripting portion it was very simple I just had an L1 and an L2 right but imagine if now things were dependent on each other's addresses or now we've introduced like a new L1 or a new L2 these scripts like in production can get really intense and that's hard to maintain so declarative deployments is essentially you saying like I have a Json or a yaml file we're still figuring out the actual structure of it yet but you'll say like this is kind of what I wanted to look like and then truffle's like wait I'm so intelligent I can do it for you um and and that's kind of how it goes and along those lines of what comes with development declarative deployments is being able to declare environment-based configurations so again if you remember when I was talking about the network configs it's just like a bunch of lists of like girly mainnet uh sapolia Etc but what if you could actually bundle those up into your own environment so you'll say I care about these networks only in testing I care about these networks only in production instead of doing like a truffle migrate and specifying every single Network you could just say truffle migrate testing environment and that's how you would get there so that's pretty cool um ganache plugins I'm actually probably the most excited about this because the Wi-Fi was bad here um it would have done everything locally right so the reason I had to go on Gurley and optimism girly is because we were interacting with pre-deployed contracts so if you do like vanilla mainnet I mean ethereum development right now we do have forking right where you can basically copy the state of the chain uh main neck early whatever you want locally you can unlock wallet addresses so you can pretend like you're somebody and interacting with those existing contracts on your local environment but right now you can't do that for l2s because there are very slight differences that I mean you technically can I would not recommend it because of those slight differences right and so imagine in a world where we have ganache plugins and essentially you can say hey I want to create this plugin to create a optimism flavored ganache or an arbitrine flavor ganache or whatever and then because of that you can bring up multiple instances of ganache your optimism ganache your main net ganache put those in a workspace that will interact with each other all of those pre-deployed contracts were actually also copied locally because of the forking and I could have just done this all on localhost and because it's not on localhost ganache is compatible with our other development environments so again I'm here to say we do not require you to work with other or be married to truffle itself we are coopetition is what I call it um and the last thing I think in a caveat of this so many times I am not an expert um but we are bringing on an expert so if you don't know I do this weekly live stream called web3 Unleashed where I basically say hey I'm interested in this who do I know or can I figure out will teach me about it so um we're bringing Annie she does like partnership protocol Partnerships with optimism to come talk a bit a little bit more about bridging security and then specifically if you guys don't know optimism had like a huge announcement about like Bedrock changes I don't know what's in it Annie will tell you but this is coming up on November 3rd it will be what do you call it recorded so you don't have to join live if you don't want to but that is everything so thank you so much for joining um follow me on Twitter that is a QR code to more of links that are important to me uh man I'm so scared I'm not ready for 13 minutes of questions usually I just take the full 60 minutes and then run so uh if you have any questions about this my life uh okay yes okay to another and between l2s and l2s um okay I don't work for optimism so I don't know I my guess and I'm gonna actually I'm gonna write this down so I can ask Annie my guess is probably no because we are interacting with those pre-deployed cross-chain Messengers and that is what is doing like the communication right so maybe they have deployed ones on other l2s the L2 Space is really crowded and they're fighting each other so I don't know if they would actually do that which is antithetical to the spirit of ethereum uh but yeah that that's my guess let me write this down oh my God my notes are so messy where's my phone I'll write it on my phone so you guys don't see it oh shoot where's my phone uh uh okay I'll just remember in my head but yeah cool do we have any other questions yeah yeah yeah so different build directories um so if I bring up the code again basically for each chain you would write your own truffle config um and then where why is this not opening um oh yeah it is here each config you would just specify which build directory you would have different configs and that's the problem or that's what's painful about it right and that's what we're trying to fix with declarative deployments yeah yes I should not use what oh like when should we use L1 versus L2 um I guess my specific thing is like I think l2s are the future of ethereum the problem with l2s like I had mentioned is probably the ux problem as well as the adoption problem so when we are building like say your first step right the biggest kind of cohort of people you could take on is probably going to be just mainnet or ethereum development right um but if you're trying to do like plan ahead and stuff you know I'm thinking layer twos are important um okay let me let me backtrack let me just talk about what I would think about when I'm choosing where to develop right so it's who is my audience how big is that right the second piece is Dev support if I am building this how good is that layer two uh at providing support how good is their documentation stuff like that um and then the third piece is also just like general adoption be of developers right so if you look at that space is there anyone who can even code with you is there anyone you can build with um and layer twos are new right and so there is going to be some trade-offs there um but it's kind of what you want to do in the future I know optimism is doing really cool stuff with promoting uh L2 dapps and I think in general if you talk or I'm not going to say words for other people but the general consensus right and the way I see the ecosystem moving um is in this direction so uh that's my opinion yeah cool any other questions yeah right right yeah yeah the challenge period is a big con right uh I I don't think you would change in the sense that if you want to interact with like a layer two um like a zero knowledge roll up right you still care about where those contracts are coming from so that build directory is still important the network IDs are still going to be different where you're deploying to so all this different configuration is going to change um actually I did mention so we have Stark net is zero knowledge uh we are working on a ZK sync integration as well which is also zero knowledge um so I think regardless of where you choose to go um this is going to be a configuration you still need uh unfortunately but um I think hopefully if you have submission or like what do you call it uh suggestions whatever like we're open source why don't you just contribute to our code base uh or create an issue we have GitHub discussions as well during our Discord Community um last me on Twitter uh whatever is most comfortable for you but yeah yes yeah oh oh sorry okay you said I love her okay disclaimer part of my personality is I really like fried chicken it's on my Twitter that's what he mentioned if you didn't hear that so okay yes thank you wow we're getting professional like personal here dang okay we have seven minutes to answer questions about Emily Lynn um okay why did I choose to go into devrel versus um you know be a core developer that's a great question uh so if you want to talk a bit about my background um so I graduated college with a CS degree I went immediately into back-end development I did that for like two years and then was like oh this is kind of boring what's cool and fancy and I was like wow devops is such a sexy word it is the worst word ever I hate kubernetes but anyways I moved into devops right and I think I was so I'm in my 20s I don't know why I'm getting into this tangent uh but I was kind of in that space of like figuring out I'm not totally satisfied with my job part of the reason I moved into devops was one thing it was sexy at the time um but like also like I really wanted to learn something new right um and I haven't gone to the devrel portion of it I promise we'll eventually get there I'm just filling seven minutes um but uh where was I so I I knew I wanted to do something where I was always learning something new right I felt like within my engineering job there was a lot of like communication internally like with my team and building projects and I really like that um but at the end of the day I think when you are plugged into like a big tech company uh for example I felt to an extent like I was I don't want to call it Code Monkey but the impact I had was not as big as I would hoped all right so when I was thinking about you know what are my next career steps so I actually didn't get into web 3 or devrel until this year in March um so I'm relatively new but the thing I cared about again was you know work environment I wanted to be around Builders like it was really important to me to be around people who like really passionate about their work and like maybe unfortunately crypto is usually our 24 7 and our nine to five but I seek that kind of environment you know what I mean um and the second piece was the thing I enjoyed the most about my engineering job was the cross-collaborative communication when I got to uh kind of background wise so my uh when I joined the devops team we're really focused on reaching stock 2 compliance and security so I was working very closely with a security team and so being able to translate technical Concepts on our side to other team members was something I really enjoyed and knew I wanted to take into an egg next job so when I was considering my different options developer relations came up and I thought it was this perfect marriage of I get to keep my technical skills I am required to learn something new all the time so that's why I'm not an expert in anything obviously but I know a little bit about everything and I think that is something I really liked and then in terms of the impact part just being able to interact with devs like my job is figuring out like what people what pain points people have what they're working on et cetera and like trying to fix that like felt more tangible to me right and I think that's why I kind of fell into devrel I'm gonna say one more thing and I always say this and she's in this room and she hates that I say this my sister actually started uh in devrel first and then also works in devrel in um web three uh yeah wow crazy um and she is like one of the biggest Inspirations in my life uh and so maybe that's part of my motivation as well or maybe I'm just like the bratty little sister I I think my tagline is like do everything she does but better uh so so maybe that that's also why I got into devrel um cool I don't know if we have any more time uh we have oh God four more minutes dang it okay otherwise feel free to go wait in line for other talks or come catch me wherever yeah I mean I'll be at like the conference I'll be at near con um consensus which truffle works for uh is gonna be having a event this Friday so feel free to stop by uh we have a lot of different panels and things like that um yeah cool thank you so much [Applause] foreign [Music] thank you [Music] [Music] thank you [Music] [Music] [Music] thank you foreign [Music] thank you [Music] [Music] foreign [Music] [Music] [Music] [Music] thank you [Music] foreign [Music] [Music] foreign foreign [Music] [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] thank you [Music] [Music] foreign [Music] [Music] [Music] [Music] [Music] thank you [Music] foreign [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] foreign foreign foreign [Music] [Music] [Music] [Music] [Music] foreign [Music] foreign [Music] foreign [Music] [Music] [Music] [Music] thank you [Music] [Music] foreign [Music] [Music] foreign [Music] foreign [Music] foreign foreign [Music] [Music] [Music] [Music] [Music] foreign [Music] foreign foreign [Music] [Music] [Music] foreign [Music] [Music] foreign [Music] foreign foreign [Music] [Music] foreign [Music] [Music] [Music] [Music] thank you foreign [Music] foreign [Music] [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] [Music] [Music] thank you foreign [Music] [Music] thank you foreign [Music] [Music] foreign [Music] [Music] [Music] [Music] thank you [Music] foreign [Music] foreign [Music] [Music] [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] foreign [Laughter] [Music] foreign thank you foreign [Music] [Music] [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] [Music] [Music] thank you [Music] foreign [Music] foreign foreign [Music] foreign [Music] [Music] [Music] [Music] [Music] thank you [Music] foreign foreign [Music] [Music] [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] foreign foreign thank you [Music] thank you [Music] [Music] [Music] foreign [Music] [Music] [Music] foreign foreign [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] foreign [Music] foreign thank you [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] [Music] [Music] foreign [Music] information [Music] [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] foreign [Music] foreign [Music] [Music] thank you foreign [Music] [Music] [Music] [Music] thank you [Music] [Music] foreign foreign [Music] foreign [Music] foreign [Music] [Music] [Music] [Music] thank you [Music] foreign [Music] foreign [Music] thank you foreign [Music] [Music] [Music] [Music] wow yeah oh awesome uh hi guys uh I'm Ben mimishevich I'm a software and smart contract engineer being in the space since about 2018. today I'm basically going to do a tutorial where we'll build through a simple blockchain indexer and just sort of explain how indexes work different pipelines you can design and make and in general just interacting with Geth on a sort of RBC level okay uh just some background quickly about me and how I would love to run the presentation in general um yeah so as I mentioned before I've been in the space since 2018 I used to work at a consultant in labyrus which is an Australian uh smart contract consultancy and then I worked as an engineer at Tracer Dao in mycelium which is Perpetual swaps uh protocol on arbitrum um yeah I was the team lead at reputation Dow which was a project at mycelium where we focused on indexing and monitoring Oracle systems on chain to make sure oracle's made uh well essentially held accountable and also that they're functioning properly and accurately so sort of just detecting uh errors sort of in that pipeline oh um so in terms of my experiencing in the indexing space I've been working in indexing for about two years um I'd like to know what I'm talking about but I guess we'll see uh in terms of questions please just like shoot up your hand if you have anything as I go um okay ether's gun uh ether scan is probably the most popular indexing tool all around um I've spent a lot of time on an etherscan it's basically a hobby of mine I'll click through random blocks and see if there's something fun uh if you've ever accidentally sent eth to a contract instead of calling the function and you think nobody saw it I saw it uh so this is one Trends oh there's a screen here uh this is just one address that I found this morning in a block and it's essentially an eoa that seems to be Fanning out Eve to a bunch of addresses extremely quickly so it's sending out full five transactions trying to spread out I think about 0.8 eth um yeah but it's really worthwhile if you haven't done that so sort of explore what's underneath the scan and see how interactions are happening on June okay so observability and transparency I know at the moment uh uh ZK and privacy and transactions is highly important and that's absolutely true and if you want privacy of transactions oh go for it uh but on the other side observability is also highly important um just as a question does anybody have any pros that they think having transparent transactions have over ZK uh yeah no corruption exactly nice and uh I'm not trying to just Shield transparency don't worry I don't work for the SEC or anything like that I'm not after the taxes um but it's still highly important in certain systems uh oracles which I work for don't really function on zero knowledge you have to know that your oracles are operating properly and you have to know what each Oracle is submitting uh having an amenity that reduces the accountability of those oracles and it can cause your systems to not function the way you hope if you uh you know one bad Oracle transaction can completely crash the market especially derivative markets uh this is actually one example here also from this morning um so mango markets lost 100 million dollars uh last night because of Oracle manipulation so making sure that you can observe what's happening and also the exposure that those oracles have onto the each market is very important and something where transparency and building an indexer is highly useful [Music] okay what actually ends an indexer uh the way I Define an indexer and the way I like to think about it is it's basically an ETL program where your back end is communicating directly with the node you're requesting data from the blockchain and you are converting that data or storing it in a unique way that makes it more accessible or useful to you um yeah sorry let me just run into here so uh why would I actually want to store it differently than on chain because you know the blockchain is a database in and of itself all the data is always there the problem becomes though if I want to retrieve specific data or a range of data or God forbid create some sort of average across it so if I wanted to do that I might have to make hundreds of each calls to process one transaction or one event that I Define on chain um so one really popular reason to make an indexer which a lot of now RPC sort of services like Alchemy and coinbase support is to fetch the transaction history of an address that is not possible directly when you're directly interacting with the node you would have to pass through every single block that uh that address has made a transaction on and then manually look at those transactions another really good reason is uh non-effemeral data on the Chain so mempool data uh anything that you run through as a test is an eth call doesn't stay on the blockchain forever mempool data in particular is highly useful for arbitrage strategy but there's actually no consistent history of the mempool um obviously mempool also differs from node to node but having a history from a range of nodes is highly useful if you want to sort of background strategies that you could have done uh if you're an arbitrator uh yeah also a gas estimation as well if you're making eth calls that don't actually go through chain you want to have a history of how your contracts will look when they're finally deployed creating a mini indexer that runs off your localhost smart contract known is absolutely a valid option uh now I just want to quickly break down a log uh that like happens on train quite frequently so this is what happens when a chain link Oracle submits oh well lots of chain link articles actually submit an answer for a price feed on chain so this is the decoded version I'll show you the encoded version a little bit later on um but even here not everything is super obvious to the eye right so you have the answer at the top which is obviously the new value of that price feed will have uh for those curious this is the price of one inch um but there's other points that are really confusing right if you look there's observations where you have what seems to appear as a intera right and you have observers which is just this confusing byte array with a weird name you have role report context um let's sort of just look at what's going on foreign to creating ND indexer creating any indexer sorry or uh sort of observation solution is first you have to understand the contracts that you're working with what your ETL really does and what it should aim to do is to take this raw like hex data on chain and give it new meaning or new accessibility and to do that you have to know what the contracts are doing already just copying the data across isn't really enough so sort of on that talk uh on that point sorry I'll just quickly explain how OCR works that was the uh chain link log that we just looked at previously so how chain link operates nowadays is that also I don't work for chain link I just want to say um how chain link operates now is that most of the aggregation and collection of data happens off chain so uh a price deviation will happen all these nodes will look at their different apis and they'll send all of their answers to a single node and then this node will submit all of these answers and the final aggregated answer on chain on behalf of everybody else who's supporting that price feed so sort of knowing that um I'll also just go through a simple timeline so as an example say I have a chain link feed that's monitoring the price of ethereum when the price of ethereum dips by a certain percentage all the chain link nodes will know and they'll start a new round every every single chain link node will then send an answer that they've collected from their apis to a leader that leader will aggregate that answer normally taking a medium of some sort he'll pass this along to the electric transmitter for that round and then that transmitter will send off a message on chain containing all the information that everybody submitted individually as well as the final answer and why I sort of went through this is by knowing this information knowing how the system works we can now make sense of the log that we looked at earlier okay so believe it or not this observers array right here uh byte array is actually a list of the addresses that each of these observations come from so uh if you all those numbers there's a corresponding Oracle address of the Oracle that submitted that answer and that answer is the number that they thought is true another thing to note is that number is very large um yeah if that number was exactly how it is I would be retired as holding like 51 inch tokens but here I am so this is sort of another step we have to overcome so we're sort of missing more information but we know it's available somewhere within the contract foreign so this information is available through a view function in the chain link aggregator contract called transmitters which returns a list which returns a list of the addresses of each article that is supplying that contract with data and there's another function called decimals which tells us by how much I should Define divide those numbers those observations to get the accurate like human readable price of one inch in this case the problem though is that these variables can change block by block these are adjustable variables transmitters change all the time not only for security reasons but sometimes certain articles are better at performing on certain Feats than others and decimals can change when different markets require more Precision out of a price feed okay so this is sort of how we break it down so I had my observations arrayed there and the way to break it down and you can find this out by sort of reading the contract and then doing a bit of guesswork is that if I look at that byte array and I split it apart into pairs each of those pairs can be decoded from hex into a number this number represents the index of which uh that observation in order corresponds to which item in that transmitters array um the observation was from so in this case the second observation here was from the second article so we're indexing from Counting from zero so zero X zero three one two e a dot dot dot responded with four three nine three nine nine um so already we're sort of getting kind of complex and how we're just deciphering this one single look sir um we'll go through the steps and code as well how we would do all the different calls but essentially at the minimum what we have to do to fetch this data is first we have to encounter this chain link log then we have to pass the data back into regular data types take out transmitters byte array break it up into pairs convert that into hex to get a number call the transmitters function with an eth call and then pass out which address is with which address now I'm doing this for One log not too bad I probably wouldn't want to do it by hand but imagine if you wanted some sort of aggregate data imagine if I told you okay tell me how accurate this Oracle was on every single Wednesday for the past six months now you're passing hundreds of logs you're making thousands of calls and if you want this to be done on demand it's going to be incredibly slow it might take minutes uh on the other side on the other hand sorry I could make like an SQL statement like select average where Oracle equals this where time equals this and this I'm converting hundreds of lines of code thousands of uh like HTTP requests to one line in SQL that's sort of the value that indexing can bring uh before we actually get into the indexer I also just want to go through the data types ethereum has so these are sort of uh our Avenues into getting different data so there's actually more than this but this is just a quick summary so uh uh does anybody know by heart what things that you can search on etherscan oh well any like blocks contract addresses any others okay yeah transaction hashes yeah so transaction hashes addresses block number block hash um sorry ens names yes nice no you cannot uh not in within the um like top search bar yes um so these things are the things that uh ethereum will naturally index so you can already select these from the node relatively quickly and they each have a relationship with each other if I have the log I can retrieve the contract address that that log was emitted from and I can also retrieve the transaction that that log came from and then through that I can also retrieve the block number that that transaction happened on and so on um and receipts as well so transaction receipts so you can see how much gas was paid for that receipt but the point here is that you're sort of migrating across these different data types to collect all the information you need for your index [Music] so dissecting a log um I'm just going to go over the structure of logs and for those curious the reason why I'm concentrating on logs is that there's quite a lot of functionality within the get client with blockchain clients in general um for creating these indexers based on logs uh creating them based on transactions is also possible but a lot more manual you have less sort of filtering power on that first step um so how log works so logs are constructed out of topics and data essentially so topics are also data topics one two three are data types that you can emit in your event and mark them as indexed and why this exists is that uh instead of building an indexer I could potentially just use the blockchain client as well to look for uh cases where the data is equal to a particular amount so I could tell Geth tell me when topic zero is equal to X and topic one is equal to this and retrieve all those cases for me within some block range um topic zero I'll go over in a moment uh the data uh sorry something to also known on topics is that you can only index up to three fields data though you can throw as much stuff as you want in there um and this is like highly valuable and a good way to think of logs and data in general is sort of like a print statement for your smart contracts so if you've ever like debugging and uh you know we're all programmers here and we hate using the actual debug tools we just print hello um this is exactly what a lug is um yeah so we also have the transaction index which is at what point our transaction appeared within that block and also log index which is separate which is where this log appeared within that block which is normally completely different uh this also removed which is like a bull that just signifies if our log was removed from the canonical chain due to a reorganization topic zero topic zero is highly useful um topic zero defines the log I would say so what topic zero is is I take my event definition so say I have an event called transfer and it takes a uint as an argument um I want to look at every single instance on the blockchain where this transfer event happened and to do that I have to calculate topic zero and to do that I take the cacaq of my event name so transfer and then each data type that is within that event definition so here it would be you know un256 or whatever um uh some important things to note you do not include uh and I learned this painfully by experience do not put spaces between the types because your hash will be wrong and also don't put the name of the variables within the type because the evm doesn't care about that so something to note as well is that this topic zero is unique for every single contract that is to say that you can only have one event with one exact hash definition per contract but this is not stipulated across the whole chain so I could potentially say look for every single log with topic zero but I might actually collect data for four or five contracts that are doing a completely separate thing that's just something to be wary of storage another really cool thing that you can do uh when you're building an indexer is accessing the actual contract storage so private variables now become completely accessible to you this is really good one of the main use cases that I've certainly used this for is when a contract is implementing uh EIP 1967 which is the proxy pattern so you have a contract that's implementing all the calls from another contract and that contract's address that's actually got the implementation is always in a specific storage slot um I can go into this example later as well but this is just one hugely powerful example of stuff you can access if you're building your own indexer okay infrastructure design so this is a bit of a web 2 thing but um it's important to think about how you want your indexing application to run you can make it as complex or as simple as you want so if it's just a regular ETL you can have your program connected to a node and then you're inserting into a database but you can do so much more you can create a hackathon submission that is looking for events on lens for example and then I'm sending out alerts through epns every single time someone's profile gets locked I could take uh you know I could scale my application I could have several nodes have a load balancer between it so I'm not overwhelming any single mode I could be sending off my messages after I've dealt with them to an AI analysis and I could be storing them across several database nodes um stuff I've worked with personally that I recommend is a sort of microservice architecture you can have Kafka sort of in the middle as a message broker and pass information between all your services all your different storage points uh maybe you're an arbitrager um and you want to do sort of an analysis through that analysis inside uh in-memory database like readers for quit act for quick access while simultane simultaneously uh throwing any archive data into your own sort of postgres database foreign database options um so indexing is really powerful because you can choose how quickly you want to access what subset of data so these are just like a few I threw up so time scale GB is extremely interesting um but any time series database sort of proves this point the blockchain doesn't give you an option directly to look through transactions within time range you can specify a block range but that's not really always ideal blocks take a different amount of time to create over time and you have to do sort of extra leg work there if you want to convert from block to time um time scale off is something really awesome especially when you're looking at a large data set uh uh like a blockchain and that's continuous Aggregates and these are materialized views that you can create for aggregate data so uh for example I can calculate the average every single week of how much gas is spent on ethereum and I can permanently store that data in a view and access it instantly as opposed to having to recalculate that data kdb is very popular within sort of the Mev Community from what I've seen um it's a completely in-memory database it's extremely fast so similar along the lines of radius but far more performance it's used a lot by Quant firms Arbitrage uh and also uh Formula One um like racing so they use it for in race analysis and stuff like that postgres uh absolute classic completely free perfect audio system why would you use anything else don't talk to me about MySQL I hate it uh okay now I just want to go through a quick Code walkthrough of a simple application so we can actually build these indexers in about 150 lines of go code easy okay so first I want to explain my language Choice um because I've been contested on it in the past I really like using go for the back end and interacting directly with Geth and with the Geth Library um like first of all Geth is well it goes fast Geth is probably the most well maintained uh Library it obviously doesn't have features of certain other um blockchain ethereum clients but it is definitely the most well maintained and it always fits through the specs the yellow paper specifications uh go has a huge uh bonus and their paralyzation is directly built into the language so we're going to be doing a lot of calls uh through web circuits or through HTTP and we want to paralyze these and we don't have to worry about race conditions when we're using go um yeah another huge bonus is that all of these functions that we're going to call to extract data our program is going to be completely portable to every single evm chain um except for memory xdi so we can Port our application uh make it as generic as possible and we can start looking at events on polygon uh polygon ethereum optimism arbitrum whatever you want without having to do any extra legwork it's like deploying a smart contract to multiple chains uh and the reason this is is uh all these RPC calls that we're making are specified within the yellow paper so any evm client that is being created is going to have to fit through these specs okay creating a client um this is like pretty basic code so I'm just creating a HTTP client I'm feeding in my Alchemy uh sort of key that's what the RPC thing is there it's just a string I'm doing a bit of error handling here making sure that I am in fact connected and in fact connecting and uh that's really it for this um there's really not too much to worry about here yes okay that's a good question uh I'll just repeat it um so the question was is should you run your own node infrastructure or use an outsourced node like Alchemy so there's several advantages to running your own um and a few disadvantages running your own node Beyond you just have direct access and you can manage all your load yourself uh you can also put other sort of add-ons on top of that node on top you can put add-ons on top of that node to make the indexing even faster um so when you're doing retrieval you're sort of indexing already on an index which is fantastic um me personally uh if I'm running in a production environment and I have an application that's fully running as an indexer and my system is depending on it then I would run my our node um I see some like node operators here and I feel that um but full hackathon projects absolutely use alchemy um fantastic solution not just Alchemy uh and any inferior whatever I'm not sponsored guys I'm sorry I keep using the same names uh websockets versus HTTP um so most providers will allow you the option of accessing their service to a websocket or HTTP um I'm just going to go over this quickly because it's more of a web 2 thing um HTTP is normally how your wallet connects to the chain so whenever I'm making a request my wallet is creating that TLC connection and it's shooting back a message and that connection is then closed when you're creating an indexer you're going to want to make lots and lots of requests and that extra extra latency between um creating a new handshake every single time is actually quite cumbersome I would just say uh straight up that if you can use a websocket connection always use a websocket connection um no reason not to really okay uh now we're going to look how to create a query and this is an SQL by query I mean we're going to query data directly from the node so uh there's this ethereum uh get object called filter query and it does exactly what you think it does it takes an array of addresses from which I want to collect logs from and it takes a list of topics uh so before we talked about topics and how you can index up to three and you have topic zero um so you can specify here I want to collect data from which topic zero and uh which other topics I want to be equal to some hex value and I sort of just declare this object and that's all you really need from here we haven't actually made the call yet this is just constructing the query uh this also takes a block range which I didn't include for some reason um next okay so now we're actually making the query and this is where block range becomes very important so there's two ways in which I can request data from a blockchain node I can do subscribe filter logs which is I'm establishing a connection to the node and I'm telling the node okay here are my parameters whenever this happens on chain send me a message so this is really useful because now I can sort of distribute my load uh from the node because I get these messages one at a time I can process them and as long as my application is at least decently efficient I'll process everything without any lag uh now this always isn't an option because uh one thing about throw uh subscribe filter logs is that I can't request historical information I will only be receiving data from the point I have subscribed so from the next block that's coming now I can also do filter logs in which I can request a bunch of logs that have already happened um so that's essentially what that does uh it's really useful especially uh if you want to do a historical analysis um the thing to be wary here is that it is like quite hard on the Node if you're asking a retrieval of you know megabytes or gigabytes of data and also your application is going to have to keep time as well um definitely super expensive uh if you want to collect the entire history for a particular log throughout the whole chain okay channels um this is a go thing um but it's also extremely important to know and it's one of the reasons that I suggest making these index applications and go so what a channel is and goes is essentially like a pipe so if I'm sending data from a process to B process I use a pipe but there's certain issues associated with um doing this right so you have to deal with race conditions for one which is a huge headache also piping can be quite messy I don't know how you're doing it but you can do it like through a bash script it can get pretty weird uh what go offers is channels and channels are naturally blocking so I don't have to worry about message one getting there before message three and screwing up all my analysis the channel will only send a message across to my next process when that process is ready to receive the message um and this for Loop here was sort of declaring an infinite for Loop and using the select statement and the select statement is just saying uh I've created this channel logs one and I'm waiting continuously until something is sent to that channel and uh the uh blockchain node is sending data to the channel and I will pull out uh that message as soon as it comes and select is just saying uh whichever one comes first so if my channel comes back with an error I'll deal with that and crash my program or if a log comes first I'll go and do some processing okay how do I actually process data um so when I request data from the blockchain and I get logs back I actually get back a pretty messy data structure um not messy but not human readable so what I'm going to get back is logs data structure which we went over earlier I'm going to have these topics and I'm going to have the data field inside the log uh and if I'm pulling the transaction similarly I will have the data field within uh the transaction field which is identical to the sort of log data now uh passing this across is pretty complex so there's natural pot padding that happens from rlp encoded values and I also could convert from hex back into sort of regular values at least for go to interpret but also uh so humans can interpret it I don't really know what's happening when somebody says oh the value came back as like 0x 60 zeros and then a three so what we can do instead is we can generate an ABI and this is exactly how etherscan does it and um for those not familiar and ABI is a specification of all the functions and all the events that happen on a particular contract and I can generate this by uh going to a contract and using cell C so that's the command at the top uh soci ABI and the name of the file or the path sorry and then I'll get a huge spit out of a Json file and we'll use this and Define it as a Sprint as a string and we'll use it further along but the API is highly useful but something to note is that it does not directly appear on chain um on chain is only sort of the compiled like bytecode so the ABI you have to get by having access to the source code or sometimes people upload it to etherscan um and what the ABI allows us to do is the ABI knows uh as I described before with the CAC it knows all the input types for all the functions and all the events that are defined within that contract so now I can use the evm to oh sorry it's plugged in [Music] should come back up in a moment um okay oh it is back fantastic so I can use this API and use the evm to decompile all of this hex data that I'm going to get blurted out back into regular data types so creating an API object um similar to the JavaScript concept but I'm going to call this API function which is also a API Library sorry that's also part of the GIF module and I'm going to pass in the ABI string that I defined previously I'm going to check that it is in fact a valid string which is important and then I can start unpacking data and that's that second sort of code Block in there I call my object I tell it to unpack I pass it in a string which is the name of my function and then I pass in my data and what it's going to spit out is a huge array of interfaces and interfaces are just generics and go so it's a it's data that I don't know the type of and I have to just tell go which data type that is and I can find that out by looking at the Smart contract code I can find that out by looking at the API and even if I make a mistake here go will tell me that I made a mistake if I try to assert wrongly that it enters a string go will tell me I'll um actually you want to type assert to a string um I don't know why I can't just do it automatically but life can't be that easy um okay working with a database okay so now essentially what we've constructed is we have a system that's requesting data from the node either live or through uh through a historical query I've collected that data I now have a method to unpack that data into regular go data types and I can convert between them as I wish now I want to insert that dotto somewhere so uh this is a pretty standard way of just interacting with a database and go uh completely fault proof um and it's using a library called Gom so go RM it's a used to be sponsored by chain link actually as well um pretty fantastic Library highly recommended uh so it's very easy for what I have to do I just Define a struct which has what my tape what I want my table to look like I throw on some strings where I want my primary keys or foreign keys or indexes and uh I'll just leave that in the module by itself and then what I'll do is I'll uh initiate a connection to my database and it's also just this one line code so I just tell it to open um I have postgres listed here but it has support for most popular uh database Management Systems and uh gorm config which you can uh specify different things in but we can just leave it blank if you're not doing something fancy you can pretty much leave it alone I do some error tracking and then I've got migrations for those on familiar migrations are fantastic if you've ever worked for a production system and you've wanted changes in your database and you basically it's like a nuclear reactor like two people have to turn their keys at the same time to edit a table migration sort of sidestep that what gorm will do is I can pass in the my uh structs that I defined before and it'll automatically create or edit the tables that I already have um so that way the code that I have is going to be exactly represented in my database um inserting so we're pretty much like done here guys um all I have to do now is use the structs that I previously defined pass in my decoded values and then I just have this one line um insert or update on conflict so what this is essentially doing is I'm sending a message and it'll be acid depending on your database of choice I guess uh out to the database and I'm telling it okay um if there's no entry inserted if there is updated um and updating actually absolutely can happen although the blockchain is immutable uh remember that the node is getting new data all the time reorgs do happen so something you want to watch out for is your block hash changing uh and also your block times down um profile idb oh sorry we just have like type assertion here so you can sort of see how these are getting paused back into the struct so I have my profile ID and this is an example that I did based off lens um so profile IG and lens is an integer which represents uh your user on lens uh and then also nft which is an nft that's generated on lens whenever you follow somebody and I just passed these into that struct I'm calling my uh uh sorry databased or Clauses update function and I'm passing in a pointer to the struct okay um so that's basically it I can go through some like actual examples as well but I just want to do a q a um actually how much time do I have left got plenty of time um yeah oh okay um so EIP 1967 basically says uh it's a proxy pattern so say I want to make changes to a Smart contract um you obviously can't really do that so what I can do is I can Define uh the ip1967 contract and tell it do all the functions of another smart contract and I can change which smart contract is uh which my contract logic is actually being changed by just changing that variable but the problem is is that there's no like view function for the contract address that's uh on that 1967 contract but the storage slot where that address is stored is always the same across any uh EIP 1967 contract so I can retrieve this address and then I can query that contract for any information that I want uh does that help okay uh yes yes I will um I wanted to clean up a bit but it's uh on it's submitted within the if hackathon I can send the link out uh if I'll send it out on my Twitter which is at the end yeah I'll just repeat the question but uh the question is how many block confirmations do you wait before inserting the data into the database or how do you deal with updates so the great thing about the system is that you don't have to wait at all every time there's a new uh reorganization the logs will be uh like re put through the node and then uh the indexer will automatically update that column for you so the data you have in your database will always be the most accurate that it can be and most up-to-date sorry yes um why is it volunteering um I mean it costs gas to emit events um why isn't it standardized I mean it is standardized in development it's not like you have to deploy a contract with events um and if there is contracts deployed without events you can also create an indexer based on that I think that's what you're getting at or yeah oh yeah okay for sure um sorry can you repeat the question oh okay um y indexes mostly use logs uh that's also I want to say more my opinion than true fact but also our most popular uh index platforms so uh the graph and stuff focus on logs quite a bit and sort of why there's so many blogs and you have to find the useful ones that information is hard to come by and if you want to create your indexer as I said you should know the contracts and the system but also you can make a general solution like the graph or like uh oh I forgot the name um oh can someone help me their logo is like doing analytics thank you like June analytics where I can do an SQL query on absolutely anything um but in terms of why there's so many events happening uh a lot of these events are just shut out for debugging purposes and they're left in the contract and you sort of have to decipher as you go um any other questions yes contract state yeah yeah um so as before as I went like through storage so if you wanna uh if you want to get contracts State there's three main things that you can do so there's access through variables um so every single public variable on a contract automatically has a getter assigned to it so that's one way we can access State the second one is through storage um as I mentioned before so it's kind of tricky to find out exactly where a variable is in storage but if you go on the solidity um uh documentation page they will actually walk you through uh how storage is structured based on the contract and you can sort of mull your way through and find the variable the third is traces so traces are the individual op codes that a contract is pushing which you can also request from the node and uh with combination of those three you can see absolutely everything that a contract does um in terms of sort of creating strategies based on collecting that state I think the best indexers are ones uh well that you make yourself and they're purpose-built and you're traversing across these different data types to create sort of your perfect arrangement of data um so I built one on top of Avo a while ago and that can be was like relatively tricky so they have a EIP 1967 pattern where accessing storage to find that contract that contract is a pointer to other contracts I'm doing an eth call to access the variables to find those other contracts and then I'm calling balance to find each balance of those contracts uh I'm also utilizing storage um yeah stuff like that and then you just have a really neat one row item in your database for what you want sorry yes closure would you notice that um um do you mean deploying the same contract on two different chains or okay um so yeah that is actually important to note so if somebody like destructs a contract yes okay if somebody self-destructure contract I just repeat the question um if somebody self-destructs a contract I believe it's possible for another contract to appear on that identical address and that can have different cards so it can potentially break your indexer uh what you can do there to solve that system is you can have a micro service looking for Destruction transactions and matching them up doing a query in your database to see if that's affecting one of your indexers and then making changes to that indexer live so I'll normally do that through a microservice architecture so I'd have one looking for destructs if it destructs happen send a message adjust or uh cancel my indexer for a period uh the great thing about the blockchain is the dot is always there so even if you miss a few logs you can do that historical query and rebuild your data set uh yes [Music] yeah sure um the advantages are sort of okay so specifically to the graph I would say is that uh there isn't a lot of functionality I believe but please do correct me if I Wrong to do queries across different subgraphs at least currently average okay um that was definitely one use case when I built them oh okay um I mean okay so number one I would say in general is latency you don't have to wait on any graph note operators to fill up the graph for you second of all uh I can create a graph that is well a graph sorry a data set that's infinitely more complex uh than what I could do I mean I can theoretically do anything on the graph but here I have very close-knit control of exactly what my code is doing and what I'm going uh what I'm putting through uh sort of third I have control of my own infrastructure so I'm not dependent uh the graph is decentralized in a fantastic protocol um but having your own data set with your own database that you know exactly what's happening on is extremely useful um fourth uh you don't have to pay it's free um yeah I guess that's like some of them um but really my main pitch for it is that this isn't that much code it's not expensive to run it's mainly really just doing HTTP calls you can run this for free on any cloud provider on like the E2 micro or whatever the AWS equivalent is you can run it on the free tier Super Bass has free postgres databases you're running your own infrastructure uh creating your own dap um and it has no cost to you whatsoever uh yeah anyone else yes so uh yes there is a way to handle this and uh you can subscribe new so there's a function called subscribe new head inside the get client and every single time there's a new blockheader or an uncle you'll get a message there so you can make a service where you're looking for uncles it'll give you the information you need and then you can uh look at what that Uncle did and it should produce new events and it should tell you like the removed tag for the event for the Vlog so you can retrieve so when your block hash gets Uncle like uh let's just assume that you detect it properly through subscribe new head you can re-request that block through the block hash and then it'll give you uh inside the log field a removed field which is a ball to tell you if that log has been deleted or not and if it has been deleted then you can mark that in your database you can delete the row or you could it depends on your private key uh sorry not private key uh your primary key setup you can delete it or change that variable to true that it has been removed to mark that it's not uh valuable okay looks like we might throw Rabe here instead uh yeah anyone else yes sort of Hardware that you need um it's so I'll say like for a couple different components uh from a database point of view absolutely um it depends what sort of service you're running uh how quickly you want to retrieve that data but in terms of storage uh foreign gigs for the database the more difficult component is if you want to do that historically for every single block number you're going to run into hiccups with having nodes requesting their data from nodes so that's going to be very expensive if you're doing that through Alchemy or inferior or one of those node subscribers where you're paying per call and if you're running your own node I would say one isn't enough if you wanted to finish like this Century so what I would do is run you know whatever 20 nodes uh put uh hook them all up through historical data so you can use snapshots now so it's nice and easy to set that up and then have a load balancer and distribute out your calls into the different notes and that's probably the quickest way to do it uh in terms of the actual indexing um pretty lightweight I wouldn't really worry about it the way I normally run it is have a kubernetes cluster and then just Auto scale as I need it uh yes okay um okay uh it really depends what your application is doing but what I would say is that uh for long-term use I would recommend a relational database system so SQL um just because you can get a lot more use out of it and if you're storing the data long term you probably are imagining some use cases that you don't have yet no SQL I would uh suggest for when you need really quick retrieval of that data um but in terms of sort of data strategy a pretty common one that I've been successful with is uh time partitioning my database um for those who are not familiar uh partitioning is sort of uh imagine you have a CSV and you have a huge Excel file now instead of having this huge Excel file that I have to search through I break out the Excel file into like five different files and I Define them by a range and now I can just search through that range for a particular transaction so there's lots of time partition databases but I would time partition your data if that's relevant and then create indexes um on everything the regular blockchain does and also anything of direct interest to you so just like a concrete index so whatever you want like block number plus the value of some variable plus like topic zero hash for example um also another good thing to do is to break apart uh into different tables your events um yeah I think that sort of goes for best retrieval um obviously also if your database is getting huge um also separated out into different nodes so you're not paying uh for like vertical scaling um oh the other one I didn't mention is graph databases I haven't seen that much use for them um I haven't used them myself sorry but that's also an extremely powerful way to store your blockchain data so I can see the relationships between different addresses or I can see the relationship between for example like oracles and the Ave Market um yes thing for indexing um so the different channels uh I mean it's paralyzation but essentially I don't have to wait for one request to get through before I do the other one so it's very very useful so I'd say if you're doing the Subscribe filter logs method when you're getting one event at a time you're probably absolutely fine without using a routine but if I'm doing the filter log method and I'm requesting a huge amount of logs at the same time and I have additional calls to do on each of those that's where parallelization will really help you out uh you'll be able to make you know thousands millions of calls at the same time instead of one at a time you're going to be cutting down the amount of time you need to index from uh whatever weeks to hours foreign yeah you can insert more than one row at the same time I could run uh multiple index programs for example from like block range zero to 100 100 to 200 300 to 400 and they can all insert separately so I'm finishing that index far quicker than if I have to go from zero to four hundred on one routine or one program uh yes um yeah I mean look node providers are fantastic and highly professional so uh you're going to get amazing Service uh and you're not going to really experience much delays there um but you can set up your node in gcp and you should not really have too much more of a delay uh the bigger risk of running your own node is if you make a mistake or you're missing a Geth update a lot of the manual stuff you have to do around managing your node is automatically done by node providers while you have to take care of those operations yourself I see data okay uh mental data yes uh are you trying to do like Arbitrage or something somewhere okay uh one thing that you can do is that you can run multiple nodes in different regions because the mempool is not necessarily synced between all nodes at the same time so a popular setup is to run three or four nodes in different regions and they'll have different peers and then you can congregate that data uh yourself like through another process and that way you'll get a much more uh complete view of the mempool at like block execution time yes all right um how much sorry I have like five more minutes uh anyone else what okay fantastic um yeah thank you for listening uh here are my details thank you um here are my contact details uh please also grab me if you want my telegram I'm always free to chat and I'll tweet out a oh sorry uh I can't control that that's somebody else uh I can just come grab me um I just need to get out of the way for the next presenter um yeah please just come grab me I'll have the GitHub repo tweeted out it'll have basically just plug and play for your indexer thank you guys [Music] foreign [Music] foreign foreign [Music] foreign test [Music] [Music] [Music] [Music] thank you foreign [Music] [Music] [Music] [Music] foreign [Music] [Music] [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] thank you hello everyone I think we're good to start so welcome to the uh Workshop which title is testing smart contract since waffle and my name is Barta krutkovsky I work for trufi and I'm also one of the contributors to the waffle open source library and I'm gonna take you through some of the key features of waffle and we're gonna code some stuff together so this is what we're gonna start with as the Internet situation is not great uh everyone that want to go through the tasks with us and I recommend cloning the repository right now and going so in the readme there is going to be a small section that's going to describe what you need to do basically it's just installing the dependencies and doing some few basic steps so yeah I'm gonna wait a second for everyone to do that I okay the URL is going to be visible also later on so um moving on um there are two basic approaches to testing smart contracts one of which is testing smart contracts with other smart contracts which has its very nice properties but also the other approach is to test smart contracts with JavaScript or typescript code and that's something that we're gonna focus on it has some nice things about it so first of all it's very easy and intuitive so it is very fast and which is important if you want to test drive your code or if you want to make sure that the tests are being added to the code as it as it's being created all the time it's also very very flexible I would say even more flexible than testing solidity with other solidity code and it's also kind of de-up native in a sense that you interact with your smart contracts the same way your application is going to interact with your smart contracts later on um and then moving on to the waffle itself which is a library that utilizes JavaScript and typescript and it takes a very very minimalistic approach so it's not a very large framework that forces you to follow some certain rules but it rather provides you with some set of utility functions that just help you with the largest pain points also it's blazing past as for the JavaScript or typescript library because some of the solidity testing can be a little faster but as for a typescript framework it is extremely fast it also has a very nice and friendly syntax and it obviously is open source so anyone having any issues or any problems can reach out and also if anyone has any ideas what we can improve then they're welcome to do so um and also what is very important that waffle uh works well with hardcat so if you are already using your hard cut setup then you can use some of the features of waffle as a plugin to your hard cut setup so you can use either waffle Standalone as a complete testing solution or as a plugin to hard cut which is very nice as well we're gonna focus on using waffle Standalone but recommend checking the documentation for the hard cut integration as well and what waffle actually does so it goes you it takes you through all the steps of smart contract development so first it helps you compile your code uh nevertheless this is Piper of solidity or solidity for most people it's probably going to be solidity if you are team vitalik and you prefer Viper then um yeah you can use Viper as well then you can deploy your code whether you want to actually prepare a deployment script for the mainnet or some other actually working Network or just deploy for the testing purposes and then provides with all the testing utilities like matchers fixtures and smart contract mocks I'm gonna dive deeper into that later on and what are the waffles components it's typescript obviously with type chain it's Mock and chai which are JavaScript libraries for just JavaScript testing but we utilize them here as well and ether's JS which is a very nice library that wraps all the complexities of interacting with the ethereum network so now what the whole process um looks like so first we need our solidity code in this case this is some solidifile called exchange dot solo which is some smart contract and then we need our configuration for Waffle this configuration that we see here is not actually a needed configuration because these are all the default values so you don't need to create that configuration you can just like skip completely this the step that is this step but mentioning this if you want to have something custom and then we run a command which is just invoking waffle and Waffle will produce the bytecode the ABI which is going to be helpful when interacting with smart contracts and a flattened code which is helpful if you for example want to verify your code on etherscan or a similar similar site and then the smart contract deployment itself which is extremely simple so basically you only need to import the the artifact from the solid from the smartphone compilation and then you need to use the deploy contract function and super easy first argument is who is deploying second argument is what is being deployed and the third one are the arguments for the Constructor of the of the function uh important thing to notice here is that the token object that we are creating here which is the instantiation of the of the of the token is tied to the wallet that deployed the the contract so whenever we're gonna be interacting with the token we're going to be interacting from uh from the wallet so the wallet is like the default center of the transaction and we can change that by just connecting the contract to some other wallets so by invoke contract.connect we can have some other person some other wallet interacting with the with the contract foreign thank you I think I'm gonna find some charger or someone will help me with that thank you thank you very much uh yeah that's that the computer is a low battery um Moving On Moving On so now interacting with the network so there are basically three pieces of the interaction between the user and the network as a whole so first we have our idea or a testing Suite or a script and that's the app or whatever else uses a Json RPC interface to talk to to interact with an ethereum node which is like one of the nodes from the ethereum network and we're gonna break down all these like three pieces and how sort of to wrap all that so it's so it makes sense from the developer perspective so first of all we have the node the node itself usually instead of talking to the node or talking to the network we use some API like in pure Alchemy OCT or a default provider injected into the browser by the metamask but also we can use an emulated Network like ganache or or a bit Larry VM or whatever else that is just a local institution that simulates the behavior of the ethereum network or we can run our own ethereum node at B and the hero of the community which I obviously recommend but I understand this is not the case for each solution and then when we have the Json RPC level we need to wrap the Json RPC complexities with nicer functions so we have two libraries two main two two major libraries that um that help with that one of them is ether's JS second one is web free.js actually web3.js is older um ether system like the preferred one by by me myself and a lot of my colleagues but just to mentioned about that that there are two of them at least um yeah and what ethers JS does is that basically it wraps the whole management of the keys it helps you construct the transaction so as we see here we have the private key then from the private key we can create a wallet object and then we can add a provider of the network so sort of connect the the wallet to a link to the particular node to the particular API of the of the ethereum network and then instead of just constructing some very bulky Json and creating a HTTP request and sending that to the node we can just use like like a simple call like wallet.getbalance and we'll get our balance and the inters.js also helps us override some uh some additional properties of the transactions so with liters.js we cannot only construct like a basic transactions but also override gas limit and non's value chain ID whatever else and then if we construct that the wrong direction this is like the very bottom line um we can just add all these overrides and perform like a very custom transaction and now we dive into the actual features of the of the waffle because right now we are sort of discovering the whole environment that's around around the uh the core of the presentation and what waffle can do on the testing field so first of all we can have like a basic testing so we can just invoke some function or we can have some value and we can demand equality so first equality button necessarily it doesn't necessarily need to be equality we can just we can also have we can also expect the value to be within a range of some values or to be close to some value which is kind of dangerous because obviously in the smart contrast we want everything to be super sharp and super precise but in some cases for example if we are doing some calculations based on time and this is not going to be super precise and you can use something like this then we can test all the events and that sort of corresponds to what I was talking about um when it comes to the de-up nativeness of JavaScript testing because events are not crucial to the logic of the smart contracts it's themselves but very often they are super important from the the app standpoint because we need to be notified about some certain action that happened and we can test that very easily with waffle by just expecting some transaction to emit um an event with some arguments or like emit multiple uh events or whatnot we can also test external calls so in this situation this is a very simple thing because we just call a function and then expect the function to be called but we can have a very Advanced use cases where we have like a contracts calling other contracts and then we can check whether some particular contract within the whole call stack was called by some other contract with some particular arguments which can be quite powerful and allows us to check some of the complex cases of many smart congrat interactions then we have the reverts which are also uh super cool uh super uh in my opinion syntax is super cool and which are obviously super important to test so first we can just test whether something is reverted but we can also be very precise about the uh reverting reason so the what the what the error is um and also we can which is one of the newest features we can check the arguments of the revert that's one of the newest features of the solidity and we have the reflection of that in Waffle as well then we have wrapper for the token balances as this is something that we test very often so we can check whether some transactions modifies balance of some tokens um on some wallets and so we can do this for just one wallet that we expect some transaction to modify the balance of a token overall it of particular value or we can perform that for a pair of wallets or a triple of wallets or whatever or whatever else you can also have mock contracts so mock contracts are just like a artificial things that pretend to be smart contracts so we can set up a mock contract deploy deploy a more contract and then very easily Define the behavior of the mock so basically just say that mock when called when like a particular method on the mock is called is going to behave in a certain way so this is gonna return something or it's gonna repair it we can also specify the arguments and we can just basically uh model any behavior on the on the mock and then the example of the usage of the mocks would be like this so we have the some setup that would retire in contract and a mock your C20 and then the mock we sort of like program the mock to return um to return some value and then we can for example check whether our contract correctly reacts to the value returned by the mock so in the first case that our contract after examining the mock will return false or in the second case it will return true because the monk just Returns value that we expect or do not expect um and the last major feature are the fixtures so this is an extremely powerful thing because normally when we have like a set of tests basically like a good rule of testing is that all the tests should be uh should be shouldn't depend on each other so each test should have like a separated setup we should be able to change the order of the test and everything should still work so basically what fixtures allow us is is sort of reverting the state of the blockchain to some other state from the past so basically we can perform some setup transactions deploy some contracts and maybe perform some initial transactions and then save that as a fixture and then revoke the picture fill the fixture in each test so each test starts with the same state and we do not need to redo all the transactions and perform all these transactions again we just sort of point to that state in the past that we want to sort of start from this from this particular moment and and that that actually is one of the things that make waffle so fast um because yeah and now this is going to be like a first full setup of the tests so uh actually this is this is going to be shown also later on sort of a cheat sheet when you start coding but here we can go through the whole the whole thing so first we need to import the stuff from chai that we need so we need the expect utility um that's as the most important thing we need to type from eaters that defines contract and then from ethereum Waffle we want a deploy contract function we want a mock provider function which is the the emulated Network that we're going to be using instead of the actual ethereum Network in the tests and the solidity which is just a object that contains all the all the custom matches and then we import the contract itself so we inject the solidity matches into the chai itself and then we can start writing our tests so here we can see that we created this provider so we create this emulated virtual Network then we create some wallets in this case only one wallet which is called Alice we create some contract and then in before each setup this time we are not using fixtures we just deploy the contract and then we can have like a in this case free tests that just assert some certain properties of the of the contract yeah and now let's time to it's time to dive in uh so we're gonna have a two difficulty tracks and so first it's gonna be like a beginner track so you can use already uh done a smart contract code that we have in the repository that you downloaded or you can go through the advanced and difficulty track so basically start with an empty smart contract and test drive your code so um this is an interesting technique that instead of just writing the code and then testing whether the code is correct you first write the test see that the test is failing so you are make sure that the contract that you are testing does not have this particular property or this particular function and then after you have the failing test you implement the smart contract logic and then see the Test passing and then do a necessary refactoring if you need and then repeat so go on to the next property of the contract that you wanna that you wanna add and what we are going to be working on so the first task is going to be to create a very simple splitter smart contract so a contract that is gonna have a split function and when uh and when some if is going to be sent to that function uh while copy while the well the this function is being called it's just going to split The Ether in half and send to different addresses and it's gonna revert when the value of the if is gonna be zero and if the value of the if is not dividable by two then we're just going to refund the reminder and to the original sender and we want to write the test for that and task number two um which is that they're gonna be sort of actually uh quite a few quite a few of them and you can you can do them in in a new order so first at the proper event when the split happens so just signalize that the split was called with a with a particular result we also want to signalize whenever the non-zero remainder was returned because the um because we have that without we have that function as well and we also want the owner to be the only person that is allowed to use uh to use the contract so the split is going to have a restriction that there is only owner the only one owner who can um who can split the The Ether using the contract and then we can also use a dynamic array of addresses so maybe these are not going to be set for good in the smart contract but they are going to be um but there are going to be arguments of the function and maybe we're going to have like more addresses than two maybe three um or for or just a dynamic number of them and of course we want to create tests for that so and that's like a cheat sheet that I'm gonna stop on so first QR code that you have is a waffle documentation that should help you with everything the bottom QR code is the repository that we are going to be working on on the left you see the list of the tasks that are to be to be done and on the right you have a you have a sort of a basic template that shows you what's the general idea of that of the test and how they more or less should look like um yeah so if you have any questions or if you need to or you need help with with something then uh feel free to reach out I'm not the only person here to help I have Daniel chameleon from my team here as well so if you'll have any any problems or any questions uh we're here to help you okay should I add something and yeah so are there any questions do I need to repeat anything is everything clear okay by the way a question um were you guys able to download the repository Because the Internet situation is not great so if anyone was was downloading it was yeah okay I see some thumbs up so so I guess there was a success okay cool oh that's uh that's a good point so actually I'm gonna switch from the presentation uh oh nice so here's the repository this is what it looks like so the first thing is the contracts folder here there is The Ether splitter the empty one so if you go for the solid implementation yourself then you should start your work here if you want to use the already created contract it's gonna be here The Ether speed are ready and with the split function it doesn't have all the features from the task 2 you can add them later on and then the test section so first there's some reference in the in the templates file and the tests themselves should go into the ether splitter and the tests where everything is set up and here you can also see that we use ether splitter so we import the the empty third splitter if you want to use the already created one you should just swap the name here from interpreter to either speed already which basically would be just uncommenting this line and then commenting this one and that would make the change for you okay uh yeah read me that's uh that makes sense uh so actually I'm gonna okay so first of all you need to have the node installed and which I would guess that most of us you should have that installed already and then you will need yarn to install the um the repository if you don't have it then here's command for you to run so we install yarn and then plug in the repository entering the repository directory and installing the uh installing the repository and then the two commands that you're going to be using more frequently yarn build compiles the the code and the iron test runs the runs proper tests yeah and also some documentations link um if you need something okay so I think we're gonna give you some time now and uh actually I think in a few minutes maybe we're gonna do some live coding if someone's gonna be lost and show you some of the things that are here uh but yeah but for now uh giving you some time foreign [Music] yeah that might take a little time unfortunately like with npm it would be the same but yeah I hope it's gonna like take a minute or two and then it's gonna install everything and yeah okay foreign foreign there's a question here uh maybe someone can go and help a bit by the way in the meantime as we are waiting for uh for the repositories for everyone to install have you guys used waffle before or some other testing Library what what you've been using I'm just out of curiosity if you've been using anything cool yeah thank you yeah I absolutely agree so the the testing Frameworks like like a Foundry it's super easy to test uh like you do like unit tests which of course you need to do this but but at the end of the day you want to have like a very complicated interactions and maybe multiple calls multiple transactions so on and so forth and it's easier to do that with the hard cut or waffle um yeah so sort of like from outside of the solidity itself technology I'm gonna go closer Webster so okay so I'm Jen I don't know what there's a kind of panel stuff like that apparently yeah because I'm just waiting for an install in the independence system anyhow um uh well I really interested in writing some tests and when it comes to web 2 there are tons of the methodologies and tips for writing tests right so um kind of um kind of uh for example this is writing um kind of given when then pattern or kind of um or PDD or the behavior driven test or that kind of things so that kinds of the things in web too so when it comes to Webster it seems like the security is also the important so I think that the um uh the mental model for testing in Dion web3 uh world is really important so I think also I really wonder you guys are thought in Beyond testing especially in the Webster world yeah absolutely so I think that one super important technique and sort of like mental model around like not only testing but the developing smart contract as a whole is is that test driven development uh because uh like when you're like writing a so I'm actually gonna stand up so if you are writing a solidity code it's super important that the contract actually does what it needs to do so that you don't have some unnecessary lines that you don't have any things that were put somewhere and you thought that they're going to be useful but then at the end of the day they ended up being not useful that all like cost gas and and this is all you know like a bloat that that needs to be reduced so it's so a very nice technique is to actually test drive your contract so actually write a very explicit expectations about your code and Define what you wanna what Behavior you want to achieve from the from the contract and then Implement only the code that uh that sort of like performs the logic that that does it that is required to um to fulfill the sort of to make the test pass [Music] yeah and then you need to go like through the whole stack so so there is sort of no no differentiation like whether you should use unit tests or integration tests or or some other type of tests you probably need to use like all of them so like you like it's the easiest to just test drive your code using uni test so that's these are going to be the tests that you're going to be writing you know like most of the time and then if you like test drive all the functions test drive all the you know like small bits of the logic that that you need to put in place then you probably want to move on to the integration tests and see how larger transactions how like more complex cases resolve how performing multiple transactions in a row affects the state and sort of like how you know this whole thing behaves and that that's sort of also not the end of the story because then you need to have like the whole or you should have the whole like test net deployment you should play around with the whole thing you need to uh you also probably should develop like the up or the script that is meant to interact with the smart contracts in parallel to the smart contracts themselves so all of like these two like remain uh in sync [Music] um yeah [Music] I don't know if there are any other tips that I can think of maybe someone can add something okay actually maybe someone has any any more questions and yeah [Music] oh yeah microphones coming is there Viper support uh yes so basically uh the only thing that you saw on the for for Waffle the only thing that's uh is different for for waffle and and the Viper is that you just need a different compiler and then you basically end up with like a the very same compilation products which one is like the byte code that's just gonna go straight to the to the to the chain and the and the API um and all the abstraction of you know like wrapping the the calls with lucky there's JS is also you know like the same for Viper and uh and uh and and solid so yes definitely there is a there is Viper support um you just need to use a different compiler which is also like I think you need to specify in the waffle conflict config that you are compiling not solid but you're compiling viper well that should be it I'm pretty sure this is somewhere in the documentation I don't use Viper personally so I'm not very familiar with that setup but yes I preserving this part so uh can you also expand the discussion about testing in solidity and testing outside solubility because that's that's kind of a Hot Topic with other Frameworks like Foundry that they use uh solidity and they have you know limitations or things that are uh that need to be work-rounded what is what is your view on this sure so actually uh I think that the main advantage of of using solidity testing is uh the fact so there are two things okay one is the the pace so the the testing and solid is definitely faster and and just having everything inside of the of the evm um just makes the test run faster so which might be important for some people uh and it is sometimes actually important if you want to you know like run the tests very frequently which makes sense and you should do that so this is this is a nice property but then like if you have like some continuous integration system on your repository then it's probably not that important because even like the JavaScript tests are not going to be that long so that's that's one thing which is which is just the performance which is which is better on the solidity side and the other is uh the fact that when using like typescript or JavaScript test there is this Json RPC middlemen and there is also like casting of all of the types so for example the when you call a function and then something is being returned this is like a some Json and and the big number that's being returned from the from the solidity or Viper code um is just a very large number that's not able that JavaScript is not able to process so you need to cast it you need to have special types and there are times when it was actually a problem that there were that we didn't have like a good implementations of of big numbers and some people were just casting to Strings then comparing strings and this wasn't great um but now I think that it's not that much of a problem anymore of course like we you have all the native types and Native type compatibility within the solidity itself and while using JavaScript to typescript this is sort of external and in some casting so on so forth but I think this is not that big of a problem I think at the end of the day uh the bigger difference is uh like sort of uh collapse to to what you just prefer uh from the sort of developer experience standpoint because I truly believe that both of these approaches can be um can be just very precise and can really you know clean your code from from any bugs or or any or in errors and and are just you know like yeah both very good yeah um have you put yourself or something you're actually testing the user interface so you're basically doing the same UI testing web2 because solidity by executing it for example through a browser yeah actually yes I think I haven't been reading this kind of tests myself but we definitely still do tests if our front ends with a typical like web two tools that even just you know like display the whole thing and then like click into like the particular like virtually like click into like the particular sort of uh components and yes and actually perform transactions though in this case we would need uh something that would just work very fast so we as a ethereum network we wouldn't use like a test net or a magnet of course of course but just an emulated Network yep I might try to expand so we what we do in true file we run the whole local uh blockchain with financial hard hat we also run a local the graph and then we run the front end and click through the front and send you the transaction through metamask on this local network so this is what we do but it's separate from Waffle right okay hey guys did you manage to download an Instagram build Etc yes hit it and how is it going yeah so my proposition is we are going to plug in a different computer and Live code with you and if you didn't manage to download it you can come here and like we can do it together so it's more interesting and some people don't have computers so you can do it with us here how does it sound great yeah so let's start okay so I'm swapping the HDMI to some other computer and we're gonna Live code yeah and let's start with this task one and chemical you understand yes all right guys so do we have a volunteer to start the first task we'll go the harder track yeah so come here and pick a round of applause for our volunteer yes so task one is we have a empty empty contract empty test and we starting with writing test for one like functionality of the contract then we write the the function in the smart contract and then the test should pass so some technical problems give us one second we're basically yes by programming for for now but here I'm up let's remind the exercise yes so we want to write at our splitter so so just a simple exercise we take an intervalue to the function of a smart contract and divide it into two addresses and make sure to return the remainder if it's an odd value so just something simple hey guys can you see the text great so we need to add another another set of second time if my mother and it will test the leader function right okay so we are going to start from the first test I just want to see how the button looks like right now it's Peter splitter and empty I guess we just have to call the to sorry this is called um we have an instance of splitter balloon so take a look at line 30 41 yeah there's bit already deployed there are addresses to be used here we have an instance of splitter and we have some accounts like Alice Bob Charlie and David and we have to catch the value right does it return something no it doesn't so you want to test the balances of the accounts before and after it comes from there [Music] yeah because right now you use the eater splitter which is not implemented take a look at that contract right here um this one yeah right now we use this which is not implemented yet do you want to implement this or do you want to use the implemented one let's let's implement it okay yeah so that's normal that's when we do like tdd like test driven development and we want to call some function and see the results of the function then we just like have like error and we need to First create a signature of the function let's maybe let's start with just the uh the function let's make the test pass Maybe let's build functions skip the return just make what else looks nice we can save it and then build right and then run our tests see that it works foreign building terminal so can you please and probably yeah here we use yarn so yarn build so now we are combining our spark contracts with uh with a waffle and could generate types with type chain and now we can run yarn test to see that our tests are passing foreign let's see yeah for now great it works so now let's maybe here we have like this split and now what we want to see we want to see that as a result of split some balances will change so what should we put here we have what addresses we have Charlie and David as those two yeah so we have Charlie and David these are like random addresses and as I understand we want them to get let's say let's send one a third either to split and splitter and then expect these two addresses to just before so let's say that so that is the Charlie and maybe David zero before so maybe let's start with just one address this Charlie okay so we can do like proper tdd which is just start with simple example and then go to more advanced ones so right now what we want to do is the first check that the initial balance is equal zero then call this split splitter and split and then let's expect for example this this balance to be equal one okay let's be ten into five and five right okay with this one right yeah I'm gonna I'm gonna instance a big number for uh that expresses one token so I'm talking um okay you will need to import big number okay it's there it is actually you don't need big number you can do it differently you can use a properties of eaters you can call no no not like this you can leave it can I show you okay yeah foreign let's import eaters and now one token should be one eater right but you you probably want to move it higher so you can use it in this split function actually all right maybe once again because we want to pass this as a value so these are those overwrites all right yeah the function doesn't receiving yeah so this would be this message value and foreign [Music] we can just divide okay and it should pass okay our terminal is broken our Visual Studio code is broken yes all right okay it doesn't expect that what if I do try to do this I always confuse this book really you know why is it complaining okay oh yeah yeah it's because it's not payable in the in the actual code to build reducing actual TV wait so you want to build because we changed the smart contract so we need to build it and then test it I'm used to use it alongside hard hat so it's just one command but okay we're on a red test so now we can implement it nice okay do you want to break or do you want to continue um let's continue okay let's go on so we should yeah so we need those two addresses so you can either take them in the spring function or take them in the Constructor yeah the two addresses that will be splitting yeah it's hard for them let's keep it simple because we only have right so just so it was Charlie and Bob yeah [Music] yeah thank you we're going to take the two addresses that we split uh in the Constructor foreign [Music] I'm going to start yeah so we have a Constructor with two addresses and we'll be splitting the funds into those two maybe you can start implementing the split right way we have the message value so we'll do address one let's transfer or send a message value is the amount that was transferred through the payable function and gentle test yeah so this will be half of it right only two okay what's going on this time yeah yes it's from okay I'll call this honey just hang again not yet but it's hanging so we don't have a lot of time but if anyone would like to continue we'll hang around somewhere here we can help  it's frozen if it happens okay guys we need to we need to finish so we didn't manage to do a lot within a short period of time and not very perfect Internet situation but if any one of you wants to continue then we are here like outside of the outside of the room and we have our booth so you can drop by we can talk and we can help you to uh continue with everything so yeah thanks a lot and see you around foreign [Music] [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] foreign [Music] foreign [Music] thank you [Music] [Music] foreign [Music] [Music] [Music] [Music] [Music] thank you [Music] thank you foreign [Music] foreign hear me okay yes that sounds good all right uh hello everyone uh I'm Eric marks uh I am the lead engineer of uh metamask snaps at this Workshop is called getting started with metamask snaps I realize we have some Wi-Fi uh ishma since 2018 uh snaps was first announced as a concept uh three years ago at Devcon in Osaka uh so I know we have we have some returning guests with us today in the room and uh you know since then lots of things happened covet happened 2020 happened but since uh 2021 we've been working on snaps full time uh at metamask and since the beginning of this year that we have been in a developer release via our Canary version of the metamask extension uh called metamask flask uh and um this Workshop is basically like the sort of snaps 101 how do you get started like developing a snap at using one of the newer apis that we developed um if you read the instructions there's a custom build of metamask to download because we haven't shipped this API in production yet it's coming in the next few weeks um but uh before continuing uh we need to talk a little bit about what is metamask Maps uh and we're gonna and we're gonna start from the very ground level and build up from there and so metamask uh as uh all of you probably know uh is a non-custodial cryptocurrency wallet for ethereum uh you enter your secret recovery phrase into metamask you can derive your at your keys in your externally owned accounts and uh it will manage those keys for you encrypt them with a password uh metamask allows you to interact with ethereum via an RPC uh endpoint by default we use our friends at inferior but you can add whichever ones that you want and that allows you to do stuff like you know send transactions from account one to account two uh the really powerful thing about metamask is that it enables you to interact with ethereum dapps and so that is through our window.ethereum uh provider object that we inject into the web page and that is what all apps use in order to submit Json RPC requests that are either handled directly by metamask or art contract accounts um what about uh you know zero knowledge applications and non-etherium cryptography so like things that use curves other than SEC p256k1 uh and that's just like a a sample of the things that's being built in ethereum that we don't support out of the box and that you know doesn't even get into Cosmos polka dots Avalanche Solana whatever um in addition to uh to those things and so uh it is uh uh we believe basically impossible and I think you know practically uh like empiric like I observe this I don't predict it it is impossible for any single organization to uh add support to develop the domain expertise to understand all of these different protocols and Primitives and then also to develop the code and maintain the you know unimaginably large code base that it would take to actually create user experience for all of the things that are being built in web3 and metamask snaps is our answer to this problem and snaps are simply sandbox programs that are run by metamask and their purpose is to create new user experiences in the wallet and that is to say the purpose is for them to modify the wallet in some useful way and uh the user adds snaps to the wallet at runtime and they have access to special permissions that are not available to dapps including things like key management and that makes them uniquely powerful building blocks for web 3 Developers and so using this simple model just in the past week over the course of eth Bogota and some and a hacker house that uh we co-sponsored uh with the bit down in game seven hackers have developed a CK nullifier snap uh transaction Securities map an account account activity notifications and a smart contract account wallet uh or a smart contract Account Support uh all in metamask all using snaps and uh and snaps currently in developer releases include uh starknet filecoin at Bitcoin R weave uh and many more and so and here I'll just briefly stop to say that like we're all at like this isn't a developer release so the reason we keep it in the channels is because we don't it's not quite ready to be pushed for it to be pushed to uh you know the tens of millions of people that use metamask on a daily basis uh but uh that is our goal in the upcoming year and we'll get to that in a bit uh and so uh we and so we believe that this illustrates that snaps is the gateway to all of web 3. by turning the wallet itself into an application platform only then can we invite the entire community in in order to bring their domain expertise and their passion for uh the specific features and functionality that they're interested in in order to add that functionality to the wallet and make it available to all of their users and uh with that uh we're gonna get started uh so so again uh there's the hack MD link uh for those of you who are able to access that and we're going to start here and we're actually going to I was I was too busy trying to get my Wi-Fi to work uh to clear out all of this stuff but we'll get started here in a second and so uh so as I mentioned the first thing that we need to do is add a custom build of uh metamask flask to the browser and uh my visibility is is the size of like the editor and the text and everything good so far okay yeah please please holler at me if not and um uh the way you add a custom build uh to Chrome uh is you simply uh get your build from wherever uh from wherever that lives and you just drag and drop it in uh your browser needs to be in developer mode uh in order for uh that to work uh so and be advised that developer mode like exposes your extensions to certain kinds of malware so you know don't put your uh don't put Main in developer mode and we're just going to go through onboarding here super quickly I'm going to go ahead and snag my throw away uh seed phrase for that and Wi-Fi permitting we should be good to go okay yes all right so now I've set up a version of flask and so the only thing uh you'll notice that's like immediately different with flask is that the onboarding is slightly different and we have a purple Fox to distinguish it from the uh regular Orange Box and uh the next thing we're gonna do is I've already done this but uh the next step is to create a new GitHub repository using the template snap mono repo uh so this uh monorepo is as a template that contains two things a uh a two or two sub-repositories or packages a website and the actual snap itself and things are yeah they're kind of loading um but um once you've pulled that down uh and run yarn install uh we can see here that should still be good that we have in our packages we have the website and the snap and I'm just going to make sure that we've installed and everything with that is good and then we're gonna kick things off by running yarn start which should hopefully not need too much network access great thank you and so this is the uh template snap interface and so you see we have it we have everything hosted on localhost and the first thing we need to do is uh connect to our snap and so first uh when you install a snap you get a permission request uh from the website that that made the request and it's basically saying hey I have the website at this URL wants to talk to at this particular snap and during local development Snaps are just identified by the localhost URL where they're hosted uh just out of uh convenience and once we've accepted that permission request then metamask will go and fetch the snap source code and it's manifest and then ask for its permissions and so here we see that this snap again identified by its localhost URL that wants to display confirmations inside of metamask and we're going to say okay to that and to try out this functionality oops excellent uh something maybe I waited too long it wouldn't be a workshop or a demo if everything just worked out of the box okay now it's claiming that everything is fine no no metrics no metrics it it won't work anyway uh okay now foreign a network issue because this was not happening when I tried this at my hotel uh mere moments ago what in this terminal perfect okay all right so it failed to add it pretty please if someone has a tether that works uh and you're feeling charitable uh we're gonna try we're gonna try something from scratch foreign yes uh please do Talk Amongst yourselves man I'll try Defcon Workshop okay you do it the local prefix is supposed to be yeah one's disabled so that's going to be the problem yeah this setup was yeah all right let's see if that works okay this is good foreign we're gonna give it another try and let's see we don't have any crazy errors in here that's fine okay oh that looks good no I have a bad state okay we're quickly gonna add this back that's fine and that's fine and that's fine that's fine [Music] very cool um [Music] uh wait oh yeah that's it that's it folks a snap a snap everyone get a look get a look it's showing a confirmation oh goodness yes yes yes okay it's real yeah yeah so so what happened here uh is I was gonna do a little I was going to mess around with this notification a little bit but uh or confirmation rather but we're not gonna do that so this is just a dummy notification for display purposes and we're gonna skip right to the source code and look at like what is going on and what is the anatomy of these things and we're going to reject that and that's totally fine uh and so if we go in back here uh and if we look at uh see we have packages snap we have you see we have like in the snap package uh there's like some regular like npm stuff going JavaScript stuff going on uh but you also see that we have a snap config and a snap manifest and then a source file and then the source file is just index.ts and so looking at the Manifest here uh you're gonna see that there's a version which you may have noticed matched what we saw in the application and then we have some information about the source so a sha sum of the bundle uh and uh some other like metadata if we were to publish uh the snap to npm which is our currently supported uh like distribution mechanism we have plans for others and then finally you have the permissions here and snap confirm is the actual RPC method uh that gets called by the snack in order to display a confirmation inside of metamask and if we actually look at the snap source code you see here that it exports a this on RPC request uh Handler function uh and uh basically the way that looks the way that looks from inside of the website so this is a file from inside of the website that you will call this it's an RPC method inside of an RPC method uh so you have a wallet invoke snap and then you pass it the ID of the snap and then the request that you want to pass to it and you see that the method is hello if we go back to the snap that is the only method that we support and that just causes this uh confirmation to be displayed now if things uh like continue working a little bit better than they were doing some minutes ago uh we're going to take this uh snap and turn it into a transaction Insight snap and if we briefly return here so we've basically we've demonstrated like we've gotten a snap running and now it's time to like replace its confirmation permission at with this uh transaction Insight permission and all that this permission does is it tells metamask uh that like oh this snap wants to provide uh transaction insights uh and in order to uh do so we're just gonna nuke the contents of this file and then we're going to go ahead and import some other stuff namely on transaction Handler we are going to uh add a package called uh utils and we're going to import some stuff from that and then we have this Handler that we need to specify on transaction and that is going to be foreign function that looks something like this and right now it's a sad function because it's not returning at what it needs to return to satisfy its type and we're just going to return some like dummy uh a dummy a a dummy insight for now oh and I think we also need it to be async yes okay and we're also just going to add a little bit of validation to make sure that the transaction is of a type that we can understand because like you know we're writing a specific Insight snap that that uses our particular domain knowledge and so we need the transaction to look at a particular way uh so if it's not an object or if it doesn't have the property data or if the data is not a string then we're going to say oh actually we're going to do this first oh wait no we're going to do just call it an unknown transaction for now foreign a little warning for sanity in case I make any typos here perfect and then we're just going to do this down here and we're going to hide that and then we need to make some modifications on the front end as well uh and on the front end so the front end is just a react application uh written in typescript nothing fancy going on there uh although it certainly looks fancy um and I'm going to snag a little snippet here with some useful constants that we are going to use because right now our problem is that uh let's see where do we have send flow when we click on the um on this button here uh it is going to call this Handler which is going to call sandahoyo which calls this hello method and we don't even have an RPC Handler anymore so that's not going to work so we need to delete that delete this and then rather than doing that we're first going to grab some accounts because we need access to the user's accounts in order to send a transaction I do need an await thank you sir thank you and then if there's no if there's no account we're just going to throw an error thing failed to get accounts actually that should even request if it rejects but you know never hurts to be defensive uh and then once we have done that we are going to then we have an account and then we're going to just send a transaction uh and we're gonna do again method East send transaction we're going to have some params that should be recognizable to many of the fine folks in this room so we have a from address the to address is going to be uh the address of a contract that is in fact deployed to mainnet but that will reject any transaction that we accidentally sent to it I just happen to know this to be the case uh we're not sending it anything in terms of value and then the data that we're going to send it to start with is just going to be some dummy uh like 0x1 and that is basically all right and now we're going to have now I'm gonna have a little fight with prettier for some reason the eslint prettier plug-in does not work as advertised We're not gonna let that stop us ha ha excellent okay now I'm going to try to reconnect and it's not going to fail to install and so we can see that like the permissions that we're requesting have changed uh because we're now fetching and displaying transaction insights that's the purpose of the snap now we're going to improve and install and I'm going to anxiously look at the background console I think it worked yes it did so now it's asking for accounts uh that should be familiar and here where metamask is trying to estimate some stuff and look Fubar okay we're using the API correctly we're slowly inching towards our goal uh you're too kind you're too kind um all right and so we rejected that and there's an error here that's totally fine that's expected we love our expected errors um okay uh so the next thing so the front end now for like this uh demonstration is basically uh is basically done uh and we're gonna go back and look at our um snap because the next thing is okay so we managed to like interact with the API we've demonstrated that we can do transaction insights but now let's actually go get some like useful information uh and see if we can um like decode uh more of this transaction than we're currently doing uh and in order to do that we're going to add a second at permission because we are going to call the four byte registry API and snaps do not get uh network access by default uh so they cannot just like call out to the network unless they are granted the permission to do so explicitly and that permission is simply called endowment network access and uh we are going to call as I said the four byte API and we have some and we have some useful Snippets here uh in order to do that and so here the this API endpoint that's simply just like the um uh the four byte API endpoint that we're going to call it has a single query parameter which is the hexadecimal like four byte signature of the uh of the contract call the call data and then we have just a useful type that we will use when we parse the results once once we get them uh this network permitting and so uh actually before I forget to do this I'm going to swap out this dummy value into something real uh let's see transaction constants Dot update withdrawal account so these are just some these are just like some encoded contract calls um that uh we to save time we encoded before this Workshop and so next we want to fetch data from four bytes and that is going to start with a fetch call uh await fish or wait are we done no we're not done because we need to uh parse the transaction data first and we are going to do uh let's see function signature is going to be equal to all right first we're going to do transaction data actually equals remove 0x so we're gonna it's 0x prefixed and we're going to strip that excellent and then the function signature is going to be at the first eight bytes of the transaction data or sorry the first four bytes uh which will uh let's see transaction data dot slice there we go uh and now we have the function signature as well and in order to uh fetch from four byte we need to do the API endpoints followed by the function signature with a 0x prefix and then we have some parameters to give this which is going to be uh get and we have just some basic headers I would already knew what I was going to do boom sweet and then uh if we failed to do that we are going to throw and we're going to say failed to fetch from four bite registry but otherwise we should be good to start working with this data and uh the result yes is going to look something like this where we get the Json uh oops and that's going to be a four byte signature an array of four byte signature results and uh then once we have that result so the thing there's one thing we have to deal with we're going to extract the actual text signature of the uh of the function call uh and uh because four bytes is not a very big space there are a lot of collisions so it might return multiple results anyone who's dealt with this with four Biden practice uh is probably familiar with this problem and we're just going to pick the oldest one uh because we need to pick something and so we're gonna see function text signature is going to be uh let's see result uh and then we're going to sort create an ad Locale compare B dot created and then we're just gonna map that to value Dot text signature and so and if there is no function tick signature then uh there is no signature for this and so we're going to say um no function signature or uh no function no results in registry for function signature and then we're going to do an early return that in the happy case uh we are going to have our insights Dot type and we are going to give that uh a try next and we're actually gonna link as well just to ensure we have no problems with that okay so going back we're going to need to reconnect because we modified the snap the live reload unfortunately doesn't go all the way into the extension uh someday we're going to be able to do that but now we see that the permissions are different we have access to the internet as one of the uh permissions now and we're going to go ahead and approve and install so far so good and then let's see what happens now [Music] this may be a lot to ask of the of the network at the moment yeah the console does get very the console there is we probably have a bug where there is too much looping happening in the background but we if we were actually if I reject this I might get a useful aha okay yeah so I messed it up uh and let's see what I messed up um yeah no the thing that was result is the thing that was undefined uh and that hasn't happened before I shouldn't no all right I'm gonna cheat let's see oh ah thank you thank you thank you eagle-eyed stranger yeah if I were um if I if I had if I had done my types better this wouldn't have been a problem would that be a lesson to everyone okay now we're gonna try that again hey there it is there it is the function signature the function signature uh and uh for for our final trick we're going to get a little bit fancier we're also going to decode the actual parameters that are encoded in the call data as well just because we can um and in order to do that we are going to add a another package called Abi utils uh to our snap [Music] spooky Workshop and that's too much yeah yeah well will it someone someone will no doubt figure out the right level uh and we have another snippet uh hey if we increase the frequency there a little bit like we can really create Magic in here uh and so this uh and so uh this uh this ABI utils package has an encode and a decode function which allows you to decode and encode uh call data and it has uh it returns values that are not Json serializable and that doesn't work because the transaction insights need to be Json serializable so this is just a function that handles that uh and we're not going to worry about what it does in detail uh decode parameters and so we are going to import encode from metamask API utils stupendous and for this one we need to now we need to do some slicing because first we need to extract the actual parameter types from the function text signature and we're going to do that by some good old-fashioned uh a string parsing and so we are going to do function text signature and it's going to be a slice and it's going to be an index of the first parenthesis plus one uh my ID is leaking that I've already done this earlier today and then we are going to split uh right because if you uh you'll recall that this looks something like a function name type one comma type [Music] so we're just going to extract this substring split on the commas and then we're going to have the parameter types and the reason we need that is because that is an input to the um decode function so then we're going to decode uh the let's see parameter types let's see const decoded equals and let's see the next thing I want is yes now I want the transaction data without uh the function signature and why wouldn't that work now hello great okay and so that's going to give us the decoded stuff and the we're going to decode the parameter types out of the transaction uh call data and just to make sure I'm going to cheat again really quickly uh normally I would have my notes off to the side so you wouldn't know that I'm cheating uh but but life is not fair sometimes and then we're gonna sit insights dot params to decoded we're going to map that with our value normalizer and then we should be now we should be in good shape oops oh I don't want to encode I just want decode all right now we're going to reconnect again so that metamask alerts our changes we're going to send a message we're going to open this up hey parameters uh address and Boolean just as we would expect from the function type and so now and so this is so obviously like we're not going super deep and like just seeing the parameters here is not super useful but the but the point that that uh we're illustrating here is that like you know this snap is pretty much aside from hitting four byte like it's a it's self-contained it uses like very basic like Utilities in order to like tell useful information and obviously we could dig deeper into the call data it's like yeah like if we wanted to uh or like fetch you know the compiled contract code and try to like say something about that and so I mentioned one of the uh one of the snaps that got built at the hackathon recently and we've had a couple of these built so far is by the community which is just like snaps that do they know something about contract security or have like a list of accounts that were addresses that are unsafe uh and will display some information to the user when they're like hey like this isn't going to work and you could just as easily uh imagine like you could even run ganache inside of a snap in order to simulate the transaction uh or like hit a tenderly endpoint or whatever like service that you imagine in order to add like useful data that you know about and that metamask does not know about uh for any given contract interaction and that is a wrap for the workshop and I am happy to take uh questions for the remaining time that we have foreign right right and so the uh so we are trying to create uh specifications for like the Manifest and the apis that we ship and so on uh we have a lot of work that I won't have time in progress that I won't have time to talk about um but like using something like wallet connect V2 to like um you know just like the the dapple just ask for the network that it wants and then metamask will go and find the snap that supports it and add it as part of like the connection flow uh so you don't have to like quality specific snap in order to interact with it and so we're trying to create specifications for those things and I can't talk it like really about concrete plans at this point but personally like my I would love to see snaps become like an open standard and like for there to be like an open source like wallet kernel uh or something that like others can build on uh in the future yeah thank you sure and I think I saw you next yes yes correct uh so uh there is so there is no Marketplace as yet if anyone wants to build their Marketplace we would love to see that being built because we don't want to be we don't want to have an app store we want it to be like a full and open open permissionless ecosystem uh and so at when right now uh the way it works is like when a snap is published to npm like if you have metamask flask you can install and run that snap and any website that like knows how to talk to it it can just can talk to it uh and so and once we get to stable uh they're like they're you know we're gonna we're gonna have like a essentially like a block list if like there are known malicious snaps and things of that nature but really in order for this to scale there is going to need to be like a Yelp for snaps essentially uh in order for people to like be able to establish trust uh in them uh because uh we do not want to be in the business of running an app store because it's antithetical to the values of web3 and also it sucks as a job um uh does that answer your question Splendid and I I think you were next also yes yes so uh so that's like uh so recently if you follow and like news about app stores and stuff uh there was an instance where uh like there are essentially two philosophy philosophies that you can use to approach it like the sort of wild garden App Store approach that exists right now and what we want to do which is a permissionless web of trust model and and so in the App Store model it basically relies on like executive oversight and like review of the tenders of the Walled Garden like for scams to not be presented but like just the other uh week I think Facebook reported to Google a list of like hundreds of malicious Android apps whose only purpose was to steal Facebook credentials uh and so even like with executive and oversight like it's it's impossible to to fully prevent scams and I think the best way that even in an app store model that you actually establish trust in something as you look who recommends this how many reviews does it have how many how long has it existed and so uh we so that's like why we want and need a market place to exist in order for it to scale to users without them getting scammed and until we get to that point our first release is probably going to have like a finite set of snaps that like at least uh you know we can uh we're confident you know our uh you know we're implemented rigorously if they're managing keys they they were perhaps audited and like we know they're not like outright trying to steal your stuff uh but like but preventing scams in a like permissionless application ecosystem is not a fully solvable problem uh but we think by building but I but but by investing in the community and then like a Marketplace uh we can get there uh uh the next question uh so uh mobile uh so we've uh mobile is a TBD it's it's going we're uh we're working on it at no timelines to announce as of yet no they so so they are uh like the execution environment is the same the goal is for a snap to be unable to tell if it's executing in the browser uh in the server on a mobile device on an abacus uh like shouldn't matter yeah that's the that's the guarantee yes yeah so so they are publicly released right now in a developer channel so like you can uh download metamask flask and just like get started with the ones that exist in terms of release to stable we're targeting early next year uh yes that is a a great question kind stranger uh and so we have like in the uh in the hack MD um there are some links at the top that lead you probably yeah no yeah it's locked whatever no it's on the hack MD which is on the slides which are accessible through the schedule like on on Defcon but uh that metamask has a repository called snaps mono repo that snaps Dash mono repo and the discussions in there are a great place to get started uh we also have a landing page on our website uh called um metamask.io snaps that will also get you to a lot of the resources but the GitHub discussions is a great place to get started uh yes um uh yes we are uh we we are in touch with Google and are working with them to ensure that uh everybody is happy and we and we don't get banned from the Chrome Store um how how much all right I I'm being asked to stop so I'm gonna stop but thank you thank you everyone so much for attending [Music] [Music] foreign [Music] foreign foreign thank you foreign [Music] before [Music] [Music] [Music] [Music] check check [Music] [Music] foreign [Music] [Music] [Music] foreign [Music] foreign [Music] chat with each other if you want but I get to a table where you're not alone at least [Music] all right [Music] foreign foreign [Music] [Music] [Music] yes foreign [Music] [Music] foreign foreign [Music] [Music] [Music] [Music] foreign how's it going so um the workshop that we're doing is uh using the graph in Dune to power on-chain actions uh my name is Christian this is Matthias and we're from component you can find us at component.fi and we'll quickly go through uh the agenda so you can get an idea of what we're doing here um so first things first I just wanted to mention that this will not be a code along we wanted it to be but some of the dependencies required uh you need pretty good Wi-Fi to download them so you'd have to run to the basement come back up uh we don't want that so instead we'll just discuss some of the things that you would have uh that you would have coded so one we want to get to know each other I think that's uh you know why a lot of us come here is to find like like-minded individuals uh two we're gonna do an overview of the web3 data stack um so give you an idea of like the different layers of the web3 data stack and how you can use them three um we're gonna do essentially an example uh that goes through uh that you would have coded along but instead we'll just kind of show you how we did it and can give you the information so you can do it yourself later um and that'll be data fetching so the data fetching process data processing and modeling so what you do with that data after you fetch it and then transaction execution so essentially a way to grab data process it model it and then have that do an on-chain action a transaction for you and then at the end we'll do breakout sessions just at your tables or whoever you're standing next to um instead of the instead of the coding element we'll just essentially design your own automation speaking with your table but we'll walk you through it we'll do some engineering instead of coding cool so uh this is actually uh my email um I don't know if you're familiar with Quest trade it's a Canadian uh company for uh for trading stocks and using derivatives I got margin called a lot uh as you can see um it wasn't that much money it's okay but um I'm not a good Trader basically um and that's kind of my motivation for for what we're doing um because I got margin called so much I know I'm a bad Trader you know maybe automating things and having uh you know logic do it for me is probably a better idea um so that's specific to D5 but of course there's many other ways that you can take what we're going to show you and use it you know across anything that's built on the blockchain okay so we want to start with everyone just kind of talking to each other at their tables um you know you can get to know each other maybe introduce each other but here's a prompt based on what I just showed you uh you know from myself and that's a time when things didn't really go your way in web 3 so that could be you know you lost money trading derivatives uh you know not in web 3 you can talk about that too a time when maybe you suffered a lot of impermanent loss or you can you can say good things too I mean um or a time when you should have sold the nft at the top you know that kind of thing um so yeah take five minutes and chat with uh the folks around you hello everybody foreign everybody okay questions yeah thank you yes the thing is there's also a very large balanced design there's also an imbalance inside thank you so who's ever whoever's talking you guys can finish up we're just gonna start in 30 seconds foreign all right if I can get everybody's attention again thank you very much so we're gonna give a little overview of the web 3 data stack uh there's a lot here and we are not gonna have everything um so absolutely if you're a you know a data protocol please reach out maybe we can add it to our slides um so we'll start with this nice little visual from Andrew Hong on Twitter um this was made about eight months ago uh and so here's a breakdown of a lot of the different sort of uh layers of of the web 3 data stack you know mostly mostly relating to to ethereum uh and evm chains so obviously you have your your sort of base layer uh where you're actually running clients uh interacting with uh you know the ethereum blockchain state directly reading logs uh call data Etc uh you have nodes as a service you don't do that yourself but you're still operating on those sort of raw data streams and you have a layer on top of that you can think of that as you know the query and data mapping layer there's a little more structure there often these things are indexed um you know they're they're um potentially you know doing analytics takes uh it takes your abis and does some contract decoding so you can actually read the the parameters and the function names instead of looking at a bunch of hex codes um there's flip side and the graph and everybody knows those um there's uh then there's sort of that layer on top and this obviously encompasses a lot of things but they're higher touch more much more customized apis um the the data might be a lot more contextualized and a lot more useful for specific applications but potentially a little more obtuse um some apis you know are that data processing is happening in the background and you don't necessarily know um so things those are things like you know covalent etherscan some you know manual tagging systems like through nanson uh and then we have a few that we use pretty regularly so we wanted to make sure they made it on there um so and a lot has changed in the last eight months eight months so people know crypto stats uh David mihai um they run like crypto fees and L2 fees and all of those different front ends they've built a little you know data processing um stack to make it easier to build front ends with uh with subgraph data uh the Dune is releasing their API we mentioned the Dune but API changes things pretty significantly uh we use the massari standardized D5 subgraphs uh pretty much on a daily basis um they've created you know an open standard for different kinds of of D5 Primitives um across chains uh if you want a little more control ethl and true blocks are are pretty great they're both you know open tools allowing you to index your own index from your own node and even the ectl data is available in um uh in a bigquery database so you don't actually have to do your own uh your own indexing if you don't want to uh D5 llama uh you know they pump out a ton of new apis and new protocols uh their adapters are a pretty cool system and then we have another one spec um they're uh they do allow you to sync your own postgres database uh with uh you know typescript Transformers uh bringing in call data or sorry bringing in um uh you know transaction data indexing it and then bringing it into your own postgres database to live beside your own data foreign cool so this is the process as I mentioned that we're going to be going through um so first thing we're going to do is we're going to do data fetching and for each of these sections we're going to talk about um the alternatives to what we're doing so to give you like a little bit of flavor um so you're not stuck with with with uh one thing uh and then we'll give we'll run through the example that we actually did um but yeah just an overview of data fetching processing modeling transaction execution so our example is using python to collect data and write a simple prediction model um so yeah the three steps are pulling each price data from the graph in Dune uh just to have kind of two data sets to to compare and to show you you know two different ways that you can do it and then using a auto regressive moving average uh model to predict price movement um I wouldn't use that uh Approach at home uh but you know for the for this presentation it works um basically if price go up uh swap usdc to eth on unit swap that's the transaction that will automatically happen obviously this was built originally as a code along so we tried to keep it as simple as possible uh a lot of this can be expanded on pretty pretty thoroughly foreign so obviously we went over that data stack and there's there's so much there um so many different choices to be made and like any other choice you're making when building a product it's mostly about trade-offs uh engineering choices so we we wanted to talk about some considerations to keep in mind uh there are definitely others but some big ones are available Fields do they actually have the information that you need to use uh the data format are you going to have to Wrangle all this data to to get it have it usable in your automations um scope does it cover the chains and protocols that you want to use are you going to have to you know merge different data streams in order to get information from Cross chain cross cross protocol um is it event driven or is it pulled uh you know flexibility can you extend the model uh stability are they going to change their interface on you while you're running your animations and break everything because for some reason we still don't Version Control apis everywhere latency if your your application requires is real time you can't be operating an hour behind blocks uh trust reliability and redundancy um open openness of the actual transformation functions so you know understanding how that data was uh was transformed from you know raw inputs to the data you're looking at now and then openness of the data itself uh you know if you want to be able to inspect the internal State can you just get a dump of the database and check it out um those are all some some pretty important things so we are in our example we are just fetching each USD price data from both graph and the and dune um of course this could be done through most of the apis that we mentioned um we like working with both tools and so this was just a nice little example of using those it'll Doon first yeah we'll start with Dune so very simple query here um we're actually just using a dune created or user created table which gives you prices of different uh erc20s on layer one ethereum and here you can see we're basically just pulling in um the the time um which we're changing to hour because we want hourly hourly price and then we're doing the average of the price of eth um over that hour and then we're doing the max price and the Min price during that hour uh for the last 30 days and you'll see this query as a query ID here that's going to be relevant in a second cool so yeah as we said we don't have access to the uh Dune API right now um if someone from Dune is here please uh let us know we'd love to use it um but uh so instead we're using this this uh open source SDK that grabs essentially the the data from a query uh it's limiting in the sense that you can't actually run the query using this so you basically you know every time you want to do this you'd have to go back to Dune run the query and then come back here and it'll update after you run this function um but yeah basically it's just grabbing kind of that that static data from the query the last time it was run then uh yeah if you just scroll up a little bit to data data123 yeah just quickly mention this it's not that significant but we're basically just changing the uh Json format that we get in the response and we're turning it into a pandas data frame uh are people here familiar with pandas data frame a lot of nods okay cool rows and Golems all right cool um and then yeah that's a good video yeah there's a little bit of processing here to get you know the data wrangled so it's consistent across both Dune and the graph uh this one is you know the the graph data pull um so we're specifying the endpoint uh we're just using the uh chain link prices a subgraph here um in fact this data isn't actually hourly data um so we first you know we were using graphql to query the graph uh we're just looking for the USD asset pair we're ordering by Tam timestamp so we get the newest data uh we're ordering descending and we're grabbing the first thousand prices as well as the timestamps associated with that uh then we do the exact same thing here except we do one thing which is resampling so that we only end up with you know one time stamp every hour or one price every hour instead of instead of multiple foreign here's just an example of the outputs you'll notice that there's actually inconsistency between price and price here that's because the Dune table actually does this in decimal format while you know the graph uh here this subgraph specifically uh looks like uh yeah eight decimal points um so uh the the fact is we're running this model separately so it doesn't really matter for this example but it's just one of those things to pay attention to obviously your data needs to be consistent yeah and one thing I'll I'll mention about that as well is um it's actually great to use more than one data source um just so you can actually check these things uh you know it's hard to know what the uh the source of Truth is so you know using different data sources check them against each other you know maybe before you run something is always a good idea and another thing is uh we didn't really mention this but um with the data we're pulling you know you know this is a simple example but the really cool thing is that you know anything on chain is fair game in terms of data that you can use so think you know lping lending protocols uh you know on-chain derivatives protocols nfts you know doesn't have to be defy related um you know you can do some pretty sophisticated stuff uh with different types of data so yeah moving into this section now so data processing and modeling um you know now we're at the point where we have uh the the Dune query and the graph query uh pulled in uh using Python and now we want to uh model it essentially so before we jump uh in back into the code um there's just a few considerations uh kind of like just what I said with like there's so much composability when it comes to data there's also infinite composability when it comes to modeling um you know you could use instead of using a Time series prediction you could do conditional logic like um you know maybe there's someone you follow that trades really well and anytime that they make a trade you want to mimic it uh right away you know stuff like that or if you know someone like me is not a good Trader you can take the opposite position um then of course there's there's so many types of machine learning algorithms time series predictions uh the list goes on and on for the types you can do and again I know we're focused on on D5 for that presentation this presentation because that's mostly what we interact with but you know if you're really into stable diffusion and you want to see text generated images uh you could always grab you know uh text from your lens protocol interactions and generate an image based on it and mint and nft on chain if you wanted to something like that you know that's really up to you because all this computation is done off chain the uh the sky is the limit foreign cool so uh quickly just on the uh I guess the modeling uh we didn't we already did the processing I guess earlier when we uh just reformatted stuff into into a panda's data frame um so here's it's it's quite simple um if you're familiar with like a little bit of data science I'm not a data scientist myself um but what we do is we basically split uh the data that we pulled in so the Dune data and the graph data and we split it into a train and test set um just basically 80 trained 20 tests not that sophisticated um and then what we plot it and we'll show um you know we'll show the results after and then we run it through a Arma model so uh Auto regressive moving average model to essentially predict um so we're doing this by hour and the goal here is to predict um whether the uh the price of eth in USD is going to go up in the next hour and so the logic here is basically just if the next hour price is greater than the last price then we want to buy Yeet if it's less than we want to sell uh or short or what have you it's that easy folks not Financial advice cool yeah these are the results so as you can see the so the red here is the test set um and we are basically you know the prediction is basically saying it's trading sideways uh maybe I think it probably goes down about 10 10 roughly uh if anyone knows uh the crab strategy on in squeeze this would be a good time to use it I guess um yeah these are just the results thank you yeah so the most web three relevant probably the most complicated um Step uh in automation here is transaction execution so there's a number of ways to do it so bringing these insights back on chain um so there's there's tons of considerations to think about uh which chains you're operating on is the environment adversarial so are you you know if you're working in D5 then you're probably looking out for Mev and sandwich attacks anybody trying to exploit your model if you're you know minting nfts for art purposes and not for financial purposes it's probably less of a big deal that someone front runs you uh what kind of timeline are you operating on you know some things have much larger delays than others a key management do you want to manage your own Keys what kind of permissions do those keys have should your logic be transparent so you know if you're running a proprietary training algorithm um you probably want that to be executed off chain and just have the results posted to the chain but if you're running something that you want to be transparent uh you you would likely want the the you know computation to be visible on chain uh you know what happened of a transaction fails if it's or it's congested these are things that are annoying for manual transactions but if you're not taking them in account when you're automating transactions you can get something stuck in the mempool forever you can potentially end up not being able to to transact if you're not you know replacing that transaction and replacing that nonce um so there's there's a bunch of options um there are almost certainly others as well and these are not necessarily mutually exclusive they're just kind of ideas of part of it so you know libraries that wrap on top of uh you know the wallet apis that translate Json RPC ethers web 3js web 3 Pi which we're using in this example uh if you're running something like that it's probably in some sort of function that you can either be running you know locally or on a cloud um you can you know use traditional cloud service providers or you know tenderly has their new web three actions which is effectively lambdas for for for web 3 interactions to be triggered by events um keeper networks uh so you can some keep your networks support like more complex off-chain logic um some only support uh triggering you know transactions with a function signature um uh there are transaction execution Services um so something like uh open Zeppelin Defender relay and uh inferior transaction Services they handle a lot of these questions that are kind of annoying for for a small development team to deal with so things like Key Management they allow you to hook into a KMS system they also handle you know gas uh figuring out gas fees so if a transaction fails and the first or a transaction is is um waiting too long in the mempool because it doesn't have a high enough gas price assigned then it will actually ramp those up progressively and it tries to figure out you know uh how much gas do we need to be able to execute this transaction in a certain amount of time that being the variable you set uh you can you need to make the decision you know if you're not actually doing uh execution and you're just posting data to the chain then you might want to actually more like an oracle model so just posting data you're not necessarily thinking about execution then you're more thinking about on chain execution that is you're more thinking about how do I get a reliable uh like reliable posting of results to the chain you can go through a multi-sig if you don't trust your automation you could have them as one of the signers of a you know one of two milk multisig where they you know basically are queuing up that transaction send yourself a notification and then accept or reject that might be the most thing that most people are more comfortable with you could potentially run things run the actual uh run some of this Logic on an L2 um so what's the name of the uh yeah uh there's a company called uh modulus Labs uh they're doing some pretty cool stuff uh so they created this thing called Rocky bot um that basically does what Matthias was saying uh where uh they're running uh they're it's on it's on start Nets uh and they're leveraging that and just basically uh posting the result to the chain uh so it's like a neural network on chain it's it's it's very cool um definitely check it out yeah and then I'm not very familiar with Mev or you know like uh being a Searcher so I'm sure there's other people who can expand on this but in that case you're probably using something more dedicated to your building bundles using the the Builder API I believe oh yeah uh and for this example we're just using uh you know web3 dot Pi um this is probably the thing that people are actually the most familiar with uh were fully we're just you know setting some uh some variables for selecting our chain being girly we're grabbing an RPC provider uh there's some middleware that's required for for Gurley here we're grabbing a private key from environment variables which of course means we have to manage that ourselves uh and uh then we are you know executing transaction in this case we are swapping on universal v2's router um so we're grabbing the ABI uh using that to to encode our function signature and uh you know setting some parameters and and posting that to the chain cool so before we go into this um just wanted three caps so we used a subdraft to pull um to pull ethusd price data we use Doom to full USD price data and we processed it we using python pandas and then we used web3 dot pi to actually send the transaction um it's actually what we were supposed to show just putting it all together uh it's again you know three steps here really oh grab graph and dune um you know formatted data uh check with the model whether we should buy graph buy based on the graph model whether we should buy based on the Dune model and you know if both are true uh we are buying yeah and one more thing to say here is um so this makes it look easy um and that's actually what we're working on at component uh so we're working on something called blueprint that abstracts away all the stuff we just had to do although it's really fun to learn how it's done and you can definitely do it that way um and you know to see how it's done under the hood but what we do with that product is essentially uh try and take you to this step without having to do you know all the other stuff okay I guess it's me so uh you guys saw what we came up with uh now it's your turn um this might be a little long with the 10 minutes but um I'm sure everyone who came here has something in webview that they're passionate about uh that thing probably is generating quite a bit of data um and that's probably available through one of the many services we we mentioned um so we'd like to take a little bit of time uh you know explore some data sets um think about what kind of automation you could build using those as you know your input you can work as individuals or as a group to start uh after that we're going to sort of have a little 30 second pitches uh to everybody else in your on your table and you'll decide on one to sort of design as a group yeah so just to you know give you an idea of what you could do so anything in defy um where you know you're triggering you know based on a prediction model or based on some conditional logic it could be to sweep the floor of an nft collection um you know the really anything you want and any data that comes to mind that's particular to you and uh what you're doing and I remind you to kind of be thinking about those three steps where I'm getting the data from how I'm going to process it and then how I'm going to actually generate something actionable from it yeah go ahead now we should go around right foreign thank you apparently okay two questions [Music] okay um seven minutes of course thank you foreign thank you foreign thank you thank you thank you all right oh okay um I don't want to break the flow of ideas too much but if you haven't kind of centralized around one idea yet now would be time to potentially pitch and try to get your your idea chosen foreign thank you foreign thank you very much foreign foreign thank you foreign thank you all right folks uh we're happy if a few people came up with an idea and like thought about the process and I think if you did anyone come up with an idea raise your hand if you did you wanna you wanna talk about it so um we think that kind of D5 investing has been quite risky forever and so the idea is kind of a generalized pressure release valve so if a condition is met whatever investment you have if it crosses over that threshold and pull pull out you know pull out to wallet essentially so you can think of a liquidity pool you're invested in there but if the two assets start deviating Beyond a certain range then you you exit that position thank you Greg anyone else you look like you have an idea you do okay Quick Pitch here let's hear it um I'll try to make it very quick yeah what I've learned throughout a lot of uh oh a very powerful loss experiences is that you have to optimize your buys I uh that's in strategy for centralized Finance I mean centralized trading but I did it does work for defy and helping and it's basically spotting when the price hits it hits the threshold and when when it's oversold within the volunteer bands like I mean like in the in the lower part of the Bollinger Bands and you you want to do that you want to identify that buy signal throughout uh different uh temporarily these temporality um like the weekly time frame the daily time frame and maybe not no shorter term like time frames maybe the three day time frame I don't know but they're identifying buy signals throughout different temporalities using the polymer bands those the that's that's basically it oh it's working yeah you look like you have an idea no okay you have an idea okay so we discussed an idea of Auto rebalancing crypto index so let's say you want to build a simple index that's like 50 wrapped VTC 50 throughout teeth over time that balance is gonna be different 50 50 if the price of Bitcoin increases for example so maybe using some some kind of feed like that to calculate the balance of your portfolio and rebalance every hour week whatever cool yeah rebalancing I think is a is a very good use case like in whether it's you know just a simple spot trading portfolio or it's you know something a little more complicated like lping or Landing or borrowing that kind of stuff um do we have time for one more maybe we have a little time okay it's okay anyone else cool so um like um none of us were actually in device space but we actually uh thought about some author use cases um so I'm working on um a reputation on computation protocol um based upon pairwise trust like a whole trusts to him by how much and then I'm like in my output would be a bit basically the number crunching would be um like after all that over because of the calculation like um each peer in my network is um assigned a trust score right and like he's actually from the dial space and we talked about how they can actually use this on this type of algorithm in like a voting uh versus like a civil prevention typically um my algorithm is pretty good ad like I'm identifying the Civil clusters who actually trust each other but like none of the other real people actually trust any of them so maybe we can actually ingest this data and then um do that number crunching identify those civil culture and then um his dial could actually um emit something onto the contract so I sort of like those um um accounts as potential Maybe maybe like avoid them you know things like that cool thank you maybe one more if anyone has one if not it's okay anyone Keen to share Adrian you you look like you want to share you're writing your idea right on your phone okay later okay um cool yeah that's it um so we'll just wrap things up here uh yeah we don't have time for that I don't think so we'll just go to the last last slide I guess yeah if you want to run with any of these just remember to think about like we have the basic idea right now but there's a lot more to it I think adversarially where are the attack vectors um how could your strategy be be manipulated um you know uh be defensive yeah and then just to close things out um to mention what we're doing again uh so at component we're building something called blueprint and all of your ideas except for maybe the last one that sounded really cool but it was a little over my head um but very very cool um but for the D5 related stuff at least and would love to talk to you about what you're doing to see if we can incorporate that in the stack so if you have any ideas that you actually want to execute on or you have you know friends that like want to build these kind of data driven strategies um we're building tools that basically make the entire process easy so you only have to worry about the logic of what you're building um so yeah that wraps it up thank you everyone foreign thanks a lot I know it was an unconventional Workshop but I appreciate that everybody was talkative and you know engaging instead of just hanging out on their phones and things like that so it's great [Music] foreign [Music] [Music] thank you [Music] [Music] foreign [Music] [Music] [Music] [Music] foreign [Music] [Music] foreign [Music] foreign [Music] [Music] foreign [Music] [Music] check check so much thank you guys foreign [Music] [Music] thank you [Music] [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] [Music] thank you foreign [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] foreign [Music] foreign [Music] [Music] thank you hey there thanks for coming everyone I'm zero age this is Ryan we're with openc and we're going to talk about the seaport Marketplace and some more advanced techniques for how to utilize it and interact with it and build on top so Seaport is a beast there's it's a single contract but there's a lot going on and so we're gonna work our way through first start with some of the high level uh key points and then from there we'll we'll get into some of these Advanced Techniques so first thing to understand is that there are two arrays that dictate the basics of a Seaport listing or offer the first is the offer and that's all of the items native tokens erc20 EOC 721 1155 that you the offerer are going to spend then on the other end you have the consideration which is everything that you or others are going to get back if you want to spend the offer items you gotta get the consideration so there's also this idea of a Zone every Seaport order has an optional Zone that you can set that's a contract that gives a thumbs up or a thumbs down on whether that particular order is still valid there's also a concept of a conduit which is a it's a contract that you can approve to transfer your tokens so you set your approvals on the Conduit and from there uh you can set additional marketplaces or contracts on that conduit support multiple marketplaces migrate to new versions of Seaport so on so forth so when you it comes time to create an order to list your nft the primary way to do it is you just sign an off chain listing this is an example payload that you would see in metamask you're gonna have to pop open the expanded view to get this whole thing but it's got the offer array consideration array start time end time zone conduit then another method you can use to create an order is to call this function validate and that means you don't need a signature at all you just provide the order and it gets listed on chain so to speak the interesting thing about both signing an order or calling validate is you have to explicitly cancel you have to actually call and tell Seaport I'm no longer interested in filling this signatures are not just standard ecdsa they're also support for 1271 which is is valid signature Seaport will give the offerer a digest basically the order hash and a signature and then leave it up to the contract to say yes this order is good this one's not and that works with both traditional signatures as well as validations and you can use this technique to list from a smart wallet or a multi-sig without having to pay cash but you can also and here we start to get into the Advanced Techniques you can utilize 1271 to do Dynamic orders where you might have a contract that's willing to it wants to update the order based on a price that's coming back from an oracle or maybe it's implementing a bonding curve or it's a pool something to that effect so what you do is instead of giving the signature for 12.71 you actually give the order itself then and this there's a trick you can do here where you can actually Supply an offset to call data that reuses the same segment of call data that you already provided with the order and cut down on the overhead of doing this but then what the offerer that's getting called will basically have to do is rehash the order derive that digest and compare it to the one that was supplied by 1271 then it knows that the order that you gave is the signature is in fact the correct order that's being filled at the moment and then it can go and look okay let's check out this offer item this consideration item and make sure that they match whatever the the latest state that we expect is so that's a really interesting technique to to do with more Dynamic orders you got a question so this is not zones this is if you have a contract that is going to serve as an offer and so it could have its own validation Logic on the contract as part of this but it could also utilize a zone right that's very much a something that it could piggyback on validation logic in his own all right so that's creating orders let's talk about fulfilling them the standard method for fulfilling an order is to call this function fulfill order and or fulfill orders is the actual function and you basically just give this whole payload just like the payload that you signed you provided to this function and it creates an implied second order a mirror image of the first one where every item that's being offered on the order you're fulfilling you just say all right I will take that and take all of those items those are your consideration items with you as the recipient then look at all those consideration items I'll I'll send those out I'll pay them that's the the basic method but there's also a basic method which is there's a small subset of orders that actually constitute a pretty wide swath of what people are generally doing which is I want to buy an nft I want to sell an nft and maybe pay a fee Port doesn't actually have a notion of fees at all so it's everything is just another item but if you have one of these simple subsets you got a single offer item you've got one or more consideration items and you take that sum total of all the items there's one nft that's part of that everything else is a single item type it's a they're all Wes or they're all die or something like that then you can call this other function and it performs a more optimized fulfillment less call data you just need to supply a subset like give all the additional recipients which spells out um usually it's used for fees and uh on top of that the basic fulfillment methods have a slight deviation where if the offer is the item is a erc20 token or native token then it will be used to pay for all the non-nft consideration items so you don't have to take everything you can minimize the number of transfers that are occurring that's a common theme with uh you'll see uh as we get into these subsequent fulfillment methods it's all about cutting down on the top efficiency gain is from reducing the number of transfers right particularly with tokens native tokens a little different but with other tokens it gets very expensive if you're doing redundant transfers so when you want to buy five nfts you want to sweep the floor right oftentimes you'll have each one of those has a fee attached what if those that fee recipient is the same recipient you don't want to do five transfers you want to do one so we use this fulfill available orders method this basically goes through each order and says has this been fulfilled has it been canceled if it's still valid then we'll go for it if the order is not valid anymore we'll skip it and you supply the you basically point to okay this order this item that order that item these all have the exact same item type they all have the same uh ID if you're talking about 1155 token they all have the same recipient effectively they can be condensed into a single transfer cuts down a lot on uh the number of transfers there then you have this method match orders when you're talking about fulfill orders fulfill available orders seaport's not going to be able to figure out on its own how to do these transfers the way that it works is you're going to walk through every single fulfillment and it's the same idea as fulfill available orders here's the order here's an item here's another item here's another item let's let's aggregate all these together then we're going to match those with this item this item this item on these orders on the consideration side and that whole group gets distilled down into a single transfer so this method is it's not utilized as often if you just want to buy an nft this is what you really want to reach for in the power use cases where you have your maybe you're searching like you're looking for Mev where you can find a price mismatch or you want to compose multiple different orders with zones and um get them out to all fit together in a neat little puzzle piece the big thing to be aware of with this is that if there's a problem after you supply all these fulfillments it's going to go through and make sure that every single consideration item on every single order has been fully credited it's got to be zero on every single one or else the the whole batch will come crashing down it'll revert so definitely this is this is the power feature and uh the first thing you want to reach for if you're looking for searching or um or more advanced strategies okay let's talk about some zones zones is the it's the main mechanic by which you would extend Seaport any order can choose its own Zone and then say I'm a restricted order except the type is restricted now the Zone gets to decide whether or not the orders good or bad and in addition you can always extend the consideration array you can always add items as the fulfiller we call them tips this is it's cool because you can take an order that came from One Marketplace you can fulfill it on another and apply a tip what you can also do is you can use logic in the zones to ensure that the tip that got supplied matches whatever it is that that you expect it to maybe that's a dynamic calculation of on-chain royalties right something like that so let's talk about a couple potential zones things you could use them for so one application of zones is for dynamic nft metadata certain items in Seaport they're called criteria-based items and in place of giving a token ID an identifier you instead give a Merkle root and this Merkle root is comprised of all the token IDs that are valid or you can give an empty one and that signifies it's a wild card you can pick whatever token ID you want but this only gives you so much granularity because at the time that you sign the order it might have certain metadata but maybe the metadata gets updated right so the traits the attributes that that this had with the time you created the order they've changed now so you can obviously leverage zones for this anytime that a creator of an nft updates their metadata they go and they update the zone registering that hey this particular Merkel route is actually now this other one right and you can't match the tokens that have changed another potential use case is for compromised nfts you might have an nft that gets stolen and um you don't want to be able to trade it anymore and that's one potential use case for his own is to just check and make sure that the items that are part of the order are no longer fillable another cool potential use case is for front running resistance say I have a Zone where I have to call five minutes ahead of time and commit similar to how you would do it with um I believe ens has a similar thing you register ahead of time and say I want to fill this then you wait some period of time and then you reveal if you include as part of the the parameters called extra data when you're fulfilling that gets passed along to the zone The Zone then can look and say oh there's a I'm going to Hash this looks like you committed to being able to fulfill this order another interesting one is leveraging Oracles maybe I have a listing I don't want this listing to be fulfillable if the floor falls out so I could read from an oracle that is periodically updated and if the price drifts too much then cancel the order don't let it be fulfilled or you can even leverage this along with that trick with uh Dynamic orders with 1271 to create a strategy that will buy nfts below the floor price sell nfts above the floor price that kind of thing so here's some links uh we've got obviously the seaport repo itself as well as any any questions or do you want to get into the weeds the discussions uh there are great place for that deport.js is a library for interacting with Seaport makes a lot of this stuff much more straightforward one thing that I will note is that much of the match orders functionality is a little more rough around the edges would love any contributions if anyone finds themselves working on that and then this last link Seaport order validator this is a contract that we put together to make it easier for checking an order or if you are accepting new orders coming in there's a lot there's a lot of gotchas things that can go wrong um and it's a quick way to say oh this order looks like you're not actually getting anything from the order right you're not set as one of the recipients on a consideration item you sure you want to do this there's a hundred permutations of things that can be um maybe a warning or an outright error right so it'll check uh on chain registry for uh Creator information like make sure that the the tokens Implement EIP 165 that you're not trying to pretend like one one token that's actually a nft is an erc20 token something like that all kinds of interesting stuff and if you're trying to just piece together the potential uh things that can go wrong this is a great resource so how we doing on time all right I think we can open it up for discussion first off if anybody is currently building on top of Seaport and has a a sticking point or a question by all means let's let's hear them yeah here let me bring Mike over um so certain nfts have royalties associated with them and I was wondering do you include the royalties in the orders themselves or does that get handled somewhere else in the contract and if so how does optimization happen on that front yeah so the basic approach as I mentioned earlier Seaport doesn't have any notion of fees or royalties it's baked in it's just you could very easily create an order that doesn't include any fees or royalties whatsoever so it's really up to the discretion of the application layer whoever's building on top of it um one approach you can take that I think is a pretty good one is to just read from the Registries at the time the order is created this depending on your perspective is either a feature or a bug one thing that I would consider a bug is if when I go to create a listing the royalty is five percent and I'm like okay assign my listing now the Creator goes and changes that to 50 that's a problem and I might not have listed it if I knew that I was gonna have to pay that right then there's also the question of well what if they just want to tweak the recipient of the royalty or something like that for those cases you can Leverage tipping right so I mentioned earlier that you can always add additional items to the consideration array can't add them to the offer right you can't decide that the offerer is going to spend more than they originally agreed to that's that's a very important and variant not to break but um you can always say oh yeah I'll I'll give out something extra you combine that with call it a a royalty Zone the royalty Zone will go it will read from in real time from the registry and ensure that the last consideration item this tip matches what the registry has on file so then the only way you're going to be able to fulfill it is to supply the correct updated information that's sort of the gist cool thank you cool yes I have a question about one of your earlier slides so you on the matching orders slide you have this statement which you wrote something along the lines of like if a Searcher identifies an opportunity there it is so a search or identifies an opportunity you can take whatever leftover item amounts and match them to a new consideration item to itself so I'm a little confused because my understanding of the architecture is that in every single type of order or function call you make all considerations have to be met on the other side so I'm a little confused how like like in the in the case of like the classic case of Arbitrage right like there has to be an opportunity on the table for the arbitrager to take and it's not clear to me what this means for for an opportunity if the considerations are always evened out or yeah it's a great question and this is actually a good a good opportunity to get into just the the nitty-gritty on how this would look let's just consider a really simple stripped down case where you have one listing so the way this might look is I want to sell my nft right so I have one offer item Which is my nft and one consideration item we'll call it five weth okay with the recipient being me the offer right now someone else likes my nft they don't realize that I've already listed it for five what okay they put out an offer a bid on the nft to buy it and they offer six web so the weight would look for them is I'm offering six weft one offer item one consideration item this nft recipient is me so now person number three Searcher comes along and realizes that there's this uh mismatch they call match orders they Supply both of these orders and they give a fulfillment saying Okay order zero item zero is the nft order one item zero on the consideration side is also the nft these match that turns into a single transfer from the offerer A to offerer B then we do another match fulfillment order zero item I'm sorry order one item zero which is the six weft order zero item zero on the consideration side is the the five width those now match the way that this works now is that they get the the five weth gets credited okay that's been accounted for the six weth gets spent there's one with left you can actually leave offer item amounts on the table there's not there's not a reason that you have to spend all of the offer items but you do have to credit all of the consideration items so we could leave it at that you could match those two orders and the original or the the order be the person that made the bid just end up paying five but what would in practice what would happen is that this the person who located the opportunity might say I'm going to create a third order and this third order I'm offering nothing it's an empty array consideration item one with recipient is me and then they create another fulfillment that you know matches the the same one that we've just spent five from with the new one you don't even have to create a new order you can also just add on a tip to order b or whatever and use that to match too so that's the idea there other questions okay thanks um so I haven't built anything on C board but I've looked into it a little bit uh just wondering uh does it support like natively partial fill orders like is it possible yes single signed message with like multiple fulfillments yeah I'll get into that a little bit so if the offerer elects to to support partial fills it's specified in the order type just like a restricted Order In the Zone uh requires that so if an order supports partial fills the way that this works is that you can supply when you call a normal is like fulfill order uh fulfill available orders match orders those don't do partial fills but there's an also fulfill Advanced orders uh match Advanced orders fulfill available Advanced orders those you give criteria resolvers basically Merkle proofs for the criteria based items as well as fill fraction a numerator and a denominator and the the heuristic is that every single assuming that the order supports it every single offer item and every single consideration item is going to get that fraction applied to it and then once the order is fulfilled it's just going to update with the fraction say here's how much it's been fulfilled the rule to avoid any kind of weirdness around grounding errors is that every single one of those fractions has got to be exact it there can be no remainder after applying the fraction so in general when you're constructing an order that supports partial fills from the get-go the easiest way to do it is to start with a single quantity right I have some ERC 1155 tokens that I want to sell for one eth each right I want to sell 10 so I'll now just take the one eighth multiply that by 10. take all the fees that were already calculated multiply those by 10. so it'll be a nice even fraction that's applied the math behind that on the contract is also pretty cool the uses um the euclidean algorithm to ensure that there's uh if there's an overflow we can all uh be rounded down to the greatest common divisor but that's that's different topics yes there's partial fills and um and once the basically once the fraction The Fill fraction is applied and all the criteria resolvers are applied and it's all the exact same flow as with the standard stuff hey there can you talk a little bit about extra cheap signatures and when they should be used about what signatures extra cheap I see that's a parameter when you're creating an order and I think you use EIP 2098 in that case oh yeah yeah so 2098 is um the 64 byte signatures so it's a standard ecdsa in ethereum has three parameters right VR and S and um turns out that there's there's a parody to the V right it's almost always 27 or 28 right and there's basically a signature malleability concern there where you have two exactly identical or this the signatures are different but they resolved the same uh or cut they recover to the same signer the trick is basically to say what if we just always flip the parody right so you can take any 65 byte signature and you compress you flip it so that the parity is always I think 27 and then you also can because when the parity is that 27 then the S value won't use the most significant bit so then you can compress V and S into a single word you basically take what was once three now it's just two words so you cut down on a word of call data in um standard API encoding which you know you're looking at what 130 bytes or 130 gas for those bytes and uh just a minor optimization that that you can employ that's the idea nice thank you great questions everybody hey hi so I assume I'm trying to do like a searching strategy right so uh to help users with a gas uh you may take like signed orders right and those are not visible on chain so for a Searcher to like look through all the possibilities of uh orders out there that I could possibly fill with a match order where would I get a list of all the orders that are not on chain like is there a HTTP API that I could call ah so this this really um it delves into less of how loud is Seaport do it and more all right what about the marketplaces they're built on top of Seaport right we work at openc we have an API if you have access to the API then you can read from the API and and get a sense of yours there are also other marketplaces that are built on top of Seaport you might want to be pulling from those but it does get more complicated to find all of that you can listen on chain for the validate events right which is one way to do it you can listen in the mempool there's another way right so um but there is I think it's it's definitely an area of active investigation to figure out how to best um democratize that search okay thank you yeah I guess two questions on my end uh one right one is uh the seaport support swaps of nfts uh today absolutely so when you look at an offer consideration the items eth or native tokens erc20 721 1155 any combo of those Seaport is totally fine with the exception is the fulfilled basic order method does have more opinionated uh subset of the possible orders that it's going to support but yeah Seaport was built with this idea of barter like nft for nft as a first class citizen yeah just the second question I have might be a little bit um yeah of a comparison question so uh we we are right now integrated with like Xerox V3 for uh also for private Marketplace so I'm just curious uh I mean maybe you can speak to like some of the differences between C port and Xerox V3 there's any yeah yeah so first off Xerox is really cool they are definite innovators in the space um zero X is more geared around single nft like buy an nft sell an nft and it's it's actually a very good protocol for that Seaport is more geared around uh how do you how do you grow out from that there's less um less opinionated um on this what the exact structure of a listing looks like basically for the exact reasons that we were just for discussing is a top one um another thing that is different is that Seaport is totally unowned and permissionless there's no special notion of like a protocol token or a protocol fee that could be turned on it's just meant to serve as a permissionless piece of public infrastructure on chain so that is a difference um and but yeah big fans of what the Xerox team has been able to do thanks over here I was wondering if like currently on open seat using Seaport do they utilize any like interesting zones currently or um do you have to like Define that yourself as like a someone who like creates a listing on openc so uh I can't speak too directly for openc I'm I'm one of many and but what I can say is that for at least a couple of months after Seaport first went live it was a brand new protocol used a lot of assembly and and so we we kept guard rails on we used a global plausible Zone and required that all orders that were sent to open C had this Zone set on them and it would allow for us to basically hit the panic button and just cancel every single order if there was a problem with the marketplace it's now been long enough and there are enough interesting use cases for zones that um efforts are underway to really open that up other other chains off of mainnet don't currently use its own so stay tuned stay tuned on that and uh I will also say that if anyone is authoring zones or working on them get in touch let us know we'll definitely it would go a long way to help um see what zones people are coming up with and um and that will definitely inform the discussion and efforts oh we're integrating with Seaport and awesome we're having issues with signature verification where recovered signatures match the original signer but orders fail interesting okay and it's I've it's been unsolvable for me so what are reasons this could be okay so if you have if you have an order that's signed and the signature is valid right like you can recover the signature and it works there are a number of potential things that you could look into the first would be checking the order validator right that's that's going to scan through and give you a number of potential problems when you go to try and fulfill it and that's actually it's a very important thing if you are maintaining uh listings and offers you have to ensure that you're not putting listings out that aren't fulfillable right so um that's one thing to try another Seaport has this notion of a counter so every single offerer has a counter that's tracked independent of all of their orders and at any point you can just call increment counter and that serves as an eject button where all the orders that are signed with that counter are now invalid interestingly though you don't Supply the counter as an explicit argument it's an implied argument so if you have two identical orders except one has counter zero one has counter one they'll have different order hashes but the call is the same so that's one potential area that um you can run into issues the last thing I will say is that cases where there's something really sticky that's just like confusing and not um not making sense I would really encourage you to go to this discussions board both for it's a great Forum to lay out all the information and also for others to then benefit from figuring it out and so I'd encourage you to to do that but um yeah signatures are are notoriously finicky to work with and it every every developer that's that's had to work with them that there's always a sense of relief when you finally get your workflow figured out and and the signatures are working because it can be quite opaque why things are going wrong the counters though uh they only get incremented when you cancel an order so it's actually not related to canceling when I call cancel on an order that cancels a specific order and that's actually one of the only times you do explicitly provide the counter so it's saying here's a particular order that I want to cancel when you call increment counter you don't provide any arguments you just call increment counter and it cancels all of your orders that were signed with that counter yeah two distinct things thank you other questions okay uh how are we doing on time all right uh well I guess we've got we got another 10 minutes maybe we could all Workshop oh do you wanna you have another question yeah yeah um I think this might be a little bit unrelated to Seaport but more on the API so any any plans on your end to I guess make the API more Enterprise grade maybe like a higher TPS and so on uh we are we're just focused on Seaport but um definitely get we'll we can put you in touch with the API team um maybe we could Workshop uh an interesting Zone something that uh that would add some new capability to the seaport anyone got any ideas something you'd like to see yeah um I'm coming a bit late so I suspect this is always already been raised but is it plus how about a Zone where it's only possible to make sales to certain people or I suppose certain addresses or maybe certain EMS addresses that's very possible yeah um and that actually reminds me of an interesting Advanced technique that uh is used for Private Sales so if say I want to I want to sell just a specific nft and you are the only person that can buy it what does that look like right how would I set that up one kind of interesting way of doing that is just to say all right single offer item my nft consideration item one is eth to me consideration item two is my nft to you right so I've basically just set it all up but now if I wanted to go and call these implied mirror order and you know just fulfill orders on that it's not gonna work because the the offer item from me needs to actually match to the same order right the consideration item on that same order so you got to use match orders for that and you would then match it with an order from you that just says I'm just offering the eth and there's no consideration item right so I'm basic if if I were to just take that order and sign it then it's effectively a donation right but if I fulfill it alongside this other order now the two of them together make a complete picture so that's for just a single private sale but for say I only want to sell my nft if you're on this allow list that's easy enough you have a Zone where you just Supply okay here is a Merkel proof that says that the fulfiller the caller is in the root right they're one of a set of people or I could check and see like the caller has a balance of this particular token if you don't want it to be a token gated thing where only someone that owns this token can buy it from me or something like that well that's all actually it's pretty straightforward to do with the zone hey um so with like developing new zones um and building just generally on top of Seaport like a new Marketplace do you see it as like um like what's the what are the steps for for doing that is that like create a UI that signs messages and then create like your own database and API to serve those messages uh do you see that happening as like the pattern as this scales out or like develop the zone and then like work with openc to have that zone integrated or maybe like a mix of both well we knew that the place to start was with the smart contract right the marketplace that's it's the hardest and riskiest thing and most expensive to get audited and vetted and all of that so started with that the the contract and now that that's in place really where we go from here is is uh anyone's guess but I think that if it really depends on the application if you have a particular flavor of listing that you want to see supported in other marketplaces then I think the most expedient route to do that would be to go ahead and put it together and then shop it around and sort of like I mentioned earlier you know I would we would love to to see what people are working on zones they're creating and that would really help expedite the process and help standardize around certain zones that do specific things really well we're creating a brand new Marketplace from from the ground up I think that's it there still is very much a traditional um web 2 component to it that would need to be um would need to be undertaken at this stage but um I imagine that that too will become more uh accessible to all soon is my help so you spoke a little bit about private um Private Sales recent just now I imagine that openc is not spawning new contracts for zones every time someone does a private sale can you walk us through the flow of a private sale in open seat today yeah so so there's no Zone required on Private Sales that's basically just taking the standard order and normally you'll see an order with it's like the basic order you'll have a single offer item that's either the the tokens that you want to spend or the nft that you want to sell and then you'll have one consideration item the first one by convention like if you use the order validation helper thing the first consideration item is almost always going to be something coming back to you the offerer right and then it'll be followed up by usually fees like here's a fee to the marketplace here's a fee to the Creator that's a standard order that you would see but in Private Sales one way you can do a private sale is you deviate from that standard a little bit and you just say I'm actually going to include the the recipient the person that I want to sell this item to as a consideration item on my order if that makes sense so it's like literally you need to get this or else you can't take it from me yeah that's the idea I guess um like for like a Zone idea is that like I think when I was reading the like Open Seas like wyvern contracts like there was support for just Dutch auctions and pixel or fixed price sales and they had like a comment in it saying like they wanted to maybe do something more advanced or like English auctions or something like that right and I remember watching one of your like I guess it was like an East Denver talk or something like that and you said that like something like an English auction or that could be possible using the zones uh so I I should this is actually another Advanced technique that we haven't really touched on that you reminded me of and that is every item you can specify a start amount and an end amount so when you do that it will look at the start time and the end time on that particular order and then it does it a linear interpolation and we'll just pick out okay here's the current amount based on where we are along the the timeline for the order so oftentimes like when you talk about a Dutch auction what that or a reverse Dutch auction what that really is getting at is this is a it's a some listing where the price is going down over time right or the price is going up over time it's not necessarily an auction per se now auctions there's a couple different ways to run them and it really depends on what you're trying to optimize for and what your trust model is oftentimes what it really comes down to is like I have a reserve price and I want that reserve price to be met and I want that reserve price to be secret too right so um like one way to handle an auction assuming you have an Auctioneer that is a someone you trust is you set the auction the runner of the auction as the Zone on your order zones generally the way that we would think of them is that when you have a restricted order that zone you're gonna call it and say is this a valid order if it is then um it'll give back a magic value saying this is good go ahead but another way you can do it is that that zone can actually call Seaport if they call Seaport that's also them if they're the ones that are fulfilling the order that's also them giving explicit approval per se right they're message sender so you can basically sign a listing that you here's my my reserve price that's the consideration item to me I'm going to give that to this this Auctioneer whatever the marketplace they're going to keep the order Secret and then they have to be the one to fulfill it right it's a restricted order and they'll apply a tip on that based on the difference between the reserve price and the actual price there are also constructions where you can do stuff like the commit reveal pattern for hiding the reserve price you generally have to bond up front I mean it gets it gets complicated depending on whether you're optimizing for the privacy of the the um person that's that's trying to auction the item or if you're trying to optimize for protecting the bidders you know if you don't want the person running the auction to pull out of the auction and cancel it and pull their yoink their assets or something their items um there's there's a number of different variables to control for but that's one thing that I think would be really cool to see more work on is leveraging zones to run different kinds of auctions yeah all right that's time thank you all for coming and uh can't wait to see what you build [Applause] [Music] [Music] foreign [Music] [Music] foreign foreign [Music] [Music] foreign [Music] [Music] 