good morning everyone so yeah my name is Liz and today alongside my friend and colleague Natalie we're going to be talking about rational decision-making and how we can use it to maximize both our personal and our collective impact so a bit about me previously I studied astrophysics and had very lofty aspirations of being a cosmologists and maybe winning a Nobel Prize and all of that wonderful stuff however after graduation I had a fair bit of student debt that I needed to pay off and before I knew it I was somehow on some reality TV show that took five complete poker beginners and taught them how to play and then before I knew it I was playing poker full time and physics kept intending to go back to it but never quite did and so instead of looking at the Stars this is usually the Stars that I look at this is a classic scene of an international poker tournament hundreds sometimes even thousands of people in a room not making as much noise as you think it's all this weird sound of chips if anyone's ever played a tournament you'll know what it's like but nonetheless it's been an incredibly fun and fulfilling career and things have gone far better than I could ever have dreamed I've won a couple of international titles I've been extremely fortunate and off the back of that what it's led to is that I've become generally fascinated with this sort of application of Poker thinking and scientific thinking to our daily lives and how you can use use this type of thinking to optimize them because like life poker is also a game of skill and luck obviously the luck part comes from the cards that you get dealt there's not much you can do about that and then the skill part is about what you choose to do with them the the decisions that you make and that's obviously the interesting part because poker has so many rational thinking skills that you can use and apply to everyday life and that's a little bit what I'm going to talk about now that's me doing my thing there I am so the first of these is nuanced pokers about sort of making predictions under the face of an immense amount of uncertainty you'll have all this like conflicting information and deliberate misinformation from your opponents and so you really can never be certain about anything and so you have to become very comfortable with that our minds love to sort of think about things in sort of a black-and-white absolutist sense but that's really unhelpful because we can never be certain about anything in life really it's very hard to predict the future and so you have to become comfortable in thinking in grayscale and nuance then you have to get comfortable in thinking in numbers if I'm playing in a big hand I can't just get away with going there probably bluffing that's just gonna lose me a ton of money because you have to train yourself to think in probability so usually a poker player will be thinking oh I'm 60 or 70% confident and this again this this sort of quantification applies to so many things in life where you'll you'll become more comfortable in thinking in terms of like expected value of your decisions and then of course it teaches you about effectiveness and specifically cost-effectiveness things like return on investments and hourly rates and so all of you as entrepreneurs think about this stuff a lot anything that's required to basically to be a smart investor and then most importantly of all poker is about objectivity is about finding the objective truth of a situation not what you want the truth to be and that's can be a huge problem because you'll be in situations where you'll have lots of money on the line a lot of personal ego at stake and so you can our minds are incredibly good at coming up with all the reasons to believe that maybe you desperately want to believe that your opponent is bluffing you'll come up with all the reasons to confirm that idea and not really pay attention to the evidence that they're not and so it really requires you to understand and master your own mind look out for all these biases and especially the unhelpful emotions that can cloud your thinking so it's really about scientific thinking about sort of weighing up all the evidence and information you have in order to come to the objective truth and these are just a few of a plethora of rational thinking skills that I found it's taught me that applies to life and hopefully you will identify with many of these to in your lives as technologists the thing about rational thinking is that it's not just about making the best decisions to achieve your goals it's also about figuring out what your goals should be in the first place and so for me after a few sort of blissful very hedonistic years on the poker circuit I turned 30 and well we meant to have sound down basically a hamster having an existential crisis yeah basically I turned 13 and at the same time I came across this chart some of you might have seen it on the wait bolt white blog it's basically this is your life in years and each one of these dots is a week so basically the time you spent at this conference you'll spend at this conference is one of these dots and that seems alright until well for me when I was 30 I realized that this section had already gone and I just completely began freaking out and because I was like is this you know it's poker just gonna be my thing is this gonna be the legacy on my tombstone that I made some expected value from the guy down the casino she did a great job at that no I wanted to have I guess something bigger that I felt I could aspire to and particularly something that I felt could benefit the world more concretely and this is also will sort of compounded by the idea that I knew I've been making pretty damn good money and obviously we look around us and we see there's a lot of big problems going on and people less fortunate so I felt like maybe there was something I could do if I could give it to the right place but the trouble is is that I was very impressed with the whole sort of current system particularly the sort of charity system because it didn't satisfy either the poker player or the scientist in me first of all there was like a huge lack of data and transparency you know there's all these different causes and charities vying for your donations and how did I know which one was best to give my very limited resources my time and my money too and then on top of that I felt that any sort of acts of good that I did any kind of charitable thing or so on was always very emotional based where you know I would like see some really upsetting ad on the TV or some disaster and I'd upset and cry a bunch and give some money just sort of feel a bit better and then that was the end of it and well you know positive emotions can be a good thing I knew that they certainly lead to bad outcomes in poker if that's Hughley what you use to drive your decision-making and so I suspected that this was probably leading to suboptimal donation behavior of myself and then thirdly I felt like it wasn't really big picture focused enough because it wasn't really objective to ask what are the biggest problems in the world out of all these different problems and which one should we really be focusing our time on so yeah basically I was very very stuck about what to do and then fortunately I came across a sort of a group of people a movement known as effective altruism and this is essentially the application of scientific and poker thinking to the idea of doing good whatever good might be and it's a group of philosophers technologists entrepreneurs scientists smart people basically who care about the world and the bigger picture and have dedicated their lives to figuring out what are these biggest problems and how do we solve them most effectively and so this this was basically the most inspiring thing I ever came across and it answered this question inside of me of like what I should be focusing my time on or at least I felt that this offered a sort of a glimmer of hope of how to figure out what they you know what I should be doing and some of my poker friends felt the same way too so together we sort of got involved and started an organization and today I'm very excited to announce they have one of these full-time effective altruists here with us she's simply brilliant I won't give any more intro than that because she's enjoying herself her name is Natalie Cargill and she's gonna explain a little bit more about what we're working on Thank You Liv no pressure so my background is not in science or in poker or anything so glamorous but in law and this is not actually a picture of me doing my thing because we almost never wear wigs and as you can perhaps tell from the slightly glazed expression this was at my call to the bar ceremony several glasses of wine in I couldn't find another picture so I love two things about more in particular first as a barrister especially it's particularly hard to your way through it and it really forces you working in unfamiliar areas and difficult topics to think really clearly to reason really carefully and to express yourself very precisely and if you don't do that someone will tell you really quickly as I found out during my training several times and the second thing I love about law is that if you go into the right areas you can actually work on some release with big picture questions of ethical or political or social importance and I'm lucky that the chambers where I'm now a tenant does work on these big questions and public inquiries and inquests etc so essentially what I was always drawn to was a career where I could work with really thoughtful really smart people on pretty big questions and that's what drew me to effective altruism which I've been involved in for a few years so as Liv outlined effective altruism is the intellectual and moral project of finding those actions that will do the most good for the least sacrifice and then the practical project of actually taking those actions which is often harder there are a couple of things that I think make this project distinctive from other social movements well there are three you can see them so first of all and I think this is perhaps the most important effective altruism is about maximizing the amount of good you do so often when it comes to various sort of philanthropic endeavors or career choices we ask ourselves is this a good thing to do is this a reasonable use of resources what we should be asking is is this the best plausibly with the best use of my next bit of resource whether that's time or money or energy and there's the answer to those two questions can often be very different secondly effective altruism is about using science so we've seen looking back through history the incredible things that happened when we applied the scientific method to finding the truth we had the Scientific Revolution we've not really applied the scientific method to finding those actions that do the most good and we should perhaps and the third thing that makes effective altruism distinctive is it's about impartiality so when we talk about making the world a better place doing good etc we want to do that treating everyone equally no matter whether they are socially proximate to us or not whether they're here or far away whether they exist now or in future generations that's that's effective altruism in a nutshell but why is it important why is it timely and important now essentially because we're living in a really weird time where for the same amount of effort some actions can plausibly do a hundred or a thousand times more good than others which when you think about it is really weird in the environment in which we involve there was no sort of one action that would take a little bit of effort and in some cases results in thousand times more good but it seems this is the case now so I just want to give you an example from the charity sector very briefly although actually perhaps what we should be more concerned with is broadly which actions we should take which projects we should work on but the best empirical evidence that the moment might come from the charity sector so say you wanted to improve the world and you're uncertain about how to do so you could think oh I'll just spread my bets across a broad range of charities and see what happens I think it's likely that you'd end up wasting almost all of your money if you did that and that almost all of the impact from your donations will come from a very small number of things so for example it seems plausible in 2015 we're good we're good ok most things don't work as I just said in 2015 the director of evidence-based policy and large foundation reviewed a huge number of RCTs of interventions have been tested and about 75% of them showed no effect or a very small effect about 10% of them had a negative effect so plausibly you can just sort of forget 3/4 of the things you might have invested in that still leaves another quarter however it's plausible that only a tiny fraction of that will actually do an enormous amount of good just yes for example it's estimated that a charity called the against malaria foundation can create the benefit of one year of extra healthy life for about $100 if you focus on a slightly different area treatment of a particular sarcoma that also occurs in the developing world the same benefit would cost about $50,000 the contrast is more stark if you sort of widen the lens to developed countries some US government departments spend around 7 million on safe the ark safety infrastructure for getting the benefit of an extra life saved the most cost effective Charities in global health can produce that same benefit for around $3500 so the broader point is not simply what we should fund this intervention rather than that intervention but these really really stark differences in effectiveness are possible and this should give us pause and make us think well this is a bit odd maybe we should think really really carefully about the actions that we take so we don't end up wasting most of our potential impact and maybe we should ask ourselves what are the problems that we should be working on in the first place I find this a pretty useful framework for thinking about which problems to work on it's it's pretty simple you'll have more impact on a problem the bigger it is the more solvable it is and the more neglected it is so the bigger it is this is pretty obvious say we want to end factory farming it would be better if we ended factory farming in China rather than in say the Czech Republic because more individuals are affected in terms of solve ability we could think of some problems that are really huge such as aging or such as an asteroid hitting the earth and these are enormous in scale but seem relative to other problems less solvable in terms of neglected nurse all things being equal we want to work on problems that are relatively neglected because the less time and effort that has already gone into these problems the more likely it'll be that there's low-hanging fruit that we can sort of swoop in and take for example climate change is an extremely large problem on a global scale we seem to have reason to think that it's pretty solvable there are things we can do about it however relative to other problems of similar scale for example the risks posed by artificially engineered viruses it is comparatively not neglect it this is just a framework and there are no conclusions built into it and the framework itself is not immutable but a number of researchers over a number of years have converged on some areas that seem really important so for example Global Health this is in many ways a really messy and complex problem but in others pretty solvable there are things there are diseases that we know how to treat cheaply and if we were to fund those cheap interventions lives would be saved another example factory farming or possibly up to a hundred billion animals every year erased on factory farms in conditions likely to cause some extreme levels of suffering not to mention the effect on climate on human health on antibiotic resistance etc we know that there are interventions that work and yet last year collectively as humanity we spent more money going to see a film called sausage party which is about an anthropomorphised sausage than we did on all charities working to end factory farming this is a an appallingly neglected problem and then there's a whole sort of bucket of problems related to reducing existential risk that is reducing the chance of an event that could permanently end intelligent life on earth or drastically and permanently curtail its potential a little bit of context on this so this is a graph of GDP per capita over recorded history as you can see for a long time pretty much nothing happened that was really boring and everyone was really poor was unthinkable that you could affect things the other side of the country let alone the other side of the world and then something happened anyone what happened yes the Industrial Revolution and potentially the most transformative event in recorded history so it wasn't just GDP that shot up but life expectancy percentage of people living in a democracy an energy capture per person per day basically life got better for most however what also shot up that ridiculous rate is will making capacity as a historian is documented so basically every time we invent a new technology most of the time it goes really well but every time we invent a new technology there's also the risk that this is the one that has more destructive power than we're ready to handle and if we look back over the last century we see exactly this we see it in the number of nuclear weapons that we have on hair-trigger alert if you want to be terrified look up the Wikipedia page on nuclear near-misses it's long we may have just been lucky we also see potential risks posed by extreme climate change if the climate warms by more than 10 degrees it's game over and looking forward we should expect to see this pattern continue as we develop new technologies for example it seems plausible that in the coming decades we are going to be able to engineer a virus that is as contagious as a flu as deadly as Ebola and has a long incubation period so it can spread around the world before we have a chance to react also a number of experts are concerned that artificial general intelligence seems to be something that's going to be happening in the next few decades and the task of aligning the goals are the super intelligent general intelligence with human goals may not be as easy as it seems and there are things we can do about this now so there's a lot to do funding hasn't caught up and we donated over 400 billion last year less than 1 billion of that went to pandemic preparedness Oh wrong slide and pandemic preparedness was one of the most well funded in these pressing problems so we clearly sort of haven't caught up to the nature of the challenges we're facing but I'm not here predominantly to talk about funding I'd also like to talk about talent and to ask for your help we're really just at the beginning of this intellectual project and there's so much more intellectual ground to break and so many more actions that we need to take and projects we need to start there are fundamental questions about what is the value of the future why do we think it's going to be passe or negative how does economics game theory coordination theory changed when we assume altruistic actors rather than self-motivated actors at the calls level how are we going to think about risks posed by new types of global conflict how can we improve institutional decision-making how can we improve forecasting at a project level recently projects have been proposed such as having a database where we can subsidize a prediction market for questions relevant to these types of risks so in summary I'm here today to ask for your help in the spirit of this conference please take a photo of our emails please do and please just send us a blank email and if you can help us spread these ideas if you've got ideas of people we can talk to places we can talk places we can write and present live and I really really a keen to do this and if we can help you if you're working on a project to make the world better by asking the big-picture questions please do email us we would love to share you look cool with you thank you very much you 