[Music] [Applause] [Music] so so [Music] [Music] stream should be transferring hopefully things are quiet on the chat it was kind of chaos last time all right um here's the agenda i do expect today to be short but i guess you never know on testing releases there is some activity on the spec repo there are some minor features that are being worked on that we expect to come out in something of like a minor hard fork early mid next year um the actual discussion of what's going to go in there i'd say let's wait until january we can spend some time making it kind of clear what the intentions are and we can debate and go back and forth a little bit i think the low-hanging fruit here are a little bit of accounting reform on how attestations and things are stored in state adding a sync committee or light client sync committee which reuses some of the generally similar committee functionality both on the networking level level and in the in the spec to add a um white client first support and some other small stuff but again i think our time will be better spent formalizing some of that stuff writing it down getting people up to speed and then we can discuss it in january um additionally there's ongoing work in the spec on him i should um interrupt in just those specific issues like there are um github issues and pull requests and that you specs that you can look at already so on the accounting reform stuff if you just go into the polls section of each use specs so the the most recent and recent two from myself i forget the numbers but one says like accounting reform and the other says um quotient um reform or something like that highly recommends for client developers to look at them and at least familiar familiarize yourself with the proposals and comments if you have things to say right and some of that in there uh moves some of the state accounting to the way it's generally optimized on epoch transitions anyway so i think this would be a net benefit helps for things like empty pop transitions and stuff which are currently probably a dos vector um cool uh so ongoing work there uh there's also um to make this testing a little bit more sustainable i want to use a little bit different model and i expect that to come out early next year uh didn't really want to pull off the pull the rug on you on testing infrastructure right near launch but um that's right uh let's see anything else on testing and releases media you got anything for us not much crashes lately which is good i guess we had to fix our fuzzers after a few client updates messed them up still have one small issue with hong kong's the mutation based fuzzing engine not the structural one it's spitting out way too many false positives to be useful um so we need to basically implement some timeouts to give it enough time to initialize all the clients but yeah it's been good we've been working with parry um on deploying the fuzzers to the aws infrastructure he's got some great ansible and terraform scripts um but yeah pretty pretty quiet i'd say um no crashes to report which is good good thanks okay anything else here um so uh about the test vectors uh i have a proposal about adding the uh bls serialization test uh posting here um i think i got some feedback from the clients and the os uh the battery implementers so i think they will continue to implement it in our test vector but um the the interface might change if i found something new but basically is the test will focus on the three significant bytes and the verifications great and this is after found a couple of issues in pi cc around some of the serialization right shall we uh yes thanks to crong and it's our uh is to funky hunter and help the pisces a lot great okay let's move on to client updates we can start with taku everyone uh from the taco side we've been focusing on optimizing epoc processing uh creating the first block of the epoch is still slower than others so there's potential for further improvement but it's significantly better than it was and we're now like we're not seeing blocks get orphaned on paramount anymore at the stations for the first slot is also now much more accurate because block import times are faster we've modified eth1 genesis block search to be more tolerant of missing historical blocks we've reduced we can say backing tree heat consumption and we significantly sped up as a seed serialized in the serialized and we fixed the bug which caused eco to produce invalid at the station aggregates that's about it nice and prism hey guys terence here so we've added a database backups at runtime for both and validate validator client we also support team um reading graffiti from file and this is for the validator side and this was a highly requested user we have peer scoring enabled by default we update it to golan 1 15.6 and with disk io for validator client and this results in safer testage a safer tester slashing protection which is great last but not least we've added it one fallback option for the uh for the eth1 node and this was also highly requested by our by our user and that's it thank you i'm curious on the fallback option is that if the api the connection fails or does it try to detect if maybe the the main option is following the head uh we're just doing the api protection fail cool yeah i wonder i wonder um maybe if you like look at peer count or some other stuff that might think that it's bad i i was just setting that up the other day and didn't know exactly what was gonna happen but thank you uh lighthouse hello um first of all apologies for missing uh the last call two weeks ago uh we been working on enhancing our slasher so we fixed a misproposed slashing bug and we added the option for users to broadcast their slashings we fixed a couple of io failures that were causing potential database corruptions i think like a lot of people there's been some f1 client issues so geth works seemingly and seems to work really well but everything else seems to struggle so we we also added an f1 fallback node and a while ago and we also now have a manual flag for users to purge their ethernet cache for dodgy clients um we simplified the beacon lock files we're now using os locks we almost completed the standard http api the service and events are implemented now i went and corrected some light attestations uh we've been testing and analyzing gossip cell data metrics and scoring so we found a little discrepancy in the expected message propagation which will be corrected very soon in the future pr um and yeah we're currently working on reducing our block proposal time couldn't get down from 500 millis to about 100 millis um paul and benedict are working on a beacon node fallback so kind of similar to the f1 fallback giving users the ability to specify multiple beacon notes and we started experimenting with a new scoring parameter to essentially help detect censoring nodes and that's about it great hi so yesterday we released uh our uh version 1.0.4 uh we didn't announce it but we will be announcing it soon though some users found it still though the biggest change that we had where um properly handling the termination signals uh for example making sure that the slashing protection database is correctly flushed on disk and uh closed we added also a new performance scoring so that you can check if your system can keep up with the small requirement of the if to chain and um also importantly we fixed uh some a bug where we didn't fully aggregation we received and we forwarded them to the network and we ended up getting bad score and we also fixed uh issue in gossip sub which led to a slightly worse attestation effectiveness so right now we are focusing on a couple of performance bottleneck one is disk io so when we we have some io when we do attestational block proposal that we would like to reduce and accelerating state transition via having something called a state diff instead of storing the wall the wall state and lastly multi-threading that we plan to have we have the primitives done and we plan to uh refactor or verify benefits from multithreading at two different levels and for maybe three weeks from now great and came in hello everyone so past few weeks um we turns out we hadn't implemented the api the standard api but uh we implemented those two thing to end points we finally got on implementing and integrating the bls batch verification which really helped helped us and we've just been going going through profiling writing beacon node and fighting finding low hanging fruits some things as simple as you know like in lib p2p getting piers in in jsp is kind of a it takes a while so um just doing our hey did i lose cayman or am i disconnected um we also you know the other one for about like 20 seconds or maybe 12 12 seconds oh your internet connection is unstable um yeah um uh sorry was last thing you heard bls batch verification profiling how to get peers right um so we're just doing less to try to get some final things together um that are really stopping us from having a responsive beacon node all the time um and we've decided to cut cut releases every two weeks so we're just going to do like a really that kind of release schedule so that's it from us can people try load star on pyramid yes so it works i will say currently um so you could pull it down from either master build it or from npm but um one thing uh it will like kind of pause every few minutes um but it will it will it will stay on the head but it will not be responsive at all times so uh we're working through those last things great i lost my agenda page but i'm pretty sure next up is research updates anybody want to go um so on the um shorting front uh then i'm not sure if i mentioned this in the previous call but well but the data availability sampling starting is now a yeah uh apr it's also one of them very get more recent ones in the pr list uh so that includes the uh the beacon chain transitions uh and there's also a yes a separate document that the army that the pr links to that has been around for a while that basically talks about like what it how the data availability sampling works um and in the ima dan grant has been doing some excellent work on optimizing proof generation and making it look like generating the inclusion proofs for or or the correctness proofs for branches of a block is going to be much more practical possibly some um somewhere around eight to uh uh eight times eight times faster or more than we um than we had thought before which is uh potentially good news because it just kill because it reduces the headaches that we might expect from my needing from a block proposing otherwise block proposing just be a significantly simpler process can you help us understand the complexity of implementing kate commitments in in terms of like what type like how much is it built off of existing bls libraries and things versus uh really good question so i think one really important thing is that you need to have a library that exposes bls operations so multiplication and addition being the most important ones and ideally you want this fast linear combination some aka multi-exponentiation which basically just takes a whole bunch of points and a whole bunch of coefficients multiplies each point by the coefficient sums them all up and gives you the output basically there's you know optimized ways of doing that that are potentially up to something like 10 times faster than for for large inputs than doing it the kind of naive way so if you have libraries that do those things saying if you don't have the fast linear combinations that you then you could also just code it yourself so if you do have things it's actually not that hard and so making a academic commitment for a piece of data just what it really means it's a step um you have a kind of pre-existing uh set of points which would basically be the trust basically an fft of the trusted setup pre-computer fairly easily and you just take the first object you just basically do a fast linear combination of the setup to get to a block so so you do the first point multiplied by the first piece of data plus the second point multiplied by the second piece of data and so forth so kim data is easy um gener verifying a proof is an inclusion proof is also easy and basically it's just a single pairing check uh and now generating all inclusion proofs is the thing that uh incred has been working a lot on optimizing but the good use is that it's still something like 41 or 250 lines of python code or so and so you can probably just uh take the uh to take the python code and translate it so my opinion is that it really it should not be all that difficult actually and is this is this a known enough quantity that it can be worked on today i think so [Music] uh just yet once again if we have the bls library support right i mean i think uh yeah for blast i think you have to wait for them to expose those uh i can give you uh some comments about the library support but uh just to make sure we don't need fft because it's simple enough that we can just use a multi-scalar multiplication right um correct so the fft is needed in a couple of places so one place is that to generate all all inclusion proofs for a block so to generate and inclusion proofs in um analog end time instead of an n squared time um you need the the the fancy um algorithm which i dance right i have created by adapting this earlier thing from uh demetri and one other person and that uses ffts internally and the second thing is that the uh mccatey trusted setup that you normally see um comes in the form of a sequence of powers but in order to just commit to a blog you want one that comes in the form of being in sequence of evaluations and converting from one to the other also requires an fft okay so in terms of the state of the bls libraries that we can use remember that uh with my very first talk with supranational back in april that was one of the things they wanted to look at the multiscalar mule but i don't think it's ready yet however consensus has a library called golf and gnark for snacks and 12 381 and they have the multiscalar multiplication that is also multi-threaded and that they optimized heavily and the zxz project has also a library in rust recently they are renamed to arc works and they also have a heavily optimized bls 1230 81 including fft and multiscalar multi and i think it can also even work on gpu oh excellent so i know looking at the the libraries that are being used for snarks definitely seems like a potentially fruitful route to take um but they're one thing i wants to stress is that there definitely is value from working on the um cate pieces sooner the reason basically is that um we really wants to just get the statistics on how um um what it what is the run time of one of these things in practice i mean basically adjust them like if we have that statistic i think it significantly de-risks the whole thing also i'm very happy to uh like create a little intro to the fft on group stuff like the method to create all the proofs um like so if as soon as anyone is kind of saying they want to start working on this i would yeah i would create something to like get them on board yeah i think it maybe in in january it might be a good time to do some various likation and knowledge transfer so we can all kind of get up to speed on this and some other stuff that we're looking to do next year all right i need to totally derail you there um i think that's the main the main new stuff happening on the research front um hmm no i can't think of anything else though okay uh anyone else i mean related to the data availability sampling i guess one aspect is the then possibly you know slightly modified dhts with new properties like low latency and i guess one of the things we're looking to do is is hire a networking expert who could maybe help us a different foundation investigate these issues so if you know anyone please pass them on all right um any other updates here all right great um i might have had my mute backwards there any other updates all right um great we had a networking call one week ago uh there's a to-do list that i need to get to thank you for taking notes ben um is there any other uh networking components people want to discuss today okay and general spec discussion uh like i said there is plenty of movement on the spectre i think it it makes sense to have at least one person on your team keeping up on the various developments and engaging and very well have plenty of good stuff to talk about on maybe like a first hard fork and like i said i think it'd be a good time to maybe get on some calls and make sure we like write down a lot of stuff to just do some knowledge transfer and get people up to speed because there's plenty of um engineering r d tasks to begin to um tackle here other than that anything people want to discuss today uh do we want to talk about fork choice things at all or is that just the kind of i keep quietly working and figure it out sort of thing um let's uh i'd say let's pick that up in the new year yep makes sense no i mean for anyone listening the quick update is basically that there's some multiple small tweaks to the fork choice rule that we have been mulling over in order to uh address uh all of the issues that some academic people have found with the fork tourist role basically some theoretical issues with liveness uh so yeah we will like and the idea the the ideas on exactly what to do have been around for a couple of months now but just kind of pushing them forward to something close to a ready-to-go stage and kind of underneath that is more of a general just contemplation of liveness in general because as you aware the fork choice you know is lmd ghost but then has a number of these like tweaks and fixes to make it more alive under the attacks found um which is a game of whack-a-mole which is maybe not the like uh okay um anything else at all that people want to discuss today before we take a law at least for this can we call about crocodile for 40 minutes um yeah yeah you can start us off metallic can you start us off with a 10 minute diatribe yeah okay fair uh thank you um excellent work as always happy to see main net very stable and um have a great holidays talk to you all soon thank you bye [Music] [Music] so [Music] [Music] [Music] [Music] [Applause] [Music] [Music] [Music] you 