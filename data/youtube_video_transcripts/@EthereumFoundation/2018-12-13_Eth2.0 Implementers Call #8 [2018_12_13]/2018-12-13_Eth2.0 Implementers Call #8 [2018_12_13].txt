[Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] okay stream transitioned or transitioning people of the Internet give us a thumbs up in the chat box and you can hear us and we will get started welcome to the call number eight so these are nightfall which is exciting I believe you all have the agenda here is the agenda if you haven't seen it nothing too crazy on these number today we'll go through the normal things we have a few things to talk about opening its best expect discussion and then that'll be it first client updates no one likes to volunteer so I'm going to volunteer somebody how about Joey hi so on this week we were implementing the bill asked Marty verify function it's in IBM a Satori and waiting for more reviews and hope it will be helpful in generating the test vectors and the other thing I think we were doing is keep trying to catch up the fake yeah that's updates thank you great thank you how about harmony last weeks we've been working on pls refactor and this reflectors had a goal to make our implementation agnostic to elliptic curve mathematics provider and current implementation is based on my crew but after this refactor it could be swapped to any kind of elliptic curve mathematics provider or even build it even a custom one also we've been working on simple serialize implementation with two care consensus low-level implementation and building some high-level stuff like Timothy which will work with annotations with the annotated classes it should be pretty handy for poor simple serialization and another part of work is abstracting from material J so it's still in progress and will be in progress for couple of weeks we're also touched base with Pegasus guys which was pretty nice and we decided to collaborate on lipid Opie on crypto stuff and testing stuff also there is it's possible to work on C on the same eath 1.0 provider so there is a plenty of things to collaborate on and we decided to start from lipid to P work that's that's it great thank you how about Pegasus my apologies my mistake but we decided on our name for our client it's gonna be called armas we had plans for opening open sourcing which are in progress right now and coming soon we have validator registration process in place and raising it event when a new validator is detected also in talks with collaborating with harmony and we're waiting on getting up here approved for limb p2p daemon so it can interface with Java natively and that's it great thank you congratulations on the name any thought any explanation behind that name do you want to share yeah so we wanted to stick to like a Greek or Roman god or goddess and so we have pantheon for our client and Artemis is the goddess of light and since it's called a beacon chain she's also the torch bearer so since it's called they can chain that's why we decided to go with Artemis that's very cool cool how about prismatic is slower you could respect update we're currently catching up on spec we're working on picking up refactoring with the radius back updates and also with ongoing refactor realized it would be idea to modify how how our current sink service function so previously was split all the same service between between initial sing and the no more sing to right now were combining the two servers together we finish that on top of that we also implemented a first version of simple see realized spec which is now implemented in prison and that's it awesome thank you the Nimbus hi so now we are at most one day of the spec so we are keeping up we implemented or scheme free for BLS signature so in line with latest spec from two weeks ago we now have a commit and reveal scheme that can work for right now until we have something more concrete in the spec we've developed yeah Mel tester generator for shuffling tests there is a dedicated ripple now so it's not in the name becomes in the repo it's ver so feel free to put request for tests I already have one for BLS signature and aggregation that was asked by people from and over teens we have a mock gossip sub based on our LP X now in the name beacon chain and regarding the p2p pub/sub we have raised the kind of critical issue today so when we have multiple multiple connections done to the same peer if one is closed all others are also closed so this has been raised to the attention of the team I'm posting the issue also here and apparently it's a critical flow in where's the rock around but it's something I have to think about and lastly regarding community we studied 2.0 series with introduction to become chained to validators and transition from proof-of-work to prefer stage and the community has been looking into it with interest and there are some that we will be translating vowels to Chinese and Croatian so other translations are obviously welcome so let us think so that's it for the neighbors team possum is there somebody here from the lodestar team I know the Kyra has finals today and the lighthouse team had a company holiday party and it's 1:00 in the morning after that party so they left me a note to reveal their update is that the recipe TP which i think is managed by parody has finished like a major API refactor which is a blocker for them for utilizing the same repo and Adrian has begun to implement gossip sub they finish that refactor they've also been refactoring a match the spec updates been doing a lot of kind of project management stuff and I have been working towards a q1 beacon chain test tonight actually I think Alex Stokes is here who does some work with lighthouse does that cover most of it Alex yeah that's the main thing and then just yeah it's back updates cool great and parody it has an internal workshop right now so they will not be here but generally they're continuing to follow the spec continuing to ensure that substrate is going to meet the needs and kind of get in the bones in place so but no major update on their end great I didn't miss anyone right I think Zack crawl from a white blocks had some updates from the simulation group but I don't know if he talked to you about those I'm not entirely sure but we're moving on research and that's probably a good place to put it if you do you want to start us off you have an update from that end or a link I know that there was a call last week but I did not attend okay let me find my note from the call okay so it was a call we were about eight people and the main topic was network emulation and so we started some nodes and anyone can join them and the main issue we were talking about and that was raised by alexei was how to generate activity and the test plan is where I put the notes and also relevant links in the chat box so the next step for the simunition group is coming up with a test plan so this is the role of Zack and his team and then it would propose this test plan to us and asked us to elaborate on that and there is a repo that is in the plan and some generic type of test that everyone can get inspiration from I had to test on the client but I think he has a lot more to say so I'm probably not faithful to Holly want me to say no that that's a good update and maybe he'll join us next time appreciate it yeah do we ask for update from chain3 yeah lodestar change safe I don't know if anyone joined us today I know Mick Cara has finals and she's usually the one that is able to join our calls okay thanks yeah oh you're right they did put something in the H and I think they're their biggest update as they've changed the next full refactor to utilize typescript which i think is the same decision if you're in JavaScript okay cool so research we have the testing group is continuing simulation groups doing some work is are there any other updates from research I have a question actually concerning the simulation and I just look at the link that was shared on the chat and and this is a question that I had previously is how do they how do you decide the bridge between minor notes and transaction notes in different simulations you are doing honestly I can't reply and best would be to ask Zach Cole on the repo just open an issue and ask about how they choose the parameters okay cool so research updates anybody yeah so from my side I have been doing some refactoring notes on the Honda simulation on the simulator that I planned to running the supercomputer I added a couple of features previously every single MPI process so I'm not I'm not sure how many people here are familiar with MPI is a message passing interface which is what we use to communicate in supercomputers every single process was simulating a single node in the network I have changed that into that now one single MPI process can simulate multiple nodes in the in the peer-to-peer network so that allow us to do more large-scale simulations and I also added some kind of speed the speed up time feature I wish I can speed up time by up to a hundred times so that the execution of the blockchain happens a hundred times faster than it would actually happening in in real life and to have much you know faster pursuits so that I have been working on those on those features and a little bit of refactoring and I had some some questions over example when we look at this pack so right now I use small sizes for the simulations that I run in right now is just basically for testing the APIs of further I am developing so it's not real size simulations but when you look at this bag you have like for example 1,000 shards and 256 validators pressure and I wanted to ask how this compares to the current number of notes that we see in the India Trillium Network right so if you think about the number of pollinators for that respect you think about almost two to sixty thousand which is not the number of nodes that we have I think right now in the tearoom Network so I don't know how is this I mean are we is we think in about I don't know I starting with I don't know less number of charts at the beginning and as the number of validators increases increase the number of charts or what is the plan on this right so the number of validators per shard actually scales in it is scaled I think in like a function called get current shuffling and so essentially per if you have if you reach a certain threshold Valladares then per cycle you do cross link all shards in but if you do not reach a minimum threshold then it starts taking multiple cycles to cross link all the shards so that you don't have too few and your committees that are cross-linking so the number to answer your question the number of shards is to be fixed the minimum a number of validators for this to begin is defined by a constant chain start full deposit threshold which is 16 is 2 to the 14th 16384 so another thing to consider is that these validators are 32 weak instances and in all likelihood a lot of actual physical nodes in the network will represent multiple validator instances I don't have a good handle on what we expect that kind of distribution to be but say we have 300,000 validators and we only we have the same number of nodes in the network today so say on the order of 16,000 that's like 1819 validators living actually in each node and participating in multiple shard subnets so in that case when you're doing simulations we have to make some sort of assumptions about distribution of how many actual validator instances are in a physical node and so yes we do expect more of these discrete validator entities but we I don't know how much we expect the total physical node count to grow so Vitalik or justin or anyone have you thought about house we expect some these numbers to grow and scale so yeah there's nothing for attention right more of given say say we have Tim Malini validating we have on the order of like 300,000 validators how many the actual distribution of nodes on the network say I think right now we have like 10 to 15,000 nodes in the network you know do we expect to have a similar amount of nodes in the network and just to have mini validate or entities crunched into each one or you know what that what you think that distribution might look like it seemed it's hard to tell now I think we'll definitely see a power-law distribution of some kind I mean nautical identities there'll be one validator and in terms of physical like computers and IP addresses I guess it's hard to tell one kind of nice thing is that the amount of resources required for validator as in like a node with multiple validators grows linearly up up to a coins up to roughly I guess a thousand validators so if you have small validators relatively small validators that are not pooling then that should lead to a lot of physical machines but it's hard to predict how much cooling will happen right but this is also desperation I think is important because when you consider when you want to consider a number of bad actors most likely all the validators run in the same note if one of those validators is a bad actor it's most likely that all of the validators in the same physical note are bad actors because there's no belongs to the same person and probably will be using the same so far and so is this is why this ratio is interesting what we want to do simulations because that give us some kind of hints on what the number of bad actors you know really what would be the impact of that no no I don't think you can assume that actually because there will be you know that you've got a beacon chain being hosted nobody and pure something in in a ton of validator clients connecting to that one some of them could be bad actors in some yeah I I was just thinking like for example if if we assume that one of the you know we have today about roughly 15,000 nodes if we think that one of the nodes that we have run in today will be transforming to say 10 validators when charting comes you know the person person taking care of the node that runs today will probably apply the same for all the validators that that person will run I mean this is this is what I mean no I'm not talking about the IP address I agreed you know you can have the same IP address and still have different virtual machines running different persons difference of our different clients but I'm talking about if you transform the number of nodes that we have to the Internet work into a higher number of validators and that is likely to be the case that the same person if it's a bad actor might be account for many multiple bad validators right so I guess moving forward in the simulations is just to be able to capture that notion of a physical entity representing multiple parties within the network multiple validators in the network and then maybe we can figure out you know some sort of distribution on the size of these validator instances have been per note I had a question about this like the way the system performs when when more or less violators a 9-2 in right now is that scales basically this way but if we start seeing that there are a few validators in times when there are not so many or nots moving nodes will have thousand and twenty four slow nodes and then in times when we had a lot of other areas where many bad days we still have a thousand twenty-four nodes and there'll be an upper bound on how fast those are so in terms of scalability that way there will be something I would be interested to see a few thoughts and graphs on in terms of what the bounds are for when the system is viable from [Music] when when it becomes interesting to start thinking about more or less charge and because terms like this I'm not sure I fully understand the question in times of low validators yes so the system doesn't care with dynamic we in terms of number of sharks right so what we're scaling with instead is how fast the sharks get validated is that correct yeah well we're scaling two things that we stand the current spec one of them is basically how frequently cross links appear and so what the load is on the beacon chain and the second thing is that if at least I'm not sure if any of this is actually in phase zero it might only be in the phase one file right now but if the number of validators is too small then we base allow some of them to not submit group of proofs of custody and so the assumption will be that the majority of the mouths of the across wink validators when we summon the crosslink validators won't actually be doing full validation and all crew of custody generation they will just be basically either validating data availability proofs or something similar yeah yeah I'm not sure to understand this because when we have less body daters I would respect the few validators to do more work but what you are saying is that when we have less validators then somebody does to do less work to compensate for the fact that if we have fewer validators each one would have to do much more work we instead allow in the case where there are few valuators we allow some of them to not submit the group of custody bits and this allows us to do basically what this means is that they would have to check more blocks but for most of the blocks they would have to they would be able to basically skip doing most of the work okay right so essentially random sampling on who has to do the hard work so that your resource requirements stay close to constant even though your distributed across more of the network so I guess the general idea from a design perspective is to do some sort of graceful degradation and you know we could have a dynamic number of shots but reducing the number of shards is something that's very disruptive so it's not so graceful and so in terms of things that we can do gracefully is what the type talks about which is reducing the frequency of the cross links and not requiring so many proofs of custody is when we don't have that many validators and things we can also do with the execution layer is reduced the gas limit yeah that or even skipping slots but I suppose that's a similar similar mechanism well it also depends on how dynamic you want the system to be I understand change change the number of shots is costly if you change every every hour or so but if if you want if you for example I start with a hundred charts and then every month say to reevaluate this and is that cost that heavy in terms of unifying state I think there's much complexity there I'm not sure the actual computational cost but the problem is not increasing the number of shots that's easy the problem is decreasing the number of shots and there could be some sort of catastrophic situation where you know the number of alligators just drops by a factor of ten from one week to another and we wouldn't want to reduce by ten the number part and granted a lot of these graceful degradation scenarios are scenarios of incredibly decreased security but that's just even though performance is degrading but the security is kind of falls off a cliff at some point but it's just kind of the nature of the beast if you don't have a lot about yeah like if there is only something like less than 1 million a thousand then security is in some ways like hugely degraded anyway so right so doing major things like trying to reduce the number of shards it really doesn't even get you that far in terms of like increasing security at the cost of complexity yeah I know I was not thinking about decreasing I was mostly thinking about increasing kind of like for a bootstrap you know for like when we when we actually start charting so that at the very very beginning we don't have 300,000 body de toes I was thinking about start just starting with different number and then increase slowly as the number of alligators increases I understand the Christian is much more challenging now sense who makes luck time law by knowledge so if darkness when it becomes available or less resources available we have not enough time to run dance right I mean that's a similar trade off to just reducing the number of cross links per epoch and it's a similar trade off and reducing say the gas limit and shards by if you increase the slots or this slot length or skip the or skip certain slots I think it all of those kind of linearly reduce load and are viable but I think I don't know I don't see much changing the slot length kind of I think is may maybe changes the regularity of these events so maybe changes the speed with which they can become fixed if like they can mend themselves if say a number of validators do come on online so I think keeping slot length is probably healthy the same is probably healthier way to go fundamentally having less validators causes bandwidth issues not latency issues so we should address the bandwidth you know by reducing the block size or releasing the gas the metal things like that but changing the you know we don't have to compromise on latency and increasing this fluctuation compromises unnecessarily on on latency right and again as if you make a puck stick longer and you keep the same validator churn cushion then you're actually you're taking longer for the network to maybe get into a healthy spot again by inducting new validators cool fun stuff any more comments on that four move on to any other research updates okay but ah sorry I want to update yes sir on the question for Leo I just left some comment in their chat room about that the number of the test simply thank you so in terms of updates are on my side I guess I just wanted to give some visibility into significant changes that will happen to respect so one of the things we're considering is to pull out validated balances separate from the of the registry and the idea here is that the the balances are updating very frequently for the validators but not so much the rest and so we can for example save on the on the hashing do that's hashing at every Airport right move to Kakaako 256 that might be a requirement just to reduce the load pretty talk on a hashing I will say in terms of in terms of actual implementation you still have the same validator you still have the same index into that that entity so I think it's actually kind of minor on the actual implementation side but significant from a it's like data strips rework right in terms of data structure reorg we are considering merging some of the fields for for justification and finality so right now we have four different fields and we could merge them all into a single bit field that basically grows by one bit epoch and that represents whether or not the Year Park was justified and beyond being cleaner it has an other advantages like being more flexible we're considering adding more random mixes to the state the recent Mandar mixes and we also have to include various placeholders for example for the the proofs of custody and the PDFs but hopefully these obviously additions to the existing data structures in terms of significant changes I think there will be some simply through all the bug fixing that will happen so we we fixed we've identified and fixed a lot of bugs in the last two weeks but I still think there's a lot of unidentified bugs you know on the order of at least 50 and Stan needs academic review I see three frames one is the the fourth choice rule and I think we have Edo bento who's looking at that we also need to have a review of the the BLS hash function and it's possible we'll ask Dan Bonet or open attic bones to look at that and there's also a new logic around the justification and finalization for Casper Ritchie I guess more people need to look at that and try and break it or maybe we should go ahead and prove that it's correct once we fat but it wasn't meant for fairness so I mean it was possible for well or just higher energy to be a non-central but I was open for a silver miner to generate ended notes if you see what I mean I mean can be live you can be safe that a single miner has taken ownership of an ocean okay I'm speaking about the old version of Casper effigy in hand that was supposed to go on top of focus off work I feel about this and we found that two electrons speaking about I referred that some if you please likeness and substitute notes on us but we have some or some homes in the suspension right the analysis moves out towards the way at a stations are happening in that you know many validators get to participate on the consensus on the fork choice of each block being proposed and beyond that out to the way that group rewards and penalties are calculated and that the more participants and the consensus the higher the the rewards are there but agreed so and generally I especially because of the the attestation driven fork choice I believe that it's it is actually more resistant to say single minor takeover but I I do agree that just safety likenesses doesn't finish your analysis and that there's there's analysis around of incentive compatibility that absolutely should be done is how I give any comments enough yeah and I definitely think analyzing thinking incentive compatibility and like stability and various other properties is really important [Music] like I guess so far all that we really have to work off of our kind of existing arguments that we know of about ghosts the one thing that still makes me feel uncomfortable is kind of the stitching between the ghosts and fortune or fortress rule and the finality gadget and that seems to be like if there are issues that seems like one of those areas where there Creek there could be some weird king that's where the flip flop issue arose this kind of is the stitching yeah yeah I mean this is also one of the reasons why I kind of like Casper oh yes for CBC in the long term because it actually it doesn't require this awkward weird stitching thing but on the topic of the problem with bloc opposes having this monopolistic issue because you only have a single proposal has full control over the next block I agree with Danny I think to a very large extent that has been addressed with at the stations and I another name for the stations that I like is Co proposes so basically you have a committee that is invited to Co propose with the proposer and the proposal only goes through if the co proposes agree that this is you know a proposal that makes sense in the sense that it's building on top I don't really like that way of phrasing things because the proposer does have like very real power of choice about what things go in the block and realistically the tester is basically a close to zero leverage to influence that decision the best that they can do is reject the block if it's invalid co-signers yeah well I don't like ho because the word Co implies a relationship of equality like I think whatever word we use should imply an explicitly subordinate relationship right strictly weaker so it doesn't address things like censorship so the producer can create an empty block if they want but it does address things like stuff like trying to to build on top of an ancestor and trying to do short term things that would take over our tags and things like that any other [Music] [Music] [Music] [Music] okay I think we're gonna move on from there I apologize it's tough on the hardware today Yanik or anybody that's been working on any of the p2p research is doing update on that not really maybe one thing I've talked to Felix a little bit and he was very happy if we that we considered shooting and recovery version 5 and he we basically discussed how we can help and how to get the spec ready and he mentioned three things that we can do the first one is finding gaps in the spec so things that I'm not talking about or only touch briefly upon sexiest formulas which I'm not sure how we can do this mess I guess that's for later and the third thing I can't remember oh yeah why I prefer there's no there are no messages or anything defined so this is also something that we have to work on yeah that's all as and if we want to open issues and to talk about this kind of stuff it's best to do this in the Imperium does p2p repository that's it great thank you if anybody has molarity with pedis every protocols would be a great place to get contributing to because yeah this is gonna be as we want to have clients talking to each other even if they're the same client we're gonna have to figure this out soon you know they're cool any other research updates hey Nico can I jump in and just ask a quick question about about the assumption you know with the you know if one validator is bad on a note all of the all of the validators are bad is that considering potentially the possibility of someone setting up you know like a node hosting service and allowing the validators to independently connect to it no yeah I mean there there is definitely a world in which somebody can run a node and sell data say to validators so they can sign their own messages and broadcast them without having to handle the full requirements of running you know in that case that assumption fails in the case in which validators running their own setup and yeah many validator entity is tied to a node would be corrupt flawless truck very lucky in terms of incentives and security I'd like to try to construct the system in which it aligns to validators not outsourcing just because I don't want to see the network degrade into a handful of master nodes you know serving doing but that was my follow-up question is what what do we need to do in order to prevent that from happening if that's right Vitalik tests and thoughts I know kind of the non outsource ability of custody does a little bit of that is then you actually have to store the data on your own but that doesn't really fix the requirement that you're at your full notice requires that you've got this data from full node well it were it comes close to requiring you to be a full node at least in the downloading sense for all the way up until we start talking about state execution I mean in general if the it's hard to incentivize the property of actually being a node in the sense of serving other nodes in protocol because you could always just basically tend to serve yourself so if that ends up being necessary that the only realistic way to do that is to basically have things like markets for we're basically a node next or the other node and pays it inside of a state channel in exchange for services or something like that but you think the argument of having because you have to download definitely get cheaper and like people who are lazy will definitely like just run the phone software and use and use it instead of trying to do some fancy cheap thing where they do a little Lin of the minimum necessary I mean I definitely agree that like i personally am not worried about a no-talent crisis but if that's what we end up getting there are we wasted it I mean there's some honesty assumption that a validator is going to like do the full participation network but I don't want to make that honestly something too strong yeah realistically I think it's honest yes up should that only a few percent of elders really need to be all honest underfed in that sense and if that happens then there will be enough to serve everyone else mmm but definitely worth considering kind of like these worst-case scenarios in which a handful super notes are just trying to serve all the data to a very thin okay thank you I had a question about the proposers so I just did some quick math is like with a hundred doesn't proposers looks like you know one proposal every seven days rough isn't it does that sound familiar is that a proposal yeah a meeting right now right it's like six seconds for a salade so in order if you have thousand proposed the proposers then you get one per day so add about 90,000 or so $90,000 here get some one per week and if you go all the way up to like a million then you get one but every once so yeah yeah is the frequency of it a concern that you don't get to do so many proposals is that once it's w-why it's an operation and you just don't perform very often I don't know you have to be available for a very short period of time so you're available for that short period of time on every epoch thank you buck for being part of a committee it's like an additional rare duty on top of your committee duties that Awards you extra capital so it's worth thing it's just from - I believe I don't think it's like a major hindrance regarding to peer to peer network planning stuff just too carefully from demos at least we're we're just gonna run over any network for for the next month and indeed what kind of start looking at it or the next year just sort of properly implement I don't know how the other groups are approaching decision I think that was gonna run it over depth which would be probably unless unless we're lucky wouldn't it be to be yeah I think that's a sane approach oh just any Petunia their clients want to comment on their current strategy in pi vm we do the same thing we automated on deaf p2p for now let's move on to the next agenda item which is the low-hanging fruits for testing by mommy you wanna yeah so a part of the spec that are pretty much a standalone and if I can like shuffling if I have everything in the spec I just copy past in my test generator and we can have a shared test vectors in ml if some are missing like pls I just ask my VM if there are some kind of implementation that we can use like a blessed one from the EF and if you have some suggestions about test vectors feel free to open a PR on the test gen repo the goal is to push that upstream so in as ETH to tests once we have something solid and that we know that other people can consume but for now I'm using the status repo because it's easier to tribute for me I've been about to again and help you here focus mainly on spec but I'll spend some time on testing on YouTube and on the terms of blessed by a VM side we're doing a lot catch report over there so on the order of a couple weeks will be a similar spot where we can begin sharing testing ok so well if you know any low-hanging fruit that are pretty much implemented cleans the speck feel free great the next thing is the unsigned underglow there's kind of been an ongoing discussion around this seems I want to catch yourself on the call so that's another Eaton I put because it was raised twice in the past two weeks by yacek and Paul Henare from Sigma Prime I think we should have I don't know how maybe just removes the - from the spec and just use the plus everywhere or at least put some I thought last last call about some kind of implementer good practices and maybe the sign suddenness potential issues should be put in there yeah I think that's fair I do want to move towards the the plus I think that we did add that a few spots but as Paul pointed out that anything coming in from a user might actually just be very high values that mess up that Plus and cause overflows even though they're highly unlikely because most of them are related to slots but if it's user supplied data they can they can cause that so it doesn't fully fix it I think it's better but some separate best practice document I think would be a fair thing to start on Jessica I know you've kind of in a similar vein want to define what the scope of regional values are for these most of these variables do you have a proposal on what form that would take it where that would live well there's two two things one is I don't know as a community and as a as a network we want to be offering to our users certain guarantees that the system will continue to run for whatever time right and that requires that all the clients implement the spec with support for some minimal values in terms of how many slots would be able to process and so on like just what a general competent network right so those are minimum values and then and everything exactly analyzed which ones are listening that every time supports [Music] [Music] we support 200 years of slots that means that there it's mathematically guys even in 64 year and whatever else those are good guarantees to be able to you're fading can't be anywhere better no yes yes so again you entirely fade it out we can't hear you no no yeah yeah sorry so you can mathematically they write these things and enough to come out of a formal implementation of the spec I'm not sure a lot of our by Archer that will handle January or March or whatever but I would see this this as a help many quality inclusions of immunization ready I think I generally agree I in terms of where these information might live and you might be an accompanying document rather than embedded into the phase zero document and I mean if you want to begin delete the charge on that I'm very open to incorporating a separate document that kind of defines some of these values for the community and decisions at all yeah I'm gonna explore it a little bit more I think it's much more viable now that Mike is starting to slow down on yeah yeah maybe this is a maybe this is a January mid-january activity yes there's no hurry on that means but yeah and see if I can formalize that talk a little bit more okay increasing sounds good okay so we haven't necessarily solved the underflow or overflow problem we know it is a problem and need to make sure that we addressed Danny yeah we you suggested the three times that we should put things in accompanying document should we create a repo for that or can we use maybe not maybe not the ETH 2.0 specs because it's quite busy already and we want to keep that focus but should we create a new like ETH 2.0 implementers guide I actually would lean on the direction of just making a new folder well the issues of yours might get crazy for now I would lean towards making a new folder and if we need to pull it out i i'd rather these things live closely together yeah that's true okay for the time being if it gets too crazy we might move it interfering but i think we can handle Alexa diamandra though anything really other related to the last couple things you're going though before we move on to which we did a handful of this kind of throughout but the just general SPECT questions comments discussion okay I was for doing another form we'll meet up and get together or conserve a concentrated whatever you're getting us all together in a physical location on the research team were erring on the side of not doing anything in q1 that kind of causes us all to gather in one location specifically obviously there's always kind of stuff going on so some spontaneous meetups happen what can happen but we're thinking maybe in April that we target April to get everyone together you know and keep q1 just like we focused on work and then gather ourselves together in April and begin to solve the next string of colonies and right now I don't really know what that guy Lang would look like exactly maybe it'll be us getting clients talk to each other maybe it'll be us hashing out six fishing proposals maybe does that sound generally reasonable great any other further discussion on any thing at all any I just wanted to tell you about topping it's been you know it's been a freaking question getting outs to us a prismatic so would expect to like issuance overall for aetherium I mean the idea is that eventually you know people that have their private keys will have the same amount of e as they did on 81.0 once we migrated the whole state of 1.0 2.0 so the question is in the meantime before we might have in this state there's going to be an allowed leaders earning rewards basically and overall the issuance of etherium the cumulative issuance will go up right so I mean have you guys thought about this how the transition will happen what will happen to the economics of heat throughout that process etc he's wanted to spark a discussion around that topic there's a lot there one the issuance Saval deters is generally marginal compared to the issuance to minors so I don't see as a major we're decreasing to two relatively soon on the work chain and we'd be increasing a marginal amount when we create the peaking chain and then wand that there is a proposal floating around to do kind of like this hybrid proof-of-work SiC proposal where you begin to utilize that you can change the finality in terms of issuance you know the community seems to like reducing issue and so I'm gonna prove or change so maybe depending on the economics over there and depending on if that proposal adopted the community might push for further issuance reductions on the report chain I'm not going to be you know charging for that political justice I'm gonna stick with something technicals overtime ultimately issuance will go down when this entirely quickly through the state and during that time yes validators can move steak over through this deposited contract but when state execution exists on sharp chains there will likely be another enshrined transfer contract or deposit mechanism to move from f-102 to there's a lot of little things to think about and how that transition happens but I I don't know if I'm gonna sell all good it so in that case it doesn't make sense to talk about release unless it's phase one upwards right like two main that really sweat to do like a maintenance if any any sort of client may not of like a big future yeah yeah like should we go live basically with zero where should we go live until phase one and I think we should go live with phase zero because getting a live proof of stake chain is no small feat and keeping managing complexity in such a way that like we can make sure this works and we can add this and make sure that works we can have this and make sure that was I think is it rather than doing it doing it in a slightly semi-main net and conditions is I think gonna give us much more valuable feedback and rather than waiting till phase one or phase two a swatch anything obviously if phase one is like all that shit's ready then we could consider launching it together but I personally think it's wise to launch phase zero without the phase one because there's there's only so many proof of stake blockchains out there and I think it just I want to get it right any thoughts on that No thank you it's pretty clear thank you cool and also with respect to just interest rate and issuance in this is full proof of six system there's an issue open in the two aspects repo about discussion on this there's a guy Eric or his last name who's running github I know not gonna eat hub and running Etha and he's been doing a lot of different economic analysis and stuff and I think there's so much room for the community involved in that conversation regarding that he put something on reddit because CFTC which is a commission of commodity trading in I don't know the full Achra name so he's asking everyone to contribute to reply to them about like the purpose of a ferry on what YF areum when a Bitcoin exists and things like this so yeah yeah I saw that's pretty cool effort someone shared and looks like there were some tougher questions at the end about pretty safe and implications when you make derivative contracts on these and how that affects the signal [Music] okay anything else yes concerning the meeting in April I don't know if the location has been already decided but if not I would like to propose Barcelona thank you I know what does it add Kahn is in Sydney and a bunch of us are gonna go to that that's kind of what's been talked about a little bit but obviously we need to figure out a lot of people are gonna go to that or not before we do I'd love to do something in Barcelona in 2019 regardless yeah I think even if not spring-like porcelain as the place to do it in your absence seems like it makes a lot of sense [Music] cool any other any other anything great thank you very much the holidays are coming up so I'm not sure exactly when we're gonna have our next meeting likely first a second week of January rather than in the you know end of December really generating but we'll we can communicate on the sharding getter as always be in touch a lot of excellent work going on let me know if you have any questions comments this mean now and then and stay tuned is like those facts all that thank you everyone it's good meeting talk to you soon thanks everybody thanks guys bye thank you thank you thank you [Music] [Music] [Music] [Music] [Music] 