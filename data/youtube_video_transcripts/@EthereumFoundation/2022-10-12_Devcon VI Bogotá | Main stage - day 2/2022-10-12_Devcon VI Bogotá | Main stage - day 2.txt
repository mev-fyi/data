foreign [Music] [Music] [Music] this is [Music] thank you thank you foreign foreign [Music] like this foreign [Music] foreign [Music] foreign [Music] foreign foreign [Music] [Music] you'll let me appear underwater to help me breathe no Spanish till life's over with you my dear foreign [Music] [Music] [Music] thank you [Music] I'll help you heal make you stronger than your inner feels [Music] and I'll pray for you my dear stay together as long as we're here [Music] [Music] thank you [Music] foreign [Music] [Music] thank you [Music] foreign thank you [Music] foreign [Music] [Music] foreign [Music] foreign [Music] [Music] [Music] thank you [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] I am foreign [Music] [Music] [Music] God [Music] we're not crying [Music] foreign [Music] coming up [Music] foreign [Music] thank you [Music] foreign [Music] [Music] foreign [Music] [Music] have you been losing faith I Don't Wanna Talk About It today [Music] now I wanna see [Music] I wanna know what's in your head around me in [Music] time is Christmas all right good morning everyone my name is Gloria cambrala I'm sorry for all the extra energy I have but I have it all the time so hope you guys get used to that uh my name is Gloria camboella I do developer relations for buildbox which is under super modular I'm formerly of get coin if I've known you like come say hi of course I'll be your MC for this morning and we'll get started uh right now so I would like to bring up our first Speaker our first speaker is Jeff Lampert Jeff is the Project Lead for privacy and scaling exploration solutions for the ethereum foundation and for Jeff's talk this morning they'll be talking about interrupt and interrupt is a bridging solution from web 2 to web 3. so with that I'll go ahead and hand it over to Jeff hey thanks Gloria hello Devcon good morning um so I'm Jeff Lampard I'm from the privacy and scalings Explorations team in the ethereum foundation and I'm going to talk today about interrupt which is a project we've been working on it's in the identity space uh so a brief introduction to what we do it's there's lots of projects in the trying to bring identity into ethereum um and they tend to be like uh have some identity source and and build it up from from the ground our approach is a pragmatic approach where we built on the identity that we already have in our digital uh in our digital lives um and we bring that across to ethereum so we can have an established pool of uh or established identity uh pool and we we can integrate that into our ethereum applications um so yeah very much a pragmatic approach building on the identity sources we already have so what we aim to do is build a bridge from existing digital identity sources to ethereum uh integrate with providers of those identity sources and then privacy is very important to us so we build on the semaphore framework of those building blocks all come together to form the basis of an application so identity um we spent a lot of time in our social networks uh um some people more than others but you know people spend a lot of time on their Twitter accounts and building up putting out a bit of our personality in into those accounts uh so we spend you know every tweet you you write is a bit of humanity that goes into that tweet that represents you and we build those up in in our social Network accounts um people some people spend a lot of time on that kind of thing even if you're not into social social networks big time we still have digital identity in the in the non-web 3 world we have things like government IDs and driver's licenses and all that kind of stuff so um yeah it's our our real world human identity is reflected in those digital sources so that's what we try and build on but we need to recognize that those digital sources also are vulnerable to civil attacks so we need to yeah filter out the Bots and kick them out um so they're the kinds of things we're trying to do with interrep now um let's take a look at what the interrep Lego block looks like in an application we have we have uh everything rooted in the blockchain interrep is the Lego block on top of that that provides the identity the identity module um and the Lego block on top of that is semaphore and your application hooks into semaphore and with all of that we get the um the identity layer in interrep we get the Privacy layer in semaphore and we get the blockchain sort of providing all the all the guarantees um interrep will integrate with those identity sources like our social social media accounts and those kinds of things now semaphore relies on the idea of groups you form pre-existing groups and the semaphore replication will use those identities in those groups to verify the kinds of things that your application is doing so semaphore is is a privacy layer so those groups the group membership is guaranteed but never revealed it's never revealed what the underlying ethereum account is so um yeah so we'll talk a bit more about the the details of that a bit later but that's an idea of what your application stack is um it's yeah it's really just a bunch of Lego bricks all plugged together uh the kinds of identity providers we've been linking with so far uh these examples Twitter and Reddit and GitHub so what we'll do is a an oauth uh verification on your Twitter account for instance and using that we'll link it with an ethereum account and never reveal that link but we we maintain that that link that Twitter handle is always reflected in that in that ethereum account uh and it's easy to for us to add new new providers is really just it's an oauth verification and some rules about um you know what's a qualified account or what does it look like a bot does it not does it look like a human um we can also integrate with other providers we could use email as a as a an identity source and this is useful in some cases not in others maybe it's not so useful for Gmail accounts but even Gmail has some barriers to entry so but if you've got like a DOT edu account email account then that's a fairly good guarantee that there's a human behind that account and and a reasonably good guarantee of uniqueness so we can use those kinds of sources and integrate with those government authorities are good in that um you know the government make sure you only have one driver's license for instance uh and there's there's a strong guarantee there's a human behind that driver's license so if we can we can integrate with those kinds of sources and it also includes the people who don't use social media so that's another approach we have um we can do things like curating groups of of um users so that might rely on personal knowledge of of uh of the individuals involved so that's that's also a strong way to guarantee Humanity other ID projects we can integrate with those and we can integrate with Unchained sources like use things like nft ownership that kind of thing now a bit about semaphore so with those identity sources we create a group we put someone into a group now semaphore relies on these groups semaphore groups uh membership sets so um there are guarantees of uh once you're in that set you're you're expected to be you know anyone can expect that that identity to be to have a human behind it um so and with semaphore it's a generic framework in which members in that membership set can signal on a topic and that apply that can be applied in multiple ways but an easy to grasp example would be a dow that has votes on proposals in that situation a signal is a vote and the topic is a proposal and semaphore will guarantee that that anyone who votes is a member of that group and they can only vote once and all of that is is uh is done with privacy so you don't know who is voting on a particular uh voting in a particular direction so it can support secret votes but it still maintains strong guarantees of um membership in that set uh so this yeah the semaphore framework gets used in lots of ways but uh the group membership part of semaphore semaphore plain vanilla semaphore has its own group management but what we do with interrep is semaphore outsources the group management to interrupt and then that's that's um interf itself is is basing its identity groups on for instance on Twitter membership and GitHub membership and so on so um the way that works is users will prove their membership on that in that social network identity source um h so that will form a Twitter group but we subdivide that into tears which basically represent a level of confidence that there is a human behind that behind that ID and as we know uh Twitter is riddled with um Bots um so we will just apply rules to filter out the spots as best we can we won't we're not going to say it's perfect but we'll get pretty close uh good enough for most applications the way we do that for instance with Twitter is we'll have a we have some criteria that we apply ourselves with Twitter it's a a fairly High bar to get in Gold status you'd need 7 000 followers um with two thousand fellows you'd be silver with less than that you'd be uh bronze but we also linked to botometer and that will do an assessment of your Twitter account and for most people that's gonna that's that's going to give us a score on how much botometer uh how confident they are that you are not a bot um so most people with a bit of history in their Twitter account and a few followers will be able to get in silver or gold just using that bottoma to school you can you can try you can join a group and and on our website and um assess your own status there and see if you can get into one of those groups I'll the link will be in the in a later slide um but yeah so the way we do it is um is we'll we'll do that evaluation uh give someone a score and then assign them to that to that that level that tier bronze silver or gold um and uh that yeah so uh applications will be able to choose what level of confidence they require some applications will insist on a strong guarantee of humanity but they're going to be working with a smaller pool of of people who can qualify for that so some people some applications will want a large group of people to draw on and they're not so uh not so concerned that we strongly guarantee Humanity as long as we do some filtering to kick out the Bots um so that would be a bronze level with interact groups because interrep is managing those groups if you join a group that group can be used across multiple applications um so you can join once and use it in many applications and effectively you've got to sign in that will be workable across multiple applications and the advantage of doing that in a privacy setting is that we have a large privacy pool uh so the nitty-gritty process of of joining a group the user will come to a sign on screen sometimes it'll be a step just before they go in to use the application sometimes it will it can be done well beforehand someone can join a group and then they'll keep their identity and use that to kind of log in to work with the application so whichever way that's done first step is to prove the identity with the provider that might be like Twitter oauth or GitHub or auth having done that the application will do that assessment assign the user to a tier called Silver bronze and then invite them to join that group so the user will uh do their Twitter sign on say okay you're in Twitter gold would you like to join this group they click click that button and then the next step is they link that with an ethereum account so the user will sign a message with their ethereum account which guarantees that they own that ethereum account it also prevents that account from being used again so they can only join once and the Twitter account likewise can only join once so having made that link we we have we return a semaphore ID the semaphore ID provides that guarantee that that Twitter handle is represented in that semaphore ID and that can be used from there on in the application without revealing that link of who the actual Twitter user is behind that account and neither is the ethereum account revealed in the actual application because we're using semaphore IDs and it conceals that we can also work with on-chain sources of uh proof of humanity if you like some of those are pretty pretty strong guarantees of humanity and I'm thinking there of like Sol burn tokens or poapps like the pop-up you get from your Devcon 6 with your Devcon 6 ticket that can only be owned by a human right because they're only giving out tickets for humans um so that's a that's a pretty good indication that that account has a human behind it uh it's certainly very hard to um very resistant to civil attacks so yeah so we we take a slightly different approach with on-chain groups behind the scenes but um but they end up as a semaphore ID and work the same way in your application so the kind of applications we work with that we have in mind for interrep uh private voting I took a bit about this before um yeah membership of uh Dow for instance and we can guarantee membership guarantee that there's a human behind that um uh a human in that in that group but never reveal who that human is social networking we think is a promising way to apply this and some of our sister projects in privacy and scaling group are um working on this you'll hear some talks in Devcon about that um but yeah that's uh another place where privacy is important but also Humanity proof of humanity is very important um we have anti-spam applications like the rate limiting nullifier another one of our sister projects we can do things like Fair air drops and civil resistant faucets so if you want to um yeah put some anti-civil properties into a an airdrop or a faucet interrupt can do that kind of thing so to close we think a pragmatic approach to Identity building on our history that we we all work on you know in our existing digital lives taking a pragmatic approach to to use that bring it across to ethereum um we can build up we have a existing source of identity that we can build on we don't need to build it from the ground up uh we don't need to discard those relationships we have in our social networks but we don't want to bring along the surveillance opportunities the opportunities for misuse and abuse and we can build applications that respect personal privacy so our theorem accounts can be used for more than just Financial transactions we can start to extend it into the social realm bring along our social relationships give them a human context and make our accounts more incredibly human and our applications in the web 3 world so the links that QR code is to our Discord you're welcome to come there and ask questions and find out more you're also welcome to come and hit me up I'll be hanging around a lot at the temporary autonomous Zone down on the ground floor um which is the pse's um uh little uh hub um you're welcome to visit the application interrep.link and you can sign on there get just get yourself signed up with a server ID see what your Twitter status is maybe you have to work on that we've got documentation links we've got our code open source you'll find all that on the um on those links but yeah please come to the Discord and ask questions if you or come and ask me in person so thanks for all that um the QR code on this slide is the Discord for privacy and scaling we do lots of cool applications in the xero knowledge space so you can join that Discord and ask questions check out our job openings if you like building cool applications for privacy and scaling and check that out and on that note thank you [Applause] [Music] thank you so much Jeff I think anything that makes a more civil resistant uh Network and is probably something that I really appreciate after spending so much time at getcoin and working with get coin grants um one piece of information if you are ever asked for a grant or are looking for Grants the EF is having grantee day downstairs on the first floor I believe in Workshop room two or actually second forward Workshop room one so if you're interested in getting a grant from the EF it's going to be all day down there you might want to go ahead and check it out all right uh next up next up we have Andrew and Andrew works at give directly on part of their Innovation team and he will be talking about lessons from the field uh threats modeling for everyday use of digital currency [Music] [Music] I don't believe [Music] foreign [Music] [Music] got me so in love [Music] foreign [Music] foreign [Music] [Music] foreign [Music] [Music] [Music] show me [Music] together [Music] foreign everyone please welcome to the stage Andrew vasiri Andrew works at give directly's Innovation team at this his presentation today will be lessons from the field threat modeling for everyday use of digital currency welcome Andrew [Music] all right thank you for that great introduction good morning Bogota okay we got a couple I think we can do better than that I mean we are at a very high elevation and this is the highest conference room so as an excuse you are the participants at the conference with the least oxygen right now good morning Bogota awesome but that's a little too much okay don't get too excited I wasn't kidding about the oxygen there is a sensor there that's literally measuring the CO2 in this room if you get too excited we might suffocate I'm Andrew vizieri I've worked at give directly I'm on the Innovation team and this is the presentation lessons from the field threat modeling for the everyday use of digital currency before we talk about the uh presentation though I want to take a step back and ask why are we here at Devcon this was the topic that was first brought up yesterday at the kickoff on this stage why South America why Bogota because ethereum is for everyone it's not just for financial capitals it's not just for the most comfortable developed places it's for people who are uh still in places where they might not have Financial inclusion there might be more corruption uh there might be more censorship and those are the people who really have the most to gain from using ethereum give directly sends cash directly to people in poverty poverty the kind of people who are in those settings we've reached over a million recipients we've raised nearly a billion dollars we work in more than a dozen countries and we've had some of the greatest Partnerships that that you can in the development and Aid space and that has really been made possible by our approach giving people cash is really simple right if you want to financially include someone financially include them I think this really brings me back to yesterday's talk about subtraction about keeping things working very hard to keep things simple and effective it's really easy and charity to say we're going to get the best experts we're going to decide exactly what people need and I think it's a little bit more respectful and in fact it's been proven to be more effective to give them cash because they know what they actually need so let's talk a little bit about our approach and at give directly our approach always starts with recipients first so what does a recipient look like this is lizoma she's from kibera Kenya and that's her house on the left so this house you can see it's very modest it's made out of a whole bunch of different materials whatever she had on hand it probably doesn't have a door that locks it probably doesn't have Windows that close but Liz does have some access to technology specifically she might have what's called a feature phone if you're old enough you might have had one maybe you skipped that you went right to smartphones but this is a very simple phone you can make calls you can send SMS and you can use ussd now that third one might be less familiar this is when you can go through a series of menus where the app is being served on the other end by your Telco so you could go through those menus and you could see how much air time you have left top up basic things so in her setting she might not have reliable access to electricity it truly does make sense for her to have a phone like a feature phone that can last for many days without being recharged and we want to meet people where they are when we're trying to help them and so when we look at our process we have four steps and each one of them is designed to meet the recipient in their environment Target enroll transfer monitor so what is Target targeting is of course to figure out who is in extreme poverty who could benefit from this or in some cases if we're doing humanitarian work who's been affected by the most recent flood or what area needs some help to achieve equal rates of gender participation in education so there are all sorts of criteria we could use to try to figure out where to send money and that's the targeting step the next step is enrollment so this is uh very relevant for the talk that we've just heard we need to verify people's identities we need to make sure that they're real people that we're not just sending money to some account somewhere which was set up for the purposes of Fraud and we need to be in person there's no such thing as a free launch I think everybody is skeptical if somebody came to you and said I'm going to give you what is more than a Year's worth of your salary tomorrow for free you wouldn't believe them it has to be a scam there has to be a catch and so it's really important actually that we go there and we can talk with people we can build rapport with them and they can hear about other Villages nearby other people who've already gone through this process and they can know that this is truly unconditional cash it will be theirs they can do whatever they want with it the next step is transfer presently these transfers use centralized digital currency systems these are mobile money systems that are operated by telcos these are very popular in Africa and Kenya over 90 percent of households use m-pesa which is Safari comms mobile money these sorts of systems truly are the best systems that we have at the present day it would not be sensible to give somebody literal cash although it would be more private and more decentralized their house doesn't have locks you know that would expose them to a lot of risk and danger and finally we have monitor so we follow up we make sure everybody was able to receive their cash that they were not threatened they weren't bribed nothing bad happened to them because of it uh and that they continue to understand how to use their phone how to use it safely securely to protect their pin code Etc so let's talk a little bit in more detail about fraud prevention and then we can talk about how we might reimagine the system with web3 so give directly lost 241 000 in 2021 and that's about what we would expect now that's a lot of money but at the same time because give directly operates at such a large scale that's only 0.2 percent of the funds and you can see on this chart here that 2021 and 2020 were relatively similar and you can see that we have a breakdown of the types of of uh fraud that we discovered the first is theft makes sense somebody coerced a person to give them their money or perhaps uh tricked them lied to them tricked them into revealing their pin code the next is imposters this would be people who should not be eligible for a program perhaps they are assuming a false Identity or they've pretended to move into a place where they don't actually live and the final are bribes uh people who have uh asked for payment for some sort of favor which is not appropriate which is an abuse of their power so the rest of the presentation I'll talk more about theft and bribes while imposters are important I think theft and bribes affect individual people directly and that's of course uh makes them even more important so some of our measures that we take we have our standard approach which we've already talked about we're going to give them training when we first meet with them there's a hotline where they can call us we do follow-ups to make sure everything went well additionally there's a recipient advocacy team so this is an entire team that's firewalled from the day-to-day work the people who are doing targeting operations Etc those people don't even know who the recipient advocacy team are and that allows us to do audits we audit that nobody on our team asks somebody for a favor in order to be included with a program and finally we'll do risk assessments so sometimes in a certain setting it's actually quite uh sensitive and so we'll we'll take additional actions we'll randomize when we send people to the field if we know that our our field officers are being tailed by scammers or people who are trying to take advantage will make it as hard as possible for them to figure out who was in our program additionally we'll conceal who's being enrolled and we'll stagger payments if we pay everybody at once they all go to the market at once it's very obvious that XYZ Village was the village that most recently received their payments from give directly so that was an interesting system but I think we can make it a lot better and to that end let's talk about what give directly currently does splitting that into two categories funds in we've received crypto donations since 2014. we've been very happy to receive more than 50 million dollars in direct crypto donations and I think that speaks to how well our Visions are aligned give directly and ethereum are both focused on financial inclusion they both are focused on empowering and respecting individual people and their privacy uh and for that reason I'm very happy to be able to speak here today uh in terms of funds out we're still working on uh piloting these programs but it's been surprisingly uh an interesting learning for me this year that I always assumed it would be really painful to use cryptocurrency you know it's so much easier if you have a smartphone if you're in a setting where you don't have a lot of technical expertise you only have a feature phone I would have expected it to be quite quite difficult but in our initial Pilots it's second nature if you can make the product feel like what they've used before feel like mobile money then suddenly everything makes sense by analogy and in fact there were very few questions about how it worked and more questions about what are the fees what are the exact details of of the financial uh incentives here so in the interest of time I won't go through the centralized versus decentralized I think people in this audience probably know that there's a lot of value to be had by more decentralized system what are the Privacy threats that we see and specifically what would be happening in an naive implementation with a public Ledger contrast presently we're using centralized systems so they have some degree of privacy as long as nobody leaks the information it's not published anywhere um and we would imagine in a public Ledger some of these types of Adverse Events might become more common maybe the first thing to say is that while in an naive implementation people are anonymized they just have a wallet address that's probably not going to be enough the first time you transact with somebody in an everyday setting you've paid them for a good or service they've gone to a store that has a known wallet address it's very easy to quickly de-anonymize uh everybody in your local community so thinking about that theft becomes very easy if you're sitting outside of a store and you wait for somebody to walk in and you're refreshing the blockchain on that store's address you could see the most recent transaction you could see the balance of that person and you could say it's worth it for me to take the risk to mug this person because I know that they have enough money that I will potentially benefit bribery similarly people pay legitimate fees all the time once they've paid that feed if you can look at their balance you can know exactly how much you can extort them or they'll be able to pay fishing you'll see I'm not wearing any give directly clothing in fact there doesn't exist any we're very serious about preventing fishing and just showing up in a village wearing give directly clothing is enough to let you social engineer much more than would be safe for our recipients and if you imagine what somebody could do with a public Ledger they would be calling somebody who had been in a give directly program that person has already been sensitized to expect a call because give directly follows up they would speak to that person and say hey I know that we've given you a transfer in exactly this amount at exactly the state I see you bought a sandwich yesterday that was a dollar fifty uh was that you great let me secure your account please open up your app I will need your seed phrase and suddenly they've lost all their money uh the next category is scams of course scammers are always trying to find the people who are the most vulnerable who don't have people who can intervene and say wait this doesn't sound right so they're looking for people who are elderly people who are illiterate people who are going to be more likely to be scammed and we don't want to make that any easier for them we don't want them to be able to cross-reference these are all the elderly people and these are their account balances in this Village and therefore will Target so and so and finally maybe the most hard to pin down is social pressure it's supposed to be unconditional cash it's supposed to allow people to make decisions for themselves and if that decision is for example to send your daughter to school that might not be the norm in the place that you live and it's very important for that person to be able to make that decision for themselves and for their family without people giving them undue scrutiny so of course there are mitigations for this that was all assuming the naive implementation you might have heard of Aztec that's a layer two focused on privacy and they have many of these features balance and transaction privacy it's enabled by default for example if if uh I told somebody hey there's a way to be private you're going to go use the smart contract called a Tumblr you're going to add to that Tumblr in one amount and when you subtract you'll subtract in a different amount and each time you subtract you're going to make a new wallet address now if you understood that you were probably Afflicted with a terrible disease you're probably a developer and I'm sorry to say it's terminal okay maybe that joke wasn't that good okay but for normal people that's like way too much okay they're not going to be able to do that you need something that's more akin to venmo you can easily swap between private and public and you can be given a little warning that prompts you hey this is public people will read it in the future do you understand those implications and finally the fees need to be reasonable in a setting where you spend in your entire day less than two dollars and fifteen cents to feed and house and everything even a fee that's five cents kind of precludes you from doing stuff on an everyday basis you know you buy three meals you've spent 15 cents you're getting close to spending 10 or 20 percent of your daily budget just on fees so going to extremely extremely low fees can be important and given that privacy features generally require more gas more uh transaction fees you know this is a challenge and luckily there are a lot of Solutions on the roadmap to help with those scaling issues okay so if we assume that we exist in this private L2 in a future State maybe post-surge where the fees are low we still need to think about how do we actualize this how do we bring it into the real world and have people comfortable with it existing in their country and I think it's important to think about in this hybrid model where there are real world activities but there's also uh blockchain underlying the mechanisms that we can have censorship resistance as a feature but we can't have it as a strategy and what do I mean by that I often hear proposals of people who may not be thinking about the recipients or people in extreme poverty and they say something like oh okay if if people don't like this we'll go the permissionless route just try to ban us just try to just try to stop us you can't really it's decentralized so that works if you're only making a financial product and you're okay uh with uh operating in a in a hidden manner but the moment that you think about a hybrid method where you actually need to go out and meet people and build rapport and you need to follow up with them all those activities become impossible with that approach now what's what's a good example of censorship resistance you might be in a refugee camp and refugees are of course in a very precarious situation they may be re-housed moved somewhere else depending on political changes they might be supported in one regime and not the next and so it is really important in those cases that we have something which is really owned by the people themselves so if they're changed if they move somewhere else if they go to a place where different Telco operates all their funds and their livelihood isn't tied up in Mobile money it's something that they can continue to have access to so if we assume that we have cryptography and we are going to try to work with governments and have uh this be a force for good government we are going to need a couple more features so selective disclosure would allow us to continue to have the kinds of systems and institutions in place that Democratic societies often create so I'm talking about having legal recourse having regulations even taxation and I know that's not a really popular subject but I just want to imagine for a moment if somebody was interacting with you in a truly fully private system and they claim they pay you and you claim they never paid you and you sue each other and you go to court and you're in Discovery ideally you should be able to say to the person who said that they paid prove that I paid and they should be able to do that without exposing their public key with or their private key rather without giving you access to their funds they should just show you that one transaction so that would be an example of how I think presently we have some solutions where there's a viewing key you can see everything that ever happened associated with that account that's probably a little bit invasive of privacy and so I look forward to better ZK proofs where we can answer the specific legal question that's at hand for only as much information as needs to be uh communicated to resolve the issue so takeaways from this talk I hope you uh agree that ethereum is for every person and if we think about every person the people who have the most to gain are the people in extreme poverty or in places where their institutions are really not functioning very well today we have to think about each person as existing in their own ecosystem right they exist in a house that doesn't have locks what does that mean for them they exist in a place where their government is going to need to be a partner if we're going to help educate them and bring them services in real life and finally I would like to thank everybody for their work and remind you that today's EIP is tomorrow's family tree that's kind of a lame rhyme but it's the case that some of these really uh I don't know Bland or at seemingly at first glance not very intriguing improvements actually fundamentally change how usable this technology is so if you read the text of eip4844 you might not get it at first if somebody explains it to you it makes Roll-Ups less expensive but thank you to Proto for providing me with this chart how much less expensive if you look at gas fees on optimism for example the L1 data fees are like 97 98 of the expense of each block so if you can imagine that we create this EIP we're going to suddenly be in a case where instead of paying five cents for every transaction you're paying a fraction of a Cent and you can actually use it every day and it's a zero to one change it's a step change that I'm very excited to see happen hopefully in in just a few months so thank you again I would encourage you to support uh all the relevant eips and of course the surge uh reach out if you think we should work together my Twitter is also just at my name and if you're interested in donating to give directly that QR code will direct you to all of our addresses thank you [Applause] we do have a few minutes yeah um if you have questions feel free to raise your hand and one of the volunteers will hand you a mic um so we can go ahead and take some questions there's a question right here in the front row there's a question over there go ahead thank you very much for this I I'm kind of impressed that you've raised 50 million dollars from philanthropists that are sort of handing over the decision making of where the money goes that's impressive do you have any kind of idea who um are the sorts of people that uh that that uh that do this I think that a few of them are uh giving their donations under an anonymous circumstance I mean it's just a crypto uh wallet address you anybody can send to it but I know that vitalik has been one of our top donors and you know thank you to him awesome I know there's a question in the back yeah and there's also a question over there Hi man uh great job what you're doing man I just heard about how about your project and what you're doing uh what's the landscape in Latin America like what are you what what do you think about Latin America here we have so many problems that you describe like crime corruption bravery worst governments you know like there's it's really bad and I see that you support a lot of African countries so can you tell us about Latin America if it's in your roadmap or or not or or when yeah absolutely great question so we've done projects in many places throughout the world Africa tends to be the primary source because many of our funders are looking for where is the place where the poverty is the most extreme the most widespread and so their dollar will go the furthest now I don't think that that precludes us from being other places but it's a question of finding the funding of people who are specifically interested in seeing change in Latin America and luckily there are a lot of uh things on the horizon I know that there are some U.S government and other International organizations that have recently proposed some more Aid so hopefully give directly will be able to bring some of that to Latin America soon awesome I believe there's a question over there too on the yeah with the gentleman in the black shirt AGM uh amazing presentation thank you for that I'm Russ uh founder of 40 acres Dow and chief five officer and we we kind of echo a lot of the same sentiments that you talked about today really through trying to create self-sustaining communities of color utilizing blockchain technology as we've seen like the biggest hurdle has been just this convoluted language and vernacular in which we use every day that makes sense to us but for other people just goes over their head liquidity pools yield farming amms so we've been trying to aggregate all that information through education empowerment and engagement and so the question I really I mean you guys been doing beautiful work raising 50 million dollars and so as far as allocation goes do you guys focus on protocols is that something you've been thinking through helping aggregate it to certain communities versus just individuals themselves thank you great question so right now we're at the prototyping stage so our our funds presently are used to test delivering cryptocurrency uh directly to recipients and I think that we obviously want to have that kind of killer app that says why did it make more sense to do this on a general purpose blockchain and that goes back to I think at the beginning of of this event they spoke a little bit about the over emphasis on financialization right that there should be non-financial apps and I think that that's an incredibly important point to show that this isn't just an alternative to mobile money but this is actually something new and different this is infrastructure this is part of a functional Society so I don't have a particular protocol that I can say today we're kind of proving that first step which is it's at least as good as mobile money and once we have that information hopefully the ecosystem will have a lot of great partners that we can start proving why it's beyond uh present-day Solutions I know that we have just run out of time but thank you again I'll be off to the side after the talk and I'll be with you at dinner once you invite me there thank you so much Andrew for your talk I think it was so important to remember the human aspect behind blockchain um up next we're going to have Guillaume ballet but you have five minutes between that and this next transition I do want to give you all a reminder that if you are grantee or a grant person who's looking for a grant the es is having grantee day and it's going to be down on the workshop room number one on the second floor and it'll be all day today uh we'll conclude with our next talk in about five minutes [Music] [Music] [Music] save me from my mind Keep Me By Your Side when I can't sleep foreign [Music] [Music] tonight [Music] [Music] [Music] [Music] into places [Music] [Music] all right good morning everybody again my name is Gloria kombala I'm part of the bitterbox team under super modular uh I've been here emcee for this morning and I apologize not really for being super high energy that's just how I am um I'm gonna go ahead and introduce to you Guillaume Guillaume is going to be our next presenter it's guillae from the guest team and Guillaume is talking about um stateless stateless ethereum how vertical trees make ethereum lean and mean guilla's on the guest team he's interfacing between research and engineering and he's interested in the evolution of the ethereum protocol I'll go ahead and hand it over to you again foreign hi um yeah excellent so uh yeah I'm going to talk about vocal trees I've been making a few presentations about those already but they tended to be a bit too uh deep technically speaking so because this is Defcon and we're trying to onboard more people this one is going to be a bit more high level so hopefully uh enough to to raise your interest in uh in vocal trees um so yeah what do we what do we uh why are we considering vertical trees uh it's basically a big change in the in the way ethereum functions so what do we want to risk this well there are several reasons the the first one is we want to be able to build uh blocks as a self-contained execution units so at the moment ethermia has a bit of a problem uh that when you want to join the network or if you haven't followed the network for a while you need to go through a process that's called the sync synchronization you cannot access the state directly it's uh like you cannot just download the state I mean you can't download the state but it it's a fairly convoluted process so uh the idea is that if you include in the block everything that you need you can just download the block and execute it and see if you're interested like even before you uh if even if before you execute the blog you can even know if it's going to be of interest to you or not and if it's of interest to you you can execute it otherwise you don't even have to to care so it's something that is it's to build something that is in between a full client and like a full node and a light client in the sense that you are still supposed to follow blogs but you don't have to hold the entire state um and it's nice because it paves the way for other upgrades or it makes other upgrades a bit simpler for example if you want to shuffle committees between between shards in the future you want shards you don't want shards to full uh short the validators to keep following the the chain at all times like several chains at all time so it's something that's going to help them get up to speed a bit faster and of course uh there's the the idea of State expiry like the state of ethereum is quite large so we want to be able to delete some of the state but we don't want to delete and forget forever if your state has been deleted but you want to use it again you need a you you need to provide a proof to resurrect your state and the idea is that vertical trees make your proofs smaller so it will be cheaper for you to resurrect the state so uh because it's a fairly uh like deeply technical uh topic I have tried to re to make a simpler explanation with pirates so imagine you have four Pirates and they they bury a treasure somewhere and they plot the directions to get to the treasure on the map and then they want to go their separate ways so if they adopt the method like the metaphorical method that we uh we we currently use in in this in these terms to store the ethereum state what they would do is they would split the the map in four bits and then each of the Pirates would get their own bits and when they want to get when they want to access the the treasure they need to to put all the the pieces of the map together the problem is inheritance if one of the Pirates wants to retire and for example wants to uh to sell you his bit of the of of the map uh how do you know he's not selling you a fake map a fake piece of the map he's a pirate after all so you should be careful well the problem with this the method that that was chosen is that to figure that out you need at least the other two Pirates to check that the the pattern matches so the proof size is quite involved it requires you to take uh the siblings the the simply The Sibling pieces now um if we use the the proof the proving technique that is uh that is suggested by vertical trees which is called uh like it's based on something called Vector commitments hence the name vertical what you do is you uh like cut out something at the center some little stub and you make this little stub as hard to reproduce as possible ideally cryptographically uh impossible to to fake and then everybody goes their separate ways and when you want to buy the when you want to buy the your your part of the map all you have to do is make sure that your piece fits into that that proof uh that little stuff uh so of course we don't use pieces of paper we we use cryptography as stronger cryptography than this and now this is your proof size and so how do you transpose this to uh vertical trees well the current ethereum state is stored in a tree where all the data of ethereum is at the bottom of the tree and then you group them the parent is a commitment the parent node is a commitment and then the parent of that parent is also a commitment all the way to the top and the root of the tree is ending ending up in the block so if you want to prove in the tree for example the the purple Square here if you use the current method it's the same thing as with the pirates for each level you have to pass the siblings and here this is a very simple representation but in in ethereum each parent node has 16 children and the consequence of this is that you need to pass 16 sorry 15 other value for each value at each level for each value you want to prove so there are thousands of values per that get touch per block that's that's a thousand times 15 values per level and uh if I remember correctly the the depth the tip the average depth of the MPT is between 10 and 15 I don't remember exactly so that's a lot of data that's roughly uh if you want to pass the that data in a block that's three megabytes we are in Bitcoin territory um so yeah it's a bit too big to pass around the network in a reasonable time if you use the Virgo commitment so you have the equivalent like you still have the oops yes uh you have the uh the little cryptographic proof but all you all you have to pass as as your proof is the the nodes along the way to your value and that is much smaller first of all because you don't pass the siblings but on top of that because you don't pass the siblings there's a virtual cycle that allows you to widen the tree you can have more children per tree and per per node and as a result the tree gets shallower so your path is even smaller even shorter and as a result your proof is is that much smaller so uh there's a unfortunately it's not that simple there's quite a few changes to to introduce at the same time uh like the first one is putting the proofs in the block that's uh that's that's the whole point uh but we also need to change the tree structure and I'm not gonna get too deep into the details because once again it's quite involved there's an EIP there are other talks about it uh look at them look them up if you're interested but the idea is that all the data ends up in a single tree So currently accounts have their own tree and for each account you have the another tree that encodes the storage for this account well here everything is kind of uh yeah hashed or mixed together and spread over the tree um each item like each account item for example the balance the nons uh the code the any any slot like for example uh if you're thinking of crypto Kitty each cat is uh accessed independently because we don't want to add more to the proof that is uh required so if I'm sending funds to to a new address well I just need the address the target address balance I don't need to know how many uh how much code they have I'm only interested in in the funds um right and like I was saying the data is spread all over the tree um but we are trying to group things that belong together a little bit so that you don't spend your time jumping all over the tree all the time so it's grouped in batches of 256 and I'm going to go over that uh in just uh just a bit so this is a picture that comes from the EIP itself I'm going to describe on the left side you've got What's called the stem tree and it's the basically the top of the tree so the tree is flipped to the side is rotating 90 degrees to the to the left and um the root sorry the the stem tree only has a branch nodes so that means every node in that tree has at least two children when the when you take your key and you follow the you followed the the past Trace by the key at some point you will reach a moment where there's only one group that is a group of 256 that is uh pointed out by this key so there's this intermediate uh like what's called an extension yeah I don't quite see the pointer here sorry but the blue the blue box um that the extension says this is uh the prefix the 31 byte prefix that every key below me have uh like are killed by so um that means that if when when you go through the tree and you come you have to compare the key that you're using with the the encoding the the key encoded in that blue box and if it's the same that means your data is uh in the group below it otherwise your your data is not present in a tree and then there's the suffix tree so that corresponds to the 256 values and there's a force column that we're not going to cover it's not really important for for this talk um so like I said every every piece of data is broken into chunk that means for example the code is broken into bits uh into 31 byte pieces that are fitted in a 32 byte piece the storage slots are also have their own uh on at their own data the the balance has its own value and each of these uh values each of these chunks is given an offset and for example the the balance is always offset one uh the non-set offset two and then a bit further you have the beginning of where the code is supposed to start and then even further you have the the bits where the all the data slots are are supposed to to be um and the way you find them in the tree is you take the address of uh so you have a key that is made of two two parts the the for the 31st bytes are called the stem and the suffix it's just a byte that indexes in the group that we saw before I'm talking about the the third column here so the the last byte is the index in there um oops sorry and um and so to build the stem what you do is you take the address of the account and you take the the first 31 bytes of uh the the offset of that chunk and you you hash them using what's called a Pederson hash so it's like uh it's like catch Shack but it's much more friendly uh for uh for ZK applications and it's also much slower but uh you get uh you so you get a 32 byte values you take the the 31st bytes of this value and uh that gives you the stem and the way you use it when you compare it to the tree uh the stem will give you the pass through uh the stem tree and the extension and when you you found that you use the suffix to select the the value in the group um so like I said uh just a recap uh vertical trees are are nice because you can make the tree much larger much smaller uh much more shallow sorry you can also experiment with uh with ideas like you could sing so I know that this is very interesting to dab developers you can just download the blockchain not care about the state and when you look at the when you look at the proof in the block at the witness you can you can figure out if your um if that block is accessing something you're interested excuse me interested in so for example uh if uh yeah if your crypto Kitty you want to see if the crypto Kitty contract is accessed if so you just execute that block to update your internal state if not you don't care um yeah and I was uh there was just a recap for the rest of the slide so what is the current state of uh vertical tree implementations uh we have one and a half running test Nets um the we have one test net that is uh fully working it's a proof of work test net called country I'll give the address at the end um and so uh proof in blocks uh it works it works it's been working for a while and then uh there's a proof of stake test net that is currently in bring up phase so unfortunately I wasn't able to get it to to work for for Defcon but it's going to happen shortly um when we do performance we currently have like performance testing we see that is currently five times slower than the regular magnet so when we replay blocks from Main mainnet on a translated vertical tree layer it's five times slower um we have been uh we took it down it used to be 40x so it's it's a bit faster already we have another Avenue to to make it faster but it's I mean in my opinion it's always going to be a bit slower than the current method but it offers some opportunities to to build interesting applications so I think it's worth it um and they are uh there are like three implementations uh and there's a fourth one uh ongoing with uh with Basu so I wanted to I don't know if it's quite readable but I wanted to give an example of uh what you can do with vertical trees so there's a block Explorer on on that test net on the running test net and there's a piece of software uh that is able to read the block and reconstruct a view of the network sorry of the tree that is uh everything you know to re-execute the block on top of it so I don't know if it's quite visible I still don't see the pointer but basically you can see that the the leftmost branch here is an account the the next brand the branch the right of it is another account I mean I can tell because uh because of the way the the last level looks like and uh you have the the other two branches from the root these do not have a very deep tree and that's because this is a proof of absence so that means uh this is the way you signal that those uh branches those locations did not exist before the execution of the block and what definitely happened here um is that those two accounts on the left probably send funds to those two accounts on the right that did not exist yet that they will exist after the the execution of the block uh so it's quite interesting because you you can see what's going on you can visualize it this way without loading the whole tree uh right so this is the current state what are the challenges we still have to overcome uh one of them is the transition uh converting a Merkle tree to a vertical tree is no there's no walk in the park uh it requires a lot of ram it requires a lot of this space um and uh yeah it's uh it's it's quite difficult so um there are two methods really two Avenues to do this uh this translation either un trust the conversion to very powerful machines uh I have a test machine that that is a Xeon it takes its uh six days I know Aragon is able to do it in like uh less than a day but even even for arrogant it's it's not instant um and uh where was I yes um so that's the First Avenue the Second Avenue we have to do the translation is simply to Pace it to the slowest machine on the network so uh that would be to do a translation of let's say five ten a hundred values per block but this would last for a month but then every node on the network would theoretically be able to follow um so these methods are have names uh the one where uh like you follow the pace of the network it's called the overlay tree um the other one was called offline conversion there's a third one that is uh known as the roll-up Appreciation Week where you just do nothing for a week or a month and you wait for everybody to be done translating that's uh it's just here because it's a cool name no one's really considering that um yeah one last thing I wanted to say about this slide is uh pre-images so uh most of most clients including guests do not encode the addresses directly they just write the the hash of those uh those addresses so to do the translation and because we use a different hash system we need the pre-images it turns out that most clients do not store that Aragon does but the rest of them don't so pre-image availability is another problem that needs to be uh needs to be addressed and uh it's not a it's not an easy one uh another thing is the slower cryptographic Primitives it's not as fast as ketchak so this is one of the latest uh runs and you can see that roughly 30 33 35 is spent just doing uh elliptic curve operations so um cryptographic Primitives is really where uh well the effort needs to be the optimization effort needs to be made so either by writing faster crypto or uh by uh by not calling those functions as much so caching for example is is a technique that has worked well uh yeah there's a slide on database design so basically the idea is that uh that like current most clients have written their optimized their database layout and their database access layer for the current MPT a lot of those assumptions are no longer valid uh let alone help helpful with vertical trees so there will be some need to adapt to something that is a bit close to to what Aragon is doing uh but that will take time unfortunately and I wanted to finish on people on what you can do if you want to help uh the first thing would be there there are test Nets so the first thing you can do is just try to deploy your contracts on on test on the test net and see if that works um if uh you can also try to run your own client um like hashtag testing the verge um you can also modify a client to figure out how to propagate the proofs because currently uh it's not it hasn't been defined so it would be interesting to to run a fact-finding mission uh yeah finding out where and how the proofs need to be need to be propagated in a in a proof of stake world um like I said crypto is the is the bottleneck so if you can find a better crypto cryptographic primitive than what we have that would be also quite helpful um yeah it's also going to affect uh Layer Two Solutions like presumably Layer Two uh layer two groups don't really want to to diverge too much from uh from the main net so um they will need to they will need to um to adapt as well there's no really uh there's not a clear path for that yet um like I said pre-images are also a problem so if you have a way to to make pre-images available to everyone that's a very good that's a very good test very useful and then you can go crazy you can try to prototype uh the interaction of vertical tree with the portal network with uh try to implement State expiry using vertical trees all of that no no no no all of that is Greenfield but it's also quite interesting to to get some some information some ideas of of what is to come and with this uh that's pretty much it I have put the addresses of the two test Nets knowing that the second one is still in a bring up phase so it will probably not work today uh but the other one is the landing page for the proof of work testnet and this one works or should work and you can look you can look at the Explorer you can send you can send transaction you can try everything and that's it thank you thank you so much do you mind taking a minute to answer our questions if you do have any questions for Guillaume go ahead and raise your hand and one of the volunteers will actually come towards you there's a question right there let's see uh in the fourth row or fifth row with the black sweatshirt you mentioned accessing data is going to be a little bit different does this imply that like um tooling teams and wallets and such and are going to have to like enforce accessless now moving forward no uh it doesn't mean that but it means that the gas model is going to change to uh to follow this this new model which is why I was like if you've got a contract please deploy it on the test net but you do not need access lists are going to disappear they're replaced by something else that is not really exposed to the to the to the user so to for the end user in theory apart from the gas cost everything will be transparent awesome I think that answers the question thank you so much Keo thank you appreciate it oh there's one more question do you mind answering one more I'm sorry there's a question here can I repeat the question real quick oh sure I'm just going to paraphrase it real quick and they said that they wanted to know if there's any drawbacks to the vertical trees yes there's plenty of drawbacks like I said there's the the transition the the slow crypto otherwise uh yes like the biggest drawback I only alluded to uh in the previous answer is that the gas model changes and that means that a lot of code uh you know like uh contracts them to some contracts than to be very optimized for gas uh those optimization can turn out to be completely Obsolete and counterproductive uh so that I would say that's uh that's the biggest uh drawback I can think of any other questions I'm sure you'll be over to the side feel free to ask him thank you awesome thank you we're going to take a couple minutes to transition uh to our next speaker but I have a few questions for the crowd so while we transition I would love to know who's is this anyone's first time at Devcon have anyone yeah okay welcome enjoy I hope you enjoy it as an OG and someone who's gone to a couple of these events I will just say pace yourself try to go to as many things as you enjoy but try to make as many connections as possible too that's what is always the best and you can always re-watch these talks afterwards as well [Music] foreign only Earth no more okay um [Music] [Music] foreign [Music] [Music] [Music] thank you [Music] okay so these are my slides all right everyone all right next up we're going to have David Theodore David Theodore is a security researcher at the Experian foundation and his talk is going to be a Noisy Neighbor an automated fuzz harness generation for going projects I'll go ahead and give it to you David tests all right the room cleared out so uh I'm gonna have an easy easy audience right now um yeah so I'm David uh last time I saw you guys I was in better shape I'm surprised I made it here um more on that later I'm going to talk about nosy neighbor uh nosy neighbor is a tool I've been working on um open sourcing for everyone to use uh hoping it makes some waves in the golang community um talk a little bit about the challenge um finding bugs in open source go projects and a little bit of the motivation so ethereum really loves go uh some stats here Geth accounts for 82 percent of execution clients 42 percent of the consensus layer clients are running prism and this is as of like last week these metrics actually used to be higher like 90 Plus on the execution side and like 60 70 plus on the the CL uh Mev boost is also written in go it's the only production open source uh Mev client for flashbots right now it as of like I think last week 48 of blocks on mainnet were flash blocks so I won't go into Mev and all that fun stuff but what I'm trying to kind of hit home here is that uh go is like critical in the ethereum stack so somewhere I would say like maybe three quarters of no nodes or more are using go at some point so it's super important let's see lots of code got to run two chains the execution chain the consensus chain we've got the entire evm all kinds of stuff so there's like a a huge amount of code here how big is it exactly the pure go ethereum stack is 583 000 lines of code so as a security researcher like a deer in headlights I'm not going to manually view all of that right we do do manual reviews here all of these things have been reviewed at least once most likely if not twice or more times but they're moving targets we've got uh every six months or so we've got hard Forks on both the El and the CL so it's just kind of something that if we can automate anything we should we should automate finding issues here um so my task there's a few of us at the ethereum foundation working on the consensus layer security research team my task is to kind of like look right now and focus on the ghost stuff uh this is kind of a daunting thing so a few months ago I guess about a year ago started looking at this and trying to understand the problems that we have so talk a little bit about it first of all uh go is memory safe which is awesome we don't have remote code execution issues stuff like that very often the memory safety stuff helps also a lot in the I'll talk more about in this talk but making it possible for me to make a tool like this a lot of common mistakes and go though there are some that are queryable right there's a lot of these like little issues like the colon equals sign this like quick variable assignment it makes writing go really easy and and human friendly but it also means like you can have these shadow variables where if you like declare a variable in a loop you override it and you might reference it later thinking you're talking about the first version of the variable if you call it Go routine and and you kick off like which is basically like for non-go people it's like a it's like a piece that create under the hood the variables that are passed to that are not the same variable that you might think they are so if you have like racy type things later you don't really know and go doesn't complain so we can query for a certain things like this this is a good example of like one query gosec this just says like hey you need to manual review all these uses of unsafe probably not the best example but we have code ql simgrep and gossacker like just major tools you can look up for like automating querying static analysis right another big one is race conditions so goes I think the the reason it was designed and the design decisions they made was to make parallelization very easy so they have like this concept of channels and they have this concept of go routine so it's very simple to be like hey just go on another thread go do something and then come back and Google made it to be Memory safe but also efficient and human readable but to process massively large data sets and so we can do a lot of parallel parallelization very easily but the problem here is that it's so easy that it's really easy to introduce race conditions so like one thing we have been doing is running these thread sanitizers this little terminal prompt right here is an example of actually a mainnet gethbug a race condition that was causing some memory corruption which if you see memory corruption and go it's usually something race related or you're using like cigo or some native library because go is relatively like almost 99 I would say percent safe um if you're not in one of those conditions as far as memory goes um there's also some other sanitizers there's asan msan ubisan things like this we're running notes on Robson sepolia uh the Prater girly test net and also on mainnet that have all these sanitizers running so we're like we've kind of automated you know this querying we've automated uh like sanitizers running stuff like using Dynamic analysis so we've kind of checked both of those boxes but uh you know what else can we do and that is where nosy neighbor comes in um so how else can we cover these 583 000 lines of code uh the solution let's talk a little bit about the problem I'll rewind just a bit um obviously I already mentioned the huge attack surface one thing I do want to point out here is the denial services are like critical for us um not just like for other go repos necessarily but a blockchain cannot have a denial of service so usually a denial of service on the common vulnerability severity scale is like a three it's not like a nine it's not considered critical there's no information disclosure there's no remote code execution and thus there's not usually privilege escalation so people aren't like lifting keys but if you have you know more than 35 percent of the network running some kind of go under the hood and there's denial of services and those goes go routines or or these repos then you end up in a problem where the ethereum network could like be brought to its knees we obviously have a multi-client architecture so these other clients would be kind of like carrying the network during that time uh but it's not something we want we wouldn't have finality um for those of you that are like really familiar with proof of stake uh it would be pretty big deal so we kind of have this like weird issue where we the worst kind of bugs we don't really see but like we care a lot about these smaller bugs um the good I mentioned rce is rare we have the source this is really great I've been a security researcher for a long time and I've not had this Source very often in my career so this is like a whole new ball game um it was strongly typed all of the panics and stack traces and failure reporting is like excellent so if you write a fuzzer and it finds a crash it doesn't bring down your fuzzer and your fuzzer doesn't commit suicide so that's really helpful and I'm going to talk a little bit about the tooling uh this is a big deal so go 1.18 I guess like maybe six months ago they released native fuzzing support so this is an example of like in the testing Library I can fuzz this function so the function on a test on the right side and I lifted this straight from like the go fuzzing like native fuzzing design dock um Foo is the function under test here so we can fuzzfu we can say hey F dot fuzz give it a function interface to say I want an INT and I want a string which are the two argument types to Foo we can add a test Corpus of like right here it says five and hello anytime you want to like prevent like regression you can add like previous bugs into your test corporate this way and it will automatically tell you if the bug is reintroduced so that's really cool it automatically coverage guided all the test cases when there is coverage they get added to the test corporate and they get mutated on errors are super descriptive don't need health Checkers because all this stuff is built in natively it's awesome this is kind of the next piece of the puzzle uh discovering this kind of like opened my eyes to the possibilities of what we could do here the AST is exposed um the parser library and the go types Library expose everything about the source so when the compiler reads your code and then compiles it everything that it sees you can see right here so like this is an example of the ASC um it kind of is pretty printed you can see like there's a variable you can see at the top it says like AST if statement that's saying there's an if statement here the first directive is X the value is to there's all this information here there's more information than you'll ever want here so that's really cool so what can we do here we can parse all the go code in a repo we can basically collect all the dependencies for the packages and the types we can collect all the function declarations the package declarations the type declarations all the interfaces we can see what every function looks like like does it does it take like you know arrays slices bytes strings complex structs also uh if it takes a complex truck what is that struck made of and recursively down the whole thing so you can basically go all the way down to all the built-in types and go and you can see all the information you want about something so using this we can generate valid fuzz harnesses for all these functions that we have typed and we can fuzz them we can round robin them we can fuzz them uh while you know the target's running and I can talk a little bit about that more later uh but then yep find their bugs profit I know this isn't like a security specific conference so this is a reference to uh an old Frack magazine uh smashing the stack for Fun and Profit I'm not profiting off these I promise I want to clean up all of these bugs um that's what I'm paid to do that's how I profit uh oh and then you can repeat on every commit which is kind of why nosy got its name it's the nosy neighbor uh you can integrate it into your CI hopefully people will do this and then when bugs are introduced like the moment they're introduced we can just like automatically fuzz a function before even the tests are written for the function and we can find these bugs so it's like really annoying and really nosy to developers because there's like this old granny across the street that's like always looking in your business that's where the name comes from I just call it nosy nosy neighbors way too much so I'll refer to it as nosy from now on so nosy in action uh it basically has three main stages there's an initialization there's the harness generation and the fuzzing you can put this all into like one seamless you know action if you're integrating into your CI but for the purposes of like the tool as I made it um you might want to debug stuff in the harness generation you might want to add test corpora there's all kinds of like interesting things you can do in between these steps so I have it broken up into these three steps just uh for like kind of Sanity reasons this is the input every time you run nosy no matter which of the three like actions you tell it to do you're going to give it this yaml file and this yaml file contains a bunch of stuff the most important thing though is the URL to the repo so it'll pull down this repo you can say I want this particular Branch you can specify different Go versions uh like prism for instance is like one of the big repos that I always look at and it won't build with go Knight 1.19 right now so this is really easy as long as it's like 1.18 and above because that's what supports native fuzzing you can kind of use older versions and that sort of stuff there's also these like ignore declarations I put in there like maybe you have a bunch of test functions maybe you have things that use networking stuff that writes to the file system that you don't want to fuzz because you don't want to pulverize your file system you can declare at the package the function and the object level to ignore these kinds of things it also has substitutions what this will do if you're familiar with go if you put a substitution in here uh it's you just put both packages in there and it will put a little replace directive in the go.mod file and this is really nice if you like want to knop out all of your like signature checks you get a lot more coverage this way like obviously your fuzzer's not going to be like signing ecdsa signatures correctly that would be a whole other talk and and we'd be having bigger problems with those case uh the initialization it uses Docker it basically makes this little fuzzing environment and building environment all in Docker and there's kind of a lot of reasons for that one is that we don't want to pulverize our host file system we have a lot of ease with dependency if you're like looking through and you're trying to dynamically write code writing all these fuzzing harnesses then it's a lot easier to not use your own go root so this makes a valid go root inside of a Docker container it makes everything it adds all the dependencies for nosy for doing the The Source parsing and the harness generation and all the fuzzing and all this stuff those are in this little Docker container and initializes it inside this repo or initializes the repo inside this container um it uh has a shared like host file that you'll see like in a little bit it's an asset directory that keeps everything that the host needs to get so you do all your fuzzing inside this like protect protected environment if you're a security researcher and you're familiar with like jailing a Target this is just like a true root under the hood except that uh we get to stand on the shoulders of Docker and you know uh we get to like potentially neuter all of the the networking we can like control things in like really jail stuff it also makes it where you could like run this on your host computer and like only give it a few cores and you could still like work and you know maybe you're you're kind of like Dual Purpose using a fuzzer that's also like your desktop for research um let's see generate hardness generate harness will copy all the Assets in and then it will spit out this one liner and if you double click this one liner and run it it'll start generating all of the harnesses uh and so you can kind of see like the lower half of this terminal it's spitting out all of these fuzz nosytest.go files all of those files are placed into the respective package under test directory the reason I do that instead of having them all in one is that one bug doesn't prevent the whole thing from compiling and having go complain the other thing is that we can fuzz internal functions you might not want to fuzz internal functions so nosy has a flag for that but if you do want to fuzz everything and get like this serious breadth first coverage of your target this is the best way to do it that I found so this gets to the fuzzing um you same thing spits out of one liner it creates it adds all the assets to this asset directory and then you start fuzzing so you can see on the right side here it started fuzzing it found a crash like right off the rip it minimizes the test case that produces the crash and then it spits out the like Panic output so kind of funny that one found one like right off the rip this is an example repo that I have that comes with nosy so that you guys can all test this I don't provide yaml files uh for all the targets I'm testing because there's I don't want to give you guys free bugs and uh knows he's still kind of like a work in progress so I will release uh other stuff further down the line as I've like hammered out all the bugs that are there um I think what I'll probably do is kind of like have this like private repo that's maybe like three months ahead and then as we've kind of like shaken out all the bugs that this fuzzer can find I'll open source the other parts of it but you can copy the example yaml file for this target repo that I've made and you can point it at the Go standard Library I haven't had time to do that I'm sure there's tons of bugs out there like I have one thing nosy does do is it causes like a decent amount of false positives but it does find bugs so I have like a ton of crashes to look through before I'll release all this other stuff um oh that was the this is an example of like the round robin so when there's not a test when there's not a crash found this was what the output will look like so it'll fuzz for like 10 seconds on each thing the yaml file has a little variable there where you can say like how long how many seconds you want to fuzz for as you um generate like larger test corpora that are getting better coverage you might want to bump this up to like you know six minutes per function or something like that uh this is just a little shot of like what the script looked like like what does the round robin this is a shell script that's just like kicked out into the asset file that's run on the target so there's some reasons that this is not the best way to do it so I don't think I'll be doing this way forever but if you can see right here it basically calls the go test fuzz on the function you want if there is uh test data fuzz inside of that package now that means that we found a crash copy that in the asset directory so that it's available on the host if the fuzzer user either commits suicide or if you're done fuzzing you don't lose this a lot of people like know that you a stalker your container might not be persistent if you don't have something like asset directory where you save stuff off to so this prevents you from kind of losing work that you've done all right example findings um I made this little repo so that everybody can kind of like see nosy in action and have an example so they can point it at their own repos uh these are all the root cause of all of these bugs are copied from real bugs that nosy did find and I'll talk a little bit about like the type of bugs it finds because it doesn't find everything and it's really good at finding a few things and and I'll talk about that uh looking at these here so um this is just showing like the Panic line like this is identifying the type of issues that we have uh it looks like there's two index outer range the second one actually has another bug there's two bugs in that function so I included the wrong screenshot it should be like a divide by zero so these four functions on the right show the vulnerable functions so these are the kind of things that nosy like if you say like spend three seconds on a function those people find these things like immediately and if you notice what these are they're panics they're not like remote code executions their panics where things stop so if you have some uh blockchain software it's highly social it's listening to all these peers every time it receives a packet if you have like a grpc Handler and it's meant to like Panic gracefully and it just panics in that go routine you're fine but if you have this in like core code this Panic can like make the Panic go all the way up the stack and just completely bring down your notes so these like true like packet of deaths they're a big deal and this is kind of the thing that like keeps me up at night because panics are not always handled gracefully especially in uh like these huge systems so like the evm for example if you found a panic in it uh you might actually crash that part of the process and then Geth would just be like completely worthless right so let's talk a little bit I've only got five more minutes left so I'm going to talk really quickly about like what these functions look like so this is the most basic right so uh if you look at this this is the same native supported testing the input to the top is is it it's actually a test function it takes in the testing object from go you hand it a function interface right so this function here all I'm saying is hey I want to fuzz this log validator web auth right I just pick some random function it takes a string a string and a string right so you know this is the kind of thing I need to tell Gophers hey I want strings when you mutate like I need a valid type string super simple this is something that go testing does not support complex structures so if you see the second line there what it accepts is actually a byte array what this does is I use right now nosy ships with the open source version will ship with go files utils from Trailer bits there's some reasons that and I won't go through them unless I have time at the end why that's when it shifts with the biggest one though is that you see all of these fill errors it will return if you don't have enough data so if I have like you know a bunch of nested structures and like you can imagine uh my function or test like needs basically like 2 000 bytes to fill all the data correctly it'll it'll say hey uh return there's no issue or anything give me something larger it doesn't really say give me something larger but it keeps letting the fuzzer mutate until it finds you know further pass and this is coverage guided so the fuzzer will very quickly make it all the way to that last line so what happens here um that last line is ACM import it takes the context variable I need a valid context variable I want to basically test import but I need ACM this is a this is an actual like object so it doesn't just fuzz functions it fuzzes meth like methods on receivers which is Ghost version of an object so methods on objects we need a valid object created we need the argument there that kind of stuff get more complicated here we actually have a Constructor so why make like an object and fill it with random data when there's custom Constructors made so like uh you know these these large blobs for the evm um maybe like different peer structures maybe like Beacon blocks things like this we've already got Constructors for them so like why make them ourselves we're going to get a bunch of like no pointer D refs and false positives so what nosy will do and this is hugely inspired and barred from fcgen even like probably like 60 of the code for this type of interface is is borrowed from that uh but what we do here is we go look and say hey is there a function that returns this object and only this object that doesn't take that object as an input and you know it can either just be that object or that object in an error and if that's the case we say oh that is a Constructor sometimes you see false pauses for this but in reality they're actually really good at still generating valid objects so in this case I need a new key manager I didn't have to write new key manager some developer that made the new key man the the key manager object wrote this Constructor that's what he uses it takes you know this configuration deal and then whatever C1 is a context variable so what happens here is nosy recognizes this builds not only its own version but a second function defuzz this that relies on the Constructor and whichever one gets you know more coverage can find the bugs so right here we we basically find the Constructor and we know how to see a function interface so we build everything we need for that Constructor and then we make the Constructor hand us the Ops object and then we also provide everything for the function under test which in this case is fetch validate something priv key I can't really read from here but this is just like a random example there's plenty to choose from one thing I forgot to mention out of the 55 583 000 lines of code there's over 15 000 functions the in the in those five repos which is basically all of the dependencies for MAV boost getth and um prism that are supported so that's fifteen thousand functions that I can get coverage in uh that's coverage guided fuzzing that I don't have to write the the harness for that's kind of like the value out of this tool here um and and yeah notice here that like no nosy didn't only like create the valid arguments to fuzz here it created the object and by doing that um the way that it did that was it created the valid Arguments for the Constructor so everything that needs to happen here to try to get like as close to like a real test case as possible we have all right mistakes learning I'm gonna go really fast I got a minute and a half um version one actually there's like a version 0.5 uh shout out to Tyler Holmes uh one of my teammates uh he did a big code ql query for various things and we found like a bunch of stuff that just accepted byte arrays so we wrote some python it would like basically generate hardnesses to fuzz those that was version 0.5 then version one um was in Python this is just like to show you my pain I'm grepping for regex here in Python all that gibberish I felt like Jr Tolkien like basically like writing Elvis or something this was no good um trying to do this for for complex structures and stuff was like a total pain so moved on to the AST objects uh that you get from the go parser library but you guys have seen this this is kind of cool looks sort of pretty printed it still sucks uh all that stuff is like you don't really know like this AST I didn't on the fourth letter Fifth Line that X is you got to like do a type check on all those so you end up with like this massive parsing thing that's got like you know a gazillion nested case statements still better than python but still really ugly then I ran into FC gin uses the go type libraries to write that like more complex function interface that I showed um I it blew my mind I can't believe I wasted all my time for six months on these other things so I basically grabbed all the code that works from there threw it in here it was a minimal rewrite for me um cool I talked about why we use Docker these fuzzers will find the go binary and delete it they will write all kinds of crazy stuff to your file system if that happens you can just restart nosy and your host isn't screwed let's see various fill libraries I talked a little bit about trailer bits I have a proprietary version that I'll talk a little bit more about here last slide that really matters I know I'm out of time things that we want to do Auto corporate bootstrap so you can imagine here we already know how to dynamically cut right code we can dynamically rewrite code so if I point it towards the repo and I say hey I want to run go ethereum uh you know let's say I support 7 500 functions in it then what I can do here is I can say all of those 7 500 function instrument them run go normally run it on mainnet if you want save off every valid call to all of those functions and and receivers and then mutate on those so I can I can bootstrap a corporate that way I can automatically fuzz in a separate go routine uh in a Docker image or something in real time you can be like continuously fuzzing mutating on real valid test cases um let's see auto object fuzzing you can find race conditions this way uh you could say hey I know I support this Constructor it's got 10 methods on it write a fuzzing function that will kind of round robin those there's some work like this in FC gen that I'd like to copy as well I think if you run that with the thread sanitization you'll find a ton of race conditions that way lockdown networking you can do AST walk to say like hey I want to like look at all the reachability from this function if it writes the file system exclude it because I'm tired of something something's pulverizing my file system and it's destroying my fuzzer that kind of stuff final task test case minimization at the end of a run and all the coverage analysis this would be really great if I had this done today because then I could say hey look you know prism's testing library has this much coverage and I added this much coverage automatically with nosy neighbor that would be really cool maybe you'll have that in six months for you guys all right uh I will open sources in the next 24 hours that's my promise to you uh my creative excuse as of all procrastinating Engineers um has a creative excuse I got bit by one of these snakes like four or five days ago I wouldn't be here if my wife didn't like do so much to get me here uh I spent a lot of time in the hospital I've been elevating this foot hence why I came up on crutches I'm starting to be able to put weight on it but yeah I actually have like a real excuse this time the dog didn't eat my homework one of those guys like legit bit me it was a whole thing follow infosecule on GitHub or Twitter I'll drop the repo links probably later tonight or latest like this time tomorrow uh depending on how the rest of the day goes uh real quick I do want to thank FC gen trailer bits for that uh Phil repo uh zinchata and and Justin traglia for various things that they added to this uh repo into this project uh the go fuzz folks and then everyone in the go for slack that's been like super helpful uh any questions yeah with that David I'm going to say you can go ahead and take questions over to the side but thank you so much for a making it here through all of those different hurdles and for giving us your great presentation so thank you so much if you do have any questions for David please feel free I am sure he'll be answering questions over there on the side we'll make sure you get all set up over there too as well next up we're going to have bartek in about two minutes while we transition the stage feel free to talk or transition yourself as well [Music] [Music] all right next up to the stage we're going to have barteki and he's an architect at makerdale and he's also the founder of L2 beats bartek is going to be discussing our Roll-Ups in the most secure Bridges uh with that I will go ahead and hand it over to bartek you all set beautiful thank you thank you very much that's a big stage thanks so much for showing up my special thanks is to make a doll fan obviously and I'm gonna talk a little bit about bridges you might have heard a lot of talks about bridges this one might be slightly different because the subject of the talk is actually quite serious I mean we had a lot of problems with Bridges recently so um before I actually go into the um the Crux of the matter Let's uh let's just go back uh and look at a bit of a history so how come I'm here two years ago more or less we started to work at the uh multi-train strategy for the maker Dao and we ask ourselves a question how do we actually move the eye to different chains so um it was actually quite quite hard and and for us it took it took sorry let me go back so two years ago we started to work on the multi-train strategy and uh we had to look at all the other chains and we had to find out how secure they are to actually be able to move die in a very secure Manner and to do that I had to look at the security of all the other chains so basically I created the spreadsheet and I posted the spreadsheet on the Forum and frankly after a while not a lot of people looked at the data and looked at what we had to say so I figured that we need to make this information more broadly available to the broader audience and we basically created a website called L2 beat and the reason for us to actually do that was to make people aware that security of die on all the other chains is very very different if you hold the eye on let's say polygon if you hold die on Phantom you'll be looking at a very very different die and the security properties of the die will be very different for make it down it is of the utmost importance the dye is censorship resistance and if you hold the eye on all these other chains you should really ask yourself a question is this really a DI that you hold on ethereum does it have the same Properties or is it actually different right and can you make all these different dies fungible and what is what is it really needed to be able to maintain all these other chains so these are actually quite hard questions and that's why it took us so long to get all of us to where we are here and once we looked at all the other chains we want to publish all the results and this is how L2 beat was born ldb was essentially initially created as a website to disclose all the risks for all the different chains and it took us really by surprise how important this thing was everyone was like really looking at the risks and the value locked and at all the information that we actually uncovered in a way so let's have a very quick look at the state of the bridges and where we are today so essentially uh when we look back at the last year it was about a year right we had a hack at the poly Network we had a hack at the chain swap we had a hack at the uh um any slope so last year was really very bad but that doesn't really compare to what we witnessed this year and it's really shaping up to be much much worse so it all started with the Wormhole hack then we had a running Network um it was like a huge 600 million dollars uh was taken from that bridge uh then we had the harmony um Nomad this one was particularly bad uh I personally really liked Nomad architecture I was actually trying to convince my peers at maker to have a very closer uh much closer look and unfortunately to a bug in a smart contract it was uh hacked uh literally two weeks after I pitched uh Nomad so that was that was really really uh intense and and then probably a week before Defcon you might have heard about binance and I even had to correct my presentation because of what happened literally yesterday right it's not just the bridge some other D5 protocols were hacked as well but yet we had another Bridge hack so bridges are scary and bridges seem to be really a weak point in all of this and we had to take a closer look at all of them so far with spent the last two years looking mostly at the Roll-Ups and now it was time for our team to have a look at other Bridges as well and how we publish this information like I said before we basically looked at all the escrows we looked at all the values that was locked in all the bridges but looking at other not just the Roll-Ups looking at other Bridges was essentially requested by the community and if Josh Stark from ethereum Foundation asks you to actually do something you should really consider so without the further Ado I mean this is actually my pleasure to uh to announce that at L2 beat we also are covering all the bridges uh you can check it out it's actually up and running and live uh since yesterday and I'm gonna tell you a little bit how we look at these Bridges and what are the funding findings that we uh uncovered uh by by looking at these Bridges so to put it simply we obviously track total value locked in these Bridges so we can see more or less the same type of list as for layer tools uh we tracked total value locked and uh you can you can see how much value is at stake uh this is all that value that potentially can be hacked and the bridges are like these uh huge pinatas uh for uh for potential hackers right so we really need to understand what are the risks and what are the security assumptions behind all these Bridges and then uh you can look at the bridges to roll ups uh as a type of a canonical Bridge so you can combine this information and and you can see the total value logged in uh all of these systems and all of these Bridges uh but as you know uh l2b is primarily about the uh the risks we want to disclose the risks uh like you can see on this particular example uh most of you probably know that optimism does not have fraud proofs uh uh right now deployed and this information should be known and available to everybody so you know when you move your funds to optimism what are the security assumptions I mean we are in a close contact with Optimist team we know that they're working on the fraud proof system but as it stands right now you have to trust them right you have to trust the team and you have to trust the sequencer um so I guess we thought that you know we need the proper uh risk framework for Bridges uh that would work more or less the same way as we did that before for uh Roll-Ups we believe that risks should be disclosed we believe that we should make everybody aware uh of the underlying security assumptions uh we should constantly monitor infrastructure for upgrades and we should really monitor the other security parameters and and this is tough this is hard because some of these constructs are actually quite quite complex and you need proper automation you need proper tooling you actually need to be able to read from Storage diffs which if you have ever tried to do that it's not particularly easy and thankfully right now there are some tools that actually allow you to do that much easier but generally what you need to do is you need to replay all the potential ethereum transactions that change the particle slot so so that stuff but but this is our task and we believe that once we do that we'll actually make multi-chain infrastructure more transparent and secure while keeping teams honest and it is all about honesty right it's all about proper disclosures it is all about making sure that users do understand the risks so what are the risks when you're actually using Bridges and you would be surprised how a few people actually do understand most people kind of think that when funds are in transit and once they arrive to the destination they should be safe right so it's almost like you know Crossing the the bridge across the water and and once you've made it to the other side you know you're safe but you're not you're definitely not safe and I will try to explain why but before I do that you know I will actually share with you uh interesting findings that you might actually also find surprising so so the first one and I think it's actually quite a big one uh is the uh the multi-chain multi-chain is one of the biggest Bridges with the biggest dvl uh turns out that last year they actually moved from escrow uh quite a lot of funds like literally millions of dollars so normally for that type of bridge you expect that you put your funds into the escrow and on the other side of the bridge some funds will be minted right and when you go back the funds from the destination they will be burned and the validators will release the funds from the escrow turns out that you know in this particular case validators actually took funds out of the escrow without actually burning them from destination so that was odd and the the amount was very significant and it seems like no one cared like people were not really aware that that was happening and just the fact that it is possible for the validators to take funds out of the escrow uh this is the risk assumption that you know you should be all aware of right if you're using the bridge that's externally validated that's the thing you know they can all take your funds so in this particular instance apparently the funds were used to provide liquidity uh to any tokens on on a lot of different chains and to make sure that this is exactly what happened he would have to like go to all the other chains and check it out but you know my question to uh to the multi-chain team is uh was this part of the contract right uh what are uses aware and what is the consequence can actually users withdraw all their funds and more importantly uh what is this additional trust assumption uh because it validators can remove funds from the escrow uh they can do all sorts of things as well right and how do you actually monitor uh what they're doing so that's one uh then you have something called plasma Bridge uh some of you again might be aware of because this is uh one of the two Bridges uh that you normally use to move tokens to polygon and this particular one has a very interesting documentation it says in the documentation that it provides increased security grantees because there's a seven day withdrawal period and during that period you can challenge uh um validators from polygons so it's kind of like a plasma exit mechanism however the best of my knowledge uh this was actually implemented and deployed on a test net but it was never deployed in a mainnet right so if you look at the mainnet code and by the way who's looking at the main and code of the bridge you know the contract probably very very few of you you'll see that the method that allows you to actually challenge the validate this is empty right you can't do that so frankly the plasma bridge right now has the same security assumptions as the POS Bridge the main bridge that you normally use the polygon and it's got this user nuisance of seven day withdrawal period and the last one that I wanted to mention uh which in the documentation uh the risks were properly disclosed but again I think that the user should be aware of that if you use the Omni bridge to move your funds to the xdi chain uh they might invest some of these funds they might actually put the funds that you normally expect to be in the escrow into other into compound or whatever they like actually right so normally it's called re-hypothetication This is the practice where you know banks are using your funds to actually invest them and you're running into liquidity risk potentially if you were to withdraw all the funds it uh they may not be available they might be like locked somewhere in in say other or whatnot right so the whole process is very transparent but the power of validators to actually do that may be surprising to some of you because again is a question uh what are the security assumptions right and what do you normally expect when you put the funds into the bridge so uh so now with all these examples you may wonder you know how do you actually collate all this information and how do you actually make it available to the users and this is a challenge we've got hundreds of bridges we've got hundreds of different destinations we've got hundreds of tokens and every single transfer may be actually different right and this is a challenge for us as well because we really wanted to make it very transparent to everybody and we wanted to make sure that users are actually aware what exactly is happening behind the scenes so so we try to kind of you know make it the whole framework user friendly and I will quickly summarize what you will be seeing uh on the L2 beat Bridges section so first of all we kind of differentiate primarily to different Bridge types and the first one is a token bridge and that's the bridge that means tokens on the destination and then uh so this is something that you know normally you should be like uh intuitively expecting right you put tokens into the escrow the Bridgeman's tokens on the destination however a lot of bridges cannot mince tokens right like take die as an example I mean most bridges won't have access to dry minting facilities so they have to do something different they have to on the destination they have to create a liquidity pool they have to mince something or maybe you know through some other mechanism and they will like swap whether they minted for the die that is like sitting and waiting for you on the destination and we call these types of bridges liquidity Networks and I think what is the most confusing for end users is that if you go to a UI of almost any Bridge you will not know if you're actually using token Bridge or a liquidity Network in fact uh some of the bridges are hybrid sometimes for some tokens they may actually mint you tokens sometimes they may use uh liquidity poles and it like I see the case for the multi-chain you can have like some mixed results some of the tokens may be minted for you and some of the tokens may be actually uh coming from the liquidity Pawn so these types of bridges we will call a hybrid and again if you compare token Bridges to liquidity networks they have a very different risk profiles um so for the end users I think it's very useful to actually understand uh the difference between the two right you have unlimited liquidity for the token Bridge uh you have tokens uh that if you keep the token at the destination you will face the risk of the validators of that bridge and generally token Bridges can be quite slow and expensive while the liquidity network is almost like the opposite right it has a limited liquidity typically so you may not end up with your tokens being stuck but tokens held on the destination are not at risk of this network they're actually at risk of the token bridge that was used initially to move tokens to the liquidity pool so again this is the risk that's actually quite difficult to uh disclose and finally they can be fast and they can be cheap right so so this is the uh the column on the L2 beat which you can check very quickly and and this is something that should be essentially easy to read for all of you and if you use any particular type of a bridge you know I do encourage you to check it out and and and and and understand the consequences uh more importantly from the risk perspective and this is like maybe a little bit more technical uh is the question how the messages are actually relayed between the source chain and the destination chain so technically we use all sorts of uh terms for this like arbitrary messaging Bridge or some other terminology but because we wanted to make the framework sort of user friendly we just want you to understand what are the four in our opinion primary mechanisms that are actually used to relay the messages and again these messages are important because when you lock your token at the source the destination somehow has to be informed how do you mean the token destination right so what are the four different categories well first of all you've got the third party meaning that you have to trust someone to relay this message and that particular party can essentially break you right so you you put full Trust on that party then you've got what we call the optimistic scheme we relay the message we trust that the message is correct unless someone actually proves that the message is incorrect so your orientation should be like who's watching uh the relayers right who are the Watchers and what is the length of the year of the fraud proof window because optimistic uh message Bridges they always have watchers and they always have the uh fruit fraud proof window then we've got bridges that we normally call as secured by light clients and essentially what it means is that we trust the destination chain to tell us what happened right so when let's say polygon validators say that something happened on polygon I don't check that this is exactly what happens I just trust the polygon validators and on ethereum I just need to build a software that will check the signatures essentially right so you're putting your trust on the validators on the destination chain and the most secure bridges in our opinion are the trusted bridges that use ethereum as the ultimate source of Truth so we don't trust anybody we build smart contracts on ethereum that will validate if the destination chain is not lying to us obviously there are two techniques right now you can use ZK proofs or you can use fraud proofs that's why we've got zika Roll-Ups and optimistic Roll-Ups and if implemented correctly these are by far the most secure Bridges provided that there are no bugs in the implementation right so uh what can go wrong I mean you forgot the external validators everything can go wrong right they've got full access to the escrow they can mint whatever they want to Mint if there's a bug you know you can have billions of tokens minted out of thin air and validates this can censor they can steal they can freeze funds they can do whatever right you have to fully trust validate this for optimistic validation as I said before you need to make sure that Watchers are actually active because if no one's watching uh the fraudulent message can be relayed for the light client validation uh if you're transferring your tokens to a chain that's weak that has very I don't know it's a low value chain and vital this can be potentially 51 attacked then your tokens again can be stolen from escrow so you have to really understand how strong is the chain and that you're moving your tokens to and finally for roll-ups for a full-time ethereum validation in theory nothing can go wrong right so funds cannot be censored funds cannot be stolen as long as there are no bugs in the implementation and this is the uh how we actually show uh who is validating all these Bridges and I think this is the most important column that you should focus if you want to understand uh how a particular Bridge operates then we have the upgradability uh so so this is essentially the information whether the bridge can be upgraded and who have got the upgrade power and again we kind of have to assume that whoever's got this power is honest so this is a very important security assumption if you can upgrade the bridge you can steal all the funds that's as simple as that and finally and I think this is the most interesting aspect which is often overlooked is who's got the minting power on the destination right so take again die as an example uh if you move uh die uh via three different Bridges uh let's say use the uh make a dial bridge and move your die to arbitrim Optimus starknet your dial will be essentially minted by make a dial contracts right and it will have exactly the same properties as your die on the mainnet but if we move dive through the polygon bridge then your die on polygon will be minted by polygon validated and they might actually have the upgrade power of the die and finally if you move die on Phantom it will be minted by multi-chain multi-seat right so again it's a question to you I mean how secure you feel with your die in your wallet uh so this is the last column uh that we show on our framework and as I said before uh I guess you know the the the end game for all of us should be to build trustless Bridges um because everything else uh we need to put our trust on some uh some other parties and these bridges are very very hard to build we had some problems with arbitrine Bridge uh there was a bug it was essentially uh fortunately uh uh uncovered and the bridge wasn't hacked but uh but as you can see you know uh the roll-up Bridges can be buggy uh same situation happened in optimism um and this is one of the reasons why uh these bridges are right now not fully uh yet permissionless and I hope they will be uh very very soon but even more importantly as you can see from this transaction uh that's actually moving uh how much is it uh this is actually seven uh over 700 000 ether from one version of the bridge to another version of a bridge and that power has a arbitrary multi-seek right so even though you may think that arbitrine has fraud proofs and whatnot uh they still have a multi-stick that can move all the funds from the bridge and they did in this very transaction and it doesn't really raise any alarm so that was kind of uh interesting um we uh we saw this transaction and you know we analyzed this transaction it was an upgrade and everyone knew that which one uh was about to upgrade but seeing such a transaction moving essentially uh billions of funds in one one move you know it's it's kind of scary so to sum up we kind of think that we have no choice we have to put engineering effort into uh building those roller Bridges I don't think it makes a lot of sense moving forward to rely on on third parties uh in the long term in the short term they might be quite useful because we need that functionality but in long term eventually we need to find a way to actually make sure that the code behind all these Roll-Ups is actually secure and as I said before I mean the code is very very complex right these bridges are actually very hard to analyze I guess for a while none of these Roll-Ups have shed the training wheels so so you should really also understand what are the current assumptions uh but every single team that we talk to they have promised us that eventually these training wheels uh will be shed so there's there's some hope for the future but how do we make sure that such complex software is bug free and how to make sure that these Roll-Ups will not be hacked in a ensuing months and I think this is probably one of the hardest questions from the engineering perspective and from the perspective of the whole Community we don't seem to have a solution for dealing with uh discovery of potentially critical bugs without actually relying on some honors actor right if the bug is found uh we all want some good guys to shut down the bridge fix the bug and restart the bridge without the bug that's quite obvious right no one wants really the bridge to be to be drained by uh by malicious actor however right now it just seems that the best we can do is to sort of create a multi-sig of some trusted uh security Engineers I guess or a security Council of sorts and these guys can perform these certain upgrades and um to make it permissionless and to make it immutable that also means that we are exposed to uh potential problems so uh so thank you so much uh for listening and I I do hope that you know the future is bright and and hack free thank you so much bartek um I'm sure if you have questions of our Tech I'd ask you to go on the side and then if people have questions for bartek you can go ahead and go over there next step we're going to have Bristol Cahill and Bristol kaher is a founder and a digital librarian of the internet archive Brewster will be talking about Publishers denial of digital ownership versus decentralization I'll go ahead and turn it over to you Brewster thank you very much so thank you very much once again um I I bet this isn't a talk you were expecting so I hope to at least uh I mean maybe a bit of a downer but at least you'll learn something from it uh in the Devcon in uh in Japan um I suggested that the issues once we start to have currencies with interest that we could have debt with interest that you get runaway wealth inequality and historically according to David Graber and Michael Hudson it leads to Civil Wars um so we needed some mechanism to have jubilees or other mechanisms of doing debt relief or things can go very wrong okay so I'm going to give another kind of uh thing to worry about that I hope is going to be at least useful uh uh to you on a going forward basis and it revolves around the term digital ownership of what is digital ownership how is being manipulated what are the risks what are the large corporations trying to do about it and the like but before I get on a downer let's just I I wanted to say thank you all for for moving ethereum to proof of stake I mean what an enormous achievement and thank you very much and I actually moved all of my personal Bitcoin to ethereum because of this just in the last while so thank you all um it's really wonderful to see this whole ecosystem take steps forward in the way that you guys have have brought it Forward okay um Publishers denial of digital ownership versus the decentralized web which is the work the internet archive has been doing so what does it mean when the mega Publishers for Mega Publishers sued the internet archive about trying to have digital ownership of scanned books and this is I'd say a wide spread a precursor of things you'll see in other areas so in the nation they wrote it up as actually above just the internet archive it's taking the internet to court that the concept of what it means to have files be able to Archive them be able to have use of them be able to have them on your hard drives is coming under attack from these extremely large organizations and they're doing it in the guise of a lawsuit against the internet archive so who who are these people um it's orchestrated by the AAP um but it's the uh four of the very largest uh Publishers in the world one owned by Rupert Murdoch there's other uh large monopolies multi-billion dollar corporations that are coming after the internet archive for fundamentally what we've been trying to do is buy electronic books buy electronic books in the same sense we used to buy books in the past so we'd buy an electric book and then we'd be able to preserve it and lend it out to one reader at a time right that's kind of what it used to be in the physical world why not in the digital world they would not allow us or any library to buy an electric book They're not available at all so you can't own them so that's a a puzzle so we said okay let's go back and scan the books that we do physically own have one copy and lend it one reader at a time and doing this for 10 years it's been going great hundreds of libraries do it and in the beginning of the pandemic these Publishers sued us to try to stop this practice across the board so it's a bigger issue than just a little Library sort of the lawsuit as I will try to suggest like for instance if you want us get into the mind of what these big Publishers are doing Pearson which is a major Textbook Company is starting to invest in nfts as a mechanism of of killing off the secondary textbook market so even though if you've paid them for a textbook in the electronic world you can't go and sell it to somebody else or give it to somebody else or actually own it in any real sense so where the uh wonder of the blockchain was to have an artificial scarcity in the digital world we've now allowed also mechanisms of holding on to things are passed when it was normally released based on being paid in the uh in the world of books and we're starting to see that in movies for instance or music if you think about the music you've probably listened to in the last week you probably don't actually have the mp3s of those you're just listening to them off of some streaming service that can change at any time so what does that world look like um it's really problematic and at least we have some friends so there was a recent uh letter signed by 300 over 300 authors it's now up to 850 authors and Neil Gaiman a bunch of other very famous authors to basically say that this lawsuit against the internet archive and libraries in general is a problem but the eyes this is not again restricted to just a library uh issue so digital ownership is what's at issue and it's what's been informed now and this community could really help if we work together to try to understand what does this mean how much role can people have on an ever going basis forever to be able to say what it is you can do and how much can they retract at the end of the day so let me just say a little bit about the internet archive I'm going to just flash through a bunch of big numbers to just say gosh isn't it impressive but to give you kind of an idea of the what the internet archive is which you may only know as the Wayback machine but it's a bunch of other things too we have 790 000 software titles many of which are are emulatable so you can go and do your old Oregon Trail uh days or whatever it is your favorite video games on Old platforms uh out there we have over 5 million moving images that people have uploaded this isn't even counting television that are available lectures and and the like on archive.org a non-profit live Library audio recordings 14 million of them including 280 000 concert recordings from bands that agreed to share sort of in that non-commercial uh kind of Creative Commons ways uh so the internet archive has lots of these and people are uploading more all the time we have about two million hours of television news so you can search what people said which has been very important we're it's not just United States television news we also now have Russian Ukrainian news that's being useful to find out what the uh what different populations are getting fed by uh the large media companies um and we have about six million books that we've digitized uh one page at a time that are available for free for Lending and a lot of web pages we're probably best known for the Wayback machine but we've got over 99 petabytes of data I just love this number because it's just kind of ridiculously large and so we're going to break through 100 100 petabytes and have a party um so we've also been pioneering this idea of these decentralized web by going and promoting values-oriented Next Generation web where it's a peer-to-peer back end on the web that the file coin the storage uh are are sort of parts of this that we're trying to build build a better uh better internet best known for the Wayback machine we've got 700 billion web pages and a lot but what happens when corporations license rather than selling digital things and we've got troubles with the right to repair we have you know people that own tractors they can't repair them because they're under a license agreement um you know what does it mean to own anything in this Digital World what happens when corporations license and sell things um well they get to hold on to them forever so they get to basically be able to reach onto your device and pull it back I guess the most dramatic of these is when Amazon came out with the Kindle why would you call a book reader something that has to do with fire but anyway um the book uh their book reader they bundled 1984 onto it and distributed it well the family of George Orwell objected and so Amazon went on to everybody's Kindles and took it off I mean 1984 happened to 1984. um so is this happening yes um it it is happening so they get to hold on things forever they can decide what can be done with it and these issues forever they can say who can get access to what when and they can change anything about what it is that you can see they can take it away and uh this is this is happening um what if you can't buy one and only lease digital books then every reading event is permissioned so anytime you turn a page somebody is controlling what it is you see and whether you can see it and it can be completely individualized so the pages can be tracked they can change the books at any time they can deliver different books to different people and you might not ever know it and corporations and governments can change history they can just make things go away no amount of digital currency magic or changes to copyright law will stop this it's the magic of licenses it over steps all of that the Publishers have manipulated copyright law to last way too long and cover all sorts of things but at least it was under rule of law but when you're under a rule of contract they can go and set whatever terms they want and there will be fewer and fewer Publishers which is happening they're consolidating and becoming platforms so they're not interested in protocols they're interested in platforms so where we have a typically Now sort of where we're trained to go and say oh bad Google bad uh Twitter bad Facebook um it's true those are those organizations should uh reform but there are there's these organizations that are behind the curtains owned by some of the very richest people in the in the world that control not a lot of what it is we see what gets published and that structure and they are getting stronger and bigger uh all the time so is it happening I mean you know we hear a lot of scare things about you know this isn't that and the answer is well uh yes um and will it continue to happen I would suggest yes unless we win our lawsuit so our books disappearing so just two weeks ago Wiley which is a major educational publisher that had been selling these database products or remember you can't actually buy the ebooks you can just rent them if you're a library um and then they were being assigned in classrooms and then they took down 1 200 of them and just made them away right so yes can they go and take books away on scale yes are they yes um are they watching every page yes um in fact um they're proud of it so Amazon is proud of being able to count all of the pages that you might read in some particular book and go and change how they compensate people Upstream the author's Guild which is a trade Association very closely allied with the Publishers as opposed to authors has been pressured and they were very proud that they pressured Amazon to spy even more on users such that if you flipped too many pages in a book that you had bought that you couldn't return it for money with Amazon that they thought this was a huge Victory to spy more on readers um so we've got some uh incentives um not not going right but I'm just trying to demonstrate yes there are real problems going on our this book Banning going on yes at scale I mean there seems to be a competition in the United States between the states that go and say how much Banning can they do and that's as a pride in one of the parties in the uh uh in the United States to go and go and uh surface and and constrict more um of what people can see in the library system so there's libraries can't buy things they can't uh and they're starting to get Rules by governments to take them out what libraries do is they buy preserve and lend they buy books from Publishers and it compensates authors this way um they preserve them long term and they make them available and then they also um lend them one reader at a time what the Publishers are saying is you not allowed to buy you're not allowed to preserve and you're not allowed to lend in the electronic world this Con makes a a shifting sand that's kind of supposed to be the antithetical to what we've been building in the decentralized world where you actually know that you actually have those coins or whatever but we're seeing some of these contracts being able to be used for exactly the flip opposite right I it's a little Deja Vu for me I'm an old guy that did a lot in the early internet internet Hall of Fame the system uh publishing before the uh before the web called Waze I I so I've seen a lot of this go through I've seen a lot of the promises go through I've seen a lot of the dreams get Twisted by extremely powerful players to play against exactly the things we set out to do in the first place so think about it hard um as we're building some of these systems because it's going on now so what should we do what what's sort of the you know okay that's a little Doom and Gloom booster um I got any suggestions well yeah let's go and get the Next Generation Publishers let's get let's buy books from them and let's publish your books with them um so when you're trying to go and get it your next book uh out there go with one of these presses they sell the libraries and um and vitalik's book um the proof of stake book it's on seven stories press and I visited them and they gave me a a pre-print before it was published a edition of it which is just great but these um are some of the Indie Publishers I would say Indie Publishers should be independent of the big behemoths and they should just like in the Indie music world go and do something differently of supporting the authors more and supporting libraries more so these at least are are ones that are are selling support any trust um the the idea that these organizations can get so large it can make it so it doesn't even matter um if uh There are anti-censorship rules if a few only a few book publishers get to go and say who gets compensated to make books available at all or who's on the major television news channels like Fox then you can bend the discussion just from that so let's keep the organization small Corey doctoral and Rachel have been uh very cogent on this point and something to do and support the internet archive and other libraries that own collections that should be something that you're conscious of hopefully out of this it's just digital ownership is something that really needs to be protected not just for libraries but the internet as a library as we're going into the decentralized web if we cannot make copies and put them in different places we are sunk the way that the world worked before the web is Publishers um writ large all sorts of Publishers would go and sell things it would be bought by individuals and libraries and they would go and hold on to it and make it available and even if one Library burned down it would still be available if the publisher went away um it would still be available if it went out of print which they do all the time it would still be available um this is not the way the web works it's on one server and if it's changed on that one server by that one organization they assert the right to go and change it forever and for always this doesn't make any sense so the decentralized web was to try to bring a peer-to-peer back back end back to the information ecology to make a a healthier uh uh world so that's the uh the uh the hope and and um please engineer some of your systems into building a better web thank you very much [Applause] I think we have time for a few questions if at all otherwise you get some more time back um why don't you just start by talking loud yeah there's a question over there uh with the gentleman in the white shirt oh if you stand up it might help the volunteers get your mic quicker oh yeah so I read about an effort the internet archive was making to curate um the Wayback machine and curate snapshots of websites to include um you know some flags for fake news or misinformation can you talk more about that or yes so the internet archive collects lots and lots of web pages and tries to get everything that's publicly available but not all of it uh sort of belongs in a library in lots of different ways for instance we get people coming back to us with from their blogs and going and saying look you know that was a blog when I was married to somebody else and I kind of like to not have that be available so a lot of those get removed from the from the Wayback machine unless they're a famous person so for instance there are some people that are now running for uh for political office we will put those uh back in in in play there are other things that people have use the internet archive as a publishing platform and we're not a very good thing for that they might upload a movie to go and promote their recruiting of uh adherence and having close-up violence uh in recruiting of of certain soldiers in their War um we want to have copies of these but we don't want to be a publishing platform so we put some speed bumps in the way of making so it's not just a Twitter click away YouTube and and those sorts of things are publishing platforms we are a library there's also some uh things that are not just uh um uh calls for of violence but they're uh ongoing harassment um so these are people will write to us and try to have things that are uh being used as harassment and we will often put in a speed bump or put some context around it if it's been been debunked to try to give some context to people I think the the uh sort of something we've been trying out is the answer to bad speech is more context so to give it so that when people see something they kind of know what's going on they think of it as the card catalog function of the of a libraries not just to have everything on the Shelf uh blanket uh is to go and have things such that you know what it is you're looking at and some things in the short term um actually are are used uh for um harassing people to the point of death um and so we're trying to make the balances of these to such that we don't take things completely away we might just make it so that it's less visible or less visible for a time to try to make it so that um I don't know the bad behavior is not multiplied based on our um our efforts where we're uh we're here for the public good we try to stay out with that with that uh North Star it doesn't mean that everybody agrees with what it is uh we do but we try to be transparent non-commercial uh about sort of what our decision-making processes in general if not exactly in every specific uh specific case as yes so uh I hear you when you're talking about we need to decentralize more content distribution to have a more part of their web but as you put it yourself incentive works and right now there is not a strong incentive for the distribution of content uh like user even as you use returns before I suppose and raise the inflamas I'm having a little hard time understanding oh sorry too fast so I suppose everyone in here has used torrents before right and Torrance comes with a problem of seed versus leech ratio and if you want to propose a more decentralized web for distribution of content there need to be an incentive for the cedar to provide data to the leader independently of the content of the data and what blockchain does currently in cryptocurrencies is the incentivize block production but not necessarily content distribution to the user and how would you solve in the decentralized fashion the incentivization of content distribution right now it's centralized by lawyers and this big operations like oh you're not allowed to distribute my contents but at the end of the day there only have as much power as the loan and if you have someone that don't respect this low like no like someone in Russia does not really respect Western Law let's say and you could have content that is banned in the west being distributed by a Russian node and but right now in Torrance there is no incentive for this Russia not to give you this data so how would you go around incentivizing data distribution in a decentralized fashion which means rewarding data distribution regardless of the content of the data I could only understand a small amount of that let me see if I I'm going to say something back to see if it's basically right how do you incentivize people to go and do content production distribution in a world where things can be pirated endlessly no no so I think the question was how do you incentivize uh content distribution am I correct contract distribution correct Anonymous no incentive to seed data to other people outside of Goodwill you're not getting paid to give you to give someone data regardless of a data like peer-to-peer internet you have no incentive you have a cedar to give data to other people how would you solve that so it's more of like how do you solve the incentivization like structure in order to have like more incentivization for people to um give the data like give the right so there's there there's been a long bed of work to try to get open access to work basically writer pays you know government uh created materials which is great but it doesn't uh solve everything so how do we get people paid by going and making materials and then Distributing on the internet without getting lawyers involved yes so you below the consequence of the laws have been centralization by big platforms so this means you need a protocol solution to get around below like Bitcoin did not write for the US government to create digital money and you need the same kind of thing to happen to have your internet of future content so they're saying that the lawyers actually present like a point of centralization then and so how do you incentivize it without the lawyers involved peer-to-peer structure not everything is solved let's start with that so it's there's open questions especially in the digital arrangement I like looking at history as sort of when did things work well and there were periods of time when basically there was royalty structure for large-scale production distribution sales um of say books or music in the physical form um a lot of that has not translated forward um some better for worse we've seen a lot more centralization I think that we can have a many to many to many protocol system as you point out not a platform uh system uh we are attempting to do such a thing with book server um by going and making it so you can sell and lend books over the internet and be able to actually buy them could there be piracy apps absolutely but let's make a system that actually works for people and fortunately there's enough money around the in the United States is 12 billion dollars a year just spent on the library system three or four billion of that goes to Publishers products it's about 20 percent of all the trade books Let's go and spend that money as well as we can to build a system that works for more than just a few big Publishers and so do we have the Solutions in the digital world no not yet and since this uh hence this talk awesome thank you so much Brewster um thank you very much so um I don't I'm sure there's other people who have questions you can find Brewster over to the right if you do right now it is time to eat so feel free to go out to the lounge grab yourself a bite to eat I hope you have a great rest of your afternoon again my name is Gloria I'm with little box if you have any questions or need have any needs come find me space and distance but if that's your decision then I'll let you be [Music] changes [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] foreign [Music] foreign those times in love with you [Music] is our love my California foreign good afternoon everybody hope you had a great lunch my name is kartik I am from Eve Global and I'll be your MC for the rest of the afternoon I will wait for everybody to sell in a few seconds we have an amazing next four hours planned we're going to talk about the nature of money Mev what comes after the merge resource pricing security ZK Roll-Ups and a bunch more in the middle so we've got the next few hours really packed for you and with that we are ready to kick off with our very first talk for this afternoon and I'd like to invite Justin Drake who needs an introduction to talk about ultrasound money please give Justin a big round of applause thank you thank you Karthik okay so I'm going to be talking about ultra sound money and really that's ether the asset so I'll be focusing on the asset not so much ethereum the protocol and it turns out there's only one Defcon talk uh about ether the asset and that's the one right now and I'm hoping that this time next year we will have multiple talks about E30 assets because in my opinion E30 asset is critical for ethereum to be successful in its mission in becoming the settlement layer for the incidental value we need to understand it we need to nurture it so yeah with without ether there's no ethereum and if ethereum becomes the settlement layer for the internet of value then de facto ethereal ether will become become something very special namely uh money the internet sorry money for the internet money and there's this deep in um you know friendship between IFA and ethereum that I'm going to try and tell you about today but before we get there I want to give you a mental model around the temperature of money or some people call it the velocity of money I'm going to invite you to think of money as water which can be in multiple States it can be liquid it could be solid if it's cooled down and Frozen and it can be in this gas state if it has extremely high velocity and this uh this is interesting because at layer one we have mechanisms that explore these extreme temperatures so you can take ether water and at layer one you can freeze it you can stake it and in the process of staking you're reducing the velocity of that ether because it's kind of put in a black box and can't move and something similar happens with the burn the burn is all about in you know destroying if consuming it vaporizing it and turning it into into gas vapor and something very similar happens at Layer Two so at layer one all of this is enshrined in the sense that ether has a monopoly and at Layer Two there's something similar happening but it's more of an emergent ecosystem it's more competitive so what happens at layer 2 is that ether or other forms of money get bonded and get used as collateral in the context of decentralized Finance and money could also be used as currency when you're transacting for example when if it flows through the pipes of uniswap and what the word currency comes from the word current and it's basically money that is moving and most of the time when people hear the word money they think currency and they only think about the higher velocity use cases but it turns out that especially for ethereum we shouldn't be discounting the low velocity use cases as those are extremely important as well using ether as collateral is a use of of of of money so just to recap we have ether programmable money which can be programmed to do various things that contribute towards ethereum a little bit like a stem cell it can be fully programmed to be a brain cell or heart cell or liver cell an ether could be programmed to be stake contribute towards security it can be programmed to be base fees and contribute towards the sustainability of ethereum as a project economic sustainability Economic Security it can contribute as economic bandwidth in the context of D5 and it can contribute to economic activity that is that is on top of of ethereum within the decentralized ecosystem and one thing that I want to highlight again is that there's these two different economies there's the cold economy of of money mostly collateral money and there's the hot economy and both are extremely important and in this talk we're going to go through the various uses of of of of ether that kind of help ethereum become a settlement layer for the internet of value starting with security so if if ethereum is going to settle the um the internet of value it shouldn't get crushed by the economic weight of it because the internet of value is going to be massive it's going to be tens of trillions of dollars and we can't have the economic the internet of value be be be secured by like a tiny amount of ethereum Economic Security and so there's this important concept of the security ratio which is simply the total value secured divided by the economic security that ethereum has and right now we're at a point where the security ratio is very healthy it's only 20 the lower the better and ethereum is securing roughly 400 billion dollars of value in the form of if erc20s and nfts and because it has roughly 20 billion dollars of Economic Security that gives us the security ratio of 20. 20 billion dollars of Economic Security is that a good thing is that a bad thing well in a way it is a good thing especially for ethereum that is such a nascent project and it's especially good that it's become a film today is the most secure blockchain even surpassing it's older brother Bitcoin by a fact of of 2x so if you want to do a 51 attack on ethereum that's going to cost you 20 billion dollars if you want to do a 51 attack on bitcoin that's going to cost you roughly 10 billion dollars but 20 billion dollars in the grand scheme of things is that a lot no it's not we I would argue that we want trillions of dollars of Economic Security for ethereum partly because we want to keep that security ratio relatively low but also because we don't want any attacker even the most sophisticated ones like like nation states to be able to attack ethereum and if we have so much economic activity then we'll be protected now the economic security comes from these if deposits and in the last two years we've had a very healthy continuous stream of deposits um on the order of 20 000 if every single day for roughly two years and so now we're at a point where we have 14.2 million each state and we can ask ourselves how much each can we expect to be staked in in the in the long term and the way that I think about it is by looking at what incentivizes people to stake which is issuance so there's two parts to staking there's the cold economy where you you're freezing money at stake but there's also the hot component which is when you're issuing uh ether as incentives for validators and it turns out you can have a look you can look at the the yield from issuance and there's this relationship which is that every time the amount of if state grows by a fact of 4X the yield from issuance decreases by a factor of two so with 4 million if State the yield from issuance would be eight percent with 16 million if staked it would be four percent and with 64 million if staked it would be six percent sorry two percent and now it turns out that what we should expect is that the yield from issuance is going to have an equilibrium with the cost of money and if the cost of money is let's say three percent then we should expect something between 16 and 64 something like 30 million if state now this brings us to the importance of the eve price because we have let's say 2x increase in the amount of Eve staked like how are we going to get trillions of dollars of Economic Security so today we have 20 billion dollars of Economic Security we want to get let's say to one trillion dollars that's a 50x increase we can get a 2X increase from each stake to 40 billion dollars but we're going to need more than that and specifically we're going to need the price of ether to go up 25x in order to get this really robust amount of Economic Security now one thing I want to mention in this in this first at the end of this first section is this idea of minimizing the cost of security so issuance is has negative externalities because it dilutes all the holders and at Genesis we were issuing a lot of if roughly 12.5 million if every single year and now we're at a point um at the merge where we've decreased that by roughly a factor of 20x and we've reached a point where the the issuance is extremely small and is essentially optimal and that because we can't improve it this is actually a forcing function for us to essentially ossify it because we've reached the best possible design great so now let's now that we understand that if it's like critical to the security of ethereum let's talk about sustainability now what do I mean by sustainability we can think of ethereum as a company and the product that it's selling is block space specifically secure block space extremely secure blog space and as a as a project it has income and it has expenses and that leads to profits and we want profits to eventually be positive we want the project to be successful to be sustainable so income is the block the the block space sales expenses is the security budget and that's basically for ethereum is the burn minus the issuance and we can go further than that we can actually look at P ratios for example and analyze ethereum almost as if it was a tech stock now since the merge despite the massive reduction in cost of security we are still not sustainable in the sense that ethereum is still not able pay for its security to compensate that with the income that it gets from selling block space but the good news is that the amount of unsustainability is absolutely tiny it's less than 0.1 percent per year and um if we were to to zoom out a little bit because right now we're with a moment in history where where the depth of a bear Market and the the transaction fees are very low but if we were to zoom out even just a little bit then we'll see that actually ethereum is in a position to burn much much much faster than it is issuing so if we take all the data that we have since eip1559 we're burning roughly at a rate that's 3.5 times the amount that we're issuing today and so the supply growth is expected to be negative and so we have this shape of the supply which we should have which is that during the first seven years of um ifa's existence the supply has grown very very fast from this extremely high issuance and the peak is this inflection point around the merge after which the supply will start decreasing and finding a new equilibrium and this is what birthed the ultrasound money meme if you know we call monies that you know strong monies that can't be debased artificially because they have a cap Supply sound money then surely something that has a decreasing Supply where the money becomes stronger and stronger every single day should be called ultra sound money and it turns out that bats produce ultrasounds and David who's with us here kind of innovated here at the memetic level and said let's wear the bad signal to spread the ultrasound money meme and this is where he started we now have thousands of accounts on Twitter that are spreading the ultrasound money meme with the bad signal and there's a there's a community that is being built as as we speak okay so ethereum needs security it will almost certainly be sustainable thanks to all the fees that it's collecting and burning compensating for the cost of security what about the the application layer what about economic bandwidth so if is used as economic bandwidth for decentralized applications so two examples would be maker which uses 1.4 million if as collateral to power its decentralized stable coin and Ave which is consuming roughly half a million Eve for its decentralized loans and the reason why if is such a good choice as a collateral asset is because it's pristine and what we mean by pristine is that it doesn't have a lot of these tail risks that other assets might have it has no contract risk no custodial risk no Oracle risk no Bridge risk and no governance risk but there is one downside to if which is that it is pretty damn volatile and so one of the things um that we can try and do is stabilize if and this is exactly what stable coins are specifically decentralized stable coins that are backed by Ether and here are three different projects that are using ether to back that decentralized stable coin and right now we using about 2 million if specifically for collateralizing decentralized stable coins now I believe that we're at the very early days of ether being used as a collateral in my opinion ether is the perfect collateral money and so today we may only have let's say 16 million if that's used as collateral but in 10 years time it could easily be you know four times more it could be something like 60 million if that is used as collateral now again I want to emphasize the importance of the eve price here in the context of economic bandwidth right now we have about one billion dollars of decentralized stable coins that are um collateralized by Ether which is almost nothing and really we want to be in a position where we have trillions of dollars of decentralized stable coins right we would we don't want to see a future where the economic activity is denominated in in usdc or usdt which are centralized stable coins now let's say we want to get to one trillion dollars of decentralized stable coins we need to grow a thousand X from where we are today we can grow the amount of collateral quite a bit by 15x but that would only give us 15 billion dollars we need the price to go up essentially we need ethereum to be successful so that we have a lot of economic bandwidth for decentralized stable coins now one of the concepts I want to talk about here is the is the notion of illiquidity multiplier so you know how I I kept on emphasizing that there's two economies without within ethereum there's the liquid economy which is hot and the illiquid economy which is cold and really all the cash flows happen within the illiquid the liquid part so if you think of the burn it's liquid if that is burnt to to pay for for Block space and if you think of the issuance that's like fresh uh if that is liquid that is added to the liquid portion and so really what I what I one one way to think about the ethereum market cap is to focus on the liquid portion for which we have models we have the discounted cash flow we have PE ratios Etc and then once we understand how much this liquid portion should be worth the portion which is basically ethereum as a business as a tech company then we can scale that out to the whole market cap and the scaling factor is this in liquidity multiplier and where we are today is that most of the Eve is liquid and so the liquidity multiplier is actually tiny it's just noise it's like 25 which is you know roughly the the monthly volatility of of of ether but things change quite a bit once most of the Eve is used as collateral menu let's say that eighty percent of what if is used as collateral money and only 20 is liquid here then the liquid is the multiplier is pretty big it's five five x so if the ethereum cash flows if the business of selling block space is worth let's say one trillion dollars then the whole market cap of E30 assets should be five five trillion dollars great so when the stand security sustainability bandwidth all of these things are critical to the success of ethereum and they all are tied with E30 assets what about the last Point activity so by activity I just mean the amount of flows that are happening on top of the film I'm thinking fluidity liquidity diversity Vitality like all sorts of applications millions of transactions per second something very vibrant and the only way that we can get there is with scalability now the good news is that I believe we will be able to scale if I'm roughly a million x we have this massive wave of scalability coming we have the search is coming and just to give you a little bit more detail there's basically three technologies that Compound on each other each of which give us roughly 100 x and scalability so we have Roll-Ups that will bring us to 1 000 transactions a second we have shouting which was going to bring us to 100 000 transactions per second and we have Nielsen's law which is going to bring us to 10 million transactions a second Nielsen's law is basically the equivalent um law to to to more law but for bandwidth and it turns out that bandwidth is the only fundamental resource um that that blockchains need to to to to to to consume now as we scale the ethereum by a million x there's this concept of the ultrasound barrier which is how much each single transaction needs to pay for a film to remain sustainable so basically for ethereum to have enough income to pay for its Security expenses and so the ultrasound barrier is going to decrease by roughly a million x so right now we need to burn in base fees roughly 3 million way for every single transaction but once we scale things up a million x we only need to pay per transaction three three way to to be able to be sustainable and the good news is that three-way is an absolutely tiny amount of money it's three billionth of an ether and even if this ether is widely successful even if it's worth a million dollars let's say three way would be still less than one cent it would be 0.003 basically one third of a cent and so basically we we're gonna be in a position where ethereum to remain sustainable requires transaction fees which are essentially noise essentially just dust now one of the exciting thing about ethereum as a business is that the secure blog space is is Big Business and it's been growing extremely fast and this is the basically the the daily blocks block space sales since the very beginning of ethereum and the y-axis is is a logarithmic axis so as time progresses even though the transaction the per per transaction fees might go down the in aggregate the the income um should increase and this is partly due to a concept called induced demand as you improve things as you reduce costs then more you on more and more users will come in more and more decentralized applications will be will be built and you're unlocking more and more activity and I expect this to continue to happen of course the um the block space is a very you know volatile resource and so these Peaks and troughs you know they're highly correlated with with bears and bull markets and you know it could look like you know the the the aggregate fee volume has dramatically decreased by a factor of 100x and it has the 100x in the grand scheme of things is actually not much okay so here's my last slide and it's basically trying to give you the big picture summary um you know talking in terms of orders of magnitude in terms of where I see a potential future for ethereum so I expect the supply to be roughly a hundred million dollars in in the long term so right now we're at a 120 million dollars and the the supply should should decrease slowly and eventually in the equilibrium reach 100 million dollars now where will these 100 million ether live so they will live um you know partly at stake securing ethereum partly as collateral providing economic bandwidth for defy and partly as currency you know for example IFA within exchanges like uni swap or even centralized exchanges if we have roughly 30 million Eve staking that's going to lead to roughly 1 million each per year of issuance and if ethereum is going to be sustainable as a business then the burn must match that at also 1 million if per year now the income what I expect is remember the previous graph I expect the income for ethereum to be billions of dollars every single day in selling block space even though the per transaction fee will be less than the Cent so this is the success for if where we can get the best out of worlds on the one hand we get tiny transaction fees it for one single transaction but in aggregate because we're doing 10 million transactions per second actually ethereum has a huge amount of income and that allows it to have a huge amount of Economic Security and then again in the success scenario I'm expecting tens of trillions of dollars of economic bandwidth for defy and correspondingly tens of trillions of dollars of stable coins that are being traded on top of ethereum and I think if we do reach this potential future then undoubtedly ethereum will have succeeded in becoming the settlement layer for the Intensive value thank you amazing thank you Justin we do have some time for some q and A's if you have any questions for our speaker please just raise your hand really quickly we'll come in and give you a mic so if you can raise your hand or stand up we'll make it easy to find you I have one question on this side we'll have a volunteer just come to you right away it's just behind you sir and other people will uh keep keep your hands raised and uh there we go perfect let's make sure the questions are relevant to the talk hey Justin uh thanks so much for uh one making this a talk highly approachable thank you for that um so I had a question with respect to from your talk what I would Now call the iliquidium eLiquid premium and I think it was actually in David's talk where he had a friendly ultrasound debate where he gave up essentially the point that liquid staking derivatives then I guess would reduce this illiquidium illiquid premium could you potentially speak to that a little bit yes so I wouldn't have given up so easily for a couple of reasons like the the first reason is that one of the the main uses of the the the liquid sticking token is to have leverage and so what you end up doing is you end up locking this liquid sticking token and so that that liquid sticking token is itself not liquid but there's maybe another reason which is more important which has to do with the cost of money that I mentioned so let's assume that the cost of money is fixed over time let's say it's three percent the cost of money is going to dictate how much if is being staked and what the liquid staking tokens do is they allow you to unstake immediately as opposed to having to go through the exit queue and you get this privilege of unstaking immediately by basically paying a very small fraction to to market makers or arbitragers who will go through the pain of unstaking on your behalf so you're going to sell let's say you're one uh staked e for 0.9999 if paying a little fee for the privilege of not having to go through the execute now what will happen is that these arbitrages they will go through the process of unstaking but when they do that someone else will come in and compensate for this for this removal of stake and the reason is that in in the equilibrium the amount of staked if should correspond to the to the cost of money and so even if there's like a large amount of Eve that on Stakes then in the equilibrium more if will come in to bring to to bring things in and so really you can think of the total amount of if really as being this illiquid iceberg um that that is essentially impossible to melt because if you melt a small portion another amount of of ice grows on the other side awesome we'll move on to our second question so in in your future um why would there be tens of trillions of dollars of stable coins instead of ether just having much less volatility and becoming like a stablecoin right so you're really thinking ahead so I'm I'm thinking 10 years into the future and I think you know it's going to take a long time you know to transition from Fiat currencies that live in you know in in central banks to and and and Commercial Banks to basically uh stable coins that are that are settled on on ethereum but I think you're right if you want to think much further than 10 years if you want to think 20 years 30 years 40 years then maybe there is a case for IFA the asset to kind of be the stable money I mean one possible counter argument here is is gold in the sense that gold never really managed to become this like perfectly stable asset and it's possible that there will always be like too much volatility relative to you know baskets of goods that people want to buy for E30 asset um so I think at the minimum we have to go through a transition period where we have these decentralized stable coins and it's possible that even in the end game IFA won't be stable enough and we have time for one last question so I'll let David ask uh this is just extrapolate on on the last question the debate was that um ether locked in this taking contract has always been a fundamentally like bullish pillar of ether it's like the more ether that's locked in the contract the more scarce it is uh more that more value it has and then Jordy in the debate was like well all these things are going to become staking derivatives so that you can easily sell so there's no such thing as locking anymore um but the counter argument that I heard that I want to check with you Justin is that it doesn't matter whether you can easily sell it on a secondary Market because the incentive to hold has always been through the yield and you can always you can always withdraw out of the staking contract so it does so is the the four percent five percent three percent yield of ether equivalent to just like straight raw demand for holding this taking token regardless of whether you can unlock it or not are you saying that it completely nullifies that that in my opinion it does yeah cool yeah awesome well please give Justin a big round of applause thank you so much thank you for our next talk we're going to talk about how do we keep promoting the development of ethereum protocols so for that I'd like to talk uh bring up Trent van apps to talk about the protocol Guild on how do we sustainably fund ethereum development please give Trent a big round of applause check check hey everyone uh oops can I I think I left my water over there can somebody grab that thank you everybody who's uh here to listen to this talk um honored to be speaking at Devcon I never really imagined I would be doing that a couple years ago when I first got into ethereum so uh honor to be here and um happy to educate or communicate what we've been working on here with the protocol Guild so the title of the talk is funding ethereum with the protocol Guild uh like Karthik mentioned my name is Trent van apps I am a member of this Guild uh however I do also work for the EF on the protocol support team which is uh we we work on network upgrades and generally coordinating the ecosystem around where the protocol is going and how we can improve this coordination process so a brief intro I'm assuming most of you are aware of this but uh never hurts to step back and think about what we're what this topic is so ethereum generally is a globally distributed computer that anyone can use anyone can access um uh people can deploy contracts to it they can send transactions and interact with it anywhere around the world uh this means that ethereum the network so mainnet is a screenshot from etherscan there and this is a public good that users of the network um can depend on and use throughout their lives they can trust that it's going to be a resource for them nobody can stop them from using it this is stretching in the definition of public it a little bit because we have transaction fees but generally um we can we can understand it to be this and if we take a step back looking at the yellow paper this is the ethereum virtual machine this is a another public good that ethereum developers core contributors they maintain and many other chains uh besides ethereum also use the evm so these are two fundamental public goods infrastructure that people depend on they build companies on they store their finances on and they're really important for people to actually have access to and if we're thinking about the different categories these can include you know the research about where the protocol is going uh the client developers who are implementing the protocol as it currently is the coordination like I mentioned the work that I do along with many others to shape Network coordination and then there's tooling so what developers actually use to interact with the chain and then that brings us to the question of how are these uh these areas of public goods funded a big one is the ethereum foundation you're probably aware of what the ethereum foundation is and what it does it funds a huge number of initiatives in the space sometimes through direct contributions sometimes delegating funding to specific ecosystem groups or things like the client incentive program where it it gives eth directly to client teams to run validators and it unlocks over a specific period of time and then outside of the ethereum foundation there's groups like optimism giveth git coin CLR fund who run matching rounds quadratic matching rounds where the community can participate in actually funding these important public goods things that people depend on and then another smaller project which you may not be aware of is called open grants which does vested eth to specific groups there's a some projects that are using this to fund public goods so yeah there's there's quite a diversity and I think this is um uh one of the strengths of ethereum is that it has a diversity of approaches Kevin owaki uh formerly the founder of git coin uh had a talk earlier that I was on about uh practical pluralism and how important it is that we have these many overlapping approaches to how to fund these important initiatives how to get funding to people who are working on infrastructure and this is a great visualization of I'm sure I'm leaving out some projects so I apologize but there are these projects on the on the slide and many more who do the important work of getting money to public goods infrastructure the developers who are actually building the things that we depend on and I'll Echo that by by saying uh many Community funding mechanisms are good it decentralizes power and influence away from uh single entities it celebrates pluralism like I mentioned um prevents influence from being siled with individual allocators and it strengths strengthens the intra-community relationships however uh especially the quadratic funding mechanisms they often use similar curation techniques for example it weights the matching pool division according to how many people donate to a specific Grant and this is not State it's a bad thing it just um it's it can have a challenge when it comes to delegating funding or getting funding to areas of the protocol that may not be a fit for quadratic funding um yeah so this is the question is how can we curate better specifically related to the core protocol and then even more broadly how can we incentivize long-term core protocol contributions so this is a a big question that's you know been around as long as open source software has has been worked on and it's not a new problem for ethereum people have talked about it over the years you know people join core development they leave core development it's something that will be with us as long as we're producing software and modifying the protocol so these are these are the big questions um that uh came to mind um over the years they've been a recurring set of concerns and especially last year in November the discussion in the community began again about how can we properly incentivize contributors to stick around while also making sure that they're financially compensated so when this discussion came up last year there were my perspective of being around core development for a few years now and then working with core developers directly some researchers we started to think about what sort of challenges were most important to address when thinking about what sort of mechanism would be best to design and if I'll go through the first three here just an overview and then the next slides detail out what these challenges are so the first challenge curation is hard the second the incentives are imbalanced and the third contributor churn is bad so the first challenge about curation the ecosystem is very interested in sponsoring um this guy The Princess and the magician the ecosystem of broader individuals Dows protocols l2s they're interested in funding the core protocol but they don't have a single mechanism to send funds to there's uh sometimes projects will publicize their you know ethereum address that you can send donations to but it's not necessarily easy to find all of them in a single location um similarly protocol contributors are interested in receiving funding some of them may not be directly working for a team but they're doing important infrastructure work they're interested in receiving some form of financial compensation for the work that they're doing but there's no single mechanism for them to plug into and be recognized for their work and then on top of that some of the existing Solutions favor teams due to the difficulty of curation like I mentioned the solutions favor teams and it's really hard for them to surface many individual contributors for example in a grants round um and we can't expect a single organization to uh that's outside of this core development or this core infrastructure to effectively curate the work that these people are doing you know it's very deep technically uh it requires you to sort of be embedded within that work and it's it's not reasonable to expect a single organization like Bitcoin to really effectively curate who's doing the work at the core protocol and and how they should receive the funding uh so the response to how to address this question is um we should uh designate a contract on on chain that is regularly updated by the the members themselves so people who are doing core contributor work uh they're updating this membership registry the second problem is that the incentives are unbalanced uh so this is maybe a little self-explanatory but I'll go into it l2s D5 projects token projects things that have Equity there's a stronger incentive for uh people to go work on them rather than the core protocol and this is completely rational you know if you're weighing your options here um ethereum just doesn't have token incentives or Equity or anything that can similarly be offered by applications or l2s however it still needs to attract and retain talent to evolve the protocol you know ethereum is uh an infrastructure influx there's a lot of changes that we'd like to make to better scale to become more secure and we need we need really smart people working on these problems but we should be compensating them fairly it's totally rational to pursue something with um you know greater Financial upside and I don't follow people for that or for other protocols leveraging these these incentives um however as the broader ecosystem continues to grow competition for these talented individuals is really going to only increase um of course Financial motivations aren't the only or best motivator for people we just want to recognize that um uh it's just one tool in our tool set that's being under leverage so the problem of imbalance we can address this by um tapping into the the financial value that all of these amazing projects are building on top of ethereum and getting them to contribute some of them back to the people who are working on the core protocol the third challenge uh exclu excuse my rushed Graphics here but the contributor churn is a challenge when it comes to the core protocol it can take you know six to 12 months for somebody joining a client team to really start to understand how they can contribute to the client effectively uh and start making meaningful impact on the work so there's a steep learning curve for new contributors to to deliver value however the contributor value does grow over time if you stick around but there's less incentives to stick around if you're once you're an expert you you sort of reach a certain level of of expertise with a client code base for example uh so one of the things we thought about how to address this contributor churn is that membership eligibility to any sort of public goods funding mechanism it should only be after six months of regular contributions and that assets should vest over time in order to incentivize this um to incentivize this knowledge transfer between different cohorts different uh generations of people working on the core protocol you know there are some amazing people doing work today that maintain clients and make ethereum infrastructure in the protocol possible but eventually they're going to move on or retire if we're still around in so many years and we need to make sure that the next generation of people that are going to be maintaining this software are ready and incentivized to stick around similarly so uh as you may have guessed I'm describing the protocol Guild which started as an idea last November and we've been building it since then uh we worked with a team called Xerox splits to um design well they already had a split contract but we worked with them to design a vesting contract and it's a collective of today 119 ethereum contributors and we're working to rebalance the incentive address all those challenges like I laid out in those previous slides and here's a very simple diagram uh the sponsors these can be anybody in the ecosystem individuals projects large scale small doesn't matter anybody who's interested in giving back to a really highly curated set of core protocol contributors they send funds in whatever form they are to investing contract over a certain amount of time and then it goes to this weighted registry which is regularly updated by the the membership itself and that's the key that it's self-curated because you know you have a really high signal for the membership and the fact that you know that these are people who are doing really crucial work I'll dive in a little bit uh into eligibility and self-curation like I mentioned to be part of the protocol Guild it it has to be you know something Beyond a typo in a client code base or something and Beyond six months um we want to make sure there's a there's a high threshold for people who are actually really committed to this infrastructure work and uh touching on self-curation again the the reason this is super important is because it avoids intermediation between external curating entities which may or may not be really close to the work that people are doing so like I said you get a really high signal curation and you can be assured that this is going to be consistently updated over time with a membership that's really contributing to the core protocol and it's incentive compatible because adding new members dilutes existing ones so you don't have to worry about new members just adding anybody in the ecosystem there's a cost to properly curating however if eligible contributors are not being added then it removes any legitimacy that's built up over time and external funders won't continue um funding this mechanism so we hope that these are sufficiently balanced against each other but um this this next year is sort of a learning period uh over yeah it's a learning period so we've launched a one-year pilot to test out the assumptions about the challenges that we wanted to address as well as the assumptions about what the best ways to approach them are how long should vesting be things like this so we're working on that we we launched the the protocol itself in May of this year and it'll run until May of next year and so far we've raised 11 million in sponsoring assets and like I said these will vest for one year overtime again to incentivize long-term contributions knowledge transfer between different cohorts of core contributors and it's it's been very awesome to plug into existing funding infrastructure to touch on this idea of pluralism in funding there's a git coin Grant we've tapped into some Dow treasuries who fund back in their native token so shout out to the people that have funded including uniswap Lido ens announced out to name a few as well as this Norm that we want to pursue Sue of one way to scale the incentive the treasury sorry uh to build the norm around allocating a percent of the initial Supply or annual revenue so again another shout out to True Freeze gnosis safe and texture punks and nft project they've committed to contributing some some of their revenue and over time we want to build this more and more we're not saying that this is the only or best way to fund through you know initial token allocation but we're very excited to explore this with the broader ecosystem we're already starting some discussions with l2s about how they can directly fund this this incentive mechanism and one thing we really want to be intentional about is documenting the outcomes to see you know does this really work does this increase the incentive to contribute to the core protocol and we hope it will but we want to make sure that the community holds us accountable and we really iterate and improve the mechanism over time uh one of the cool things is because this is all on chain anybody can track it so if you go to Dune analytics and search protocol Guild or something monkey sorry I can't remember the name of the contributor but we've been working with someone to put together this dashboard and anybody can track the finances of this on-chain protocol incentivization mechanism which is pretty amazing you can see the membership uh the the total weighting of their share of the the proceeds who has contributed uh really great data source and um awesome for transparency if anybody's interested in tracking that uh so I'm ending a little early if there are any questions um I'd love to talk with anybody who wants to learn more about the mechanism if you're part of a D5 project or something that's planning to launch a token um please do come talk to me or any of the members there's a ton of core developers here who are part of this project that QR code I think takes you to the docs or somewhere else relevant um so yeah and then there's some bitly links if anybody's curious to explore more that's my handle and then you can follow the the organization itself at protocol Guild on Twitter yeah so thank you for the time again to the Defcon organizers for giving me space to talk about this public goods funding is incredibly important and uh it's it's important to have also a variety of approaches different curators different uh mechanisms so that we can make sure that the incentives to contributing back to the ethereum protocol in the context of amazing application layer projects is maintained over time so thank you and I'm happy to take questions if there are any [Applause] we have a question here we'll give the mic to the gentleman over there if you have more questions please just raise your hand or get to the end of the line so we can quickly give you the mic and I'll let's begin with the question Adrian thanks um amazing initiative thank you for giving the speech I had a question about the recent acquisition of uh prism um I'm curious if you could comment on that like obviously on one hand that means that there's I guess less pressure on the protocol Guild to fund those developers on the other hand is that the kind of outcome that we strive for now obviously Arbitron they're they're a good actor I think they have a great reputation um but one could think of some potential downsides so I'm just wondering how does a protocol Guild feel about those kind of outcomes what sort of downsides do you see undo influence I mean obviously we have like nine teams in total who are contributing to this if I'm not mistaken um and so you know We Trust arbitrum if um if they start doing some weird stuff you know there's other options for people to choose different clients um and obviously if we have many more clients their influence uh you know they won't really have an influence um but nevertheless you know they have certain interests um they might like they're probably going to launch a token tokenomics how do they pump their token you know these kind of questions yeah you definitely uh pick the hardest question um given they announced yesterday so yeah this is this is really interesting and digs into it touches a lot of different areas about protocol governance incentivization um funding the core protocol work and like you said I don't I know them all personally um so I do have a bias here but I do expect that they will maintain their neutrality um I can't comment super deeply on it again because it just happened and I'm still digesting still understanding the the mechanics of it but I don't expect that there would be any uh undue influence exerted by the L2 and like you said if there were red flags starting to appear I'm pretty sure the community would call it out uh pretty fast um and uh either arbitrum or the Prismatic team would adjust course pretty quickly but yeah that's the short answer it's on the other hand do we have more questions there we go um what's the like let's let's say someone's leaving the protocol Guild what's like the process for the offboarding like do they have an amount of time or has that been thought through much uh leaving or joining leaving um if they're leaving so they can they can claim any assets for investing at any point but there are windows in the contract so once they leave uh contributing core protocol work they can they won't receive future vesting but they they can claim at any time it's permissionless like that does that answer yes cool anybody else I have one sure how do you think about deciding what should be funded and how do you sort of in a way prevent or get ahead of not having favoritism kind of coming to play yeah um this is something that we've been trying to iterate on through the pilot and one of the reasons we wanted to start really small I mean 10 million is uh it may seem like a large number but split between 120 different core contributors it's not not that massive but we were very intentional about the amount of money that we're raising and and that's one of the main reasons is because the eligibility framework isn't going to be exactly right the first time and we're going to need to iterate on it and so that's part of this pilot is figuring out um what sort of scope we want to take on and I think what we've learned over the past six months since May is that um it's probably better for a more narrow scope and to be as explicit as possible so if you're working on a research team if you're contributing to a client code base or doing coordination we want to make sure that it's it's very clear that these are people who are contributing value because if you aren't explicit or don't maintain rigor in the eligibility process again the mechanism will lose its value it'll become a lossy signal for people who are interested in contributing to something that's that's that's uh going to get their money to go to the right place so um make sure that we're iterating and starting small is is how we've approached it that's great and just out of curiosity did you kind of compare this thing with the retroactive funding model and sort of what was kind of the the pros and cons list that you made made you kind of pick this model sure so retroactive funding is great in that we can also plug into that um however uh these individual teams they don't have to apply on their own or the the because protocol Guild is biased towards the individual um it's you can imagine it's sort of like a collective or a union that represents them and makes it very very straightforward for people interested in funding like like optimisms retroactive funding program they can just point it to a single address and scale it accordingly however much they'd like to give back rather than uh possibly missing somebody who did crucial work over the past two years they can rest assured that this is this is a mechanism that's going to be very very tightly curated but yeah I'm super excited to plug into retroactive funding continue to have a good coin Grant things like that is uh all possible and I'm sure there will be even more mechanisms in the future that are a good fit for these types of things awesome to any other last questions great well please give Trent a big round of applause thank you [Applause] we'll take uh one two minute break before we get ready with the next talk so uh you can stretch a little bit and we'll be resuming in two minutes expected [Music] thank you foreign foreign foreign [Music] foreign [Music] we are ready for our third talk for the afternoon and for this talk I'd like to invite Alex to Stage to talk about building blocks after the merge so without further Ado please give a big round of applause for Alex Stokes okay hello great foreign er down and let me just check uh that this works it looks like it does great uh hey everyone good afternoon uh I'm Alex Stokes a researcher at the ethereum foundation and yeah you know the title here says block building up for the merge there's like a subtitle which is Mev mov moving forward uh you'll see in a bit I have another kind of variant of this talk that looks at more I'd say like the technical side of things and I hope today to kind of communicate uh like a sense of the landscape around this topic and like Mev is like the obvious uh you know uh Buzz phrase here um but yeah so let's let's dig into what that means and hopefully by the end you'll have a sense of again yeah like the landscape and uh what some of the concerns might be moving forward so I've kind of always said that putting currency into crypto like cryptocurrency is like this double-edged sword because like yes you know there's like uh this like speculative aspect that draws a lot of attention a lot of talent a lot of capital to the space and that's great uh but in the same you know sort of in the same breath that also means that we're kind of directly programming with incentives here we have the sandbox for [Music] um you know playing with these different crypto economic games and uh I guess hopefully you'll see as we move forward that uh you know this could perhaps backfire it could be the case that short-term incentives that are supported by protocols like ethereum are perhaps too great for us to uh sort of resist and in the context here uh this is an important point I say secure block space will be a premier commodity of this century so maybe that's like a bit of a forward-looking projection and maybe you don't quite buy it that seems to be to me the direction things are going I called secure here out in italics because some people say oh you know you could just make a new L1 there's like as much block space as you need but I will claim that you know there's different qualities of block space some is much more secure than others so we have this thing and if there's this thing called block space and it is actually so important it's going to be very valuable and because it's so valuable we should expect battles for control over block space so uh this is like if anything the takeaway points I'll just get it out of the way um and when I say this I want you to think about like you know influences both inside the community and outside the community there's going to be all sorts of people who are going to want to like try to attempt to co-opt ethereum um and you know that can happen in very overt ways it can also happen in a very sort of subtle ways so just keep this in mind I think when we think about any of this stuff around the protocol what it looks like how the protocol changes things around the protocol like Mev and like a whole separate talk in this Advantage like staking pools but when you think about this stuff just uh have an adversarial mindset and just yeah be be careful out there okay so I use this word block space maybe some of you have never heard of it so what I really mean is just the stuff that goes into the blockchain so today that's like transactions if you ever used ethereum or like metamask you've done this you like have this transaction and uh maybe you sign it maybe there's some error maybe there's not enough gas maybe you didn't pay enough for the gas like a lot of things can happen um but you're probably familiar with this notion of a transaction and so you know in the very sort of naive model we have a bunch of transactions they get packed into blocks and these blocks go on chain so to speak which means they're like accepted as canonical or you know part of the consensus and then somehow this like moves the state of things forward I uh have this like sort of elusive comment to say tomorrow you'll see in a bit that this notion of Builders I'm going to sort of present today unlocks a lot of sort of abstraction and flexibility around how we use the protocol and how we like access his resources and uh yeah so maybe in the future it looks a lot more General than just like the transaction you get the metamask but so concretely like transactions are you know like the takeaway here is that transactions are a way to interface with the protocol's resources and like what we really mean when you say that is like the state like the fact that ethereum is organized as a blockchain today is like kind of a detail it's like an engineering detail almost like the important thing that we all care about is the fact that there's this like shared Global state um for example the account balance is everyone in the protocol the state of smart contracts of uniswap of Ave maker and you know everything else there's there's a lot these days uh and the state is like the the thing that you know is sort of the actual valuable thing any block space to access the state and this is what everyone you know I claim will be uh will be battling for control over and it turns out that you know because block space at least on ethereum is so valuable you know it supports this ability to specialize so what I mean when I say specialize is that we're seeing the emergence of this this role within the protocol uh called a builder and um yeah it's just this entity that says okay like rather than just like run a very naive algorithm for like getting these transactions into the block which then goes on chain you can do like far more sophisticated things and if you're familiar with any of this Mev stuff this is like one example um and yeah it's like I really do think kind of this guy is the limit in terms of like the Ingenuity people are bringing to to doing this task and the takeaway here is that you know Builders specialize in refining block space so a hopeful analogy that I've come across is like thinking of you know we have like uh actually I think this yeah so Alpha and algae here is like and Alex lead to like mining some some resource like say copper ore you have copper ore you can like dig it out of the ground you just have this like thing you have to like get the Copper from The Rock and this whole process of extraction to get to say like refined copper this copper bar in the middle here and then that can be further refined into uh you know say copper coins or pick your thing so this is just like a generic notion of like taking some raw asset some raw commodity and refining it through like a series of of phases and in each phase it's sort of like is more valuable in the face before it's like for example if I just like walked up to you and gave you like a hunk of copper ore you'd be like okay cool but I don't really care whereas like if I walked up and you know handed a bunch of coins you might care a lot more so this is what I mean when I say that uh you know there's this sort of raw asset or this raw commodity is probably the right term uh block space and again what we're seeing is is this this notion of a builder in the protocol or at least you know around the protocol that takes box base and sort of provides these like value-added services or almost Goods you can think of them as to go from a less viable thing to like a more valuable thing and that's the job of the Builder so now the question is well okay yeah what are some examples of things they can do and there's actually a lot so uh here's like a list of things there's a long list of things again this is where I think all the Ingenuity and creativity will come in that I think is really exciting around this space and I'll just run through some of these examples here right so like one of them is like sponsored transactions there's so many people have wanted for like a very very long time and the idea is that basically you have this Builder and they pay for the gas so kind of concretely what that looks like is you know I have my transaction rather than making like a direct ethereum transaction I make some intent some message something the Builder knows how to like interpret in their own way they still have the same effect on chain uh but then they can be responsible for paying the gas and like end protocol another thing they could do instant confirmations so this is again something if you've like you know going back to a metamask example you might have seen where you send a transaction and oh you have to sit and wait and it's like is it on chain yeah like what's going on like sometimes especially when there's like volatility and like the gas market and things like it's it can be very unclear what's happening you can like end up waiting a very long time and that's not fun but uh there's this almost service or abstraction a builder can provide which is just to say okay um you want this Con this transaction to be in this block and I can basically as a builder say I promise you this will happen uh trust me and there's a whole design space around you know changing what trust me means but basically I can I can give you those promises a builder to get into that block and in that sense then I can turn around immediately say yes you're in the block uh related thing cancellations retries so the notion here is just saying like um yeah let's say I make a transaction and I'm like oh wait like the market just moved against my unit swap trade I'd rather just take it back if you're just sort of sending raw ethereum transactions today that's really hard to do because you like gossip them through this Global nipple and you'd have to like Yeah It's Tricky um one way people kind of game this today is they will send a duplicate transaction or one that will override the previous one that has different effects but again that's like inefficient and you can imagine there's like this layer around the protocol that handles this for you and like in the same bucket there's like retries so like let's say I want to like I don't know do a token transfer and for some reason it fails just because of like conditions on chain so then I want to keep doing this you know until it goes through and rather than me have to sit and do this like a builder could do it for me uh next one gas Futures so here the way to think about it is that a rather than someone you sort of like block space right now as a builder I could sell you block space in the future it's a pretty cool idea and one you know one reason you might want to do this is because you know as part of this like contract that we enter into you're also selling me at a certain price so even if like the the gas marker moves against me I still locked in a price that's nice to me and voters could do this I mean there's other ways to do this on chain with like looking at the base fee and stuff um but yeah so just to give you a flavor again of what Builders could do uh sell Futures around block space this was an idea I heard from hasu you could basically also sell blog space in the past and uh I won't go into too much detail here because basically what this means is like selling reworks which is uh probably something we shouldn't dig into too much uh there's like some I'd say moral hazards around it but the Symmetry between selling box base and the future in the past is like I think too nice to pass up another one is just like this whole bucket of abstraction you might have heard of eip4337 and basically again it's just this way to like add more flexibility around the core protocol so that uh people have more again flexibility and and how they used it how they use it um a simple thing would just be like a different signature scheme than ecdsa and in this last bucket Mev I'm sure you guys have heard about this a ton this week and you know if you think about extraction as like the service a builder could add or well there's a couple different things but if you think of extraction then there's like this whole bucket of you know we can kind of just shove Mev into this whole notion of like a builder providing the service to to users whether it's Searchers or someone else and so then I have a few examples within you know sort of that Subspace uh maybe extraction which is what you usually think of when like a search is running some ARB it may be smoothing the notion here is basically you know maybe it's very spiky and so instead of what we can imagine is somehow capturing it within the protocol and smoothing it out over time then it's paid out uh to builders to proposers however that looks um that'd be pretty cool and you know you could imagine off-chain constructions that do this that Builders offer our last one is like it may be protection or rebates and the notion here is like um Builders kind of would have this direct pipeline to the protocol and they could say hey I promise to keep your transaction private so it can be for example front run so there's a lot they can do is is the point and again there's there's a bunch more um uh there's okay and then like even looking at a little a little further forward I'll just touch on this so these are like you know this this list here I think is like pretty concrete things you could do today and I do think this is painting a picture of this Builder as this like generalization that we'll continue to see in the protocol um for example you could have rather than transaction level 1559 you could do the Block Level so today when you like send a transaction you basically have to like have some kind of eat that you burn but if you think about it the economics are the same if the builder of the buck uh burns the same amount of eth across all transactions at the end and the reason you want this is because again there's like better ux for users they don't necessarily need to have Youth and um yeah again this is the generalization of like the protocol providing resources and then the user consuming them and then a similar thing is Roll-Ups consuming Bobs and 4844 so you might not know about the CIP but basically the idea is we're going to add a bunch of like data space to the protocol for users like roll-ups and again it's like we don't want roll up stuff to necessarily like sit and like manage Bobs and figure out when they get on chain and things like this um and so you can imagine there's a builder some sort of abstraction like a builder that manages getting blobs from blow ups or from sequencers or developes onto the chain uh here's another talk I'll just quickly point out where uh the one I mentioned previously where I went into a lot more of these use cases in depth you could welcome to check it out so this sounds cool you know I am claiming there's this Builder thing and it gives you all this functionality and that's great uh but what's the catch I mean there's probably a catch and the catch is that the specialization actually implies validator centralization and this is bad because it kind of harms like the whole health of ethereum like the reason we care about ethereum is because of this essentialization of of the consensus right of the protocol and uh Builder specialization harms us directly so let's look at why and why is that you know this this process has economies of scale so right now the like Builder protocol or sorry the Builder role in the protocol is tied to the validator role and because of that uh you could have builders that do their things you'll have entities that sort of have validators they partner with to do their thing as Builders and what happens then is like better Builders have better profits and this makes this flywheel where they have better profits they can get better building they can help their validation operation and you just get this like again flywheel that goes until suddenly like you have these like really huge actors in The protocol so again if you're like the best builder that's great for you uh but if this you know goes unchecked then it's actually really bad for the protocol in the long run because now you have this like very fragilizing thing of this like one huge actor that's like easier to say attack and all sorts of things so just like a note you know Mev kind of directly accelerates this problem uh which is probably why we've been hearing so much about it this week so okay what can we do um there's a couple things one of them proposer Builder separation uh Barnaby gave a talk about this yesterday I believe and I mean the idea that I think is pretty straightforward just from the name you I mentioned that this Builder role and sort of the proposer about air roll the thing that actually is like minting the block on chain this thing these are tied together so instead we can just separate them and uh this sounds great the question though is like how exactly you do it and once you start looking into this in some depth there's a bunch of like subtleties and like open questions that have a lot of nuance that like still need to be worked through so for example um I think like the leading designer now is from vitalik where basically we have two slots alternating proposer and Builder and the point here is that you want to have the proposal do their thing in a different context have the Builder do their thing and it sort of firewalls you know these two these two entities from each other and that's great but then you have to make sure that it's in significant capacity incentive compatible like you don't want uh a proposer to like release their block too late after they've accepted a builder's bid and then because of that the Builder doesn't have time to like uh you know reveal their block and it quickly gets to a lot of uh tricky situations like that another one is like actually deciding the mechanism the mechanism of sort of selling the block space that a validator may wish to do uh the default thing we do is like just enshrine an auction um but then the question is like okay is that is that what we want do we want this thing where it's like I'm going to auction Off My Block space to the highest bidder there's like a bunch of different ways to think about this I will call out again Barnabas various and post on each research on Boeing PBS and he talks about kind of uh maybe pulling the auction bit out and just having sort of this notion of like a commitment Market where the commitment then is like quite General another point then is like yeah just the Integrity of this thing because kind of like I alluded to there's there's many actors now and they all have different incentives and you need to like line them in the right way uh if you don't do this properly then well yeah if you don't do this properly then you can imagine like people just not using it so one way you could fix that is you have a testers go and also attach to the chain you know if there's this two slot process alternating you can have the testers to test what they see and in that way they strengthen again the mechanism but then it's like okay maybe they could be bribed like who knows uh so point being there's a lot of open research questions there oh no my emoji didn't show up anyway um it turns out that that's not the only problem so even if we had a great PBS solution I think like I think the way to think about it is like you firewall off all this Mev all this builder stuff from the batter set so they don't have these pressures to centralize that's great but then you kind of Kick the cane down the road and there's another problem where again you yeah you really just get the kid down the road uh to the builders because now the Builder is himself could centralize so we don't want to get to a world where you know there's like a few actors uh let's say like very sophisticated actors from drought Phi who are here and uh you know sort of gatekeeping access to the protocol like again it'll be a way for them to uh again violate ethereum's values and that would be very bad so I think it's even less clear how to handle this just because like the scope of the problem is so big if you thought there's like incentive issues with the previous sort of like proposal Builder sighting there's now like it's I would say even like less constrained so that's fun and okay like let's let's think about this for a second like how do we how do we fix this um one option is just to say okay we will have like very centralized Builders but we just want to make sure they can compete and the idea is that if there's like very healthy competition then there won't be one internship player and that avoids the situation where there's like there's very direct gatekeeping where I have to go through like one or two entities to get on chain so to do that we want to keep the barriers to enter your building very low um and yeah maybe that's enough we'll find out but still you know I think if you look around the world you see there's like power laws everywhere and so I think we'll still be you know even if we do have a healthy ecosystem it could be the case that there's like not a great distribution so we can ask well what next well pretty much most of us here we can call ourselves crypto Economist so we'll design a mechanism and what does that mean well we'll just read off this quote that I made up what does it mean to design a mechanism here well we want a peer-to-peer network with proper incentive alignment to ensure safety alignments of the protocol and now what does the protocol do well it facilitates the refinement of block space in this way I was describing um so that's great but there's some like huge caveats the huge caveats are uh we want to make sure that I think there's many but like two ones to call out right are that the people who are using this thing like let's say users who want to like make some trade on uniswap we want to make sure that you know when I make a transaction and for example it has some mov then like I've actually generated value that wasn't there before and it seems you know I think we'd all kind of agree it makes sense that the generator that value should capture most of the value so that's like a pretty big constraint on how something like this block space refinement decentralized protocol would look like another big one censorship resistance if you've been following any of them at Boost stuff which I'll touch on in just a second uh you see that this is like a very critical question because again when you have just a few sort of I mean yeah centralized pipelines in the protocol uh becomes much easier first internship to censorship resistance to Fall by the wayside so I'm just going to keep going down I kind of want to just like sketch this path for you hopefully to jog some of your maybe like capture some of your interest or uh you know dragoo creative juices but essentially what would the centralized Building look like um I mentioned this FPC conference Vitality of a talk uh on this a bit so I'd also recommend that one so um but yeah so for today the you know the ways I've kind of been thinking about lately are you have a builder and you want them to basically well yeah so there's different contacts the first context would be in a single domain and I'll kind of make that clear in a second but essentially you have a builder just imagine a builder on one chain and rather than this Builder being like one server somewhere you can imagine it being split across many servers sort of implementation wise um but anyway so that's actually not what we really care about like we care about higher level properties like um we want this builder then to be able to again be like multiple maybe competing entities and so what that could look like is you have agents who are doing the building and they're now competing for like order flow for example so if this is like an Mev context you have people who are making trades and I'm now like working or perhaps competing with other Searchers let's say to to build the best block but we're doing it in a way that again we sort of enforce this competition there I think the more you think about this there's like a trade-off between privacy and execution because you know one thing we could say is as a user again of my Dex trade for example uh you know nothing and then it's just like uh grabbing random batches of transactions and like putting them into a block instead you could like kind of be in the setting today where you see everything and then you have sort of full uh full information to even leverage against Maine when people are front running they're upset about that this is this is exactly what the tension they're getting towards so like what I did here is like the the Builder on a single domain context is you have you know imagine doing your dap your your defy app but inside some APC circuit um Cal swap is this thing for basically settling trades off chain before they land on Chain by just doing uh just the diffs or just like the remainder so it could be a cool research Direction another one there's this uh app I guess maybe application uh sorry maybe protocol but either way it's called Rook used to be called uh keeper down I think and either way uh at a very high level how that works is that they have like a trusted set of Searchers who have access to a private mempool and because they're trusted you know we trust them to then uh search and extract maybe but do it in a way that for the value extracted most of it flows back to the users of Rook so what this looks like is you have trades where you're paid to make the trade um you can do something like this and the question then is like how can we tune this like trust Spectrum uh so that we minimize trust while giving us all the nice properties we want another cool thing now is like you know there's not just ethereum there are other blockchains and so now we can think about me being like across domain context and this one quickly gets pretty hairy because like when you think about it you kind of now like if we're going to do this decentralized building thing across chains then you now need to like I mean yeah it's not even really clear how you do it like you could imagine like uh some crypto economic layer whatever that looks like maybe like a network of State channels uh maybe it could look like um yeah I don't know again this is where it's an open question but there there's a lot of things you could do um and yeah so I think we'll see a lot of exciting research come out of this area uh in the future so yeah I think I'm just trying to like lay on a lot of problems and maybe this seems like pretty hectic that's not good um but yeah like I do think this this these questions around like the Builder and like how the protocol is used moving forward or like some of the biggest that we face as a community so I do want to call them out and um yeah just just be aware that uh there's a lot of thorny issues here so hopefully you uh are motivated to work on fixing them and yeah like I'd like to like and done a good note like we did the merge you might have heard of that one and you know there's really this is like an existence proof that like progress is possible like uh I'll steal a quote from uh Danny Ryan quoting Albert knee who said that ethereum is like an intellectual gravity well and yeah I mean I think that's the case like ethereum is like a really outstanding community and I think that we're able to sort of adapt to whatever comes our way so I think I think uh good things are possible I'm running a little short on time so let me see I think I just had a few slides so yeah thank you okay my problem um right so just a few more slides and uh the first one is I just want to again call your attention to like yeah how can we actually start to to work on these issues um with this problem of validator centralization like yeah just supporting r d towards PBS I think there is some like nice PBS solution that we could get to and we may realize that there isn't one and that's also great but uh the work the work needs to be done and we'll see what happens in the meantime we have this thing called map boost so there's like an off chain implementation of PBS uh started by flashbots and uh many others now they've recently made a call for like open stewardship of the project so that's a great way to get involved I've called out the GitHub repo for red boost there's also some stuff around how this interface between the core ethereum software and this Builder network works and those specs are under this Builder specs repo uh some things that you know that Community will be looking at very soon is like address addressing censorship resistance I'm also working on this notion of a really monitor there's this like very trusted actor in math boost right now called a relay and they can kind of do some bad things and the idea of the really monitor is to add some like automated monitoring uh to figure out when they're doing things we don't like and that then we'll feed back into Mev boost to hopefully uh make the situation a bit better than it is today if you're interested to help there's a repo there that I have and please I would love contributions and then yeah I mean you probably get the sense that this this like Builder centralization problem is maybe even poorly defined like I think that's the first place to start there is just like defining exactly what we mean because I think it's like a big umbrella for many things you can start pulling a bunch out of it maybe if we can like Define the problem we can start cutting into smaller pieces that are you know easier to make progress on um you know for example if we do some sort of like NPC or like some crazy State Channel thing then how far can we push the cryptography to like actually get the properties we want uh how could we like now in this like very complex system address uh or analyze all the incentives to figure out like okay this this mechanism actually work and I think so far flashbots has done a lot of the thinking here so I just wanted to call out them uh they have a forum at collective.net and if you're interested in thinking about this reading about this research and things like that uh check that out and that's it yeah thanks um there might be just a few minutes for questions and uh yeah if you want to get involved just uh here's my Twitter and I can I'll answer any more questions you have direct you to the next step all that awesome we can ask one or two questions if there's any questions just raise your hand quickly make sure it's a short one we'll pass that mic over there to you in a second uh just over there hey um my name is Marat I'm part of block native where we build a lot of blocks flashbots has a great Searcher reputation system I mean we can talk about how great it is and whatnot but I'm wondering if there's a reputation system that we can come up with within the protocol for Block builders in the future as well right so I would push back immediately and ask how much we want actually in the protocol because like once it's there it's like very fixed um but yeah I mean again like a lot of these I think more like research or like even even you know even even less formed ideas around uh distributed building need to take things like that into account like you're going to have some actors who are like helping the Builder do their job or you can even think like the Searchers are the builders in this context and yeah like that's one way is like ideally we could have some cryptographic mechanism where like everyone does like perfect searching and valid like users get all the value that is allotted to them and that's great I don't think the cryptography is there uh and then perhaps it will be one day but not today so then yeah we'll then rely on like trust reputation things like this in the short term um so yeah I mean it's definitely a very interesting place to uh to look at amazing that's the time all the time you have for questions and uh we're ready for our next talk so please give Alex a big round of applause all right next up we have a really interesting topic we're going to talk about a theory of mov and to talk about all of that I would like to welcome tarun titra from Gauntlet to be on stage so without further Ado please welcome Peru on stage [Applause] thumbs up hello so uh you know I probably don't need to talk about what Mev is as much uh given that there were if I remember right 17 or 18 talks about Mev um but you know I think in the spirit of trying to understand the incentives uh hidden in a lot of these systems one question you might ask is does there exist sort of some type of formal theory for Mev does there exist some type of mathematical structure to this thing that seems to be you know Captivate people's imaginations yet no one can describe it um and so I'm going to talk a little bit about uh different ways of addressing this problem including some work we've done and um I I like to call any analysis of Mev sort of measuring the cost of feudalism so that's that's sort of where the title comes from cool so let's start with the operative definition of Mev you know when you see it like the of course the famous Supreme Court ruling on porn uh and uh you know Mev comes in many shapes and sizes uh you know of course we have everything from Sandwich attacks liquidations Arbitrage nft front running and cross chain um and as you can see there's it's sort of quite a variable form of revenue for for validators and Searchers uh and somehow we because we know there are many examples and we feel like we can't enumerate all of them it might feel like the space of all mevs super big so how do you analyze it well you know I I know there were two talks yesterday about what is and isn't uh Mev but I think we're going to focus on uh kind of an operative definition that uh can be used and uh we could we could sort of say Mev is any excess value that can be captured by validators by reordering transactions strategically adding or removing transactions um and the idea is most of this is currently managed via off-chain auction so people bid on transaction priority atomicity you know within bundles uh and you know if we take a step back and look at the history of ethereum of as to why we got to the auction world um part of the reason is the blockchain was just getting spammed by people doing liquidations and back running oracles and instead of normal users being able to get their transactions in you'd have the you know entire blocks filled with people you know span background transactions on the other hand of course as the previous talk was focused on uh there's a lot of centralization risk with off-chain auctions so let's you know try to maybe schematically look at you know what how Mev works we have users who submit transactions which are the Deltas we have a mempool uh the Searcher has sort of their own view of the mempool and maybe they have some transactions that are directly given to them which you know people would call Private order flow and then the Searcher sends their bundle which uh they're willing to pay for to the validator and the validator added to the block so the philosophical question here though is how do we know value captured by Mev is excessive or in a notion of excess you know in this sort of first definition I said any excess value well how excessive is excess so describing value Flows In Mev is actually quite difficult so in in algorithmic Game Theory you usually have two main ways of thinking about the world one is optimizing social welfare social welfare means if everyone has some notion of utility some notion of how happy they are with the world you want to maximize the sum of everyone's utilities on the other hand revenue is you know the the the person selling the good uh you know maximizing how much they earn um and and in in cryptocurrency it's actually interesting that you have to optimize both jointly so obviously user welfare is important for the success of any network I don't need to really convince anyone of that but validator Revenue being optimized is actually important for Economic Security if validators are not making sufficient income from it then they're unable to to Really secure the network and in decentralized networks versus centralized networks these are two competing goals and I think the one reason there's a broad view of how Theory you know algorithmic Game Theory it's different for crypto is that you have to sort of balance these two goals instead of trying to optimize one of them so what pieces are sort of missing so how would we kind of describe welfare as how would we describe Revenue um you know one thing is understanding the user's utilities what is the user getting out what is their individual notion of value and that can vary over the entire network the other thing is some notion of transaction fees and payments that you know the distribution of payment sizes that users are willing to handle and the last thing is an understanding of how an Auctioneer so in flashbots or you know in PBS how they allocate block this is to users and that that last part is actually quite complicated and these three things are quite entangled when you want to try to write a mathematical theory for a meeting and these sort of things actually depend a lot on the application right the user's utility for minting in nft is extremely different for a user's utility for borrowing uh against some collateral uh and inevitably that means that the allocation mechanism should somehow be tied to that okay so let's let's try to do kind of like the eli5 simple version of this which is uh you know we have a notion of block space which is sort of a notion of Max number of transactions or slots or size or gas you can choose a unit but for Simplicity just assume there's sort of some fixed number of units there's sort of a notion of a binary allocation to a user of whether a particular user gets a particular slot the users have the utility functions I'm unspecifying the domain and range because of course it's actually quite complicated in a world of cross-chain bridging and we see here that social welfare is defined as sort of the expected total utility of all the users given an allocation so these X variables are effectively whether that slot is given to a certain person then this is sort of measuring their sort of net happiness let's say uh Revenue however is just the expected value of the payments and notice these are quite different um in in particular the social welfare includes the utility of the auctioneer which means that all of the payments that the the users send are subtracted or sorry our negative terms for the bidders and it's a positive term for the auctioneer so the payments cancel out in social welfare so you have no dependence on payments explicitly whereas in revenue of course you you depend on payments so you know if we wanted to try to formulate what is an economic equilibrium for the system you might say okay well let's try to find joint up you know Maxima of the social welfare and revenue functions however given an allocation that optimizes social welfare it implies a set of payments and it can be true that the payments that you get from optimal social welfare are very far from the payments that you you get from optimal Revenue right that there's some intuition to that right like if if flashbots just basically gave every bundle for free obviously the there's a lot of user gains but like you know the auctioneer is pretty pissed aka the validator slash minors and this happens all the time in mud the the idea that the optimal revenue equilibria and the optimal social welfare equilibria are sort of disjoint so you know the the name cost of fee or cost of feudalism is really a pun on the concept of the price of Anarchy which is sort of a common concept and algorithmic Game Theory roughly speaking you can think of the price of Anarchy as if I take if I have a set of many equilibria I want to look at the ratio of the worst case behavior of an equilibria to the best case Behavior it's an approximation ratio and so what this for instance this formula says is what's the worst case that the equilibria the payments earned by the validator deviate from the payments earned at optimal welfare and what's the best case and what's the ratio of those and you could basically think of this as if this is really large or depends on the number of transactions or users that's really bad and so you know uh tongue-in-cheek uh you know of course nothing in real life is asymptotic but you know I I Feel Like These are good heuristics which is constant price of Anarchy is really good um it means that even if you get to a shitty equilibria uh it's not that much worse it's not that much uh worse than the best equilibria if the price of Anarchy is is weakly growing uh so little o of n so like maybe it's logarithmic in the number of users or slots maybe it's square root of the number of user slots that's okay it's you can deal with that um and if the price of Anarchy is linear in the number of users that's horrible that that basically means that the more users join the system the worse the equilibria is for everyone which is like the opposite of a network effect it's like the anti-network effect right no one wants that um and the interesting thing is that this quantity if you try to write it out depends a lot on your choice of how you what applications you're modeling because to compute the prices you need to sort of know these utilities of the user and that of course depends application and not to keep be laboring that point but I think that the one of the reasons Mev has this you know both me mobility and inability for anyone to write down equations for it is because it's so dependent on the application which is something I think you know the early designers of cryptocurrency networks did not you know Divine at that time okay so let's go through an example a stylized example of kind of what this looks like how would you analyze this for amms um so there's a very famous Paradox in algorithmic Game Theory called braces Paradox and braces Paradox is really about how traffic flows on a network so we have this network on the left and we have a source City s we have a destination city d and imagine that there's a bunch of traffic that needs to go from source to destination each Edge that it takes is a latency and so when you see a latency of one that's sort of like a a link that can take arbitrary capacity it takes the same amount of time for everyone to to cross that link when you see a link of X it's dependent on the amount of flow in that Network so you could basically imagine that say we have 100 cars um if a hundred cars all go down the route X then it's proportional to the number of cars that are going all right and so what you can do is you can say Hey what if everyone is selfish or greedy they're not cooperating they don't have Google Maps so Google Maps effectively gets around this because it it sort of implicitly coordinates people whether you you know you're thinking about it or not uh but assume everyone's selfish and they they know this map how would they how would they choose which path to take and the the thing you can show is basically it they would split themselves up 50 50. the traffic would go half on the upper path half on the lower path and so the the time it would take is three half you know we choose some units such as X's from zero to one on the other hand you might think that adding more roads always you know decreases traffic and this is not true so there's this interesting thing of if everyone's selfishly optimizing if you add a link between the two middle cities that lets you teleport um then everyone just takes the X middle link X path and the total congestion that everyone realizes goes up and so the the this sort of you know paradoxical Behavior Uh I think philosophers would not call this Paradox but but uh economists call it a paradox uh is that you know even though you added a road you've actually worsened congestion because people aren't routing themselves across the network well because they're not coordinating so you might say okay great what does traffic have to do with crypto well you know first before we even get to that you may think Mev is always bad you know there's always these articles that people are writing that are like front running is theft it's bribery it's you know whatever you will pick your favorite negatively connotated we use a weasel word and I you might just say okay like yeah it we we need to get rid of it at all costs with instead of thinking hey maybe maybe it's just endemic to such systems so you know we we saw abrasive Paradox and what we're going to see is we're going to see that for some examples of applications in crypto you can get around braces Paradox by having Mev which sort of says Mev has some positive externality in some situations which is you know the opposite of front running is theft as a service or whatever um and again not all applications are the same so that that's where the the conundrum in defining your sort of optimization problem shows up um another thing that's actually really important to pay attention to is if we classify users into two types of users strategic users who are Mev Searchers or people who are trying to optimize routes on chain and non-strategic user like the person who pays 80 bips for a metamask swap um if we kind of look at you know those two two sides routing is actually one of the hardest problems for non-strategic users so non-strategic users actually in fact Outsource that to third parties right now right so if I want to trade token a for token B but there's no pool directly from A to B or there's not enough liquidity you know I go to one inch matcha gem I'm including gem from the you know you could argue nfts have the same properties um and you know routing is actually quite complicated so you know algorithmic game theory is studied routing in fact braces Paradox is a great example of how how to study routing uh and one question you might ask is hey does this apply to amms does this apply to one inch the supply to mantra and the interesting thing that you'll see is now imagine in this prior example instead of teleporting in the middle link we actually add a small amount of congestion Epsilon times the traffic now you can show that equilibria basically approaches something as Epsilon gets really large you go back to the condition where everyone routes themselves across the two paths and when Epsilon is really small you get back to the the purely selfish thing and the idea is the Mev Searchers are actually adding this extra Epsilon so that people route themselves across the graph more efficiently and that's something that's a weird positive externality that if you write out the math you know I try to not add a lot of the equations to this talk but if you write out the math it's actually quite compelling that the social welfare somehow has improved by Mev in some scenarios right that's not the narrative you hear right the narrative you hear is like oh I'm just grannies are getting robbed in metamask and that's just not true always so I uh like I said I'm not gonna go through how you show such a thing but I'll at least give you an idea of like what such ethereum statement looks like for such thing and the idea is is we we showed that even when they're sandwichers the price of Anarchy is constant remember price of Anarchy constant that's good that's very surprising you would think that hey as more users come to network sandwich attackers make more of a profit they cause more loss but in some liquidity conditions they do not and this this sort of bottom uh chart shows you the expected profit on the y-axis and it shows you sort of the amount of slippage in your by the the user and you'll see that it has a Maxima it's not like it keeps growing and that that's the thing that's actually quite interesting and nice about this example okay so you've listened to me try to convince you that Med is not bad it can have these positive externalities maybe there's something really interesting uh about it and maybe you can direct it into uh being used for some particular applications that uh are just net net beneficial to your network so one question is what do you do to to harness it for good so one thing I think that's interesting and and this goes a little bit to Alex's talk before is suppose you did have a mechanism where it was just extremely expensive for people to bribe a validator off chain and in fact people were willing to basically uh share their Mev Revenue imagine like a mining pool for Mev Revenue now the reason that that's very hard to design is it's very hard to make it collusion proof where people pay one minor ahead of time who in the pool and they don't share Revenue with everyone but suppose you have a way of doing that and there's a lot of people working on really really interesting stuff both on the cryptography side as well as on the sort of distributed system side for for trying to to to do such a thing but suppose you have such a mechanism then you can redistribute Mev to all the validators in the system and one very interesting thing is you can show in some some sort of different types of for different types of Mev you actually can lower the overall inflation rate of the network if the Mev subsidy is large enough so the x-axis on this plot is the percentage of Mev Revenue shared and the y-axis sort of is a measure of how much people are adjusting their stake so let's say there's sort of opportunities outside of uh staking that people can earn yield on their assets with uh one question you might ask is like what what are the incentives that keep people staking and the interesting thing is that Mev actually adds this feedback loop such that you can lower your inflation but also ensure that people stay staked and so you know the y-axis is sort of a notion of percentage of how much is of the network is staked and you can see that at around 25 to 50 in this stylus model of Revenue sharing you actually get people to continue staking which is just you know it's just kind of surprising right like everyone's always like oh we've always needed kind of hyperinflationary economics and there's lots of reasons for that but but but Mev distribution also allows you to avoid having to do that so that's sort of like a kind of amazing blessing in disguise um and there's a lot more research that can be done in this space I think we we mainly looked at how liquidations impact uh um Staker incentives uh another interesting thing and I think this is the type of thing that we're seeing in multiple ecosystems whether it's ethereum um especially with uh roll-up auctions whether it's in Cosmos but everyone sort of is starting to realize the Mev auction of having a single Mev auction for everyone to kind of compete in may not be the best form of an auction you may want to have an auction per roll up you may want to have an auction per application so that you can tune the off you can tune the social welfare versus Revenue trade-off right now if you think about it everyone who's making a flashbots bundle for an nft mint is competing with everyone who's sandwiching for the same sort of block space but they may actually if you segment to the block space and say only this amount goes for sandwiching in this amount goes for nfts you might have a very different equilibria uh and I think you know a lot of the roll up developers are are basically kind of talking with us but an interesting thing is and some some current work is you can actually show that disaggregating uh a single auction into many auctions can actually have better social welfare for the end user and that's sort of like an interesting kind of trade-off uh that I think as things like PBS get developed you have to sort of analyze these types of incentives um so you know I uh I think I want to just at least impress upon people that theoretical foundations for Mev are really important and I think we've sort of started with this thing as this like emergent unstudied phenomena we sort of backed our way into some mechanisms for like you know doing an auction coming up with sort of rough reputation scores which you know it's not totally clear exactly how that whole system can be analyzed uh to a point where we actually are really able to start thinking about okay how do we optimize for things like redistribution how do we optimize for social welfare how do we optimize for validator Revenue in a sort of joint manner and formalism uh I think it provides us this way of finding these truths about Mev where which show that hey it's not always robbing granny isn't metamask and the interesting thing is I think people you know this is sort of the beginning of this kind of new branch in my mind of algorithmic Game Theory where you're really focused on the joint optimization of social welfare and revenue because both of them are extremely important to network survival in cryptocurrencies and so I I want to leave you with some open problems in case anyone kind of is is interested in this type of stuff uh the first thing is what's a notion of optimality for an auction right right now if you look at flashbots it's sort of a first price auction with some filtering because they use a scoring function that removes some public mempool transactions is that optimal does that work when you have multiple chains or multiple this sort of hierarchical system um also does it does it sort of uh deal with uh some of the problems of hey how do I trust the auctioneer right now we have a system where everyone basically trusts the auctioneer and you know economists have copied cryptocurrency enthusiasts and made some trilemmas recently on proving things about when auctions uh when you when you when and when you can't trust an Auctioneer and a lot of that work you know I think if the right people were focused on it could really determine how PBS functions as an auction and what sort of like the expected properties of it are on the other hand there's sort of some notion of lower bounds like in an open permissionless system with a certain notion of value there sort of has to be some lower bound to the amount that's extracted because within without any extraction it's very hard to imagine validators being able to to continue to sustain the network and so one question is how do you construct those lower bounds you know in information Theory and in theoretical computer science the lower bounds are extremely hard upper bounds are always easy lower bounds are are really sort of some of the hardest kind of things to show and I think the Mev space of lower balances is still quite open I think you know in in spite of kind of there being some a camp of some people who believe with sort of fair ordering that there exists no such lower bound I I would I would argue I would argue just proving that the lower bound's not zero is already a quite difficult problem though you know be worth solving and the last thing that's a very big uh open problem research-wise in Mev is this concept of aggregation versus disaggregation effects and so I think a lot of people in in the Mev parlance we'll focus on talking about things like private order flow order flow aggregation like what happens when a builder has all of a certain type of order flow I there there are ways to to talk about what the equilibria of the system are what's the distribution of Revenue to different participants uh uh based on these kind of aggregation versus disaggregation effects but if I were to kind of give you the stylized version of what this question is asking and saying what is the coast theorem for Mev so cos theorem for for for for those who don't know is sort of a a very famous thing that I think basically says imagine you have a company now suppose the company had everyone at the company as an individual contractor why is it more inefficient why is it more efficient to actually organize as a group versus individual contractors who are giving payments to each other and the coast theorem sort of says there's some equilibria in the Middle where there's aggregation effects where it's cheaper for people to work together and share common infrastructure up to some point and then after that point the overhead of managing that many people starts causing you to to lower your welfare and this notion of aggregation versus disaggregation and Mev is is completely unsolved yet people are always talking about it it's it's kind of implied in people's language yet yet not formalized cool and so that with that I'll leave you for questions and also yeah launch or something today audio check there we go thank you uh do you have any questions for tarun if so please raise your hand we'll get you a mic we got one question on this side we'll get to you in a second got another question at the back just stay patient on this side so the one in the middle awesome hi uh so my question is you gave an example of uh you gave personal theoretical example of how uh removing an edge from a network can make traffic more efficient and then you give an anology for how this can also happen with amms and you gave a practical example of how it could happen with amms but I I did not understand how this practical example works so could could you explain more like how could mov improve the efficiency of trading on this scenario with three two pairs yeah so so think of it this way imagine that there's uh people who want to trade from token a token B and there's an order flow of n orders from A to B uh if I look at how to optimally route the orders from A to B um if everyone gets routed on the same route the price that everyone pays on average could be a lot higher right if everyone gets routed on different routes throughout the network you could have sort of your your load balancing what the price impact is and the point is that the Mev Searchers are sort of acting in some weird capacity is almost like air traffic controllers when there's a bunch of traffic going on the same route it increases the Mev profit but as the Mev profit goes up then people start routing away from that and you could effectively think of it as a way of sort of having a decentralized coordinator where where it comes from the fact that the more traffic going on on Route the more the sandwich profit but then once people start realizing the sandwich profit they route elsewhere and so this routing problem is actually you know the quintessential example of uh these cases where congestion sort of you can you can add in some sort of like incentives to avoid congestion and and you know a lot of internet routing traffic routing on the internet a lot of that kind of work is like where this initially started and this is sort of making an analog of that here but the key is that someone is getting a worse price by being sandwiched there's no doubt but everyone going across the graph is getting a better price on average and that that's the social welfare versus Revenue trade-off if that makes sense awesome we have another question at the back hello uh good afternoon I love the presentation as usual my question is have you made any studies around uh Central Bank digital currencies or even Fiat currencies using the same Theory yeah I mean I think the hard part with any of these sort of like pseudo centralized Federated type of things is well I I mean the validator should can just always do that movie themselves right like the limit of of the centralized thing is like well what does Facebook what are Facebook and Google doing they're just doing Mev on their own auctions right they're constructing the bidding strategies for you they're like we're using the highest machine learning to give you optimal like targeting it's like it actually means actually we're just going to front run you in our auction but it's too complicated to explain how so in the centralized World these types of things are not that interesting to analyze from that perspective in the sense that the centralized coordinator will just like choose the most expensive route for you all the time right but in the decentralized world it's actually quite interesting because the user has to choose their own way uh through the network um so yeah that that sort of great well one last question on that side and we'll move on to the next talk so please go ahead yeah hi I'm following up on the first question in the brass example the conditions under which the routing would actually or in which Mev would be beneficial is and if you can teleport right these conditions are usually not met what are the you said under certain conditions this applies for MMS what are those conditions does it mean if I can trade you know if I can print free money or trade at unlimited or zero exchange rate or what are the conditions in which no yeah actually that's a good point so so the the zero uh is in the traffic example in the amm example you can never have zero effectively in that Edge there's always some amount of liquidity uh price impact unless it's like you know a linear amm I I think I think the main thing we showed is that the liquidity difference on certain edges on that graph relative to the center edge has to be large so it's not necessarily that it's saying that hey you're teleporting or it's like you're you're you have some sort of like non-balanced budget Condition it's actually just that the liquidity relative liquidity differences on different edges has to be high and that those are the conditions and you know I'd say our proof is pretty pessimistic in our conditions and there definitely were ways of like getting much better bounds on it um yeah awesome thank you so much please give a big round of applause for tarun [Applause] next up we have our speaker anscar and he's going to be talking about how do we scale blockchains especially from a roll-up Centric Viewpoint so without further Ado please welcome on scar on stage Clickers hello everyone um yeah my name is anska I'm going to talk a bit about scaling but I want to start first just with a very quick apology in case you were here to hear about multi-dimensional resource pricing uh I had a bit of a hard time to make up my mind which of the two talks I wanted to give so for a while on the website both titles were on there so if you're really into multimeter resource pricing which you should be I can only recommend I gave a talk earlier this year about it in the ethereum context which um is quite interesting I think and then also with eip4844 we are about to introduce a there's an open PR to to update the fee Market there and hopefully fingers crossed this will be the very first time that we start moving to multi-dimensional Resource pricing in practice on ethereum like in this case two-dimensional so do have a look um but today here I'll talk about scaling and specifically um um Roll-Ups why Roll-Ups um first one I want to talk more more in on the theoretical side why really is a roll up so fundamental to scaling and then um bring it back and and talk about ethereum's uh future place in that world basically um so first why why roll ups um uh and and I want to start by uh with something that I call execution chains it's basically just blockchains as you know them so uh Bitcoin of course was the very first ever um special purpose um execution chain uh special purpose just because it's only for payments and and money uh ethereum the very first general purpose execution chain in general uh all these chains of course they want to have maximum functionality maximum throughput um but that that's attention with needing to guarantee security and decentralization and and to illustrate that kind of the tension um I created this little panel of graph so basically uh on the on the x-axis you have the cost to run a full node and on the y-axis you have the the throughput that your network can have um and with Bitcoin and ethereum basically uh you own this nice Zone where they're down there where basically everyone wants to can run their own chain locally I don't run my own Bitcoin chain right okay okay so there's Bitcoin but I could it's just a trust trade-off that I'm I choose to make um but that does mean that these chains are fundamentally Limited in throughput right by by uh basically the minimum consumer Hardware capabilities and and kind of the key Insight here really is that like everyone validating everyone's transaction doesn't scale but of course we we don't want to give up you know security by by kind of moving beyond this so like the very first thing you could do and I I picked Salon just as an example and this is not meant as a slide at all actually I think uh in a second you'll kind of see how in a way they're kind of moving in an interesting Direction here but but basically what they're doing what their version of scaling is just to basically go further up this diagonal um and that does give you higher throughput but of course it means that now running a full node is it becomes really expensive so that's one way of just increasing a throughput the problem is what if you don't run your own full node and there's some sort of disagreement right some some malicious attack some some chain Fork uh you only have two choices either you go with a majority in which case 51 of the network can always rewrite all the rules take away your money everything right all the other the other thing you can of course do is how Halt and recover via the social layer but that's um very slow of course so where do we want to end up on that graph that's basically this what I call the Unicorn Zone up there where everyone could you know trustlessly validate the network but we still have like really high throughput um so how how can we basically find a way to to to get there um and and that's basically where roll ups come in and why do Roll-Ups come in there um to explain that as you might be aware you probably are aware there are like two different flavors of roll ups optimistic and ZK Roll-Ups they're easier to explain in this context is optimistic rollups so uh to talk basically to to kind of get any tuition for for how optimistic will have solve this this kind of this dilemma here and we can look look again at the at the Savannah case and as I was talking about right if if there's a disagreement and even if you don't run your own full node you always have the of the option to just Halt and recover by the social layer and the optimistic roll-up kind of idea here is what if we could just massively speed that up right instead of running that kind of um this this fallback mechanism on human brains where whenever something goes wrong you have to actually go on Twitter and whatnot what if we basically just automate that right like we replace the human brain with uh with software and in particular with fraud proofs and and um and that's how you how you get optimistic growth so kind of trying to keep with my little picture some symbolism so so their optimistic groups are also basically a form of an execution chain they are their own blockchains basically um the way they work is that they apply the changes optimistically um and anyone can submit a fraud proof uh so so the only basically the only guarantee you need is that there's someone in the system that notices if something goes wrong but one of and honesty assumption is a way way way less severe restriction than a majority honesty assumption um and then these products they are automatically resolved on some sort of settlement platform um yeah that you need and then the alternative as I was saying ZK Roll-Ups they are just cryptographic magic right so in that case you don't have to to to do this retractive fixing of problems instead you just have any state update come with a cryptographic proof that no one did anything wrong and again you need some sort of settlement platform um where you can where you can resolve this um one more little caveat here is that um basically with Roll-Ups we're moving away from this world where like everyone needs to run their own like full node to ensure Integrity right like I could basically only follow the settlement chain um and still basically have all the guarantees about the roll up um but one additional uh thing to ensure is that we have to also pay attention to data if you're on your own full node for a chain data is implied right because you actually download all the data and execute it locally but to throw ups you don't do that anymore so now we basically need explicit data availability mechanisms um and and that's what I put this little kind of database symbol there um yeah and and with that basically once you have you have like an explicit settlement system and you have an explicit data availability system now basically you you can break out of this of this kind of graph of of um of this um full node uh versus throughput um uh basically trade-off and uh and how can you actually use this now to kind of to build blockchain systems um that's kind of what the what the second part is about like how how do you actually turn this into into something useful um and this is going to be very picture heavy because I kind of I don't know for me it's mostly about giving good intuitions here um for like I don't know my mental models around this basically that was that was my motivation for the talk um so again this is like an execution chain I drew a little box around it it's basically in its own box there it has its own security um and that's that's the world as it used to be the blockchain world we had a lot of these boxes like a couple years ago right and now we're adding these exciting new tools um to the picture we are we're adding settlement and we're adding data availability um and how do they basically change the picture well first we kind of have to bundle them in some like we have to kind of put them into some useful form the way we like to think about it is bundling them into what we call a settlement chain which is its own blockchain there you can see it has its own security and it's not the only way to do to do this like if you for example know Celestia which is a really really interesting other um kind of project that that basically works with similar kind of models um they keep data and settlement separate um but for us the the way ethereum kind of likes to approach these things is by combining them into into a settlement chain so now so now we have these these two separate chains how do we basically now actually make use of them well the way to do this is by and this is what the arrows are for by basically having turning the execution chain into a roll up um it kind of functions as it did before but now it uses this the settlement chain for for for data availability and for um settlements so you need some sort of fraud-proofing mechanism or it needs some validity proofs attached but other than that it still feels like a normal blockchain basically and the simplest way to do this is what what we call like an in trying roll up so in that case you'd have like one settlement chain and one roll up on top and it's basically like like a one one to one um a relationship and and a very simple way you could imagine basically this process playing out in the blockchain world is um and I guess that fits well into this kind of the multi-chain vision would be where every every blockchain that wants to basically go hyper scaling and just adds their own little settlement chain um underneath them um and that would basically bring you to this to this picture um with multiple different uh blockchains um they are that would all now have their own settlement chain the the downside there is um that uh for one you have fractured security right each each settlement chain has its own valid data set or its own miners or its own however you you get your security as your as your chain um and it basically some some of those will be higher security some will be lower security and that also affects Bridges uh I'm maybe some of you have seen kind of metallics right up a while ago about how basically if you bridge multiple chains you always end up with the the weaker secure the weakest security of all of them right if you basically if you want to add use assets of like 10 different chains if the security of one of those breaks like that specific asset just basically is is broken for you right and if you have some sort of defense system where all of this is interconnected basically everything Can Crash and Burn um you really don't want this minimum the worst of all security kind of situations and also I guess that's less less of a severe thing but also in this picture you're kind of duplicating a lot of complexity um for each chain so what would be an alternative Vision how do we think the future might look like uh that's what we what we call like a shared a settlement chain so in this case you have one big settlement chain and you can have multiple Roll-Ups on top of course in probably realistically the future will look some sort like some sort of hybrid you'll still have some blockchains that's preferred to do their own settlement chain but but we predict that like this will be a big chunk of it basically like a shared settlement chain and why is that advantageous um well two main points really um one is the shared security um I like to think about it like shared pool security it's not quite free security sometimes you hear people talk about how if you if you turn your chain into a roll up you just get the the security of the base chain for free and that's not quite right I think because actually if uh you say you have 10 Roll-Ups on top of a settlement chain then they basically all put additional strain on top of that settlement chain right like now the incentive to take the settlement chain is 10x as high so you you don't just get like security doesn't just you know isn't just created for free um but it it is pooled right so so now basically you have to break the entire combined system instead of just being able to take the weakest link and what that also gives you is then because you have like one shared trust um um once you had I don't know a trust Zone basically that all the bridges between those roll ups if implemented perfectly you know important caveat um it can can be can be fully secure [Music] um okay so with that kind of bringing it back to X to ethereum of course I guess the last slide they're heavily hinted to where we want to end up with at but where where were we in the past where are we today and how how could we get to this shared settlement layer future so kind of starting with ethereum a few years ago uh in the early days basically ethereum also was a pure execution chain we had approved work security robs weren't yet a thing that was kind of a happy place to be in for for a couple of years um at some point of course like ethereum always wanted to figure out like how do we actually scale to billions of users uh it took quite a while quite a few years of iteration in the iterations just because I like kind of research archeology and I would encourage you if you ever have some free time and nothing else to do uh go look at all research posts it's always fun so to basically just illustrate that a little bit I've like picked like three that kind of accompanied our way kind of towards this this lower Vision the first one is if you look April 2019 uh it it's it's really quite amazing kcd Trio phase one and done it's two as a data availability engine nowadays I think these this technology like everyone would just nod and be like yeah sure Bank starting but three and a half years ago I think there was quite visionary um then uh a year later a year and a half later we had vitalik for the first time confusing this term roll-up Centric roadmap where basically we we finally realized that yes there is no other way to scale like you really need this decoupling of the execution in the settlement otherwise like you you basically as I was saying earlier right you can't break out of this dilemma so so we really like Roll-Ups are the way to go here um and then just uh third is the uh upon little one um that uh my colleague Matt um uh wrote a couple weeks after vitalik's post and looking back at our early these two plans and it actually turns out that uh basically this if you remember the early charting plans um if I just go back a couple slides if this works uh actually what we what we were planning back back in the day with all these different charts was kind of this picture all along right it was just that we wanted to have all these charts be like super enshrined and and at some point in trying to roll ups basically and then someone we realized it's just much better if we open this up for for General Innovation if we if we don't build or basically if we are the only parties building Roll-Ups um and so yeah this this basically just you know it's a little history kind of tidbit so so this is kind of how we how we got to where we wanted to move move forward with ethereum so that kind of brings as to to the kind of the pre-merge state where we already started to use the ethereum chain as a as a settlement chain as well but of course it still has execution so it's like kind of like a hybrid chain it's still proof of work security of course before the merge uh and as I was saying right settlement chains need the settlement aspect which you kind of get for free when you have a general purpose chain but then you also need data availability and data availability on the existing ethereum chain is really quite expensive it was never meant to provide data availability so what it's kind of basically right now kind of hacked in you just basically just dump data into into ethereum transactions and then never actually use them um which works but but it's just very very um expensive as a source of data availability of course we started having rollups on top um really exciting if you ask me I think Roll-Ups have been making a lot of progress over the last two years um and then you know pre-match we had this the speaking chain just an empty little box nothing in it and but much stronger proof of proof stake security right and then of course um as of today we ended up you know merging and now we have have this uh basically same same situations before but but much much higher security um and just as a maybe quick aside I I think I have the time for that uh why does proof of stake actually give higher security I always I mean it's not really kind of part of my talk but just because I always see a little bit confusion about that debate on Twitter and I think it's it's really quite quite simple actually like um the the way I would think about like moving from working to proof of stake in terms of security one it's just more efficient right and that is because you don't you basically with mining you actually have to pay for the entire cost of the operation you have to reimburse minus for both the mining hardware and the energy right like they have to make all of that up with the income whereas improve of stake you only have to make up the lost interest on your money so basically you can get away with with paying way if your rewards for the for the same security uh in in improve stake um and then the other one it is also that proof State security is just fundamentally more effective so that means that if ever there were to be a failure which of course hopefully there will never be but if they ever were to be like an attack or something um the attack is it attributable and so you can you can just you can go in and selectively punish people improve work once someone like an attacker has 51 of the resources you basically just you know your change just lost nothing nothing to be done improve stake it's really not big deal actually right it's a little bit annoying for maybe day and then afterwards you're just done with it and so so that's really really neat I think and then also like I couldn't quite help myself um maybe this one esoteric maybe but um another interesting mechanism in terms of security that I really like is this um ultrasound uh money one where basically the idea is when you have an uh normal mining rewards that means that we have uh as the asset has just much improved monetary properties uh which in the long run might you know might or might not turn into a higher expected monetary premium higher total eth market cap and we can just buy more Security in absolute terms but again you know this is esoteric totally fine if you don't buy into this that the first bullet point is the more important one here um okay so this is ethereum today uh where do we want to go how do we actually get to this full you know shared settlement chain uh how do we get full data availability all of that kind of thing so first thing is next year hopefully a fingers crossed looking good I have to say prototype charting erp4844 that we've been really actively working on just earlier today there was there was a session on this um we're basically uh we I don't know if you saw that but like the data pick the data symbol there just become became way bigger because you just you know you you add better data availability uh to the ethereum chain for the first time data available is an explicit service we provide it's not just something tucked on but it's an explicit service and so it's just more effective um and then of course uh you've you've probably all heard about that tongue sharding soon TM afterwards uh that could be two years from now hopefully like maybe maybe it'll be three years but but soon um and that's really where we get like Ultra scalable data um and and and with that we will be for the basically we'll be able to to um to host multiple of these really high throughput Roll-Ups so this is kind of in terms of scalability this is really the end game um that that we as ethereum basically are are aiming for um and it's basically kind of with those pictures in mind I kind of wanted to then further for the last last part talk a little bit about where does this leave us like this I I hope that kind of gave like intuition wise like a good idea of where we're moving and why but but what implications does that have so the first first thing I wanted to briefly talk about what does it mean for the existing well each one we used to call it it's one chain like basically what now is just the execution chain with within the beacon chain what's the future of that and um they are basically multiple different um potential future Visions for it that you could you could you could see the first one would be that it basically stays this hybrid execution settlement chain or the roll up settle on top of it but also still you know it has some default on it whatever for high value transaction it can still be used as an execution chain so that would be kind of the default case um then we we could we could have the scenario where it really turns over time one more primarily into a pure settlement chain so that means that really more and more of the user activity migrates layer twos and and layer one is really just becoming more just a just a robot management layer and then the third one it's more like a fun thought experiment it's not really kind of planned or anything but just wanted to kind of illustrate how this modular architecture is really lends itself to to all these these different different ideas what we could also do is that we could uh basically add in an additional separate set of pure settlement chain to to the beacon chain and turn is one basically into a well you would say you could say a roll up right so in this case if you if you look at that picture you could just think of you know like one of those roll ups being it one so that's again I don't I don't think that's likely that that we'll go that way but you know it would be almost I don't want to say trivially but it would be very feasible to to go that route because we now live in this in this in this modular World um the other one I briefly want to talk about was the the future of the evm so um first I I do want to say it is by no means certain that kind of the future of high throughput execution chains will be VM based right I think ethereum is the settlement layer will will always use the evm I think it's just good enough for that and but it's it's not not yet decided like it could be that you know I don't know Solana or something has the Deep dominant uh winning highly scalable uh VM um solution it could could be could be the evm it could be some some of these other competing um new ones this is yet to be seen I mean we are very optimistic for the evm in in in that um scenario as well and I think I do want to point out um because that sometimes misunderstood uh the the reason why ethereum only has the limited to put it has is not the evm that's not the limiting factor it's really that we want to keep the resource requirements for validators low the mom the moment you are a roll up and you adopt the evm you can still go far beyond the throughput constraints of the base layer and so and there are many possible evm improvements that we just never bothered to do on the base layer because that is not relevant for us but that layer twos are very actively looking into it so I think there's a very good chance that the evm will turn out to be to be like the winning or one of the evening High throughput VMS um yeah and and but but of course uh whether like like the the outcome of all of this process will have like big implications that clients will clients basically say the existing evm clients will they be primarily settlement clients only or will they also be used for Roll-Ups at some point maybe they'll want to focus on Roll-Ups even um how does that look like for programming languages for the evm uh whatever tooling all these kind of things right um so I think this is this is going to be like one of the the main interesting kind of technological debates of the next five years um and in particular I wanted to briefly very briefly talk about evm equivalence because that's just a topic that I I personally am really interested in so for these layer two layer Twos for these Roll-Ups that choose to go with the evm and the question is do they go with the the the exact evm or do they just go with something that looks kind of like pvm right and if you remember say optimism for example they started out with what they called the optimism optimism virtual machine or something ovm which was basically an Adaptive version of the evm and now they're back at using basically the EVMS is so the question is in the long run what what is the way to go should you go with evm equivalents or not and so just briefly basically the pros that I see would be of course um standardization right like if if you use the evm just all the tooling works out of the box you have multiple existing client implementations which again for security having multiple clients is just really really helpful but also really hard to achieve so this is like a big win you can you can get with evm equivalence um this the the third one is a bit more speculative but we could definitely imagine in the future that we have some sort of specialized settlement um functionality around EV the evm that that we offer for Roll-Ups of course that would not be mandatory right if you want to run your own like fuel or Solana or something on top of ethereum you can do that as well but we would have special uh special special support for for these evm based ones and one really interesting one especially I think in the last few months people have more noticed how governments can really be a liability um and if you actually follow the evm as is you can just defer to to layer one um governance and follow their changes basically and then what are the what are the cons um um why might you not want that well of course one it's just like if you if you're if you're stuck with the layer one evm that does come at a cost of slightly slower iteration speed right we have to really vet every change that goes into the VM quite severely to make sure nothing ever breaks um you might just need some layer two specific functionality it's just harder to add that um if you really don't want to you know kind of mess with with the evm um and also and I feel like that's the one that's the most relevant in the context of my talk here if we expect layer 1 and layer 2 really operate at quite different scales in terms of throughput maybe having identical VMS it's just not the the ideal way to to to to to to go and just as like a potential compromise here or having the Best of Both Worlds idea to that I want to leave you with here is uh one that I think might actually be quite exciting to explore in the future um what if we could maybe get the Best of Both Worlds by having a dedicated version of the evm specs for layer twos that's still standardized across all the rollups that want you know to opt in um but is is able to over time depart from layer one and really focus on on optimize for the layer 2K so I think there's a good chance that we might end up in that world and and I think that that might actually you know be the be the best way to get us to to high scalability um and yeah and I think I hope if I remember correctly oh I do have a summary slide so uh let me briefly go through that but then then we're done so you know traditional uh blockchains you always have the trade-off between security and scalability uh Rob solve this ethereum's Vision we want to become the primary settlement chain um we're still at the very beginning of this transformation um ethereum well likely this this is the last point I I had the likely because who knows right but we we do still with the evm also have Ambitions for for execution chains we do not just want to be to be a settlement chain yeah and with that um thanks amazing thank you uh we may have time for just one quick question Stephanie is a quick question please raise your hand if not we will move on to our next talk any quick ones going once twice three and we're done please give Ansgar a big round of applause [Applause] all right next up I'd like to invite Nick Johnson to talk about the state of ens you may all know Nick as nick.if so without further Ado please welcome Nick to talk about everything that's happening in the world of the ens ecosystem please hello how is everyone uh I'm Nick Johnson founder of ens and lead developer and I'm here to give you an update on what's happened with enes in the last three years which is give or take 300 years in crypto um before I actually start can anyone who's got an ens card hold it up above their head wonderful probably about half of you I'm so delighted with how everyone's been doing with this if the person next to you held a card up have a word with them say hi tap your phone to their card and you'll get a poab that proves that you visit uh that you met them at devcom uh we still have a few of these cards left at our booth on level three uh so after the event come down we'll print one for you with your ens name and your ens avatar on it we expect we'll run out sometime this evening so I'm sorry if we don't get to everyone um but this is a great opportunity to meet the person next to you and have cryptographic proof of that afterwards so uh first off the agenda uh I'm going to recap everything we've done in the last three years and then go on to talk about what we're working on now and what we're working on next uh first of all in the next category uh Thorin which is ens's New Look and design system and new app second of all talking about scaling ens with off-chain reads and writes next the name wrapper which you may have heard about is a way to improve the functionality of igneous names and the ability to issue trustless subdomains finally zero gas DNS integration how we can use these other components we've built to make ens integration possible for DNS names without any guest fees and then the conclusion so first of all the recap it's been a long long time since I've been at a conference since I've talked on a stage in front of a lot of people uh since I've given anyone an update on ens last time I spoke was at last Devcon October 2019 uh we're just transitioned from the interim uh auction registrar to the permanent registrar featuring its current renewal model and that was a mere five months ago and while it was doing well at the time we had very little idea of the phenomenon ens was going to be coming in the next few years we had about 50 Integrations with various wallets including metamask applications such as etherscan and so forth that's changed a bit in the last three years our set of Integrations now looks more like this laughs so as you can see we've come a long way from under 50 Integrations to over 500 we had about 300 000 registrations back in the day that's now over two and a half million uh we had about 96 000 ethereum addresses that had interacted with ens in some way that's now over a million addresses um 66 700 years of registration had been purchased that's now over six and a half million uh if you Strang them all into end figuratively uh and the nascent EMS treasury had a stunning 382 ethernet at the time that's now 38 000 eth and I'll talk soon about the Dow and how it's able to put that to use [Applause] of course it's not all about the numbers ens has accomplished a lot on both Technical and governance fronts in the past three years uh some of it will seem like old news but it's been a long time uh at divcon 5 we had limited DNS integration with only the dot xyztld supported you could take a neonessner sorry.e XYZ name you could import it into ens and use it just like you would any dot ethname since then this has been expanded to nearly every top level domain uh that supports DNS SEC so that's nearly 90 of all top level domains uh nearly any name can now be imported into enes and used as a native name uh just ask our developer Advocate Loop dot computer it's printed on as badge I believe um there are transaction fees associated with importing any of these names and at times when gas prices have been very high and The Ether price has been very high it's been quite pricey but we've got a plan to improve massively which I'll talk about shortly another major Improvement has been ens's transition away from being just a way to name wallets and decentralized content to being a web 3 native identity platform with the introduction of Avatar records and text fields that provide information about your profiles such as your Twitter handle your email address your ens name now represents you as your web3 identity it's a universal portable identity and one project that's been bringing that to more users is sign in with ethereum it started out as an RFP issued by ens and it was funded by a joint Grant from ens and the ethereum foundation Spruce won the bid for that and has done an outstanding job of growing it into the primary way that people authenticate with ethereum replacing a plethora of incompatible and different standards for signing messages to assert your identity with a symbol system that can be thank you uh that can be um easily plugged into existing systems including web 2 Legacy systems but of course when I talk about the last three years and particularly the last year top of most people's minds will be the launch of the ens Dow which is now one of the largest and most active dowels in web3 which I am absolutely both Blown Away about ens has always aimed for gradual decentralization starting with the minimum set of emissions held by the widest number of people we could which was the original four of seven multisig unlike most multi-sequencies it included participants from around the ecosystem not team members and they had limited powers to upgrade enes to replace components our goal was always to move from that to a system where ens was governed by a decentralized organization since we launched all the way back in 2017 the only example we had to go on was the DOW which needless to say was not a stunning success that inspired us to immediately decentralize but things changed a lot and the Dow space is now a lot more mature than it was in the past and we decided that you know the time had come that things were mature enough that we could let the ens Community govern ens and the Dow is the major Milestone along that path of gradual decentralization the Dow was now responsible for almost all governance leaders and controls available to ens including approving contract upgrades changes to core parameters such as pricing and how expired names are used it's also responsible for treasury grants and projects using the funding gathered from the protocol in the years since the Dow's launch the unes Dow has shown that it can maintain a high level of civilized discussion made useful progress forward in improving the protocol besides budgeting and day-to-day bookkeeping it's made meaningful changes to the protocol including changing how expired names are handled in order to safeguard the stability and fairness of the system the Dow has also started to build out public goods and grants programs of its own uh one example of this is the small grants rounds that we now run inspired by nouns uh props room this is a regular system where anyone can submit a proposal for work they want to do or work they have done anyone with ens tokens from the Dow can vote on them and the top five in each category we have a public goods category and an ecosystem category then receive one e feature and funding to pursue it the public goods is focused on anything in the wider ens ecosystem and the ecosystem category is focused more on things that relate directly to ens and we hope this can work to better incubate and start up new projects both for ensn for The Wider public goods on ethereum and web3 ecosystem working groups have also funded initiatives on scale small to large ranging from a 200 000 k Sorry 200k ens token Grant to the protocol Guild who are formed to help fund core developers throughout the platform uh 169k Bitcoin matching pool and we continue to fund and support Bitcoin and smaller projects such as this plugin for discourse forums which provides you with insight into the roles of delegates and their participation on the Forum which is something that any dowel that uses discourse can take and plug into their own system uh this was built by Karma and integrates with all their stuff you can also just use it to provide insight into how your delegates are voted how active they are how many tokens they have and so forth the Dow has also resulted in more Community participation in the core protocol uh one major success story is rafi's work on improving ans's normalization functions normalization is how we handle names like uppercase neck being different from lowercase neck and ambiguous emojis hidden characters and so forth to start we used a well-tested system called uts-46 which is what the domain World uses but it's become clear over time that ens has some unique requirements and we wanted to enable things such as emoji and other characters that are popular in the community but not supported directly by DNS uh so refi has been working on harmonizing all of this we're very close to rolling out their new standard for Dow approval and it will enable a much wider array of characters while also providing more protections against deceptive names the last three years has also seen an explosion in community-led ens initiatives uh independent projects that build on top of the ens ecosystem one popular example you may have seen is the ens leaderboard which shows people with Twitter handles that contain Dot eth and they're ranking relative to followers we've had some pretty popular ones including Paris Hilton for instance right up the top of the leaderboard I myself am now ranked I don't know number 400 or something um we've uh had the launch of ens Vision which is a third-party ens trading Market allows people to now register names from scratch and also trade existing names and projects such as nimi which is a web 3 profile site it leads you generate a customized profile and in fact the eth.limo Gateway folks have integrated with nimi so if you have an ens name that doesn't have content set up it will automatically show your profile with your perhaps and so forth and you can customize it as you wish uh before we start talking about what's new one small announcement true names limited is the name of the development company that builds enes the company I founded that gets paid by the Dow employees about dozen of us to build our ens when we formed it we didn't really think of it as a name that would be visible to people that was purely an internal thing but in the intervening time it's become more and more visible and every time we have to say we're from True names limited the company that develops ens and it gets a bit tiresome so we're renaming to ens Labs limited to better reflect what we do and Who We Are uh so what's next uh first we're going to talk about Thorin Thorin is ens's new design system and it's built from the ground up with usability and web3 in mind we've used it to completely rewrite the ens app from the ground up coupled with improvements to the smart contracts behind DNS this enables a huge Improvement in usability for ens users the ens UI faces kind of a unique Challenge from amongst web3 apps and in fact kind of apps in general in that it needs to provide an interface that is both easy and user friendly for new users but has the advanced levers and and sophisticated interaction required by Advanced users we don't want to create a situation where the app is sufficiently flexible to do anything with ens but deters existing users which is a little bit the case in the current APP or is so straightforward and wizard-based that you need to go somewhere else if you do have more than basic needs by surfacing the important details and flows while still making Advanced functionality available under the covers the front-end team have done an outstanding job of writing an app that is all for all users aside from the functional improvements we've hugely improved the loading times and made the new app 100 mobile friendly the new app is at feature parity and live now on the girly test net would be live on robston but that's already been deprecated and you can try it out now at alpha.eds domains just to emphasize it's only on Gurley it is a little bit you know sharp edges still the team really raced to get it out in time and did an amazing job please send us your bug reports but we aim to have this launch on Main net shortly after Devcon once the name wrapper and other contracts are approved by the Dow as I'll discuss shortly so keep your eyes peeled Thorin isn't just for ens either we've made it available as a standard react library that anyone can use for their web3 apps you can check it out on sauron.ens domains and you may have noticed it powering a number of our other sites such as the swag microsite and so forth one of our major ongoing projects is scaling ens for many projects this is accomplished by going multi-chain deploying to just multiple chains if you're uniswap for instance you fragment your liquidity a bit but you can work in parallel across multiple chains ens is in kind of a unique position here we need to maintain a single cohesive registry of names and it's far too early in the L2 and the roll up ecosystem to pick a single Service as the winner that we're going to migrate to instead we've been pursuing options that make it possible for people to host their ens names anywhere without the resolving having to know or care where that is earlier this year we launched ccip read as a collaboration between ens and chain link while previous systems such as bridging often introduced new trust assumptions and require L1 transactions to execute ccip read uses a lower level primitive proofs which means that in many cases such as with l2s this can be done with no additional trust assumptions over those the L2 itself requires meaning you could host your ens name on optimism have users resolve it from any client that doesn't know what optimism is without introducing any additional trust that relies on the Gateway operator for instance further the solutions far more flexible than bridging allowing data to be stored not just on l2s or side chains but on arbitrary systems including centralized databases at its core DNS is a way for any contracts to fetch data from off-chain resources because contracts can't directly talk HTTP requests this ends up being a little bit like having one of those conversations with a couple who have had a fight and are refusing to talk to each other well you tell the Gateway that I think that they should give you this data I need so the conversation tends to go like that unfortunately just ask them yourself isn't an option so the client has no choice but to play middleman the end result is good with the resolver and the Gateway agreeing on a protocol it's possible for the client to facilitate a lookup of off-chain data without any knowledge of what their shared languages or what the off-chain system in uses uh the necessary proofs to make this trustless are encapsulated in the response sent by the Gateway and verified by the resolver before returning the result from the name resolution this means that implementing the base protocol is enough to enable all current and future l2s and off-chain storage systems to be used in the NS name resolution for instance ethers already supports this which means that you can resolve any ens name that uses it even if it uses an L2 that didn't exist when the ether's implementation was written and ccip readers already in use in production both ethers and Webster ejs support it and so if you use either of those libraries or in fact as of I believe today web3.pi upgrading to the latest version will mean you automatically support ens of chain resolution some of the largest apps and wallets have already upgraded to support it too including metabase metamask coinbase wallet as well as ethereum etherscan there's a long way to go in terms of making this latest change Universal so please reach out to your favorite wallets and apps if you see that they don't support these new names and ask them to let them know how important it is uh like our Thorin ccip reader also isn't just for ens it can be used to add off-chain resolution support to any project coinbase has gone a step further than just integrating ccip read for name resolution they're using ccip read ens wildcard support and ens's DNS integration together to allow their wallet their wallet users to create ens names under the dot cb.id domain for free these names will instantly work in any wallet or dap that supports ens's new resolution improvements and they have no transaction fees to set up for either users or coinbase likewise lens is using ccip read to integrate their own dot lens naming system with ens any.lens name you can add dot X sorry dot XYZ to the end and it will resolve in metamask or any other wallet that supports this so off chain read support is great but how do we enable writes the default option for every platform is to provide its own interface for users to update their records meaning if you use coinbase wallets you have to use coinbase to update your records if you use metamask you'd have to update with metamask but this leads to fragmentation and makes general purpose apps like our own manager much less useful fixing this is still a work in progress but Eep 5559 lays out a way forward by enabling a discovery mechanism that allows clients such as our manager to discover how they can send a transaction or an HTTP request to update data that's stored off chain um it's currently supports writing to evm-based l2s or side chains um or sending signed messages to an HTTP API but this is extensible with new methods as they crop up adding support for this to the NS manager and further standardizing the best practices and making it as as flexible and extensible as possible is an active active area of research and development for the team so next up the name wrapper which you've probably heard about of griping about on Twitter because uh it's been underway for a while enes predates all of the nft standards and while the dot eth registrar was written after each 721 came out that functionality only applies to dot e second level domains so nick.heath but not uh wallet.beck.eth or nick.xyz or whatnot as a result not all lioness names can be transferred exchanged Etc using standard nft interfaces uh further one of the main advantages of tradability is trustless ownership if somebody sells you a name or a subdomain or gives it to you you want to make sure that they can't take it back next week and set it to a different address you're kind of reliant on their Goodwill there are solutions to work around this you can give net ownership of the name to a contract and we've had a system for that called now.ns.domains for some time but it has significant shortcomings in that you're committing your name to a specific contract where it has to live for the rest of time which limits what you can do with it the name rapper solves both these problems it allows any ens name at any level whether it's a DOT eth or a subdomain or a DNS name to be wrapped as an ERC 1155 nft it also allows owners of wrapped names to revoke permissions such as the ability to replace or delete subdomains by mechanism we call fuses fuses allow the owner of a name to revoke their own control and that of any subsequent owners over certain functionality on a name such as the ability to unwrap it again to create or to replace subdomains to transfer it to another user and so forth once the fuse is burned that fuse can't be reset until the name expires giving a user's a guarantee as to what can be done to or with their names until the name expiration is reached the name ramp attracts these permissions and provides a very easy API for fetching the set of restrictions currently applied to a name and when they'll expire alongside the name wrapper we've also implemented a suite of other contract improvements including to the dot eth registrar controller the reverse registrar and the public resolver all together these will prevent a much smoother registration process for end users and cut down on the number of transactions and gas required as well as other quality of life improvements like allowing contract owners to set primary names for their contracts the long and short of us is that with the new.eth registrar you will be able to register a name wrap it in order to set permissions burn fuses and set your primary name all in a single transaction and using less gas than doing those operations would cost today uh all of these updates are live now on the girly test net and we're planning to submit them to the Dow for approval on mainnet very shortly after devcom uh thank you finally I'm going to talk about something else I'm excited we'll be able to release soon gasless DNS integration presently claiming a DNS name in ens cost a substantial amount of gas it's about 100K to a million gas per signature it has to verify depending on the ether and gas price that can range anywhere from 20 bucks to at the extremes of the bull market a thousand dollars obviously this isn't a particularly scalable solution and so this can be a substantial barrier to DNS integration fortunately we have a plan for reducing this all the way to zero uh so first a quick overview of how DNS works it uses a chain of trust just like SSL the root zone is signed by a well-known certificate Authority and they sign keys for each of the subdomains such as.com dot link Etc uh each of those zones uses its keys to sign this the subdomains and so on and so forth our current DNS integration uses this to allow users to claim DNS names inside DNS our front end collects up all the complete set of proofs necessary and submits them to a Smart contract which verifies the signatures and if they match it lets them claim the name uh if you've been paying attention to the talk so far this may sound quite familiar to you similar to something else we've discussed ccip read if we treat the whole of ens as a massive off-chain distributed database we can have a Gateway that fetches DNS data collects all the proofs necessary and submits it to the chain just like when you're resolving a name so then we can write a resolver for DNS names that uses that gateway to resolve names in ens entirely using data stored in DNS users can set DNS records to configure their name and they will resolve any from their ens is supported with xero on-chain transactions necessary claiming on chain may still be useful in some cases for example if you need granular control over the subdomains but for most users it'll be possible to claim your DNS name just by setting some text records we're working on this right now the DNS SEC Oracle changes are done and we're working on implementing fixes from an audit before we roll it out we hope you have it ready to go before the end of the year there's been a lot more going on and with ens but compressing four years down into 25 minutes naturally means I have to leave some things out just one more thing the Dow was nearly a year old but still in its infancy we had a lot of a lot to learn and a lot to do and we need your expertise please take a look at our governance page reach out to ens domains on Twitter see how you can get involved and help us build a truly decentralized public good naming for web 3. and that's all I have for you thank you very much awesome do we have any questions for Nick please raise your hand we'll get you a mic there's a lot of things that we talked about yeah we see a hand over there keep your hands raised so we can find you and get the mic to you all the way at the end we're coming from this side almost there sorry that's all time I have questions no I'm kidding hey Nick thanks a lot for the talk um one thing I was thinking about uh you should probably be able to use ens to uh the problem is when you use UI to uh to communicate with a page the metamask will generate you uh it will provide a transaction for you and basically you have no idea like if actually the UI is the right UI and you if you are calling the contract you want to be calling and I guess you could UNS you could do you you could UNS for this for linking both the the domain and the smart contracts with the same ens and have metamask check it basically to provide a lot of attacks connected with the UI yes it's spoofing yeah definitely a better user insight into transactions is I think probably the major adoption barrier and and phishing and so forth fourth issue in web 3 today um naming contracts of the Indians names is one big step towards making that a bit better and in fact the latest contract updates we're pushing out uh make it easier for contracts to get ens primary names um I am also the author of a proposal with Richard Moore on how to better provide insight into transactions which is also very relevant there yeah and could you make uh basically the the calls from the other side meaning um metamask could somehow check with DNS like what what this contract uh is what ens is this contract associated with is and further you could put authorized front-ends on your ens records so that will warn you if you're making a transaction to say uniswap from a scammy site is an excellent idea yeah perfect perfect thanks cool thank you very much awesome we have one last question here to set the front row and uh and we'll be at time oh hi I was wondering if you could kind of give us a state of the union on efforts to resolve Pages via browsers and at the OS level sure uh so at the OS level is depending on you look at it tricky or easy you can run your own DNS resolver in which case you personally get to resolve all units names getting it rolled out to everybody is a very Steep Hill to climb I think we're going to have more success getting this integration to browsers such as Brave and Opera which already supported rather than integrated directly with os's on the other hand there are efforts around talking to Ethiopia about whether they would be willing to relinquish that this is all very nascent however so there's there's nothing concrete for that right now the shorter term solution is as I said browsers I think awesome that's all the time we have please give Nick a big round of applause [Applause] up next we're going to talk about how do we make the best possible experience as we use and scale more blockchains and to talk about that I'd like to bring on Taylor Monahan on stage to talk about the original sin so please give a big round of applause to having Taylor on stage foreign [Music] all right let's do this um for those that don't know I'm Taylor Monahan uh I'm gonna be talking about the original sin basically some of our early choices and how they've shaped this ecosystem and more importantly how can we make better choices so that the world is better tomorrow a little bit about me uh again my name is Taylor Monahan I've been in the space since 2013. I got in right before the mount gox crash I've been building wallets since 2015. I started my ether wallet we then did like a brand Fork into my crypto and we were acquired by metamask earlier this year uh it's been a it's been a ride that's for sure um but I'm basically like an expert in how to like build wallets also how not to build wallets so maybe I can like share some expertise today um so I have a I have a four-year-old now and this is one of our favorite books and it's like quite ironic because uh it's basically the Story of My Life uh when I first started out uh I was just building I was building something amazing and I think a lot of you here are probably in the same boat right you're in the early days you're in the early stages you're building something um inspirational right that's going to change the world it's going to make uh people's lives better it's going to make Society better um and I hope that you're really proud of what you're building right like you you you create something you brought something new into this world um and this space specifically is like truly remarkable it is next level in terms of like what we are actually doing and the impact that our products can have um these are all of the best web three words all of the most amazing things that we can do with the technology in our products and most importantly like I think you know at the end there we have the inclusive community and we have the genius people and the Good Vibes like that's what I'm here for um and that's kind of what I like to focus on most right like when I get on stage I like to talk about people because if we only think about the technology and the products that we're building well you're going to end up in this situation quite a bit because the second that you sort of um I don't know the second year dreams start to come to fruition the second that everything starts to line up and you feel like you might have a grasp on it it really does seem that then out of nowhere everything keeps crashing crashing down because building is really really hard and especially when you're a wallet and uh you know you're the product that people are are using to access and manage all of their digital assets it's really hard things come crashing down a lot and the worst part of failing uh like building a good product is actually like the failing people right we're failing the newcomers that enter the space uh they're getting fished they're getting scammed they're optimistic one day and then they have their hopes and dream crush the next day and that's what basically the last I don't know like seven years of my life have been right like trying to be better every single day trying to help people understand the technology trying to get people to understand how they can use this technology to actually improve people's lives because this is up sometimes as hopeful and as optimistic and lovely and as much as we want to believe that we are building a better world it also means that sometimes you have to face the reality that our world is when we're like this is money this is people's livelihoods this is their financial well-beings this is their families their mortgages their children's colleges and this ecosystem specifically the entire ecosystem from the get-go has really been uh built on top of these public-private key pairs like every single thing that we do traces back to the private key and that private key is just like a single string of characters and it's so important that um I've spent countless hours trying to educate people about the importance of this private key I worked with metamask years ago to rename it now we call it a secret recovery phrase so that we can like hopefully have people understand the importance of it and the secretness of it earlier um but the reality is like the products that I built are responsible for a lot of money getting lost and if we don't get significantly better and make web 3 significantly easier to access in the coming years it means that the products I build and we build are going to be responsible for billions more dollars lost and that's like a hard thing to wrap your brain around it's not super Pleasant uh I would say it's pretty  up and it's been pretty for a while actually this is a comment I made in 2018. uh one of the earliest mistakes I ever made was when we created my ether wallet we didn't really understand why you shouldn't let people enter their private keys in the browser on a website and so we did exactly that you would generate your private key you would enter it on the website and that's how you access all of your money um that was a terrible idea don't do that seriously don't do that uh uh this is this is Dan uh Dan is one of the founders of metamask uh and he has a bit more optimistic take right the way he kind of looks at the world around us and the things that we're building is uh he Praises it as we're basically at the eating poisonous mushrooms phase of product development and we are all just leaping we're taking the leap of faith um hopefully we're coming back and uh you know letting our product creators know like what hurt and what didn't what worked and what didn't and hopefully the people that are building those products are listening to the people who are adventuring out there into the abyss and updating and improving and iterating on all of their products so that uh ultimately it hurts Less in the future because what we are doing is truly like a new paradigm like web3 we are really starting at the ground floor um we are creating entire new systems we're creating new tech systems recruiting new social systems Financial systems everything is brand new unfortunately sometimes these new paradigms just uh you know they come with some struggles and I think one thing that took me years to really comprehend and really grock was the fact that there is such a huge incentive for Bad actors to get your private key to get your secret recovery phrase like it is so huge that um I don't know hundreds of thousands of like random scammers around the world North Korean hackers like literally like nation state actors are trying to get your private keys and we're building the product that houses that thing that has all the people's money that's cool over the years we've seen like an increasing number of scans and Sim swaps and social engineering phishing spear fishing account takeovers web 2 account takers web 3 account takeovers supply chain attacks DNS hijacks bgp hijacks injection attacks and even at the root the cryptography itself we've even screwed that up a couple of times resulting in Keys either being stolen or inaccessible and this incentive is so so so large like I cannot emphasize the traditional world just does not operate like this there's almost nothing in the traditional world where if you lose it like that's game over and there's no like path to recourse like that doesn't exist we have so many layers to protect people uh and in crypto we just don't have those yet and the hardest thing about this is the reality that truly people don't understand that this like this string of characters these like random numbers and letters or these words like if they lose that or if it's stolen it's game over and increasingly especially with this last Bull Run it's not just their eth right it's their tokens it's their nfts it's their Collectibles it's their soul bound tokens it's access to communities and games it's it's everything right it's like basically turning into their identity like we're getting dangerously close to turning that key that that that string character is that nobody really understands into people's identity and I think that we think a lot about education we think a lot about ux we think a lot about the UI we think a lot about the things that we can do to fix it I've given probably like 15 talks covering how you should educate people more and fix your uis and it's had some impact but not enough and the thing is is that the people in this ecosystem are creating real value and they're creating it so quickly that I'm not sure that just like you know updating some copy is going to cut it because again at the end of the day the whole entire ecosystem is relying on these freaking characters right this this string this string that's a private key don't lose it that's you that's your identity and all your money and everything you have in your children's future don't lose it uh it might look like this that's the secret recovery phrase it's it's it's the same right don't lose that either that's everything it's kind of it's kind of absurd like when you really just like cut down to the core of it it's absurd and we have such big brains in the space like truly remarkable Innovation happening every day we talk about Game Theory we talk about incentives we talk about economics we talk about so many different things and yet somehow we haven't really been able to come to the conclusion that like hmm maybe we should focus for a second on how do we actually improve users lives on the whole at the core protocol layer right we're like solving scalability resolving we have thousands of VIPs that are solving every single thing can we do something for like the end user though that's going to directly impact their lives and save them hundreds of millions billions of dollars over the coming years because right now migrating all of your assets from one account to the next is basically the best thing you've got earlier this year metamask had 30 million monthly active users that's a lot of people there's a lot of private keys out there with Ethan them with some asset on any of the other 23 evm compatible chains tokens nfts non-standard tokens standard tokens there's open positions there's open positions across chains they're synthetic assets and right now if you get into the space and start doing stuff and then something happens right your computer is hacked you're physically attacked your entire infrastructure is taken over by North Korea your only path of recourse is to try to front run the people who have stolen that that phrase uh and like move all your stuff really fast and that like not only is is absurd uh it also like it has a real cost like it's hard it's stressful uh it's time consuming um it punishes the people that are most engaged right so like the people that we want in this ecosystem the most the ones that are like total d-gens right it's punishing those people because when something happens which it will they are the ones who have to spend the most amount of time and the most amount of real money to move their assets and frankly it should not be like this because we can do better because this entire ecosystem builds magical all day every day we literally create billions of dollars out of thin air like nothing we can do this it's like it's it's it's quite remarkable how Limitless our imaginations are in some ways and how limited we seem to be in the other ways so this is the original Zen we need to understand collectively whether you're building wallets whether you're building smart wallets dumb wallets whether you're building gaps whatever you're doing whatever layer you're stuck you're in we are responsible for what we create we are responsible for how that impacts people's lives technology is incredibly incredibly powerful but it is not like the end-all be all solution we can't just like put technology or code like in a bubble and say like oh that's just that thing over there uh it's immoral it's a political it's it's like just this thing what we're building is is not about I don't know whatever's on your landing page right like what we're building uh is trying to make people's lives better make society's lives better uh what we're trying to do is solve really messy problems social problems we're trying to improve how people can coordinate with one another we're trying to allow people to take control over their lives and their futures and not be restricted by some government some State some Corporation and in order to do that like we really need to Value people and we should be putting people and the problems that people are are encountering every single day sort of front and center like what are we doing to fix that and our products are a mechanism that we use the technology is is the tool but the choice is those are ours and those have to be about people and they cannot shy away from the hard things this book is really real guys I highly recommend it all right so new paradigms this is a new world we are actually successfully creating a new world we have successfully onwarded a remarkable millions and millions and millions of millions of people into this new world we have successfully disintermediated a ton of things we've given people control full control we're nothing can stop them what we need to be heading towards is saying that this stuff this key this whatever you want to call it right whatever it turns into tangibly this is mine right when we talk about identity when we talk about our things it's mine what we should be striving for is it cannot be hacked or stolen because it's mine I have full control over it I can use it I can access it I can revoke it right if I think it might be compromised I can be like oh let's just pause for a second and reevaluate the situation let's not let those hackers take that thing and then once I've uh secured the perimeter I can recover it the things that I do they don't just happen on my behalf but I'm giving my full consent that consent has to be informed like I have to know what I'm consenting to um I have to have a choice in that right I can choose to consent or to not consent because ultimately we all need to choose how we interact with the world and also how we impact the world because it's our choices that shape this world every single choice that we make so they're sorry there are there are a couple eips out there that are trying to tackle this problem I am not going to uh say which one is best I think that the solution is probably not one of these it's probably a few more conversations some online debates and whatever evolves from that I trust the big brains to figure it out but these are the ones that'll get you started they're the most recent ones if you want to go down the rabbit hole there's like 10 other ones that that really did some deep research but these are the ones that are kind of out there right now erc4337 this is sort of operating um it doesn't require a protocol change it'll be uh implemented probably by flashbots it gives some quote-unquote account obstruction stuff then you have 30 74 this is the one that um if you have an account right you have a private key right now uh you can delegate control uh uh that's like sort of one half of it right like uh when we talk about key rotation or key revocation or key recovery uh it's you know you have to like assign that Authority somewhere else and then the original thing you want to like revoke The Authority uh 3074 is the one where you can like it's the rules for how to delegate and then erp5003 is a new one I think we're calling it auth usurp this is a basically you're gonna deploy some like code uh we imagine that in the beginning it'll be some simple code but it'll basically take your current account your current private key and it'll give it some like smart contract abilities 503 really makes sense with 3074. it doesn't really there's better ways to do it without 3074. but most importantly there's a lot of mechanisms and a lot of things we can learn from all the history and all the research that's been done the conversations that have happened around these uh and we can talk and discuss and put our big brains together to hopefully come up with a really strong powerful solution that will actually serve real people because that's the goal we can do anything we want and the most important thing that we do is continue to dream don't be limited by some I don't know uh stupid tweetable phrase like code is law don't have your imaginations limited by this ecosystems obsession with uh immutability or like trying to put technology and code over here and pretending that's separate from the people over here everything has to work together right the whole system is where the magic comes from and so we all have to work together we have to use the tools available to us we have to use each other we have to collaborate right we have to get really really creative and we can't be we can't be limited by anything all right so I encourage every single one of you to keep on dreaming because that's the only way that we're ever going to build a better world and we're well on our way the amount of people that are actually using this this technology that we're building it's truly impressive I never thought that we would get here but I do hope that we're going to be able to make some real improvements before the next wave because as of right now we're simply not ready for 100 million or a billion people to have their identities tied to that single string of characters all right I also have to show some stuff okay so uh for those that don't know I'm at venomous metamouse is part of consensus consensus has a ton of amazing things going on one of them is Village doll so remember I was talking about like you know incentives and getting people working together and collaborating so that like everyone can be better and more empowered village now is one of our various attempts to do this it's really really exciting whereas is villaged out in the house Make some noise find them they're freaking cool uh they'll explain everything to you uh it's a really it's it's it's such a cool initiative uh and yeah I'm so excited okay next uh infuria you know that evil centralized thing that the whole ecosystem is relying on and it's gonna be our deaf yeah no it's well on its way to being decentralized we could not be more excited EG and the team have been working on this for God as long as I've known him and I've known him since like 2016. it's been crazy um but we are actually making moves there that's a QR code I don't know where that QR code goes to but I assume it'll give you more information or maybe a party favor I don't know find out uh isn't Vera in the house is Patrick here oh okay okay they'll explain to you but all I want to say is that we are committed to building a decentralized world right we really are and last but not least wear snaps okay we all lost announce people here metamask this is the future of metamask I know every single person in this room has some problem with metamask I have problems with my mask I sit there and I go like why do you do this to me metamask and I'm building metamask and then I tell people to fix it and then like I yell at metamask more I know that you've all been in this boat with me metamask is actually the solution now because we can't keep making metamask bigger we can't keep running around like doing whatever Taylor says to do and I think that's not scalable uh we are building for billions of people what stabs does is it enables every single person to extend the metamask functionality so instead of metamask having to like build and maintain something for your custom thing and try to keep up with this ecosystem that moves so freaking fast what we're going to do is we're going to put the power in the Builder's hands to actually extend metamask to better serve you as the Builder and also better serve your users because you actually know best right we we can grow our team bigger and bigger and bigger and we still won't be able to keep up because the Innovation that is happening in this ecosystem is so so remarkable and that's what snaps aims to do it aims to give everyone the builders the smart big brains in the room the power to make metamask work better for you uh like you heard earlier there's a bunch of snaps people here if you're a builder and you're frustrated with metamask talk to them they they will explain it all to you and that's all I've got just want to say thank you [Applause] amazing that was a excellent talk we have time for just one question if anybody has a quick question if so please raise your hand and we'll get a mic to you ASAP do I see a hand I saw one and then I went down there we go just I'm just blind yeah hello just a quick question what would you what will be your perfect world for perfect users uh a perfect user system for you yeah like the private Keys yes yeah for example on what link can we back the user information so right now we in the physical world we back up with the people's bodies in I know that person because I see that person physically beside me so I will need something something based on the physicality of the person or something like a second like a second degree second Factor authentication but then yeah so the reason why I kind of shy away from um saying like this one technology this one thing or this one thing that these one groups of people or the standards body is working on is like the solution is that I think um frankly I think it's ignorant to think that like any one party or any one group of people can serve like the entire world perfectly and especially at the pace of innovation that we're seeing um I think that there's like a couple important factors and I think the conversation was often marred in this like like account abstraction is the word if you want to Google it like ethereum account abstraction you can get the whole history it's it's such a big thing it has so many goals at this point but the thing that I'm most focused on is like um I think we need to provide a migration path for users that is as cheap as possible so not migrating all their assets but going from whatever this old way of doing things to the new way of doing things has of a low cost secondly I think that um people should be able to like revoke whether that's like permissions or their entire key or whatever it may be they should be able to say like no that's not valid anymore that's not me anymore um and then I think that obviously uh there's in order to make those two happen there has to be some delegation some permissioning system something where uh because like if you revoke all the permissions then you don't have any you can't do anything so you have to like give them somewhere else um and there's there's a ton of people that have been doing a ton of work on this over the years the ethereum account attraction research is in conversations like those that's one thing but if you look at decentralized identity which has been a decades-long effort by some remarkable organizations around the world that are really focused on this um that's like a whole another rabbit hole that you can go down and I will not pretend to think that uh like I I deeply understand the this design space as much as I'm so if this is something that like really interests you and you want to start working on it um I would definitely recommend like starting there and looking for the experts and the people who are talking about it because they are uh way smarter than me awesome that's all the time we have please give Taylor Applause love you [Applause] and with that we are ready for our last Talk of the evening without further Ado I'd like to welcome Yin Tong and noline bardwaj to talk about recursive zika applications and affordances please give both of them a big round of applause hello everyone I'm Nolan I'm ingtong uh and today we're going to talk about recursive DK snarks the kinds of applications they unlock and how we can Implement them so first we should talk about what recursive proofs even are so in the context of snark recursion is usually the ability to verify a smart proof inside of another smart proof so this is the ability to say something like I know a smart proof that when I run the smart verification algorithm on it returns true inside of another is not proof and the sort of key part here is that verification of recursive ZK snarks is usually not significantly slower than ordinary regular CK smart verification so now that we have this primitive in mind we should think about the sort of natural question is why would you want to make recursive smart moves so typically regular ZK snarks you know we think of them as having two uh sort of properties so sickness and their knowledge so recursion in fact unlocks powerful versions of both of these properties in the form of compression which is a stronger version of the cygnus and multi-party composability from zero knowledge so first let's talk about compression we think of compression as supercharging succinctness and in particular usually the applications of compression tend to share a sort of common pattern and this common pattern looks like you know let's say we have a proofer who wants to show a verifier some n pieces of knowledge how do they do this they make a proof showing two sort of things first they show one piece of knowledge and then they also show you know Additionally the N minus one other pieces of knowledge but for these n minus one pieces instead of showing each piece individually they will show that they know a another snark proof of these n minus one pieces so the next question is how do you make the smart proof for the N minus one pieces of knowledge um and in fact we use the same kind of strategy again the N minus one pieces of knowledge we show one piece of knowledge and additionally we show that we know another proof of n minus two pieces of knowledge and so then you know you just gasket down this sort of strategy and you end up with the situation where you're verifying uh one uh snark proof and in that it's automatically verifying these n items of knowledge another instance of compression that's particularly helpful to point out is the setting where you want to compose between different proof systems or arithmetizations and at the time also pick the good features of each of them so for instance you can have some setting where you have two different proving schemes one where you have a fast prover but unfortunately the verifier is slow and another where the prover is lower but you get the trade-off that the verifier is fast so using recursion you can compose between the proving system from The Wider setting to the narrower setting and get a tiny proof output as well as fast-provers getting sort of the best of the Both Worlds a concrete sort of instantiation of this interoperability is the setting which Starks and grot16 in particular grad 16 is very cheap to verify whereas Starks are very easy to prove so if you verify a start group inside of a graphics scene snark you end up with a proof of the original statement with the fast prover as well as a fast verifier so generally compression has this sort of property that is very mechanical and usually you're rolling up some giant list of computation or items of knowledge incrementing to a single proof so just to give a flavor for sort of what applications this unlocks um let's look at things that are interesting to roll up um so first is signatures over the summer we built applications using sort of this primitive of recursive compression of signatures called isocratia where we end up with a low trust low cost sort of roll-up of off-chain votes and end up securing governance and then more related to sort of blockchain land you can do the same kind of trick with like client routes and in fact plumo which is solos light client is based on this sort of idea and there's also another group named Axiom which is exploring sort of more cooler use cases for this with aggregating and providing historical data through the use of recursive snarks um and then finally the sort of Hot Topic in blockchain land these days is making Roll-Ups of transactions um two particular ones that are sort of interesting to point out are Mina who sort of use this recursion um primitive as a consensus player primitive and polygon Hermes who use the exact strategy of like using starts for fast-proofer settings and uh grad 16 or snarks for fast verification settings next let's talk about composability my personal favorite property uh unlocked by recursive Schnucks um so to give some context for this let's take a step back let's think about what a normal ZK proof uh you know what's the context of a normal ZK proof we usually think of you know ZK proofs in this context here approver is showing knowledge to a verifier um without revealing the underlying fact of the knowledge with recursion in fact you can unlock something more powerful approver can show knowledge to a verifier without fully knowing the underlying effects themselves so this is a bit hard to model so I'll just lead with an example over the summer we build this application called it dos which is a dash number is on social graphs so these social graphs are sort of graphs of relationships of people saying I am your friend kinds of things and for instance here we have this graph and vitalik sent someone who sends someone who sends someone and finally I ended up with a four degree path to vitalik now I can prove that I have a four degree batch of italic without reviewing any or without knowing any of the intermediate parties in this path so how do I do this I say I am a friend of adhian and Adian has a ZK proof that he is three degrees from italic so in this process I do not know the three degrees that precede adyan and I have still convinced any external as well as myself that there is a valid path of four degree between me and vidalik so of course this is not the only application you can build in general we think composability is particularly cool to think of in sort of incomplete information game kinds of settings um and uh of course the the sort of very typical example the the phrase starting point we thought of was games like telephone or Chinese Whispers where you know you pass a word around or something and you want to make edits to it uh incrementally and then you can make more complex applications um like party games like Mafia those kinds of things and then more relevant to blockchain land you can build private State channels and roll ups of that sort oh so now that we have some intuition for the high level properties of recursive proofs and now that we've seen some classes of applications that are enabled by them you might be feeling that recursive proofs are kind of unreasonable we get unlimited compression and compostability so I guess the natural question now is how do we Implement and construct these systems so right now there's broadly three classes of recursive proofs in production and as we descend the hierarchy we are relaxing the requirements on the proof systems which are eligible for recursive schemes so at the very top of the hierarchy we have really the most stringent requirements so we we need proof systems with verifiers that are sub-linear that are succinct in the size of the statement being proven and this enables us to do full recursion at every recursive step so this has been implemented for the growth 16 and Fry priv systems so if we relax our requirements a little bit um and we say even if we don't have a succinct verifier maybe we're happy enough just with a succinct accumulator so intuitively what this means is that we want a verifier with this shape that they have a succinct check a cheap check and then separately they have an expensive check and so here we can instantiate an atomic accumulator and at each recursive step we only perform the succinct checks and we accumulate the expensive check and delay checking it until the end of a long batch of proofs and doing this gives us amortization of the expensive check and finally if we relax even more um we don't even require a succinct accumulator well now we're just happy with a succinct public accumulator and the idea behind this split accumulation is simply that you split your accumulator into a public and private part and the public part is short and this is what we accumulate at each recursive step um where whereas we delay the verification of the private part of the accumulator until the very end so let's go through these constructions at a high level one by one just so you can see the shape of it so probably the cleanest shape is oh the the cleanest shape would be full recursion so over here we start with our application circuit and it's f um F of w-i-z-i gives you z i plus one right it's a normal relation now we bundled that together with a recursive verifier and um basically this recursive verifier takes in a proof instance that was produced by the previous instance of the recursive circuit and so if if we look forward we we need to generate a proof of the whole recursive circuit in order to input to the next recursive instance so in this way we're chaining recursive circuits and at each step we are fully verifying the previous instance and when we get to the final verifier we no longer need to bundle it with the applications they're getting here we can just perform a final verification of the proof outside the circuit so this is full recursion it's it's the cleanest API um now we're gonna get slightly more messy and we're gonna relax our requirements to get an atomic accumulation scheme so now if you recall here in atomic accumulation scheme our verifier is not sublinear so in fact the verifier inside the recursive circuit is just the accumulation verifier and it only concerns itself with the succinct checks of the verifier and the expensive check is accumulated and deferred at each step so here we are chaining basically instances of proofs and accumulators and at each step we're just procrastinating on performing the expensive check well until we're finally satisfied at the end of a long chain of proofs we perform the final decider subpritical that finally bites the bullet and does the linear time check um but at this point we can do it outside the circuit and at this point the cost of the linear time check is amortized across a big batch of proofs now from here to Atomic accumulation is just a small step so it's just splitting up your accumulator and your proof instance into a public and private part and now the verifier the recursive verifier gets even smaller and it concerns itself only with accumulating the instances the public parts and it does not perform it does not have access to the private parts of the accumulator and rather it relies on the Pervert to provide some commitments to the private parts which it then performs accumulator checks on so a lot of these constructions I've described are really cutting edge and they come from a feature of our modern proof systems that are very modular in design and as we get a better understanding of the building blocks and the components of our previous systems this lets us customize our proving Stacks with a lot finer granularity oh and recursion as we saw also allows us to compose proof systems and to get the best of both worlds in many cases so here's an example of a modular conception of a proof system so I work on the proof system Halo 2. and I think of Halo 2 in terms of these four components so at the very front end is where you're interfacing with your business logic so you take a relation and you arithmetize it into um so in in Halo 2's case we encode our values in the LaGrange basis and we encode constraints on these values as polynomial identities we then input these polynomials into this information theoretic polynomial IOP that basically checks the correctness and the consistency of the polynomials encoding our circuit and then we realize this polynomial IOP using a cryptographic compiler so in this case it's the inner product argument that and the Fiat Shamir transform that allows the perver to Define their interaction with the verifier and at the very end of it Halo 2 is a recursive proof system and we can infect instantiate an atomic accumulator over the inner product argument so these are the four sort of modular pieces of modern proof systems that I think of now we can do pretty funny things composing these pieces so I've set up three cases um so the first one is information theoretic compilers and an example of this is MPC in the head um what this does is it converts one information theoretic protocol to another one and in this case um it's the proverb sort of pretending to run a multi-party computation in in her head um so she's really stimulating the multiple views in an NPC and committing to those views and now the verifier is only checking the outer protocol being the NPC instead of checking the inner protocol which is the ZK proof so this is one very interesting way to compose proof systems another way that we've seen before in this presentation is more or less just implementing verifier X and prover Y and you would do this also for efficiency gains and um sort of the last Clause of composition that I came up with was really just thinking up better cryptographic compilers so there's this recent paper by a group at consensus um and they they took this protocol gkr that's highly optimized for repetitive computations like hash functions now but the problem of gkr is that it has a slow verifier and um so and it also uses the Fiat Shamir hash as a cryptographic compiler and this makes it very inefficient in the context of recursion so what the team at consensus did was they came up with their own cryptographic compiler that was custom made for their target proof system and the target proof system here is like a growth 16 r1cs per system and so really like that's going in the middle and making changes like customizing criticisms at a very low level um for efficiency and yeah I think this this leads me to ask um whether or not we can systematize this process and um whether or not we can I don't know um explore this optimization space in a well-defined way so you can think of this as kind of a call to action um so I think there's certain nice to have certain to Do's that all proof system implementers would really like the first being good benchmarks Fair benchmarks of heavily used Primitives like hash functions like bigint arithmetic so benchmarks of these Primitives across different proving stacks and the second would be it's a kind of a meta requirement is to think of like what metrics we're interested in for example efficiency for example proof size and basically how to optimize towards these metrics so on what basis are we comparing different compositions and configurations and the last sort of call to action would be to think carefully about how security properties also compose like excuse me like is it the least secure approved system the the fewest bits of security or like some weird composition when we mix and match approved systems so all these are questions that it would be great to have everyone's input on like even this taxonomy that I came up with I'm not sure that it captures um all features of proof systems in the best way so Nolan and I actually help out at um a group called Xerox Park oh we didn't put the name on the slide it's 0x Park um and there we're setting up this task force to look into this area of recursion aggregation and composition um yeah and I think like I might as well take this opportunity to shout out Xerox Park and they supported a lot of our work a lot of those fun apps and a lot of these Community efforts yeah I think that is all I have so thank you [Applause] awesome well thank you so much we have time for one or two questions if you have any questions please raise your hand we got a question here on this side all right I didn't think this would work for years and years and years um and I also I'm not I'm not even sure that does work it does seem way too good to be true so can you prove and how do you prove that that it's secure to do recursive like proofs like this like where where is the security proof you know I don't know how to convince myself that this works actually yeah I mean that is a good question it seems very unreasonable that you can prove like an arbitrarily long history of computation with a constant size proof um it does seem unreasonable so I will say that security proves exist there in papers um but now and they have like some intuition as to why the security should hold uh yeah for sure I I think one sort of physics-based view that we've seen before is like it's like oh you're 3D space and you're collapsing into like a 2d surface um I forget the exact name of this but holographic principle uh so I I think there is like some sort of meta justification you can come up with to convince yourself if that's like this sort of thing but there is fruits of all kind that are actually substantial it's a good question any last minute questions we have one at the back all the way over there to your left so recursive proofs are real fun but if you do it at scale then you're you know it's like you you you have skill and corruptus napping at your heels uh because of the proof carrying data right if you want to build on recursive proofs and it doesn't happen at the same time so let's say you do a proof and you do recursive proof and then you have to wait for a state change for something else that might happen much later you need to keep the proof carrying data around and as you know if as you know but most here that is typically a very large amount of data um so it's like if you're doing it at scale you're really running into the issues of data provisioning and all the fun part can get really expensive really really quickly not even talking about like the the um you know the the computational overhead that you have yeah yeah for sure I think I don't think recursive proofs are a silver bullet and I think they're better suited for some shapes of applications so recursive proofs are very commonly used to reduce reverse based complexity so breaking up a large circuit into many smaller parallelizable circuits so yeah but I I agree like in context of applications with more complicated and like timely data flows it's it's we have to put some care into how and where we are inserting this proof carrying data yeah right and also just to add uh I think there's also some interesting like sort of clean separation here of like rules versus data availability sort of problems um and if you just look at you know data availability as a sort of Black Box problem you know you have lots of blockchain kinds of solutions for it and for instance isocratia explorers um one sort of solution that um maybe you can check out The Blog on yeah also to add on to that like I I really like knowledge thing about composability the fact that um you know you you can play incomplete information games so I think sort of fun applications like that that are unique to PCD are also very interesting to explore amazing that's all the time we have for today please give Ian and Elaine a big round of applause and with that we are done for today thank you so much for staying here with us we'll see you all tomorrow for the rest of the talks have a great evening everybody take care foreign [Music] foreign [Music] [Music] [Music] [Music] you're not here [Music] [Music] hold on [Music] hold on [Music] I've tried I've tried I've tried to let you go and give you up in my mind [Music] [Music] foreign [Music] [Music] [Music] foreign 