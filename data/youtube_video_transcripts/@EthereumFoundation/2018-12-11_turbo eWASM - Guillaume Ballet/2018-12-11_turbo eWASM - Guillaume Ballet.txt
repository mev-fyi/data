so now I'm delighted to pass you over to yes I want to talk about Ruby wisdom so that's working name it's actually reference to to go get some of you have heard of it it's it's a project but by alexei to to work on to improve the speed of gas and we we want to leverage it was them so it's colleague and i from he was a team for henskee we are working on leveraging it was them to try to make against bits or at least the ether 1.0 clients a bit faster so as a good reminder what is he wisdom so maybe we should start with what is web assembly what it was them it's a binary formats that you can run in your browser so you can try to program it whatever language you want compile it to to the wasn't formats and then your browser should be able to run it so now it's not only used even if it's the initial intent it's not only used as the binary formats for the browser you have a lot of other application you have applications you have people running it you know in what go ring zero and like for every good application so that used to be done in the 90s with a visit JVM and now people do it with the with the was mmm and yes you also have blockchain projects that they use it for example yes and of course parity uses it for actually is it for a music for a polka dot or is it for a substrate or both [Music] anyway so how does he wasn't compared to was some well it basically was regular wasn't except that you import functions that would initially up until now corresponds to a specific instruction in the in the EDM so functions like you get the conveys get get the code of the caller gets things like that that I used to be instructions now there are just function calls so you just import them [Music] so how it wasn't going to be deployed in the theorem well you might have heard of ECM one point X which has been discussed for the last month and a half so it's basically like improvements to if you're one point zero to make it more scalable waiting for ECM 2.0 which is now a nickname serenity so until seventy arrives we we still need to make one point zero scalable so that's that's what we were working on at the moment and it has been decided that in Prague during that con that's it's actually been proposed it will be decided next year but we're going to use wisdom as the language for pre-compiled so pre compiles are special contracts that are called often and they are going to be written like they're going to be written in wisdom the run was them and if you want to extend it you can write the contract once and for all and you don't have to bring women them and in when it comes to ECM 2.0 Rossum is the prime candidate to be the execution engine for each shard but that's further down the road so there's no there's no promise of that and yes I'm talking on behalf at least part of the it was a team but just because we're working on it wasn't doesn't mean EVM is going to disappear like the old EDM is going to disappear it's still go it's still going to stay first because we we have all those contracts that need to to remain and as like I'll explain in a couple minutes while some is still a work in progress so there's a lot of reasons to keep investing in solidity in any VM and all this all this environment so yeah I was saying EDM is going to stay there are some trade offs like when you compare to the current state they are different there are some challenges maybe some trade offs do you have to overcome first is binary size because solidity compels sub it's very streamlined you start executing it there's no real transformation it's pretty it's pretty simple it's pretty a bare metal when it comes to tourism or wisdom you can take whatever language and those languages they don't know like those compilers they don't know you're targeting any specific market blockchain environments so they will produce a new binary that has something called the runtime so there will be a lot of cruft that is basically here to prepare for anything that can and that can happen and and yeah all that Trust takes a lot of space some languages are fare better than others THC is the best rust is slightly better and slightly worse and and go is absolutely horrible because you've got the garbage collector so yeah I mean each language has its specificities but some of them are adapted this specific application or not yeah Mikey I was saying the spec here there wasn't spec is still evolving so we're not I mean where it's going to remain more or less what it looks like right now but we could have some surprises so when it comes to making sure that every single client does the exact same thing that's a bit of a challenge and yes the the biggest trade-off when it comes to wisdom is that like I was saying you have a medium binary you start at the first instruction and you execute it all the way until you stop in wisdom you require a little bit more work actually a lot more work you need to transform you need to validate into validity binary it's not yes like you have to go through the entire program check everything is fine all the loops are properly inflated and things like that so it's been designed for an application that has that would last like that would run a long time so think Gmail in have Gmail in your browser could be printed in wasn't clearly you're going to spend like 10 seconds waiting for Gmail to load the once it's done it's going to remain is going to be running for 4 hours and hours at a time in the case of smart contract the load overhead is a bit of a problem because the smart contract executes and then you have to load another module which is which corresponds to another contract so it's not as it's not as easy or at least it's not as simple and it's not as fast so that's one of the trade off we we have to deal with so until now I try to describe pre compiles as libraries so it would be some contract that you call and yes like you you could optimize it this way it wasn't to you noted once and for all the module is there and you keep calling it again and again but at this point it starts looking more like your service and that's really what the core of this proposal is about start thinking about recompiles more like your service than the library so we keep them permanently running and because in the regular operating system which is where Paul and I the world that Paul and I come from an operating system to service system to have better access rights so we want to explore the idea of giving those services a bit more control over the ply what the client does then then regular contracts too so we would like to give them access to the transaction pool to be able to map memory and yes that's talked about so there are three main domains where we could actually improve or at least offer something or it's very mad at least its scalability of course because that's kind of the thing it was a bit easier for storage storages if I mean whoever has implemented the client knows that storage is a problem if anybody has done a full sync which is what I'm doing right now at home it's taking three weeks and I'm not even halfway done that's right yeah 30 yeah I'm going to the office oh and yes consensus oh that's the one that's a bit more science fiction II but I just want to throw a couple ideas so let's start with scalability so I just want to a quick reminder about parallel execution so right now you need when you receive a blog you have transactions and almost all sorry all of those transactions get executed before the mining starts and it's very important that sequential I'm going to explain why what we would like to have is something where yeah so what I meant if you look at the second CPU is idling until the mining starts so it's kind of wasted it's not a lot of time to still mining Dwarfs everything else but because you have things like uncle rates that got to go up from time to time getting the to the getting being the first to the blockage is quite an interesting so what we would like to do is the second case which is to have all the transactions right between the two CPUs and and be able to to get to get to the mining faster and that's all the more important because when you're actually syncing with the network the mining is gone so the transaction is everything preventing you from from being up-to-date so why can't you really have transactions that are okay interesting yes so but at least the the picture is still here so yeah so I try to explain in water parallelism it to be difficult I propose switch transactions so those squares on the Left are represented States and when you apply the transaction each transaction apply like thirties of rights or reads from squares so the transaction one will be represented by a wreath of rights to the right square the two to green square and so on and now yes next makes the slides to still exist so you can see for example if you perform transaction three before transaction 2 you get a different result then you should get transaction 2 first entering transaction 3 afterwards in the case of transaction 3 and transaction 1 it's not a problem because they don't actually write to the same the same area but yeah you see the problem so what needs to happen is that the exact order of the transaction needs to be reproducible reproducible because if you don't you just dump all the transactions in your block someone seems to block execute the transactions like in parallel yeah but with a different number of of CPUs or something like that and it turns out the order is invertible isn't broken and therefore you have no you have no consensus that you have a fourth so yeah like this the difficulty in partitioning is really determining which which non-conflicting a transactions can be run together or concurrently if two transaction touch the same area it's better if they're run together sequentially and if they don't touch the same area at all you can separate them and run them in cargo yeah so one idea is that partitioning is really a generalization of sharding so if you look at shorting like you're a big doable state you want to be able to run on each shard and like a parallel process or you want to be able to do what we want to generalize it to is inside this single shard to be able to create partitions and write to those to those separated partitions so there's an EIP that already exists is called 648 and it's been created by by detailing and the idea is that it requires a little tweak to the current model where each transaction has to declare upfront or beforehand which which addresses is going to touch so in the first case you have a transaction pool on the left and each transaction says I'm going to address those addresses and if for example the number one and number two overlap so the scheduler the transaction scheduler will say well clearly those overlaps so I'm going to put them they should be executed sequentially by CPU 1 & 3 & 4 the overlap - so they're going to be executed sequentially by CPU - and then once it's done you just wait for completion and then you start - what one of the things what I working on his left partitioning so the idea is to do more or less the same thing but without actually changing the interface so the idea is simply you you run the you run everything in part parallel as if it was always possible and if you detect that there's a conflict you drop the second transaction the second writer and you put it after or in a different block yeah so the way that would happen so you have two CPUs two transactions running on two different CPUs and you have the global state at the far right so transaction one is right in two locations actions to in the location and then in the next step transaction two tries to right in the second location but it's a location that has already been written to by by transaction one so what we do we simply idle and it feels a bit wasteful but what you have to realize is that if you compare it to to the current state you wouldn't you wouldn't be using superior CPU to anyway so it's like you're trying to cut the line if you don't get caught good if you get bought well too bad but you don't go to jail for cutting the line so that's fine another execution model that we're looking into is the classic MapReduce so a lot of people I assume are familiar with this because of Hadoop so the idea is to go even deeper inside inside the state and realize that not all transactions address the same state the same area of sticks right and that means that you could technically run several transactions in parallel at calling the same contract but not touching touching the same area and yeah it would need some special kind of services first keep doing that I will get back to so I just this is a fantastic code of course but the idea is that yeah you have an array that contains all your tokens so this is some kind of a or C 20 token you have a first function that that tells that the the scheduling contract will or this scheduling service would call to see to tell you I have two transactions are they conflicting so you just check so this is a very simple example you just check that the to and from are all different and if they are different you just return true so that means okay the the scheduling service knows that it's possible to to schedule them together and then it will select to like it will call for each transaction it was called the mapper function on a different CPU so because those transactions are not conflicting it's it's safe so on on a more functional yeah presentation its you have four CPUs and for transactions but work two of those transactions right to the same location so at most three transactions can be low can be loaded or executed at the same time you assign three CPUs to it the fourth is idling doing regular contract management and the third the third transaction is pushed back to another block or later down later down the list yeah so that was it for for execution for scalability execution scalability now I want to talk about storage Chubin so yes the the first technique that the vault in operating system is caching so you just catch a bit of the state so right now I was talking about ACM 1.6 or 1.5 before there's a proposal still but I excited the turbo edition book is guy who just proposed like to have some linear space so apparently it's not making it to the final draft but this is still an interesting idea I find so map some areas of the of the space linearly and cache it so yes this is spending a lot of time waiting for IO so what we want to reduce that we just want to keep that in memory and only write so often so yes spend less time not just waiting for a disc to respond so once you do that you can actually do so that was the state the memory we can do that for the code as well so I have a bit of a complicated diagram but you still have the transaction pool here and you have a cache of contracts and you can see that transaction 1 for example through transaction 3 all correspond to the same address so they want to call the same contract and it's been capped so the scheduler are going to say ok we clearly access the same contract let's put them in serial in seed points on the first CPU and then we see that transaction 2 also corresponds to 2 cache contracts so we're gonna ask CPU to 2 to execute it first because right now the cache is still containing the contracts so we should benefit from that and then transaction 3 our transaction for sorry is is not like its contract is not in the cache so you execute it afterwards you going to have to load it from disk it's a bit of a pain one thing you can do however that's that's a diagram that has been used at Def Con is while you're loading that first that that contract you can actually while you waiting for this to load the this grain is running on will just block and give the give way to another thread so more work can be done so yeah that's that's roughly what was we're working on and now I just want to like I was saying a bit something that is a bit more sense fiction but I think it's a it's a pretty exciting idea so I'm talking about it anyway and it's to give to those services to those contracts part of the consensus and the idea is that I was talking about the model like the the MapReduce execution model before I was talking about the the other that I didn't give a name to but let's call it the commutative transaction model I don't know and those things could depend on the type of traffic if you are at the time where you have a lot of cryptokey like or nico a lot of transactions looking the same you don't want to use the same the same service as if you're executing a regular regular contract that just yeah RC 20 token for example so it would be interesting to actually be able to send a transaction to some service to explicitly address that service and the service will schedule those transactions for you and from then some miners can decide to run some service or not and that's pretty okay because actually in the theorem we can still have uncle plots so you can have several blocks that were all generated using a different execution model and of course the only thing that matters is that if your contract is not available or if the miner doesn't want to run that contract you should always be able to fall back to the standard execution and now I start using the big words governance it's yes so there's always a debate governance is a big debate so why I find this idea interesting in spite of being a bit a bit undefined still is that you don't have to really vote if you want like to have a four to agree with everybody you can just deploy your own service if people if for example miners don't agree with your with your service with what your contract does what your service does well they just won't run it they will refuse your transaction so you can go to a different to a different miner to propose that that transaction and the only thing that matters with that model is that even if you refuse to access to run a given contract if you end the block that does use it but there's a transaction that they'd use it you need to be able to so the hope is that it will result in less force or at least reduce the need for forts but yeah that's still up for debate and people yes so as a conclusion yeah like the reason why we offer that we want to work on that is because we believe they are advantaged for for minors simply because they get to generating the generating the drug faster and hopefully that also translates to an advantage for the user because if it cost less to generate a block hopefully cost are going to also be reduced and ultimately when you send a transaction you wait less time on this the second work is like for storage right there's like idea numbers they look kind of like generic in the sense of it could be implemented by any client what's the relation to you wasn't right so indeed like some of those ideas are already implemented in yet for example there's some caching in fact peter currently is doing a lot of work on that actually it's a pillar of fuel etc number but one of the two is doing something on that so why why is it real related it's not so I mean the reason why it's it doesn't have to be wasn't the thing is I was just mentioning that because the caching could be use as an indicator of what transaction should be scheduled next so this is just connected to that idea but clearly caching is not a novel idea and yes it's already news in someone else yes yes and good in the sense that yes I started measuring but for that I mean by my not to sing the entire blockchain and fortunately I didn't reach I have some free some pre diagrams at home but they just were where I am at at the moment is right after the dowel hack so you have a lot of conflicts coming up people are calling the same contract over and over so it's not giving me an overview but yes I'm looking into that and I will tend to publish that hopefully before the end of the year well you know this this thing takes a lot of time I mean I might not have the best computer either the business work connection and so on yeah but yeah it's been it's taken me three weeks so far yeah I just thought about giving your sneaker network and just walking to someone with yes I have thought of that except no one workers so people do that it's it's a monthly cost so yeah I mean I asked a couple people but they were not really a happy to have me run scripts that take forever on their on their machines but if you haven't known that as already synced please talk to me yes you do yes oh my code is forget but I'll be talking to you do we have some more questions okay so let's say thank you very much 