[Music] foreign [Applause] [Music] yes sir yes boss um okay we should be transferring over um live chat so i can talk to the people of the internet okay cool if you're on youtube and you are in fact listening and can hear us let me know here's the agenda someone is spamming the hell out of that chat call 53. i've been doing this for a while um great so if y'all weren't aware maine at launch um call 53 new deck of cards new era yes indeed uh actually we're at the joker there's two jokers in this deck um anyway yeah i i think that y'all may may or may not be aware um may not launch obviously you can debate taxes you can debate um what actually launched but yes we bootstrapped the proof-of-stake consensus and it's running stably and um very proud of everyone it was awesome um and now there's plenty of work to do but hopefully you can enjoy the holidays so testing release updates nothing nothing going on here uh we do have some testing reforms that we want to do and uh fork choice stuff that we want to get in both of which the testing reforms kind of enhance enable the fork choice a lot of this is going to be kind of deduplication of repeated stuff within the testing outputs so that this thing doesn't blow up to be like 30 40 gigabytes it's already very large um so that's in progress uh obviously it's not being prioritized in the past three four weeks uh but that is in progress um there's also some specification work going on that is related to a couple of upgrades i think that we'd want to see early on and maybe kind of eyeballing for first hard fork um the feature wise the the big one would be and it's not big it's actually very small uh is adding a light client sync committee to add my client support as a first-class citizen it's pretty much reusing um all types of infrastructure we've already used signature aggregation uh subnets that kind of stuff but for this particular type of committee that changes more slowly um so keep your eye on that uh probably in january we might release some test sectors for that if people want to begin building but i also know that um you know there are optimizations and stability things that people are still working on as the main net gets bigger we want to make sure we stay stable any other testing updates a quick note about api testing i've been working on api bindings for the standard api a source test vectors and trying to run through the full surface of the lighthouse api if anyone else is working on bindings or i'd like to talk about api tests then please reach out on this card can those bindings be generated from from the definition so there's two parts to this server tests and client tests um for the client test i run through a whole lot of variants that called the server collect requests and response data and then mock that interaction to test the bindings server testing is more complicated since it depends on lots of dynamic conditions and there is am checking stats codes right now and checking the format of each of these responses to make sure things are right but then again it's a lot more to go through with server testing we can talk about that in this card cool anything else on that um i also think we're probably inches away from a release on those apis that's i know it's something i need to get back engaged with but if you are regularly engaged with apis if there are any kind of open issues or anything else that you want to see uh before this release now's the time okay cool uh test net mainnet pure mount looks good mainnet looks good again congratulations it's been a wild ride any comments thoughts anything here um i have a question has there been a discussion on starting a test net but with finality this well with finality disabled i'm asking that because of um there's just a great lesson learned during the non-finality period at the peer month and the definite clan made a lot of optimizations around there but i feel like we can use more optimizations yeah i agree um some of us were discussing us this morning um on either we were discussing it from an angle of like just running some load tests um and seeing what we find but an extended test net devnet without finality might make sense adjusting you and you have some thoughts no i was just going to say that yeah i agree it's high priority and it's um i mean for for those who may not know we onboarded perry uh peritosh dfm foundation helping you know at the intersection of of devops and security and um you know that's one of the things that we really want to prioritize a test network no finality yeah um just a survey i'm curious uh do in terms of client performance if there's no finality but incredible stability um is that a tough scenario or is it when there's no finality and also a reasonable amount of forking or orphans and things is where does the load in your estimation uh become induced here i think when there is a forking and non-finality clients will not prune as the dag in memory and then you will have usage right so but it in in the assumption if there was zero forking uh do you have the same issue no pruning but since we don't have forks to keep in memory that's fine i suppose okay so it might make sense also if we're going to do this to have some subset of the nodes maybe have a clock skew so they regularly uh are getting blocks orphaned uh to try to capture some of the load in a more loadful manner um anything else on this uh definitely something i think we should discuss in the coming couple of weeks and maybe target for early january i think another interesting case is is long periods where there are no blocks at all uh i mean when prism had the rough time issue we didn't have any blocks for uh i think maybe two epochs was it three bucks i don't remember right now the numbers but um there was a good test for the sync protocol to ensure that we can handle an entire epoch without blocks correctly yeah i got you um that's also that kind of stuff's also on the list of some load tests that were like to engage with um but we could also induce that on like a public devnet i suppose everyone turn your nodes off everyone turn your notes back on um okay cool anything else on this okay can we talk about future of um test nets in in general uh getting lots of questions in about whether one is it long lived or uh will there be something else so my intuition and i'm happy to waver on this uh depending on what people think but my intuition is uh pyramid works um and at least probably through the end of january i don't i don't see any reason to disrupt it obviously that doesn't mean it's quote the one um there are some techniques at our disposal to ensure that a test net stays more stable and we haven't the only thing that we really have at paramount right now is we ask people to not spam it and we run 100 000 validators this may be enough for a while uh but ultimately like it might it might just degrade um and so we can start a test net with a much higher ejection balance like uh the prism guys did many months ago probably a year ago and we could also tune the leak parameters to ensure that the network even if it has a little bit of instabilities kind of stabilizes more quickly we can also alter the queue links to kind of have a higher quality of service so that people can get in although then you're now changing the user experience from mainnet so maybe that's not a great thing maybe changing the exit queue but that's actually not easy to tune independently of the activation queue so there's there's some stuff to discuss about what we would do in that test net but my my intuition is essentially probably paramount's good enough for the next two three months but we should consider our options and maybe do a a fresh start next year um q1q2 but that's just my opinion right now i i don't know what do people think on on this yes since last question uh sounds good to me i think it's uh because two three weeks ago we were talking about taking a view on this and people just want to know where they stand um i think you're right piermont is uh serving the the function at the moment does anyone else have any strong opinions on what we might do here okay so i think we paramount serves a purpose right now we'll keep our eye on it through new year and keep an open mind towards how we might have um a more stable test net in the future uh if and when pyramid degrades mommy you get something yes um one thing is that pyramid in a month will start being quite slow to think and um we might want to have the weak subjectivities thing in place uh well in a month or so yeah agreed um and i know paramount's a higher load than mainnet as well but that's probably a good thing rather than a bad thing uh but you're right yeah to weak subjectivity sync from uh from a recent state is um probably a pretty high value feature um not just from security but from uh ux standpoint to get out in the next couple of months okay anything else here well i'd only add that we'll be maintenance where per month is not too long from now because you know we never prune the validator set even when they exit so right although i expect pretty low exits on mainnet yeah but nonetheless like yeah it'll happen yeah i mean and there's there's multiple types of load right one is that validator set even if exits happen um grows in memory but if exits happen and the validator set is half of what you have in the registry the active validator set then that doesn't induce as much load on networking side so there's a few different angles there okay client updates let's start with nimbus okay so uh well mainnet launch we have uh following that uh a couple of things to do in particular documentation but we still have work to do there to try to clarify because right now it's very detailed we have a hotfix yesterday we have another one uh scheduled today so people using nimbus could track of our discord and we'll put in place the mailing lists and the hash of releases for for we want to thank our supporters in particular those who supported us on git coin over a year ago we still thinking about you and we'll have something for you soon and otherwise on the software side we are still using import and export or slashing databases the v3 so we plan to do v5 soon and on the networking side we for the launch we raised the number of peers requested by default from 79 to 160 which had a very good impact uh because we have now a much better attestation inclusion delay um usually it's zero now uh one thing we are concerned with is that um over time we see a drop of lighthouse clients while you know pure connection while teku and prism are stable also not related directly to nimbus but for everyone benefits as a team at blst very least a very significant improvement to the square root function which implies a benefit of 40 on the hash to g2 and uh since this is almost a third of uh verification uh this should translate to 15 per improvement uh for every clients using blst and uh that's it for me is that improvement in the latest release was it 0.3.1 uh or is that oh i'm putting a link right now this was released 16 hours ago super thank you very cool um lodestar hey uh so we finally um got our blst integration at the door um working closely with with their team uh they were very helpful we did something similar to a lot of the other teams where we can create a common interface between uh blst and harumi's ruby's library so we can use blst and node.js and harumi in the browser we're working on getting um the blst to compile to wasm of course it's not going to use the super fast assembly but we're very curious to see what the performance is going to be like between harumi compiled wasm and blst wasm so we'll keep everyone informed when we get some results on that uh other than that we did finally cut a release the day before maynet um i would say that let's start with experimental level robustness um we are we do have some nodes uh on mainnet and they're they're staying syncs there's some few performance issues that are still uh kind of plaguing us 100 cq usage verifying a bunch of aggregate improves but staying on the network um so yeah that's that's it for us cool and you're not attacked you don't have validators attached to those nodes right now no no yeah no no economic value attached to those notes we're gonna we need to do a lot more testing yeah um on piermont and other things so i suppose it's just an end user node you don't even need to listen to the aggregate improved channel although it it helps you in some like censorship resistance uh scenarios but you know it's probably worth listening to that channel to induce the load and figure out how to optimize it right right yeah just from a read-only kind of beacon node standing up to the head um seems pretty stable right now um cool congrats thanks let's do prism hey guys so yeah mainly lunged um before mainnet we were mostly working on our documentations many readiness fixing user reported bugs we have two or three patch release from that and yeah so thank you to our users and contributors for working with us on that and post mainnet for this week next week we'll be working on um import and export of validated client exchange format that's the number one priority right now which we don't support and in parallel we're working on with subjectivity sync from the checkpoint state and also working on implementing the e2 api and uh um that's it thanks great thank you let's do taku right that is me uh so we have released this uh weak subjectivity checkpoints inc feature so you can pass an initial state to teku via the cli and you can start your sync from there so um this is a great user experience win never mind the weak sub subjectivity side of things if you can get a recent state from a node that you know is reliable you can be up and running in under a minute so it's great for cold standby and stuff like that anyway meredith has made a great video that demos this and explains the long range attack issue very nicely which ought to be out soon so keep an eye out for that we've also implemented a historical sink that will backfill the blocks from genesis up to the initial state that you specify in other news we fixed an issue where our attestation sometimes failed on the first slot of an epoch on piermont it's a kind of race condition where we'd uh get the wrong source on occasion so the attestation doesn't get included um we have a remaining issue about delayed block production after epoch processing we're fixing this it doesn't affect mainnet at all at its current scale it seems to be just a scale of piermont that exposes this we also fixed an issue where we failed to gossip voluntary exits and slashings we now uh gossip both correctly um i'm aware of the conversations about gossiping slashings or not but we do that now by default and the main work in the last three or four days around mainnet launch has been finding ways to pull data more reliably from eth1 nodes on mainnet turns out it's very different from gurley there's lots of geth around on slow drives or limited resources we've had to work around nevermind and open ethereum not downloading chain history or not providing um the data in etheget block events so we're just finishing up the last testing of our fixes for that as a workaround we've been recommended to any users that have trouble just spending 10 minutes syncing up with infuria before switching over to their own eth1 node as the load is much lighter after the initial catch up um aside from small bug fixes and bits and pieces that's it from techy awesome great work uh i'm excited to see that video um and i i'll mention this in the networking video i know there's the open issue on exactly how to do backfill and sync and stuff if you're starting from that state um and i will take a look at i'll open that back up today and get it merged and lighthouse is there anyone from lighthouse here uh yeah cool they launched on main net as well and seem to be running okay and we will catch up with them later um and tomas you're joining us today do you have any updates on your end you'd like to share oh all good okay um research updates anybody have anything for us sorry sorry diane it takes me ages to to unlock the phone to be able to click okay like entering the passwords and searching the unmute uh no sorry i joined mostly to to hear about like was the follow-up the feedback what kind of problems you had with uh with ethereum one nerds so our ethereum two obviously is on hold and obviously congratulations to everyone as i said on the channels as well and yeah i'll just listen okay cool um is there any any particular uh comment you'd like to make about another mind in this context or any questions for tomas while we're here okay um i i do have a question so i saw on reddit that uh a full well uh a nevermind node that can be used to serve the f1 monitoring will only take 45 or 60 gigabytes that was in 2019 how much because uh since uh we target uh 100 gigabytes now okay so this this is still much better than gaff at 300 gigabytes uh or turbo f i think is also in the same range uh yeah for the minimal support so what you need for minimal support is the receipts uh since the deposit contract was deployed on ethereum one network so this is eleven million fifty thousand blocks so deco had this trouble because they were doing binary search where they had reasonable approach to just find that deployment of the contract by searching when it appears but if you hard code it then you know that you don't need any receipts from the past and what you need is just like 10 15 gigabytes of headers around 30 gigabytes of receipts from the recent history and 60 gigabytes of state and this is this is the absolute minimum to support uh ethereum too gotcha okay anything else here uh another mind eth1 syncing that kind of stuff before we move on is anyone working on a you know on infrastructure to remove the requirement for the e5 node where we have this this super light client that just um you know syncs the the headers and then we have an ad hoc um gossip network specifically for the deposits and the miracle associated miracle paths it would be just so much lighter than the current situation for validators a follow-up has anyone experienced experimented with using the les protocol the light protocol we were trying to implement less in another mind but obviously is this good question for for ethereum to clients so sorry the the beamsing client potentially can serve all your or your requests and it would be smaller in a way that it could go down to 40 gigs if we just beam sync to the to the recent state and download receipts and we are working on it for uh for rocky support and it also would work with ethereum too so you can actually go a bit below what we have now and with trinity team we working on the weakness protocol that actually they the beam sync can exchange information much faster with the nodes in the network so you can go below that as for the last client light client thinking if it requires receipts from the past and obviously it will be heavy download of the receipts you need to have it unless someone like delivers verifiable probable bundles of receipts historical receipts for ethereum to just for the deposit contract so this would be other approach to just be able to download those and get them verified maybe store them somewhere and and be able to trust that this is the correct bundle gotcha okay let's move on to some research updates short note about week subjectivity stuff there's a new week's objectivity calculation uh wherein the period also depends on the average validator balance there's a branch for it expected to get merged in the next release um on on a different note alex and i have been working on this slashing protection rebuild thing where um it well depend it uses a few different methods to rebuild the slashing protection interchange file we actually did not know that clients don't support uh v5 of the slashing interchange format yet but if there's any other nuances that we should know about please let us know it also uses the eth2 api so super important that clients support all of that infrastructure for software upwards in the stack uh other research updates um so i have a uh a couple of uh prs in progress and so there has been that light client one which uh i think well most most recently i saw xiaowei has been doing um a lot of work on trying to make it executable and uh i've been reviewing that just now the um second one is uh the incentive accounting reforms um so that is well i will just uh get the get the pr number for that right now at two one four zero um and the goal there is to basically um take some of these uh simplifications to rewards that we had in the big humongous phase one candidate and just move them over to a separate patch which could potentially be included much more quickly so the goal is to get rid of pending attestations and basically replace them with a midfield data structure um and this should simplify the spec increase efficiency of accounting things and also set the stage for things that i think would be good to do later but that i haven't uh well yet written the sp um written the specs for um which is basically there's a couple of uh kind of wish list items i have uh one is to redesign the spec a bit so that empty epochs and long strings of empty epochs don't have ofn per epoch processing time the second is reforming how the inactivity leak works and then the third is potentially using polynomial commitments or other magic to remove most of the marking overhead from the from epoch transitions uh so that stuff's longer term but like in addition to it just being like simplifying and making it and making it easier to add more incentives in the future that's another thing that this um pr is designed to kind of uh set the stage for in the long term uh so the pr exists um and i hope the yeah the longer term things i yeah um that i mentioned they all exist as kind of scattered issues as well but i'll probably um write a more con and and publish a more coherent document that just talks about all of that stuff quick comment there more implementation focused all or most clients are already optimizing the e-book transition in a way that's very similar where it first collects the stats data of all the validators of the previous two ebooks and then those other reward calculations um so this change there if the bit field may not actually actually be that big is looking at implementing that optimization uh to improve their ebook transition at times okay in that case you might even end up just simplifying the code by a lot because the the data structure that makes sense from an efficiency perspective would also just be the data structure that gets hashed great um any other updates um yes um the executable beacon chain proposal has been published uh thanks everybody for the great feedback uh there are some pain points um to address like walk hash issue some others and we'll keep working on them in the meantime um the prototyping is already in progress so soon likely soon we'll see the deck of client with one execution in it um guillaume is also working on dating catalyst um so the prototype is the goal is to implement and evaluate the core um the core proposal um yep and uh probably around a test that in the midterm that's it thanks michael other updates here one quick update is some some good news regarding blst so an optimization was found for doing square roots over extension fields and that means that the the hash to g2 is going to be 40 faster so quite a significant and nice optimization there yeah mommy uh mentioned that in the nimitz update maybe you were away from the computer which translates into a fifteen percent speed update on signature verification i think he's team as he said yeah because in my benchmarking um h2 g2 is uh one-third uh because you have h2g2 then pairing and uh it's one-third two-thirds uh in terms of proportions time spent okay cool yeah killer library thanks supernational um okay other updates here um yes um just very quickly can you hear me then yep okay uh we yeah with respect to the figures uh so that i showed last um last meeting we have uh written a document um kind of showing all the things we found uh and it relates to many of the things that we discussed at the beginning of this meeting so how clients perform during periods of non-vitality suffering finality when there is a long period of no blocks and this kind of things so i have shared this with some of you and i already got some feedback so thank you for those that give feedback um if not then we are always waiting and very happy to have feedback and if um somebody here didn't receive the document yet and you would be interested please contact me so that i will be happy to share it with you thanks a couple thanks anything else okay great uh networking um some of us have been discussing uh having a networking call next week to kind of catch up to speed on all the various things uh it's tentatively wednesday morning i'm going to look at the calendar and put it on the calendar right after this call um i know i mentioned earlier there's a standing pr uh with some comments that we still need to be addressed on um the subjectivity in the context of sync and and what is a good and bad node in this respect um and i will get to those comments today and hopefully we get that merge relatively soon are there any other pressing networking items people like to bring up right now otherwise we'll have a longer form conversation about a week okay yeah i would perhaps just repeat that it's good not to have very low peer settings overall that makes it difficult to find to form a suitable mesh on on all the attestation topics that we're supposed to subscribe to makes it harder to find clients and it kind of degrades the network performance in general so i'm hoping that users that listen to this just keep your max pairs settings reasonable and not something like 30 that will significantly degrade your at the station performance by reasonable i mean in the range of 70 80 100. gotcha um anything on networking before we won so about pairing um the rest distribution issue or kind of improvements we could make to connecting and onboarding is this where the client should not be strictly dilugating at the exact maximum of their bearing that either keep some buffer or some kind of elasticity to allow for new pairs to join them even then slowly rotating them out or handling this churn in some way or another that this would help on a kind of situation of mainnet where one or two client types make onboarding others rather difficult right so essentially allowing for elasticity on the upper end and then on some interval pruning down to a target number rather than having a hard limit at a target number okay uh anything else on networking before i move on great um general spec discussion any questions comments thoughts here um i mean if we wants to talk more about uh some of the things that i mentioned always happy to talk talk in more detail to this is around uh changes to incentive accounting and then up empty pocket optimizations and a couple of other types of optimizations um yeah any questions here for vitalik maybe i'll just like publish with a more readable all-in-one place document so people have something to refer to and we can also talk about those things that well although i didn't yeah i do think that we should start some of some of those discussion discussions as sooner rather than later as well and especially if we wants to um move toward having a um having some of these things in or in a yeah uh a hard fork in a fairly reasonable amount of time yeah agreed i mean i think if you get it into a digestive format people uh okay i won't do this um i have a question uh regarding the uh phase one and phase two spec well uh everything after phase zero uh what's the state of the uh the spec and the tests uh because will likely uh dedicate now people to those phases and we'd like to start with some low hanging fruit let's say right so the big things that are being in r d right now are the data availability sharding and merge spec both of which i think are going to probably spend the next four weeks doing some testing and refinement of the ideas at which point i think we'd start seeing them form into more concrete specs um on the date availability stuff uh there's kind of two components here there's a number of components here but um we'll likely be leveraging past lookups in a dht uh we'll be leveraging uh some new cryptography uh called kate commitments um and uh be needing to kind of manage additional validator duties and some extended uh beacon chain spec items um and block essentially managing blocks in parallel to the beacon chain um so before we can do for example the car tech commitments um we would need to push the bls library implementers to expose the group operations um we already have those they expose everything already um not last time i checked at least bls blst and tarumi and many others like they don't expose the basic operations they expose only the signing infrastructure um which is not enough actually if they do expose events fp fp2 fp6 fp12 g1 and g2 right right i mean the question is whether you can do like multiplications and additions in g1 and g2 that's the main thing you'll need yes we can and general pairings then then you can start but at least last time i checked with bls like plst i couldn't do it in python okay comments so it depends on the bindings what is exposed rumi and go exposes quite a lot but not quite everything and then beyonce in go is quite limited so the bindings are limited in the exposure but the underlying blt library isn't necessarily well no the library can do everything like you need to be able to do these things um but yeah like the question whether it's in the api i mean there are questions here around how to design the api to be to make the best use of the library because sometimes the binding you know can can have quite a bit of overhead and you want to minimize communication for example between the binding and the core but yeah that's a discussion we can push forward with supernational trying to design an api that makes sense and implement it for all the bindings um another thing to think about is that we are going to need um specific uh dls things optimized for like cad day-based data availability sampling probably the two most important ones are one is fast linear combinations i'm aka multi-exponentiations and the other one is the generate and proofs in uh and login time thing right i mean the latter one is like a specific thing that we'll have to implement ourselves i don't think we'll be part of a bls library but the former i mean it's so general and like any xero knowledge proof system will need this so yeah we should prioritize this somehow um for the former um i've talked with the guy at blst and they were already looking into that six months is ago uh or even beyond so this is uh one of a priority right and and they they've been working on what they call zk blst which i guess is vlst for these linear combinations for the stocks i guess it's a matter of finishing the work polishing it and publishing it but they have done a lot of the heavy lifting in terms of finding the best multi-exponentiation algorithms depending on the size of the multi-exponentiation because it turns out if you're doing small medium or large it's a totally different algorithm that's optimal for these linear combinations um okay i think maybe in the next couple weeks we'll spend some time sharing resources and things with client teams uh so we can kind of come to a plan to begin to be effective on these things in the new year um we're not quite in spec mode but there are going to be components i think that would be valuable and some of the teams might be able to help with some of the the r d on these efforts over the next few months i mean in terms of low hanging fruit to answer the question i think that like client is probably the most low hanging fruit in terms of being easy to implement you know and also being like relevant for the first fork that we intend to do yeah absolutely um there's a pr right up up right now if your team wants to review it that not only has the slight modifications to the beacon chain but has the discussion of the like client sync protocol so an implementation of that early implementation i think be really valuable agreed okay um anything else here on spec discussion okay um general discussion open discussion closing remarks anything else people like to discuss today okay cool sorry i'm distracted by the stuff in the chat uh it does look like someone was scammed and people are upset and um that's very unfortunate um okay cool thank you everyone uh congratulations again on the launch uh stay diligent on monitoring a test net and we will talk soon take care everyone bye thanks for watching thank you thank you [Music] bye [Music] [Music] [Music] you 