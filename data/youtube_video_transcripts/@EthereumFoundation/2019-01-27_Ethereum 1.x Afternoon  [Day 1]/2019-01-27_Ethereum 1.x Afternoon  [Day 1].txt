okay for real this time final final announcement coffee will be here at 2:30 all right everybody listen up Alexi is brewing his presentation now okay so thank you very much Hudson so I'm going to just first go through the old and new materials so that in the later iterations we're gonna just repeat what we said before but with modifications so I want to introduce to the recent so state rent two proposals which is the iteration of the from the first one and it's based on various things is on the first one of some on a framework it based on some discussions with lots of people and some proof of concept which has been done by Adrian from Pegasus team from some fun Locke proposals and stuff like that so main differences are if you if you're seen the first proposal it had this thing called a linear cross contract storage this has now been removed because we currently believe that we can emulate it by using the new create two up code which supposed to happen in Constantinople and I also published the the example of the smart contract which implements that approach for our ERC 20 tokens and so then the priority queue for eviction has been removed so the main reason why it was there in the first place is because - or not so my idea was not to give minors any extra powers more than they have at the moment so one of the power we do give them here sleep to control the eviction so but I got myself convinced that we it's okay to give them that power because of the sort of censorship resistance of aetherium which was discovered in 2016 after the soft attempted soft work on after the DAO attack so then another another changes that we are introducing the calculation of the storage size before and not after not during the introduction of rent and so then there's a lock ups which I will look into further so and then we only discuss in temporal protection here and the rent price is fixed in this proposal you know not floating as in one before but we can introduce the floating one if it's really necessary so this proposal was also organized the previous one had six steps but this one is more of the dependency graph and so this diagram is essentially outlining what these changes could be from A to M and their dependencies explained here so they the solid line shows what has to happen in two distinct hard Forks and the dashed lines is something which could happen in one hard work so we just discussed it in in the breakout session like what could be potential potential division into the forks so like how quickly can we do this and so if we really really push it so in the first photo you got obviously two easy changes and then you got up to the rent on the counts and the eviction of dust so after the second hard work we would see some improvements in the state size by getting the dust account removed that's the country moved we also introduced the state law caps you see on the bottom the change II which means that we start penalizing the expansion of the storage and so in the third hard fork we introduce rent on the storage and contract storage and also eviction and recovery of contracts so now I present the eviction and recovery contracts together so that because there was a lot of questions about what happens to their contracts which were removed but by mistake and so here they this comes as a single package and then the KL and M other like this little leaves which are they sort of auxiliary functions to to smooth out some rough edges of the of this whole thing so let's see that so just to quickly remind you why we needed for your play protection so in the one of the changes is essentially eviction of the dust accounts by dust account we mean that the the known contract account which has zero balance and so it's if we remove those things then the problem is that when this account gets recreated by sending some east to it then the nones gets reset to zero and previously rather transactions still become valid so the this this change has been proposed by by Martin from go-go is theorem team team so it basically means that we we're adding an optional field into transaction which is called valid until and so the users will be in charge of protecting themselves so this transaction will only last for like three something like minutes or whatever they do you and so in the first change it's in change a it's optional so that gives the the ecosystem the time to get used to this change implemented and things like this so in the change B it becomes mandatory and so that everybody has to start thinking about what they're gonna put in there they can put an infinite amount if they want to all behavior but essentially they will be forced to choose the value and if they choose the value such that the validity is before the eviction then they will be protected from replay so there was other proposals which were based on the change in unknowns after the account is recreated there are some advantages and disadvantages of this but for the concreteness I just left this proposal in in here so change see is that so what I call the net contract size accounting so for the things like lockups and for the rent we require to have access to the accurate number of storage items which exist within the contract which we don't have now in the in the protocol so introduction of such a account needs to be done in two stages because they did the the because of the blockchain keeps moving we cannot simply introduce it from a certain block so we first introduced in the net accounting where each store now starts increasing the counter when the the item is allocated and decreasing the counter when it's D allocated and then in and so this year we introduced something like a huge number so the reason why we need this huge number first of all we we don't want to have a storage size as a the signed integer we want it unsigned but the second reason is that later on we want to distinguish between the contracts where the storage size hasn't been even introduced because the contract who hasn't been modified and the cases where it has been would have modified then the the the the accurate contract size has been introduced so I think I'm not going to go into the much details of here is just I will show you what the contract were to change D means so when we go from a net to gross accounting of the size so essentially because we split into two changes so in in Block C we start net accounting and then we know that everything after Block C is now accounted so all the only thing we need to do to get the accurate count is to take the sizes at the Block C and this is what we can we can then do it because then we can compute it offline and in we included in every client implementation what was the size of each contract at the time C and then by by adding these two together the net count and the gross count at at a time see we get an accurate account dynamically and a huge number here is is used to as I said to be able to use sign unsigned integers also to distinguish different cases and the important bit here is about observable storage size which will be used later on so when we so we try to not introduce any more transaction churn here so we we do not increase number of modifications of the state simply for the sake of the accounting so they so the storage size is only introduced or changed when there's other reasons to modify the account so that's why we need this notion of what what is the observed value because if there is an account if there is a contract which never changed after the Block C we still want to see the correct size of it so if this is the observability rules which also include this huge number so in change eb introduced the storage lockups so the idea of the lockups is a we wouldn't introduce it if we were starting from scratch if we didn't have any existing contracts if we simply had zero nothing like in theorem 2.0 you probably would just simply introduce rent but because we have some contracts in the state that some people might want to keep using without necessarily rewriting them completely so we give them that option although I personally think they would still rewrite them anyway but this is actually also applies to recovery I think that these features we only need there to give people the option but but given the the cost they will probably decide to start from scratch anyway so what the lockups do essentially I know that Andre doesn't like this analogy but imagine that each contract is the is kind of like a glass weight one item is is like one centimeter long and so when your so the size of that glass the height of this glasses is that is the storage size and then what you do is that you can increase that size or decrease it by free and storage or increasing the storage but you also have to pour some water in it in it so pouring increasing the size of the glass requires to pouring a little bit of water like to fill it up so for the new contracts it means that whenever you add to the contract storage but you always have to fill it up so you basically have to keep it full we keep this glass always full so when you reduce the size of the glass the excess water gets back to you so you can release those funds imagine that the liquid is actually the funds and but but in the case where you had the accounts which were full previously so let's say after we introduced the lockups we had some accounts which were basically like empty glasses before so what would you gonna do with those well we were introduced in the rules where we're so when somebody changes the value inside even without changing the size they still have to contribute a little bit of liquid in it so eventually if the contract is used a lot then they will eventually fill it up and after that it will behave as just as the other the new contract but if nobody cares about that account so if nobody cares about that contract and they just nobody fills it up it will be eaten by it will be eaten by the rent and will be reclaimed very quickly so you might if anybody read the proposal a IP 1283 which was supposed to be included in constantinople but it wasn't it was actually very similar semantics of this change was very similar to what i'm going to describe and here the semantic assessed or depends on the the three values original current ana new or value so original is the is the value of the storage item before the trans personal transaction happened current is the value of the storage item before this store operation happened and value is what we're trying to set and without the loss of generality we can only think about 0 1 & 2 where 1 & 2 are any values which are kind of distinct from each other in this case you can think about there's only 27 possible combinations of these things and you can describe for all the 27 combinations what the semantics should be and then you will be sure that you completely describe it but actually it is even easier than that so when we describe this state transition we will just think about four different states something i call ground state we can like green thing is when we allocated new storage so we went from 0 to 1 or 2 or we can have a removed storage item where we can't go from 1 1 & 2 to 0 or we can have something which just changed the values which is the orange one and so the so each state transition is essentially going to be the arrow that goes from one of these circles to another circle so for example we go from the ground state to the green state which means that we are located a new new value or and so how we decide where the the arrow starts and where it ends it's very simple table here so the the the place where the arrow starts only big deep two things an original and current and then using this table you can figure it out and in the same exact table but are you looking at two values of original and new value you can figure out where the value of the whether the arrow points to and so for example these are the the three examples of regional current and value and what are the state transitions so so what I'm trying to say here is it's very easy to describe and you don't actually need to seven to twenty seven possible variations but much fewer than that because so here you've got nine and nine I think eighteen or something and so here as I just described you because with the analogy of the glass we what you feel with the water so you either have a glass which is already full and this is the the case number two and the case where the glass is half-empty which is the case number one and the reason why it's important is that for the for the half-empty glass where the contract existed before the lockups it's still been filled up so the the current users have to pay for the preview prove the previous users who didn√≠t need did not need to do the lockups essentially that's is the cost you pay for you know like if the contract is really important and the current users are prepared to do that then it's fine and we just let it go and then if the contract is new or it's already been filled up by the users then it behaves this way so whenever you go you create a new item it releases some of the some of the easier to the TX origin where you go the green spot or if you were sorry with the red spot or where you go to the green spot where you allocate item you have to look something up but in the case of the full glass the semantics is a bit different so your for example when you free up the item it doesn't give you back the ether it just keeps it so it's kind of more greedy and then when you change the value or add a new value it will take Easter for you anyway so even if you're you're basically changing somebody else's value so this particular thing removes the the possibility of dust attack does talking attacks for example because it's so what a furlough cop is introduced that it does there's no point of adding the that the storage to anybody's contract and I was explaining why later on so here's the example of let's say that we are in the glass in a half-full glass and that was original equals one current equals to Val equals one and so we can figure out the transition and and looking at the rules before we can figure out what the semantics should be in this case so and what I want to say here is that you might have noticed that I didn't try to piggyback on the gas here because that's probably one of the intuitively one of the first thing you want to do is like oh well can't you just use the gas mechanisms for that well the problem is that the gas behaves differently from lockups so when transactions revert the gas still gets spent it doesn't get refunded but with the lockups and with the releases they need to be reverted when the transaction is reverted right for example if you you don't want to release ether if transaction is reverted because you didn't actually free the storage and in the same in the same way that if you created a new storage and then you didn't because it was reverted you shouldn't really take this or from from a person but it introduces some safety problem I think because now it might the amount of ether that will be deducted from TX origin is only limited by potential number of s stores it can do in a transaction and this balance so we might need to introduce a new field and in a transaction to say like this is how the maximum lookups I am prepared to do I haven't put in proposals yet because this this kind of was a bit late late thought so then proposal number so then F is a fixed rent on accounts so in a previous version of statement proposal we were only introducing it on the contract accounts but here I'm introducing it for all both contracts and the non contract accounts just rent important bit is no eviction here just rent so I separated eviction from the rent in all cases because they so what the rent allows you to do is simply to reduce the balance but doesn't doesn't decide whether the account will be removed or not and so here in order to to to support this we need to constant account rent is how much you charge for one account per block and the code rent is how much you charge per one byte of quote per block and this could be this would be different values because the code is kind of more stable and it probably it probably doesn't cause as much performance issues as the as they account itself and obviously pre-compose are exempt for some of these reasons so this is how it works so this is how the so whenever the account any account gets modified it recalculates the rent balance and ran block and potentially also reduces the balance but this particular operation does not evict so this is only the reducing the potentially reducing the balance or rent balance and another important piece here is that the rent balance could become negative right as a result of this so if there's no more balance left you just go basically start accumulating negative rent balance but because this change doesn't include eviction you know it's just gonna be run negative rent balance so then during the proof-of-concept implementation adrian figured out that there's something needs to be clarified where exactly the calculation of rent happens and then i looked at the yellow paper and then it states that during the block finalization there's this four things happening and illogically i concluded that the rent calculation should happen before between three and four and because in after four it's too late because this is where we recalculate the state route and by that we need to finish all the modifications and before the three it's too early because the potential rewards can prevent you can change the the rent calculations so so basically have to do it before three so after three but before four so then after we've done with rent so we can introduce the eviction so here we only in this particular change we only evict non contracts and again this has been asked by the proof-of-concept to clarify what do you mean by non contract accounts and C's here I'm clarifying this is the specific code hash and if the code hash is equals that and a balance equals zero way then it it's it's deemed to be dust account and will be evicted as a result of this change and this is how it happens so the eviction check is performed at the end of transaction for all the accounts that were touched during this transaction not necessarily modified by touched by touching means that you read their balance or you try to send zero ether to it so then this account is touched so in the end of the transaction you have this loop which goes through all touched account and figures out whether they need to be evicted so if the if the account is not going to be evicted then it's not modified so this this is why in this diagram we don't modify any actually I need to fix this because I think this this implies that the rent balance in rent block is modified but actually I need to create a that's a good point so essentially the thing is that it does not introduce the change unless the county's it gets evicted so then change H is where we start charging the rent for the storage and as I so now you would understand why I had needed lockups for the existing accounts because the rent is actually charged not on the entire storage size but on difference between storage size and lockups so it means that if the lockups equals storage size then there's no rent on storage the only rent will be charged in this cases for actual account and the code so which means that any new account new contracts created after lookups will pay constant constant rent and but everywhere of all the empty contracts which existed before and nobody cares about they will pay a rent on a full storage size and they will be evicted pretty quickly but it is possible if somebody really cares about their contracts they can fill them up with their ether and prevent them from being kind of very quickly decayed and again we need to introduce the third constant here for the storage so yeah it changes the formula about how to calculate the rent due and this also come from a proof of concept that we need to specify here that the value of storage size lookups and code size need to be taken at the beginning of the current block because otherwise you will be overcharging or under charging so because because basically the calculation of rent only happens when an account is modified so it could be like for last hundred blocks it has not been modified so now it's finally modified and you need to calculate the rent you shouldn't be calculating it on something which is currently there so you need to say what was the state of the beginning of the block and this is going to be the determining the charge for the last hundred blocks and this is where I refer to the notion as observability of which describe didn't change d so now we come into the eviction and recovery of the contracts so this was basically copy pasted from the previous proposal it doesn't really change a lot so the only thing which came up with the proof of concept is that we need to clearly define how distinguish hash stubs from the contracts themselves it's possible to do but it needs to I haven't clarified it yet but but it's possible to do so that's what I was going to say and this is the graphical representation of how the restoration works and so the main idea here is that so when you plan to restore the your account so your contract for example zoo multi-sig that the sudden LED accidentally got evicted so you need to figure out what was it storage like at the time of eviction recreate it the same exact storage in the new contract you because you can code up the new contract the way that you simply accept the storage item from a certain account so you recreate the storage items then you create a second contract which will contain exactly the same code as there is the the one that you need it so essentially you need two new contracts one of them will contain the exactly same storages that you're ready to contract had the second one who had exactly the same code that your evicted a contract had and then you call this thing called restore - and it basically merges them together and restores your contract at the same address as it used to be so the reason why it has to be this way because because your your contract which is evicted could be quite large it wouldn't be possible to push all the storage in one transaction so you might need to be able to do it over course of many transactions so that then you can do it in one go there are some edge cases here but for example this particular opcode would require a calculation of storage storage root within in transactions which we haven't done before so then this is the the cofee thing so I mean it's also copy/paste from the previous proposals this is for the potential library contract which will so if nobody is looking after them and they want to charge for their own existence so they can introduce this call fee which is if it's a popular library that everybody is calling they might be able to kind of immortalize themselves if they charge a small amount of ease for each or to each color and that the important bit is that this charge doesn't go to the balance but to the rent balance so it cannot be recovered it can only be used to prolong the life of this contract and and so eventually you can this contract can collect enough rent to last for a hundred years or something like that and then everybody will be sure that this is gonna be there forever practically and then last oh no actually the second-last is that if you have a if you have a contract which doesn't have any way of accepting easter but you still wanted to keep it around so you can add the easter directly to their rent balance rather than to the balance by using this new up code and the last one big after we've introduced the lockups the locals basically give much more straightforward and better reward for the clear in storage and and if we also so basically we can remove the storage refunds at all and if you if you if you decide to go even further and then say remove the refund for the for the service truck then we can just completely remove the concept of refund altogether which just simplified the protocol the end of it thank you very much all right do we have another group that wants to go next yeah all right grow it a head if you need help getting set up just holler I just won - hi King Arthur Murray so just a quick rundown of food what we're working on code name of sakala we're building a light client for primarily browsers and environments we reduce networking capabilities and resources in general so it's built around this concept of slices which are sub trees of the Merkel sea storage and and storage as well in a state then we have a movie called internet which is a network of flight clients seed that say they also traditional my clients right now at least they connect to a node and download what they need but our idea is to actually see that's the across the white lines themselves it relies on on full nodes to provide access to the state so there's gonna be some are bicycles to retrieve State so what are slices again they're their miracle sub trees they consist of some parts I can you can show that in a minute but basically it's the three nodes the branch nodes and the Leafs which are the counts there's a VM code in there as well and and the stem and the cool thing is that we can identify them by we call the stamp pad and the depth which is basically the four navels of a key in the in the merkel pressure tree and then the depth identifies how how large that chunk is going to be and we can also use the stage or the storage root to uniquely identify a slice so we can we can use just the stem path and the depth chart of the four enables and like the Deaf it could be anything ten for example oh sure the yes so so we can identify the slice by the stem pad and depth which basically allows us to grab it grab it and then if you have something like pops up or multi-class or something like that you can use those as identifiers to to create subscriptions and then you can near-real-time this could propagate changes to to some subset of those of those slices the kids on that network is the lifeline network itself it's again p2p notes they see this state across across this disc lines build with lip to be a sure that people know this but it basically allows you to run peer-to-peer ordinate so some semblance of peer-to-peer in a browser again we're using the pops up for for near real-time data propagation right now there's up which is what's available on only p2p but work is being done on creating something a little bit more performant and yeah so again I kind of touched on that already data propagation is being built on top of pops up slices can be identified and can be grouped they can be created as topics note subscribe to those topics and they get updates as soon as the new block is generated there's a slides me and extract it and propagated for the network a client is only interested in on a subset of this of the slices which are they can be based on user account the sum of the absence the tokens that are being interacted with and then we can also take advantage of a large amount of this discounts in the network and basically say well you know if a client can dedicate 20 30 50 megabytes to store a portion of the of the miracle state then if we have a million clients then we can we can provide you know several fold redundancy in the network so and we basically arbitrarily assign slices to clients based on their on their ID and some notion of distance so security is basically it's based around I was the proof of work we get a header we get verify the seal we can as long as we have we can base it around some some notion of checkpoint and if the for example we can talk though the checkpoint in the client itself and distribute it update clients every every now and then an update that check when basically week we can use in this checkpoint we can we can guarantee that the slices we're extracting are are correct because they're based on the state or the storage hood so they're basically time-stamped and yeah so it's basically slices which are so please take it's a net network peer-to-peer notes that currently use bumps up as a protocol to distributed slices and fill notes that are being that are being added to methods in order to retrieve this thing and that's pretty much it so we're very interested in knowing what are the changes that are coming to to state management on pruning cetera et cetera because obviously it's gonna it's gonna affect this questions thank you so much anyone want to go next presentations that's a good idea is that wasum team if we do like a QA yeah so we have a couple microphones that I'll grab we'll start you'll be the first question yeah I actually have them I have a presentation to go with it with it so I hope you don't mind if we use it to get some visual material with it because some of my questions are based on that so we can just keep the slide on one second I know I just gonna use this one but but I just wanted to have something on the screen so we're I mean I hope we're gonna my questions will be along these four lines so I'm gonna read out for you so when I was trying to describe the Hossam group to other people and obviously I was a bit short of time and I just put I call them an unresolved questions right and there's four of them gas metering memory allocation interaction with the rest of the EDM state and interpreter compiler guarantees and so what I would like to do is that I would like to just go through four of them and ask what is your current state opinions and what are the potential ways of doing it so let's start with the gas metering I'm not going to read out of the slide but I just give you comments on that and maybe describe what you're thinking you're a good microphone okay maybe the slide just tell me if this isn't correct or anything like that all right yeah so I would explain to the audience so that as far as an understand from the last time the there were two different methods of duty and gas metering in the azam in first is the injection and the second is the upper bound estimation so injection means that you're adding some extra register in the code and it gets incremented by jumps and calls and then there's an out of gas check and then there's an automatic upper bound is that you're doing some static analysis so is it the correct description yes there should be a third one what is the third one exact not upper bound but exact calculations so you have no matter what the input the gas calculation is a function of the input in the current states that might be intractable for a lot of contracts but it might be reasonable for pre compiles but yes the whole question of metering is a very interesting one obviously pre-compiled zanoits I'm contracts have to be metered you have to pay gas for them currently its benchmark based and yes the injection way so this is one level currently like EVM excuse opcodes and each opcode uses some guess we have an optimization I don't know if it's the best one but at each basic block which means a block of app codes that will they're at guaranteed to execute in sequence there's no branches into or out of that block before it we inject some code that says you know we count the gas used by that block and then we inject some code into the web assembly to use that amount of gas at the beginning of the block that's what injection means and the automatic upper bound my understanding of it may be your your my interpretation of it is a little different means we you give us an awesome contract and we give you an upper bound of the gas use Viper has something like this already but Viper is in a touring machine and this is sort of a halting problem we don't even know if you if you give me an e you awesome contract I have no way to tell you is it going to halt yeah so it only is that's why I said for the the cone the cones is only subset of codes will be you will be able to do this estimation yes so we would have to restrict things and the other one would be even worse because the number of paths through a given contract can just branch you know exponentially so so only for certain contracts we can do it but it's hopeless in the generic case we would like to do the upper bound estimation for pre compiles but there's a problem because the input of hash for example hash functions can be arbitrarily long well obviously limited by guess or whatever so it's not an upper bound you know the upper bound of the max we don't want to charge it for everyone so we want to make it a function of the input size yes this is is there a specific question or are you asking us it's no just asking about what does your current prefer preferred path that you're exploring it's just kind of revealed to us what is the what do you think you're going to be doing for precompile Zin in a Phase one current prototype is not a program like this is what we want to have but we're still working on it so the current situation is to just do what regularly was in precompile our so you have a fixed fixed gas like get charged a fixed amount and then depending on the input size you add something but it's really arbitrary okay so essentially doing the same sort of work that was done for the compilers in Byzantium yeah so I'll add a pro to number two the upper bound estimation is then the gas rule is simple enough that clients can implement the pre compiles natively and if with the first option the gas rule is very complex and it basically would make it impossible for clients to implement the pre-compile natively so they would have to import a web assembly engine but if we can extract an upper bound for the gas rules then it gives clients the option to implement them natively like like a past pre compiles like the existing free compiles anybody else have a question about this from the audience or because I have got another three questions I thought I would share an observation I had these guys are the ye Hwa's of experts I just have a lot of background and processors and is a so I thought I would join that group today and I thought a useful point that I learned from that in maybe it's obvious to everybody here but I thought I would just say it in case it wasn't that the phase one when they say pre compiles I thought that there might have been some implication of the wasum system being you know required to be embedded in client flows as a result of them being part of pre compiles but the way to think about phase one I believe I should just say here is that like right now pre compiles people specify the algorithm in a pre compiled in a fairly generic way with no requirement from an EIP standpoint of like how you specify what the what is being what is inside of that pre compiled contract so phase one in a sense one of the things that we should think about as a community is you know phase one is not requiring death or parity or anybody else to actually implement any given wasum compiler phase one is about actually saying any new pre compiles must include as part of their VIP process that they will have a full wasum implementation and that full wasum implementation will allow a gasps mechanism to actually measure the computational cost so that it's calculated automatically by the community rather than being chosen arbitrarily and it will allow there to start being the idea that clients could actually people who are creating clients don't have to actually use any walls and whatsoever they can from first principles just look at the Oise encode like they look at a formal description of an algorithm and then recoded in go or recode it and rust or java or whatever or they could try to use some wasum system to actually help them with the compiling effort and so that's maybe helpful in this gas metering to understand this first phase is really about specifying an algorithm that people can under - you know have that gas being picked automatically anybody a lot of helpful comment I won't make others like that if that's not anybody else have a question yeah or we can we can return to that if I like I just wanted to go through the second one the memory allocation so when I read that I wasn't sort of not specification actually I just read some Doc's about was and when I noticed that it specifies that there's ACOTA so wasum has a linear memory and at the moment in a in the first version there's only one linear memory and it could be grown on demand but it's basically consecutive sort of items in memory so my question is that so how we're gonna handle this in in Eva's amenge in' included into the UAE vm so is it going to be allocated every time we call the engine and then discarded after the call or is it going to persist between the call somehow so what are what is your current thinking and if it's actually if it's allocated in turndown how is this going to be more performant then could it actually could it be more performant than EVM because this is exactly what EVM does at the moment at the core so what's your kind of thing you know not anybody torn down I mean you can zero it out there's a third option you can zero it out as well because there's garbage left over from the previous run and maybe you did some previous run that it didn't end up being used so you would have to save this old stuff anyway so maybe zeroing out I think it makes sense to either zero out or to give a fresh chunk of memory that's what we're doing currently in a test net it's all fresh each time and do you think it might be like a bottleneck in the future maybe like is your optimized older older like your compilation and everything could this be kind of remaining bottleneck or the amazing engine yeah of course this is a bottleneck of any engine in anything everyone's gonna have the same problem I think it has to get zeroed out otherwise you run a risk of spectra like attacks you can just overflow or do something and then all of a sudden you might have access to code to execute on somebody else's account and it might if everyone's running the same system it might just cause problem that way anybody wants to ask a question and comment or I mean I'm gonna shut up after arts ask for my questions so don't worry about it so I mean am i correct let me just ask your question so I mean assuming that there are memory instances and they get zeroed out there's no I mean it would be part of a you know used up memory spaces would go back into a pool get zeroed and then get dynamically allocated another uoit's and calls so it's not like it would be statically assigned for in any way so I mean that's not very high performance overhead at all I mean that's how all network processes you know almost any kind of process like that my I mean sorry just to say yeah the operating system will do most of the pooling anyway so yeah my other comment was depending on how often the pre-compiled gets called it may not be a bottleneck because how many precompose get called one after the other right now probably very few right so I'm not sure actually we're discussing a precompiled like memory allocation in pre-compiled yeah exactly I just wanted to make a quick point regarding the specter attacks that any kind of cache timing attack or side-channel attacks in general depend heavily on things like real time high clocks being available and that's not going to be part of the evolving semantics this should not be a concern for us and in other points about the performance implications there we're still navigating through the performance differences between web with so many interpreters and compilers engines so until we you know make that leap to where we're dealing with compiler engines then the this is a very issues this is margin number four so the question number three is that so interaction with the EVM state so essentially as I read some really old I think you've uh some proposals and there in order to say when you're running inside the e azam code and then you need to access some of the EVM state some mysterium state then you would have some kind of external functions declared so this is not the actual function which was declared but I just was too lazy to look it up so essentially they imagine that is a sanction which allows you to do some sort of s load and then delivers pulls something out of the serum state and delivers into the EVAs in context so alternative approach would be to not allow any of the state access from within the USM code but simply provided as the argument so essentially like anything you want to tell the USM code about the state you have to push it in as input and anything you want to modify after that you have to take it out of the output and put it in storage yourself but this of course makes it's difficult or impossible to use even for maintaining large persistent structures like if you want to implement like say red black tree with Eva zoom then you would have a problem here because you would have to first decide what to push in as the input but then by that time you already read or wrote most of the red black tree algorithm so so what is your current thinking on that so I read the spec the webassembly spec I implemented it I'm implementing it again now and I can tell you that having exchanged inputs and outputs would be difficult the outputs would be difficult because the output is limited to one value there's a proposal to the webassembly spec to allow arbitrary number of return values but they're still on their first version they just want to make it as simple as possible for now so the output will be a will hinder it but certainly we can branch you know we can fork the spec and return arbitrary many values and hopefully the webassembly spec will catch up to us this is one of many questions that you know should we fork the spec or should we not and for now we're not forking the spec but as the input also an issue is we can only have a the at at static you know at compile time at deploy time you know exactly how many arguments there there are gonna be so this would only work for fixed number of arguments certainly you know if you have a 256 bit value you would have 460 64-bit integers or whatever so you would have to you know do it like that right now we're not doing anything like that we are we do have arguments okay so when you call in a contract it's all just called data we're just mimicking EVM right now but certainly it's possible you and I have talked about this a number of times that this we would instead of contract calls we would have you love assembly function calls with arguments and things like this and that's that might be faster than having to you know get called data size get you know call data you know move you know things into memory bring it bring it into our stack things like this so this is a bottleneck this is one of the sort of micro optimizations that I think we're putting off a little bit but it's a very good point and I yeah it's it's very interesting that yeah so your current thinking is actually doing this to this kind of way where external function can reach into the state right and then how the task networks you know what's one of the interesting part of the the whole wasn't model is the way you import dependence is how you import modules and one of the things you can do is actually either share an entire memory with all your your modules or you can import memory from from other modules so when one of the things we're looking at is but it would also depend how storage happens would be to do some sort of a map memory mapping and then yeah this is incidentally this is what I was one of my kind of inspiration when I was proposing a linear cross contrast storage right I was hoping to get it closer integrated with he wasn't but I think yeah would go rid of this so in my last question for now yeah this one so this is about the interpreter compiler guarantees I remember I first learned about it when I talked to some of you in Prague at that so essentially there was you probably heard a lot of discussion about just-in-time compilers essentially not being suitable for the for the for the things that we want but I want to get your current thinking about I remember we discussed that in phase one we want we potentially want to just implement what I call like a dummy dump oh sorry no dummy dumb straightforward interpreter which basically implements the classification one-to-one and then we put it into the put it into cerium and then we have a motivation to work on more sophisticated interpret interpreters compilers and things like this so your current thoughts on that yeah so very good you're exactly correct that okay could I just add a comments it's not jits it's not just in time compilers there are their problem it's optimizing compilers that artha problem so it's it's not that it's doing it just in time it's that it's trying to apply some optimization algorithm that is attackable but there are actually a number of jets that are not optimising compiler so they are just linearly scanning across them that might work pretty well yeah that's exactly correct Firefox has a linear Pass compiler where it linear linearly passes through the code one time and it compiles it it's usually 2 times slower than the optimized code yeah you're right that there could be we call it a JIT bombe you give it a web assembly module and it takes a long time perhaps quadratic this was the v8 one he used to used to do this where it the intermediate representation was some sort of directed graph that had cycles for each loops and then if you had a lot of nested loops and a lot of nest control flow it would have this sort of exponential growth in in the compiled time so there were these pathological examples that took a very long time to compile in v8 thankfully v8 shifted away from this and they they have now they have two compilers they have their base line which is a single pass and then they have their optimizing one first they let the base line compile it so they can start running and then they have the optimizing one working in the background and then they swap it eventually yes it's very important as you're saying not to have these sort of JIT bombs or compiler bombs ahead of time compilers usually have linear passes and you have some optimization levels that take all these you know a certain number of bounded number but certainly some code compiles faster than others so I think the part of my question is that I remember somebody mention it to me in Prague that are essentially at that point there were no existing compilers that would give you the guarantees that we want sofirst guarantees in a compilation time and second guarantees that the product or the product of a compilation will also not be more mobile like will not be exploding and so that is when I suggested the idea of if we have to write the compilers ourselves eventually because if there's no good compilers around we have to write it ourselves but in order to be able to find the motivation to do this work we have to make it more certain that this compiler with this work will be useful so that's why that's one of the reasons I really wanted you wasn't to be part of this kind of initiative that we want to put it in so that you know if for other reasons is always as I see it as a Manta feature as opposed to their point features and so but it will also even if we put some really kind of slow interpreter a compiler in and it doesn't actually give you any any benefits but then this particular event motivates the work on a compilers which we could be performed by also to range of people but they will know that they work will be rewarded not like the monetary and necessarily but in terms of so you know you're the result of their work will be in the cerium yeah this this this goes into the question of auditing verification and certainly we have and we have a hundred fifty page web assembly specification it's written down I submitted some fixes to it so there are still some sort of typos and still some things being worked out in the web assembly expect but it's good it's it's it's good from what I've seen and certainly I interpreted their what they wrote on paper and when I was writing my interpretation my implementation of the of the spec maybe there was a bug maybe I interpreted something wrong and maybe one of these compilers interpreted something wrong and someone knows of this edge case one person that knows one that you know one bug in one engine can sort of forth in that work this is a big risk and when they were writing it you know the Firefox engineer maybe wasn't concerned about consensus they knew that they can eventually you know push a some sort of fix in the next version but we are concerned with consensus so I think yeah I think the point is it's reason I think it would be reasonable to you know when they submit the NIST the crypto stuff to NIST they have implementations reference implementations usually in C and they have some of them are verified so I think it would be reasonable to at the very least audit the implementations and it would be better if we can verify them maybe have a computer check our proofs that in fact this spec was implemented in this code and you know a C expert knows that you know over of signed integers is undefined behavior and see so we need some flag for certain things so everything is language specific but auditing definitely I think we need it verification would be great another option is redundancy so one person would run multiple implementations so we would have you know these these three compilers on one machine executing the code and you'd have a best n of em you know if if n of them agree then then there's some threshold so there might be some sort of or they might if there's some disagreement you don't include that transaction these kinds of ideas yes I think to start your rights let's motivate people that we need therefore we need audited verified compilers do we trust the existing ones maybe but yes I think this is very important this I think this is thank you for selling I've been trying to convince my colleagues of this point so thank you very much alexei so there this is end of my questions any more people want to I have one other comment I wanted to say on this one here alexei cuz this was a good point we didn't discuss this at all when we were just having our breakout session here I kind of wish we did this looks to me like this pretty heavily interacts with the gas metering question I just say that from the perspective of like whether it's a jet or even more and like phase two what Alexei is saying here on the ahead of time compiler I mean there's you know doing any compilation step is an investment in time now with the assumption that you're gonna run that code enough times to recoup that cost and more over time and so you know I think there should be a consideration of in the gas cost model I mean if you're going to do a compilation step there's a cost associated with that maybe you know the assumption is you do it every single time for simplicity but maybe you also if you knew it's just throw throw away code for one time and you don't want to do the compilation you just run it in an interpreter mode and yeah and the other comment was the JIT I think somebody over here made the comment that it's optimizing compilers that can get into really hairy situation to spending a lot of time crunching an optimization the goal on the assembly I'm hoping with the you Azam right is that we're trying to make it a very simple mapping from that to is ace right so there should not be optimizing steps to some degree if we actually talk about the cost of compilation that's such a metric for what the compiler is assuming it's going to be spending in its time to you know generate that um you know generate that machine level code as well so my question is this slide right now suggest that indeed compilers optimizing is a fundamentally more dangerous problem than a ahead of time compilation but isn't it more or less symmetric like you can you like it right now suggests that you cannot have a secure ahead of time compiler but if you use the same linear passes then ahead of time up to a compiler would work just as well as the JIT compiler right I think I just make sure we're all talking about the same terminology here so ahead of time I I don't take that to me and ahead of submitting a transaction and dynamic transaction ahead of time where do you where do we believe the ahead of time is actually compilation out yeah so if we're just talking about pre compiles then we don't have to worry about the compilation time because it's the pre compiles I mean they're pre-compiled so there's be no attacks on you know on the compilation time and we were more worried about this last year particularly with the with the JIT bombs but and we did fuzz test v8 and found JIT bomb for for two versions of v8 since since that time someone last year there have been so now there's a v8 version called liftoff which they claim is explicitly linear time there's other fire there's web assembly compiler engines around Firefox that are supposed to be linear time we haven't fuzz fuzz tested those to verify that we can't find any compiler bombs for these other engines but that's the the to do I think the bigger issue with with compiler engines isn't even to the point of isn't so much worrying about the security whether it's security against consensus bugs or security against do s attacks it's just having compiler engine implementations available in the languages that the clients are written in so you know for parity there's a lot of good you know stuff coming out of Firefox that's written in rust so that parody the parody client could adopt and incorporate into the client but for the death client for forego aetherium there's really not serious efforts at compiler you know web assembly engines that that we can use so I think that's the biggest blocker right now so my second question was if I look at the way the EVM is currently used I would imagine that ahead of time compilation makes a lot of sense because the contract is deployed once and then used many times even if you account for people wanting to grieve this by deploying lots of single-use contracts you could still maintain a simple counter that does like hey the tenth time this contract is called we ahead of time compile it and store the architecture specific instructions instead of the EVM code do you think something like the obviously for pre compiles this makes a lot of sense but even for Annie wasn't chained do you think that will be mostly ahead of time compiled and still just compiled yeah we'll see one of the ideas was actually to compile one of the webassembly compilers to webassembly and then run that in a web assembly interpreter in that case we already have a web assembly interpreter written in go that perhaps could run the ahead of time compiler at deploy time and spit out some machine code the that goth could use sort of more directly yeah you're right that sometimes it might be better to compile things ahead of time I think that's up to the implementation we're only here for writing down a spec and you can execute things however you want is the point but yes I agree with you that it might be wise to ahead of time everything or most things I mean the only caveat I would say on that is that you know if if you were trying to include the in a gasps cost you know the costs of compiling so that explicitly I mean because no matter what you know you can't get away from it compiling has some fix upfront costs and then a lower runtime cost for more iterations whereas interpretation is you know zero up front and then a much steeper cross and they cross after some number no matter what they cross after some number of calls and you know I don't know I would like not I don't know necessarily we'd want to say ahead of time in this is a phase two questions so it's kind of far off so we'll have a lot better data and I don't know that there's JIT versus at a OT I mean I think there's not going to be like Java style JIT here where you know you have really big code and you're compiling part suit or whatever it seems like you're gonna compile a contract lump sum one time and then use the compiled you know machine level version after that or before that potentially you'd use the interpreted so it's just like somebody was saying here like phase either you could explicitly say do it at instant zero you know it's our runtime zero meaning the first one does it or you could set a counter and it actually could be something that the contract writer could say they have advanced knowledge that it's only gonna be a one time use contract so don't bother or they could set a threshold or something so I think I don't know to me for phase two it seems like a bit of an open question just my opinion yeah I mean I I agree sure please okay you know yeah it should make sense I wouldn't trust the the person to actually tell you the truth like when it comes to to telling you yeah it's going to work only once like you don't need to compile it to ahead of time because it will only be a single-use contract basically yeah because if you do that you can just lie say yeah it will be a single-use contract right yep so yeah what I wanted to say is you can indeed like try to learn from from the usage and compile a portal right yeah we just add a comment on that ahead of time here is its when the client is executing the contract for the first time essentially right but before that when you make the deployment of the contract it is kind of rational to run an optimizer and deploy optimized wasm code which has already gone through constant propagation and and and and the vast majority of tricks that you can do at an intermediate representation level so the only optimizations that was imagined really has to do is is that the machine code translation level register allocation and stuff like that but a lot of the heavy lifting has already been done all the control flow all so your returns on optimizing are not necessarily that great either whether you choose a JIT or you choose ahead of time and and ahead of time being execution time right so it's still ah has it been 10 minutes yet or do we still have time for one more question Oh is there anyone oh okay cool thank y'all we're doing any more presentations or was it I got a quick one I made it five minutes ago and by the way we're not going to be using the podium mic anymore we'll use the handheld mics because the livestream doesn't pick up the podium mic for some reason very well oh no problem yes normally I can do good with this kind of stuff though oh well my laptop needs to be on that's one thing I did that thing rice woke it up and then I hit the power button so it went back to sleep so this will be a second standby I think it's fixed now my computer was asleep all right everyone judging me for using Windows say all right there you go yeah where's the start oh there it is okay so this is talking and writing and stuff communicating your ideas to the etherium community it's three or four slides long I forgot I'm Hudson hello so here's the problem the etherium what next stuff is complicated and some of us are more builders than communicators so whenever we try to bring things to the community we're like let's dump this like 30 page PDF document and then everyone give me feedback no no no offense Alexei just saying it happens and so then there are some like people who give feedback which is great it's usually less than 10 and it's usually not you know people who are using the etherium network who feel like they have a say in things who do have a say in things so things that are obvious to us are not always obvious to others so whenever we're coming up with these ideas we're not always thinking of how this is gonna look from the outside words like state rent sound really scary some people have been saying storage maintenance fee instead earlier we were joking that we were going to call it tipping so it could be like a little bit easier to swallow like hey you know you tip your uber driver you know you have to tip the blockchain but we're probably not going to do that also there's a lot of trolls there's trolls from different block chains there's trolls from yeah trolls from aetherium aetherium classic all kinds of stuff so they're gonna try to mess with your plans as well so what do we do first thing and I put write a simple blog but really it can be any kind of like like right up on medium or a write up on a gist or something that's accessible to normal people people who aren't very technical I should say not like we're weird or anything but you know more normal people and after you do that and when I say simple I mean like don't go into the technical one have a link to your technical document from that one just say I want to do X I think it's very important I have run tests the numbers are in the document and I think we need to do it by this time and I understand the other side of the argument but I will be explaining that in the other technical document and if we talk about just that much and a blog post it makes people feel really comfortable about the idea it makes people feel like they're they can connect to it and they can understand it get feedback definitely listen immediately wherever you post it for people who are saying this is confusing people who are not giving any feedback if you don't get a lot of feedback then that might mean your idea is still too complicated or your presentation of the idea is still too complicated spread it on medium reddit Twitter aetherium magicians forum getter everywhere you can gonna bring up a Lexie again he does a great job with his rent present presentations of always going to Twitter I see it on Twitter I see it on reddit I see it on the √´the magicians forum and on getter whenever he comes out with a new rent proposal document so spreading it out like that makes sure it reaches the widest audience we don't have as many signals and we don't have as many platforms as we really should right now like I just listed the top five and I can't think of any more than that maybe telegram if there's some really cool telegram groups the next one and this one's overlooked a lot of the time gets support get support from and more like endorsements is the better word from core developers and from people in the community that people really trust so if you have a group of like most of the people from the core dev meetings commenting on something that's a--that's gonna go through that might be normally controversial if enough people who trust the core developers here that they trust the idea then that's gonna make it much easier to go through cleanly like some ideas are like real simple and they get through really easy like whenever we switch to snappy compression you know between Gath and Paradis there was a little bit of some like I guess discussion amongst people about that but it wasn't anything major and the community didn't care at all because it was too technical and also didn't really affect them except behind the scenes a lot of the stuff we're talking about like state rent and some pruning initiatives does affect the community so they need to know how they're affected they need to know what's gonna happen you know if we go through with this change and they're like the reasons we're doing it they have to be really solid reasons so getting endorsements from really smart and admired people in the community is super important iterate so if it doesn't work the first time try to do a message in a new way in a different way with more endorsements with more people talking about it and then finally win which could mean that you know your idea works and everybody wants to do it and we implement it or it doesn't in the community doesn't want to implement it if there's one thing you take away from this it's that we can't do anything without community support otherwise we're a cabal and we don't want to be a cabal of developers we want to actually listen to the community no matter how non-technical they are because they are the ones that we're catering to the user the stakeholder and the ecosystem they're the ones who matter in all this so if they say rents a bad idea I don't want to pay for it but I can but I will trade that off for the network being slow and unusable then that's the trade-off they're choosing so getting that support and getting the signals to realize that support is one of the hardest unsolved problems but I think that there are ways to accomplish that and I'll keep it here while we get some comments from the audience I just wanted to add a quick comment I think it's maybe less relevant for people here but relevant for the community at large is when proposals are brought to the table like you always have to keep in mind that all the client dev teams are extremely busy and just don't have a lot of time to do stuff and so if there's a proposal that takes a lot of work from a clients we might love that proposal and really want to do it but on the court never calls it'll be like yeah that sounds great but no sorry and getting an idea what it takes to implement your proposal and sort of putting in the work to show that you know what you're talking about and how to get it done even if you don't do all the code yourself even if that means you interact with them and you can guide some of the client developers to how to implement it that goes a really long way with actually getting it done thanks for a very good point anybody else have comments or questions anybody well cool my last slide has another picture of a diversion a Doge costume thank you everybody does anyone else have any presentations wonderful oh that's awesome do we have enough time for two Alexia whoever so there was like a two-hour breakout period that doesn't really need to be two hours I think so we can have presentations go a little bit over into the breakout period do at least one that's a good idea I'm curious about what you guys are up to oh they're clearing out the food and coffee has arrived food might already be gone but it's someone's grabbing it up there's cookies brooke has confirmed their cookies yeah a five-minute break and then we'll come back Internet sorry we're gonna come back later about five minutes from now we really need coffee you you check-check alright let's head back in and take a seat or a stand or whatever you want to do cuz we're about to start do you know how to do the extend screen thingy on a Mac wonderful and this will be the last presentation then we're gonna go over the objectives again and then we're going to have some breakouts is my understanding okay sounds good ya know it's the right plug your screen is showing it's uh leave it open I'd say and definitely use this handheld alright we're gonna get started here we have Zack who's gonna talk about white block stuff can we get a chant going Zack Zack Zack Zack Zack Zack Zack Zack Zack okay good thank you I'm getting you a cookie cake alright hey I'm Zack Cole CTU I want to talk about like simulation stuff and testing in regards of testing I think this is gonna be applicable to a lot of you folks so I'm gonna kind of like breeze through this because I think giving you a practical demonstration rather than like reading off of a reading off of a slides is uh is good is better okay cool all right so yeah so first I want to clarify the difference between like a simulation and an emulation a simulation is like a mathematical model and it's really only as good as the data sets that you provide so it's really hard to account for things that you can't really predict or don't really know about so if you have a good enough data set you can run a lot of simulations it's really fast and efficient so an emulation is more of a functional model that can actually like replace systems right so with a simulation you're just mathematically modeling different processes with an M within an emulation you're actually replicating these processes and you're you're doing them it's practical the system is actually functioning right so that's good for acquiring like large data sets that can be highly accurate depending on the setup right but it's more indicative of a real performance it could take more time but so the world is a big place there's a lot of stuff going on so what I'm presenting for acquiring these data sets it's kind of similar to what we're doing already for like Ethernet stats right everybody just provides their own nodes we're collecting data it's cool but we don't really have granular views of this data so we don't know how accurate is or valid the data is going to be because we don't have control over those notes so we're not really aware of all of the environmental conditions that are involved that provided that data right so what I think we should do because one thing we were talking about was like how do we calculate block propagation time for it for instance does anybody know like does anyone have a practical answer for that okay all right sure all right so what I'm proposing is like we can set up nodes in like different regions and those nodes we control them globally so we can deploy them on the cloud or whatever they're just pretty much light clients that are passively receiving data and writing new a shared database and like Kafka or something like that so that allows us to understand more granular granule understand exactly what's going on within the main net so we can acquire these relevant data sets does that make sense you guys so far and then that's for simulation purposes because Ethernet stats is only gonna take you so far because we don't really know so that will allow us to run better simulations so then on the emulation side we're working white block we've developed a testing platform that allows us to like provision multiple nodes running whichever client you choose to configure the network links between these nodes so each node exists within its own VLAN and is assigned an IP address that allows us to provide logical separation between those nodes who are each running independently of one another and then we can configure the network links between those nodes with like packet loss latency or bandwidth constraint so we can actually replicate a live functioning Network that is highly accurate because we can observe how this client performs and how it responds to different environmental conditions etc and then we automate processes so like we're generating transactions they're real transactions because it's actually running the GAF client or whatever client we want it to we're automating all of that so we can test like TPS and what the effects of network latency or packet loss or different bandwidth constraints have on TPS that's a pretty high-level example we can also implement forking conditions so we can test consensus and like observe what happens within the network when these when these when the blockchain is is segmented right and forked and then we can do a bunch of other stuff so it's an actual full mesh network so it's it's real I just wanted to go over some tests that we ran earlier like first we wanted to just start with some basic stuff as like what effects do does latency have on like minor profitability so we set up a test network comprised of 12 nodes and they were divided into two groups man you guys aren't seeing the whole thing sorry I was gonna show you guys like this you don't mind so the control group each node had equal computational resources but we applied and no latency was applied and the test group we applied incremental latency to each one of them and we wanted to observe the wallet balance after a period of time when they mined and that was what we used to gauge to validate our hypothesis so the results at the end of the test were that the the the control group had a 25% aviary a higher balance than the test group so what are the implications of this it's like latency increases block propagation time block propagation time reduces transactional throughput because there's an increased uncle rate and that weakens the absolute security of the network because not all of the hashing power is going to actually securing the network it's just going towards mining uncle rates our mining uncle blocks right so then I was at I think it was like Idi Khan last year Shawn Douglas from amber dado was talking about how when the uncle rate is whatever like X you don't actually need 51 percent control of the network in order to engage a successful 51% attack and I sent him in the email and I was like cool but you didn't really provide any data it was just like literally a bullet point so I asked him for the data and he never responded so I was like you know we'll just run the test on her own so that's where our next our next test goes so we actually just built it out on our own so we had four nodes we implemented a really high uncle rate forcing a high uncle right through latency and then we had one node that was like a super node and it controlled approximately 46 percent of the network hashing power we had a low block time because you were just really trying to observe like these effects there there was a 57 percent uncle rate was what we measured as a result and we ran the test for a thousand blocks so these charts are kind of wacky so let's go at the end of it the node that had the lowest latency and the highest hashing power controlled most of the blocks that were produced so it's pretty interesting so what do we do with this information like one we could like raise the block time and the gas limits per block higher gas limits are bigger blocks more transactions luckily we didn't have to really need to worry about that because we started working with Ubik they hired us to do some tests and Ubik was like an early aetherium fork it's pretty much just a gaff work and they implemented their own custom difficulty algorithm to target an 88 second block time which means they have larger blocks and they want to to see if they could raise the default gas limits from 4 million a 30 million and they wanted to make sure that it wouldn't negatively impact the the performance and they wanted a benchmark that against aetherium as well so we set it all up hold on so at the end anyway I want to get I want to just show you guys a demo because I'm not really good at doing these presentations I'm so sorry I'm very good face-to-face though so you guys should come talk to me so so throughput was higher for you booked under the same conditions the difficulty algorithm implied higher stability more consistent block times Uncle Ray was two point seven percent for Ubik and twenty seven point six percent for aetherium under the same conditions so I mean this just gives a show that there's a lot of things that we need to test still so does anyone have any questions so far anybody this is making sense to you guys okay cool so here let's see figured I could show you guys a demo of what we're doing this isn't this isn't it this is just my terminal do you guys want to see you don't worry now should I do that right now up here okay cool all right so I already had a blockchain built out here so we do all right I guess I messed something up so I'll do it later yeah I don't want to waste any more time did any of you guys have any questions so far so I was gonna say that we could get you to four to come kind of sit in the corner for the obsession then people can just come in to directly okay if anybody wants to ask a question now I don't want to shut anybody up right perfect time all right we're gonna do a breakout session for an hour and the then the objectives are at 4:30 bye Internet we're stopping the stream for today see you tomorrow 