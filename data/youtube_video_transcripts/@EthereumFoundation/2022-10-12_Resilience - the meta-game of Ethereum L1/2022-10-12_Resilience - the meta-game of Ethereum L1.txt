foreign [Music] thanks for having me I'm working the EF I work on the research team and name I do a lot of things that aren't just that but you know here we go so resilience I want to talk about what we might call the metagame of ethereum L1 we're trying to ship a lot of stuff there's a lot of things underneath the hood that maybe aren't quite clear that that are being worked on and thought about kind of at all times I did ask the internet what should I talk about Devcon got some answers um L2 very important it's gonna be a lot of stuff to talk about this week dig in deep um Hudson if you want to talk this evening I got a lot we can we can exchange some fun stories Kevin um I'm glad it's worked the pseudonym has fooled everyone um and and Johnny Ray I won't do a handstand up here but I love handstands and if you want to do handstands out there uh we can we can join but that's not what I'll talk about today um so again being listening to death but the merch happened finally it did indeed took a village take a village a lot of those people are up here a lot of people are out in the stage and they're also distributed all across the world thanks guys quick quick just like perspective on on what happened um it's been a bit of a non-event which is good it's good that's how it's designed we can kind of see um in that little Spike towards there's two little spikes at the end and it looks like participation kind of fell off a cliff real quick right around the merge picked up went back down it's been kind of leveling off and figuring out um I think it's worth zooming out because like this this starts at 94 not at zero this is actually what participation looks like there's a gap because our infra wasn't collecting at that point but it's it's pretty damn good when the system was designed years ago we we didn't know what participation would look like we'd think okay so normally it's going to be above two-thirds normally people are the incentives are such that people are gonna turn their machines on and make sure that we're finalizing uh but we thought 70 80 85 would be like kind of normal but really like people are turns out are extremely obsessive about every last attestation I got some laughs up here because uh if you if you're on a client Discord it's like somebody misses one out of station in a month they're like what's wrong with my machine um but anyway shit's pretty good like and and you know there's there's a couple hiccups here and there with a couple clients and and people are uh resolving them moving forward and we have a nice little nice little stable graph blocks turns out those are good too they're coming out in a healthy clip blue there's actually three colors on this graph blue is uh is successful blocks each day and almost all of them are let's see but we do we do miss a few slots from people being offline I was actually talking to Terence and it turns out that we miss fewer slots now than before the merge so even though there's more complexity in the system um terence's hypothesis is that uh there's a bit more money on the line you really want those blocks now with those fees uh so the the number of blocks is even better than it was before and then what about reorgs there's another color on this graph presumably it's orange but I don't you know there weren't many before the merge and there's not many after uh in fact Michael Sproul dumped from his note he's seen 26 reorgs although some of those might be double counted and 85 orphaned blocks all of these generally show very late properties so if something's reorged generally we're seeing you know things Landing towards like the last two-thirds of a slot or even like right on that boundary so the network gets a little bit confused and then resolves it and I should say all these reorges are depth one um also from Terence check out his talk in two days um 50 of the orphans so these are the blocks that tried to make it on chain and didn't uh come from Mad boost relays there's additional latency and complexity that happens there people are working through it but you know that's that's uh an interesting component here also it depends on your perspective you know some nodes might see like a little reorg and the other node always saw it as solve the correct head so again these numbers I mean that's like one a day so things are pretty pretty smooth I think the the like Uncle rate in proof of work obviously because there's a lot of redundant work happening because of the way competitions uh improve of work happen there's like a four percent or eight percent um uncle rate and you know we're at near zero now so things are things are generally working this is what it looks like it's plain and simply healthy again finality step wise very nice almost the entirety of the beacon chain since Genesis has looked exactly like that it's set for this one time I was out to dinner on a Friday and I got a text and it's not a text you want to get on a Friday night there's something up with mainnet from Paul uh there was a little there was yeah the network stayed live we lost some block proposals and we didn't finalize perfectly into epochs it looks like we finalized a few in three epochs and it's been resolved in very clean since um I know Victory lap on the merge but like Victory lap on the beacon chain it's been an incredible two years uh and ultrasound OnStar ultrasound money ultrasound uh Justin Drake I'm scar it's a nod to onskar convincing us to merge like five or seven days earlier uh to to save on issuance um but Justin's given a great talk tomorrow check it out and before I move on uh there is a merge data challenge going on all of those are like very simple metrics there might be some more interesting stuff going on underneath the hood check it out and submissions are due by the end of the month so you still got plenty of time certainly from the inside uh we feel the pain but I know the pain is felt from the outside as well the interest in fact was one of the suggestions for my talk how we quote ship faster I don't think I'm going to talk about how we ship faster but I want to talk about why it's slow and it feels like this both from the internal and the external hopefully this is not a very busy road so much of much of this is fundamental much of like the complexity of shipping here is fundamental it is fundamentally new research fundamentally new mechanisms fundamentally new networking and new crop cryptography ethereum has the luxury of uh having tons of backwards compatibility considerations at every moment of every day and quite frankly distributed systems are complicated it's much easier to get a computer to do something than to get a bunch of computers that you don't control to do something together and agree always and quite frankly much has improved a lot of the conversation in the past couple days with a lot of the L1 devs and a lot of people involved in shipping and improving ethereum um has been like wow this this thing's working well like this is a moderately well-oiled machine like we're moving faster we're getting more done than we used to and some of that's because more core questions of the research have been answered so it is a lot of engineering a lot of that is is alignment and Ethos a lot of that is sophistication and specialization of client devs we have a lot more people on testing we have devops wizards driving our test Nets and helping us at every step of the day dedicated security analysts all sorts of academic collaborations really fun development Retreats um and the process is just it's refined it's really moving well so things are slow things aren't going to be fast but they're moving pretty well right now but there are actually a number of considerations that are at odds with speed things that we're thinking about things that we're optimizing at all times that if you looked at it from a naive perspective you'd be like you're you're shooting yourself in the foot you're making this hard and there's but there's good reason that we make things hard and that's the the metagame of ethereum resilience right and I might touch on some of this in in her talk but we're you know we're optimizing for an infinite game we're not optimizing for a pump and dump we're not optimizing for an acquisition we're not optimizing for uh you know people being rich tomorrow you know we're optimizing for ethereum existing and running for 50 plus 100 plus years and being a fundamentally uh foundational protocol of the internet and for Humanity so we're trying to we're trying to continue to play the game nothing we're trying to have redundancy built into the game we're trying to be able to recover in the event that the game fails when you're thinking about 50 plus years like shit's gonna happen and we need to be able to pick up the pieces and keep moving and in fact we need to be able to harden under after this adversity you know not only do you can you pick the pieces back up but can you come back stronger and tuning for ossification and avoidance of capture you know the the more valuable this thing is the more it's valuable for people to kind of get their hands in get their interests in and this thing needs to be robust against anything that might happen in the next 50 years 100 years and one more thing when we're thinking about ethereum resilience there's a number of like ways that we might think about it the the most obvious is probably the first the protocol like we're trying to make sure this is a resilient protocol that this thing works next is is kind of the instantiation of the protocol that's the network that's like does this not only fundamentally this abstract protocol work but does it work live and is it resilient in its instantiation of tons of computers distributed across the world doing their thing and then there's the kind of the social layer on top is the social layer resilient is the social error can people come and go Can it can we avoid capture can we deal with with issues in that layer and get I can get into each one of those oh and shortcuts are obviously available we could have a single client we could have a single dictator we could have truncated r d and just ship it we could have easy centralizing solutions we could have a willingness for downtime and we could have processes that are right for capture that's not what we're doing and that's why it's taking a long time and that's why that's how it is so protocol resilience there's a lot of things that go into this this is probably again one of the more obvious things tons of research and design tons of security and testing nothing goes out lightly the the amount of time and effort put on Simplicity in ensuring that the system is generally extensible over time is is profound if you there's a lot of hard jobs in ethereum L1 but if you've done if you've worked on research for any amount of time in this space you've thrown out things that you've worked on for easily a year things you've spent countless amounts of time and you just been like you know what it's not right it's not simple enough it's not right for ethereum and and that that is a regular regular component of this process being able to operate under adverse conditions and be able to recover under these failure modes I think one thing that's a very Guiding Light and I highly recommend vitalik's piece on functional escape velocity but we're we're looking for you know you can throw everything out of protocol you can you can try to build everything into the protocol you can just be like okay this is good let's throw it in okay this is good let's throw it in but instead we're looking for that minimum functional escape velocity and that's an art you know you don't get that easily you get that through years and years of thought and iteration and many protocols only try to avoid failure whereas ethereum is borderline obsessive with the fact that it likely like something can fail and like all of these protocols essentially in a crypto economic protocol it's you get X properties unless this thing happens usually this thing happening being some size attacker someone willing to throw a bunch of money or burn a bunch of money and you know protocols work unless you hit those thresholds but in 50 plus year time Horizon we're going to hit like not necessarily you I can't predict the future but like happens and we need to we're borderline obsessive with not only trying to avoid these failures but to be able to recover from them which takes time the next is Network resilience and there's really a heterogeneous Network and that provides resilience in so many ways so we have multi-client multi-layered Justin actually was pointing out there's another layer we think about the consensus layer the execution layer there's actually this other layer which is kind of the cryptographic layer we rely on a multitude of of black boxed crypto tools which allow for expertise and and separation of layers here we have hobbyist stakers we have home nodes and Regional diversity every single one of these things makes it harder like every arguably multi-layer doesn't but the fact that we have like nine clients working on this thing does not make shipping easier but it makes the network more resilient under failure modes it makes users more resilient in that they can pick different things in the case that something fails hobbyist stakers allow for Like A diversity or participation they allow for fail like backups in the event of failure modes and I'll talk about that home modes Regional diversity similar things I think one thing that we don't think about when we think about like this heterogeneous Network and how it helps us we really obsess over like we want perfect distributions we want like 20 of each client thus if one goes down then like we're 100 good that's the ideal and that actually optimizes for kind of the continuity of the network like the the network can be continuously resilient in the event that you get these perfect spreads so for example you know if we have five clients uh they're perfectly distributed across the network if one goes down you might get a few uh fewer block proposals until it comes up or people switch their nodes but you get finality you get like a really nice quality of service it's great we should move towards that direction there's tons of reasons as a whole and as individuals you know we should try to optimize for this but they all it also helps us even in imperfect distributions and these are more in the tailor scenarios so if that big if if client diversity looks like that on the network that large block goes offline and it's chaos right like we're not finalizing we're getting maybe 50 of the blocks that we're expecting um and and shit's going down but the network continues blocks are built transactions are processed and users have options so in that event users over the course of a day can dynamically you know either that big block gets fixed the network stays online or that big block has issues and users have options to switch through and they can recover and make sure the network continues in the event that it's just one block you don't have all of that that you have zero ability to recover until they turn that thing back on so this goes this goes for some of the other things here I think people sometimes say why are we optimizing for home nodes why are we optimizing for homesteakers you know like if you look at staking distribution you know homesteakers are a third or less like it's clearly not working but it's it does not it's not giving us that kind of perfect distribution that might help in in continuity in the event of intermittent failures but it does help with recovery it's critical for Recovery it's critical for these failure modes so in the event that some of your mega pool and the mega cartel of pools they finalize something invalid they try to take the chain over then you have a resilient the ability to continue like that that big block finalizes something crazy and that small chunk of hobbies validators become the backbone of ethereum and continue forward and they don't care ethereum doesn't care you know and the ability like if that was just three large pools and they their cartel like it's so much more difficult to recover so we do think things are ourselves for continuity and Recovery we also have it's kind of like these soft things that we're optimizing all the time in the social air you know multi-client is very important for um for Network resilience but it's also very important for Like A diversity of perspective it's very important for ensuring that every stone is unturned it's important for kind of the security of this thing and how everything kind of communicates and comes together similarly a diverse staking set brings more people to the table ensures there's more diverse perspective on the needs of stakers and the desires of the network optimizing for the global very similar we have this incredibly like if you talk to academics almost comically open research process which brings in a multitude of perspectives and helps Harden the social air and ensure that the the social layer is diverse similarly open processes Open Door all around and Albert neon said uh the ethereum is an intellectual gravity well and he said this five years ago and it was it felt kind of true but it's just like increasingly true like increasingly every time I talk to new academics or new people joining it's just like the obsession and the fervor to be involved in this this intellectual pursuit of uh of ethereum the the ultimate nerd snipe just increases more and more similarly um Ben calls ethereum a bizarre in the sense that you know it's not top down controlled it's not top down organized it's not it's not like a well-structured thing and there's chaos but time and time again because of this open nature of this open market of ideas and intellect and engagement and software development like people just show up they join they join the party at the right time they help move things forward and and and get things done and this this is not that this this open wild structure is like not it's not how you optimize things and move as quickly as possible but is a way to be resilient ethereum's L1 structures tend toward a multitude and thus I would say ethereum's L1 structures tend to sword ossification like the more people that are at the table the harder the conversation becomes to change things and I won't get into it too deep but I personally believe ethereum ossification in the not so distant future is incredibly important incredibly valuable um like I said earlier the ability to modify change or manipulate this this uh machine is very valuable to us because quite frankly ethereum is not done you know ethereum needs to reach that functional escape velocity but it will be increasingly valuable to others to also potentially attempt to manipulate for their own their own value so a lot of what what's involved in kind of bringing more people to table is to make sure we have a more resilient protocol while we still can manipulate it but to ultimately tie our feet down with bags and not be able to move where does the EF fit in I think I will probably talk about this a bit I think Josh is going to have some interesting perspectives on this as well but in general you know we're we're here to help we're here to coordinate we're here to help connect the dots um some of some very interesting work and valuable work does come out of the ethereum foundation but tons and tons more you know this is increasingly just a small piece of the puzzle this is uh the last the last suggestion reporting Back From The Trenches the art of project managing the merge um one Evan I'm not a project manager but you know um the uh I think the the biggest thing is if if someone were to attempt to do such a process in the future is uh know enough to connect the dots contribute enough to uh gain the respect needed of the group and and ultimately get out of the way you know there's there are incredible experts at every layer of everything in the stack and in creating the room for um for people to do the hard work is is one of the most important things here I do want to flip this l1's thinking about resilience all the time like every piece of the puzzle is all about resilience and all about ethereum lasting and being a utility for the future but I do turn this on the application layer I think it's definitely time to think long term um you know I see a lot of unnecessary debt taken out in the application layer you know whether that be complexity governance where things maybe shouldn't be governed upgradability bad token distributions these things they're liabilities in the sense that they can help you small bits of this it can be very important to Applications but I feel like uh naively if we take a look at applications they they take out quite a bit of this debt for very unclear return I would suggest the application layer more Unix philosophy more of doing small things more of little widgets on chain rather than uh Behemoth type contracts that try to do it all when in doubt minimize or eliminate governance and when you do need governance make it small it governs this one component that interacts with all of these ungovernable components this is very very important like governance is a liability of being able to manipulate and change things like with L1 is going to bite you in the ass if it's not done with Incredible care I recommend to tend towards ossification similarly if you need upgrade abilities today have a path in which you don't need it in the future similarly I think there must be more interesting value generation models than the ones currently being explored today I think there are clearly some very interesting things that are being done on ethereum with tokens governance Etc but I promise you on this new landscape of coordinated games on top of ethereum there are going to be interesting and less um potentially risky value generation models check it out explore the non-financial especially with l2s opening up more scale for ethereum there's much more room in this stack to be doing things Beyond just that defy Beyond just that speculative cool little picture I I do think especially in the identity space especially in the Privacy space there is a lot of incredible work to be done in the next few years oh and if you're riding l2s it's time for fraud proofs it's time for decentralized sequencers I think that goes without being said but if l2s are going to inherit the not only the security but the legitimacy of ethereum we can't go without this stuff and I think the former is is obvious the latter is is not so obvious obviously you can construct secure l2s without a decentralized sequencer but when you start thinking about regulatory risk and other types of things at play here these are a must um so I suggest playing the metagame resilience across the stack not at all not just at all one unify this whole thing um everything built on ethereum does isn't going to necessarily last for 50 plus years but the the applications that matter will and uh quick Happy Birthday to someone in the audience that I could not do any of this without thank you [Applause] [Music] 