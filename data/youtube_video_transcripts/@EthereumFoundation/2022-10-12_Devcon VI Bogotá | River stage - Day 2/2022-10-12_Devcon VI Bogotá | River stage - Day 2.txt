the way that he put it I was working on an analogy to describe kind of the web 2 dilemma and hopefully this isn't too soon but one analogy that kind of made this stick for me a little bit is that if web2 is someone sneezing on you during the pandemic and web 3 is a properly fitted n95 mask then web 2.5 is kind of like a chin diaper right and like I know there's a lot of different uh opinions and you know ideas on the efficacy of you know Mass mandates Etc but I think we can all agree that the chin diaper really didn't make a lot of sense and that's kind of web 2.5 right it just doesn't make sense it's sort of uh you know it's incongruous with the goals of of you know blockchain and web3 specifically it undermines a lot of the value propositions that you know the ethereum founders uh and a lot of the early you know builders in web 3 sort of uh you know United around in the first place so you know being able to build Unstoppable applications with composability when you start building on centralized infra run by you know single service providers well then your app is no longer Unstoppable it stops as soon as you know that platform gets shut down um once you stop building on Open Standards um the composability of your applications and of the stuff that you've built goes down quite a bit and even if there was a standardization on these centralized servers there's a limit to how much composability you can get when you're building on centralized building blocks because the more centralized building blocks you compose the more brittle your system becomes because now you're basically you know if one centralized building block in your giant compose system goes out well now that ripples to breaking your entire system as opposed to you know Unstoppable smart contracts running on ethereum the way those work where you know a new D5 protocol can come along integrate with an existing Unstoppable D5 protocol and that composition uh can keep you know playing out until you get this you know this really rich tapestry of you know decentralized applications um it definitely hurts for usability you know if you're just doing one-offs all the time and then I think you know on ownership censorship resistance fairness I'm gonna try and paint this a little bit in a few examples uh the first is um how many people saw the the article that uh Moxie Marlin Spike from signal wrote earlier this year uh okay like let's say 30 so he he wrote I recommend you look it up he wrote a very um I think well-intentioned could we get uh levels down just a little bit uh very well-intentioned well thought out critique of web3 from someone actually trying to make a good faith attempt at building uh some decentralized applications in the space and so one of the things that he did was build an nft app and to sort of uh kick the tires on like the guarantees that we think we have when we're building on nfts he basically built a single nft but depending on where you viewed it whether you viewed it on openc uh wearable or in your own wallet you got one of the three images shown on the screen so like when you're actually buying the nft or looking at it in a collection you're seeing like this cool piece of artwork and then by the time it makes it to your wallet you get a poop emoji and that's possible because the nft was not hosted on decentralized uh data and using a decentralized data supply chain it was using centralized servers to serve that that nft you know and and for a lot of us who are sort of inspired by the ownership vision of web3 you know that web3 is enabling digital ownership you know how can we own things when the actual information artifacts that we're owning are controlled by centralized you know intermediaries I think this experiment also highlighted a another interesting place where we're falling short today sorry we got some clicker uh there we go uh so this experiment also highlighted a a way in which we have censorship in quote-unquote web 3 today because once uh openc realized that Moxie had done this they actually delisted uh his nft from openc which if openc was doing that as a individual application and doing that for you know sort of their own purposes and I think that's you know fine like we believe in choice you know at the at the level of projects and individuals um but the problem was that so many other projects in the ecosystem were building on the open C API that him getting delisted from the openc application also made it so that the nft stops showing up in wallets and all these other places where you would expect to see an nft that you had purchased right so this is a real example of censorship um that's happened just this year in in the context of you know the blockchain data supply chain for a use case that we all I think care a lot about another one that this is a little bit more speculative but I think it's an interesting one just as a thought experiment is um index or extractable value this was an idea that was put forth by someone in our community you can think of this as being a little bit analogous to like Mev or also payment for order flow which is which got a lot of attention this past year or two when people realized that Robin Hood's business model for offering free um you know stock trading to retail investors was that they sell the order flow to Giant hedge funds like Citadel and then Citadel with its privileged access to these to this order flow can then like extract all this value at the expense of the retail investor you could imagine a world where if we were all accessing the blockchain where we expect more of our financial lives to exist over time and we're all accessing it through a centralized intermediary uh that that centralized intermediary might gain a lot of Alpha from you know being the one that's seeing the sort of Google Trends style uh you know data around accessing and querying you know our financial lives as it exists on the blockchain okay so that's kind of where the web 3 vision is at today and sort of the importance of you know the uh keeping the blockchain supply chain decentralized let's talk about where ethereum is going and the ways in which a decentralized blockchain data supply chain supports that Future Vision so for those that saw vitalik's ECC talk earlier this year you might have come across these new um let's call them work streams that are all happening in parallel so you know they're not sequential Milestones but they're all all uh parallelized work streams that are happening in the ethereum ecosystem the merge The Surge The Verge and the splurge and the diagram on the left can look a little intimidating we're just going to focus on a few aspects of this roadmap specifically parts of the Verge uh The Purge and um parts of sort of the light client vision of ethereum so a brief overview The Verge one of its sub goals is around supporting stateless clients stateless clients allow validators to sort of be small and light while having like heavier specialized builders in the you know the right side of the blockchain data supply chain there's different approaches to this weak statelessness strong statelessness weak statelessness is where Builders sort of provide the um the witness of state that's being used by a transaction and strong statelessness the end user actually when they submit a transaction they would also have to submit the state that that transaction is going to access as a witness to the network The Purge is about history expiry as well as state expiry so eip44s covers the history expiry side of things which is the idea that after a certain amount of time in contrast to the way that ethereum works today full nodes and validators would be allowed to drop they'd allow be allowed to prune historical blocks um uh basically keeping the the storage footprint of these nodes lighter and then State expert X3 basically um uh attacks the unbounded state growth of ethereum where certain state if it's not touched frequently enough again would be allowed to expire and then like clients uh we're going to touch on a little bit in the next screen but I think they're interesting to bring up here because they share a lot of the same requirements as sort of those previous two milestones and they're also part of the solution space right because a lot of this stuff boils down to being able to access State and and data uh but the problem with like clients is that today at least like clients rely on altruism from the full nodes in the ethereum network so if those full nodes decide to support the light client protocol and serve data to these like clients then it works out great but the reality is that because of that lack of incentives uh as you know Piper one of the researchers working on this noted uh basically the the light client protocol in ethereum is a vast desert of starved clients desperate for data historical blocks or pruned blocks from the you know the blockchain or expired or uncached state so in the case of State expiry it's expired state in the case of stateless clients that might be just state that the Builder or the user needs that's not you know cached locally and the solution space breakdown here I think you know can be broken into two larger categories uh one is financially incentivized approaches you we mentioned those like uh those you know like clients needing cooperation from the full nodes which right now don't have an incentive um so things like the graph things like pocket Network could fit into that category um the other category here is using more like Tit for Tat incentives which are not Financial incentives but this is kind of how like the BitTorrent network works for example where you know if you're being a good citizen in that Network uploading data as much as you're downloading then uh there's sort of this reciprocity you know that you get and that's the approach uh being explored by uh projects like portal network using things like gossip protocols and dhts which again are techniques from BitTorrent and now ipfs as well uh and so why are we doing all this like why are we getting rid of all this state why are we getting you know what are we doing it for the fun of it no we're getting rid of this state in this history for a purpose and that purpose is scaling ethereum in a decentralized way so simply put what that means is being able to fit more transactions into a block being able to have bigger blocks while maintaining a small footprint for validating clients and and like clients and as an example of this uh one of the eips that's out there right now is called eip4488 it proposes a uh approximately 5x cheaper uh 5x reduction in gas costs for call data this is about supporting like the ethereum like roll up uh you know Centric future um but the reason that they feel comfortable doing this which was inevitably going to lead to bigger blocks or more full blocks uh is because it's intended to be paired with eip44s which is one of the proposals in The Purge which uh specifies dropping this requirement for full nodes and validator nodes to keep around all this historical blocks past a certain point so that's what all this really boils down to is decentralized scalability of ethereum okay so this last one is kind of a bonus section I think this is really interesting from uh both a couple standpoints one is that the fire hose which we we briefly noted earlier is a Next Generation extraction technology I think it's interesting a because I think it it should impact the way that ethereum clients get built in the future but I also think it's interesting because it's an example of sort of this uh positive externality coming from an ecosystem that's tackling uh the blockchain data supply chain in a decentralized open source way right so this is fire hose is a technology originally created by streaming fast which is another core developer in the graph ecosystem before I get into how it works it's worth um calling out some of the problems with Json RPC and the way that it works today so you know most of you I think are show of hands people that are familiar with Json RPC okay most people in the room so this is how you access you know data from like a guest or an Aragon client today it basically depends on a running program to read data so if you look at this diagram on the left you kind of have this fan in architecture where all the users are sort of hitting a running process that process consumes CPU that process becomes the bottleneck for getting data out of the node and then because you need to have heavier nodes to serve all the data that people want like archive nodes potentially running parity Trace it's also incredibly intensive on memory and solid state disks because in order to actually efficiently access that data you need to provision a lot of of both of the latter it's difficult to get query intermediate States so Json RPC really only lets you query data as of a block you can get a little bit more by using the parity Trace API but it's still incomplete also very cumbersome it can be difficult to debug so if you're using it you know a subscription to like if get logs for example via inferior like we've encountered this you know in our own stack that like sometimes you know in the past messages will just get dropped you know due to you know transient Network events or partitions uh and there's just no way to debug that like you just miss the message and like it's very very difficult to figure out that like hey a message you should have gotten never made it to you um and there's a pretty incomplete verifiability story some of the some of the data you you want to get out you can get a Merkel proof for but other data uh like if you're using like the eth get logs uh interface for example there's not a really easy way to get a compact proof that says you didn't miss any logs you know within some range of uh within some range of blocks um so what's the solution uh we think the solution is the fire hose approach uh it's streaming first so if you look at the diagram on the left uh data is being on like as soon as it's available it is being broadcast out in a fan out approach rather than this fan in it's being distributed uh as flat protobuf files so these can be distributed across uh you know commodity Hardware like and using things like you know uh Google Cloud object storage or Amazon S3 um because you know now we have these distributed flat files now we can convert uh parallelized workloads on those files you know all without even touching the blockchain node so this is much more akin to like what you would see in like a Hadoop uh you know big data architecture where you have all these flat files distributed across commodity hardware and then you have you know these compute clusters that can be scaled independently and spin up concurrent and parallelized access for doing this sort of transform steps you know on that data and so so when you do that stuff you get you know compared to the approach of using Json RPC today you you know you get a one to two uh order of magnitude you know increase in read performance uh based on the use case uh there's a couple integration strategies that I'm going to move through here real quick um the first is just integrating this as a drop-in replacement for Json RPC basically have it be something that you know runs locally on the Node when you're running you know your node instead of accessing via Json or PC you would be using sort of like the fire hose stack and that's kind of like a really basic integration but in the future you you also might want to actually improve the verifiability guarantees that you get from fire hose so you know you could imagine sort of the fire hose instrumentation logic running as a wasm process that is implemented as a read-oriented roll-up so like an optimistic roll-up or even a ZK roll-up that actually uh gives you some guarantees on the validity of the sort of uh data that is extracted through that fire hose instrumentation process and then the Final Approach that you know and again these are still very early and US thinking about this but the Final Approach is you could even potentially integrate fire hose files into the consensus process itself now you probably wouldn't want to do that um initially because initially there's a strong benefit to having what's called like data agility being able to evolve the schema evolve the instrumentation logic based on sort of a changing understanding of what's needed but as those Integrations stabilize there might come a time and point where blockchain core developers decide to say hey we'll you know we'll reference you know a maybe the fire hose files from the previous Epoch you know at some future block right so that they're actually you have some guarantees natively in consensus I'm happy to announce that uh actually we have our first example recently of a blockchain core development team um self-serving their fire hose integration and I think this is going to be really important for every blockchain core development team especially including the you know ethereum ecosystem to eventually own their fire host deployment so that they can sort of maintain that for their own use cases and then that also has secondary benefits like basically automatic integration with protocols like the graph um there's another uh integration story here uh related to eip44 called shim clients but we're out of time so if you're interested in that uh you know feel free to come up to me and find me afterwards highly recommend checking out Alex B from streaming fast talk this week on substreams and then also Vincent from asari has a talk on standardized subgraphs but they're heavily using fire hose and substreams as part of their as part of their dog footing So yeah thank you guys very much that's my talk do we have time for questions or I guess we have time for a couple questions we have a mic in the back oops is there a published specification for the phone host fine there's there's pretty detailed documentation um I wouldn't say it's at the level of like an IEEE spec or anything like that but there's very detailed documentation on the architecture how it works the repos are open source um so if you just search like fire hose the graph docs uh uh you'll find it real quickly Dave in the front so for oh thank you for the um the stateless clients and like eip444 is there any way to estimate or predict like how like basically what I'm trying to understand like in the graph Network itself as a whole essentially like earn income from providing a service of like you know basically the the current ethereum nodes retiring the state but then graph notes serving up that and then as a whole like the network getting some profitability from that yeah it's a really good question so this is um these are sort of emerging ideas in our ecosystem but like increasingly my view of the graph um uh is that it is going to be like a multi-service uh ecosystem so like today the primary service is you know you do ETL into a subgraph and query it via graphql but there might be a range of services for example accessing fire hose data directly or Json RPC data directly or data in a key value store or a SQL store and I think all of those could potentially be supported side by side in different like name spaces if you will within the graph ecosystem and in that context then you could imagine yes graph indexers and service providers being the um the endpoint that like light clients use to to get their data it could also be what blockchain nodes themselves use to hydrate uh you know data and some of these other you know related to these other Milestones so yeah I think I think it will be a source of uh query volume you know in the future on the graph yeah great question cool I think that's it thank you guys so much for your time and attention [Applause] the clicker's up there is that okay opportunities [Music] [Music] [Music] [Music] foreign [Music] foreign [Music] games um announcing Alvarez Justin Gilbert and Kevin Fincher [Music] [Music] doing this would you recommend [Music] [Music] foreign [Music] hmm should we wait for the room to fill up yes okay cool let's go cool let's wait like 30 more seconds cool doors are closed we're ready good morning everybody my name is Justin and along with olivarius and our friend Kelvin from optimism we're going to go over new technologies for unchain gaming so Alvarez and I work on lattice among with many others it's a project that's put out of Xerox Park in others to in order to push the envelope of Unchained gaming um we basically want to enable people to build crazy things on top of ethereum um and things like full-on Virtual Worlds worlds whose rules run on the evm and whose state is secured by ethereum people usually refer to those projects as on-chin games but we prefer to call them autonomous worlds because we think it goes well beyond gaming it's about giving autonomy and sovereignty to complex systems so the problem is building large on-chain projects is actually really hard which is why today we're going to go over two new key pieces of Technologies built by lattice and optimism in order to enable autonomous worlds and I'm going to pass it to Alvarez to go over the first one cool so the first key piece of technology that we want to introduce today is Mutt mod is an on-chain game engine or how we'd like to call it an engine for autonomous worlds that we develop here at lattice and when we started working on on-chain games there was no engine to build upon so we had to run through all of these very common very like General problems very non-trivial problems as well but they were common in all the games we were building so we set out to build this key missing piece of infrastructure and build mud with the goal of solving all the hard problems of building on-chain games so what are the hard problems of of building Unchained games well they've Fallen to mainly three categories the first one is how to make sure that your client and your contract state are always in sync and then the next one is how to architect your game in a way that it that makes it easy to add more content later without having to refactor the entire code base and then the third thing if you care about impact Beyond just an individual game then how do you make sure that your game is interoperable with all the other games out there so before I go into how mud solves all of these problems let me quickly go over like the previous common approach of um yeah approaching these challenges usually the the most common approach before was you have one struct per entity type on your contract like if you want to have a monster then you have a monster struct and in that struct you store all the data for that struct for that entity and then of course on the client you have to replicate that like interface in order to represent the state there and then you have getter functions for each individual like type of entity that you want to sync to your client and you implement your logic based on these specific structs and every time you modify one of these data structures you have to emit a custom event that then can be caught by the client to then like update the local client state and this is already this sounds already pretty annoying but it gets even more annoying when you want to now add content because now you have to add a new struct and you basically have to edit your entire network stack in order to make it compatible with this this new struct from the event over the getter functions to like the um yeah event handling on the client you have to modify everything and then on the interoperability side basically all you have are existing interfaces like erc20 erc721 Etc which were not built for unchain games and are very limited in what they can express right so our goal with mud is to solve all of these like General problems so that you as game developers launching game developers can just focus on making a fun game all right so this is for the Y now let's go into the how how does Mud solve these problems um mud is built around an architecture pattern called entity component system this is a very popular pattern in the traditional gaming industry for a reason but if you're not familiar with it I'm gonna give you a brief crash course on ECS in ECS an entity is just a numeric ID so in our case it's just a un256 and then you have components you have components oops you have components that store the data for this entity so in our case we could have a component that stores the data like you can think of it as a as a mapping from The Entity ID to the component value you can think of it as a as a fancy like standard ethereum mapping and then you have the systems which implement the logic so components are only Data Systems implement the logic and systems don't act on specific entity types because there are no specific entity types in ECS but rather an entity is just the collection of components that are attached to it basically and so your move system as an example doesn't care about whether it's moving a donkey or a dog it only cares about whether this entity that it is moving has a position component attached to it and then it can modify that position component and if you think about it that's actually in a way how ethereum already works today you can think of addresses as entities and then a token contract like a year c721 token contract can be thought of as a component and a system mixed together and attached to this entity to this address if you wanted to model this in like pure ECS then you would just have a balanced component that stores the data and then a transfer system that implements the logic of transferring stuff all right so with ECS in mind how does math handle the state sync in Mata is a very Central contract the world contract and every time you add a contract and every time you add a component which is also a contract it gets registered on the world contract and then every time that component gets updated an event is emitted automatically through the world contract that means the client only has to listen to this one Central stream of events coming from the world contract and can then like keep the local state in sync basically and the great thing is with mud you don't have to worry about any of that because mud handles all of that for you what you do what you have to do as a game developer is just create a component contract um give it some ID and then create a component on the client and give it the same ID and mut handles the state sync automatically and the great thing with this General approach is also that we can provide generic indexes that help your client catch up faster and reduce their RPC load and you don't have to write any like custom sub graphs because all the data is stored in a very generic way and that's why we can have indexes cool now to the fun part of adding content as a quick reminder in ECS entities are just a collection of components so our fighter entity here is actually just a collection of a health component and attack component and a movable component and now if we want to add more entities or stronger entities like a dragon then we can just modify those component values give it more Health give it more attack and suddenly we have a dragon another way to add more content is to modify or like recombine existing components together for example remove the movable component and suddenly you have a defense tower and the last way of adding Quantum content is adding new components every time you add a new component the number of possibilities of combining your components actually doubles so you can just recombine your components in a new way you have double the amount of entities you can now represent as an example you add a healing component now you can build a healing Shrine A Healer and a healing potion without changing any of the existing logic and then when it comes to interoperability in theory everything that you build on chain is interoperable to everything else already you just have to make like a custom integration for everything which gets obviously kind of annoying and is not scalable so in other words interoperability needs interfaces to scale and you can think of mud as an interface for those Unchained worlds you can read the state from your own world in the exact same way as you can read the state from other worlds so all those words are just by default interoperable with each other and you can think of existing interfaces like erc721 as an interface for ownership but mud on the other hand since every component is a standardized way of storing the data and we have the standardized query system basically mud is an interface for anything like you can just write a query for any world out there and just represent whatever you want basically this query this very simple query gives you all the movable attack entities owned by this address but you can get arbitrarily complex with that so this is how much solves all the problems for building ancient games but the great thing for much is that it's actually completely genre agnostic we build two different games in-house Atlantis over the last couple of weeks two completely different genres the first one is called skystrive and it's an Unchained RTS the goal is to build your army to defeat your opponents and then steal the loot from the center of the island and then escape the loot as the first person it uses 39 components 20 systems and not a single line of networking code because mud handles all of that for you and we're actually going to play tonight at or not tonight this afternoon at the hacker basement at 4 pm so if you want to check it out come there and then the other game we've built is yet to be announced it's an Unchained voxel game it features an infinitely proceededly generated world you can mine you can build stuff you can craft stuff and it only has eight components and seven systems and also here zero networking code and those two games are completely different genres but they build on the exact same infrastructure they just use different components and combine them in a different way yeah and this is much as a summary with mutt you don't have to write a single line of networking code because mud handles all of that for you adding content is completely trivial adding a new component doubles the amount of entities the types of entities you can represent and any mod world is by default interoperable with any other mud world and that is how we solve all the problems cool all right I'm gonna drop some more crazy stuff um full nodes are great so after this like short introduction to mud I want to go over two kind of like Advanced features slash mental model from what mud is so the interesting thing with full nodes is that they give you access to the entire chain directly from the node database with a node you can do things like oh what is the counterfactual of this can I execute a transaction but slightly change the storage of that contract like what would happen if I were to make a transaction on unit Swap and have a billion die instead of like 10. um the problem is that traditional dap clients today are not full nodes they rely on things like inferior or Alchemy to serve their data and then they have to build this like complex State machine of indexers and events in order to serve the data they need to their users um as an example the uniswap client has to connect to a full node and it has to fetch the state it is interested in just in time because otherwise it would take way too long so as you like move around on uniswap and you like select different pools you have to wait every single time to know what's going on um the I don't know if you've ever read the unisub client code but it's pretty insane just to be able to keep such a short like a simple State machine in sync and there needs to be like a lot of custom code in indexers additionally the unit swap client cannot actually simulate transactions and it doesn't know what will happen if you like execute that that single Swap so the way it actually works is you have the unit swap client and then remotely you have a full node and you have a bunch of indexers and the unit swap plan has to make very slow Network requests in order to be able to populate the information that the user needs so why don't we put the full node and indexer inside the client right like that would allow you to make instant queries you would be able to index addiction however you want you don't have Network delays anymore after you're synced and then you can simulate transactions right that would be amazing um and actually for like the ethereum ogs here that's how Mist was working which was the ethereum browser like five years ago but the thing is full nodes are super expensive um they record a lot of bandwidth and storage they have very expensive cryptographic data structures that are needed in order to serve live clients so it's pretty much like it's not really practical today to put full nodes in the clients and so because of that most dapps today like if you use D5 or like whatever kind of stuff usually they have ux hurting Network calls you have to wait a lot for every single thing you have to wait for the TX to be mine in order to know what the side effects of what you have done like actually is there are services today like tenderly and stuff that allow you to simulate transactions but they add additional complexity to the code base and more often than not they need to use remote indexers which at yet another like surface of things that can possibly go down in complexity so can we do better now that we have like slightly better infrastructure than when web3 JS and ethersjs was invented is there a way to essentially have our cake and needed to um the one interesting fact about autonomous Wars or on-chain game is that they're more often than not Standalone unlike traditional d-apps what that means is that the state transition function of an autonomous word almost always only depend on its own state so as an example when doc first was running on xdi talk first could have run on a chain with nothing else but Dark Forest dog first didn't care about the other things on xdi right that's unlike most dabs today which rely heavily on like a plethora of different services on chain that they connect to things like oracles things like erc20 contracts and so forth and again this is unlike as an example unit swap where if you were to want to simulate the transactions of like a uni swap trade you would need to know about the other smart contracts like the erc20s on each side of the pool because they could be implemented slightly differently um so one like monitor model for what murders is that it's a namespaced full node which is why we think this goes like well beyond gaming it's a way to build actually like better clients than what exists today and the reason we can build a namespace full node is because as I said earlier autonomous words are mostly Standalone so mud sinks a world the word contract that Alvarez talked about it's a namespace for data and logic so data are components and logic are systems so mud can sync the data of every single component connected to every single entity and download the evm by code of every single system and the way it does it is it does its initial sync via a general mud indexer or a full node and it keeps its state up to date via a full node or a mud stream service mud doesn't need the cryptographic data structures that are usually in the full node because we don't want to serve light clients we just trust a node remotely but what we want to be able to do is like give like extremely Snappy applications by having the entire student logic client side so I think that is interesting with Mod is that components are self-descriptive components of on-chin schema that explains how to interpret their actual like row bytes um and so the mud client can read the orange schema and so compare that to a full node with a full node you know the the actual storage Slots of every single contracts but then you just have like 256 bits of like you don't know what that is this is why people write view functions in their contracts in order to be able to like load actually contextual data from those applications with mud what you get is a key value database of entities mapping to a bunch of components and it doesn't matter who deployed those components the client just knows what they are it knows what their name is it knows what their structure is so as an example when you sync like a mod full node so a mud client you would know that the first entity 0x0 has position 1245 and health 200. so it's way more contextual than the waitful notes are done today um it's because I mean ethereum is trying to be as general as possible whereas here we impose constraints in order to get features um this allows a client to run complex queries on components without any network delay so you can run aggregated queries like oh give me all the entities that have a position and a health with value 10. you can do crazier stuff like Aggregates and stuff like that but all of these are executed instantly in like one millisecond on the actual state so if you were to rebuild uniform with mud today or at least the unit swap client um you would be able to move around and do things without any network delay when it's synced and downloading the actual snid snapshot usually takes like less than a second so the other thing that is pretty interesting with mud is that it ships with a local evm so when you make a transaction in mode that is when you call a system what mud does is it runs an evm on that system given it knows its bytecode and it injects the easier State when that actual like EVN by code needs to write the state needs to read the state it registers all the side effects that happen so as an example if you were to like call the move system on entity one and you say move to X10 y minus 3 mud can run that into an evm and know that the side effect is that like oh no the position component of entity01 is 10-3 it also sends transaction on chain of course and then when the transaction has been mined on chain it compares the side effects that happen on chain with the one that were predicted if they match nothing happened and so from the user perspective it seems it seems like the transaction was essentially executed instantly which like gives way better ux and when it's not the case when the prediction fails so as an example if someone else kind of like Clash with our state by having their transaction execute before ORS or if we're behind the tip of the chain we just revert the side effects and apply the actual ones and but that happens like quite rarely actually this is how modern MMOs work they do prediction in Roblox all the time um so yeah with mud you can essentially read and index components without network delay client-side and can it also simulate transactions without waiting um and we think that oh sorry we think that this actual like increase in user experience is pretty insane we've seen it for games because that's what we're trying to do but I'm I can't wait for someone to build a D5 protocol mode and make it like the the snap yes swapping protocol ever um another thing I'd like to talk about is is this like concept of extending words with mud so today with like fully Unchained permission is up things like uniswap or dark phrase developers can extend the protocol via new contracts and custom client right that's the power of those applications so as an example in unit swap you can build an LP kind of like liquidity um mining program on top of uniswap permissionlessly you don't have to like phone the unisop company in New York to ask if you can do that similarly with dark Forest you can create smart contract players or new features um however the problem is that developers that do that they need to ship new clients and indexers when they do that so as an example if you want to build a yield like sorry not a yielded grader a swapping kind of like aggregator that finds the best prices well you need to build one inch you need to build a new client also users need to know where those new features are they have no idea that someone out there built new contracts and new features for that specific d-app um and that actually creates a clear distinction between first party code and third-party code which in our opinion like greatly hurt like interoperability and like creativity so as an example in dark first you can do something like hey I'm team XYZ and I'm going to deploy a thing that marks some planets as rewarding and if there's captures them they get some some eth that's pretty cool you can do that but now how do users know that this exists right like where are the contracts how do you like even if you had that information in your client how does your client know what to do with that data does it render a button does it trigger a Shader um similarly you probably have to rebuild all your indexer from scratch so you get a fragmentation essentially between first party code and third-party code so again can we do better um in mud the central contract is the word contract if you know the address of the word contract you know everything you know about all the components you know about all the systems you know about all the entities and the thing that is interesting with the word contract is that it's it actually has no owner um if you deploy yeah so it has no owner it's permissionless and so that means there's no difference between first party code and third-party code anymore everybody's first party so the creators of the world contract the deployers of that contract actually have no special kind of access to it they're not privileged in any mean um the word contract is non-upgradable so the rule is anyone can create components and systems so when Alvarez was talking earlier about the health component and position component and the move system anyone can register those components in those systems on the world itself um and when you do that when you create new components that is like new data or new systems that is New Logic they're accessible in the client they're indexed they can be found in a debugger they can be executed in local evm and there's actually no difference between like what the core team deployed and what like any other people did deploy as well so the only like the rule is that all systems can read from any components so and and those components can be deployed by different teams so as an example you could write a system that runs a query on the world that queries a component develop like um deployed by team XYZ and a component deployed by team TTT and they can actually aggregate those data together the Only Rule is that components have to whitelist which systems can write to their states and that's really important because otherwise an attacker could deploy A system that just resets everybody's inventories so the way it looks like is you have this this like graph of components and systems that kind of like trust each other but also you have this interesting social phenomena as where users of those applications decide what is real so if you have two position components that like don't match with each other the users have to decide okay do we believe in position one or in position two and that's really what happens today on ethereum if I deploy a new die contract my die is worthless so it's all based on essentially what you think is real but it is made in like mud is architected in such a way that you never have the problem or you need to create something from like oh like we need to like give or upgrade keys to Dao in order to let our players upgrade it snow this can emerge naturally essentially from the web of trust of the players themselves and this leads us into like an interesting kind of like idea of augmented reality so this is not the augmented reality you know with fancy glasses and Hardware it's more about layering Bayes rules with new interpretations so beyond the core components and systems all players believe in probably the ones that have been deployed by the core team the low level physics it is possible for anyone to create augmented reality layers that only a subset of players engage in and that permissionlessly so we're going to illustrate this um imagine a game it's a very simple game it was deployed by the like one core team it has three components position movable and resource there's three systems you can move you can pick up a resource so you can drop it and you can see there are three players there zero zero one zero zero seven zero zero five there are little characters riding horses and you have a bunch of resources on the floor what players do is they can vary resources around this game doesn't actually have any goal it's just some rules of physics essentially um and like as an example I can call move on my player and I would move my horse from one place to another no I'm team TTT team tic-tac-toe comes in and they deploy two new components on the world because they can you know they don't have to ask anyone those two components are the stake component in the board component and they add three systems challenge accept Challenge and resolve um now all clients are aware of those new components and systems they just don't know what to do with it yet if you open your game at that time you'll see a little install box it's like hey there is some piece of JavaScript that is linked with those components and systems do you want to use them um if you do now you can play a radically different game while still being compatible with the low level rules so as an example I can take my player I can move to the gold at zero zero three I can pick it up move again and I can come next to that player at 0x07 and call the challenge system on that player that challenge system is new it was deployed by the team Tic-tac-toe and attached one eth to my transaction the other player if they're aware of that augmented reality layer can accept the challenge stick the same amount and now my like this new system is going to create a new entity 009 because anyone can create entities and attach the stick component in the board component to it so now for the players that have the actual code that allows them to experience the tic-tac-toe augmented reality they can see your board on the floor um I know they can play Tic-Tac-Toe they can drop the resources in order to play Tic-tac-toe and someone can win they can call the resolve system and they can take the stick and destroy that entity and you can do that without clashing with the rules that all other players believe in so tic-tac-toe is just like tennis like tennis is an augmented reality layer on top of our physics I can drive in my car and look at tennis players and we're not breaching the rules like we're all like living according to the symbols but we're just like experiencing the world in different ways so it's an augmented reality and from the perspective of other players they're just like what the hell is going on why are people dropping resources on the floor on the grid but they can still coexist together other so there are a lot of augmented reality out there the main one is capitalism it was made up uh we all wear the glasses that allows us to see capitalism but I can interact with an anarchist that doesn't believe in money I can go and like have dinner with them and we won't actually experience the same augmented reality but we share the same low level rules competition is also an augmented reality the thing that is interesting with this game um is that it has it has no goal some people just made a set of interesting rules and resources but now anyone can come in and essentially puts a competitive layer on top of it many games are also augmented realities so for the people here that have played Minecraft in Minecraft servers a lot of people build minigames you know you have to break the wall underneath people's feet and fall in the lava those minigames actually don't clash with the rules of Minecraft they're just like new systems that have been created on top um and you can do that permissionlessly you don't need a governance for the world because the world is onerous anyone can deploy new components and systems and players believe in whatever components the system they care about and I'm going to pass it to our friend Kelvin who's gonna drop some more cool stuff all right hello hello hello hi everybody how you doing how you doing um so you want to build an autonomous World good luck good luck have fun trying just kidding of course um I'm gonna be talking to you today about the op stack uh technically we were originally hoping that this talk would be after the other talk about the op stack so just pretend that you're five hours in the future you've watched the other talk and you know whatever time doesn't doesn't matter anymore so introducing the op stack except Carl has already done it five hours from now kinda we still need to write all the docs so if you want to use this you're going to have to dig deep a little bit uh you can talk to me afterwards about how you can actually achieve this but all right introducing the op stack I want to talk to you a little bit about basically how you can achieve this build your own system today and get really good security guarantees at the same time all right so boom what is the op stack essentially the op stack is rollups gone modular over the last year we've been designing and building this thing called Bedrock which is the next major upgrade to optimism um and while we were doing that I think we realized that the key part of building a solid roll-up client was to make it as modular as you can possibly make it and we sort of we'll talk about this a lot in the talk later today the back-to-back talk that I have with Carl but we kind of realized at a certain point that if you really want to maintain one of these things you can't allow different parts of the system to bleed complexity into other parts of the system and the classic example that we saw over the last two years was we separated execution from proving this was the big thing this is what basically optimism's evm equivalence upgrade arbitrims Nitro upgrade they all followed the same pattern which is let's build the client the way that we want to build the client and then let's make execution work on top so the end result of all of this overall this time is that we've broken up our system into a highly modular system with lots of different pieces we think that there's three simple layers that kind of follow what you think oh there we go look you've seen these things before consensus execution settlement you've seen these things before if you've heard anything about modular blockchains you kind of have an idea of what the op stack is all about except the lp stack is putting this modular Theory into practice so the real difference here is it's not just charts on a blog post about okay if you plugged in this data availability layer you'd get you get this behavior and if you plugged in this data availability layer you'd get this other Behavior instead it's actually concrete components that you can Implement and you can switch out to get the behavior that you want um so I'm going to talk to you about the Core Concepts the different components that you can switch out and sort of what you might do if you wanted to build a game to to use these different components and do something really interesting so the first layer that we like to break out of these different there's obviously the three the three primary layers inside of consensus we think of two sub-layers quickly here we've got what we call data availability and derivation but I'll start with data availability so you've probably heard about this you probably have a basic idea of how this works data availability is where you publish your data right so the idea is well people don't always want to publish their data to ethereum all the Roll-Ups originally were built under the idea that okay we're always going to publish our data to ethereum so let's just build our architecture under that assumption and so the op stack basically says well actually whatever as long as you kind of have an array of blobs that's what we call them they can be blocks if you're ethereum they can be blocks if you're Celestia they can be all sorts of different things but essentially what you want is an array of things where you can publish data to and ideally you have some properties about this data availability layer ideally it's somewhat immutable otherwise the whole thing is just going to keep reorging itself and that's going to be really annoying ideally the data is actually available otherwise you can't do anything with it so there's some properties that you want about this but the nice thing is the op stack basically says well whatever you can Define any data availability layer as long as it fits this basic idea that it's an array of you know byte strings you can slot it in as your data availability layer so concretely what can you do with this I think the easy example is instead of putting all your data onto ethereum you can use something like a data availability committee instead reduce your costs make your system cheaper I think this is a really good application for gaming because you basically you don't need those sort of ridiculously high security guarantees that you do when you have a basic roll up where you're just putting data on ethereum the ability to switch this out for a data availability committee or a different data availability layer all all together is really important to you know get the exact sort of security properties that you want depending on the amount of value that you actually need to secure all right derivation derivation is interesting I think derivation is one of the coolest parts of the the op stack design and essentially the idea is that derivation is how you are pulling inputs for your blockchain from the data availability layer so derivation is basically like a function that's aware of the structure of the data availability layer it's like you know let's say we're putting data on ethereum it's aware of the block structure it's aware of how data is put onto ethereum and it parses that data it pulls it out and it turns it into inputs to your layer 2 execution engine derivation is really important and it's you know generically you can understand why this is important let's say we're a roll up you know the same thing that we're doing for unannounced game will be announced soon if you're one of these systems what you do generically is you post data to an address on layer one and maybe you have deposits and maybe you have some other sort of information and you transform all of that maybe you know if it's data posted to player one by the sequencer let's say you you decompress all of that data you transform it into inputs on layer two and then you're going to execute those inputs derivation is really interesting I think there's a lot of like hidden things that you can do inside of here that might maybe aren't always obvious um one of the things that I think people can achieve with this is have in-game events or have events on your chain happen when things happen on the layer one so let's say you want to have an in-game event happen every time there's a uniswap swap event on layer one over a certain value what you can literally do is in your derivation function you can take our derivation function you can tweak it slightly and you can say okay I'm also going to look for uniswap swap events and then whenever there's a uniswap swap event I'm going to generate a transaction on layer 2 that makes this thing happen and the end result is that in my game fireworks go off whatever you want you can basically modify this however you want to have the state of your layer 1 Define what's going on on your Layer Two it doesn't just have to be transactions you can build amazing things with this and it can be very very stateful so you can do a lot of cool stuff here boom execution okay execution is probably what you think execution is it's your execution engine on Layer Two it's your state transition function it's the thing that takes up the inputs that were generated by the derivation layer and it takes the current state and it's going to translate that state into a new state right it's going to take that state into a new state and that state is going to be used to derive new inputs and it's going to be you know you get it right every time I make a transaction and something happens in my voxel game and the world updates that's what's happening under the hood in the execution engine the execution engine in the op stack lives behind the engine API right so what we decided to do was ethereum you know while it was going to the merge needed consensus clients and a needed execution clients right so you need a way to talk between the consensus client and the execution client and that interface between the two clients is the engine API so what we did was basically take the same API and you stick the the data availability and the derivation thing and you separate that from execution by that same exact API so it looks exactly like ethereum looks um the nice thing about this is that you can plug in absolutely anything in here you can it doesn't have to be the evm you can take the evm and maybe you can make some easy tweaks you can add a new pre-compile you can tweak a few op codes if you really want and that'll just work really easily in optimism in Bedrock we add a new transaction type we add this deposit transaction type that's really easy but it really can be whatever you want it could be Bitcoin it could be a Game Boy as long as you have a state transition function and you wrap it inside of the engine API you can do whatever you want and it should just work the whole thing should just work so if you want to build a game and you want to use an evm and you want to add a new pre-compile because you have some complicated game State function that's just too expensive to run inside solidity then you know just modify the evm if you want to run a totally different execution client all together you can also do that and it just sits behind the same API and all the rest of the stack all the roll up stuff all the transaction stuff just keeps working as if you didn't do anything at all right and then finally settlement settlement is this weird one it's a little fake it's you know what does this really mean I like to say that settlement is about establishing a view of your system on some other system and it's all about making claims right I'm making a claim about the state of my system onto another system and so settlement is really useful obviously in the you know in traditional roll-up settlements is really useful if you want to do withdrawals if you want to be able to move funds out of your your roll up onto let's say layer one you need to be able to settle the state of Layer Two onto layer one so that I can say okay that is the true state of Layer Two let me pull it out let me let me operate on it and maybe I'll give you a withdrawal as a result but the thing is you can do a lot of really interesting things with settlement you don't just have to make claims about let's say the total state of the system I think a really interesting way to think about settlement for gaming is that you can have a short-lived chain that plays some game let's say we all want to play a chess tournament right we can play a short-lived game and then at the end of the game we can all you know we see who wins the whole tournament and we can make a claim and we can say you know Kelvin won the whole tournament and that's one that's the claim that I'm settling and then you can have this generic proof system that will just prove arbitrary claims about the state of your layer too and so you can prove this idea that okay Kelvin won and then we can resolve that winner back to layer one and we can pay that person out and then we can throw the chain away because we don't need it anymore so we got this short-lived verifiable system right this game that we know that the whole thing ran as it should have ran there's no weird State coming out of it we prove that back to the base layer and then we can throw the whole chain away and we don't have to worry about storing it and so for short-lived you know high capacity games you could really bump up the gas limit you can do crazy stuff because you're not worried about State bloating to infinity and then you can just settle any sort of information about the state of your Layer Two back to layer one all right no sequencer no problem actually currently a very big problem but this is just an idea of basically what where we imagine this system going in the future because there's a big issue which is that every single time I talk about this idea somebody comes up to me and they ask me doesn't that mean you still have to run all this sequencing infrastructure and the reality right now is yes but we want to get to a future where the answer is no right because most people don't really want to run this infrastructure you want to focus on building a game especially let's say you just want to build something small you want to run it for for a couple of days you want to put it up there the reality is if you if you're you know I'm sure that the average person does not want to deal with the level of stuff that we have to deal with at optimism to keep the sequencer running so we have this concept that we're exploring called shared sequencing basically shared sequencing is taking all the headache of running your own sequencer and it's deleting all of that and the basic idea is that all of these different autonomous worlds can share a single sequencer and of course when I talk about the students are you can see there's multiple machines there I've had to think about the sequencer as sort of a single logical entity but in the future what's going to happen is you're going to get decentralized sequencing you're going to have something that looks like a leader election where at any given time slot there's a specific sequencer and that sequencer sequencing your roll up and then there's the next time slot and the next sequencer comes in right so the the thing with this is you could do something really really interesting if you have one sequencer sequencing all of these different chains at the same time right instead of having multiple different chains that are talking to each other the problem today is if I have let's say I'm ethereum and I have Cosmos right now and I want to sort of I want to interact between a cosmos chain from the from ethereum they don't share a validator set which means that my communication inherently has to be asynchronous but if you have a single sequencer producing the blocks on many different autonomous changes autonomous Worlds at the same time you can get this amazing property of atomic composability between all these different chains you basically have a single sequencer saying okay there's a transaction coming in on chain a and there's a transaction coming in on chain B and I'm supposed to guarantee that they can come in anatomically and I can do that because I sequence all the chains at the same time so now you have different games different worlds different realities that can interact with each other they're their own States right there the validation is separated none of the validity of one of these chains depends on the validity of the other chain but they can talk to each other as if they're on one unified chain that's crazy right now now you can have I can have an action in one game all of a sudden create some simultaneous action in another world at the same exact time if those two worlds want to want to talk to each other so this is part of something that optimism is playing with that we're calling the super chain we think that this extends a little bit more than just its shared infrastructure I think that the incentive here is not just to share infrastructure it's to share code it's to share a set of values is to basically collaborate on having all of these different games and all these different worlds maybe it's not games maybe it's entirely different Roll-Ups but they basically I think there's we think that there's a strong incentive for these systems to not just be able to transact atomically but to really be able to collaborate with one another towards some coherent Vision because you're much better joining in on this system than you are trying to build your own chains separately with your own sequencer set and you have to run all the infrastructure and you don't get to talk you know atomically with the rest of the system so you know long live the super chain very I would highly recommend if you're interested in this how this might work in more detail come to the back-to-back talk with Carl and me later this afternoon we'll go into much more detail about how this how all this works all right where are we all right so the other question I get is why make it you know free and open source right aren't you basically just like letting people compete with optimism um and build their own role up and the answer is like kind of yeah right this is the idea um and and the idea basically the argument is that the reason we have to do this is because there's just no other way to do this we need you know we think that there's going to be this explosion of people who are interested in building layer twos interested in building layer threes right we're already seeing all these you know big L1 systems come in and they're experimenting on the execution layer right they're they're competing with ethereum on the execution layer they're saying we're going to build a parallelized VM and that's our advantage and if you really want to survive you're going to need to be able to compete on this stuff and we think you're going to need to be able to compete on this stuff without having to have 25 Engineers work on this problem like three years like for three years like we did and instead you're going to want the ability to have three Engineers figure out how to do this in three months and start business out of it so this is basically the argument we if you if you want to really make it possible for ethereum to continue to compete and for people to experiment on the execution layer experiment on the derivation layer experiment on all these different layers it just has to be available right if there's not a permissive license on it you can't use it if it's not if it's not modular enough if it's too hectic to try to hack in your modifications to the execution layer you can't use it so the goal is just make it as available as possible so that ethereum can continue to compete on every single layer of the stack but you can still stay within the ethereum ecosystem um and you know this is us today this is where we are this is we got a lattice we got a couple other people and you know this is the world that we're imagining right we're imagining that basically everybody is building on a system like this and they're collaborating and they're working on a shared infrastructure and by working on a shared infrastructure you share audits right you can share engineering time it basically takes you a hundred times less effort to build 100 companies instead of having every single company fragment and build their own system you basically have all the freedom in the world without actually worrying about the low-level technical details about how are you going to publish transactions to layer one reliably how are you going to deal with reorgs right how are you going to make the proof work because all that stuff is extraordinarily complicated there's no reason why every single person who wants to build one of these chains should have to basically build it from scratch doesn't make any sense all right so some closing remarks here basically go nuts build something crazy you can do so much with this architecture right you can swap out the data availability layer make your chain cheaper you can swap out the execution layer build an entirely on-chain game you know you can literally take an emulator of some system you can put it into the execution layer and you can even prove that the whole emulator functioned properly you can do an enormous amount of stuff with this and the nice thing is you don't have to worry about how are you going to go build the sequencer how are you going to go build the proof and all these different things you basically get all that for free so that's the idea um where are we yeah thanks we're thanks for coming to my TED Talk um where are we right now so the code is all there it's possible to hack on this stuff the real the next goal is to take take all these modules and make really really clean documentation so it's clear what you have to change where you have to change it to make all this possible if you go in today you know lattice has been extraordinarily Brave to go in and basically hack this system together and really make it work for them and we've seen other people do it as well if you're interested in doing this you know come talk to me later and I can give you pointers but the goal is you know right now it's still a little early we're looking for people to come in help us figure out where the apis aren't clean enough right help us figure out where the documentation is in clean enough if you're if you know what you're doing and you're really interested in hacking on something new like come find me and I will try to help you get started with this whole thing and the goal is make this accessible to the average person who just you know doesn't want to under doesn't want to deeply understand how this whole architecture works um so that's me I'm gonna hand it off now all right you want to keep that mic all right cool three minutes left um announcement time announcement time so just like the op stack is meant to like essentially increase pluralism by making something free and open source and easy to use we kind of did the same thing with Mod mud is MIT licensed at soft launch today and to kind of like pave the way forward um that is an optimism have been working together over the last month and a half on an autonomous world that was built on mud and runs on the op stack so we're like pretty excited to show opicraft to everybody it's a 3D voxel game powered by mud running on a crazy degenerate op chain uh yeah I even have a video well I will see if it plays but Alvarez and I yesterday were trying to build the house so yeah that's that's uh that's running on DVM guys it's it's a procedurally generated world I can't wait to see what people will do with that you can deploy marketplaces oracles extend it build augmented reality tennis capitalism whatever you want um it's going to be open source soon it's playable today um let's let's let's let's actually see how we built the house I remember it was quite quite hard given we didn't really have consensus on how to how it should look like yeah okay cool we did it um opcraft is gonna be soft launch and playable at the autonomous World Arcade at 4 pm today at the hacker basement so if you want to play it um come there additionally we're going to have a tournament of skyscrive which is the RTS that was built with mud uh we have playlisted it weekly for like the last month people really like it there are Starcraft players that don't even know that it's running on chain they just like the game so yeah we're gonna try to hit 64 players so come along as well hacker basement 4pm so what about the other stuff well mud is actually already available we just don't really talk about it because it's not very documented it's like the op stack it's a mud.dev um the code is on GitHub um we have a bunch of teams building stuff with it but it's it's yeah talk to me if if you're interested um the op stack is going to be announced soon by Carl at 1 30 pm on the main stage um and yeah that's us thank you guys [Applause] 50 minutes 50 minutes yeah it was 15. good job did you good job it's a great talk foreign okay awesome you understand what is sure after this one uh Carolina yes yes okay you're next yeah after no but Carolina is not showing up so you're not okay okay sounds good but we are but but [Music] are we moving the schedule foreign thank you foreign [Applause] from open Zeppelin uh those are not my slides yeah yeah those are my slides okay so thank you everybody for attending uh I'm working at open Zeppelin and this talks talks about like five smart contract pattern but that's actually a lie the real thing I want to discuss is what I think are it's a good mindset when writing solidity contract and basically the pattern I'm going to show you are more of like examples of what I think can be a fun development and solidity and how I think it aligns with the good good development practices wait distance okay yeah so I think one of the two main points I want to make today is that a lot of the ecosystems value is a result of smart contract composability uh that's particularly true of defy and the first thing you should do when writing a smart contract is make sure that you are leveraging as much composability as possible and trying to make sure that your contract can interface with all the existing tooling that would be relevant an example is people always ask us like hey can we make an honorable contract payable like someone could buy it and this makes really no sense because there is already a lot of tooling for buying assets and that's the nft space in the nft space you can just buy anything from openc or variable or any other marketplaces and we don't want to redeploy that for for the NF for the ownable contracts that that exists so the idea is that when own ability is just like the ownership of of a contract in order to to have access to it to some admin functions well you could just turn that into an erc721 and and this is how you would do it basically you can very simply say like hey my owner is just the owner of a specific token on an ownership registry and I can have a normal owner modifier for that and when I want to transfer ownership the only thing I will have to do is go to this ownership registry and try to transfer as a corresponding token no on the ownership registry you would have to override the either approval order function to allow that but that's very easy to do and so here in this example you have a basic Factory this is actually live on mainnet and when you want to deploy a new vesting wallet with a beneficiary for it well here's the beneficiary it's just the owner of the nft on this Factory and when I deploy a new contract I just create a new clone I initialize it and I mean the token and that's the equivalent of my owner if the contracts were ownable the difference is here my contract show up on openc and I can basically sell it or transfer it very easily uh if you want to go a bit further you can even have like a universal address ownership registry which I think is pretty fun because it allows you to get rid of the minting part uh by just saying like a by default all the tokens are already minted and they are owned by the address that corresponds to the Token ID I mean all the token ID that matches an address in exact smart form and then you can just say that hey it's not possible to burn them you would just send them back to the original owner and there is this is approval ownership that I'm doing some fancy stuff with codes but you don't need to care about that and and this can just be another approach I think it's nice and it it shows creative use of VRC 721s um and another thing we use is that ownable obviously is something that a lot of people are familiar with but the granularity is really bad uh sometimes you have different admin functions in your contract that you want to have different access for and access control does that pretty well access control is provided by open Zeppelin the thing is that access control is maybe a bit more difficult to work with because you cannot transfer a world you need to Grant it to someone else and then either get it revoked or renounce it and so it's very nice for some users but at the same time own ability has some advantages so let's just combine both let's just make a contract that as an owner and the owner is basically the default adminual and then you just cannot Grant or revoke this default adminore because that's controlled by the ownership part but the owner still is the admin so it can grant any other one and this here it's ownable but it could be the ownable registry so just before so you could have a contract where the owner is the nft orders and then you have all these access controls that are managed in that way or you could be creative and use ERC 1155s here and so yeah that's that's just some small ideas but it's not very complex code I think everybody can understand that but the point I really want to make is that you can combine tooling together and combine contracts to make sure that everything is as basically as seamless as possible the second thing I want to to present quickly is that the ecosystem is constantly changing and and basically when you write a contract I mean you can make your contract upgradable but even without the upgradability part you really need to care about what is going to be the life cycle of my contract and are there Small Tricks that I could use that will make my users life better in the long run and that's for the users but also for like the UI designers or and basically anybody in this space so these are just two small pieces of code like 0.4s and five that I came up with very recently and I think that that's things that are are interesting because we never expect a hard Fork to happen until it actually does and people start trying to do a proof of work blockchain and then the bridges that are on this proof of work chain starts breaking and that's a pain so you could imagine having this very small piece of code here that basically takes no size on on chain that just gives you two modifier that verifies that the chain ID that you're currently using is the one that was registered in immutable storage when the contract was deployed and then you could do that to create some kind of bridge where actually most of the function remains completely trustless with this only initial chain modifier but if for any reason uh there were to be hard Fork the version of the bridge that is on the chain that changes the chain ID then all those would be automatically disabled and you get into recovery mode when some like multisig would be able to take over and this multi-seek is not a threat for the user on the legitimate chain because because of this only fork chain like this admin cannot do anything nasty to your users but that's that's a mixing point that would have saved some pain I mean it wasn't the proof of work chain so maybe we don't care a lot but who knows maybe there will be more legitimate Forks at some point in ethereum's life cycle and another one is that that's something we provide as open the screen and that's what we call the multicold contract and that's very simple it's just one endpoint one small functions that allows you to delegate to yourself with an area of data and that's very easy for you to integrate into any of your contract and I don't think there is there is any reason not to do it and the way it's being done is earlier we saw this example here and here you have this multiple that maybe you didn't see because it's red on black so it's not really visible but what it allows you to do is when you went to create a new best thing for one of your investors or someone when if you have 10 or 20 investors maybe you don't want to do 20 transaction that do 20 calls to this new wasting function so what you do is just that you encode like you have a map of entry and you record the function using like e server.js or F3 of whatever you like and then you just have to do a single call so there is a single transaction here that you have to wait for and what it will do it will basically run like all these these operations so deploy Trend investing at a time or you could do an approve and some something else or you could batch transactions together like you don't need to wait for Icon abstraction to batch transaction you can already do it at the contract level I mean providing that the target is the same contract for all the subcodes and that's as simple as including that so yeah it keep in mind that there are all this nice trick that could possibly help your users down the line and I think it's it's important to have that in mind when building contracts and try to be creative that's it [Applause] yes you know the mall design and stuff yeah so I'm going to repeat the question for for the stream and the live and uh the question was about like can access control be used for smart toilets is that that's it basically I think uh well uh it really depends what's kind of Smartwatch you want to build there are different kind of smart wallets if it's just something that you are the sole owner of I'm not sure it brings anything new to the table uh but if you are doing a multi-sig maybe it will be relevant I mean my opinion is that a time lock for example is a kind of smart wallet because it's just someone that will manage asset and do operation but with specific rules and in the open Zeppelin time lock we use Access Control to separate the role of the proposers from the executors from the admin that may have the right to cancel potentially so yes if you are building a multisig and you want to have different privileged access maybe and having an overseer that is able to recover in case of of issue having signers having proposers that basically you're turning your multi-stick into some governance mechanism which which it basically is a governance mechanism so yes you could use Access Control uh hey uh in the example with a multico that you've shown we are deploying the same method like a byte code for this method in every contract wouldn't it be better if we have it deployed separately yes it would but it's not possible right now so like if we had a EIP 3074 live we could just have this make use this OS and oscore mechanism to do batching transaction and and you would not have to include that in your contract the thing is that this is not available now it will not be available until at least Shanghai and maybe later so I think the bytecode increase is is really small compared to the the value that is added to your contract right now but yeah in the long run hopefully we would have already supported at the at the execution level layer hey uh great talk by the way uh in the ownable ERC 721 part you were talking about how you could basically ditch the ownable the ownable library right what what advantage I I kind of missed the point of like what's the advantage of implementing the ownership inside the ERC 721 logic instead of just bringing ownable is it just like byte code size or is there any other advantage that I'm missing no the rare advantages in in composability the examples for example your your own Apple contract it could be tied to assets maybe you would want to consider that as a class of its own that you would be able to land against collateral or maybe it's uh maybe it's like a vessing wallet that is basically a future uh financial future that you want to sell on unisa on openc right now you cannot sell a non-able contract on openc but you can sell an nft so the way here is to make sure that your contract is compatible with all the tooling that exists out there openc and others also just being able to see the ownership in your zirion or any wallet your use that's also something nice thanks thank you [Applause] [Music] know why I won't give it a life [Music] [Music] cause all I need for you my angels [Music] [Applause] [Music] [Applause] foreign [Music] [Music] foreign [Music] foreign [Music] foreign [Music] [Applause] [Music] [Music] foreign [Music] [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] foreign [Music] [Music] are we good to go should we do it let's do it all right standing room only feels good man all right so uh Aaron McMillan and I are both the founders of a quadratic quadratic funding protocols or unfounded CLR fund I founded Bitcoin we've been friends before we were founders of that project and we were talking about how inspired we were of the ethos of client diversity that has come out of Prismatic labs and other teams at the base layer and how that Trent go around this way yeah those are not stairs anyway so uh we were talking about what it would mean to have practical pluralism at the public goods funding layer of the stack and so I've assembled some of the top founders of public goods funders in this space to talk about practical pluralism so I'll hand it off to you Orin so I'm just going to read a quick excerpt from the article that we wrote about the essay that we wrote it's up on this QR code if you want to go and check it out later because I won't read the whole thing because we don't have time but here we go so pluralism itself is a primitive for anti-fragile resilient and regenerative systems as an ecosystem ethereum has done a great job of fostering diversity in its Mining and validating clients similarly we should insist on pluralism across the full stack of web3 Technologies uh and uh culture so this includes discrete products like wallets RPC nodes Dow tooling public goods funding mechanisms amm stable coins uh developer tooling as well as the intangible influencers like the people groups communities uh and opinions which participate in and hold its way over our ecosystem so we we're all here today because we believe in client diversity we believe in pluralism as a primitive and we want to join we want you guys to join us in kind of extending this ethos of client diversity and pluralism to other layers of our Collective stack so by having pluralism as a core value in each kind of vertical we make it more likely that the space tends towards capture resistance and not fragility participants should be able to choose or to use or not use any of a number of options for any given need and so by having pluralism at the kind of Beating Heart of each Niche we ensure the space is anti-fragile if there's a major bug discovered in one system the resulting cascading harm can only go so far because there's always another alternative system to pick up the slack so for web 3 to truly Express itself diversity and pluralism must be a core value I mean I hand it off to Griff to say a little piece on this as well yeah and I think we need to make sure that we're watching for opportunities for pluralism I'm really worried I want to make two points I'm really worried number one about etherscan I think it's the hidden centralization that we don't Matthew Tom and The Ether scan team are amazing and they do great work but that is the biggest Honey Pot in our industry and we don't even think about it if you can hack etherscan and say you sent a million dollars somewhere you sent a million dollars somewhere we we really need to make sure that we're funding Alternatives like block Scout and I'm really worried about block Scouts since gnosis just added gnosis scan an etherscan on that chain and now where's block Scout gonna go we really need to think about blockchain explorers I also just want to say uh pluralism goes if we have this infrastructure at our base layer we can extend pluralism to the world we have monopolistic governments telling us what to do all the time and demanding Monopoly over public goods and if we could instead change it so that we have competing organizations that are trying to meet the demand of society to satisfy our public goods needs we'll have a much better world and this will only work on top of a practical plurality based layer hey um so I'm Carl I'm contributing to the optimism Collective a layer two and we had practical pluralism in two spots one inside of our protocol we started out building a monolith but it was rigid hard to contribute to and Bug prone we needed a multi-client ecosystem in our ecosystem so we took a step back we split it up broke it into modules and then now we're actually building towards this multicline ecosystem and have multiple clients for Layer Two so that's practical pluralism at work allowing us to scale our protocol and this is just amazing an amazing moment of practical pluralism on stage here today we spent so much time focusing on Brands but I am a believer that there is something which is forward progress and that is why information and open source is so incredible because you can actually make forward progress for an ecosystem it's not about you getting forward it's about moving the ecosystem forward as a whole so that's it wow that was great hi everyone I'm pm and genico founder and CEO of open Collective we are not a web 3 project so sorry about that but what we do is we fund a lot of Open Source projects we currently support 3 000 open source projects we do project directed funding and the way we do it is by creating an umbrella organization that allows them to access funding from companies and individuals and foundations that otherwise they wouldn't be able to access and so our approach to pluralism is really by enabling any open source project out there to be able to receive funding they don't need to be big they don't need to be fancy they just need to be an open Collective and in the past four years we've distributed 30 million dollars sorry in public directive funding so that's what we do great okay my name is Abby I'm the head of community and governance at radical we build decentralized collaboration tools for developers building decentralized Technologies if you see me talk I love free and open software I am a Foss fanatic and I believe that practical pluralism that's a tongue twister can save the internet the internet is being captured by anti-competitive forces that censor and capture and continue to extract and if we don't build against this by investing in technical plurality giving people the ability to exit infrastructure to freely act on their protocols and their infrastructure instead of relying on platforms to keep their experience if we can do that if we can be more plural in the way that we build together if by ownership distributions um radical and Bitcoin just did an awesome public goods Alliance we did a token swap if you can embed pluralism in your ownership that's another way of securing resilience and then finally if you can build pluralism in your participants in the people in your network by building super diverse multi-stakeholder governance you can build practical pluralism across the stack and build a better internet for everybody that's what I think is great I think that was one minute right hey everyone my name is Trent Van Epps it's in first it's an honor to be with these people so many of whom I respect I'm a member of the protocol Guild which is rebalancing the incentives to contribute to the core protocol making sure we have people maintaining this infrastructure that the entire ecosystem depends on and that the people that are working on it are properly compensated and motivated to continue doing this work for many many decades to come and I would like to point everybody to a great talk yesterday from Josh Stark of the EF he included many of the organizations represented here on this slide uh I encourage you to go check it out it's about the EF generally but um uh he he references or Compares uh organizations fundraising for public goods as ethereum's civil society and it's a really apt analogy because um we don't have a government in ethereum we have the private sector which is people that are you know building tools and applications for people to use maybe profit motivated but we desperately need to maintain the civil society that is making sure that the publicans of ethereum are maintained and that people can get the resources to build them belonging to the Future um so I'd encourage you to check out that talk and imagine uh this this group of people here as you know the Vanguard of civil society and ethereum and it's something that we need to make sure is uh encouraged to we should be able to um contribute to the Civil Society as well um while having these organizations building alongside of each other um yeah go check out that talk alrighty I'll bring it home uh so all right Kevin owaki founder of Bitcoin repent for building a centralized monolith in the beginning and I'm really glad to be seeing get coin move towards a decentralized modular infrastructure and I think that that modular infrastructure is going to enable getcoin to be more plural in the future um and I would love to I'm not in control of the Dow in any way but as an outsider I would love to see a future in which we build on top of the modules that CLR fund has pioneered that giveth has pioneered retractive public goods funding at optimism open Collective has been an inspiration for me from the start radical same thing and I'm really proud of what protocol Guild is doing with public goods funding for the client developers in the ethereum ecosystem I really hope to see uh to give another talk on practical pluralism in a couple years and invite we're going to figure out how to put 20 Founders up on stage of public goods projects in 2025 and I think that we want to eat our own dog food and be practically plural with the public goods funding infrastructure of the ecosystem and this is a challenge to the rest of the ecosystem whether you're building nft marketplaces dexes or any other piece of infrastructure to embrace modularity and pluralism from the start and uh I'm so inspired by you thank you for joining this panel and please join me in a round of applause for our panelists all right right on time there we go thanks everyone see you in the in the lobby foreign [Music] [Applause] [Music] foreign [Music] [Applause] [Music] foreign [Music] [Music] [Music] foreign okay can you hear me yeah hello my name is haiko I'm a developer at Corpus Ventures and I'll present you now dm3 what is Team three team three is uh a simple protocol for messaging it's decentralized it's open and it's secure to achieve these people but um both team 3 on established with three protocols like ens the properties I just mentioned make it sensorship resistant we designed it so that there is no single point of failure and with the M3 users are in control of the data everyone can write an own implementation of team 3. the basis for dim 3 is the record registry where users can store their profiles and be used in as text requests for that and on the middle layer we have the delivery service delivery services and buffer the messages until they are delivered to the messaging app and on top you can see the messaging app since the registry is the core of the protocol I'll now explain a little bit deeper how it works as you can see we have the public encryption key in the text record for the profile and also the signing public signing key and also important is the delivery service name so there must be at least one name of a delivery service the delivery service tax record also contains sorry no it works again okay um the delivery service text record also contains public keys and it also and it contains the URL this URL is pointing to the delivery service instant where messages can be sent to it's also possible to store data off chain or on layer 2 by using ccip this allows the creation of Team 3 profiles without a high transaction fees or if it's completely off chain you don't have any and it also makes it possible to include external public key databases this slide shows how a message would be delivered from Alice to Bob so at first Alice types a message into the app then the app will retrieve the team 3 profile of Pop which contains the delivery service name he is using in The Next Step the app will retrieve the delivery service text record where there is the URL of Bob's delivery service then the message is signed and encrypted and sent to Bob's delivery service the delivery service will push the message to the app that will be decrypted and the app will look for the profile of Alice and that's needed because the signature needs to be checked and if it's the signature is fine um the Bob can then read the message besides the protocol definition we also have a reference implementation the reference implementation consists of four different packages we have the dm3 web app as you can see a screenshot here on the left side it's also online available on the app.gm3.chat besides the web app we have the react package this can be used to include a widget of Team 3 into other apps and then we have the backend package this contains the delivery service and finally we have the dim three lip which contains basic protocol services so um we are working also on protocol extensions which takes care of things like group messaging these extensions are optional if you want to write a team 3 implementation you only need to follow the dm3 message transfer protocol so that's our roadmap until now we are published the protocol craft and the reference implementation a critical goal of Team 3 is to enable interoperability between currently isolated web history Messengers we are now talking with many of those messenger teams to understand their needs and yeah please let us know if you want to join the discussion after we finish that process we'll publish the specification and adapt the reference Implement implementation yeah um if you want to uh include team 3 into your app let us know we'll try to support you that's it thank you [Applause] question foreign [Music] foreign [Music] [Music] [Music] foreign foreign thank you for coming I'm Adrian I work at open Zeppelin and today I'm going to show you how you can very quickly build your first contract with open the plane Wizards very quickly a few points about open Zeppelin you may know us but our testis now is that there is a trillion dollar open economy being built on Smart contracts and we are not the one that are going to build it you guys the builders are going to do that through your dabs to device through everything but in order to do that you will need a set of tool products and services that will allow you to do it in a safe and effective way and that's where we're coming trying to be the leader provides leading providers for for solutions for for Dev developers and people in this web 3 space uh we do that through many offerings or it's obviously a Defender that I encourage you to try if you haven't tried it already for for managing your contract uh and and also the open the print contract Library obviously and we support a lot of network so last year one thing we did on the contract team is create the the contract Wizard and basically so it should be animated but it's a PDF so sorry you'll see in connection later the contract quiz are basically a website that allows you to bootstrap basically a lot of contract trc20 721s Governors we'll see that together and the idea is to remove as much pain as possible in the early stage of building your contract by providing what is common to everybody what is easy so that you can then focus on either just deploying them and building your your app on top of it or customizing it with some logic so yeah we don't have much time so let's just go to a demo so you know how the network is so I'm just running a local instance here but you can get that through wizard.thensepin.com and for example today I propose that we both create a governor Dao that we could all be participant in and our participation in this Dio will be represented by an nft so we'll start by building an nft contract so we're going to take a nearest 721 contract we're going to make it mintable and you see the code change so if you are teaching solidity like using that is also a great tool for for for showcasing how like adding features modifies your contract so I'm putting the vote module obviously because that will help us a lot I'm using roles instead of own ability but you see that the wizard updates everything very nicely and and that's it that's a very simple maybe make it burnable but that's a very simple uh nft contract so once you have that you can just copy paste download it but what we're going to do is open it in remix and it's also a local instance of freemix because Network um and if this one and and here you see that your your code is here uh it just got put into into this part here so we have the file and we are ready to work on it but we want to do a governor so we just need more than than just an nft so we're going to go back to Here and Now go to the governor and let's make a governor that is pretty simple with a current that's at least 10 nft holders we need to participate obviously we are going to use the RC 721 votes uh we don't want a time lock but we want to make it upgradable to uups so yeah so that's a governor that is upgradable and since it's upgradable maybe we don't want to have the setting updateable you will update and to upgrade you do what you want that's not just our code so it turns out to be a pretty small piece of code but if if I had put that like you see that there is a lot of over specifically some overrides that are sometimes painful so the result is here to to help you figure that out and so know that I'm happy with my Governor I'm going to just open that in mix [Music] leave this one remix is a bit strange but now I should have both files here my token and my Governor so let's let's deploy so I'm going to use a local compiler because authorize it's not going to work without network and I'm going to compile this file this is possibly the longest part of deploying a contract is actually compiling it in remix in this case hopefully it doesn't take too long because I only have three minutes left okay it's good oh one thing we could do is like this is ownable but here we could just modify that and make it only governance so that your your great ability would be managed not by the owner that we can remove uh but by the by the governor's Governor itself so this is a good time for you to like modify your contract a bits hopefully I haven't made any type on it will compile again always the longest part yes it's good I also need to compile this which is my token so here and now that this is compiled yes I can just go here take my token so my token is here it's on your system 21. I can just deploy it again to a local instance we're not going to wait for for girly oh I removed it yeah this is okay this is my token here I've got a lot of features so I can just take my address here and paste it into safe mint to Mint myself one two three tokens yeah I've got three tokens uh if you could look at my balance I've got three tokens I need to delegate this to myself so I'm just calling the delegate function and right now if I go to get votes here you'll see that my wallet has also three votes so that's good know that we have this we are going to deploy the second part which is our governor where is the governor it's not here uh do I need to yeah okay my Governor is here we remember that the governor was an upgradable contract so basically what is going to happen is that remix is going to understand that and is going to deploy first implementation and then the proxy which it's great from remix that they support that so now you see that I have two contracts the governor and this and if I go there and I just again copy paste the address of my my account and I see the get past vote where is it um oh it's in the view function I've got a get votes that allows me to check what were my votes at block number six and at block number six I had three votes that was after I I delegated that book number three I had zero votes that was before my delegation so we're not going to do a proposal or anything we are out of time but you could take this put it into Defender to propose easily from open the plane Defender you could also link that to tally so that your user and your nft holders can vote easily and so basically in seven minutes we managed to to deploy an entire governance system Benson nft and that wouldn't have been possible without the wizard so yeah that's what we are very proud of that we want you to use and yeah and I should have put the address the address is wizard.openzaplin.com thank you [Applause] I'm not sure if we have time for question or if there is no question you can just go see us later during Defcon and ask us or or go on the Forum and and share your your opinion about all that we are building thank you foreign foreign can I go okay um hello everyone my name is Pavel I'm an Epsilon team at ethereum foundation and um this talk uh was originally about what's next in the evm but uh we shorted it a bit because lightning talks um uh but what I want to tell you about today is uh quick to give you a quick introduction to eof evm object format um but we have to start with the the current VM we have so one of the design goals of currently VM was Simplicity and uh the thing is that we kind of overdone it um and uh the the current VM can can just execute whatever bytes the it's provide you will provide to to it and that's why I kind of sometimes thinking about it as a garbage hitting machine so it's it it brings some success to evm but uh must also bring some inefficiencies to it so um one of these inefficient aspects of evm is that you need to do a lot of work except above the the actual work the instructions are doing internally so this is like the checks that uh every every step in The Interpreter you will need to perform to make sure that the AVM works as a specification wants it to go um and uh this is kind of the motivation we want to do to clean it up and the cleanup of that is to introduce a container binary container for the for the programs in evm and so that it will kind of translate the the mixture of different features and some Miss features in the in the in the Legacy VM to something that is a bit more um structured and uh and and Polished so the the main aspect of eof is to provide some metadata about the program uh including the version number and splits the the bytes into code and data sections we can also do a bit more about that this is the kind of the the continue like the next proposal that can be applied to the Mev of eof which is to introduce functions so we can partition the code section into more pieces with additional function type information and to to work with the functions in evm we will introduce two new instructions one is to call the other code blob and and one is to return from the from the call to the to the caller and this like the calling the functions internally works like allows you to move you between the different code sections in the code sections you can use uh relative relative jumps which would replace the existing Dynamic jumps and uh yeah so this is the the control flow instructions that will allow you move it around in the code sections and it won't be allowed to actually close the boundaries of the of the partitions and as I mentioned having to this control flow features we can deprecate the existing the existing jumps semantics in particular this is really useful because we can drop the jump this analysis which has to be performed about evm programs before every execution and if we kind of adapt all of that we can with additional code verification that will happen we can eliminate the this like uh first three uh checks in the AVM so um this is the additional aspect that can be added to that which we can like verify the how the functions behave internally with like simple algorithms but to sum up all of that um uh yeah that's kind of improved version of evm that has some nice control flow have the code and data separation and support native functions um yeah so that's that's mostly what I had to to show you today um these are Pointers when you can find more information I think in particular the the FCC talk from this year it's kind of the extended version of this talk so uh yeah you're invited to to see it after it um and yeah the the five bullet points in the end are all the aps that kind of specified the the broad aspect of of eof yeah I still have one minute so if you want you can shout some questions from the audience that's hard question I mean we're kind of competing with the like proto-dunk sharding and withdrawals right now um so yeah it's it's hard to tell actually uh some of these aspects were prepared for uh for Shanghai but not like not all of the features I I talked about today hi I have a quick question I'm here um so in one of the slides you said you you you strike through um stack on the floor and stack overflow and bigger basically yeah this one and only okay can you give me uh can you give a bit more details around that yeah this is done by code validation so when you want to deploy a code it will go through additional validation process and in particular when you don't have Dynamic jumps you can you can statically check if the if the function will never stack underflow and stack Overflow is a bit more complicated but you can compute like the maximum stack height the function reaches and then whenever you call the function you can check if you still have enough stack space available so that's the the second one is a bit more complex and it has some trade-offs um I think it's it's my time so thank you very much thank you [Applause] foreign foreign [Music] foreign [Music] just yeah thank you yeah yeah foreign [Music] foreign foreign yeah yeah foreign foreign thank you [Music] foreign foreign yeah that's it Justin okay this is destroy the uh yeah can I stop you destroying stuff yeah I'm destroying here all right good afternoon everyone good thing we're just after lunch everyone's like all hydrated and ready to process some fun information all right the objective of this talks my name is Rahul I work for reddit's crypto team and over the last year I've got really into Roll-Ups but I don't I see these layer dues not just as a scalability solution but rather a way to extend what ethereum can be could be or it perhaps should be um so I'm very delighted that I have with me these three amazing people who are running like what in my biased opinion is perhaps the most unique and coolest layer tools in the space so I would love for three of you to just introduce yourselves talk about what you're building very briefly before we get into like the cool things of your systems oh hey everyone uh my name is Joe I'm one of the co-founders of Aztec and I I your product um Aztecs privacy layer for ethereum um and we currently have Aztec connect live which is a VPN for all of defy and we're working on a fully private VM which has private smart contracts hi my name is Louis I'm ecosystem over three years and a half so star queer is building Security Solutions using xero knowledge proof more specifically stocks our first product you may have used is called star kicks it is the one piling severe immutable dydx diversifying plenty of other Laguna and on soon and in the last year and a half almost now we starting to work on Stark net which is a general purpose layer 2 on top of ethereum enabling scaling using a featuring complete language called Cairo so my name is Nick I'm the CEO of fuel labs and you know to describe fuel in a simple way you can think of it like a layer two we launched the first optimistic world to ethereum that was a fully trustless you know optimistic roll up no multi-sig anything um and to describe uh what we do we have a new kind of transaction processing system and this can take the form of something like Oblivion it could take the form of something like a layer two um we use egxos for this we use a different Paradigm from you know typical ethereum systems we have our own language called sway which is used to Target this system we have our own tooling We have basically a revised version of everything ethereum offers um and uh yeah you know we're here to help ethereum scale and basically incorporate all of the lessons that we've learned from you know production ethereum over the years provide ethereum a new a different kind of Pathway to scale that isn't the evm you know tool chains and evm processing systems very cool all right so we have like we have a good mix of people here we have like two companies building zero knowledge we have two companies using utxos but if all of you have like such unique branding and products so like let's let's go for a very first principle approach before I ask why you chose non-edm can I ask why not why should blockchains just not use normal VMS like I know x86 or Ram why is it so necessary to build something new I think I'll I'll take a stab at that one so um x86 and these other instruction sets are really designed for uh different Computing architectures so you know when you're designing x86 you're designing arm you're designing them to Target a hardware system and so that's going to come with its own criteria and its own restrictions and physics whereas with a blockchain virtual machine you're you're designing for a different kind of physics so you're pricing every operation you're designing for adversarial scenarios and because of this you end up having odd design constraints that really put you in a corner and you have to really understand those physics to design a good virtual machine that will both be you know great for processing but also be great for security so it really is kind of an art designing some of these systems and we've learned a lot since the you know kind of inception of Bitcoin in 2008 all the way through to to now and you know basically uh those those instruction sets are for different purposes whereas um you know virtual machines for blockchains are categorically a different thing now you can do it but you do lose some of the nice things whereas if you had designed it from scratch you you basically can kind of design a better world so yeah uh I was just going to add I think like compatibility is one of the main kind of reasons why we have to limit the feature set on uh blockchain uh kind of VMS like you have multiple clients trying to all get to the same uh kind of state update and that doesn't exist in the world of kind of like Intel um chips so it's just yeah it's a much harder problem and that usually means we get a limited feature set like we have in the evm no I don't really have much to say I mean the technical aspect was very defined yeah blockchain VMS is an art is really a good way to put it put it so what are your expectations from a blockchain evm then from a blockchain VM like what are the things we've learned from the evm what are the things that you wanted couldn't get built your own things uh I think the starting point is probably like the more complex the VM is I think the harder it is to scale um we're seeing this with kind of people trying to prove computational evm and you need like giant data centers to actually construct that proof so a simple kind of maybe tailored feature set of the VM it's probably going to result in more scalability it's maybe the first point can you repeat the question what are your expectations from a blockchain VM and this goes to like things you can get the media yeah so so um the thing is that what we were expecting from a VM the blockchain VM before now changed and changed significantly between the origin of Bitcoin and ethereum and what we know now and I guess one of the main difference is that um we now realize more than ever that we need scalability and we now discover that we the art Tech that gives that's good ability while preserving the core principle of blockchains and the core principle of blockchain is you know trustlessness and verifiability and before and I'm going to toot my own horn obviously in and talk about DK here before the the arrival of ZK as a practical technique to bring very status verification we just went to to the sources to the simplest which was the evm and now that we we are looking at this new tech and this new knowledge that we're learning you know what Fury is doing or what Solana is doing and what others chain are doing um we are bringing the new you know more top-notch computer science to it and which are providing more feature set that we are looking forward to to develop good product good tabs on top of crypto on top blockchains yeah I would say so coming from sort of like 2015 2016 blockchain to now um you know like I've been using ethereum almost since it started so for me it's been like you know a long road um and I would say that the expectations have completely changed I think but just as well we didn't the community didn't fully understand all the design constraints when they were putting it together and there was decisions made over time particularly with the kinds of architectures that ethereum chose that ended up being really costly for just compute and and for all the different kinds of design potential that you want um and as well backwards compatibility was something that you know it was was not really kind of in part of the picture and I think it's ended up locking us into a design that wasn't really educated on what could potentially happen if we had this design and so we're just sort of stuck with it so um you know I think the expectations are that you know again you design a safe VM you design a virtual machine that can provide all the behaviors we like for ethereum but as well open up a lot of new kinds of designs that we currently don't see that we'd like to see and then on top of that you know just designing for um you know a lot of different uh scenarios where if you could have done it a different way you would have factored in all the research that we have you can basically you can create a new reality for blockchain that I think is much stronger than what we have now so yep oh uh yeah I was going to say I mean like one example is probably like the curve that we all sign over so we've all got a seed phrase um and it's kind of hasn't really changed in a while people have tried doing smart contract wallets but if you control the VM uh everyone in the room's got an iPhone or an Android that's got a TPM in it and you can actually build that into the VM and help get adoption so yeah recreating all of the the evm I think would be a mistake and just trying to kind of focus on adoption uh in the feature set would be a good thing and and um um you know specifically about the the change that we are expecting now from the VM there are a couple of examples which are just so significant so clear that the the target gold Target moved uh Aragon when they launched they were like you know these massive OS were for Dao was like very well filled out the point that it was way too expensive I mean back then no one cared you know when they started you know using your whole block for yourself was like who cares no one's here and now you know uh you try to optimize the way of all those people on Twitter doing those gas golfing to a point which is just ridiculous right and and so um one thing that I'm we're observing specifically in the context of starknet and the new language that we have is that when you provide new like feature set in New capacity to the chain you get like a combination of creativity that you like new things that you don't exist before and so um Joe here was talking about uh the curve we're using or the fact that we have EOS he always was a mistake in retrospect and the problem that EOS is that they put us in the local uh equilibrium there is no way smart contract wallet will pick up on ethereum today because it's always cheaper to use EOS it's very steeper to my priorities and so there is no incentive for the dabs to actually build their application to be very well compatible with redconnect or just you know to work well with smart contract wallet and some even some just reband them because they're smart contract and so um in the connect stock that what we because we don't have uas we don't use a Smart contract and therefore only smart contract wallet we have people using the native curve of the network called the start curve and now we're also people trying to build using the trusting Enclave of your iPhone So within the same wallet you can actually use your iPhone you can uh you you can use any care that you want you can use your brothers that have also curved in it and so we we once you unlock the limitation that we know you start adding new things that get created basically right away yeah I agree with you I think asking Engineers to gas golf instead of thinking about Innovative things to do is a big waste of time and probably prevents a lot of innovation that could have happened in the space by far yeah just just to speak to that too so like I've done my share of gas golfing like I just I want to say I'm like you can check my GitHub like it's it's sort of like an art for me but it was more of a therapeutic thing to gas golf than it was like a this is a good use of my time mind you that was before I worked with fuel so you know started fuel so essentially yeah um the thing is is you can gas off all you want but it's not enough and it's never enough because when enough people use the system it just gets congested and then you're you're back to where you started and you keep asking the same questions like well how could we do this how could openc run in this way you know and then the thing is is you lock yourself in so much to just trying to support this thing which by the way I mean there's some controversy around it but the evm was sort of designed a little quickly and was put together a little fast and at Defcon one there was some conversations about that particular thing if you want some spice but anyway the the the reality is is you know I've been sitting here looking at this machine for years like years and years and years and it's held a lot of different kinds of designs back because it can't move forward like it really is very very difficult to move forward so you know the fact that these teams are sort of bold enough to still be part of ethereum but try to do it differently just for the sake of like getting to Global adoption and getting somewhere else I think is a is a you know it's a sign of how good the ethereum community is because you know we're not afraid to challenge what people have made a culture of the system and I think that that's a very beautiful thing you know so but yeah it's not all just vitalik and Gavin's design that gets to run the show you know I mean we can try to do other things and with layer twos we can now so it's great yeah exactly like layer tools should be seen as a way to extend everything that we can't do in ethereum not just a cheap transaction that's something no yeah yeah about the you know everyone come to say about uh yeah it's always about cheap no it's not about cheap really not about cheap I can give you a few examples of things that are being built that you just like dream of anywhere else in ethereum and so for instance um Sparkle chocolate is most specifically like an important one because smoking the wallet is not working crypto crypto if we will not get Global adoption if we have to keep a key and if the eoas mechanism like a private key remains basically we're gonna go back to the financial system where we have five Global custodial and and that's not what we want and so on the smart contract part um we are now things are getting unlocked for instance uh urgent around here actually or it's working on extensively on Stark net and they're working on the plugin system meaning you can actually install an app in your wallet meaning that for instance every time you spend 10 goes to saving or every time you you want to play a game you actually don't have to sign every transaction you can open a decision key that's going to last six hours and that is only authorized to do a set of operation and so really the cheap transaction is like an afterthought it's just a requirement and honestly to be honest I don't think it's going to last long like l2s himself will not be cheap I have a theory which is you can't have a cheap successful economical layer because there is no reason in the universe what that my ticketing app that is trading or where I can change my my Nifty of my ticket being packed it by the fact that the big price of Eve dropped by 20 and all of a sudden my app doesn't work anymore and so that just doesn't happen that's just one work maybe maybe on a and like what enables all of you of your architectures to actually be able to do these things I'd love to I think everyone here would love to know more about these architectural decisions they've made that enable these new paradigms here okay so if we're so we all get what you're saying is we can all shell a little bit just like a little bit for each project okay all right I'll try to publish into it okay I'm gonna try to keep my Shilling in a kind of a dome so some some highlights but okay so first of all the fuel VM is highly inspired by the evm so all the lessons that we've learned with the evm over the years it tries to incorporate it doesn't leave that behind it doesn't try to say we're arrogant enough to rebuild everything so that's the first thing we've basically taken all the great eips all the great research that the ethereum community has done and other blockchain communities have done and put it into a virtual machine now we've made some very interesting decisions um and they all impact the kinds of things you can build the the kinds of experiences you can create and as well the scale that you can achieve with this particular system so some highlights are it's utxo based that's the first thing secondly you get smart contracts just like ethereum there's no loss in any kind of behavior from a developer secondly Scripps is another one so in ethereum you have to go through a smart contract to make multiple calls it's ridiculous it never should have been that way um so we have scripts and then we as well we have account abstraction via what we call predicates and so this allows you to send to the hash of a script and essentially if the script returns true then you can spend the output and this gives you all kinds of things you can do for example we can support signing with a saloniki over a utxo that is usdc from ethereum you like that's pretty nuts you know and that can happen at it's cool and then that can happen in like an output you can also do things like um you know basic well some some other cool stuff um is we've redesigned all the processing within the virtual machine as well such that when you make a smart contract call with fuel instead of having to serialize and the engineers will know this I'm sorry if you're not an engineer so it's just bear with me but when you make a call you don't need to re-serialize the data between smart contracts it's all in one chunk of memory but the memory is segmented per call frame and what that does is it allows you to go I'll write 5 000 things to memory here I'll call this contract over here and that other contract can just reference any one of those items so you can imagine trading engines things like this would love that because you can write so much to memory you can really abuse memory and you can abuse compute which we have a lot more of and not storage so we give you far more options to use that are not storage oriented so these are all part of the processing model but you know lastly for the last bit of shill this also because it's a utxo model you get all the nice things of ethereum but you get full complete parallel processing so you can you know basically have all the benefits of some of these newer ecosystems that are parallel processing but because the fuel VM is designed to be arbitrated it can also be a roll up or layer 2 on ethereum directly and on top of that it has trust minimized like clients so you're not leaving behind the nice security properties what we have with ethereum so that's my shill on the VM yep you go okay as it's also utxo model I'm a big fan of utxos they're very difficult but they do enable kind of uh some important features which the account model lacks and in our case that's privacy um so it's very hard to do privacy in account based model because every time you update an account you leak which account you're updating um so in utxo model uh we can create and Destroy udxos and they all look random so it's one of the key kind of design choices we had to make to get privacy and then kind of more into the VM we also have account abstraction built into Aztecs so we have this concept of a viewing key and a spending key um when things are encrypted there's a different set of people who may need to see the data to those who can spend it so I think being able to control that has been a super beneficial for our architecture um today the VM only supports um kind of circuits or programs that we've written but we're expanding it with a concept called Aztec 3 which uh Mike from Aztec is actually talking about tomorrow on one of the other stages and the main kind of uh improvements there are that every program is actually a client-side generated CK snark so we've built a language called Noir which enables developers to write these programs and then users will actually instead of sending this to be executed uh on kind of a node they'll actually compute the snark in the browser in Noir prove the correct running of the program and then send that kind of packaged up kernel circuit to a roll-up provider and that means you actually get really cool features like code privacy confidentiality and anonymity so we're excited about that um so in the context of Stark net and starkware um we also in creating our own VM um but and focusing only on on scaling uh kind of similarly to fuel and I just want to sort of make a differentiation in terms of scaling between the field approach to um which is basically polarization enabling the execution layer to do more and the ZK approach which is basically requiring less from the verifier and those are orthogonal completely orthogonal so you can get both potentially but the reason why I'm making that that um that's the differentiation is because uh the in some way the way Dark Net scale is by saying you know what validators can have stronger machine than the rest of the world today when you look at ethereum or any blockchain like Bitcoin the the your your limit the scaling is limited by the weakest machine in the network and so when we compare the TPS or whatever I mean the not the throughput of Bitcoin versus ethereum versus the fruit of Solana we are comparing Apple oranges and Ferrari uh uh and the reason is very simple Bitcoin Target a Raspberry Pi which is roughly the cheapest computer you can find um ethereum says okay you we are targeting this is a bit too constrained for the real world application maybe we can have like a 2500 Dura machine so for instance I think Eve completely on my laptop my 2021 M1 upper my book uh like a month ago two months ago and um and Solana is like you know what two thousand dollar machine is very constrained because companies they pay that for like a flight for their employees to to Bogota uh and so maybe we can have a 2005 reservation per month that's a practical uh cost for servers for an entity for copyright and so we are really not comparing the same thing and so when you're looking at the the limitation of scaling for all those blockchain is the weakest Point what is the minimum machine the network needs to have and so when you use a regular traditional um execution layer uh without using crypto cryptography to scale it you basically um don't really change this symmetry you the guy who makes money is still requiring the same machine that the the guy would verify it in his in his garage and regardless of the fact that these miners this validator can spend millions of dollars at stake on millions in machine it will roughly run on the same laptop that you have at home and so ZK breaks that breaks that's uh that uh parallel all of a sudden it it doesn't matter what kind of machine the validators have I can verify it on my phone in a millisecond and so they can have a data center for like here I can still verify it on my phone so the the start where created its own VM called Cairo because the pro that we have with existing VM is that they are optimizing for a different programming paradigms that um zkps so the best way to explain it is that you talked before about x86 so you're really you know regular VM is optimizing for basically your CPUs and your transistors and transistors you know one thing very well which is Boolean logic and beats and bytes the thing is what you underneath the KP environment you are working in the arithmetic environment where the base element you're working with is what we call a film a field element which is basically a big uint and the cheap operation that you get is multiplication addition division subtraction and Boolean logic is expensive so you you move the model on his head and there is other differentiation that I can expand on um like non-determinism or something like this but roughly speaking to make a change that is verifiable cryptographically verifiable and using zkps variety proof I know what you call it um you want to have Optimum you prefer to have a VM that is optimized for the computing paradigms and so um these specific dimensionality as I said these orthogonal to the execution layer and so start net right now is basically roughly taking the same structure execution model then uh than if ethereum uh with a few distinction like we try to do optimistic polarization we try to do we are looking into different data structure while remaining using it remaining of the destructor of Eve also expanding on what the new state of the art is coming like uh thing like three optos we are looking to what they're doing because it's cool it's useful and so um what matters is that you that is a separation so a start that is focusing on the the separation between the validators and the rest of the world and then afterwards we are looking into optimizing the execution layer to provide the num the the the the brought the transfer throughput that they even expect let's just say one last word because node requirements came up so I'll just I'll just make one comment which is um you know we're in Latin America and this is a new place for ethereum to be uh I think you know having been through a bunch of them it was a bunch in Europe Etc I think with fuel and the way that we interpret node requirements we want people here not like you know in Switzerland like people here to be able to afford to run a node in This Global peer-to-peer network not only for their own research for building for interoperating with the network but we want them to be able to afford it just for the Global Security of the the system itself and so I think with fuel we've been designing the best system we can possibly think of but we're also making sure that when we talk about node requirements which ends up being really important because it really dictates how much throughput how much processing you can put through the system um you know I think this is like a very key factor so so for us we would like someone in Colombia to be able to actually verify this and not have to pay an enormous sum like someone's whole Year's wage or whatever it might be to be able to just run a node you know exactly yeah I mean to that point The Genius of having Roll-Ups like the ones you all three are building is not everyone has to run their own node so that really adds up yeah I think it gets worse for privacy because there's like a censorship component so um if you kind of restrict like your kind of nodes to AWS Google cloud and Microsoft um quite quickly you don't have a decentralized privacy Network you have Fang um so yeah our node requirements we we do the same as fuel and we have to kind of think about how do we get it working on a laptop how do we get like Roll-Ups actually being built uh in a peer-to-peer Network um and actually some of the l1s are doing a really good job here like Mina's got a model which is kind of like a Federated uh approver so I think there's a lot to learn from some of the other chains as well and by the way you said that uh not everyone has to run nodes I 100 disagree with that we should be able to run node on your phone you should you should be yeah and and that's that's the target that's what we should achieve so so um maybe it's not practical and the fact that it's not practical is irrelevant the fact that it's a Gore is what matters that's what's drivers that's what brings us towards one point and so um that I I really don't I really want you know ideally in the future inferior would be make redundant to some extent of course not but to some extent at least on your on your phone or you should be able to run the network locally that makes sense so we spoke about all of the utxos and stuff and I know you mentioned about how it fuels parallelization and the stuff you're doing with verifications orthogonal we all over here obviously are cardano Maxis and we all obviously were quite sad when cardano couldn't work out with utxos um how are you guys doing it possible with cardano couldn't and I guess for stock wear for Louis when utxos yeah I can go first I mean I think it's it's the elephant in the room um so currently an Aztec client has to sync every single utxo test it see if it's your utxo try and decrypt it and like clearly that doesn't scale so um at the moment we kind of use brute force and we have some like very Advanced multi-threaded wasm so like pushing the browser right to the edge of what it can do um and that gets us kind of the current throughputs that we can kind of think about today to get to kind of I guess World Adoption um we actually have to look at kind of the network layer of privacy um so we're moving to looking at using something like Nim so you can actually request utxos from a kind of more centralized data store without revealing uh who you are and if the utxo is completely random uh when you request that through like a network layer privacy layer you get the same anonymity as kind of a full sync so there's ways to do it but it requires kind of the whole privacy stack in our case and some pretty Advanced web browser computations so I'll address that one pretty simply so basically this is one of many things Charles has done to damage the reputation of something completely innocuous to this particular thing so uh so basically just for some spice for the panel yeah yeah just a little little spice so the main thing is cardano's model at least from the way we can interpret it and this is sort of how we think about it too is it was implying a certain kind of determinism across the system that was basically blocking or bottlenecking how they were using the utxos for example if you build something like uni swap what would happen is is and again this is just my read so you know let's fight on Twitter about it or something but basically you have something like uni swap well you can't really have it because with their model you had to sort of sign off on the change state but what if you don't know the change state so what if there's a bunch of people in front of you and behind you in the mempool who are actually manipulating the state of this one thing then when you produce the result of the utxo well you don't know what it is so in their model they couldn't do that so so it caused this issue where like you would use uni Swap and there'd be like one transaction per block for that one app because you you didn't know what the state was so you had to just use it one after the other obviously this is horrible like you know Imagine One TX or whatever per block per unit swap on ethereum like we wouldn't probably wouldn't even be doing Devcon or something like that you know so basically um you know the reality is is that that was more of a design decision on the whole system and it doesn't actually relate necessarily to utxos per se utxos are just a way to notate and Define the transaction model which is something that you can do in various ways so with fuel if you have a smart contract as an input you can have like say a uni swap like system that's one input when the state is manipulated we basically have an output so it is noted that it changes the state but like ethereum there is this uh kind of reasonable malleability of what could happen under the constraints of the system such that you know this output basically is uh you know it's notating there's a change but it's under certain constraints in certain conditions similar to what we expect with ethereum and uni swap when you use uni swap you don't always know what the state's going to be or what it's going to change to but in ethereum we're willing to accept that reality under certain constraints so I use the word determinism here maybe the academics don't like that particularly but it is sort of how I would interpret the situation but with fuel we don't have any of those problems at all you can build a uni swab leg system or whatever you can use the transaction utxo model we get all the parallelism benefits there's no downsides to that and it's not an issue it's really just it was publicized as an issue and utxos were related but in our case we have different designs that don't feature this issue at all yeah in the context of fuel either any problem any problem compatibility or is because of scripts like how do you manage the coding beautiful state at the same time yeah so so basically fuel has just normal smart contracts so you can have a smart contract that calls many smart contracts if it does then you're notating those various other smart contracts as utxos as well their inputs to the system you're outputting potential changes so it's very simple in its design we've inherited a lot of the work that was done in research for State access lists for ethereum so really this is just a reinterpretation of that research but it's in a cleaned up model which is in a utxo setting so we again get all these nice benefits from utxos but we don't lose the user experience or behavioral elements of what we get with ethereum so it's a really nice model in that sense and then scripts just scripts just allow you to make a transaction you could say call multiple contracts so for Trans you know proven transfer from you have to make two transactions in ethereum from the origin sender which is ridiculous why are we doing that that makes no sense at all and it should never have happened and the main thing the main reason why is because of just the design of ethereum itself is funneling everything through single accounts and that restricts you so you know with again a utxo model and with scripts you can just have a script that calls you know approve and then transfer from in the same transaction and that's it and you don't need to deal with that anymore so it's really not crazy it's really actually pretty simple and again just you can read all of our work and our research on this so it's all public and available um you can try the test net in our test net we do that already so it's yeah anyway um so the question was um how do stockware look at this question of State Management and basically the question of asking is here is can how do you paranize how do parlay stuff roughly speaking um so the start Stark net at the moment do not do polarization as of now um because we were focusing on making the whole thing work right we had a new VM a new language uh we focused on make things work and so we took we went for the simplest model which was the one that was used in uh and uh you know Bulletproof by ethereum um and now that we have like all the features that we are focusing on actual execution scaling so I just want to say I want to separate um verifications getting from the from execution scaling and so um one other thing we are going to have relatively soon which would dramatically improve our the throughput to the system is optimistic execution so it's not it's not an intimate solution it's uh it's as some downtime it has uh theoretical negative um um like um let's say that um adversary reaction that could be uh impactful of the network um we are planning to solve it um one after the other it's not right now we're focusing on you know bringing scale uh another thing that we're looking into which is um within the line of this systemistic polarization that otxo enables we are looking at various data structure like I mean a model that exists in the space we look at Solana we look at Aptos we look at three we looked at all the sort of like chain that are actively um building vaporization and look at how they did it um we still wanted the account model because a lot simpler and we already have enough mind change with like the new language so we focused on you know bringing keep it simple in that sense and but we are looking as I said into the new ways whether or they are doing and take the best idea that exists there so we should actually you should expect more on that front in the coming month but there is nothing to announce because it's still on the research phase at the moment Alpha drop no but stockware does have parallelization but at the verification level through cost of proofs right so so but that's not okay so it's actually it's so we already focusing on the on the on the scaling of the execution and TVM itself the the the parallelization like the recursion enables you to do partition of the verification but you have to know today on Stark net verification is not an issue whatsoever yeah like the verification proving is not the issue right now our problem is the sequencer our problem is that our execution level layer is pretty bad at the moment and we're working very actively to improve it by 1100x roughly in the company in the coming month and so uh recursive proof does enable you to like scale like the the proving it also enables you to um scale the the execution by basically going into converter scaling um which is basically the ability for instance to have a stark networks dark net and so what before was talking about the ticketing solution that we don't have to shouldn't leave on the same environment then uh uni swap then using under three you can have this ticketing with the same requirement the same trustlessness than you would expect on the regulator too but in an environment where the fees are more stable because there is no sort of like strong economical incentive to build like decks and so on um so um to answer your question um over those polarization topic is very high up into our roadmap um they're still into research and we should expect to have things coming to production in the coming month but have nothing show today that makes sense So speaking from developer who is trying to use one of your systems throughout the panel all of you have dropped some really really interesting paradigms let's talk a bit more like I know if you all spoke about uh having these scripts and stockwest broke about having no EOS whatsoever and direct like contract wallets and you use the term programmable privacy I'd love for like everyone to like think about what these new features are but thinking about it from a developer or adapt developer perspective yeah I mean from a developer perspective um you know it at fuel we look at it mainly from a few different points of vision my own which again is reflective of many many years of trying to build apps on ethereum and struggling with a lot of key things in the system that make both the developer experience horrible but secondly the end result being a sort of odd disjointed experience between the wallet what the wallet can do and then what the application can do and then as well the kinds of applications you can design so with fuel we open up a lot of the compute so you have far more available to you you have far more memory to use you're far more um just just general compute to build anything you you want you have more options for uh user experience uh with things like account abstraction and with uh kind of other apps aspects like native meta transactions so in fuel you can have a party that just builds a piece of a transaction then you can have another party that just tags on the fee on the other and just send it and that's it and you don't need to have this situation where it's like you have to wire through five contracts to have some form of account of Attraction so I think from a developer perspective of looking at the space um the thing is there is always going to be hurdles with a new execution environment with a new development environment with something that's bridging liquidity so you're bringing your usdc and everything from ethereum into fuel um but the result is is that once you're there and once you're actually using it and once you're actually seeing what's possible uh I think developers can open their minds a little bit to where ethereum should go in and and where it will be soon you know once we go to mainnet yeah native Native meta transaction is pretty cool I know quite a few companies would like kill for something like that but also I assume when he said memory you didn't mean like how in solidity we had like string memory ABC even more like Ram or something yeah I mean literal Ram yeah so just having a lot more access to RAM and memory and being able to do a lot more with it and across many other contracts so just having that kind of access is enormous it's huge it gives you so much more flexibility because with the evm and paradigms you're so constrained by so many factors the kinds of designs you can do are extremely limited so from my personal perspective I've walked around Devcon a lot I've heard a lot of new designs for a lot of new defy and to be honest it's still okay but it's not what is possible like there is so much more and it's it's good but there's a there's a long way to go um yeah yeah I was gonna say I think it's like maybe healthy to kind of also tell developers that not every kind of VM is going to be suitable for them so we focus on privacy and you work for Reddit and Reddit has a a point system that's public so like that's not really a good fit like but like a high throughput VM that kind of focuses on public data maybe a better fit so some of um I think our competitors in the zika evm space kind of pitch everything as possible all the time and I think that wastes a lot of Dev time because you have to kind of go through the test net try and build something and you realize kind of a while later that it's not possible um so for Aztec what we really care about is applications that have private states that could be things like CK games um Consumer Finance which is just doesn't exist on on D5 today we have over clatterized lending you can't really have Consumer Finance unless you're willing to have a public passport salary um address on chain uh so I think privacy is kind of um what we care about you're not going to build an ammo on Aztec because by definition it's it's the ratio of two public pools so being really transparent about what you can and can't do I think is is something we all need to do um to help attract the right developers so like instead of storing variables in the contract itself you'd store it in your address kind of thing yeah so each each user basically controls their utxos which are encrypted and you can feed those into an Aztec transaction and prove something about it and then kind of in an Aztec program if you if you prove that your salary is above X you may be entitled to a loan or not entitled to a loan so having that data being able to be fed in as an encrypted input to a program is really powerful in our case you mentioned how some zero knowledge VMS are now realizing some of the things they ran into can you expand a bit more just for all of us I just mean like I think uh you need to kind of let me think a second go ahead go ahead go ahead um it's hard to do privacy in some applications is all I'm going to say and then I'll see what Louis has to say about that I mean 100 and so Stark net is not built for privacy whatsoever but that's not nature uh what's what's true is that you can build privacy protocol on top of it and so I was literally saying in a random idea yesterday to uh to Joe here why not uh I mean Aztec and anyone else free you know I mean there is no reason they're not you could have you know the scale of compatibility just not the same purpose um so you ask what kind of like things you can like you know things you can build so the main thing that you can build on stock that I always give like a three to it as a Dev the only thing you care about three things which are you get cheap computation cheap core data and icon obstruction and you get like a three and a half which is a long-term vision of scaling which means that even if you're priced out of this layer itself you can go a layer up which would be cheaper so what you get when you get those three things you start adding new project so I just I named before the ability to get abstraction gives you the ability to sign with your phone without having private Keepers say it's your phone that you're either private key um so now when you come you combine uh for instance cheap computation uh you're starting to have people making uh physic engine on on the blockchain so I had we have someone like a company called topology on stock net that is building um a physic engine so you can prove Collision you can prove like you know games that's existing in the 80s or 90s uh worms like you know you can make that happen directly on chain um you can Implement things like um infinite risk you know like uh an infinite map using um a barely noise or Advanced algorithm that generic Maps um and we have those people making it today on on the ecosystem so when you get cheap core data and cheap computation uh you get things like that when not possible in ethereum before like practical storage proof so if you're not familiar with storage proof storage proof enables you to prove the state of if in the past to if in the present so why is that useful so it's useful for instance for voting so you know when you vote you basically vote using the token balance that you had add that proposal and so this company called rototus is building this and they already have a snapshot trying to create everyone voting 302 using their Tech um in the now the amount of um so what else I think very exciting I feel we have a lot of Unchained gaming because unchain gaming was completely moved that priced out of ethereum and the proof is uh the only existing on chain game today on if it's basically on Windows chain it's called a dark for us so we have seen like a massive boom of projects that were priced out that couldn't build on if building on us things and you know even like Flagship like loot literally building their own Universe on on stock net right now thank you so much yeah I know we're running out of time all I'll say is all the dab developers I think because we work in crypto we kind of owe ourselves to Destin prod I say that as a meme but what I really mean is I think we are here to experiment and try these new languages like Sway and Cairo and Neuer and stuff so I hope you all like actually go out and please read up on what these cool things are doing I know if you have time but we are happy to take one or two questions if anyone has oh yeah oh yeah anyone has any questions here hello a very interesting very interesting very interesting talk I have a question why create why each one create their own different language instead of using something more standardized like circum or even I don't know C plus plus how to save for our case um none of the languages other than circum are built for kind of private State um and we found that um second was too low level um and we're trying to Target kind of web 2 developers or solidity developers and they shouldn't have to kind of know how to be a cryptographer so our language abstracts the cryptography part and so you can just write an application and nothing was out the box um so is it working circum is not sure incomplete as simple as that and so uh if you want to do an if statement which you kind of need for so stock net is on OS the real name of starting is a protein system right second device and so everything every Cisco in Stark net is written in Cairo so if you don't have a system if statement your program is going to be quite big um and um so another thing that uh Second doesn't allow you to do is being able to prove multiple program within the same proof which is something that carries through sharp enables you to do and so we needed to create our own language for that purposes and finally um circum is I mean I guess it's actually material Targets in snark but that's not yeah remove that that's another part but yes not turning complete not being able to prove multiple program is insane proof yeah and in in our case um you know we really really really didn't want to create a new language we looked at a lot of options um the main reasons are the some of the existing programming languages like C or Russ for example they're really not designed to Target a blockchain and there's a lot of different ramifications around targeting A blockchain system that you want to catch in different stages of of the compiler so that was one strong motivation for us to have our own language secondly the compiler and the tooling have to work really hand in hand so in a blockchain environment you want the developer to have extreme control over every aspect of the system so they can really simulate everything so the developer experience was another and lastly we wanted to create a rust-ish-like language that really targets blockchains not just the fuel VM so the way that our compiler is designed is such that you know and this is unlike others in the space it's designed to be very modular so if we want to Target a back end you know like uh like you know Cairo or wanted to Target the mine VM or we wanted to Target a different language the language ecosystem will be set up to Target many different kinds of blockchains including the evm so one we're working on right now is targeting Yule and that's with Foundry so you'll be able to use sway and maximize its value and its design without having to want to rebuild languages again now mind you I think some of the ZK teams have different criteria different stages of the compiler that they really have to factor into their design so like you know we can't speak for all ZK VMS or anything but it's a good harness of a blockchain language that's rustish that people will like yeah uh any other questions I'm not sure how relevant the question is to your uh environments because I haven't looked too deep into it but if you build something like uh an only swap on it which like excludes Aztec already would math be a problem on those networks as well because the indexes could uh sort transactions differently or is the summer solvable we have right now it's darknet I think top of Mind five different units of V2 so the answer is no it's not a problem and um no that was a joke but uh no it's not Stark Nets use currently uses exact same data structure even model than than if you say it doesn't really exclude Aztec like we have swaps uh from Aztec connect to UNI Swap and uh probably the most liquid uni swap uh because it's on mainnet so liquidity doesn't get fragmented uh we just have to kind of acknowledge that uni swaps are public uh application so we can't make it private but we can make the users private so users come to Aztec and in this case they bridge out to L1 in a batch to get scaling and privacy um so yeah it's possible but it just requires a different kind of Paradigm um to normal scaling yeah and then for us um you know we don't make any claims about Mev uh so you could probably extract it um if you know in a decentralized sequence um you know setting but uh I will say that we actually take a slightly different approach in the sense that we actually want to give the node as many abilities as possible to extract as much Mev as possible or provide teams that either try to fight Mev or actually try to Advantage it um the best tools that they can have because we don't really we don't have a solution for it but we know those incredible teams either advantaging it or trying to reduce it or solve it so um but either way doing Mev facility and fuel should be very interesting yeah for internal Aztec transactions they're kind of if they're fully private you can't see what's happening so our approach is usually to try and push it to L1 and then you can use something like flashbots to kind of solve it in the way we currently know how but uh yeah if that was kind of public components to an Aztec L2 application um then there would be Mev um on the network but yeah I think trying to push it to R1 is a good strategy well thank you so much everyone foreign [Music] [Music] [Applause] [Music] here [Music] do you know [Music] tonight [Music] [Music] [Applause] [Music] [Applause] thank you thank you [Music] foreign [Music] [Music] foreign [Music] [Applause] [Music] now [Music] hello [Music] hello is it working yes right thank you well uh hello everybody first of all I would like to thank you to the depcon organizer for giving me the chance to to install Gun also thank you all of you for attending the talk my name is Ignacio Ramos I work for polygon tkvm and I am at the at the protocol team it's been a year a year and a half that we've been working very hard to release the the ckvm and I am very happy I'm very proud to announce that on Monday it was announced the release of the ckvm on public internet so I will ask you to do an Applause for all the polygon team that they did that effort that it's it's enormous foreign what are we going to talk about first of all I will do like an overview to give some context about what is a ckvm and then I will go more more concrete on what is the polygons tkbm after that we will go like to the topic of the talk which is the the difference between the ckvm the polygons gkvm and the AVM so what is a ckvm there are certain well there are like the three statements that I think that they Define the minimum of RC KVM which is that it is a virtual machine that executes smart contracts in a way that is compatible with zero no less proof computation and why would we like to do this because volatility is scale ethereum we want to increase like the throughput of ethereum the transactions per second at the same time that at the same time that will lower the fees so how can we do it we use dksr technology to make cryptographic proof of execution of ethereum-like transactions in a summary and now when you process like about with a lot of transactions you get that result you get an output you get an estate so how can other people who can other ones to trust you that this process this process of the batch has been done with uh with currentness has been done correctly following like the evm constraints they have to process also those transaction and see that the output is the same with zero knowledge and proofs we can like do it easily because we can after processing all those transaction create acid or knowledge proof and if someone wants to validate that this transactions have been processed correctly like following the constraints of the AVM the only of the ckvm in this case they only have two um verify that proof and this is faster also the verification of a proof it's always constant which is very interesting actually this is like a a game center in the in the ecosystem so I remember uh it was around the SCC that a lot of companies were doing like release announcements of releases of ckvms and it created like a lot of noise especially in social media and and many places and a lot of people was very confused because um a lot of new Wars appeared there like compatibility equivalence uh what is the proverb uh I don't know uh but luckily we have like vitalik that he did a very interesting blog I actually I strongly recommend it to to read it when he classified the ckvms in five times he created what I like to say like the cqm Dilemma like if you have more performance you have less compatibility and if you try to have more compatibility you will have less performance actually at polygon ckvm we aim to be from type 2. and we are not there yet because we still have to finish the pre-compiles but we will be there very soon I thought you were liked 2.2 so um the advantage of of these of this type 2 is that it has a lot of compatibility it has as much compatibility that we can talk about equivalence the disadvantage is the performance in the village in vitalik course he said that it takes like a lot of time to generate the proof well this is habit relative I mean what is a lot of time um now we are generating proof in around five minutes but we still know how to do it and we have a lot of ideas in mind and how to reduce these two up to five minutes and also it's not that that a big problem because you also can like parallelize the proofs so let's go to the to the polygon tkbm first of all I would like to explain like very simply when we talk about equivalence what are we talking about we're talking about that putting the batch of transactions in the evm and putting exactly the same batch of transaction or the same block or whatever to the ckvm and get the same state and when I say State it's like the same state route and when they have like the SMS State Route it means that the storage the the state of the blockchain is exactly the same it means that all the accounts have the same balance with the same nodes with the same value code with the same storage with whatever they are exactly the same so are different black boxes because internally they work differently but the key balance means that for the same input The Hive they have the same map outputs so how we do this approach and it could be like a lot of time explaining how we've done it and there's people here sitting that could explain it by far better than me so I just do like some some sentences just to put some context also it's not not the topic of the of the talk but we can discuss about it later but at the end what we are doing is a processor okay and a processor has clocks so each clock it's like a new test a new state and we are playing with these newer States as steps so as all um processors you can build an assembly at the top of them you can build uh an assembly language to Define these steps and this is what we've done with a language called GK assembly with Decay assembly without try to replicate the behavior of the evm in an assembly language when this Assembly Language is completed it creates like a build which is a a big trace of all the steps that and well Define the the processor on the other hand we have the build the polynomial identity language with its uh like one of the more of silicon 2.0 is also a language done by or take lead or develina and what the executor does is that he gets the ROM which is the build of the CK Assembly Language that I've just explain it he also uses the bill where there are the state Machines of the ethereum defined there and he like verifies the correctness of each one of the steps of the ram while it process the transactions so more or less um this is this is how it works like I'm just scrapping the surface this is how it was the the ckvm and of course as all other processors we also have a ram and install it now let's talk about the variances between both of the of the avms first of all the storage um as you may know the ABM which is while we are using a sparsement gallery where the leaves are indexed in each Leaf of the ebm we store well the storage the it just start all the information of the account they have denounced the balance the storage route and they got the hash but we are doing lead differently oops something happen oh no because I'm moving there we are doing it differently on each Leaf we only store one property of the account so this brings me to the second difference which is the hash for the evm it's used the Decay tag but we are using the Poseidon with the goldilock prime number as definite field this is for performance reasons so when on ethereum you want to get the you want to get the key of a leaf you have to Hash the address but as we all we only can retrieve like one property of the account for each Leaf we have to Hash the the address with a property key for example if we have the ethereum address with the probability of balance we will get the Leaf where it is stored at the balance another difference is that ethereum uses more than one three two uh Define all the system as you can see here in one of the leaves there's the storage root the steriletruth points to a different state three where the storage is storage we are doing it differently we only have one tree that defines the whole system another difference is the memory the ABM uses for just a lot of memory um 8 Bits one byte and we are using 250c bit let's like 32 bytes so we are working with uh biggest memory slot this um makes that the when you are according to the memory the what the information that you get it's the same but the way that you obtain the information it's a bit different I mean the internal logic of some of codes had to be changed a bit I will show you an example now for example for the code M load we download you load 52 bytes from the memory so um well there are different cases some are more tricky than the other ones this is the easiest one when you want to get just 52 bytes you just escorted and you have to return the full slot in our case it's the fullest load because we have a slot of 52 bytes the fullest load of the of the memory in case of the offset is different from there well when I say different from zero I'm talking about mod 52. it means that the beginning of the slot is not the beginning of the memory that you want to retrieve maybe you will have to get like half of the memory from one slot and half open Memory of the next slot and you get a bit more tricky sorry when you when you want to retrieve more than 52 bytes in this case for example more or less than 52 watts in this in the first case for example we are only retrieving some bytes of one slot in the second case just um the bite in the middle of the slot and in the third case it's like if you want to do it with our offset different from zero and also more than 62 Watts then maybe you have to get some bytes from one slot then get the whole bite of the following three four five slot whatever the length is and some bite from the last slot the CK counters yes another another difference probably this is very new for a lot of you um I will say that the behavior is like gas but it doesn't reply gas I mean we are Computing the gas exactly the same way as ethereum does but um as I said before we have like a limited number of a step in the processor right so when you are processing about you can you have a limited number of steps and also you have a limited number of State machines that you can consume while doing a kind of code or an operation so in our implementation of the GK VM I will show an example just after that this is light we have to check that we have enough counters to process that of code if we go out of context for example the evm the ckvm throws an error which is out of counters this error is not user fault actually and it's like a folder of the executor but it can be solved easily like processing this bad but with less transaction because it means that the counter the number of counters to process that that batch has been exceed here we have the different the name of different and stain machines for example the binary one it just consumed when you compute a binary operation or the key tag when you do a architect hash I will show you uh an example of an up goat well it's a widely used of code it's the equal one the equal of code he compares the two last um to last values in the in the stack and exit they are equal as you can see this is this code it's from GK assembly as you as you can see the first two lines here I am checking that I have enough counters to process that of code as you can see the binary I'm taking I have at least one binary um counter for the state machine of the account for one one binary counter to process this this of code it's because here I use the equal and equal consumes one binary also I checked the steps each one of the lines of the CK assembly is a step of the processor here I put 120 although the number of lines it's less it's because I will go to read code which means that all the process has been correctly in the best case the best case a scenario but in the worst case scenario I may fall out to a stack under flow or maybe out of gas or a stack Overflow and I need and I will need some more steps to handle this error so this will be there example of the SDK contest let's go to the to the following difference yes we don't use the self-destruct actually this is a difference now but we have and we guess that it won't be a difference in the near future because um probably ethereum will accept the EIP 4758 where it replaces the cell the self-destruct by send all so we are not using um subtract from the very beginning we are using send all and I'm happy for it because self-destructure create a lot of a lot of problems um whatever the essential does instead of removing the bytecode and the storage of the of the account and you call this distract what it does is to empty the account and send all the balance of the account to the um account caller at the end we're just following the this EIP this is also a reference that will disappear in the next month because we are really working hard to to finish this and it's this is the way you are not still type 2 but as I said before it will this will be over in a few months actually we only support three pre-compiles from the ebm we support DC recover the identity and the model X and this is one of our priorities we are working to finish them all actually the S8 say 2.56 it won't be that hard because we've only done the easy recover maybe they see biting it's it's a bit more tricky but um but we're working it's working progress okay some other difference that um they are mean or mineral or faster to explain spoiler okay one of them is the code of the Exotic hash obviously if we are using a different hash we're using the procedent instead of the kitak this is returning the the housing with Poseidon also the blockage and well this one is not really a difference because it's not a variant because um now on the AVM you only can't get the block hash of the last 256 blocks um we are supporting to to get it from the blocks all the blogs in the blockchain from the from the very beginning and the memory limit we have a limited memory of around 40 gigabytes um it is different from the ebm because DB game is unlimited The Limited is setted by the gas and you can put like 50 million gas in one one block actually this limitation makes that in a batch you can put 8.5 million for each transaction that this is the the cost of the memory expansion and we won't have any more memory but I have to say that a transaction with 8.5 million cars to be enough to do whatever you want it's also very easy like to do different transactions if you have a very big transaction it can be like splitted in in different ones and also this is currently uh this last one it's a different now but it won't be different anymore because we are also working on it and it's one of our priorities which is that we are actually not supporting eip155 and eip2718 transactions but it's a matter a matter of time so in conclusion well you all have seen the hundred slide from before but this is like now the most important moment of the of the presentation ah no why is it happening now exactly is that we are passing the 97 of the ethereum test Suites thank you yes actually actually I think we're very proud of it and we're very happy because I think that it's like the most empirical way to check the equivalence of of any of between a ckvm and ah it's not finished yet it's moving along I'm doing nothing okay um what I was saying yes it's the I think it's the best way and the most empirical way to show to the people that we are compatible we are equivalents with um with the with the evm so this is the final three marks which we are fully VM equivalent and I also would like to to send a message like this in the second point which is that the difference that I've been explaining now most of them are um for this for aim to be more equivalent and with a better performance I mean we've been building the GK VM with a different toolkit that what was done with the evm so we have to take like some technical decisions with different tools but to reach the equivalence also taking in account the performance so I think that maybe also we have learned a lot from all those years of the AVM processing a lot of transactions and actually I think that again from the very beginning they will do some things different and some of the things are the ones that we're trying to do like we've learned from them with the blend from the AVM and we've tried to do it it was better and finally to finish just tell you that what I said at the at the beginning we are on public investment so we really encourage everybody to try to crush it try to test it play with it I mean it will be very good for us if you crush it so you can find a work and we can iterate and deploy again fix the back and and all this so just to to finish thank you very much for thank you very much for for being here hope you enjoyed the talk um thank you foreign uh foreign okay I'm starting in the next few minutes and who got the unit swag yeah so these people maybe if you sit down next to each other just say hi and they just scan it don't scan without saying anything you know just be friend be friendly okay foreign foreign foreign we have a few minutes there's more room on this side so if you know you guys can come over and again while we're waiting if there's someone who has a swag on your side just say quickly high and they just scan you know okay thank you hello guys how are you doing good okay so uh my name is uh well my name is Makoto but I'm ens is my talking dog is uh how many people got this swag things great okay so probably support someone with you I was a man behind you know between the nice swag and you know that you so like you know just making sure you guys are cute I'll call and all that stuff but uh I'm hope hoping that now I don't really have to explain what the ens is so it's basically Webster username whether you go to uh Co-op or Isa scan or openc or easy XYZ it's all matokundo is so that's my name and so today I think this this room is mostly in a theme of L2 track so we are going to talk about kind of L2 of gen interchange strategy on what ens is doing and we are actually been doing since kind of 2020 and there was a lot of talk and work going on but people are not quite sure where we are at right now and it's actually some of the feature it's two and a halfway of the road map but it's some of them are already available so first I was going to explain what kind of the Cross chain example already available to you so this one doesn't really require any technology technical knowledge then I go a bit deeper to the underhood definitely so probably I I show a bit of code so mostly for devs and therefore what's next section is yeah what's going to happen in the probably a bit technical yep so number one question example in the wild okay so uh for some of you may know uh coinbase I want the biggest exchange I recently announced that they decide to issue subdomain to all the users I think there's a couple from the coinbase raise your hands okay thank you and it's great because like whenever you go to like you know exchange that you change up you get your fiatu coinbase then you will not move into somewhere for the D5 then like passing struggle is like oh what's how to send to you know it's your managers in there I think it's great that it's been uh ens is available available from the kind of assurance a new user got on board with crypto and uh I got you know where makoto.cb.id because my talking is already not available unfortunately but like if you go to your in a profile page and another thing is so coinbase has I think coinbase dot eth but they chose uh CB dot ID firstly because it's a lot shorter and that another thing is uh ens is just not just about dot eth you can actually import the order your Internet domain as a same name so like origin wallet has a DOT XYZ and you can make or comment this stuff so they decide to use cbd.id to import the DNS to find the ens world then decided to issue subdomains so once it's done you can see my Q handwritten Avatar and yeah website and the email address and if you look into this our ens manager you can actually see the same thing so it's the data which is stored in I think it's in the database in coinbase it's processes route uh basically same layer one so that any doubts or like a well that can actually access the data and the great thing is uh the user hasn't paid any single gas and another exam interesting example so I think coinbase cases was in a company of change in the database so lens is another kind of web 3 social network which provide the user profile and how many people have lenses well okay maybe half of it and so this lens actually have a ens Association address Associated and something you might not know is uh it's actually that's also a proxy to the uh you say I'm L1 after ens and on layer one so if you actually look into it you can actually see that on our EMS manager and this is kind of recent uh release but now uh metamask supports so that like if you try to send no one really has to send ease to study you know if you want to you know you go to stanley.lens.xyz that's already available and this is another interesting things like so optimism uh there's some Community users just posted on their uh our Forum that hey we created a name service and they actually just booked the uh what we are doing and they create a kind of nft and they decided to issue some domain on their nft and it's actually available on optimism which I didn't even know until he posted which was kind of crazy and I do explain there's some Nuance on the difference on how you do she's doing and what we could do in a next chapter and this is a really really crazy thing is like so we I'm saying like off chain which can be anything so I showed like database example I showed you the lens is basically the polygon other evm example this is literally the Google Doc and someone put that kind of integration so that if you type the data into the Google spreadsheet it actually updates which is kinda crazy and yeah some I only got to know because someone tweeted it so this is kind yeah it's called sheets though is apparently sorry oh you made that oh hello hi yeah say hi to you what's your name okay yeah so that's his thing so if you have any question about integration speak to him hello hi we should not sing okay nice so these things we've been doing it's not something you can uh you can do it without any integration so we actually talked to many partners and the integration Partners to integrate this thing first so if you adapt developer uh if you want to have these like a coinbase subdomain or then sub domain or uh sheets of domain uh as long as your app has He suggests uh later than 560. well with three Pi B6 or web3 JS b493 uh you already have the uh feature integrated and also uh I think nowadays people use framework uh kind of tool like bug me or used up they because they use esl.js underneath that's already supported out yeah right away and for the wallet side there's a well it's like alphabet uh urgent metamask um bro coinbase trust wallet wallet connect and the uh Scan they all are integrate so if you're using this you can actually uh send money to basically sunny or like any coinbase user who has CBI d sub domains if you want to and so yeah what's common across oh yeah I just realized I can just read that sorry uh okay so what's come across this example is basically storage agronostic it can be the best polygon optimistic optimism or Google spreadsheet and depends on the storage uh yeah if it's in like a L2 or side chain you might pay a little bit of gas if it's in off chain complete gasless and uh interesting thing is like I think most of the stuff I'm lucky if you use different chain first things you have to do exactly you go to metamask and you know change the network ID and the stuff you don't have to do it because you don't want to know which chain these users data are and they're like I don't want to know like you know where data is for the coinbase users or lens users so that for the read-only purpose data is all available through L1 and this one I will explain later but we call it kind of trust not minimized you'll find out a bit more detail okay so under the hood uh so if there's any pretty much all the things I'm going to say is in this docs ensl domains and there's a QR code so if you you are interested you can just you know take a shot and sorry okay thank you hi thank you okay so uh so now I'm going to go out a bit uh detail that so ens is one of the kind of oldest Smart Control available that it's been deployed fast in the 2017 and it went through like almost like you know four or five years and the basic model is we have three well basically two big components one is called registry where it's a big gigantic dictionary key Value Store and instead of registry hence the value we return so for example in this example uh you ask what's the user says what's the uh food or east has in example it Returns the x1234 which is some another smart contract called resolver and the resolver is a one if you ask that resolver what's the address of food.edh that Returns the actual ECM address so that kind of two ways right and the reason we did is is the flexibility that uh once you kind of check it's very difficult to change smart contract once you deployed to ask everybody to change point to the new one uh so but if you have a resolver each user or each name owner this is important to understand is a can swap the resolver and have their own custom uh logic or if we release a new feature you can upgrade to the new feature uh all by uh by each user by each domain okay so this is a basic and with this in mind uh what we do with this new interchange uh yeah cross-chain uh thing is something called ccib read also known as eip3668 secure of chain data retrievable and what I'm going to explain is it's going to the instead of the two-step model of the existing resolver it's a three-step model and I call it River request and verify okay so what it does for the first time is like for example if you go ask for the uh data on the resolver instead of returning the data he actually saw the exception it would often lookup and so they could be but this error message came from I think so 88. something and this interesting thing is like a very scary it returns a different kind of data type by calling the same function so that like you don't have to client doesn't have to know whether the function core is it was L1 or L2 other place it's just like you uh e reverts and it catches and then once you revert you catch the revert message it has information about uh this address which is a resolver then it has something called URL which is we call a Gateway server and plus the core data which you know you send for the function call and of gem is over resolver so this is I think the function type of the uh function which you're gonna call once again once the Gateway returns up results and the code is a bit old so there might be some consistency that so step one revert and that's solidity code and the once that's done uh okay what's timing yeah and uh so this is a web service URL you know you just catch in a revert you call this uh web services and the uh things it does is uh fast line is the server.r is just like a function uh ccip resolver Library offers like any or any of the web services you have you can kind of Chuck in this capability easily then what you do is you basically query the data from somewhere it could be database it could be of a side chain it could be Google spreadsheet then after that we basically ask the gateway to sign the data and it returns back to the client and then once it's returned uh again this is in L1 that uh it basically calls this function to and you decode this signature and you check like if we verified and if you it's verified by the Gateway it was specified in rebut we say okay we trust this Gateway service so like hence we return the data so bye by using smart contract to be kind of proxy yeah user can retrieve the off-chain data without switching metamask or not knowing any other information but all these things are kind of encapsulated especially using instasjs so most data use you don't actually even see it but if we want to do directly with the interactive smart contract you kind of have to know yeah and okay and so once the basic logic of the of gen data redouble is explained next thing you also have to know is another EIP called ensip10 so wild card resolution for issue sub domain is like one thing you need to know in the case of we are talking about biggest use case as a issue in sub domains and when it goes to uh for example cb.id cbd.id does have a resolver contract on the L1 which basically acts as a Gateway too of chain but use the subdomain actually doesn't have any data on L1 and what it does is this isn't just another rule we Define in a client level that if I I have a let's say my token in this example it says a.m Dot eth and if we don't matter control eth doesn't exist no it doesn't have a resolver at the client library on asked to the parent in that case matokundo is to say do you know anything about your child then that child goes to LT or of chain and get data so that's how uh China allows you to issue sub domains which is gas free because it doesn't exist on L1 yeah and so the consequence of this approach is fast so no unchain event for issuing subdomain or records so quite often when you build adapts nowadays you kind of rely heavily on like something like subgraph to retrieve data with information uh in current specification which don't have that so in our case we kind of hard coding like you know especially if you have done any coding on the ens for example text record a key value store which key has been uh said we actually are or which coin type has been said we actually retrieve from the subgraph the graph sub graphs and because it the graph information doesn't exist we actually basically hard code and if you look into the ens manager and if you look into the subdomain of the C my address so they all the money so correct uh protecting the Gateway it has some security concern and for that reason if you have a gate where you you have to deploy Gateway by yourself you can't let other people to deploy Gateway and use their own so that's kind of limitation of current approach however it's here and it's working so another uh photo time is that if you want to try out this approach into you adapt this is a QR code to take a photo with me smiling thank you ready okay and so what's next and so yeah kind of yeah as I said it's kind of halfway and so we did the off-chain data retrieval clicked and basic library and wallets integrated checked and so there's three other things we kind of have to solve to to go to where we really want to achieve go and the first thing is I call CC is called cross chain right at deferral protocol did you guys come up with the name this is like so difficult to remember yeah but I think it's the joint uh EIP with I think coinbase and that Nick Johnson I think is basically so far you saw that uh all the data can be retrieved on L1 so that you don't need to switch Network to read the data but once the next step is actually you want to let users to update the data and currently I think uh in case of lens then they have its own interface on your L2 so like you have to know that you have to update on lens in case of a coinbase you have to know that you have to do in a coinbase uh basically extension but this one kind of use a similar approach to ccip read to return the like where uh you need to kind of repoints to your end point or like a URL to update the data so this is kind of fresh oh no it's June June so it's been there but I only get to know like a few weeks ago that this existed so uh it's fresh but like there's already draft so you can take a look and next so yeah trust minimize resolver equal uh Roll-Ups so that so far I was talking about quite kind of centralized approaches like you have to trust the Gateway well we uh have design is going uh so yeah one of the stuff of the Roll Up is the fact that like you most of the road whether it's a kind of uh optimistic or DK that their basic principle is to batch right uh L2 data to periodically you know but to write data into L1 that means you can actually uh verify the state or belt on L1 using L1 Contra uh so yeah optimistic uh roll up uses fraud proof and uh DK usable DT proof and then once and my understanding is that optimism or like stock where all these companies listed they do have a basic function so once we have that function what we're gonna do I explain how do I do oh yeah okay yeah so what we do is that if you go back to I think I got rid of the code so I'll explain is here so here it's uh just like retrieving the data and signing the uh message but what you can do on the L2 Rob is like you can get basically get the proof data with the proof and uh yeah you construct the Marco tree and on this uh verify station on a smart contract you can basically call uh I forgot the name of the optimism code do you remember verify was State commitment something by that yeah that's it yeah for the function to verify and by doing the uh even if a Gateway returns just data but my time is already up okay uh you can uh you don't have to trust so that's are you gonna it's a complete app of another five minute okay so uh the thing I already mentioned too slow yeah well I think I'm almost finished and there's a demo which we did two years ago for the optimism so optimism we know like how it works and we are right in the middle of updating to the latest version and yeah I'll skip that order and all the end you know this now you took my photo so sorry so the QR code so you should refer to and then more important things is yeah we have a set of ens by Nick Johnson for Sati uh so yeah that's it yes okay thank you thank you foreign foreign foreign [Music] [Applause] [Music] foreign [Music] foreign foreign foreign [Music] I guess we can start yeah sure so uh hey everyone thanks for being here my talk today is going to be about Fast and Furious withdrawals from optimistic rollups so this doesn't work oh okay it's a little bit slow okay so a little bit about myself my name is Masa and I'm a PhD candidate I'm doing PhD at Concordia University with Jeremy Clark and Montreal and I'm also integration engineer at the often labs all right so uh what I'm going to talk about today is uh research that I was doing during the PHD and it kind of co-located with the time that I was doing the job at the off chain so it's kind of a collaboration between the folks at elf chain and Korea so it's a research we are particularly interested in solving a research problem but before I dive into the details of the problem I want to take some time and talk about how Roll-Ups work in general and how optimistic Roll-Ups work so you might have already heard from other folks during the conference but it's always good to keep refreshing and make sure everybody is on board so let's start with the question of why is the term so unexpensive is slow there's unscalability problem with ethereum and it's really a fundamental issue and why there is a problem is that let's say you have a function that you want to get executed on an input X and if it was a cloud environment the cloud service provider would give you the closest node in the network and then what happened is you send the function to the node it would execute the function for you and it would give back the results and you learn what the result is but on the blockchain because we care about trust and integrity we can't really rely on OneNote to execute everything for us so what happens on a blockchain is you send your function to a node and when no what that node does is actually relays your function together with the input to all the nodes in the network and what happens is then all the nodes in the network execute your function so it's literally like you have to pay for each and every node executing the function for you and then it takes some time because they have to run a consensus algorithm among each other so that they could all agree on the same output and it's only that moment that you can learn the result so that's that's uh that's really why it's so inexpensive so this is really still okay so but why is it that every node has to compute everything so the answer is because they have to make sure that it's the correct thing so let's say I have a function I execute it for you and then I come to you and I'm like here's the output so what is the most straightforward way to for you to actually verify if I'm saying the correct thing so you have to go and compute the function yourself right so the question people have been asking in terms of scalability of ethereum is that is there any way I can convince you that I've done the execution correct without you having to go and execute everything yourself so there are two main approaches to tackle this problem the first one is you can actually throw some math at a problem and you create kind of a mathematical proof so you run a function you get the output and you then you kind of create a cryptography proof you hand it to me and then I can actually verify the proof and see if it's a correct thing or not so very if like verifying the proof is less work than actually having to execute everything then I actually save some money and time right so this is how ZK Roll-Ups work on a high level so the way SDK roll-up work is he actually sent a function to a node the node would execute it for you and then they create a cryptographic proof saying that this is a correct output now generation of this proof takes a long time it even takes like 1000 times or even million times longer than when you have to like compute a function yourself so that's kind of a hidden cost but if like once you have the the proof in hand you can actually go and send it to the network and then verifying the proof is really nothing so it's really a cost effective solution especially if you're one of those nodes that have to verify those proof and the second solution is to use kind of like economics so I'm like I execute this function and here's the output and here's a million dollar worth of ease packing uh my assertion and it's open for you to dispute anybody can come along and they can prove that it's the wrong output but they have to stake money as well so the way it works is let's say Alice is saying what apple is right uh the odd and Bob is saying the other output is right and then uh there's a dispute and disagreement right and it's only in that point that ethereum goes back to a normal blockchain mod where every node has to execute everything so uh this is how optimistic rollups work and we call it optimistic because because we're really optimistic that not every node has to compute everything because really notes always assert the right output and you see why so the way an optimistic rollups work is that uh I I execute a function and I put an assertion I stick on that and let's say Bobby's come coming and he says this is the wrong output so he finds a dispute so what happens is ethereum would be like hey I know you guys are disagreeing on this output I want you to pinpoint me to the exact step inside the computation where you started to disagree so maybe you were fine for the first 30 of the computation and it's only this little step where you started to disagree so it's actually going to verify that little step so it ends up being very cost effective even if ethereum has to step in and that's why actually it's near really not easy to get away with the wrong output because everybody knows that at the end of the day a term can come along and it can set up things and you can lose money and then uh yeah and then that's why actually the only way you can get away with the wrong output is that nobody is watching the protocol so at least what honest party watches the protocol then you you can never get out of it yeah and yeah this is how optimistic rollups work and like um in in real world it never happens and they're dispute like in arbitrum there's never been a dispute before okay I'm gonna get some water all right so let's say let's see how it works on arbitrum on a smart contract level so what happens is arbitrone puts two smart contract on the L1 inbox and outbox and what Alice Alice does is she wants to execute some function right so what she does is instead of putting the function on L1 and having the L1 to execute everything she puts a message saying that I want this function to be executed on layer one and it's only the inbox contract is going to record the fact that Alice wants this function to be executed so what happens is somebody outside L1 comes along they dump the contents of the inbox smart contract on L2 and then they're going to execute everything on the arbos and it's really based on like the the how they were sorted inside inbox smart contract and then they're gonna update everybody's account on the arbos and then they put the out like the output of this execution inside the outbox smart contract in the form of an assertion so an assertion is basically a fingerprint of the latest state of the arbos so a term doesn't care what is our Os or how our OS works it actually works a lot like ethereum it runs a blockchain it has blocks it has miners we call them validators it has block explorers but a term doesn't care about anything about that it only cares about like here's the list of function that I'm seeing that are going to be executed on Layer Two I want to see the the output of this execution that's all it cares about so we have to wait for seven days because we want to make sure that everybody have time to come along and they react to it if there's any dispute and if there's not no dispute it's going to be finalized so let's say Alice wants to do something slightly different this time she wants to withdraw 100 each from L2 and to make that happen arbitrom has to introduce a smart contract which is called Bridge so Bridge's job is basically to Escrow whatever tokens or ethers people want to move to the L2 so if Alice wants to withdraw 100 ether from L2 it means that she has previously moved 100 ether to DR Boss so what bridge does is hey Alice I know you're moving 100 East to the L2 that's fine just give me 100 each I'm gonna score it for you and then I'm gonna mint 100 is on L2 out of thin air you'll be the owner do whatever you want go ahead transfer it to Bob and the end of the day what I care about is somebody comes along and they want their ether back from me and that's called a withdraw transaction so yeah so like any other transaction I just described Alice puts a message for the withdrawal transaction inside the Inbox and arbitrum does it things so yeah somebody dumps uh the contents of the inbox on the rbos it gets executed and then the assertion would be placed inside the outbox now we have to wait for seven days so that we make sure that the assertion is finalized and RV draw transaction can go through and only in that case when it is finalized Alice knows that her transaction is in assertion number 20. she can go to the outbox and she'll be like hey upbox this is the assertion it's just finalized it's sitting there for you to go and see go check it please and then if you're happy with that I won my 100 East back from the bridge so outbox is Happy Bridge would give back The Ether to Alice and then it's gonna burn those on Wheel two so here's the problem I'm sure you've noticed withdrawals take seven days to be to be finalized and it could be even longer if there's any dispute and uh although there's never been a dispute before but there could be and people really don't want to wait for seven days sometimes they have a pressing reason they want to really do something with their ether but intrinsically you don't want to wait and then seven days is just really an arbitrary number but there should be some time window for people to pay attention to the protocol and react to it if something happens but something interesting that we notice is on arbit's room let's say there's an assertion that you're just looking at it for the first time and you're trying to figure out if it's going to be finalized or not so if it ha it actually happens if you run a validator on arbitrol what happens is what is validator is just a software that goes through the inbox transactions one by one it's going to execute those and at the end of the day it's just gonna compare the output of this execution with the state that is being asserted so if you run an orbits from validator you can be 100 sure that this transaction is really going to be finalized the assertion is going to be finalized so we found that this this is really interesting that we can leverage to get a relief of this pain point of having to wait for seven days so the question we were asking in this research is can Alice withdraw 100 eth from L2 back to L1 without having to wait for seven days so we we have come up with four different solutions in this work and I'm gonna go through them one by one and they actually get better as we go through okay so the first solution is Alice can actually use a centralized exchange like hop right so what you can do is you can go to The Exchange she can trade uh her hundred each on a two with the one on L1 and it's really easy so these centralized exchanges they have piles of eth on both L2 and L1 and you can actually trade with them so this solution works a lot of people have been using it but the problem with that is it's centralized so now we ask ourselves is there any way we can do it in a decentralized way and uh so that's where we go to the second solution so the story is Alice is holding 100 East on L2 right so if it happens to be some somebody somewhere that that has the exact same amount of if on L1 and is willing to trade that with Alice then they can do something called Atomic swap so I'm not gonna go through the details of what Atomic swap is but it's basically like a little of crypto combined with smart contract that allows you to basically do transactions on two different chains at the same time so it's like arbits from here is a different chain than a theorem right so it's like uh both Alice and Bob they agree on Atomic swap so they have to lock up some money and then there is a secret somewhere that uh if it's if it's revealed on one chain then you can use it to send a transaction on another chain so it's either like either both transaction goes through at the same time or they don't go through at all so this is the beauty of atomic swap so it's perfect it works but the problem with that that you might have noticed is that Bob can agree to do the atomic swap but then he can just disappear in the middle of the protocol so there's some time window for Alice to go back and get whatever she has locked up before but it's actually very awkward because she's not getting what she wants and she's actually losing some time here okay so we go to the third solution so we're like hey Alice we know that you initiated your withdraw transaction on L2 and uh from L2 and then now you're waiting for your assertion to be finalized what we can do is we can give you a ticket actually that says you are actually the owner of this hundred eth and then you can do whatever you want with the ticket you can go ahead you can transfer it to Bob that's fine even though the seventh day has not passed so uh so it's basically like we're giving a tradable ticket or a claim of whatever is going to go out of the bridge after the seven days and as I said these are tradable they can transfer it so if Bob happens to be an orbits from validator it means that he can be sure if the assertion is going to go finalized or not so what she does what Alice does is that she can actually go to Bob and she'll be like hey Bob I know that you're you're actually validating everything and you might not even care about my withdrawal but what I can offer you is that I have this ticket that's worth 100 meter in seven days so what you can do is I give you a discount or a bonus you can buy my ticket because you know that this assertion is going to be finalized and then uh you get the ticket you get the ticket you get the bonus and then at the end of the day you have profit so Bob can do that it's great but as you may have noticed Bob here is having two roads so first off he has to have the liquidity meaning that he has to be sitting on a pile of East and he's he has to be willing to trade it with Alice the other thing is Bob needs to run an A validator on arbitrol so he needs some Assurance he needs to know that this assertion is gonna go finalize someday otherwise he's not really willing to trade with Alice so the problem this solution is really great but the problem with that is uh there's not probably a lot of Bobs in this world so there could be some people they have the liquidity and so they have a lot of it but they're not necessarily arbitrary validators or there could be some arbits from validators but they're not sitting on a pile of eth or they're not even interested in participating in this kind of like markets they're just but doing that because they want to be part of the arbitrary ecosystem so that's the problem finding these bulbs that work for the both side of equations is not really easy okay so we are at a last solution we so uh we were like is there any way we can split Bob so is there any way we can have Alice she wants to withdraw 100 East from L2 then we have David who is the arbits from validator but he doesn't have the liquidity and we have Carol who has the liquidity but she's not a validator so is there any way these three can arrange something that can give Alice what she wants at the end of the day and it turns out that yes there is a solution for that we have this solution and our solution is not necessarily the only one but but we think it works great so the solution is to set up something called a prediction market so what is a prediction Market let me grab something okay so a prediction Market is basically a betting Market but with the difference that you can get inside and outside of your position so in a betting Market what happens is you'll have you can place a bet but then you cannot transfer it or you can you cannot get out of your position you have to sit on it and then you have to wait for the event to happen but on the prediction Market on the other side what happens is let's say you think the odds of Joe Biden being the next president of the United States is so high so what you do is You're Gonna Go place a bet against it in three months the odds are actually going down so what you do is you can actually sell your position and can get out of your position so this is the difference with a betting market and then it's really like a betting Market but it's designed more kind of like stocks I'd say so okay so we have this prediction Market the way we set up it is we put the market it's really like a vending machine it's there's no bookkeeping or anything it's autonomous smart contract we put it on L1 and uh so a user would go to it I can go to it I deposit one ether inside the market and it would give me two shares one gesture and one no share so and these chairs are betting against if this session is going to be finalized or not so at the very beginning I'm actually covered for both cases so if the assertions finalize my gestures gonna be worth one ether and my no shares actually worth nothing and uh on the other side if the assertion fails there's a dispute and then my no share is going to be worth one ether and the gestures are actually nothing so in any case I can go and redeem my one ether back okay so how does it work so let's say Alice wants Alice is the one who wants to do this withdrawal right so she initiates the withdrawal and she's like okay I want my ether now I don't want to wait for seven days so what I do is I come along I go to this market and I I and pay attention to this that she wants to withdraw 100 ether so what she does is she deposits 100 if inside the smart contract the market and what Market does it actually gives Alice hundred shares of yes and 100 shares of no so if Alice actually believes that his assertion is going to be finalized and at the end of the day her ether is gonna get out of the bridge what she would do so she would keep the gestures for herself because it's a bet against the assertions being finalized and she would get away there are no shares right out of the no shirts but she's not going to do that and I tell you why what she does is she actually keeps uh the gestures for herself at the Notions for herself and she's gonna give the gestures to David who's running the orbits from validator so she goes to David and she's like hey I know that you're already validating the orbits from chain and David doesn't care about this withdrawal at all she doesn't even he doesn't even know what that is so Alice is like I am giving you these hundred no shares is a bet against this assertion number 10 is going to be finalized or not and I'm giving it to you for a discount or bonus so you can give me like 99 cents per shares so at the end of the day you pay 99 ether and if it's going to be finalized you can always go back to the market and you can redeem it 400 East so Bob's gonna profit right so yeah um sorry Dave is going to probably I was keeping saying Bob right sorry about that so I'm in debut yeah so so Dave is going to profit right so he's willing to do that that's fine so what she does with the no shares that she kept for herself now she can actually go to Carol uh who has the liquidity but she doesn't know what's going on on arbitrome chain and Alice would be like hi I'm willing to trade my ticket with you this is a ticket it worth 100 East it belongs to me now but I can sell it to you and I know that you don't have any idea about this assertion number 10 you don't know if it's going to be finalized or not that's fine you don't have to do anything I provide insurance so what I do is I'm gonna give hundred no shares to you for free so in any case if the assertion is going to be finalized and my withdraw is actually confirm what I do is what you can do is you can go to the market and you can redeem your you can go to the outbox and then you can redeem your ticket for 100 East and if no if there's a dispute happen and these assertions happens to be like uh not finalized what you can do is you can go to the market and you can redeem your no shares for 100 each so in any case Alice is ensuring Carol so Carol would be able to do the trade with her there's no risk for her so this is great this is the best solution that I I guess we have come up with and for the implementation this is a work under progress so what we did so far is we modified arbits from Nitro to support our Solutions and we provide measurements we fully implemented solution three so far it's a proof of concept so what I did was I implemented an L1 Market it's really like a vending machine as I said so there's no bookkeeping or anything and we modified the outbox so that it would support our Market and for the solution for the prediction Market one it's still under progress but we modified the roll up and outbox more contracts uh so uh there could be prediction Market friendly okay so I'm gonna walk you through the the protocol of solution three how it works and how what what are the functions that we added to the product the arbitrary protocols so let's say Alice wants to do a withdraw so she puts her withdrawal transaction inside the Inbox and then what she does this is the function that we added to the outbox she wants to participate inside the market so Market needs to know that she actually locked up her her ether inside the market so what Alice needs to do first is she has to go to the outbox and cause the transfer spender function with what basically it does is it it transfer her exit her withdrawal to the market smart contract so it's like it's collateralizing her exit and then once that's done she can go to the market and she can actually open a market on her exit and Market would check if Alice has really deposited her exit inside the market or not and if yes that's fine she can open a market then the market is open for some time until there's a trade Bob comes along he's a Trader he is willing to trade it with Alice what he does is uh he submits a bid that actually uh is greater than what is Alice as Alice is asking for and that that's when the trade occurs so the trade happens everything gets settled down but Market does it first gonna first is gonna send the East back to Alice so Alice is happy she got her ether and then what it does is because it's owning the exit now what it can do is it it can actually go inside the outbox and change the owner of this exit so it reached inside the outbox and it changes the owner to the ball so now Bob owns the exit we wait for seven days and then what happens is he can now go to the outbox smart contract execute his withdrawal transaction and then because he's the owner the bridge would send 100 eighth back to him so easy peasy everyone's happy and then we run some measurements too to find out how much at one gas it would cost us to run this function so it turns out it's really cheap so uh for transferring the spender inside the output smart contract it's around 80 uh six K and it's really like the most expensive one because it's the like the it's the first transferring of spender so it's actually you're paying for creation of a mapping so the because there's a mapping that keeps track of all the owners of an exit so this is really expensive the first one is really expensive but the LA the second one and the third one I guess they were around like 40K away which was really great and for opening the market we had to pay around 300K and for for submitting the bid uh I had to pay around 100K and then for executing the transaction it cost 90k and that sums up the talk uh I I hope you enjoyed it it's really a work under progress so uh the repo is not really public yet but I urge you to reach out to me on Twitter if you need to learn more we're going to submit it somewhere soon and the repo will be public thank you sure hey yeah I get lost at some point but it doesn't matter or not so in our solution tree what we needed focus a validator and heated 99 right selling him 108 for 99. yeah maybe I can repeat the question so in solution three Bob was a validator and he needed 99 each because he uh well he was selling Alice 99 eat for 100 each so he could make a profit yeah and in solution for the validator who was David he was buying shares 19 0.99 eat for one share which means he also needed 99e so in that case David who is a variator also needs this money which means that solution three my in my opinion is better because it's simpler and in both cases divider needs 99. yeah let me think that's actually a good point she gives the no shares 100 shares it means that the Violator still needs 99 each so it's a more convoluted version of solution three yeah so that's the thing so we can really work on the pricing of these shares right but we could also work on the pricing of each to eat yeah so the pricing needs some work to be done so yeah we can also improve the solution tree yeah because these are at the end of the day they're like a Futures right they're like a promise for something so yeah we have to really work on the pricing to see if it works or not but yeah thanks that's a good point foreign yeah thank you thank you [Music] [Music] thank you [Music] [Music] [Music] [Music] thank you [Music] foreign [Music] [Music] foreign [Music] cool ah cool hey hey everyone so many nice people here that I that I know what's up guys um my name is Pablo buenos dias and today I'm going to speak about streamies um a project I've been working around with the ethereum foundation and the guys from life here um it's a project that we're using right now to stream Defcon so if you go to live.devcon.org you can actually follow all the sessions there um so yeah I'll be speaking about what treatment is how it works um why we need three meet actually which I think is the most important thing and then I'll go over a bit of history on how the application came to to be um where we used it and also how the future is going to look like for streamies cool so what is three myth there is a very official definition that I made up yesterday so um streaming is a self-hosted application that event organizers can use to host their virtual events um so yeah we'll go a bit more in depth later on what this means so like I said three myth was born out of a collaboration between ethereum Foundation life here and myself and it all started with ethereum Foundation wanting to decouple the terms from YouTube and they wanted to do three simple things at first so our current version of Streamys those these three simple things fairly good I think so stream we wanted to live stream the events of course without relying on YouTube uh we wanted to also show a schedule of the sessions and for each talk and after the event was done we wanted to record and show the recording of all the sessions that we've streamed right so when we started designing the the application we decided that we wanted to mimic um kind of how the application looked like we wanted to mimic it to what a real event is so we designed everything around rooms and sessions right so one even has multiple rooms and one room has multiple sessions um so then from then on we started building streaming the first thing we focus on was was on live streaming so each room can have one live stream um through through the whole application you can concurrently stream on multiple rooms so today at inline in in Defcon we're concurrently live streaming nine multiple rooms which I think is pretty cool we also focus on uptime and we built in a failover mechanism into our playback systems that allows a single room to ingest uh two sources that have the same content to fail over to one or the other in case there were errors in the broadcasting on one of the sources and you might be wondering what we use instead of YouTube and that is of course very interesting and that's where life here life here comes comes in stream meet is actually provider agnostic which means that we don't do any of the broadcasting ourselves right we just we are just a front-end that hooks into Whatever video provider we want in our case in our case we build a solution by default on top of life here which is an awesome protocol that some of you may know I know these guys know them because they're the core developers so yeah um live periods are the centralized video streaming Network built on ethereum blockchain a library can currently distribute live and on-demand content [Music] um so yeah it's pretty cool I'll go more in depth on why we chose life here later but you can imagine it's a protocol built on ethereum so decentralization centers are persistent and all the nice things about decentralization right um so like I said the application is provided agnostic but there's already a out-of-the-box solution that integrates with life here so you can a startup stream is a set up your life your account and start streaming decentralized then we also put a lot of focus into the schedule this is because stream it is not only something you can use to live stream but it's actually something that we want to that event organizers want to use to like I said replicate the uh the event experience experience but virtually right so the schedule as always is a very important part of any event especially events like Defcon where you have a lot of sessions in another rooms you kind of want to automate the process of scheduling everything and showing the information in nice in a nice accessible way and so we built a schedule by the way I'm talking about the features then I will do a live demo and showcase the application because I know it might be a bit difficult to imagine what I'm saying right um so yeah the schedule is a very central part of of streamies we build multiple Integrations uh with different schedule providers Defcon is using free talks as a schedule manager which is and a pre-talk is an open source tool for for management that the Devcon team is using to organize all the sessions and and all the rooms and so we built an integration with their API and that's also available in stream meets so if you're an event organizer you can spin up a pretalks incense and you know get going with that and have a pretty nice schedule functionality there um also the application has a internal clock which will basically sync you up with the latest sessions and always display the current information on which stock is happening and all of that but I think that's better too that you guys see it in a live demo that I'm going to show later then of course like we said On Demand with the playback that is also crucial for the for the event organizers actually most of the views for events happen during on-demand playback so a live video don't usually get too many views but then when you when you start a video and you show it on demand because of the content we're sharing here in the stocks is very interesting you know people go and watch it so yeah this is also currently all the on-demand video that we are hosting on different streaming instances it's also living on their life your network they recently developed their video on demand features so it's working very nicely um and I'll also Show an example of a streaming instance where we used video on demand it was at East Berlin last month it works very very nicely so I'll show a demo of that as well and finally plugins and I think this is the most interesting feature and so this over architecture that we built was taught to contain this plug-in feature right so essentially we in the long term of course we want different protocols to build plugins into stream meets so that they can integrate their features into the application right so for instance we are working with radical to integrate radical drips and that will allow to I don't know if you guys know radical drips but it's basically a a product that allows to have tipping on web interfaces so you could have a streaming stream instance where you're live streaming an event and then you have the radical drips plugin and so users of that viewers of the event could donate directly to the speakers which I think is pretty cool right so the plugin um architecture is there now we need to develop the ecosystem and you know bring people in to develop this plugins for us um so yeah it's pretty cool foreign so I'm gonna uh yeah yes so this is the stream instance that we use for a Defcon and we can see there that the biggest buffering because the Wi-Fi isn't the best in the world but yeah so like I said we are live streaming through life here this is the main stage as you guys can see uh so even though Network conditions are appreciate it's working fine right so Props to the live routine um in this case we also added the YouTube link so the good thing was about streaming is that because it's an open source application each instance can be adjusted to the needs of the event right so for this in this case for Defcon we also wanted to include a YouTube stream for a you know to to have the maximum reach and so we have we're streaming both on live here and YouTube and with other with other added this nice switcher in the bottom so you can switch between both both yeah providers I'm not going to play the YouTube because yeah we don't like YouTube so [Music] um like I said then the schedule for this instance we build the schedule into a nice navigation bar on the right panel of the page you can kind of look through all the talks I'm going to try and refresh this is like very risky maybe it doesn't load but I'm going to try and refresh this so yeah when I refresh you guys can see that the schedule kind of synced to the latest hour and so this should be me oh no I'm this is talk five this is not my stage so yeah right now in stage five how to scale the blockchain is happening and so that's that's the internal clock feature that I was talking about um and yeah it's pretty simple but it works like we said I'm going to show also the what's the East Berlin oh cool and this is the Israel Lane streaming that we deployed and this is a custom schedule schedule page that we built and so this is containing all of the sessions for each Berlin you can filter by state stages and days and so when you click on a session when you click on a session okay cool it goes to the session page and it loads up the VOD content and also some speaker information and kind of like the description of the event and let's see if the VOD video loads I'm going to click on the speaker thing for now okay well maybe it's not loading Wi-Fi issues but go check it out watch the etherlin.org and it's very good content oh it's loading it's loading okay clap also hosted on on live here okay we're gonna close this um cool so yeah like I said at the beginning three basic features but very powerful and and you know very effective as well because the main goal was to decouple uh Eve events and community events of centralized platforms like YouTube right so I think even though it's nothing fancy we're not tweets we don't do VR we don't do 3d nothing it really serves a purpose right and and now because I'm talking about purpose I want to go into a bit of the ethics on why we built we built this why we think is important and why a yeah no why we built this and why we think it's important I think that's it yeah so can we yes so like I said most of the web 3 events are being broadcasted using centralized providers and this sucks a lot and it's not just because I say that it actually sucks um like we all know YouTube and twitch don't real align with a core values of decentralization that we you know that we're all here for and that we believe in uh so streaming this you know should be a good first step to help these communities decouple from from these Services right so now we're going to look a bit of what are the problem problems about that you get with using a YouTube right so the first one is pretty clear a YouTube and twitch and others are censorship prone um so yeah here I I put two tweets hey the first one was at East Barcelona and the live stream was taken down because they had some copyright issues which is usually I mean event production is pretty hard and you have all kinds of audio you have all kinds of music and sometimes uh some music segments with copyright can slip into the production and then your whole stream gets taken down hey so that's not good so each Barcelona had one day without streaming and then there's another tweet about a YouTube account that went got taken down because they were uh talking about web free content on YouTube so yeah there were some disputes and YouTube kind of banned their their account right so what is the solution three meter so that's why I'm here talking about three minutes now hey the solution is you know having a front end that well the solution is twofold actually so the first one is the front end right you want to deploy the front end on a decentralized storage layer like ipfs or swarm and that is actually one of the next steps we're going to take after Defcon is to make sure the application is lightweight and we can use it and and deploy it in in one of these two layers and the second solution to the problem is using decentralized and video providers like life here since life here is a decentralized layer of note and the content cannot be really stopped even if the government or the platform any platform says so right so yeah um that would be the solution to censorship issues the next problem that arises from using centralized providers is the intellectual property it is kind of tied to the censorship prone issue and so like we said copyright Claims can result in streams being taken down China's being banned and users being demonetized we don't want that and also it's not only that they're taking down the streams but it is the lack of transparency in their process to decide which streams get taken down and which content is being shown or not right so there's really an ethical discussion around what content are we being allowed to see right so using decentralized Services we then really solve this content because there's no moderation right but I think we're heading in the right direction in regards to not allowing this one Central entity to decide what we can see or what we can't see right um so yeah I think it's an interesting ethical problem next will be the high fee to content creators and this is also fairly interesting especially recently a twitch I think increased their this year they're taking from from content creators from I think it was 15 to 30 percent or something like this because these centralized providers are actually super expensive to run right so Twitches even though the free is the content is free it's Mega expensive to run an operation like twitch so in the long term they they have two solutions and one solution is to increase the share they taking from configuration content creators the other solution is uh to display ads right um so yeah moving on to decentralized solution like streamies and also live here will basically allow us to give back the monetization is a power to the content creator because then if accordingly is using live here to distribute the content the content is actually theirs right so he is then able to decide how he monetizes the the content also building on top of the plugin system that we that I was talking about earlier we're releasing setting up this ecosystem for developers to come in and build custom Solutions on top of streamies that they can use to to you know monetize their content so radical drips will be a good example but you know this is web 3 the best thing we do is create monetization a route that oh right [Music] um I lost my other thing yeah this is web3 crypto we're good at monetizing without having someone in the middle taking a share of a our money so you guys can figure out the rest uh just build a custom plugin that sends money to one address or the other and we should be solving this issue and finally and that's for me this is the most important one the web free ecosystem and how to Twitch YouTube and others under really respecting um the values that we sign for right especially the open source and their communities they build Solutions sometimes and they're trying to get into into web 3 but they're not actually thinking about the community they're not making this code public they're not contributing back to the protocols they use right they're not part of our community and yeah I think we stream it is actually existing because we believe in these ideas and is coming out of our community effort between the EF life here and me and others the other developers to embrace these ideas right and and trying to help like I said communities decouple from these providers cool and finally oh no no the most important Slide the members of the team and I want a round of applause after I say all other names so um first we have hands which is the guy that developed quite a big chunk of the code he's sitting there in the audience like props Applause yes then we have Wesley efr she's in there oh oh yeah Wesley also Applause sitting there in the corner I don't know if Akio is here I don't think so he's watching me on the stream Akio what's up he's the designer and then I'm there with the panda that I set for the merch it's my pfp for the Emergency I didn't change it so yeah the panda and that's me and you don't have to clap yeah so yeah it was awesome working with these guys really great cool hey how much time I'm done okay quick things we used it at devconnect that was the first demo that we used it was awesome lots of traction we hacked a demo in like a week and so that's why I'm saying it's a great team because we didn't really plan the development it was just it was really a decentralized development effort because everyone was doing its own thing right so but we go to devconnect it was awesome we got great numbers on viewership and no box I think uh so great then we went to Ether Lane and you know we redid the design and we call this stream stream is 2.0 we added dark mode which is actually the best feature in the whole application uh the schedule and super good there really we had no bugs and I I know this for sure and and overall we're super happy with it and then oh okay I didn't do my slide okay no I didn't okay good and then yeah Defcon which is a great so yeah and how this feature look like we're gonna focus on usability we're gonna focus on plugins and we're going to focus on embracing the web 3 ecosystem like we said and yeah and this is kind of like our vision I don't know if you guys know WordPress but the vision that we had since the beginning is to have stream HP WordPress so something so WordPress for video right so something that a event organizers can clone and use quickly to to stream their events cool I think I'm done thank you hey Mom oh wait wait I I want to say thank you to my girlfriend who helped me put this this up so hola hola hello hi Paula thank you for your talk um I'm an open organizer and I have used several streaming providers and I like live peer but one thing that worries me is how is the performance compared to other Alternatives like beam meal YouTube because this is the centralized so this is kind of worry for for events yes so this library is pretty good so I was a pretty early Community member and I've been using it in the early days he had some issues so since the beginning I come from the web to world like production world and you always have failovers and when I started using Library I was like hey we need to build a failover here so that's why we have built in a failover mechanism into all of our players right so on the one hand life here got really good already on the other hand we have a failover mechanism that allows to basically set two live peer channels for the same room so you have double their reliability so yeah but what about the streaming related to attendees because you have attendees all around the world and streaming providers have like a CDN content yeah no so how light peers solves that yeah lifer there's a bit of a more complex question because you have the life of the protocol and then you have live for your studio but basically live here studio and that's what we are using has its own CDN and agency is pretty good so you shouldn't be have an issue if you have people from around the world trying to watch your stream like I said performance is really good East Berlin we had a bunch of people watching deaf and a bunch of people watching here you know it's Defcon just say we had 3K views on live here alone and almost no downtime so yeah if you want we can speak later and I can explain a bit more yep thank you [Applause] [Music] foreign [Music] foreign [Music] foreign [Music] foreign [Music] [Music] [Music] foreign my name is Ian Myers and uh I'm a professor at the University of Maryland I wrote the first papers on using zero knowledge proofs and then ZK snarks for blockchains this was the work on zerocoin and zero cash this turned into Z cash and it also happens to be the protocols that underpin basically every second generation privacy coin that's coming online now in other words I've spent about the last 10 years working on zero knowledge proofs for privacy in blockchains and today I'm going to give you a talk entitled privacy is dead scalability is boring water ZK proof's good for just a bit of a contradiction in terms so obviously uh privacy in debt is dead is clickbait apologies if they got you in here for the wrong reasons um privacy is really important I spent the last 10 years of my life working on this stuff but we haven't seen a large amount of demand for private consumer payments right Monero launched Z cash launched other things launched they exist they're great they aren't really moving the needle and so I've found myself wondering as I work as a professor on like what's the next thing we do you know what happens if demand for this kind of stuff is 10 years plus out one of my co-authors Iran trommer sort of described it as follows selling privacy for people for blockchain payments is kind of like selling seat belts for cars in the 1920s sure we can all kind of figure out that in the future you're going to need it but until you end up with the actual interstate highway system and people crashing cars at 60 miles an hour it's kind of hard to sell people in the future so what do we do right second problem is in terms of research right for everybody who likes to get excited about new technical stuff and new cryptography there isn't much here anymore the techniques to do this are known they're done we work them out and this is now a thing to work out in industrial applications right the approach for how you build private payments is as your knowledge proof plus an accumulator typically ZK snark plus a Merkle tree this was developed in zero cache and my PhD thesis it ended up in Z cash it's now in you know pretty much every single other thing that's coming online now Aztec andoma penumbra railgun they all have features on top of this they're not clones but that's the base thing for privacy for payments um and so sure you can build tweaks you can change the accumulator you can change the proof systems you can claim it something completely new uh you know you can add extra features that's quite valid but this kind of feels to me like we're leaving behind the main things that makes your own knowledge proofs really cool because the thing to me that's fascinated me since I was 12 is the zero knowledge bits that we're hiding things and if nobody cares about privacy well we should move to something else as an application obviously privacy's not dead everywhere uh it's definitely not dead everywhere in cryptocurrency uh so if you're one of these second gen privacy coins don't you know kill me for killing your pitch deck uh there are other things that are happening probably we need privacy for defy it seems like Traders do need that um you might be able to use DK proofs to get out of the Mev or front running still out on that you can have an interesting argument with Phil Diane if you don't believe me um but nonetheless the core protocols for doing zero knowledge proofs are still like the same as far as private payments go even for these applications so from a research perspective there's nothing new here so what do we do well I hope this isn't too offensive to any of you are but uh blockchains are slow so that's a whole problem and well okay zero knowledge proofs are supposed to be everything a growing blockchain needs there are a lot of people working on scalability for blockchains doing ZK Roll-Ups ZK VMS right this is a lot of research it's a lot of funding it's probably several billion dollars worth of value from ventral capital for this and this is where all the excitement is right now but if you haven't seen this well you know how do these things work uh in a row up you have a server that is taking transactions that users generate users submit those transactions to the server the server takes them and compresses them down using a zero knowledge proof does anyone know which proof says hey all these transactions are correct uh and then the server generates this proof and sort of throws it over the wall to the blockchain and so the server is in effect saving the blockchain work this proof is succinct at least somewhat uh and so it's easier for the blockchain to check that than this to check all the proofs and so then it doesn't matter if your blockchain is slow and does 10 transactions per second if each one of those transactions is a zero knowledge proof saying that 10 000 transactions are correct in payments that's the theory that's the pitch deck everyone's raising off of okay this is great there's really nothing wrong with here this is a lot of brilliant work has been done on this I don't mean to Bly people on it there's just as a cryptography Professor the thing that kind of bothers me uh zkpms and ZK Roll-Ups aren't zero knowledge uh they compress transactions on blockchains you don't need to hide what's going on to do that you just need things that are faster and smaller to verify there's no notion that this has to hide what's going on and in fact they likely aren't going to hide your data and so this is going to be surprising to some of you um of course ZK Roll-Ups usually reveal the miracle hash of the data they're dealing with that's kind of obvious there's a zero knowledge proof about it but they're reviewing the miracle hash and that hash actually reveals a bunch of data in much the same way that uh say publishing the hash of your password is going to reveal your password people can Brute Force these things and it wouldn't matter if you when you publish the hash your passwords that use a zero knowledge proof that it meets whatever ridiculous password policy there is you know three uppercase characters a symbol and hey let's throw into some emojis for good effort that's not going to help with the Privacy problem here and so this is going to become an issue now maybe it's just in theory maybe it's hard to Brute Force this stuff uh on the other hand ethereum just moved to a proof of stake so there are a lot of angry miners which a bunch of hashing Hardware who don't know what to do with it so if this ends up being an Mev thing you might have some problems um either way it's not zero knowledge and so in my perspective this is kind of boring from a ZK standpoint because it just isn't using the thing that's cool and fascinating about zero knowledge proofs sure you need faster proofs that's quite nice this will get you all kinds of cool technology and I'm glad it exists but it's it's skipping the interesting bits right and so at the end of the day zkvms are not a significant source of zero knowledge they're sort of nutritionally defunct from this perspective they don't give us what we want um and again this is not to say this stuff isn't useful it's driving serious Innovation and zero knowledge proofs the things I worked on in 2012 in 2017 when we wrote sexy which were like implausibly slow at the time are now practical in part because of the r d that's been funded by the companies doing this and so that's incredibly useful it's a bunch of tooling that I as a researcher can use um and so I sort of think about this like the 1980s and 1990s when people are building faster computer processors these things were tools we could use to do anything we wanted what was driving people doing them was you know faster spreadsheets for offices uh kind of like what's driving people now is faster spreadsheets on a blockchain uh so you can do this that's great there's nothing wrong with it you can also nerd out on exactly what you're going to do for the zero knowledge proofs and just go I don't care what anyone's voting on an application that's also fine but some people should dream bigger right just like we did with microprocessors you know build the internet build the metaverse build something I don't know what it is but we should be thinking about it like and so we need to figure out what the combination of ZK proofs plus blockchains can do that isn't just faster spreadsheets on a blockchain um it's going to be part of it but it's not going to be everything so this brings me to the question and this is where the sort of technical content of this Talk Stops this is this sort of theory question what is this stuff good for right what are we going to do with the zero knowledge proof and if you went and took a cryptography class uh probably even if you took my cryptography class because I'm lazy about writing slides you would get a definition like this which that is zero knowledge proof is a thing with correctness soundness and zero knowledge and this is a very sort of textbook academic thing it's very dry it does not relate what these things really do so I think we kind of should start thinking about them in different terms uh so in deliberately non-standard terminology what is a zero knowledge proof doing well in my mind it's three things the first one is confidentiality it hides data and so that's how we got Z cash that's how we got tornado cash that's how you get Aztec you get everything else we're trying to hide data to get private payments because blockchains or Twitter for your bank account and that sounds like a horrendous idea okay that's thing one thing two for ZK snark specifically is compression right they take a bunch of data and it's easier to verify than doing the linear paths that the actual verification would do without the proof that's nice that's how you get scalability right this is what's driving people's quests to save money on gas for blockchains but the third point is to provide something which we can think of as credibility right so zero knowledge proof from the cryptography standpoint is sound it gives you some guarantee that some statement is correct it doesn't tell you anything about what you can do with it credibility is this point if I give you a piece of data I can use a zero knowledge proof to show to you that it really is the data you're supposed to be looking at it really was computed on correctly um and this actually um well actually works of course that doesn't say anything about my slides working okay so the idea here comes from a piece of research done by some of my collaborators back before I knew them called proof carrying data in 2010 and this was really before blockchains were a major thing at least in Academia and the idea was you have data never mind where again they didn't know about blockchains and the data has proofs attached to it that the computations are correct that was done to produce the data so you have some data proof here says datas whatever someone comes along computes a function on the data gives you the output gives you proof that that's correct and then later somebody else can come along compute another function on the result of that give you a proof that that's correct and you can just sort of imagine some kind of state machine going forwards looks kind of like a smart contract I guess but it involves zero knowledge proofs and of course because it involves zero knowledge proofs you can also hide anything you want in the process of doing this uh so this is great it's a nice piece of work but you know first of all how do you agree on what this data is that everyone saw it second of all what is this good for this paper does not answer that question it just proposes this academic mechanism so we're back to the question of what does your knowledge proofs good for and so in my mind the thing that a zero knowledge proof combined with the blockchain and that accommodation is crucial gives you is credibility right that piece of data if it's on a blockchain can tell you uh that everyone agreed on this right this is what's out there and then I can give you a proof that it was correct that you know I didn't see anything else that I wasn't supposed to when I was Computing on it and that you know the operation I did was done correctly and then we all get a shared consensus on this because it's on a blockchain I can't equivocate on what I did I can't double spin something if there's something in this data you know this is privacy preserving smart contracts for any of you have looked at this stuff but at a level of what's the property that a normal person might care about right so what do we do with this well in general what is your knowledge proof it's good for and in this talk I'm going to give you some low-level things of like immediate problems some very high level things that are you know what was on my mind at the time and then back to some low-level things of identity so the first thing that you really do need zero knowledge proofs for is credible safety for or from depending on how cynical you all roll up operators right the Bitcoin people would call this censorship resistance uh because if you have a have a roll-up right the roll-up is taking these transactions the service sitting here it sees everything that's in those transactions right these are normal ethereum or Bitcoin or whatever it is transactions they are completely uh transparent to the server server can see what's going on okay fine why is that matter block change it that way anyway the problem is the server is getting these from a bunch of people and it gets to choose which ones it takes and which ones it doesn't and the problem is that that's going to be obvious to everybody and so the server is going to be held responsible at some point by somebody for something it failed to exclude um in other words ZK VMS and ZK Roll-Ups at least if you naively do them in a single server model aren't censorship resistant the consequence of this is you really better not mint any enfps if some meme a government doesn't like you probably shouldn't take payments to activists that the government doesn't like if you're a roll-up operator sitting in Texas I probably wouldn't take donations to an abortion fund right now might get you in a bit of trouble um because if you do your nice ZK uh block compact trying to make things efficient isn't going to be a block compactor it's going to be a trash compactor on fire you're going to just have major problems with transactions you process so this is not safe this is not good and this is a major problem for all people trying to get blockchains to scale so what do you do about this well you replace the individual user transactions with zero knowledge proofs so that those transactions are now uh opaque and as a result the roll-up operator can't see what's going on and so they have they're a dumb pipe and they have some limited ability to manipulate transaction ordering but again they don't really know what's going on they have a degree of of deniability uh and so this gives you a minimal amount of safety it doesn't solve everything but this is the thing that you need to be building into your ZK Roll-Ups um and this is things that various people are building I believe the original people who came up with this idea uh I don't follow these things too closely Aztec currently has this out there um Elio company I'm involved with is also building this I'm sure there are others but nobody's really broadcasting these features as a thing that goes on very well and part of that's because that's a really bad name right this gets called a ZK ZK roll-up which is kind of a mouthful and every time I hear it all I can think of is this bad meme from like not quite the 90s but it's pretty old um so you should be doing this and somebody should please please come up with a better name for this that's catchy so that people can Market it um because I'm sure I left off some people who are building this um but this poses an interesting problem for those of you who are working on zero knowledge proofs because uh these proofs need to be built on phones and that doesn't necessarily work with every ZK proof system that's out there right I don't know the full breadth of these things I don't play with most of them most of my stuff still in graph16 but I do know that some of these things are slower than others and are suited to other cases and so there's some risk factors that you might want to consider if you're looking at ZK Tech and trying to figure out what we should use a lot of these systems the approvers are architected to running data centers on Big Iron right this may be fundamental to the way the proof system works it may just be who your devs were and what they knew how to do but either way it's not clear they're going to run efficiently on a mobile phone or a laptop um secondly for the proof systems they may be amortized uh only over lots of transactions right so they're not really efficient unless you put a thousand transactions into this proof and check them and then you get some amortized savings which is fine for a server compressing transactions to do a roll-up but again in these cases you need phones to be generating proof so laptops to be generating proof so the server doesn't see what's going on and that's only going to have one transaction in it and lastly the proofs in a lot of these things are very large which is going to cause all kinds of problems for mobile data for your gossip protocols for transaction distributions this is also a warning sign and so the way to think about this or at least I think about this is you may remember that there's been this big problem with Intel and x86 for the past about 15 years where Intel built these wonderful server chips and then they found out the future of the world was mobile devices and they've been trying to play catch-up with getting their chips to work on mobile and there's some business development things there there's some fundamental technical things there's some position positioning that have causing them problems and so we may end up in a similar situation with ZK proofs where you can't get these to work in the right settings you want and then you're gonna have to do a nested ZK thing you have to add another ZK proof under your ZK proof in a different system that's going to drop your costs and up your complexity so Food For Thought for those of you who are working on these things um so okay that's the basic like pressing issue today but looking more broadly what else can we use as your knowledge proofs for right if we have this notion of credibility carrying data right what can we use it for and I think you can more broadly do this for markets uh like competition uh decentralization uh migrating data around is going to be a big one and obviously you can also use it for like preventing money laundering so starting with the last one of those cryptocurrency has a theft problem right this is uh stuff gets stolen now by nation states the nation states actually go get in trouble tornado cash got taken down because of this actually the tornado developer is in prison right now in the Netherlands because of this which is kind of crazy for you know thing that came out of a paper I started writing 10 years ago but this is what's going on um and it would be good if we had some way to deal with this so what if you wanted to prove uh to somebody when you make a payment that the money you had wasn't stolen and you wanted to show them that the money wasn't stolen when you got it from somebody and when that person got it from somebody that money wasn't stolen then either right add infinitum all the way back this is impossible if you're just asking questions you can't do this without cryptography right if you just do kyc or whatever you'll stop at just who you are who who's giving you the money and you won't really get a good notion of what's going on but ZK proofs compose recursively right so I actually can build a zero knowledge proof that not only is my money not on a list of stolen money but it wasn't on a list of stolen money when it was paid to me and that wasn't on a list of stolen money before that before that all the way back in time so we can have this sort of credible money where despite the fact that I'm Anonymous you actually know that it's not stolen all right so that's one thing you could build details are somewhat complex by the way but it is possible um right more broadly you can do all kinds of compliance right you want to comply with anti-money laundering rules uh currency transaction reports that you're sending you're not sending more than ten thousand dollars uh through a system you can do that right in theory we knew how to do this in in 2016 so the paper I wrote at Financial cryptography uh but now they're actually companies building this because again we have more practical zero knowledge proofs in part because of the people working on Roll-Ups um you want to show you're not on the sanctions list we can do that so this is again you can get credibility for what's going on with money um more broadly though right let's not just think about payments what else could you do what could you possibly want to prove to somebody well we're all trying to build decentralized ecosystems right there's a whole question of whether those are really going to be on a blockchain or they're going to be some oligopoly of servers where people try to move from one server to another to another migrate their data from one thing to another and in those settings it would probably be pretty useful if when you took your data from server a to server B you sort of said that here I can prove to you it's correct all right similarly speaking you might want to prove that an auction you're doing is not tampered with Google recently got in trouble because allegedly according to several States Attorney General they will manipulating their ad auctions instead of running a they said they were running a second price sealed bid auction where if you win you pay with the second price is and so you should bid your value and instead they were running something that was approximately a first price seal bit auction because if you won they lied and said there was a bid right right under where yours wasn't basically charged you what you were willing to pay uh and this is a problem with Google you know a semi-trusted guy in a legal setting where there are places to prosecute them if you try to run an auction on you know decentralized wild west of blockchains this is going to come up so you probably want to be able to prove your auctions are correct similarly you might want to run a matching rocket for some Rideshare system like uber you can do this with a zero knowledge proof I enter it right thinking even more broadly you might want to be able to say like hey if we're running a decentralized social media system I have a news feed I'd like to know that my news feed wasn't manipulated that somebody isn't for example feeding the outrageous stuff just because it generates clicks or you know making clickbait titles for you know ethereum Devcon talks uh you might want zero knowledge proof to do that and the thing here is these are all sort of Pie in the Sky dreams but we're going to need to do things like this because if you're trying to decentralize existing Services organizations and institutions it's kind of essential because people kind of trust these essential existing things for better or worse and so if you move to something that's completely crazy and new you're going to need to convince those people to trust your new thing and you can't just publish everything that's not how the world Works um so this is sort of hard to think about as a concrete thing so he was a you know a concrete version of this standard tale about internet gaming right there's some awesome game it's an online game there's a server there's a great Community everybody loves the thing and then it gets a little too popular thing goes down the toilet uh the devs get greedy or bought by some company um blizzard uh and um they somehow ruin the game never mind how uh and so you know in classic Futurama binder we're going to make our own with better things um what you want to do is like take all your data and go to a new server with the same game but your existing game state and you know for this to work the game has to be open source but even if it is you're going to run into some problems here right when you take that level 50 sword or whatever it is from server a to server B why is anyone going to believe that you actually earned that that you didn't just make it up right for the server how are we going to know that they want playing funny business I'm secretly running a pay-to-play game right how are you going to know that the economy of that server and the way the items are distributed is correct right you want to be able to prevent these guys from like correlating this game you want to be able to move to another server but you need all of your data to be credible when you do this and move it around and so the only way you're going to do this is by committing to the data on a blockchain and attaching zero knowledge proofs to all of this stuff again Pie in the Sky you can't get this to scale now but it's an interesting idea uh and this approach is broadly feasible to not just gaming you don't need to just do this about a sword you could do this about any number of things right if you're running a crowdfronting platform that has like Awards something like patreon patreon goes under you can move to another server and take the awards you've gotten improve you actually got them um so okay well what if we thought even bigger um recently there was a headline uh that the IRS had gotten in trouble for manipulating uh their audit process and under the Trump Administration auditing senior FBI officials who mysteriously had also been investigating the Trump Administration so this was regardless than tampering with those other stuff um what would it take to make tax audit processes credible and this is just sort of a hypothetical right how would you know that this is working uh you'd have to commit to an audit policy in advance you'd have to put up all of the tax returns committed on in some blockchain permissioned Ledger uh and then you have to show that your audit process was applied correctly and the thing is in the process of doing this you cannot reveal any of that data you can't tell people what will get your taxes out of it you can't tell people what other people's tax returns are but if you want everybody to know and trust that when they get audited by the IRS or some other institution that it was actually done according to our fixed procedure in the rule of law or whatever it is you're gonna have to do something and so maybe again hypothetically if you're at a zero dollar proof on a blockchain you could do this um so as I was writing this talk uh I kept thinking of this idea that like verifiability enables uh cooperation so during the Cold War the U.S and the USSR wanted to disarm somewhat they wanted to have less nukes because they could save money on it and it was better for the planet um but there was this problem of if you U.S gets rid of their nukes they want to verify the Russians are also getting aware of theirs and that was kind of hard so one of the limits for arms control treaties was that it was hard to verify what was going on and what happened was as spy satellites got better and then spy planes got better and more pervasive the Russians in the uh and the US were capable of verifying that disarmament was happening and so they could actually cooperate and there actually are now treaties about being able to fly planes over other people's territory to verify this stuff it's called the open spies act it's open Skies act excuse me so technical advances can enable better verification and more cooperation uh but of course spy satellites don't work for this kind of stuff on on the internet we can't just publish everyone's data out there for everyone to see and so to do this in this case we'd need zero knowledge lives so you know what is your knowledge proof's good for these three things uh on a more you know concrete thing you can also use them for identity moderation decentralization um so we need to prove all kinds of things about our identity online uh that we're not North Korean money launderers for example that were not a bot Elon Musk um or that we're over 18 to view a video um and so that's time but I have some work on this that would kind of be interesting so with that uh I guess I will take questions [Applause] so those are the two papers if you're interested in them do you think that oh sorry is this working yeah I think that ZK ZK roll-up providers will censor transactions by not including them if submitters don't disclose the data so there's a whole game theory question about that I don't know I'm not guaranteeing that this will solve your problems I'm guaranteeing you if you don't do it you'll have problems right there's no warranty on this right I'm in Academia I don't have to you know be responsible for that uh-uh yeah so when building like a real world application you see on ZK stuff like um I think there were Oracle issues yeah I'm kind of from one issue and um how can we the kind of the design uh the the social stuff into um to some um polygonomy circuit stuff would be on kind of a real barrier so what's your idea on that that's a major problem right you're asking about like tooling for ZK proofs like that it's we need to get better at it we need to get more developers on it um thankfully all the money in DK roll up seems to be helping producing tooling for that so I'm going to say that's an industry problem and again I'm in Academia I don't have to solve it but it's a real problem I don't know a good answer it's a good question anybody else a little more hi thank you Christian Aviva so um you you kept mentioning you know I'm Academia I don't have to handle that or I know I don't know about all the players in it so like if we actually want to build real useful products for the world and you're in Academia but we need your knowledge but you're not interested so like how do we bridge that Gap and what kind of collaboration can we do so we can build the good stuff that you've been studying all these years so that's a very good question um it's not that I'm not interested it's that I haven't thought about it as much uh you can come talk to me uh I guess shamelessly you can fund my research um I actually happen to like collaborating with people I've had like four or five startups doing this stuff so um it's just a little harder on the spot on stage to give answers as a more General prescriptive thing it's advice for particular problems it's a different thing first of all thank you for your talk best talk I've been to the whole day thank you so much thank you I'm curious about something foreign about something you said at the beginning kind of the whole the premise of the whole situation uh where you said that zero knowledge proofs aren't really zero knowledge because you know the hash vkvms aren't necessarily ckvms right um I'm curious how much information really is in the hash because you said yes you need the Brute Force if you can brute force that hash then you can then the whole system break down because you can no no so think about this if I have a Merkle tree with only two accounts on it Alice Bob balances five balance is six I do one payment move it uh document one increment one I only have to try to guess a couple of different things about what that change was to figure it out it's the same reason password don't click here it's not breaking hash functions in general but wouldn't you be composing uh the proofs of many more transactions than just two yeah so this is a good question it may be with enough data you don't into that problem you might run into others this is more so a like look if you haven't thought about it you should consider this you can also fix it by like committing to the data and having Randomness I mean that's what zcash that's what zerocache does but naively if you don't think about this and don't do it you will run into problems like this okay thank you [Applause] [Music] [Applause] [Music] [Applause] [Music] thank you [Music] [Applause] foreign [Music] [Applause] [Applause] foreign [Music] [Music] [Music] thank you [Applause] [Music] foreign [Music] [Applause] [Music] [Applause] [Music] foreign [Music] [Applause] [Music] foreign [Music] [Music] thank you [Music] foreign foreign [Music] [Music] foreign [Music] let's see it sounds like you guys can probably hear me all right oh there it is um now for something a little different uh good evening everybody um I'm Piper Miriam and this talk doesn't really need slides that much I'm here to tell you a story uh those that know me best know this about me I have a deep love of Storytelling you see stories are everything they are the glue that hold together this thing that we call reality we tell ourselves stories about who we are about what it all means and we really want it to mean something don't we at this very moment there are hundreds and hundreds of stories colliding and competing and passing clean through one another without either protagonist being the slightest bit aware of their insignificance but I digressed I promised you a story didn't I the characters in the story are messy they live in places where the water isn't safe to drink their dreams of children are met with miscarriages and disappointment their fathers drink themselves to death their Partners tossed them aside with indifference their daughters become Sons their governments charge them with treason their brains betray them with depression and panic attacks and crippling social anxiety the character that I play spends more time in pieces these days than he's comfortable with his marriage failed this year his windfall turned into tax liens and hundreds of thousands of dollars of debt he has self-destructive coping mechanisms he turned 40 this year he goes to a lot of therapy and struggle struggles to keep showing up to work and Lead when the truth is that he feels lost most of the time struggling to keep things compartmentalized and walled off separate this is fine he says is the pieces of his life fall to pieces and the ground around him I'm fine he says when all he can hear is the rattling of the bars as the feelings fight to be let free it's fine he says as the community that loves him props him up day after day but fine or not there's a story to be told here in the story of cryptocurrency is not mine it doesn't belong to any of us but it's one that I've had the honor to help write it's a story written in math and Human Experience straddling the predictable and reliable world of numbers and the messy reality that I've been over sharing with you today and in this story at least the part that I'm telling I am a superhero I feel uncomfortable and self-conscious saying those words how arrogant for real the things I get to do and the stuff that I get to work on the things that we get to work on it's truly astounding when you step back and look at it and then step back again trillions of dollars sloshing around 14 something million ether staked blah blah blah I think I have to say nfts I lied I'm not really here to tell you a story I am here to tell you about stories when I said that stories are everything I meant it stories Propel us through our day-to-day do the chalk marks on the floor telling us where we came from in this Labyrinth that we call life and my job requires excellent storytelling it's a craft I take with the utmost responsibility the stories I tell have to be compelling and true and entertaining there are a myriad of people who deserve an enormous amount of credit for coaxing ethereum into existence so I hesitate to draw such focused attention to a single individual but we do love our heroes we might not be here today without the story that vitalik told us so many people out there deal in these things called ideas and idea Merchants need not apply ideas are thin things electricity surpassing some minimum threshold across a path of neurons in your mind ephemeral things but stories stories have staying power they are sticky things infectious things ideas are nothing without a story to carry them and stories are the incantations that we magicians use to summon ideas into existence out of thin air a few years ago I decided to tell a story I called it the core developer apprenticeship program and I told a story about what some people call a job or a career I don't think those are exactly the right words identity Mission purpose okay it's a job it's a really cool job I told them a story about getting paid to build what has the potential to be the most important tool Humanity has ever imagined and they believed me they showed up and droves hundreds and hundreds of them hundreds and hundreds of messy people with Messy lives they showed up eager and ready to learn what do you have to teach us Piper absolutely nothing this is not how it works go figure it out for yourself no there is not a road map no there is not any curriculum no we have not called it Serenity for a long time no I do not know how zero knowledge proofs actually work but they did it not all of them but enough Danny and I like to say that the doors are all unlocked and hilariously wide open and I think a lot of people have trouble believing us but all you have to do is look these people walked through those doors one after another out of the Rat Race away from okrs and conversion funnels away from larger salaries and Stabler jobs and away from the that I never ever want to go back to stories are power and power that I have learned how to wield unwieldy things that can slip through your fingers things that can burn you when held too tightly or Too Close I almost drowned a few years back I told everybody a story about a new ethereum client that would be lightweight line after line of code months turned into years the thing grew and metastasized wasn't this thing supposed to be lightweight I watched as it pulls me deeper water filling my lungs I can't let go my precious story that wasn't a lie but would never become true okay of all of the things I was saved by a story about a monkey and a pedestal and dreams of the Moon so much time wasted and money to learn that I was telling the wrong story why do we have such a hard time letting go of the things that no longer serve us a few years ago I told another story that it's called stateless ethereum an Epic Journey fraught with Peril a story filled with swaths of blank pages yet to be written a story with a chaotic beginning and a fairy tale ending and nothing but empty space between a story that some of you seem to have believed was worth telling and that you continue to tell and that is still being written Aya tells us stories about Infinities and games Dany told us a story about a bright beacon on the path towards a yet to be realized dream Alexi told us stories about how we're doing it all wrong and he's not entirely wrong parody told us stories of Make-Believe and fantasy that all turned out to be too good to be true Nick tells us stories about the names of things and vitalik tells a story after story after Story and today you've listened to me say the word story 30 times or so without necessarily having a clear point to be made what story are you going to tell [Music] I I did a talk like this a few devcons back on the subject of depression uh My Hope was to help normalize some of the stigma around mental health issues that are prevalent in our industry and often invisible and that I have personally struggled with my goal this year was to do something similar for the more broad topic of the messy parts of our lives there is immense social pressure to present a very well manicured version of yourself fairy tales make for good bedtime stories but when we tell them about our own lives we deprive other people of the opportunity to really get to know us I'm done with telling fairy tales it's easy to feel like we are alone when everyone around us looks so well put together my life is messy I suspect some of you have your own messes you at least don't have to hide them from me thank you [Applause] [Music] [Music] thank you [Music] [Music] [Music] foreign two yes hi everyone thank you very much for being here it is the end of the day we I know you're looking forward to the happy hour um so I promise I'll be short uh my name is Emilia I'm the head of sales of chain security and this is estadio the core unit facilitator of makerdale Data Insights he should find the shorter job title yeah so um today I'm gonna be talking we're gonna be talking about uh statistics on maker Dao vote delegation um and you might be wondering why uh me from chain Securities and not from McDow why am I talking about this um so chain security we're smart contract Auditors and we work with many large D5 protocols including maker Dao with whom we've had a very close partnership for quite some time and as head of sales of chain security I've had more and more to you know deal with dials and kind of go through a process that almost looks like an RFP you know like a public tender to sell something to a state um and I was kind of wondering um what exactly is the difference you know when you talk to some people and it seems like a decision is made and then oh yeah it's the Dao but sometimes it doesn't feel that different so I was kind of wondering okay how exactly uh is the community represented in those doubts um and uh two look at that helped me a lot um because we looked at vote delegation in maker so that was introduced uh in the summer of 2021 and uh so what I wanted to do was to look okay since it's been introduced what has changed what were the effects of uh voting delegation so just you know kind of some data to to kind of put things in perspective um holders of maker tokens vote one maker token equals one vote so and there are approximately one million maker tokens in circulation and that has been the same in 2021 and 2022 so the whole period studied let's say it's approximately one million maker in circulation all right so you can vote as a maker token holder but the problem is that voting takes time and money hence the introduction of Delegation basically allowing maker token holders to entrust someone a third party with their voting power so um meaning it's kind of like a politician in the end you know that you trust with your vote you vote for them and then they can take decisions for you and they're going to be involved in this process you know of reading on the potential decisions the potential changes that are going to be implemented um one thing that is kind of interesting is that as opposed to a politician where you have a fixed term four years or whatever here you can undelegate at any point so if at some point the so you as a delegator you delegate your tokens but you can undelegate at any point so basically firing them you know if you want um and so there are two types of delegates you have the shadow delegates so it's permissionless as if I was saying all right I know you know everything you know about maker I trust you to take decisions for me and it's kind of just peer-to-peer between him and me but they are also recognized delegates which are monitored uh by the governance core units um and there we can see some information about them and so this is an example of the two biggest uh delegates in maker Dao so here you can see you know how much they participate in votes how much they communicate on the forums you can see how much uh you know how many tokens are delegated to them and so on so there is kind of this transparency and this this oversight from an authority that is the the governance core unit um okay so now that we know what it is let's look at you know kind of How It's impacted uh the community and the governance here we can see so this is from a beginning of the month um we can see that there were uh uh took 115 delegates and among these 23 are recognized delegates and what's very interesting I find is that almost 15 percent of Homemaker tokens are delegated so we can see that you know it has really had traction it's not something that is just a small and on the side but now it's interesting in these 15 what does it look like you know who delegates to who and this is something that we can see thanks to the amazing work of the data Career Unit um so here you can see on the left this is the largest delegator and you can see on the right who he delegated to why do I say he because probably it's ruined the founder right um and you can see here really who he delegated to um and what's very interesting is that he delegated to people that he knows and publicly supports but he also delegated to people that he publicly disagrees with he also delegated to University clubs you know blockchain University clubs and so that's kind of one of the big points that I want to make in this presentation um sometimes we think that the idea of Delegation is that small token holders can kind of you know get together and become more powerful and so on but actually one thing that we see most is that it's the opposite it's huge you know it's whales who decentralize a bit of their power and so we can see um these are also like the other five or these are also kind of big uh big token holders it's like in Dresden Horowitz and and other kind of whales and then we have not even 8K not even 8 000 maker tokens delegated from all the rests um so you can see that you know this is a much smaller right amount and so all the rest delegates to all these uh all these delegates so now that we know kind of the structure of Delegation we can look at Q2 2021 so which is the quarter right before delegation was introduced in the summer so like in July August uh 2021 it was introduced um and then we compare it here with Q2 2022 so one year later um and what is really interesting to me um is that you have in terms of the median poll participation in terms of the number of maker tokens you can see that there's an increase of 540 percent so what does that mean there are way more maker tokens which are put in on average you know in every vote so that means it is way harder to commit a governance attack you know so if you want to I don't know do something kind of shady with the protocol to borrow tokens and kind of have this voting power to do something nefarious well it's much more difficult when there are 92 000 maker tokens then when there are 14 in a vote so that's kind of the the very interesting takeaway there so takeaways um whales delegate their mkr as a way to decentralize themselves and we see again like I said before a very significant increase in the number of maker tokens uh that are um used in votes um and so now some questions that you know I don't have time because it's a very short presentation um you know I I think it's interesting to think about okay what is the optimal level of oversight you know on these delegates um so the you know the core unit that takes care of governance how much should they monitor them and and and you know kind of have this relationship um also uh looking at the compensation of delegates it's kind of interesting if you have um ten thousand to maker delegated to you so that's approximately uh you know almost nine million dollars you have a yearly salary of a hundred twenty thousand US Dollars approximately so that's a salary that you can live on um and so that's that's a cap so is this an appropriate compensation this is also I think a very interesting question um another thing so now we incentivize delegates right but should we maybe incentivize voters should we incentive device delegators maybe this would make sense there is also something that we've seen is that some whales delegate to themselves and it's kind of funny to think you know that you're gonna get paid to delegate to yourself but as we discussed um it's also some work that you know you do even if it's for yourself if you publish on the Forum if you do all this research maybe this is also you know something that you should be compensated for even if it's your own tokens and finally talking about whales decentralizing themselves should we maybe lock you know those tokens in a delegation contract for a longer period of time so that you know you cannot say oh I'm decentralizing myself but the second you do not exactly what I want you to do I take my tokens back so maybe it could be interesting to create this type of this type of options um so I just want to say a quick thanks to those who helped me um I focused here on maker but I also want to say thanks to the compound team to the pull together team and to reverie for helping me prepare this presentation and of course uh to tadeo who helped me and have provided all the data thank you and again just a little reminder I'm not from maker Dao I'm from chain security we do smart contract audits for Maker Now he hello do we have time for questions oh yeah anyone one question and in the meantime I want to the Sankey diagram is actually the work of Fernando from go Alpha but I just want to give him there's him uh anyone have a question over there okay sorry you said there was uh you know 24 official delegates and 92 unofficial delegates or something like that how do the 92 become an official delegate I guess that's the 120k compensation right um so in terms of the onboarding to become a recognized delegate right now we're trying to keep it as easy as possible and this is have a great work from gowalfa and the governance teams it's yeah you have to have a call you have to present a platform uh present yourself and basically you have a Public Image again it can be a Anonymous person that's totally okay on our side but you basically need to have an open dialogue with the community something that was shown in the one of the first screenshots coming from our voting portal um there we we actually the compositions is um is managed by the performance the performance is uh basically easy delegate voting on all the polls and all the executives and are they giving a reasoning for those votes but [Applause] [Music] now I can do crowd work appropriately all right [Music] um hola me Amo Andy and that is all of the Spanish I know unfortunately uh which is surprising because I've used Duolingo anybody use Duolingo but I used it a bunch and I'm not at all fluent now Duolingo boasts gamification that's how they like do what they do right and it certainly is fun right you get badges you get experience you level up um but it doesn't always do the best job at learning at actual teaching um and so what I want to talk a little bit about is gamification and what that means in terms of composability in web 3 today my background is I'm a former professor of games I studied digital media effects for a variety of entertainment media and how the affordances of systems impacted player or user Behavior so yeah I studied video games for 10 years they gave me tenure and then I left for crypto because hey we're all here right um in my time in crypto work for a number of protocols that you'll know status chain link labs and last year during the metaverse excitement and um you know play to earn excitement and nfts what I noticed was that there was something missing there was a lot of talk about gamification in terms of incentives and Awards and bonuses and experience points but there wasn't a lot of talk about game mechanics and how those worked there was a lot of handwringing about it but but not a ton so I now founded a company called Infinity Keys we are a project that tries to think about composability in web 3 especially on the evm and how we can make games with that so uh quickly right now if you go to Infinity Keys IO you can see a number of different kinds of games that we have they're mostly games where you have to solve a riddle find a passcode or go somewhere and find a passcode or go collect an nft and this is kind of core to what I want to talk about in terms of composability it's it's not finding a passcode and minting an nft achievement that's all that exciting that's a piece of it you can make fun games out of that but what is interesting and exciting is when we take the nft that you mint a composable asset and we require that in the next game and then we give you a reward in nft for that and then we require that in another game and then we start interlacing those assets together and requiring them and then my my the the final sort of end state that we're trying to build that Infiniti keys and that I want to encourage you all to build as well is we allow anyone to lace those assets together so developers and Engineers you know how to require composable assets you know for gating and have them talk to each other but average people don't know how to do that yet they still want to play games and they still want to be able to design games in many cases and so what I'm advocating for here is a new type of game a new type of game that relies on composable assets I'm coining the term composability games we'll see if it sticks that allows anybody to do this sort of thing and um it's not just to make games and have people have good experiences that is a part of it that's a piece of it and that's what we're doing right now it's very fun and you're supposed to have like yay I solved it like a good moment that feels good that's a nice experience to have with uh blockchain but if you take a look at this if you're familiar with that complex systems or complex adaptive systems how they work is you have a whole bunch of small components that interrelate as part of a system and as they interrelate and as there's more of them emergent phenomena start to happen and I believe I think that if we do this with nfts and we start to connect them together not just nfts but tokens wallet signatures all sorts of sort of composable elements that live on evm we'll start to see a new kind of may I use the term metaverse metaverse isn't necessarily a 3D digital world it does not have to be by any means and what I think is more interesting are deep digital worlds hey everybody good to see the room uh and when I talk about deep digital worlds when you play a game y'all play WoW anybody world of warcrafters I know there's a couple or breath of the wild anybody Destiny all right I know I got some Destiny people in here when you play one of these games you go in there's so much to do it's an extremely rich and vibrant world because any town you walk into there's a hundred quests and there's NPCs that tell you where to go and then you go to the next town and it's a different culture and there's even more to do we a a metaverse isn't just a plot of pixelated land that you can build things and put up a new sign or even build games it's a rich array of things to do and you don't need 3D worlds to do that what you need is a whole bunch of stuff to do composable assets let us do that if we connect them together using fun experiences called games um so this is what uh I'm building we're building at Infinity keys and it's a piece of what you are all building as well and so I I really do think not only is it about composable assets um but it's about composable communities um I'm not going to talk about this too much because I do have limited time uh lightning talk many things to say not a lot of time to say it but that's okay uh come on in plenty of room we're here um but kind of core to what I want to think about here that's different than just requiring it one nft to Mint another nft is we need to make good games and make good experiences and that's something that um we haven't been that concerned with because we've been making sure that the technology Works making sure that we can a stake and those things are secure or can be secured if you use all the best practices making sure that we do convert to proof of stake well done uh um team but now we can start thinking about user experience Beyond just what's on the screen and what do they interact with but what are the feelings that they have games are more than just a place to reward you with even more tokens they're a place where you can help players have interesting emotional experiences and that is if you go to Infinity keys I O and you solve some of our basic puzzles they're easy but you like all right you feel good you get that little kick and that's enough in many cases and those emotions are really really powerful attractants as as we bring more people into web 3 and into crypto economic systems right now a lot of the emotional experiences that people have with crypto is number go up which feels good but it's not sustainable and number goes down which is terrible and leaves a very long lasting impression the rest of us are here that like figured out that Curiosity um you know what else can we build how do we improve systems with that but most of the people that interact with crypto systems that's what they deal with number I go up number go down games can change that I really do think that and not only can games change that um but by leaning into composable assets and and permissionlessness of systems we can open that and broaden that to far further and further reaches it doesn't have to be me creating games instead of my nfts you can be a fan of a band and create trivia and reward nfts for very cheap or free on layer twos and Roll-Ups and all those sorts of things and make those a required asset for the next stage of your own hunt I I can make make a hunt about Devcon where you have to go and and collect poapps from five different people you got to collect one from Dave Hoffman and from Preston Van Loon and you got to find Hudson and now we've got a fun Quest and now we're using the composability of poapps which is a fantastic really fun system that we've come to love and now we can create layers on top of that and then once you have that layer we can create layers on top of that Etc et cetera Etc and by opening up to community we're creating uh Stronger systems I lost track of time and so I'm getting cut off so I will wrap up shortly I promise I think composability games will be something new and this is a meta that we have missed thus far um gaming web3 gaming is a has been about owning your assets which means selling your assets assets which is kind of boring maybe it's a value for some people but it is far from the greatest value that we offer as a community of people building together that the value is the network and so let's use the network to create value for people and their experiences uh that's what we're doing at Infinity Keys you can check us out we have a number of live puzzles we recently got a lens Grant and so put up I'm not going to read all this stuff but we recently put up a lens challenge where you have to go to different dapps on lens find passcodes bring them back to minta key and then when you collect three keys you can mint a treasure chest it's all valueless free nfts for fun we're at Alpha but what we're starting to see is people coming into our community starting to build their own puzzles and figure out how can we expand this world and use the assets that you've already created that we created all last year ad nauseam how can we put those together and more in the future to create a wider world of composability in gaming there's treasure everywhere this is a really important statement to me it's not just the loot that you find it's there's treasure in you there's treasure in us and our ideas and the things that we can build together if we use systems that allow for composability and interconnection that is my time I'm happy to talk to anybody about games I also love music or whatever I'm around very tall you can find me thank you very much for your time [Applause] [Music] thank you [Music] [Music] foreign [Music] feel free to come in over here there's some seats on this side still I'd say there's like 15 over there so I'm Connor spelsi and I'm the founder of the Dow research Collective and at the Dow research Collective we fund Aggregate and curate Dow research we're non-profit we also make that research searchable and we make it freely and publicly available to everyone forever as long as we continue to exist so please jump on and check it out a bit of my background I'm really a crypto researcher a focused on advocacy and Dows I've formally started other nonprofits in the space including the blockchain association and the Canadian web 3 Council so a bit of advocacy which also comes into play as we run the Dow research Collective the presentation today is about open sourcing information for the public goods I think everyone here is probably sold on open sourcing information so I will like skip that part in favor of just talking about what we've done on the Dow side it's only seven minutes that we have here today so if there are two things that you could take away from this I'd love for you to think firstly if there's any way you want to be involved in what we do please uh come reach out to me afterwards and if you want to start your own research Collective be it in crypto or otherwise I'd be very happy to chat about what we've done which is what I'm going to focus on today so how it all started well like really just all started because we realized crypto companies are spending way too much money on legal costs and we were thinking how can we make this more efficient we started tweeting about it had some phone calls and then we formed a non-profit so as a former lawyer I can let you in on a secret which is that law firms charge crypto companies over and over again for the exact same legal advice now some of you maybe have become aware of this but a law firm will draft a memo on something like nfts or Securities and then you as a client will approach them they will adjust that memo 10 or 20 and they'll sell it to you at the full price and you'll be paying tens or hundreds of thousands of dollars so obviously not really an efficient use of the community's money when we could be doing more collectively to take on that advice so in chatting with more doubt stakeholders realize that this phenomenon doesn't really just apply in legal of course right it'll also applies to so many other things in Dows treasury management Community taxation Dows are very much as I'm sure you're all aware novel forms of organization and there's very limited precedent to allow for Dow stakeholders to know how to operate efficiently and so those stakeholders are now taking on a lot of responsibility and researching a ton of new things all by themselves I I know that a lot of devs have a lot of money but they have very limited resources and time is certainly very limited resources for that group if they are doing research that research is often siled in that particular community so the Dow community at large does not benefit from it so what we are really focusing on is getting Dows to pool that information at an early stage so as a community we can all rise up much more quickly and we can do this in one of two ways or a composition of the two ways which is you know if you're a dow or if you've done research in the space you can open source that research now or you can pool capital and buy research collectively which we can open source for the community to the benefit of all of us and to the big loss of the law firms so an easy example here right you have a number of dows that want to come together to get information for instance on how to pay contributors they can go to a law firm you know Ave and compound could go to law firm separately or they could come together pool capital and buy advice from that law firm now there are some limitations here obviously some information is very sensitive it has to stay privileged and confidential or some information has to be tailored specific to the Dow but there is a ton of generic advice which we are constantly buying from these organizations and the same applies not just to law firms but also with respect to other research that we're buying really as a community so in building the research Collective step one was really identifying the problem right we have a very limited amount of resources and we want to make sure that we're spending those resources on getting for the Dow Community what they need most so in the summer of 2021 we hosted a virtual Dow Summit with the Stanford center for blockchain research and also bankless and really the focus of that Summit was what are the biggest issues in the space and how can we contribute to improving the space as much as possible with our limited resources we Then followed up on those events with an IRL event at devconnect and that at the start for the Stanford blockchain conference as well to really get a list together the things that are most important this is a really a very tiny sampling of it but um medigov in particular an organization we work with is currently building this incredible open problems in Dow science um I would guess you'd call it a paper and I'd really highly recommend you all check it out we're helping them out with that too uh step two so you know the problems you have to identify who is going to help you solve those problems which is a much harder thing to solve for so this is our list a great list of fellows that we have we were lucky enough to have a very strong Network in crypto but we realized we don't really have much of a network outside of crypto particularly on the academic side where we wanted to speak to a lot of experts in political science in governance in treasury management even who come from different fields but who would be really critical contributors to what we're doing in crypto so we spent a lot of Cycles reaching out to institutions we became much closer with Stanford and others and we now have a great group many of whom participate actively in editing and also drafting research for us um eventually we also partnered with medigub and scurf to Fabulous organizations which are crypto native but much more deeply embedded in the academic spheres than we are so curation and distribution kind of the third step we realized okay well we can fund a lot of Novel research and that's great obviously we have limited capacity for doing so but there's also a lot of amazing research that's just out there already um so let's not duplicate it we realize that something we had to do was build a platform that highlighted quality research that was already out there in the community which people could check out and make it searchable right so that it didn't just disappear what happens so often in crypto is that someone will publish something amazing they'll put it on Twitter it'll exist in our minds for a couple of weeks maybe and then a week you know after that we can't search anymore we don't know where it is someone writes the exact same article a month later and the cycle continues with a lot of duplication and a lot of waste to avoid that duplication we set up this platform which is searchable we curate a list of resources that we think is really exceptional and we've opened it up for the community we've also written primers on kind of these core areas of functionality like legal entity structure advocacy decentralization Etc and can give you a quick primer on the subject matter and you can just double click to dive deeper when you want to learn something more about a particular topic so results we can uh yeah so results how do I work out we're happy with how it's going so far we can always approve of course like as a non-profit our thought is that our objective is really to help the community accelerate as quickly as possible and so in order to do that we obviously need to be interfacing with the community a lot to get a sense of what are the biggest problems for the community and so we had an anonymous survey done fairly recently and the results are a bit surprising you know people the second most common reason people use the Dow research Collective was for research was to avoid duplication of their own research when they were starting and looking into a new area that they hadn't previously focused on but the uh the the most common reason they'd use it would actually be to find subject matter experts in particular Fields so we appreciate there's a huge Talent issue in Dows where we are doing things like setting up very complex governance systems often without any governance experts at the Dow right it could just be a collection of people of operators of developers who've done some research on governance but they won't give you for instance as good of advice as Andy Hall who's a professor at Stanford and governance and political science we'll just have a bit of a better sense of it so we see that as a huge need and something we're going to need to focus on going forward while also continuing to build out the platform and that's it so if you do have any questions about what we do or if you'd like to contribute your research or if you'd like to set up your own research Collective crypto or otherwise I'm super happy to chat about it so have a great conference and thanks for coming everyone [Applause] [Music] thank you [Music] [Music] thank you [Music] it's Justin right over there okay hey Justin if you want to come hang out over here [Music] [Applause] [Music] foreign [Music] [Applause] [Music] [Applause] [Music] all right ready when you are hello everyone how are you doing gym all right so uh every Dev Connor uh maybe about every quarter I send this tweet which is why are we here what is the purpose of web3 and I'd just like to see how the results change over time it's kind of fun to see what the community's values are and what they think we're doing with this technology and I I kind of bucket the responses into the the following categories so uh the title of my talk is ethereum is punk and I think the first category of punk that ethereum is is safer Punk so basically a cipher Punk is anyone who is advocating for strong privacy in cryptography and especially sovereignty in their digital systems and this serves as a route to social and political change decentralizing power into the hands of the individual ethereum is cypherpunk and if you want to know about the roots of the cipherpunk movement you can read the cypherpunk manifesto which is a canonical piece of text from Eric Hughes is a really very prescient considering it was written in the 90s the second category of punk that I think is really interesting and has only really developed over the last couple years is this idea that ethereum is solar Punk so solar punk I think is our alternative to doomerism in a world with Rising coordination failures like climate change Rising autocracy misinformation breakdown of the international order we now have a transparent immutable programmable and Global structure for coordinating we just need that key that unlocks the ability to build new institutions Humanity coordinating at web scale and that is how ethereum makes becomes solar Punk so if we want to make ethereum good for the world first we have to do no harm and I'm really proud of the merge and the fact that the network is nearly carbon neutral I think we have a little bit of work to do to get rid of the rid of the scams on the network but from there we can use this programmable substrate to build better coordination hyperstructures that can do things like track carbon credits and start to solve climate change but also can track impact on any other Vector so ethereum is a coordination substrate that it gives us the ability to coordinate at web scale and a lot of these problems can be framed as coordination failures I also recommend that you read the solar Punk Manifesto this one's not nearly as influential as the cipherpunk manifesto but uh there's a there's a few different solar Punk manifestos basically solar Punk is a movement in speculative fiction that imagines what the world would look like if we solved our contemporary problems around sustainability and coordination failure so solar Punk is an art movement that envisions how the humanity might look if we've succeeded in solving our major contemporary problems with with coordination with an emphasis on sustainability and things like climate change cipherpunk is the uh the value system of sovereignty and privacy and there's a blending of the two that has really been developing a lot over the last couple years so ethereum is punk ethereum is solar Punk ethereum is cypherpunk and since these things are not mutually exclusive ethereum is also lunar Punk so lunar Punk is regarded as The Sibling aesthetic of the solar Punk aesthetic uh has more Universal properties such as like with witchcraft futuristic design nature renewable energy and you can kind of think of like uh it being solar Punk with an emphasis on sovereignty and privacy or Cypher Punk but with an emphasis on solving coordination failures a middle ground between the two ethereum is lunar Punk and I would really encourage you if you're looking for a canonical piece on lunar Punk to check out this video Lunar punk in the dark side of the cycle that went viral about a month ago I think that lunar Punk is good because it's solving coordination failures and it's blending our safer Punk values in our lunar Punk values there's another interesting alt of punk that I I think that many of the room haven't heard of I only know about it because I get tagged in every Twitter conversation about this stuff um and it's called terrapunk so basically the idea behind terrapunk is uh is taking solar Punk and looking at the art and realizing that there's not a lot of humans in it and uh and basically if you look at solar Punk and you assume that we're going to solve our contemporary problems with coordination with it then you're going to uh then are we going to do that in an accelerationist way where Humanity continues to scale along with our economies or are we going to do it in a way that you assumes that 90 of humans aren't there and so I don't necessarily agree with this interpretation of solar Punk but I do think that terrapunk as a way of expressing solar Punk but with a more like high growth High human way of doing solar solar Punk is kind of interesting I think that what I get from all of these different variants of punk and what I get back from the tweets that I that I sent out is that ethereum is a mirror and what we build on ethereum is an expression of the programming capabilities of ethereum but also the mirror of their values looking back at us through these systems so ethereum is all of these things ethereum is a coordination technology and it's all a coordination all of our human systems and meeting our shared needs involve the coordination between people in these systems ethereum is a shelling point for the hopeful a transparent immutable programmable Global substrate for finance and coordination and since we can program our values into our money ethereum is going to be a shelling point for people who are creating new coordination systems using web3 we can build new coordination mechanisms that leverage collective intelligence to solve some of Humanity's most pressing coordination problems through my work at git coin which leverages quadratic funding we have become an uh Aqueduct for funding within the space and we do three million dollars worth of funding to the communities in the web 3 ecosystem using the magic coordination technology that is ethereum and also the quadratic funding mechanism that distributes value to communities so far Bitcoin has delivered 69 million dollars worth of funding to our digital public goods this graph is an expression of the community's preferences for what they're funding so every Edge in the network is a transaction and every node is a grant or a user and this is a mesh network of the preferences of the ethereum community and which public goods they care about so we're building coordination Technologies to fund the public goods that we're that we care about our vision at gitcoin is to hopefully take ourselves to the quadratic lands a place where we've Rewritten the laws of economic gravity to support public goods and prevent coordination failures and to do it in a privacy preserving way ethereum is a mirror that reflects back to us our values and this is our vision of where we want to go you can kind of think of how much we're able to realize our values as a heuristic function in a fitness landscape and we're executing the search space asynchronously and all together of finding the global Maxima of how much we can realize our Collective value realization using collective intelligence to allocate our Commons resources we were building hyperstructures institutions in The Ether that are able to meet our shared needs and um and are deployed on Smart contract technology and the sum of all of the hyperstructures out there are they form a meta hyperstructure which is a a set of hyperstructures that all interoperate with each other in a modular way and help us to realize our shared values so what I'm saying is ethereum is cypherpunk ethereum is solar Punk ethereum is lunar Punk ethereum is also terrapunk we are the ones who we've been waiting for regardless of whether whether of these Visions you believe in so let's coordinate and let's build the world that we want thank you all right so I'm going to take a little chance and we're going to get a little weird I invited my friend Justin Holmes up to the stage to uh sing a little song about coordination hey Justin let's get a round of applause for Justin [Applause] what's up uh just hold the mic right here please cool all right what mic are you going to speak into here let's let's do two mics right can everyone hear us okay can you hear Justin's guitar okay cool so I've known intellectually for quite a while that ethereum is all about coordination and I felt it in my bones that we have this programmable substrate for the ability to create with our ability to create our shared needs and I invited Justin to do this song with me because I want you to feel it not just to think it ethereum is all about coordination we are the ones that we've been waiting for and I'm so thrilled to be here with you today building this new world called coordination when we give each other lifts [Music] our improving situation is our most important gift so this is going to sound a little weird but lately I've been falling asleep to the sounds of air traffic control I have the privilege of being a native English speaker most air traffic control is is English and I don't know if you've ever listened to air traffic control it's a strange thing but uh it's really quite an impressive feat of coordination around an extremely deadly possibility and um it dawned on me the other day that there are two obvious questions that arise from this one assuming we on a medium time scale deprecate the monopolistic violent coordination inherent in state imperialism how are we going to do air traffic control literally air traffic control is anyone working on air traffic control on ethereum and the other perhaps more obvious is what are the lessons from those existing highly coordinated activities obviously ATC is just one example that can inform us we don't perhaps normally think of those as inspiration but maybe we're kind of at a point where it we're strong enough that it would be helpful Maybe [Music] oh it's called coordination when we give each other lift our improving situation is our most important gift all right let's bring it down a little bit I want to talk about someone who's been really inspirational for me and has been foundational in their contributions to the ethereum community they started youth research and they created a blog post called ethereum is a game-changing technology way before I even discovered green pilling or coordination technology and their name is Virgil Griffith Virgil has been an inspiration to many of us in the reap protocol research side he's been an inspiration to the ethereum community and he's now in jail for coordinating with the wrong people and regardless of what you think of what he did and why he's in jail I think that we can all agree that Virgil is an inspiration to all of us and so Virgil if you're listening to this we miss you brother thank you for seeding this vision of ethereum as a game changing technology and I hope that we realize that Vision together [Music] for improving situation is our most important gift [Music] foreign [Music] I spend most of my days working on threshold crypto and occasionally zero knowledge proofs and um I have for like four years now and during that time the solar Punk movement and particularly an emphasis on coordination as a part of the gravity well of economic impact and computational impact of ethereum has arisen and it occurs to me that this is a good time to remind us that The cryptographic Primitives that come from the ground come from the mathematics the inherent physics of the universe are our Birthright as Information Age beings and they represent both a tool kit for coordination and also a reasoning for coordination oh it's called coordination when we give each other lift our improving situation is our most enduring gift I guess what we're saying the tldr is that ethereum is what we make of it so let's coordinate it to make it something good thank you [Music] and uh another round of applause for our amazing Mike Mike stand right here all right so uh Justin you're playing a show tonight is that right Diva Lounge on the first floor you know uh the chiva Lounge is like where all the colorful flags are seven o'clock is coming right up so I hope to see you all there for some blockchain Bluegrass and video game traditionals peace and love thank you [Applause] that came out really well 