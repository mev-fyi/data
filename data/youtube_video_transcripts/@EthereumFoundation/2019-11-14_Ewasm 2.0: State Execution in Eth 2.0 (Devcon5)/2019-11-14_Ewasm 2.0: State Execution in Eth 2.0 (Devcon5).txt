[Applause] there's some time steps so if you do have to leave for something you can still come back and know what time you should come back but please like look at those times you know somewhat flexibly maybe come five minutes early compared to those times just to be sure so first we're gonna have a lengthy intro on what execution and a 2.0 is and then we we have some explanation on the toolkit we have which is called scared you should be really safe for this first two talks for sure because that gives you the background what this is and Scott explains to you how you can write any of these environments how you can test those out so if you guys are developing or want to develop anything on e 2.0 these are the bare minimum you should really have a look at and then we're gonna go very deep into a lot of the research we have done on execution environments now a big challenge of execution environments is which TC can explain is that they are stateless and therefore we need to transmit all the data to the execution environments we need to perform an end of operation and a big challenge there is how to efficiently include the data and we have a couple of different ways to do that so for example the the tufa proof is one way SSD is another SS is another way and jungle token is is a third way so these tweets hogs can explain these different ways and compare them against each other and begin at the end concludes me the test map demo which I have something very interesting so Casey if you will start up it's your your time to do the first talk please welcome / kc get the slides please what begin to sites we want to have my just specific to any slots probably gonna have some to anytime at three stuff so if these you know ask your question so when trendy I mean if the uncertainty around the timeline in the architecture of e to is driving you a little bit crazy try being a poor defense I'd like the something shoved along said he organized the recent era and the other day on the accession he said basically we could come to the interview join the cult well and we have a cult maybe this would be the prayer and we're spraying every day that this chaos you know well spring will spring forward some sanity and some serenity so when is there any I mean coming soon the starting is coming soon since 2015 I mean there's detailed blog post since 2015 about Casper and serenity and how it work and actually have to go back to this bar understand you know where the architecture here these two comes from and I think the main point is there were two betting cycles black - betting the state route betting this is when you get consensus by bet was one of those call that was game theory then turned out well traditional computer science is more secure and it's worth this out better so maybe just do something PBMCs fire that became Casper FFG but the main point is that these two game these two processes are wonderful different types of games once the consensus game the other one is an interactive verification game they're fundamentally different because the consensus gave is not deterministic and the internet verification game is deterministic this realization inspired the architecture the phase 1 phase 2 architecture phase 1 is the consensus game and phase 2 is the verification game and ideally the two would be decoupled and as all this was happening the way the the roadmap evolved is kind of messy but it was really in this link this June 2018 pivot was really a hero Hail Mary so again we're just praying that this thing is gonna is gonna work out as a Def Con last year this was the late launch plan in phase one we would launch phase one there would be 1,000 charts that Rashard would collect lots of data blobs and probably the data blocks would be filled with zero bytes so that's phase one we collect data blobs and Phase two we really didn't know early 2019 is crushed did all these like basis depression about-face you were still open how will state rad work will there will excuse me to meet or Glade will there be well all volunteers are scooped lots or will they just you know provide consensus on the data availability of the blocks pi will crush our calls or these we didn't have answers to these questions if you hear the phrase phase one and done what it refers to is beneath research posts it's not really a proposal and all it was just like some ramblings that I wrote and posted and it you probably never even when I've heard about it unless you are a religious scholar he's research but metallic responded to it sixteen days later so thanks for talking I think that's why it started getting correction as a mean the philosophy and approach of phase one and done is basically we start did we just start answering some of these questions so how will stare at work it won't because their own beanie States gonna be stateless it's like way simpler you know I think that's a commonly accepted now it's going to be a meeting execution just like eath one simpler Valhalla volunteers be able to keep the executors yes and how will cross shard the calls work they're gonna work great ok don't worry and the philosophy is really just like start simple keep execution minimum you know don't try to answer every question just get something basic like working you know a basic prototype so we piggyback on the existing data structures the beacon state data code fields in the validator accounts okay that's what keys are and then you execute the code and the shared blocks when you turn the state root keeps everything stateless and so basically in the post I argue that when you have minimal execution you know coupled to these phase one shard blocks it's a 10x improvement over or if you just have you know phase one as the data availability engine without execution so again you start simple and easy I like the term phase when I'm done because it's like the execution is coupled to consensus so the old architecture with phase two and phase one decoupled I mean if the execution is in phase one then just you know just say that I don't anyway and you punt the hard question so we put the hard questions about crosshair calls and you know so forth help to the application layer because now you're implementing this logic in wasum you know it's not really in the core protocol is it I mean it's like possible and do any ease whatever you can do whatever you can implement relate contracts unease one so so yeah I mean so you put those hard questions where researchers can keep circling and whiteboarding and you know in the meantime we decided to building and prototyping with like you know we can we have something concrete to work with recently I don't know this is where composability what composability it sounds like composability it's like charting is gonna break impose ability this sounds like news from 2015 if you were paying attention this this is a metallic stock from 2015 a DEFCON one I just think in the text that was on his slide and put it up here so you can read it okay ugly call that code per second this is like referring to a synchronous charts that's what people mean by freaking composability right that cross chart calls are gonna be asynchronous so he went he walked through how this might work was an async call an async blog and in sync callback and but then you know the 2015 2018 he has this other post about how you could do it synchronous crusher called so this is to gonna break composability I mean sounds like it won't if we have synchronous trust sharing close oh by the way if you heard there's gonna be one thousand charms actually it might be 64 charts instead so open question is how will across chard calls work I don't why people are afraid to say that we don't know okay you know you're gonna ask for direction sometimes we don't know I mean long answer we have a prototype and figured out how will the eath one switchover works I just learned like a few hours ago vitaly posted a new post on e3 search he doesn't call to switch over hoping the switch over with interruptions I propose calling it the switch over but he's calling it the transition maybe we should call the rapture but I mean it may never happen okay I mean did like months ago it was really neat there's skepticism that maybe the eats one chain is gonna have to continue on forever and everyone will have to redeploy to rewrite all their deaths we don't know houston worthless prototype it and you know see if we can make it work lastly winter any a January 3rd Navy right also likely we don't know what the price of ether is gonna be you know in our suite to be surprised so commonly people ask oh and yeah that's it for me I'm gonna teach you hey let's do some Q&A what do we know what do we know well we know what's going to use awasum anybody want to expand any other questions so it's really good you put down in the slides there but for people who want to help there's some a lot of help that's needed so the main help that's needed to basically just say is how would cost our calls work I mean help us keep it down I think every we're just getting more people involved more people building IEDs so in attention to the presentation today there's there's a lot of proposals for the crushed red cars right and so we just have to build the different ones in different keys try getting more developers involved in this I think you know this is gonna be really helpful I think that's that's what I've made one of the goals anybody knows what what any of these face two proposals are anybody knows what the architecture proposed this nobody so I guess it kind of will be hard to continue from there but we were supposed to have some slides showing darka textured it was kind of a short time frame to explain all that it's kinda hard to you know to go to everything but we all need to work we need help okay see you mentioned that there were some of these questions which there were answers we've met for many of them there weren't any answers and the same still applies on Phase two the only thing the only things we know right now is just how to execute stuff but some other things are still decoupled from the system the exact thing I'm not sure if you wanna go back to the slide but exit thing is you can us keep the statements you're gonna provide a state and that big topic is is called the relayer Markinson that's one of the big topics be definitely more eyes on and another big topic then is called the fee markets but what all of these means is how do we get the data the stateless contracting and had to be paid each of the parties involved and two we have basically four parties here at least they have the users who want to do transactions don't you want to use the system and we have another party which recovery layers right now who are basically the providers who store all of the states for you and they're able to package up whatever transaction use them into something the system can actually use and then these really are send these package things to the blog producers who are the ones actually running it on e 2.0 and each of these steps people have to be paid so these are kind of big they're many ways to do it and you were experimenting with different ways but before we get into cross shark convocation I would suggest maybe these are the things to be able to Soulforce a little bit so we thought we knew that wasn't code would be run in the shark box and not in the beacon box and then you know about a month ago metallic manual proposal that was that was like the spec as a phase two proposal - yeah yeah and this one they added functionality was oh yeah we also run awesome code and beacon blocks and so that was like eight proposal three and then the proposal to reduce the number of sharks from 1,000 to 64 which I already mentioned in the East magician session you know a couple days ago and said there will be you know more published on this very soon and that's like the radical new new proposal [Music] federal I mean this kind of like would what we know is just as these proposals are rolling out we know a little bit more every time there's a new one what so what's the reason both over that yeah so I mean each of them kind of give their own strengths and weaknesses so like the proposal with what called two and a half three three provided some level of load balancing and some level of scheduling across the charts and and you kind of treat each of the shards this you're competing layer one that kind of you know came after that was more has been more geared towards making crash that calls significantly quicker so you can make a crash call what one block so if you're calling a contract on another block on another shard you can do that block so I think each proposal has its trade-offs and so I think what you'll realize through kind of what we're talking about today when one of our goals has been to you know kind of test ground each of these and prototype each of these and you know really understand the trade-offs the gains on everything and yeah as Alex said I think the biggest still today the biggest question is who who's providing state how how are they paid to do that and so we are we kind of needed to validate some other things first like the stateless Iggy's good working time and that's generally been validated now and so the next you know the next step is really beginning to validate that question regarding the state of free market and then after that is is really expanding a lot of the things around cross our transactions but I from an optimistic perspective there are there is a lot of content and a lot of proposals in a lot of really promising directions for all of these so yeah it smells I think it's a good segue actually to tonight's talk I just want to reiterate the type is what you said today what were the kick started all this work was proposal 2 which was an actual real thing written down so we could take a look at they don't do something but up to that point everything happened just on each researching different discussions it's easy to discuss stuff twist on different texts but it's also kind of hard to know which direction actually make sense in practice so this was a big banquet with that kind of mindset we started to teach a proposal to as it is violently implemented it and tried to validate certain aspects and that implementation is is what it said so basically we took this proposal implemented it and we started out with just the goal of validating those basic assumptions and the basic assumption we had is here the limits of time you can spend and at every sharp block on processing and we all set limits of how much data we can supply to these execution environments and basically we had to write some code in Watson which takes this data tries to do transactions and fit into the time limit so this is what we have done and once we got like two really good numbers and then we solved all these different problems so a couple months of time then we started to look at the prettier stuff how do these things actually get the data and the fee stuff in a long session discussing this on a whiteboard and kind of realize that it's insanely complex and I think that's that's one of the reasons we can actually just look in isolation with these things we have to do we have to look at them more integrated way and I think probably was one of the reason that these new proposals were inspired by so I expect that they're gonna be as we look at more of these different problems and not just you know one problem at a time they're gonna be more and more proposed and we're gonna get closer to the solution so scant itself listening Tom okay so as I said it's this actual tangible tangible piece of code you can interact with it's not just the text so if influence that proposal - we do plan to take in the the changes from different proposals and we also want to come up with our own proposals but we haven't done that yet we were really focusing on getting those core basic things as for regarding speed it actually black does it in a pointer doesn't work so it's black box is most of the stuff you don't care about and just stuff you don't care about at least that that point of time is whatever is happening on the video channel I never do expect that with time as we get more closer to figuring things out and in a drawer did more complex because it has to take in more things from from the different phases but right now it's pretty simple that still there were job announcement URL you can feed a bit more reasoning and you know how does it work but the URL that the github URL is where all the dakotas just kind of itself there's a couple of different ads actually are going to go into this but the thing we call scared is this so basically scans does a couple of different things under the same name so it has it is this tool but it also defines the API is based on the proposal it has a testing format and it has a couple of example e's me we cannot go into that in a second so the ordinary original scared I must be talking about is written in rust and it's it's really small it's a tener that's like 300 lines of code that's that's all what was needed to implement proposal to in a black woods manner it uses waz me which is was an interpreter and the compiler engine it's it's an interpreter it's written in rust but a waste game is written you can you can survive two different engines this engines that will be important later and the user wasn't my tools recovered it a couple of times already but there's this other schedule today scattered TS switch if one has the same API mode is written in typescript and that uses of course notes who uses a fast compiler engine therefore you can do more stuff in time but a quick question did anybody of you seen yesterday it wasn't 1.0 session with benchmarking yet so you know from that that we won't use fast interpreters so v8 is not something you would use at least soon it's not something you would use so if you use scabbit TS to benchmark your EE if you happen to prototyping some ease so the numbers you get there is it's probably something you shouldn't take seriously you have to use interpreters to to get the actual numbers schedules can be found there one other interesting point is that with the rice rust version scant itself is the thing you can execute EES but there's also a library to write e's in rust and you can compile the transcript to aasman and then the typescript there's a second language called assembly script which looks like time strip but complies to wasn't so in the scalp TS repo we have a hello word greater than assemblers will just highlight exists that you can actually write contracts for right ease cargo so right he is in different languages and there's another staff as well but Scott one which is between C++ and that's gonna use webbot the optimized interpreter behave so this is the the scheduler ssin eventually you want to use to get the final numbers which would reflect what's going on on the network okay so what are easy quick recap they are basically the contracts in the chart and they only have a limited access they think are pure functions that all they do they get on the input side they get this data log which is which contains the proof of the previous state so you take that that proof and you construct the previous day to end up at the same state road and that's the other thing you get as an input text your state route which is stored on the shark well as a proposal to anyway because that might change but you get the state route from the chart and then you supply all the proofs to recalculate the same state route then you have to validate that it matches and that means you you have a good starting point and then you also receive in the same data blob all the transactions all the things you want to do so you apply those changes you calculate the the final stage through the positive hood and that's what you work with and that's what's stored so that that's all at ease can do so this is the API the APR in Ind s wasn't close function so the just to explain it better so this e to stuff here is a namespace and this is a function name and these are the parameters so what I just explained you have a way to get the data you have a way to get the P and up and set the positive trip the deposit stuff I wouldn't be paid too much attention to right now because that might change whatever but we also haven't abandoned API because why don't you want to debug it yeah it's an easy way to get something is end of the e during execution so you can print numbers you can pin memory you can feed number in a in a hexadecimal form but this one prints man only prints memory only the printable characters so essentially it's usable for printing strings and giving them a big nom API so that's that was mentioned yesterday during the benchmarking and it's not fixed at all but that is the discussion URL to discuss what the big media should look like this is one of the recurrent proposals it matches what is implemented in the typescript in the past version but it may change in the future so regarding the ease we have in in scalloped itself we have two examples the hell over to the bizarre I can I have some screenshots afterwards and we have a bunch of other examples but they love necessarily in the same place and these all these example is going to be all these extinction round it's going to be covered today so here is an example in rust if anybody is familiar with truss as I said you'll note here basically what this hello world is doing you expect that there is no change no inputs so obviously the piano phosphate with good French but it's just an example to see how to use the API so let's the same assembly script and I read earlier in which both lists which also comprise to us this is a longer example this instead that the baseline to do all of the work we have done because basically this doesn't do any kind of impression or any sparse market fees and just takes in the nail of fascism and that's it so basically this is the state which is a list of messages message contains self just the message of The Times them at the input blog has to supply every single time DD state because what you store is the hash of all the messages obviously you need all of them at the input side of it so this is not very useful it's useful as an example but in order to descale so that's why you have all these discussions afterwards and i mentioned that you can interact with sky through a yellow file such as an example of the demo file you specify what is the code you wanna run the priest a the prostate and the data and you can also run multiple scripts in the same llamo file it doesn't have to be a super single one you never see these sample files in the repos for every single to you so the next steps I haven't mentioned but the emergent equal team and they have taken scared to be integrated into lighthouse to do some kind of testing or simulation and what we actually are thinking about to to move all of that comes back and just have it in scared and have an independent tool to do rapid prototyping now but we do want to add a few things there may be multiple engines and a scalpel of course and me just the the developer experience better have better tools friend that's what we are one scared you guys have army on time yeah right so maybe one one or two questions okay go ahead yeah - you look more about the east crease Ted Cruz and posted moves south like they are soon to be hostage groups but is it up to the EE to use those to buy celebrity wishes yesterday question was that it assumes it's it just hatches and that both the stage with is just ahead and it's not actually limited to 32 bytes which this purpose of - to make it longer I think 96 bytes or something but anyway it's it's a bit please that's Department 56 fights what the state rule is and it's up to the EU to do whatever it you mean so is there capi prescribe 50 you mean writing decency or the law from yes so scanty one would be is written in C++ so that would be the best one to use in in C and you know calling it from C and there was one more question distantly plummet the mine activity is going to be the reservists implementation of scouts invasion as you mentioned the secret last one which sounds like it's more for benchmarking getting the most lecture announces that the assembly strings one I guess exactly if you want to work with assembly sprints and presumably the actual rust ones where is innocent leave the pleistocene register via record it's not fair to say so the center question was what is the motivation for each of these different versions of scale and so a distinction just did the languages used to write the contracts in verses what's kept is written in as you mentioned this in the script so regarding just kept it the way you run these contracts and it depends on personal preference between the thrust in this the typescript version which ones would you like more but on more on a production system the expected scale on the C++ version is the one which going to be used the other two are more for prototyping reasons one interesting fact with the typescript version is that you could use it in a browser you wouldn't even need an environment but I think they're really just personal preference which one you want to use or for day-to-day prototyping the scans one would be what you should use to validate that your stuff actually gonna work and then we got into contract languages the assembly script versus writing contracts with contracts in rust or ease or in C it's again down to personal preference but each of them we have different ways to optimize the code to be efficiently more had better experience which one or that are depending on the use case and that's that's actually one of the the biggest challenges to to figure out what is the the best way to optimize these high level languages for was necessarily encouraging papers some specific one massage is for every what we want to work with right now yeah yeah I would say thanks beer we should be moving on a time right Cecina and came from the he wasn't team are talking about to become a to bow token I'm sure it will be very interesting thanks for products party disclaimers have our time I'm just going to trade on all right so now that we've seen what these are and how we can test them and protect them we're going to go into a sample token EE and our constraint here is that we want to have a token EE that is compatible with one to eath one chain that we know and love the all kind of just thought would be as follows first people going to SMPT which is which was our initial prototype offer stateless token it was implemented in Rossum as well see then we'll go into a multi proof scheme for the work of Patricia free which team will explain and then we'll see two more token which is a lot of e similar to SPT by Jesus the butiful scheme and comes of comes with a lot of optimizations so yeah SME is a stateless o-chem compatible with this one and what I mean with that is given the same accounts it will have to produce the same state route and we also want to enable users to you know to sign transactions with their f1 private keys this initial prototype was in brass and its users parity libraries in order to maintain user balances we stored the key to accounts in the leaves of Patricia tree that you can see in this diagram so the accounts are very similar to each one accounts the same here are the leaves you can see branch no extension notes and so on but note that as we all know this is stateless so this state is not stored unchanged but we rely on third party entities called three layers to store this state and provide the service to users so users when they want to send this transaction they sign the transaction send it to the layer which then attaches necessary myrtle proofs for a sender and recipient to the transaction packages multiple of these into a block and publishes it to the network looking from outside the he would take this block data as well as the priest a truth which is in the short state and it will have to produce a post a true and now going inside of course the EE will first have to be counterpart a town and this voltage is comprised of a list of transactions it's very similar to this one so we have the to address value non signature additionally we have the food for the sender's account and as well as the recipients account and now for each of the transactions the verify the signature be verified demarco crews checked for lumps and balances and then update the leaves of the tree for those accounts after every transaction has been processed we can finally compute the postage rules to evaluate this prototype we simulated 5,000 accounts in the state and 70 transactions and run it through scout with there was we interpreter and these are the results we got so blood size here is 235 kilobytes for the 70 transaction and speed is 5 seconds out of reach 4 seconds is for signature verification but don't panic just yet we'll get much better results very soon might end of this talk now let's go back to the same diagram let's say we have a transaction that wants to prove these two accounts and as you will notice the note that I've highlighted in red will be duplicated in both of the proofs which is inefficient so if we could have a multi proof scheme that includes all the necessary notes but only ones we would reduce the block size and with a good algorithm we could also gain efficiency in the run time by matching the verification and Guillaume will now talk about such as well thanks for Cena but he's coming back so just yeah so I would like to talk about turbo proof that so that used to be called multi proof but apparently everybody started calling their own skeeball T proof so I had actually seen I came up with a new scheme name so it has been invented by Alex I had exact analysis who was using it for for a night clients proposed so it's really designed to to make rebuilding the schrieffer fast and we want to use it because while we're interest but there are several reasons why we want to use it is really pal to the eighth one miracle but Patricia tree and also we since there's going to be an S one he integrated and in eighth tube we we figured it would make sense to to study that so there are three implementations the first one is described by Alexei himself the other two are the ones seen and I wrote in typescript and rust and yeah I'm going to explain how the later latter to work yes so we start with the tree sources century and we want imagine you want to make the proof that you know the values of those two those two leaves so you start by selecting the notes so you if you want those to know those two leaves you this is in write the path that you will have to travel which means that everything that is left will be hashed so this is roughly the the tree that you're going to send over and then you just get all the notes and you put them in your desk first order so you don't actually need to store the two full notes here but they're they're here to help understand the the representation then Alex started using wanted to use a some kind of virtual machine to start reconstructing the proof so basically the preferred construction like how the instruction on how to rebuild a tree is used it is encoded as a program so relief means you have a list of leaves you pick the the leaf at the top of that list extension it just means you take whatever's on the stack and you add it as a node as you saw of that extension branch and add do the same thing the bridge actually creates the wrench node and add just says you have a rational on the stack you have a another node on the stack so you have at least two nodes on the stack and you make the the child node the parent of the child of this of this previous branch node and finding your hash there's also a list of hashes so you grab it says you brought the first hash in that list available in that list and you put it on the stack so I'm going to run through a program so this is the program that includes the double structure information so you start here you have this type right now it's empty you have the list of hashes and you have the list of nodes and so what you do is you start with the first instruction it's a leaf you put it on the stack another leaf so now you have two leaves on the stack or by the way I should have specified to the stack grows in that direction then the next instruction is a branch to grab the branch node and you take the leaf there was first on the stack and you may make it a child and then after that there's an added so the Hat takes the the branch plus child and another node is going to make that note the child of of the top node so that's what you get yeah there's a beautiful squiggle here but yeah that's generated then there's an extension note here and an extension instruction so this is what happens and finally well finding there's a branch so you create the branch like this and at this point you the next instruction is hash so you're going to take the hash from the list of hashes and put it on the stand so it's in the planet at the moment and then finally you perform the last instruction which is the add and it adds the hash to - and by the way there's another mistake here it should be Dino see that the hashes come from yes so it's pretty simple relatively simple it has a lot of inefficiency that you get inherited from from the vertical position petruchio tree it chooses our LP it's nipple base so that makes a lot of unnecessary copies of other than this very braixen in Turkey there's a write-up that is really that is almost ready and it's collecting feedback that we need to publish soon and yes so far to serialize the proof we use our LP as proto mentor who's working on the better way to encode the same tree without the structural information so there's some work here in that direction that's really twisting and that encourage you to to look at when it's when it's published and was this seniors gonna tell us what to do with this turbo proof so now that we've seen how to improve words we can go to our latest prototype which was the majority of which was implemented by virginity in assembly script this is the language that looks like typescript but it's solely different and it complies to working so children has a bunch of differences to SMPTE I won't go into all of them but one of the bigger changes is that the blog title is different it's not only a list of transactions anymore we also include some additional information for the EE and we sort them in a way so that the EE could without many memory copy without many lookups process the transactions and I won't go into details here but you can see how the party looks like so to process each transaction we recover the sender's address from the signature we get the accounts for the sender and the recipient with just a simple index based look up from an array technologies and then we update the account the account objects not in the tree but just the account object itself and then partly encoded and then you might notice that one of the differences here is that we are not doing the proof verification here that we are doing afterwards so after every transaction has been processed we hash of the addresses to get the list of three keys and then in a single pass we do a couple of things as we are rebuilding the tree similar to how how to you explained we hash the existing leaves to compute the pre state route at the same time in a different sack we hashed updated accounts to get the co-state route and additionally we also reconstruct the paths of each of these leaves to get to get the keys for those leaves we want to do this because otherwise I could send a transaction with my own address but then in the motive proof include with Alex account which has much more teeth than me so this is crucial and notice yet again this is done in a single pass and this wasn't hired by Paul Anka so from then as you saw signature verification was a major bottleneck in SMPT which was taking four out of five seconds so to remedy that Casey took beps mark which is a library of optimized wasn't code for elliptic curve and snark primitives he adapted it to the SEC P 256 K 1 curve which is what users he also replaced the the big number thematics with the bignum api and this all resulted in a major runtime improvement another thing that we do is optimize all P encoding and decoding and so we instead of having a generic encode and decode we have specific encoders and decoders for every data structure this is because for example for a branch node we know how it's going to look like we have much more information so we can encode or decode with a lot less memory copies or overheads and to evaluate we took the same test case so 5000 accounts 70 transactions and here are the results we got so in SPT as you remember that the block size was 235 kilobytes and in turbo token that's 50 kilobytes and for runtime in was B we had 5 seconds for for 2 more token we ran the optimized rabbit and it took a hundred 40 milliseconds out of which 105 minutes seconds is for signature verification of KC things that that so can go down 3 please also note that this this is a lower bound because currently turbo token is only limited to updating existing leaves it doesn't add new accounts to try or remove them and in order to do that the marketing adjust the algorithm which will incur some overhead so so what we saw so far all right so I guess we can take questions yes so he looked example try it was a trying it but I'm here is about being back was that the line on the lines of the large try or didn't know what was with five thousand that comes in mistake like that yeah so so this is yeah this is a pathological as Alexa called example it doesn't represent a real workload that's one of the things that we want to do as a next step but it was also like one of the reasons we chose this test case because of the constraints that we have or we think we have we will have for the EE is around 50 kilobytes of data in the block size so we set everything up so that the data would roughly fit in 50 kilobytes and and for run time it's likely going to be around 100 milliseconds have you considered or recently chance that the statement said of being in a but recently we sponsor a country yes and in fact we will see that very soon in the next talks this is as I said like one of the major constraints that we had for this prototyping is that we wanted to remain compatible with this one okay if there's no more questions so far what we saw was just this one compatible token EE but of course we would want a fully fledged eath 1e and for that purpose among other things we will need an EVM interpreter in yes you have like can happen and where we can find us yeah yeah all right yeah I think there is yeah so this is too much okay this is the wrost implementation of okay so for for for the EVM interpreter in in bottom I invite you I'm going to talk about these EBM interpreter there is an environment it was for example be done this execution environment is written in us on the script and it runs on the transformer for cover of scout where I gathered some more cost functions in order to process some of the opcodes the way it works it defines an IBM stock in the wasn't memory where each element in the spike is a 256-bit element so it is basically the same IBM one also defines an IBM memory and later it calls these two cost functions to tell the Scout in which part of the wasum memory this tag DVM star candy via memory exists then it gets the IBM 5 code and the input data directly from the from the raw data and once we have the IBM bytecode interests interests the byte code and execute interpret each one of the of the opcodes the majority of the opcodes are implemented directly in a some script but there are some other code for example this one that instead of being implemented directly in a semi scale because our cost function basically are they the of course that deals with bignum operations and these are a couple of examples this is a very simple EP my thought with just our first put the number one to the to the VM spark then push our gained another number one to the IBM stock and then run execute the opcode so we have the number two in the stack and then we store these are this number two from the start to the to the vm memory and at the end we return this result which is number two and we write this on the on the post at some someone asked before if we can do whatever we want to know please they post data so we can take this IBM white coat and put it in a in a stout test case where we put the bytecode and the expected result here and if we execute this test case we get this result which basically says that conference that we expected what we expected is actually we get for example if for some reason I change this sum this test case and I say that one plus one equals three the skull will show something like this it will show that these are difference between the execution and what we expected and this is another example in this case the EB my code is generated by the Sevilla compiled salinity compiler so we are we are sending this evn by code as well as the input data and again for for forgetting the result of the sound of this contract I also run it in in the MDS VM in the same result that we the SVM I'm expecting to be the result in the execution of the of the execution environment so we run this sound test case and Scout confirms that we but we expected is what we are getting so one of the next steps what still needs to be done the first thing that it to be done is to actually use the discount establish capabilities which means that we need at first we need to have mr. hood and instead of adding the IBM byte code directly in the block data we need to instead a list of transactions a list of proof nodes corresponding to the accounts and the contracts affected by those transactions and we also need to do other posture hood where this reflects the result of the only changes made in those transactions another thing another thing that needs to be done is a test with more more contracts it will be testing with the with the contracts in the team tests in the main team test and finally the one important thing that needs to be done is benchmarking and that not yet and we need to keep testing synthesis business part of the EVM once the equals speech award idea and about the defense's to to probably integrate this into two remote token and at that point you would want to have some kind of a best form of the entire need one blocks to be transmitted but of course you need two cups as well but the buck they did hi guys my name is Matt I am with the police so the name sheath comes from the shard he's her manager it's a token transfer execution apartment just like you saw with Sina and Guillaume and just like you see with all after it's written rust and it provides a few things for you provides an execution environment which is like a web assembly binary that you give to the beacon and it's execute on the shards it gives a CLI tool to build random transaction packages and the proofs that go along with that transaction package so it can be executed stateless ligament and it gives some testing and debugging tools because compiling tool of assembly arrests and it helps kind of streamline on process and streamline the process of writing your execution environment their skeleton so when I started out with building sheath the design goals fishies were we're trying to make took a transfer environment that they're really small of assembly binary we wanted to have a small crew sizes to execute on I thought we wanted to that are going fast and it turns out that we're still working on those things because they're not as easy is and so right now I'm trying to get it really hot or something and what do I mean by hospital I mean it's something like you at a hackathon you go in and fork and start swapping out components and start experimenting with what an execution environment is and does you can put your own logic in it it's hopefully a really readable via there should be the apparently idiomatic rust where us is not incredibly compromised so there's one thing to take from this is to try it for CSUN and get a go at it so the general architecture was happening is kind of laid out here and like this base layer is sheath and that's kind of just provide some like rails for you to build an execution of iron on top of and so each of these like kind of components are things that you can you can swap out and put whatever you want here and so the base layer is kind of the database that you operate on your like multi proof that Siena and Yale talked about and so my implementation is like a sparse Merkel Sharia I'm calling it in because it's an in-place multi proof but you can swap that out for nutritional vertical tree or any other kind of fruit format that you like all of it has seduced has to implement a trait that has kind of these functions so you need to be able to figure out what the value and account is what that it comes to dances and he to be able to add and subtract values increase the nonspecific Council and then there's a few types of types of transfers for execution of artisan 2.0 so the transferred applies in withdraw the deposit of the drawer like beacon chain related functions it's how you move ether in the one shard to the other transfer is how you transfer between accounts but if you you morphism pack out your own things this is where you can add and swap out and put whatever kind of trends transactions you want as long as you update them and the TX interpreter so what is M well it's it's a place to work multi Merkle proof and it's kind of born from the simple serialized algorithm for Merkel Ising very large lists it's it uses a sparse Merkle tree and it's verbalizes things in the same way that this is suspect appliance like Merkel's Asia to happen and it's optimized to perform read rights of reading in place because the original iteration of this execution environment I just use the hash table to back all of my notes my murder weapon I found that the execution environment was dominated by mental coffees and so that's not what we want we want to kind of choose like in admitted environments and take advantage of every cyclist I'm doing in a place there that's even more efficient and so the the citation here is for proto MZ kind of came up with this method so this is like a github link to his repo Arif like first kind of describes it and we kind of come back to this but let's do an SSD review as everyone good good ok so I'm just going to kind of go over like how containers working as a Z because that's what I really how this works that's what I really care about so for a website that's kind of like the object that we're going to talk about on the right side is the tree that it represents so an SSD if I want to verbalize an object it has one value 532 then it's the roots of that the mirco root of that container is actually exactly the value because it's only 32 bytes in each node and the vertical tree for SSE is 32 bytes if we have a container with two elements and these are you one two weeks that's only 16 bytes we verbalize it where it's got a tree of one depth and two children so because there are 16 bytes of a theory that could put them together into one node like we had here but for like accessories and improving reasons it's better to split it out split the containers out based on each of the members of the container so for lists you can see that it has the same structure even though now it has three elements so on the right side that set at maximum elements you can have in this list and here it's the same structure as the container and developments of the same size and the reason is is because here in that left node we're packing all two values in them because they 32 bytes in total and on the right we only have one value and 16 bytes of padding so now as we grow to another container that's a little bit bigger you can kind of see that the number of leaves is equal to the next power of two of the number of elements you have in your container so three elements the next part is four and we have each a note being the values in the container padded to sixteen bytes since there you want you 128 and then the last note here is just a zero padded note so when she's there's the concept of accounts and this is what the account reishi looks like so every leaf of my sparse marquetry is that roots where they count and it has this kind of structure so the bottom left to note is the whites 48 that's the VLS public key then we've got the knowledge that value and then the way that SNC Merck Eliza's things like we saw on a last slide is we've got the padding here for the fourth wave so if I want to prove an account value then all I need is I just need these three notes I mean that's a lot left note and I need the value note and then the padding note and theoretically we don't really need the padding notice is just zeros so what does the like steets tree for sheep look like or like just a general execution apartment well the way that I've gone through out my phone down is that it's going to be as far as Merkle tree and so I don't know if you can read this but it says the list of accounts which was this structure and there's two to the tune of 56 of those accounts and so like what does that look like it's too big filling slide so just like I don't believe it occur I don't think thought in your head but if we were to kind of do it it might look something like this where at the very top of a tree that has 256 steps you've got a roots and then like if you take last ten or fifty six times you'll get to account with address zero if you go right 256 times you get to an account root node with address up to to the 256 minus one so back to the in format in format that lets us do in place marbleization merkel operations it's kind of built into two two main portions this left portion here is the offsets and so the offsets is what let's just reverse this passion is object and you can kind of think of this hashes object is like a continuous array of 32 byte values and some of those values are like internal nodes of your vertical tree and some of our like in nodes that are the actual values we care about like the account balance the non-set cetera and so we use the offsets to traverse these hashes I can run through this algorithm if people have questions on execution environments and rather than see some questions I can do that instead say I have a preference okay let's run through it quickly and then questions so let's generate the offsets so right here I say we've got offsets very no the hashes because we've got the Merkle tree I'm going to figure out the offsets so that we can later traverse it so we can think of a Mirko tree of depth 3 here and we can think of these numbers is like kind of like the general index this is like defining which node we're talking about it you can start with the top node and that's one and then you can say two three just like kind of in order to reverse all the way down the tree so say that we've got this proof right here we want to say we're trying to prove 12 and the nodes we want we need to provide this like in the stainless multi proof to prove 12 is to 12 13 7 so what we do is we kind of like bring those down and these this is kind of like the order that these hatches will be stored in our like contiguous array of hashes or everything so now let's generate those those offsets so the first thing to do is we started like at the very top and it's kinda like this recursive thing we say how many nodes is in the left subtree of this leg entire so this entire tree that we're looking at and well like in that case it's 4 because we can just like count the number of nodes that we're providing as proof on 2 3 4 and so that's like the first number of offsets and so we started continuing to traverse down to the left and now that were wanting to say ok how many nodes is in the left subtree from 1 it's just a to note there because we're not providing anything below we're only everybody that once that's the only thing we need to prove 12 and so in that case it's a 1 so we come down to 2 now we're still traversing left first and there's no nodes and that left subtree of 2 so we can skip over to 3 and we asked how many nodes is in the 3 subtree it's just folded 13 so we can put two in our offsets we come down to 6 same question how many nodes to the left subtree one go down to 12 well there's no no knows where to leave and how we come to 7 and we do include 7 in the proof but it has no children so I kind of meandered just for the office that we've already come up with so this is this is what I kind of improve is we've got these offsets that we generated like 4 to 4 1 to 1 and the branch they'll need to provide to prove this general that's note at index 12 the branch is not actually the branch indices it's actually is 1/2 32 bytes it's just easier to like reason about it might just show the branch indices so right now this is like the size of so I've told you there's a tool to generate these funky proofs and this the size I'm getting right now and you can read them down that's it these numbers like aren't super accurate until we do these optimization so the first optimization is the offsets are going to resent firm is ended by you 64 's and I'm never gonna provide enough hashes to be all those bits of significance so I could probably get away with like you 16 or something but the more important one is that right now including 0 hashes and if you're familiar with the structure of a sparse Merkle tree there's a lot of to 0 hashes especially the lower levels of your tree and so until these optimizations start down these numbers are kind of just like waiting around in the air so I told you about how to create the offsets because these algorithms that you need to do to look up values and do the virtualization so if you're interested in like like understanding those algorithms you can read proto lambdas kind of paper that he published on get up and I've got two implementations I did one in Rus and then I did want to Python this Python one is way more readable to the rest one I suppose Python things they are if you want to learn more about sheath if you want to work in and trying to act at the next target or whatever the repository is github.com slash like client slash cheese and check out the hacking DMD file it's a pretty good guide I'm like recording is started if you want to like play around with cheese feel free to ping me on twitter my handle is about it matters for Garnett and or you saw me at the conference I hope you like talk to you more about shoes so thank you does anybody have any questions or questions ok any questions yes to do from here to do more than transfers people I feel like a lot of the the framework is there and I just like I personally don't have time to build like more exciting ones but I've been the bond it's like really you just have to like go back to like the very beginning this like slide on if I get there fast up but it's really just like replacing these kind of like these concepts transferred to positive Charlie I'm gonna do like a bounties contract II it would just feel like instead of trance would be create Dominique and an interpreter interprets some way and then I would change kind of these are like the variables in yours Olivia contract that's kind of like the same like similarity and so it's possible to do it you can fork it from here and do it it's just you need to spend some time to think about it the hashes can't be some compromise now it's a so is any expected savings any early numbers not really but I have come up with like kind so similar to the way the tours are done was the opcodes I've kind of come up with way of compressing like the offset concept here and I think that that can provide a good way of removing the zero hashes and basically is like if you're not traversing those offsets any boosters for persons with future bursts like through the same team direction for like many different levels and you should just go to compress that and by compressing that you would know so how many numbers so next up is all of these ants eats gonna talk about this stateless Virgo treats okay lots of work right it's a one slide presentation by the way for me lots of work to write a tease but I think the question is how to make it usable I think that this is the base because it's a stateless model and I'll explain this in a moment so everything is stateless and that's - so how many DAP developers doing that never complain fairness so a few so this is sort of what the who this talk is targeted at but there's less than I expect it to be here but for the maybe everyone is interested how are we gonna do stateless what's the throughput but you know how does the policy they're gonna work you know if we have stateless we're passing so many hashes and with the call data this dominates the called a ton crop what is it going to be like one transaction per selecting - I mean is it was this he could make sense to begin with and that's what I thought about an else I didn't think it was gonna work and I have a little bit more hope now it might work but we have to be very careful in this this for the deaf developers in the room this is sort of the basis these Merkle having states so you want to persist 8 but you have to you know hash it up somehow we know that there are other accumulators there's art there RSA maybe some zero-knowledge stuff i think those have big use cases but I think that the Merkle trees also have big use cases but we need trees that have like deaf Millions like you know thousand three millions of in depth so that's the big problem that's the big challenge we need breakthroughs and we need you know efficient Merkle trees for to make EF to the stateless idea that even worked for 30 goods so so now is Mike you know I thought about this for a long time so the two big things are called data size and run time and there are trade-offs between them of course there are speeds size be trade-offs but so I'm gonna explain I wrote everything in C violate chopin's C fence C programming Winston okay great so there are people maybe they're not interested in writing the absence T but I think C is a reasonable language I think we have to be efficient also when were writing EES everything has to be you know micromanage we'd like you know embedded systems we have limited you know memory limited cycles CPU cycles so we have to do everything we have to listen to them invited systems people and do everything as efficiently as possible and there are you know many years of accumulated knowledge in this kind of area so called data size so - so millions four million - to the 22 it comes in the states 40 accounts in the witness what's the best we can possibly want to be dominated by hashes and signatures or whatever for signatures for the transactions I'm sorry if you are if your dad is using but that's the goal is to be dominated by hashes and then the tree structure you know the theoretical limit is zero percent of your call data is for the tree structure but I I can get it less less than one percent that's sort of a great thing there's hope so you know this is the best we can possibly do is just dominated by hashes and this is 425 kilobytes so it's close to etholon stuff but you can double and so you say 80 but it's a little better because there are two things the two first two trips and then two more tricks that are being worked and then another sort of few things we need like two orders of magnitude increase in another one in another big trip in another victory we need a bunch of those two exes increases to make this even feasible but I think it might be possible so binary tree is the first thing why is binary tree more efficient than the hex there you saw that the tree with the sixteen leaves and then these trees have sort of two leaves II okay why why is binary pack Surrey is then the other is nothing that little bit of the Hat yes so there so for for purpose I'm sorry interrupting for four four levels here you need one - two - three - four hashes for the hex there you need 15 hashes so four versus 15 you have a 4x improvement in the call data size freezing binary so I think binary tree are a good option I think that's the best we can do okay so what does the tree look like so there's a paper in 1990 captain Jana and mech and then they defined two children pattern sequence so on each note there's a label 1 1 means it has left and right child 1 0 means it only has a left child and there's no right child I interpreted that as no right child as being being a hash so there's a whole you know sub tree each one of these hashes is just a whole big subtree down to it you know depth 22 or 30 or whatever so that's we don't need that in the witness this is what the witness looks like and so the 0 1 means that there's a hash no empty left child so there's a hash and there is a right child so 0 & 1 you know the first thing is a 0 if it's a hash or 1 if it's not a catch the right part is a 1 if it's if it's not a hash at 0 so this one has two but left the right shot so it's one one so it sort of makes sense the one means that there's something there and the zero means that there's a hash thing so that's the that's the note labels are the tree structure that enclose it and that's so small it's like it's less than 1% then we we don't need these agile labels because they're already given to us and this is sort of building down to this address which is the dress of care of this accounts and the leaf comes where these is zero zero one zero zero dot dot one and then we have an edge label here with the rest of the address and there's an ellipses that didn't render it here so we have to pass call data with no labels which is so tiny agile Able's which is still small account data which can be arbitrary you can have balance announce whatever no kidding you own whatever and then hashes and these hashes are h1 h2 all these caches these dominate these aren't like 80% and then if you do happen to have signatures or transactions then that's kind of big to the count data you know when you might need balance of nan says well the trees the good news of the tree structure we can get less than 1% and there's there's interactions between these and another thing is that these duplication so the binary is the big thing the deduplication I found that 20% least savings so we don't have to you know certain caches if we just had one account you have to pass all the hashes down but we can recompute hashes so so we can compute this hash or in this hash so we don't have to search we save with deduplication we save about 20% for significant size of that so that's what I found with my with my batch works so this is a big improvement the binary is a big improvement so the run time it will sneak about now same thing for million accounts 40 accounts and witness 20 milliseconds to so do it but it's mostly happy and we can improve hashing as well so I think we can improve this run time so we're going to be dominated this is just other vertical ization not to speak of signature verification and that's the other bottom like we can improve that too so I guess the ball might be 800 milliseconds for her have to so the DAP developers have hope here that that this sort of tree stuff is going to be marginal trivial almost like 1% 1% we're approaching 0 that's the important thing this were dominated by things that can be improved so work is being done to improve that hashing speed group the transaction you know either the EC recover you know the sake curve or a 2 5 5 1 9 is another option which has some more targets so what was written here is that I do the primary wooden post group together so in one pass so I sort of merged the reversal and it's and it's made like that you saw because they call the ADA's past like that in that first pre order because that's how we traverse the tree so the the the way past the reason it's so fast at run time their interaction with puzzle all run today but they're both sort of we sort of read some sort of optimal point where you know we it's perfect for both this is a great configuration for both that trevor's you know it's like outcodes it's like that it's similar to that model but I call them no labels and that app codes and then the traversal is just a recursive call here and then later on once we return the hash to here we do a recursive call here or if this was a happy to just grab the cash and we know what to do here because we have the one one so we know two recursive recursive left and right but if those a 1-0 lead recurse left and then when that returns we just grab the hashing than we catch up there's a bunch of other options I'm using C so I'm using pointers I'm creating a stack as I Trevor so I'm putting that the roots of the hash that I returned here exactly where I'm going to hash here and then the hash I returned here exactly where I needed to hash here so there's minimize amount of copies all these little things these microcontroller people is about it some people know these stuff these sort of tricks where you sort of minimize mem copy all these things are important know without - because speed they weren't desperate for you know run time and we're desperate for call data so everything has to be perfect for the dab developers so I pretty much called a traversal order merkel ice-free wood in the same way mem copy so I mentioned that stack there are a few other things I'm not I'm just giving you a high-level overview there are details that well this is like look easy part but there are some details that I spent a lot of time on so I already have it says next here adaptive hatchling so why 256-bit is is that a requirement for everybody nobody's broken hundreds a lot of hundred six I don't think that I need significant you know good hundred sixty bit caches with a broken and let's say it is broken I'll save link to these 160-bit hash is broken but if we have adapted but that detached is where we remark lies with you know hundred seventy six bit you know if you submit a proof of collision then we can you know reverb lies on chain and then we can bill for another ten years so that only proof things alive by thirty you know 32 bytes versus twenty bytes that's like that what like you know thirty three percent improvement in the call data so all these things you know this thirty percent that's twenty percent of all this stuff adds up another one is caching breast who there's a proposal to store it alexey taught us he had some blog post that if you passed the recent you cache so you maintain the recent hashes that were used and you can sort of reuse those and you know it'll save as well as little it'll increase you know there'll be a worst case scenario but if if the cash has a lot of fascism they were used a lot then we'll have you know this will change there'll be a lot more cities remaining transactions and what else did I want to say they inserted two leaders written it's writing the test generation isn't ready yet so how does insert and remove happen what we we find the neighbors we find this let's say I want to insert a neighbor to this one which whose address is zero zero one zero zero Levitt that one one zero one one zero definite that one zero that's this this sort of cut soft place is growing so it's the full thing yeah that's the whole thing so we instantiate a tree as you know pointers to the children but we know we pass this call data to solve done already I just beat us Confederation that we instantiate them note here and then we have left pointer to the hash white pointer to this and then we insert by you know taking the right pointers we you know this this tree structure we have pointers about the right mouth we we do some bit twiddling to change the snow label or whatever and we insert the node so it's and then when we merkel eyes we do we sort of merkel eyes this subtree that's actually instantiated where we you know the sachet children pointers of children but that's going to be I think it's gonna be on like you can insert a few notes or like a I think for a theorem it's an average they've inserted per block eight accounts an average but maybe sometimes more sometimes less so I think it's gonna be trivial just just because we're doing a little bit of you know of the parent of the glass child update you know insert new internal know things like this but it soon it's just going to be you know very close it's just gonna be like a few things we call this sort of business logic this sort of fast stuff but it's still gonna be dominated by hashing I believe and then the speed-up hashing bottleneck and then speed up transaction so I think there's hope that's what I want say that there's hope for this model the other big thing about huge thing is this 25 kilobytes they're gonna they're talking about way more this you proposal I saw for 64 shards they're talking about increasing called data by a lot I'm like you know 128 or even there's some 512 512 you know half a megabyte so this is huge and then this this sort of deduplication is going to be weight is going to help us by it's not going to be only 20% because there's gonna be so many more accounts so this is gonna help sup you know every cycle is important that were you you know bite of call data is important that's like and then you know see the programmers hi I'm writing emails and contracts and see so that's it time for questions are introduced in the US yes sir I was a little confused with what you're beginning exactly yes so if you have one child you can you have to pass all the witness all the hashes of a you know neighbors neighbor neighbor neighbor neighbor all the way done but you don't have to do that because you recompute sometimes you could you can recompute the so you don't have to pass it'll be recomputed on chin anyways so you have to you have to recompute enough this this site anyway so then you don't pass certain hashes at the very very close to the root you you don't have stashes because they're gonna be computed anyway you mean essentially before yes it's yes I should have just used the word multi-purpose but maybe some people don't like that word since you're calling it called it sighs you're imagining that these come equipped with every transaction and then when they gets bunched together in a block you do this do occasional construction up but then you get the final great question cool does this you know it's merging of these multi proofs in there into one yes it could be done we need a key role that writer who will write this merging and this best practices maybe not maybe it'll be similar to this maybe it won't be somewhere but I don't know how much better you're going to get with me if we're down needed by actions that maybe might have just but hopefully there will be some hero that invents an EE and with all this you know merging and the perfect tree and the perfect everything so yes I don't know but I mean an alternative is that you let the business yes we don't have a by that I mean though there will be some black producer some relay or infrastructure or whatever some V market infrastructure to handle all this stuff I it's a big question but it's unobtainium but the great thing about f2 is that you know crypto kitties or whoever can launch and some there will be some hero that will invent relayer than you and it's not going to be you know you have to do it this way because the theory and foundation set so it's going to be you know you know do it however you want please teach us because I think that it was basically that they have that use some trusses approved yes the cold air is enough wanting right now which you sang some string of bytes that you have passed and then to play the very bigger to learn by the state oh yes yes so currently the call data doesn't need this proof the call data is just I want to send it I want to send them my transaction to this or - uh Micra took Katie to this person but with with f2 with statelessness they have to also in their call data past this whole tree structure these edge labels these accounts these hashes so the call data is going to be much much huger so in an alternative environment the beta matrix ever called yes yes but the E's will already have the smart contracts will already exist unchanged but let's say you want to have some extra bytecode for some custom thing to send your crypto Kitty that it'll you know you'll have an interpreter on chain or something that yesterday passed whatever you want it's you do whatever you want like all data you just pass them and invent something amazing like some crypto de 2.0 or something and then I've got a little get there will be another bubble I'm never gonna get rich I'll retire we have time for another also an important opportunity the last box if it's specific to this talk very do if you'll have another like 10 minutes at 300 K will speak now oh okay you have to link to right okay hello my name is Jared washing her i'll just preface this that I am NOT an expert on zero knowledge proof or roll-up so if I say anything that is extremely inaccurate don't feel free feel free to correctly that being said sir yes there's a clicker oh cool so what is roll-up it leverages CPS night crews to batch transactions off chain and provide succinct ruse on chain like many quote unquote LT solutions there are operators and verifiers operators take transactions off chain and bash them into proofs which are then submitted on chain and verified so zero knowledge proof our constant sized verified in constant time assuming the yes verifying constant time for a given circuit and for roll-up this means that groups can be verified regardless of the number of transactions that are matched right and so scalability is mainly constrained by the on the proving side and yeah so I think we've had a few existing roll-up systems that have been advertised to provide like somewhat in the order of one to two magnitudes of transaction through put on the EVM today right so why this role of an interesting application for you two well the data availability requirements are somewhat lower than say the other on chain like if we're talking about verifying multi proof some change well this is a this is similar to what is happening with rola but the data ability veil ability requirement starting to be lower with rollers there are no exit games lock-up periods basically your funds can only be spent if you if that operator can only spend your funds if they have your private keys so we've been using a web snark which uh I think jority this is your tool thank you so written written in and we've been able to generate it wasn't generated from handwritten text format but right so if we look up look at some benchmarks we can actually see that if you look on the Left Russ native and this is for a two point peri check Russ native is actually very comparable to an interpreter assuming that we shim in debating on big number of operations as natively as host functions and okay so I'll just go from left to right Russ native four point two milliseconds Bobbitt five point seven milliseconds v8 turbo fan seven point five milliseconds v8 lift up and these are compilers here he is is going to be 12 milliseconds and then if we look at eater pra's vomit shoots up to two hundred thirty six milliseconds and v8 is at 733 right so I mean kind of the point of this talk and I don't have numbers currently we're able to generate the charts in time but I can I'll just have you take my word that Russ compiled laws in general is a lot slower than these optimized handwritten wazzle binaries and so it kind of illustrates a point that perhaps e development is going to need specialized in the sense that DAP developers the set of tool sets for the the set of skill sets for GAF developers versus EE developers is going to be akin to protocol developers versus not protocol developers and it's gonna require perhaps a specialized skill set in both maybe cryptography and understanding of what assembly but to really squeeze as much juice out of these execution environment execution engines as possible to get the performance that we want that we want a need for e to so we got that um that's my talk thanks for coming and I think I'm gonna hand it off to will and while I'm studying I'm talking about the session tomorrow and I'll dive into a quick 10 minute demo and explain what we're trying to do by simulating crush our behaviors already which we kind of circle back around the nature attack real quick I just wanted to mention these two sessions tomorrow the kiss you guys expertise so in the morning at 9:10 mp8 justice two hours long tinted window fix one and two the developer experience I think it's gonna be a real good session so if you are interested in ease and how does the network you should show up there's an every woman as 12 v8 so it's just forests felt even hour-long medieval execution anyway so basically it's gonna be kind of a flexible panel about the work which was showcase here and it's but also consist of each other find the other person and some researchers so it's gonna be a place to ask questions and discuss this more in depth so will please go ahead cool also yeah I'll be giving a quick 10 minute overview ovaries well okay so um so I think like just to summarize everything we've seen it tied into this I mean what we're seeing from early perspective is that you know we can build these V's in a stateless way that's performing enough 3/2 that's that's pretty cool and so what we talked about earlier is as you know now now that we have begun to fill it off' i that we've new things to to validate and so that would be different models around crushed our transactions and also different models around the fee market and the real a market you know someone has to be responsible for setting up these multi proofs refreshing the multi proves every block as well and you know so we want to be able to make tests grounds by which we can you know we can show all of that so that's the goal of work behind this so in general the purpose is want to be able to simulate the system at the end on begin building simulations around the the fee market and relay network as well and we want to have you know you can reckon and you can you know communicate across jars now so that's the goal here and you know the system you know should also have core tenants you know this chart should be for King house ability that should be configurable so you can also deal with real Ericsson you know respond accordingly so in this the validators are simulated using local keys so it's not like there's an entry into the test mess it's not like you're gonna run here don't know that can enter into it this is again more of a testament that is set up and optimized for YouTube right and around that makes multiple shards and shows beacon chain that's running and that is interacting with these chart changes also what will be really cool and what I'd like to have by January is real-time deployments of these so having having this running and you know you as a developer you being able to write Nene and deploy that with the click then being able to see how you know how you can interact with that in and the simulation was a whole so what is it so we're not dealing with networking so we're not trying to benchmark any other networking side of things you know it's all simulated so you can't you know start it out and connect to this this network we're not trying to go any type of production client that's not our goal at all so again we just start trying to validate all these things and let people have an early early foray into this world so you know the system should be configurable we should say how many shards are running you know you should set the fourth ability parameters you know one of the thing the taller you know has given three different you know proposals over the last over the last couple months and I think you know some of these new proposals are really awesome like they all have trade-offs and there's there's some really cool things and so if we're able to just test this pretty quickly to make changes that that becomes that becomes really viable so that's that's kind of the goal of this and what we're building and we have a basic functioning system right now and so I'll talk about that to show you real quick and then talk about the vision behind that again it provides endpoints interactive block producer you could get the historical data and say these would be like what you would have this normal RPC endpoints one of the things is this is right now if orchid lighthouse and what we did is we use the beacon chain that lighthouse has and I broke a char chain and then the char chain interacts with weakened chain and it's right now it's running one star shape it's I think after DEFCON I'm gonna expand it to build a run you know four or five and it's fairly trivial I just didn't you know want to break a bunch of stuff before coming here so that that will be working and that's that's pretty cool so I'll just kind of show you I showed this demo briefly in my talk on the first day but in this case what I will first do just clear the screen here I'm gonna start the demo so the first thing that we're doing is were fast-forwarding the beacon Deacon shape and we're bringing it to the phase one fork epics the phase one fork epoch is basically the beacon change would be running alone without the charts once you rigid or fork epic than the starts are gonna start so now we see that the shards are ready and we're simulating three second chart blocks and six second beacon blocks and so in a second you're going to see that there will be a cross link cross links that are sent over to the beacon chain finality is established and ultimately that proves the poor choice rule for the shire chain as well on this end I'm about to start a client called wool it's part of what Matt was talking about this she shard ether and this is not only an eat but it also is the binary that lets you basically go to the proofs that were talking about so this could be considered an early relayer or an early state provider so T's its own vision of state locally and it generates the multiple centers or transactions to establish transfers and imbalances so here we go okay because I just do please transfer this is actually creating a new basically wanted proof of this transaction has been submitted to the block producer I'm a star chain right now so transfer happened and so you'll see that a new state group is now available for that execution environments that operated there and I'm going to show just a little bit of code in a moment and we can you know look at the balance now as well see that that's was updated so that's really cool so the goal is really now you know all these E's that are being build we can start plugging into this and we want to kind of change this to where it's no longer just a forked plate house but we want to actually just pull them to scalp and have this be just an additional tool set scalp lever let's you mimic this whole system and you know we don't we don't need the networking side of things we can you know fairly simplify a decent amount so all right here you'll see this is the code so there's a lot of work lots of cleanup needed lots of things that need to be added but again the system is working end to end and what's what's cool is that the the hardest thing is not writing state-transition wasn't actually including the including skeleton runtime the hardest part of all is excuse me the hardest part of all this was just getting everything before choice all of the the vs and store everything like that to all all proximate ended and so anyways this this should ultimately have to clean up to be pulled into a discount or initially maybe into the lighthouse areevo the actually plugging in scalp and a runtime into the node was actually surprisingly simple and that's that's really cool and so this is really good for that client developers in this case oh we really have is in the state transition for a process shark walk bunny wickedest instantiate a runtime right now we're passing the block body again this is an early prototype this who really just accessed the beacon state and a shard state and then you have functions other than Eric that that can interact at that so this is a fairly simple again this will need to be expanded to where you can do interactive deployments of annuities and some of the logic gotcha yes that's that's something that I'm gonna start doing after the DEF CON actually so I want to start so quote has grown we have a really awesome team of really awesome and engineers and so I am going to probably start migrating to myself I'll start working on building simulations that will plug into this from the state provide the network and the relay network so I'm gonna start doing some early research on that since we really need to validate that as far as what you were saying the token economy and pain a block producer so again it depends on which proposal we go with so the tall cuz if you want that kind of enshrines into the charts if we go in that direction this makes my work a lot easier and I'm actually fairly excited about that one but again each proposal has pros a trade off so it's also like what do developers you know in this ecosystem want and I think we'll probably dive into the people into some of the meter that tomorrow in these sessions as well I don't know if that that like answered your question but in in in this system where sharp either as march right it becomes more of a system of just stay providers how do you pay some ones that provide state if ether is less enshrined if you need a whole system it becomes a little bit more complex because the block producers need to basically need to have some level of trust with the real layers and and there's some complexity there where is it in this new model that he's proposed they don't they don't and and so yeah it's a higher level overview without studying ten minutes talking about it yeah because it's like but flooring questions though because this talking is incentive also have changes a lot of behaviors of like state fighters and but a bit Ursuline and in such case maybe the sooner they forget how to we can explain those they call me their solutions yeah that's the goal and then have it have it be have some actual does not well-defined right it's not well-defined yeah yeah and so I think we need we need just you know a little time first to figure out what people so we're gonna go with and maybe some of the some of the direction of the research that you know or dive into it and also John Adler is going to be diving into as well John raise their hands yeah regarding this thing you know can also help fuel that direction yeah is anyone interested in giving markets new markets like getting involved in that area if you are like to free today take your hand up yeah okay awesome cool let's talk yeah let's see any other questions yes something allowed here but is it feasible in a way that like say we can open up an area in the memory say this area is gonna be there for the sake of this entire block of transactions execution so that let's say when you do like stainless things like maybe they're public in sections technic stopping the same uni and then they are tied to construct a tree but then the previous transaction has already constructed a part of the tree and then the said the following one is constructed another part of the tree and those up because you know and there's apples are out of date in the same tree right then like then conflicting transactions in the same block can go together because you know the following one sees oh it's ready to update the someone constructed I'm just gonna use it instead of reconstruct approved kind of thing what's that like my deal with hustle state or cash flow State yeah that's yeah did you say epic caching API under consideration you guys did some tests with it yeah but can she gave me out and I think we we had some tests with it but such conclusive yet any other pending questions questions I think so [Applause] you 