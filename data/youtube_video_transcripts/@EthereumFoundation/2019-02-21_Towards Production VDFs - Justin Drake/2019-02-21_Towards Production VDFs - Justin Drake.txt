so so my goal is to try and bring PDFs to production so I guess the goal of today specifically is to try and tackle some of the open academic problems that we would like to make progress on before we actually build the vdf so the academics are not completely of the hook but I'm also going to talk about briefly the the progress that we have so far so one of the pretty amazing things when you look back is that VDS academically are only eight months old so there's these three papers that were all published coincidentally in the same month and before that we didn't really know how to do efficient vdf with an exponential speed-up in the verification time the upper pretty amazing thing is that we've had a lot of interest from various blockchain projects so roughly historic is speaking Chia and Solana with the first and then a theorem got interested Falcone in Tasos and then I made a talk at Def Con and now we have 12 different blocking projects that are interested in using PDFs so I hope we're not at the peak of the hype cycle and this is a actual interest and it will lead to utility we shall see one of the interesting things of VDS is that they can be used for many different things not not just randomness which is one of the more obvious applications but they can be used for prefer space proof of application for space-time so known as using them for proof of history we have some people here from injective protocol there's a decentralized exchange that wants to use them for anti front-running and you can also use them for fancy stuff like expiring zero knowledge proof so you you provide a zero knowledge proof to someone proving a statements and they won't be able to pass that proof to another person because it will have expired by that time and if you use time lock puzzles you can also make the zero knowledge part of the of the zero knowledge proof expire so you give someone a statement with some private data and then an hour later they can recover their private data and you can use them for everything so in terms of progress that we have made one of the big milestones is that we have a new startup called super national with Simon who's working full-time on on the vdf project management and this is funded fifty-fifty by protocol labs and different foundation so the video project is quite expensive and so we're looking to set up a more formal vdf alliance at the moment it's mostly protocol labs and different foundation but hopefully other people will join another big effort is the RSA NPC so we're looking to go down the route of RSA groups and for that we need an RSA NPC and we want it to be scalable to hundreds of participants so today we have the the hero team that will be presenting and we hope to also fund them to to design an NPC that can be used to generate a 2,000 bit RSA modulus and one of the nice things is that the modulus can be used for accumulated as well so this is a very nice piece of public good the other interesting thing is the circuit competition so we want to try and crowdsource the wisdom of the crowd in terms of designing really fast modular multiplication circuits we believe we can do one nanosecond modular squaring and we will also produce an open-source baseline but the question is can we can we do significantly faster than one nanosecond and I guess the competition will help and that question we have quite a bit of interest in terms of people who want to help out with the competition in terms of the EDA tools the cloud providers but also in terms of prospective competitors some of which are in this room so okay today okay academic vdf day we're going to try and tackle all the outstanding problems so we're gonna have three themes vdf provers modular multipliers and RSA NPC for each theme there will be a kind of a feature talk and then in the afternoon we'll have breakout sessions to solve the problems so this is the the rough agenda in the morning we have the talks then lunch afternoon sessions and then debrief with all the solutions to the problems at 4:30 and then optional dinner okay so theme one vdf provers so you know eight months ago we had these two pure vdf proofing schemes and by pure I mean is just one simple idea and the two constructions are by whistle our ski and piet√† Zach and the nice thing is that you can take these these pure vdf schemes and you can start billing hybrids so a few a few months well actually during last vdf day that's that's when we discussed the iterated whistle our ski which gives it a different trade-off between the previous so the whistle our ski prover has very short proofs but it takes more time to generate them and on the other extreme you have the kids lack prover which has much larger proofs but they're very fast generate and I guess we're looking to explore the the trade-off space a bit more and today Benjamin will also present another hybrid which is the Cheetahs a crystal a ski hardwood and so one one of the open questions is can you come up with a new you're building block that would be fantastic and then maybe we could try and combine them with the other pure building blocks to build more hybrids or you know can you build a new way of combining the existing ideas to have a new set of trade-offs so one of the the goals for the vdf ASIC is to try and and be relevant to as many applications as possible we won't have many shots at building in a second so we would like to be relevant to many different blockchain projects and use cases and so I guess this this would be some of the ideal properties of the prover that we want with one the proof size to be less than one kilobyte verification less than ten milliseconds and we want the approval latency which is the the amount of extra time you need to build the proof after you've done the evaluation to be less than than 1% so let me just briefly give you an architecture diagram of a possible candidate for for the ASIC at the vdf ASIC so that you can you can get a little bit of flavor so we have this squarer which is going to be the repeated square the evaluator and it will all run roughly at at 1 gigahertz and the the way that the proved is a build is that they they collect checkpoints along the way and these checkpoints you have the option to store them in memory so we have we have this this memory a relatively small amount of memory maybe one megabyte or a few megabytes and with these checkpoints you want to build the proof and generally the the proof involves something other than the squarer you need to be able to multiply whether two inputs are are different and so you're going to have a performance penalty on the multiplier let's say that the motive is half half the speed and because the circuits tend to be quite large it's possible that we can only have one single multiplier for the prover and then we're looking to have an arm core in the in the the vdf ASIC so the nice thing here is that you'll be able to program the Armco and and choose the previous scheme that you that you want and the specific algorithm to to do the proving so if in the future we find better algorithms we'll be able to make use of that yeah yeah right wrist five would make more sense yes absolutely all I did and and then you know we have a few connecting bits between between the arm and um over between the CPU and and the multiplier and you know one more subtle consideration when you're looking at approvers is that you want to have enough parallelism in the algorithm so that you can feed the input FIFO fast enough to make full use of the multiplier right so I guess in my mind the parameters were about a hundred minutes of evaluation time but you're right if you want to go to one week then you might need to to move to a different proof of scheme which does not require as much memory so you might move to the PSX game for example right I guess here yeah 100 minutes evaluation time is one of the extra lines but I guess again we want to push that as far as possible just because we want it to be you know if what someone wants to make value evaluations of one week we want them to be able to do that because every megabyte increases the cost of the hardware and so basically the the SRAM takes up more area and and that means that you have to tape so in the theorem specifically if the evaluation time is a hundred minutes we we don't want to random number every hundred minutes we want a random number every let's say ten minutes so what we do is that we have ten randomness beacon in parallel and each rig has ten a six and so you have it does start becoming expensive if the chips are very big right so but then you might be limited on on the PAL ISM of your algorithm so you know if your memory is outside of the ASIC it might take quite a bit of time to go fetched what you need to fill to fill the the FIFO and then you'll end up with a multiplier being idle most of the time yeah the latency yes yes okay but I mean we need to yeah we need to look at the details of the approvers but caching might not be a good strategy because it might be completely random access on the very on the full memory yeah so the the point that was be yeah the point that was being made is that with VDS you have this really nice property of uniqueness so if you have a unique input you also have a unique output and so what that means from a practical standpoint when you design the protocols is that you have a minimal honesty assumption or minimal liveness assumption you just need one single person in the whole world to be doing this calculation which is one of the reasons why doing randomness where vdf s-- is way more energy efficient than doing randomness with proof-of-work so the this the second theme is modular multipliers so we're going to have a talk which will present kind of a new way to do modular multiplication which is especially low latency with as I understand new mathematics and so one of the problems will be can you take these new ideas and and improve upon them another interesting question is can we have can we prove lower bounds on the second depth of the basic operation which is the modular squaring it turns out if you if you have a model such as the the two input gate model then you can really trivially prove the second death lower bound of 12 and the reason is that you have the 2,000 bits for your input that you're squaring 2,000 bits for the modular so that's 4,000 bits and if you only have two input gates the fastest way to mix in all the all the signals is using this binary tree which will have depth 12 and every single input bit can influence the most significant bit of the result of the square and so hence you have this load of 12 and the question is can you improve upon that one one of the good news is that the this this lower bound of 12 is actually not too far away from what we can do in practice but it would be nice to squeeze that as much as possible and the the third theme is going to be the the rsam PC so here we only know of a single team who has confidence that they can satisfy the various requirements and so one of the goals of today is to actually go through every requirement and and check that they are satisfied so number one we want it to be n minus 1 maliciously secured so if even let's take this question of line the the second requirement is that it be scalable so of course we only know if it's scalable once we implement it but is it at least plausibly scalable they can scale to 2,000 per second so I think a thousand 24 would be I think that's more of a goal I think there will be less than a thousand 24 people in the whole world who even want to participate so that gives an opportunity for everyone who doesn't want to participate to indeed participate but even so I just as as a test I advertised your participation in the NPC on the telegram channel with 150 150 people I think all of which are you know hardcore blocking people and no one responded [Laughter] yes right so the point is being brought up is that the actual specific dynamics of the NPC will influence how many people participate for us we have a synchronous NPC which means that everyone is to be online at the same point in time the the goal in terms of scalability is that we won the whole NPC to last ten minutes or less so yeah it will be interesting to try and get hundreds of people online at the same time its timeslot so the the Z cache a sapling has 88 participants I believe the question was how many participants are required as a lower bound I'd say having at least a hundred would be very nice anything more than that is is I guess gravy defeating stables so one way is to put your reputation at stake so if you look at the the sapling ceremony I think almost everyone maybe one or two exceptions was known people from the community another idea is if you want to participate anonymously you could put down some collateral the I guess this is where the the third point comes in so the the work that you can do is then you can participate in the NPC and then halfway through just a boat and so everyone has to restart and so having the the possibility to at least identify their boats is is a key property that we need [Music] right so putting something at stake your reputation or either money would a general RSA public key yeah right so the question was do we want to generate like a normal RSA modulus or strong one and having a strong one would be better because it has all these additional properties but from what I understand the MPC also becomes much more complicated and expensive if we could have a strong one okay then we so my understanding is that for the two main use cases that we're looking into RSA accumulators and RSA PDFs a plain RSA modulus works is that correct okay okay yeah so you can relax your something okay and tomorrow if if you're interested we're having a more non-academic more practical vdf day so we're trying to figure out some of the logistical issues of pulling this this crazy project and one of them will be in the morning the RSA ceremony logistics so you know discussing the sibyl's and how do we get enough people and how do you make sure that they descend decentralized enough etc etc and then in the afternoon we're going to have a session on the logistics of the circuit competition and there will have several talks one from Chia that just completed vdf competition will have Simon from supranational discuss some of the plans that we have for our circuit competition and we'll have a representative from synopsis that's one of the main tool vendors talk about their tools and how they could be used with competition and they have a open source a Bitcoin mining implementation that they will present and so yeah that's it happy problem-solving 