like that welcome to the day three of whatever so good morning and welcome to the third day of the a theorem one point X meeting I'm going to start with the presentation a quick presentation about what has been named the state of he wasn't but it's really the state of it was a with respect to actually merging it into guests in the foreseeable future so the current well what we have with it wisdom we have a full-fledged implementation it's available in several pairs should have change slides why is that not happening okay so we have we have the P are called the evm see we have a reference implementation called Hira that uses a binary and as as a back-end engine and there's there's a go version of that of that implementation the full-fledged implementation and that's that's using wagon so wagon is is the least performance interpreter that we have so far but it's also written in go so it's pretty practical for for testing and yeah we we have we have a test net running so that's well I I encourage you to go and visit it because we it doesn't receive a lot of visits so if you want to learn about the wisdom if you want to play with it you can and if you have some feedback where we're really interested in that when it comes to even one point X however we're we're having a more I mean as most of you know we are having a more constrained version which is to use to use the weatherman gene as implementation for free compiles and there's also a PR for that and I mean I'm in the process so I started working on it like two weeks ago one week ago so it passed the unit tests and right now I'm using rinkeby like I'm sinking rinkeby to test try to find out all the problems so I managed to to to sink up to 25% of rinkeby and it's not because it's not sinking properly or there are errors it's simply because I haven't been able to get a stable connections with all the ports available in the in the last few days but it's working it's working well there's there's a bit of a problem on the sha-256 precompiled but apart from that everything is fairly it's very functional it's just I mean it's just a matter of finding the errors yeah yeah you know okay so just to clarify so what you're trying to what you're doing is that you take in the pre compiles that already existed yet your implement re-implemented them and we was a man running him he wasn't rather than running it natively exactly so there's there's there's repository in the it was an organization that's called it was an precompiled and they are reimplementation and some of them are fairly optimized all of them are written in rust so it has some disadvantages because the binaries tend to be a bit big but apart from that they're pretty functional and and yes we yeah we were implemented everything and we're just comparing it's just about finding finding challenges and errors yes sir it doesn't have to be in rust right it does not have to be in rust in fact I think for for something like pre compiles it would be much better to have something very lightweight like like C or even a direct assembly but yeah rust has some nice features like it's really a development tool consideration so I have a pre benchmark that's going to get some some people to cringe as you can see you can actually or as you can not see or barely see you have the native implementation in yellow and purple you've got the rest was some equivalent it's really taking much longer by the way I have five working contracts right now and there's only three there for two reasons v 1x mod is not used that much on rinkeby so I don't have enough data and the other one is recover the first one is actually dwarfing the other the other pre-compile so I could include it here but it's basically it's basically the same phenomenon it's it's much longer so there are several reasons for that and that i will cover in the next line I just want to point out that even though it's not properly displayed it's it's in microseconds so it's not even though it's way longer it's it's still very fast for further for humans and I think yeah I think that was it so yeah you have you see that that benchmark but please don't panic there are several considerations the first one is that we're not going to I mean we had a conversation like I mentioned by frederik yesterday or two days ago about we're not going to replace like very critical path pre compiles we're just going to add the interpreter on this side to be able to to add functionalities but when it comes to something like easy recover that is used very often I think the native it doesn't make sense to replace especially with an interpreter based precompile so yeah what's yes sir times come from yes so where do the two hundred two hundred times PDF come from there I mean once again it's not it's not optimized at all so where where does it come from well first there's the actual execution and having an instruction you you go through the interpreter so you have to do all the like for each operation you do you do loops you do you know memory accesses and things like that what else yes there's a lot of data copy because of the API we are using right now which needs to be thought through in my in my opinion yes far as I can tell these are the two sources I want to look at and once again the interpreter is definitely not the most performant way we have yeah okay so precisely the next step is is to optimize that's to get more data I mean like the current step is about finding what the issues are going to be so we're finding some issues and and then it's about trying to provide to get to squeeze some performance out of this so we want to try the GI T we want you to see if we can maybe use a different language because rust rust might not provide the most the fastest I mean that's what we were saying with with the C might not be the best the fastest language for this case for this use case all right and so the the second part of this of this presentation is addressing Alec size request to to say like to see it wasn't as as a meet a proposal and say what what a proposal should have so I'm reusing most of what has been said but adding throwing it a little a few things in so the metering method that has been discussed I'm not gonna cover that I mean there will be a talk by Paul later but that's definitely something that needs to be covered in it wasn't proposed proposal there's how do you how do you link like so far I was saying it's it's a bit slow because you have a lot of data copy it's the way we pass we're using the way we pass the the data we really need to investigate or at least any any proposal we'll have to suggest how the data gets passed from one from the from the the blockchain or the blockchain environment to the execution environment what else yes so a very nice conversation with with Brooke yesterday hi about about the migration path this is something that we I mean you know we I'm also part of the gues team so it's it's about not just jumping the gun and and pushing something some interpreter and and hoping crossing your fingers to make sure everything like hoping everything is going to work you have to be sure so yeah any proposal needs to needs to cover that and that definitely needs to be in in the requirements right so that's what I'm doing if if you have a proposal you definitely need to to be able to replay or at least prove based on historical data that it would have performed or given the same results as as what the EVM or sorry the native code and the native sorry native code did and yeah so Robert here proposed two days ago to for example when you have a redundancy option like like space like rockets or space rockets or or planes do so instead of running a single a single version of the interpreter at first why not try to run several several several interpreter several clients and make sure that the result is is completely consistent and the last slide is about data that a proposal should include is a list of pre-compile so I think the USM team wants to pretty much introduce what Blake - I'm trying to remember Blake - and is there another one some sub snark some snark contracts but that's still still debated on our end and yes on the personal level like I really find it really hard to to work with you know I mean not really hard but it's it's sometime not very practical to work with the tools we currently have and that's also the the interest of switching to wisdom it's about grabbing grabbing like tools from a different community that tends to be some of the wasn't people come from the C++ world so C++ has a excellent an excellent tradition of tooling so getting that getting that on board would be a would be very nice and I think a proposal should should definitely list and explore that and yeah I think that was it yep so if you have questions I know so in your slide about Hera evm see does that mean that it was am is implemented in there as well or is it based on Hera or is it I don't so there's an Arab based version of Aviva's um yes and there's a wagon based version is the the one which is based on here is it written by your team or is it was it like a third party is it written by you team yeah absolutely okay so people know here is the intermediate layer between the client and the Waze imagine the Waze imagine is written by third parties the intermediate layer glue code is written by us right anybody else questions thank you very much I guess you can only go up from there right from from those numbers it can only go it really go down absolutely oh sorry one thing that might not have been clear yesterday we expect it to shrink quite a lot there's really no optimization there okay cool thank you everyone my name is Amir and I'm with zero X and I wanted to talk about a little bit about date rent from the perspective of a smart contract developer with the specific focus on lock ups and why I think the current proposal doesn't really work for most smart contracts so in an ideal scenario every single time someone locked up ether for a storage slot that same address would be able to recover that ether when that storage slot is released practically this isn't very feasible because it would require an extra mapping of storage slot to use our address and this would end up doubling the storage size the current proposal attempts to solve this by simplifying things a little bit and just maintaining a counter of lock ups per contract so just a quick recap of the current proposal this might be slightly simplified every contract every contract has a storage size and a a lock up counter whenever someone modifies storage if the current lock ups are less than the storage size then they will have to pay a lock-up fee and increment that counter or whenever someone releases storage if the lock ups are less than the storage size then they would release that lock up and the lock up fee is always transferred to and from TX origin so this is meant to provide pretty much full backwards compatibility for older smart contracts so we can imagine crypto kitties which you know currently is using a lot of storage size but has no lock ups so every single time someone trance there's a kitty they would have to pay a lock-up and increment that counter until the lockups actually matched the storage size and this this also means that any new contracts post fork would always have a lock-up equivalent to the storage size and they would never have to actually pay rent to on storage because the storage rent essentially will you're only paying storage on on storage slots that do not have a corresponding lockup so before I explain why this breaks things I want to talk about a extremely common smart contract pattern this is the approve and call pattern so any any contract that interacts with tokens typically uses this so a user will first approve the smart contract to transfer funds on their behalf and then that smart contract will execute some logic and can transfer the users tokens under whatever arbitrary conditions are defined in that smart contract so what this means is that there is frequently a mismatch between the account that tokens are being transferred from and the actual caller or the TX dot origin of the transaction and what this pattern allows you to do is like place intent to transfer your tokens at some later time and that can later be executed by someone else by calling your smart contract so a quick example to explain what I mean so let's look at a decentralized exchange so we have Alice who hold 0 die and 10 wrap ether we just think of wrap either as as ether but it's like the ERC 20 equivalent and then we have Bob who has a balance of both of these things so when Alice purchases died she will be paying a lock-up fee because she now has a divalent and that's using an extra storage slot that was not there before now let's say she wants to sell this die back so she places an order to sell the die and Bob comes in and fills that order and now this will you know completely get rid of Alice's die balance and release a storage slot and release a lot up to Bob so even though Alice originally placed the lock up Bob is now receiving the release of that lock up so this drastically changes the economics of the trades now there's a much larger incentive to only fill orders rather than placing orders and it's also susceptible to front running and race conditions so let's say Bob attempts to fill Alice's order and Alice decides to front run that by transferring more dye into her account and transferring all the wrap ether out of her account now Bob actually ends up paying a lock-up fee rather than releasing the fee so my proposal is to fix this rather than making lockups a mandatory part of every transaction that modifies storage we should just create op codes for locking up and releasing ether and now smart contracts can determine their own rules around how fees are locked up and released this is less backwards compatible because if we take the crypto cookies example from before you know now transferring the crypto kitty would not actually change any lock ups you would have to write some sort of a wrapper smart contract that would do that for you but it's much more flexible and smart contract developers can actually change the economics of how things work to their favor these op codes are pretty simple they would both just take a to address the law lock up opcode would always transfer ether from the the caller of that opcode and and the release opcode would would transfer either from the caller as well and now lock up fees would be included in the value of a transaction rather than well I guess it hasn't been fully defined in the current proposal where it's coming from exactly just some discussion points you know given that this proposal is less backwards compatible and kind of thinking about REM pose presentation yesterday I think we just have to basically define the types of things that we are willing to break and the types of things that we are not you know by introducing these things as opcodes we're breaking a lot of old contracts essentially the previous proposal provides a migration path for those contracts and is technically backwards compatible but practically I think that proposal breaks those contracts anyways they're not going to be economically feasible with their current structure anyways and and the contracts that are using a lot of storage are going to have to redeploy with new role new rules either way yeah and in my opinion breaking old contracts is much better than breaking an entire class of current smart contracts and that's all I have apologize for the rough presentation just put together in the last 15 minutes any questions can you go back one slide back what did you mean with more flexible the second point so contracts could like for example decide not to use any lock ups and just pay storage right now or they could you know choose to to force people to like deposit ether which would later be be used for storage slots that are relevant to that account things like that they can basically just define how lock ups are actually included and released it first of all thank you very much for putting this together really good so one thing I would note is that in I think was the second slide or first slide where you were talking about release I think it was a bit of a inaccuracy there no there before that so yes so when you said the storage slot cleared actually when according to the current proposal if the lockups less than storage size then there's no release at all so the release only happens when the contract is full over and so that means that for some time if it's a pre-existing contract and it's really large for sometimes there will be no releases at all and my other comment is that so if you you probably know that the first ever proposal for the statement was nolo cops right and the main criticism there was that well what is gonna happen to the existing contracts because it's really hard for them to migrate so the law cops essentially is the feature that wouldn't have been there if we were creating the statement from the scratch so without a the legacy contracts so it's simply there to to provide the migration path so yes I agree that it's sort of a bit weird and since this is actually the AVI who first we talked about it with avi who here when I started to think about this idea and I had exactly the same kind of criticism that you have to the lockups where essentially it's tricky to to figure out who is going to contribute a lock-up and who's gonna get it back and things like this and also I thought like if you're if you're about to withdraw tokens from an exchange like the tote the exchange now have to pay lockup from for you because you didn't have any tokens and then now to talk and address and yes so maybe I thought what the exchange is gonna do is it gonna pay you the lookups for everybody or maybe it will start requiring people to have nonzero account before you can withdraw things yes so there's a lots of these things and thank you for start thinking about those I just didn't really have time to list all this issues regarding if you if you scroll back to your up codes I remember you asked me this question on the first day yeah about this yeah I remember that so these things are so my question here to clarify so the lock-up up code when you say to address is this address of the contract so this would mean that you could like arbitrarily deposit lockups into any contract so my question is that who has the authority to release that lookup to themselves so when you do lookup essentially if you imagine what the effect is is that in that to address a contract there's another data that needs to it needs to remember who placed that lookup in there so when you do release lookup so you can't simply just sweep somebody else's lookups from there so there's some to be some to be permission mechanism there right yeah so a smart contract would define how there was who's allowed to call lock up and release essentially and this is actually to me this is sort of almost equivalent to having a storage items remembering who looked them who put the lookup in there well there's there's no requirement to do that like you could have the lock ups work in roughly the same way right a contract would just call this this lock up function to itself every single time a storage law is modified yes so what I mean is that it's so the previously you said that the reason why it's impractical to remember where the lock up came from because it will inflate the storage right but what I'm saying is that it's also the storage will also be increased maybe not as much in only in adversarial settings with the lock up because it does have to remember where the lock-up came from it's kind of the similar the similar consideration I don't think it has to remember what about if a lot of people for a place to look up and to the contract and that and now I go and do release lock up to that contract to sweep their lookups how does that work or well you you wouldn't lock up anything in a contract that didn't have a clear mechanism for you releasing that like there are some potential attack vectors here right like you could just arbitrarily lock you threw up in a certain contract and then that contract has a function where like the owner could just release all the lock ups and yeah that's that's so does is the release lookup of code really required so is it because like does it actually affect a lot release or not or does the s store which store the clear the storage effect the lockup sorry effects the release so which action actually releases the Easter is it the release lockup or is it the store which cleared the storage it would probably be the release code rather than okay so in this case I could sweep somebody else's lockups if there's no permissions and yes so if we what obviously that is not okay why or because you know everybody will be scared to put any lock ups because somebody can just sweep them up well like miner or something well I mean the contract would define its own permissions around it right like but the contract does the contract no the basically if you're thinking about the contract in order for the contract to decide it it needs the other way to introspect the lock ups at the moment there's there's no such thing is there's no ability for a contract itself to introspect the lock ups so it will not be able to decide because it doesn't have information so the only thing that can decide it it's a is a protocol and in order to do that the protocol will have to store the information who placed a lock-up so that it won't allow anybody else to withdraw it you don't need you don't need to know who place the lock-up you would just need a smart contract to be able to access the lock-up counter right and you could it could call the release opcode as long as that lock up counter is greater than zero yeah yes the proposed opcode is that a contract can only release on its own balance so you so you can't just call release as some third party you can't call release on someone yeah so if there's like a to and from address you know for this OP code the from address is always just the contract I own address so a contract can release its own lock ups and it can add to any other lock ups from its own I guess I still don't understand it so my somebody else can explain no I just wanted to like to see if I understood things right so what you suggest is instead of well there is a problem the naive solution to this problem is to store together with every storage cell who is the owner and you suggest that instead of doing that you can let the contracts choose which logic they want to go with they could go with the logic of having this like for every third cell have the owner which will cause them to double the storage or they could go a different logic of how you were leased how you release the lock-up so for example you could choose that the contract owner would pay it or any other logic that you want to beat on top of that yeah and calling the lockup opcode would still increment the counter of the the two addresses lock ups so that that part doesn't change if you've wanted to add something where you actually were mapping storage slots to user address you could also do that maybe we could we could talk about it but I still don't understand the how the problem of permission is gonna be so but we can talk about it after your presentation so I think I it probably needs a bit more specification right but let's talk about it I mean like for example if if a contract didn't have any function that ever called the release opcode then it would never be able to release lockups right they were they were just needed to find some function you were but in my mental model I have in front of me two contracts one of them the one is the contract who actually executes the release code or lock up code and then there's a second contract which is the legacy one right which we didn't we couldn't read employ yeah is this your mental model too that is probably how the legacy contracts would work yes just have a wrapper contract deposits - yeah I guess because maybe we're thinking about two different things we are thinking about legacy contracts you thinking about a brand new contracts which which do the lookups for themselves yeah actually I think you're right it might be impossible for legacy contracts to actually release the lock up yes so that's the the the thing I want to bring up is that the only reason why the lockups have been put into proposal is to cater for legacy contracts and I want to put it more in and to able to sort of give them a chance to to migrate and if we were to ignore that we would simply go on with the first proposal which is the just a simple rent and I agree with you that for the newly created contract is not ideal the lookups are not ideal so maybe I will go and think about it thank you for this proposal I will go think about it whether it's possible to not have a lock ups for new contracts over the implication does it happen because as we are kind of realizing that the lock up and release op codes probably not gonna work for legacy contracts so we are basically having now three different considerations rent lock ups for legacy things lookups for non legacy things so yeah we kind of need to bring it together and get here into place yeah I think that's a fair proposal as well only have the lockup scheme for older contracts but I think if we were to move forward with the current proposal for future contracts it would hardly break everything okay anybody else anybody else wanted a question ask a question no okay [Applause] okay cool hi so my name is Esteban I'm a little bit of a foreigner to the old Coral Deb's meetups and everything but a little bit background about me started working on missing remote two years ago my project is called the central and it's kind of like a game with virtual real estate it says Molden ft in terms of contract size but the H n ft is pretty valuable I've run a bunch of nodes for long I have been doing that for a long time and I've got a little bit of a conservative background because I come from more of the Bitcoin side of stuff so my main takeaway from this meeting is that I thought that there was a lot more consensus on keeping the oneexchange sustainable I really like that hashtag a sustainable and I think that I'm going to try to push forward for more people to realize that this is a huge problem like all the 2018 it's been a little bit of a pain to run full note and it's seems to be becoming more of a pain every day I just run faster machines with better hardware but yeah that's that's not sustainable so I don't want to repeat everything but these four numbers were worth something that was pretty interesting to have in mind for all of this considering for all of these conversations sorry [Music] so first the current state size nine gigawatts running a full node that takes a hundred 40 gigabytes I knew that already there are about 50 million accounts out there and we could we could consider about 30 million of those vast accounts and there are about a hundred forty million storage items so first with regards to burning accounts I think that this is like the low-hanging fruit in terms of everything we need some data to realize how much how much are we going to win from this or if it's even worth to prune a lot of account data because of all the pains about resetting the gnomes but I think that it's worth it because we don't know how much or for how long will people continue to use this in this chain and make it sustainable over time it's a lot better than just saying there's going to be I could cut off and after this moment there's not going to be like your account may live forever where so the convent industry I find that it may be like independent of the contract maintenance fees I think the that is pretty simple I'm not going to explain it again because we already like sorry this about three times I understood I learned how about the count eviction how we should I add this expires at the X field it will be interesting to encode this into the nonce but I think that that may break some stuff with regards to the contract storage maintenance like my slides have been just updated by the present by the conversation about five minutes ago but I started to work towards the same probably the first storage rent proposal and I'm that we shouldn't refund storage like lookups but I'm a little bit like conservative as I already said like a lot of the complications are coming from releasing the locks mostly and I think that it may be okay if we just wait until people like lose their contracts this is what I think may become a tragedy of the Commons for smart contract developers like if there's not enough incentive for people to release a storage over time it's going to become too expensive to maintain that contract and it may be so that the contract gets evicted and I think it may be okay because it's a little bit of a separation of layers I'm not sure about that I also believe that charging TX dot audition is a little bit of an anti-pattern but we already discussed this regarding sync I wasn't able to spend much time with a team but it's a clearly a priority for the team it feels to me as an outsider that there's meanst a lot more coordination between the different teams to work on our proposal to sing together and then there are another thing that I learned was about increasing the gas limit which I think it's a little bit reckless right now adding more features which would be cool but I think that we need to fix the scalability first and releasing the gas cost for cold data which I also think it's kind of like increasing the gas limit so I think it would be a little bit complicated so I think that that's kind of like my takeaway from the whole thing thanks for inviting me it was a pleasure so with the text or you said that the using TX origin for lockups is an anti-pattern I did actually think before I arrived at this I settled what it takes origin I my first idea was to use the message e sender for that purpose but then for some reason I quickly realized this is gonna be an T pattern - and I and then there was another idea to store the where the lock-up came from so all these things have the problems and I settled for the the ones which I thought was the list of anti-pattern which the th it so I don't know if anybody has an idea what it should be or or maybe like saying that la cops don't work at all so yeah let me know I I thought that there may be some solution where we could have a new call up code that sets the lookups to be spendable like so the problem is legacy contracts and legacy contracts usually use message sender so you cannot wrap that contract in a contract that before every store whatever like tries to do something else but if we can find some kind of like condition to grab like to change the semantics of s store if they if the wrapper contract calls in some other way in may mean maybe there's a solution yeah don't you don't need to propose the solution now but I just I just encourage people to think about what what are the other ones so I just want to say I'm not completely like set on this idea just to me it was the lesser of many evils thank you very much yesterday and show you what I have changed so far so sorry my name is Alexei so I'm going to show you what I have changed in the couple of documents since yesterday after our discussions let me just okay there's a lot lots of actually lots of things happened yesterday but let me okay so first of all I have renamed the this document - no she maybe I haven't renamed it anyway so the page for one so yeah so what's something that I said on the first day and then Robert has pointed out that I probably need to put it into presentation is that in this framework for the estate management I am ignoring so we are ignoring the cost of running the phone out so it's not addressed in this framework and that's to be that's to make sure that we can kind of have some reasonable things that we can reason about and we only concentrate on the one day on the performance from a different dimensions so page number nine so pinch number nine so here's the you might remember that might recall that I was also talking about caching so for the some of the performance degradation like the reading the state from the transactions and writing the state from the transit so writing the the miracle tree obviously most clients use caching caching policies and at the moment the the most the probably the only one which is used as LRU cache in policy and so my my thesis was that if the caching policy is fixed and deterministic then it could be DOS attacked and at the moment I don't think it's happening but maybe it actually does so all these things need to be analyzed if we want to make sure that it is actually happening because sometimes you have this really weird slow downs of the cerium like mine is sinking but you know if we started to analyze what was actually happening there then we might see all sorts of things we might have already done they might have really been these dos attacks but we don't we they were just basically generally slowed down a network but I didn't see analysis on that so for that reason for the for the purpose of figuring out that the function of the caustic performance degradation we should not rely on the the cash in being able to kind of help a lot and that's therefore we just assume that the cash is randomized so page 12 okay so in page 12 I was listing the partial mitigations for the performance issues and just a quick question on the previous slide do you mean um cash hits or the doses when you construct cache misses so with the DOS what I mean by this dos attack is that somebody if if the adversary knows the predominant cash in policy let's say RR oh you they the RO you basically has this hypothesis that if the item has been used now it's very likely it's going to be used very soon right so if the adversary can basically make sure that this is not true and essentially defeating the efficiency of this policy so basically making sure that there the transactions are happening they only using the the items which haven't been accessed for a long time that's cash misses right yeah to generate as many cache misses as possible so so what I'm saying is that you cannot say that you have improved performance by simply put in the cache on the other thing because that cache can be attacked well regarding cache removing now are you and replacing it with the randomized if I understand correctly that's the suggestion well it's practically you probably won't do it but right si erratically this is the only cache which is not attackable by by by the by this right practically you probably still gonna run ro you for for the for the case of simply processing the blocks but as I discussed with some people in here if you're actually thinking then ro you is not an optimal policy the optimal policy for thinking is that if you know in advance what you're going to be touching can basically have an absolutely optimal policy but this is what I was planning to do in the troop again at some point when I have some time so 12 page so page 12 so basically here we were discussing possible mitigations of our performance issues and you might recall there was a mitigation to improve latency but not throughput then you can do advanced syncing actually you can forget about the slide mode last modified look we have the little breakout today about the sync protocols and I'm hoping to put together some presentation maybe today in afternoon to summarize what we've done but I now want to add a third item here one of the mitigations that we can ask people to increase the pruning threshold so essentially that's saying that a serial node is not 140 gigabytes anymore but it's 300 gigabytes officially and that means that everybody should should try to keep a bit of more history to allow the other peers to think properly I know this is just the lowest temporary mitigation but it could help if we just if we determined during our emulation that in the two months time it's going to be impossible to sync this is the easiest mitigation is just to ask somebody who has to run the note to increase the throughput in threshold and here is well yesterday I think Fredrik mentioned to me when we talking about a success rate of snapshot saying I was previously thinking about only free variables that affect it like three main variables which is state size bandwidth and pruning threshold but now he said to me that there's another four possible causes that appears uptime so I kind of assumed before that all the peers that they permanently online but in the reality they always drop in and out of the network it's sort of the it's very sort of ephemeral so we also need to test for the period uptime like what happens when the peers like only temporarily there's you know you cannot have basically persistent sink connection to the pier you have to be able to find your like where did I stop like how do I find the to resume my sink or something like that and this is the this is all about this document I'm gonna show you the other document okay one point here yeah with something about them like average number of peers you're connected to also be included in the function oh yes good good point thank you I'm just gonna write it down okay so let me show you the other one okay that's the one I have a question no I've got that note there I think that the sink should be a little bit more independent of who are you're sinking from like it should be better like you talked yesterday about that chunked proposal for sinking and I think that's going to be a lot better yes so we are just before we started the presentations we had a little breakout session over there about sinking sinking mechanisms and I'm hoping to put together I have some PDF about this already but I if I have time before the afternoon I'm gonna put something together and explain what we what we discussed so first of all this is the like Version three now because there was a previous it was version 2 but version 3 is not published yet so gonna so first of all I remain renamed it from state management from state 1 to state management and it's not just because we don't like the word but it's because it actually overgrown the state rent now it's not just about statement is about lots of other things and so let's see what we have here so you might recall there was this diagram of the changes before so here I started to make more clarifications so I've realized that for example the replay Protection AIP Marcin has written specifies that the first step which is the optional reply protection is a hard fork but the second step is actually so-called soft work so this is the cloudy bit like soft things and I just explained you what is the difference so the the hard fork is essentially adding new so it's extending the protocol meaning that certain things which were not valid before will become valid now so that's the hard fork extension of the protocol and the soft work is the restriction of the protocol certain things that were valid before are not valid anymore so in the example of the reply protection when we make the option of we we allow the optional field in the transaction means that we still allow the old stuff we also extend it to the new so we allow more transaction types to be valid and then we restrict it we remove the old way of doing things and only the day of the new things it's the soft work another thing I added here is the s in the inner left bottom corner which is the advanced sync protocol and I introduced anon for exchanges here with the with a circle with the oval which basically don't require the protocol upgrade but they still quite important and they should be on a roadmap it's like a priority sort of number one and then we discussed yesterday and we kind of realized I haven't formalized it yet but I will do it so that this the accounting of the storage size potentially can happen with with only one hard fork instead of two and this is why I put it in an oval instead of the square and let's see so this is kind of it messy now but I needed to rely a relay relay layout these things because they're not really nice nice circles anymore but what you could see that the circles are now not dropped out of the forks altogether because they're not Forks and another thing which we didn't realize what we did know didn't realize yesterday when we were talking about so we were talking about what is the what is the shortest path to let's say increase in a block gas limit as the estaban correctly mentioned increasing ago blow gas limit right now is a bit reckless because we will probably see the acceleration of the state size growth but we still want to do that and what are the minimum set of changes that allow us to do it without being reckless and we if we are looking at this particular proposal here probably storage lock ups will slow down the state expansion sufficiently so that it's not going to be you know growing very fast and yesterday we are assumed that this could happen in a first heart fork but now I'm thinking it's not it the reason for that is that the the the proposal I had yesterday or or before yesterday there was this thing about lockup safety so I'm just gonna show you now so it was a bit tucked into the list yeah so in this slide I had I talked about marks lock ups so the the problem is that because the TX because the lock ups are not tied to the gas and they directly deducted from the teks origin or released at X origin there is the only restrictions of how much ether could be deducted is essentially that the gap the gas cost of a store relative to the gas of the transaction and the balance so it it's conceivable that there could be some rogue contracts which have a goal of draining your account and putting it in lock ups so as a safety feature this in the same vein as that we have a gas maximum gas limit on transaction it would be prudent to introduce something like max lock ups which is like number of lock ups that you allow this transaction to do on your behalf let's say if you put it as five and the the minute the the moment it goes to the six lock up it the transaction abort verts and no lock ups are made so you can basically limit how much how much ether your transaction can spend on lock ups if we agree I mean that it is important then the situation changes that the storage lock ups can only be introduced in a second fork because before that we need to introduce the safety the lockup safety so I included the safety into the I combined it with the replay protection because these both changes modified transaction format and it's probably easier to do them together because so this is how it's gonna look like so change to change a optional temporal protection and lock up safety so now I have a little icon here to signify if it's a hard work but I haven't finished on the whole presentation so the temporal protection we've seen before but now the general this this change looks like this so I also take into consideration what the case you said about versioning so let's say that we add a three optional fields they either all together there or not none at all version valid until in max lookups and then in the change be together with the protection we also make the mandatory version valid until in max lock ups and so this now becomes because of the safety feature for lookups we we added as a prerequisite for for the lockups let's look again you see that there's a little line between the B cloud into E so that's the safety thing and because the B cloud now can only happen after a so the a will be in the first fork and be together with E is in the second fork but then the second four gives you both both storage lookups in the dust account eviction so it becomes sort of more impactful so what are the things I changed here so yeah so I haven't finished writing this yet but I'm trying to write down what we thought about the the gross contract size accounting in of splitting into two forks we just doing it one fork but now I turn it into the implementation guide line so both edit edit change see this is up to the client implementation but they start maintaining the the signed integer count and they whenever they execute a store they do these things to this counter and then in a change D they are this needs to be written by the way so it changed either they inject the correct value into the into the state after the block D so this is how you can achieve it in one hard work but actually if you look at this we probably I know it still actually makes sense yeah so this is what I've changed since yesterday and don't think I've changed anything else yeah okay so that's it for me for now any questions yeah so the proposal is becoming quite complex and it only looks complex because I didn't put them into nice nice layout yeah I think it's time to maybe start doing long-form documentation of like the rationales for why some okay guess we're being rejected but off the top of your head maybe so I'm wondering going back to like the the state rent proposal from Felix and and yarns Wendy they're still here they're still inside this proposal they in there basically apart from the fact that the apartment a floating rent everything is still inside here okay but their proposal it applies on it adds rent to existing contracts correctly and this one just rent happen on existing contracts are only the lock on the so in this proposal there's three types of rent there's a rent on account which applies to everything to a contract non contracts then there's a second type of rent which is applies only to the code the longer your code the more you pay and the third type of rent which is the storage rent which only applies to the the contract which didn't look enough ether into into them okay so it does apply on pre-existing contract yes so the storage rent in this proposal mostly penalizes existing contracts and it does not penalize a new contract and this is the reason well this is why the it's basically meant as a garbage collection mechanism announced the depiction of dust accounts as a separate proposal from the storage because that makes this a lot simpler like it's just adding an expiration date for all transactions and then evicting your account if it doesn't if they didn't pay the rent yeah this is it is separated here right you see that yeah exactly but internal when communicating it to yeah so this this separation I only came to this idea on Monday like last Monday so it's a one week old idea didn't really have time to propagate yet a B and G are yeah I will I will need to reread jiggle this this diagram because it's just organically grown into the stage and and of course we we still want to hear the opinions and maybe modify this so it's not like this is it keep changing it state management of the graph yes yes any other questions go thank you very much and anybody else wants to make a presentation for now or we are doing a breakup breakouts okay I take it as no yeah we we're yeah we're doing a breakouts now so the live stream will be suspended for for a couple of hours I guess thank you very much for listening [Applause] 