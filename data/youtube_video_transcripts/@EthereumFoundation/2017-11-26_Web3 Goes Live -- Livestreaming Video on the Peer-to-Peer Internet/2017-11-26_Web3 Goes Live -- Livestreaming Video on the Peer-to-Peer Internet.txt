[Music] my name is Eric tang and I am here with the live pure project first I want to thank Victor and and the organizers here to invite us here to tell you a little bit about video streaming on the past four days has been really awesome for me like just being among like my peers and all trying to make this interest what happen and it's like the best thing ever so today I'd like to share a little bit about why decentralisation is so important for video live streaming and also I want to share a little bit about a road map where how we can work together to make this whole system work because live streaming is is you know a combination of many different things and life here is it's a part of that and and swarming is a part of that and and among other systems so before I dive in I would like to give a live demo and and I know this is against the rules of presentations in general but I will do that so what I'm doing here is I am live streaming a video from my phone to the test network that we've set up about a month ago and I am consuming that video from my from my gate gateway and it's not very clear but but you can see this is video live streaming working in a decentralized peer-to-peer network so thank you I just broke my presentation that's okay so with the you know what Peter appeared to centralise video streaming there's a bunch of use cases that we can enable that that was not possible before right I think unsensible journalism is super important as we can as we have seen you know happening right now in the world whenever there is some kind of political unrest or war breaks out the live video stream is the first thing that gets cut off but a decentralized video streaming solution can be very very important in solving this problem another interesting thing that I'm personally very excited about is a pay-as-you-go education or expert network so this could be things like a tutoring service or telemedicine or telepsychiatry where you know finally the service providers can have the tools they need to connect and transact directly with the people who need the service and get off the centralized networks today that are charging 30 to 80 percent of that transaction fee another really interesting use case here is an auto scaling social video service and this then this works because in in video live-streaming we're pretty notoriously known for the peaks and valleys of the resources needed to provide a service you know popular streams come up and it record you will require a lot of bandwidth and computation to serve that and then it goes away and then you don't need that service anymore so the underlining economics in the blockchain can really create this automatically dynamically changing networking throughput to solve this problem and save a lot of costs and finally this decentralized video live streaming network enables that developers to build completely decentralized applications that have a video component where you know we haven't been able to do before so I'm really looking forward to seeing all kinds of interesting use cases that people can think of with a decentralized solution for video streaming so before we can get into how decentralized video streaming works I thought I would take a quick we can take a quick look at how video streaming works today on the Internet what we see here is a broadcaster could be you know for my phone could be a cat would be a webcam or it could be a you know high quality camera from from a news reporter sending an RTMP video into a cloud hosted media server now this media server does a few things that are important one is that it will store the video for a future playback another is that it can optionally interact with a DRM system to encrypt the video so you can preserve the privacy of the video and another really important thing is that the media server will transcribe the video into many different bit rates and video formats so so that these video formats can be delivered to the CDN and they can be delivered to the end devices that you're watching the video on whether it's a mobile phone a tablet a computer a high-definition TV or even IOT devices any device that can that can connect to the Internet so here what we have is a workflow called adaptive bitrate streaming and this is basically what makes the video streaming experience work on the Internet and what this really means is the end player is able to pick the right version of the video to play based on its own network network condition so what we're seeing here is we have we were starting off with a cell connection at around 200 KEK connection speed and the best video for that is a 240 p video and as we switch to a 4G connection the player is able to switch to a 360 P video with no interruption in the playback experience and this is crucial for stream internet because the download speed on the Internet can vary throughout time because unforeseen things can happen on the Internet so here are all the bit rates and formats that we have to worry about when we are streaming videos as we can see there's there's quite a bit of them which means and this just means for every stream that gets streamed onto the internet we have to transcode it into all these different formats in order to serve all the devices that are out there on top of that other than the bit rates we also have to think about video codecs the the most popular video codec today is h.264 but there's a new codec coming out called HTV see we're not gonna go over the details of the difference but the high level difference is that HTV see is able to pack a much crisper picture with the same amount of data right so here what we see in the right in your life and my left your right is HPV seif video served in the same same amount of bits as a h.264 and as we see HTV C is much better and it just happens that h.264 and HTV see our proprietary codecs which means when you're using them you have to pay a licensing fee for the patent holders so they're on the counter part there is open source codec called vp9 companies like Google are funding the development of this and and the next generation of that codec is called a v1 so all of this complexity that I described makes video transcoding on delivery a very complex and very costly to to put some number on that a traditional SAS transcoding service typically costs about 3 to the $3.00 per stream per hour and you can if you want to build your own stack to do this you have to license expensive proprietary technology and in order to do that because there's no good open source media server out there and and on the delivery side it costs about 12 cents per gig on the on a regular CDN this might not seem like a lot but a regular you know average twitch user uses about six and a half gigs and YouTube uses a little less but not that much and this comes out to be a little less than a dollar per user per month if you have millions of users this you can potentially be paying millions of dollars per month just to the CDN to relay your your video and so when we think about using the centralized solution to solve these problems what we really want is on top of all the nice things that decentralization provides like censorship resistance we want to have a cheaper and better solution than a centralized service and this is pretty special because you know these in in the blockchain world currently we we have pretty pretty expensive services and what we do but what we're trying to do here is to make the service cheaper and better so so what that really means is we want to change this picture which I showed earlier into this picture so we want to teach web 3 how to do the video transcoding how to do the encryption how to do the storage how to do the video delivery so that when the app developers are creating the apps you don't have to worry about all that stuff and all that stuff is hidden away from you so you only have to worry about the incoming video and and get the video it into your tap and that's it so this sounds like a pretty daunting tasks because there's a lot of moving parts but luckily a lot of these components are being used today so for the storage layer we have projects like swarm my PFI storage all doing decentralized storage in for slightly different use cases for video delivery we have projects like block CDN and file coin and within the swarm project we have this watch spec that addresses specifically for video delivery for content protection and privacy we have the centralized key management systems are coming out and on the application layer we're starting to see a lot of interesting app app tokens and apps that are trying to address the problem for incentivizing the content creators and connecting them directly to their viewers so these are projects like the props project from you now the stream token project and the parity DAP so this is all great but creating protocols are hard right because you have to create your software and then you have to create your decentralized protocol so that it can work in a decentralized way and not on top of that if you want to create a protocol that scales well that's even harder and if you want to further about that scale as well and it's cheaper when it's scaled that's even harder right so today I want to use live pure and video transcoding as an example to show you some of the lessons that we have learned in the past year about about some of the principles so on the high level when I think about the blockchain I think the most powerful thing there is that we can create completely new economics and realign incentives right and and this is very apparent for video transcoding and in the light in the life here network so in the traditional service economy what we have is a broadcaster sending a video in and the broadcaster has to pay for the cost of the service plus a margin that these that the platform is charging but in a decentralized in the decentralized world the protocol itself can create incentives by releasing the crypto token on a on a predictable schedule to the nodes that are providing the services to these networks so that when the broadcaster is sending the same video into the deep into the decentralized network it has to pay for the cost of the service - incentive that the blockchain is already providing to these service providers right now this might be subtle but it's a pretty important difference because it kicks off this virtuous cycle right we're cheaper broadcasting would drive more demand onto the network which over time increases the token value and the increase of the token value as we can see as we already seen in the Bitcoin and ethereal mining world the brings a brings in competition for the service providers and that creates better hardware better software and even better a cheaper bandwidth and all of that increased capacity city and increase capability of a network goes back into creating even cheaper broadcasting services and this is how you kick off this flywheel that makes the makes the service cheaper and cheaper and makes them makes a network scale more and more now this all sound good in theory right but when it comes to practice we have to make sure the protocol incentivizes reliable service and it creates a secure protocol in both from a cryptographic standpoint and a crypto economic standpoint so for the case of life here what we do for for reliability is we use a delegated proof of stake service a protocol where the transcoders when they become active and join the network they advertise their rates and stats and there are features so that when the token holders see those see that information they can choose which Delta which transcoder to delegate towards and in the delegation process that the token holders are essentially protecting themselves against the predictable inflation that's happening in the protocol and for every round that that happens in a protocol the top end transcoders become active and they get work in proportion to the stake that they get from the state from the token holders now this is important because number one it creates an open an open market where you have open competition and downward price pressure for the transporting service and two it creates some stake for the transcoders so that we can we can create accountability and economic disincentives for for the transporters who are trying to gain the system so let me walk through how the how the life here protocol works to do this when the broadcaster first wants to broadcast the video is it creates a job on chain with the smart contract and and the smart contract uses that uses that pricing information to find a transcoder who's willing to do the work and when that happens the broad Kaster can start sending the video to the transcoder when the broadcaster is sending the video is signs every single video packet so that the transporter knows exactly and can verify where the broadcaster is when the transcoder is doing the work for every video segment it's creating a grading a transporting claim using the transporter resolve hash and the signature from the broadcaster and it's keeping this it's keeping these claims around and when the job is finished it creates a vertical route based on all these claims and it writes that medical route back on chain when that happens the live pure protocol in the smart contract reveals a challenge segment with which the transcoder has to provide the merkel proof for now this is important because the transporter does not know what the traveler segment is before before the stream is over so that the transporter is forced to do work for every single segment and it can't cheat now but this is not enough right it just ensures that the transcoder is doing the work for every segment it doesn't ensure that the work is done correctly so to do that we have to use an off chain computation Oracle like true vid or Oracle eyes and what this does is you the transcoder can write the the broadcasted segments for the afford a challenge segment on to swarm or ipfs and the the computation Oracle will use that information to do the actual transcoding so that after after it it does the computation it'll write the result hash back on chain so now on chain we the protocol has the merkel proof from the transcoder and it also has the result hash from the company from the computation Oracle and it'll compare the two results and make sure they're correct and if they're different it means the transcoder has done something wrong and the transporter will be slashed now this is how we're able to create a secure or decentralized transcoding market so now I'm going to demo how that works [Music] so what I'm doing is I'm connecting to the test net and I am starting to stream from my camera - into the test net and the test net will go through the transcoding election process and start transcoding the video and what we will see in a little bit is the transporting results and this is him and I said this is really important because we need to have different versions of the same video so the big version might be for my laptop the really small version might be for my phone and the middle version maybe is for for a tablet or something now the transcoding is only one piece in this whole live streaming workflow right another really important piece is delivering the actual content so to do that we created a prototype based on the swarm node and oh and we showed this off at the swarm summit early this year and the way we did this was first we extended the buzz protocol in swarms so that each swarm node can relay videos to each other we also created a stream DB so that each stream can be searched for and found in the peer-to-peer network and on top of that we created a streamer interface so that we can embed the live peer media server into the swarm node and make each swarm node also a media server so that each swarm node can take in ingest video and conserve an outgoing video and since then we've been working on scalability solutions to make sure not only can we relay videos around but when thousands of people are watching the same video this video can be delivered reliably and these people can all have really good viewing experiences so so let's look at why video delivery is hard in in a decentralized world so what we have here is a very naive way to relay video right a broadcaster is sending video into the network maybe to a to a few people or to a few nodes or just one node and this node is relaying the video downstream to the to the nodes that they are trying to watch this stream and now this is already much better than the centralized solution because now the broadcaster does not have to provide all the bandwidth for everyone who wants to watch the video right it only has to relay to a few nodes and these nodes will spread the consumption of the bent of the bandwidth around but it has a weakness right slow upstream bandwidth will cause the downstream viewers to have really bad experience and this is this is undesirable what we really want is a highly connected graph where every node can stream little bits and pieces from every other node so instead of one video being relayed down down a tree we had this video being swarmed around in this highly connected graph so this is why we've been working on this protocol called ppsspp which stands for peer-to-peer streaming peer protocol I didn't name this it's been it's been an RFC spec that's been in the works for for a few years and it has some really great properties right number one it creates an over overlay network on the base peer-to-peer network for every specific video so that only the people who care about the video will join these swarms it has very small data chunks it recommended chunk is is 10 to 1024 bytes which means we can break the video segments down into a very small segments and rate it really them around there have much more flexibility it uses a single merkel route to represent the entire stream so that when you're relaying the video around the data can be validated and and it will have integrity and you compact multiple Mehcad messages into one packet you can have and now you can have many connections to many peers and download the stream for many peers at the same time and I can let me just walk through the really simple version version of how this works right so node a wants to join the swarm and start viewing the stream so it asks either a centralized tracker or DHT about this swarm connection information it gets them it sends handshakes to all these nodes that it wants to connect to nodes can either send a handshake back and a have request a have request to tell to tell node a which video chunk that it actually has or it can send a choke request back to tell a you know I don't have been with or I don't want to serve the video after that 8 now 8 knows who to request what video chunk from and it's gonna do the request and it's gonna get the video back with integrity check and this in credit integrity check is basically just them Merkle proof because we already have the miracle hash merkel root that represents the entire the entire stream so now a is optionally a consent act back and now when a new node joins the swarm and talks to a a can start relaying the information that he just got to these new nodes and when the choking node wants to start start relaying streams again maybe it got some free more bandwidth HSN start sending half message you get a message again and it start a sense of unchoke message so that they can start requesting for data so so that was the generic video streaming workflow to make it live when he said we need to do a do a few modifications one is we just make the broadcaster push have informations half packets into the stream into the swarm so that as the new segments become available the broadcaster just tells that tells the swarm that it has these these packets and the swarm will figure out how to relay it around and also when during a handshake you can establish at this card window so that you don't have to keep all the video around through the whole live stream and instead of now instead of having one merkel route we would have a live injector which just means we have a transient merkel route and to do that and to ensure the the video that we relay around is still correct and has integrity we use the monroe hash which is just a fancy word for saying it's a miracle route for the new for the new trunk instead of for the entire entire video so that that's basically how the video relaying network protocol works to get around some of the some of the constraints from a tree structure but what we really want to do here right is to incentivize the video delivery and and I think the the the swarm team pub published his paper calls where swaps were in Swindell many years ago and they recently generalized it to create a good good framework around this and this is a very much open research area we're very excited to continue to work in this area so to to kind of summarize what we talked about what the goal here is to teach web 3 to do all the video video delivery video streaming stuff that the traditional web is able to do right so that means adding transcoding transcoding features through the live here network using swarm or ipfs to do the storage for both the protocol verification process and for the for storing the actual video for later playback and also we talked about a few different CDN approaches to deliver the video and now since the CDN area is very much an open open question and open research area we have a fallback mechanism to to always go back to a centralized video so that we can have smooth playback experience right away the project has been in the works for a little over a year we published a white paper early during the year and since then we've been working on the test net the test net just went live a little less than a month ago and the demos that I just showed is running on the test night right now and our next goal is to launch on the main that and in production either q4 this year or early next year so this is very exciting right because live streaming in the decentralized context is happening like it's like imminent and and there are a couple of things that you that we can do to that for everyone to get involved the easiest thing is to run a node and join the test net so that you can see how live-streaming works in the decentralized world another thing you can do is to build a video based app like some of the ideas that we talked about or I don't you know any ideas that you have that we haven't thought about and another thing is if you are interested in p2p video delivery and you want to help us make this a reality come reach out to us life here works as an open source project and we work with people all over the globe and frankly that's that's part life that's one of the best things about working in this space is you you're able to work with all kinds of talented people from all kinds of backgrounds so we were reachable through through our channel we are on Twitter we're on github or we can just send me a message I'm happy to I'm happy to help you with anything that you need so that is it I am Eric and we are live here and I think we have two minutes to for any questions after like for every single packet is there kind of an sounds like that would be there would be some overhead related to having to sign every single one of those is that an issue yeah so the sending the packets would have to happen anyways in a decentralized world right in a peer-to-peer network where you don't control all the peers you are forced to do that the CPU they see the CPU overhead it is not that much of course it's better it's better to not sign it and say the CPU cycle but the security that you get is good because you can scale the network and and overall get a cheaper solution you mentioned that there are many different encoding decoding texts some of which are proprietary I do suppose that might be an issue for like distribution on swarm or something yeah that's an interesting question I think the proprietary Kodak's this is very much on the application developer to answer this question right like even the private even the proprietary codecs are in in these open source software's and if you are working if you're a centralized company and you're using these proprietary codecs and it's up to you to have to pay the license fee otherwise the lawyers are gonna go after you yeah or you can just use vp9 and it's open source so you excuse me you mentioned that the PPS VP protocol wait the PPS P protocol has has packets of 524 bytes packets of 100 sorry thousand and twenty four bytes and have you done any benchmarking on like overhead costs and like the whole system in terms of like where do you foresee the main overheads to come from and how does that compare to like a centralized system yeah that's a good question there's there hasn't been a lot of products built around this and as I said this is a very much an open research area but what I couldn't tell you is that ppsspp overcomes the problem of slow bandwidth upstream and that's enough of a benefit to for for for the peer-to-peer use case oh cool I'm gonna be outside so come in find me you 