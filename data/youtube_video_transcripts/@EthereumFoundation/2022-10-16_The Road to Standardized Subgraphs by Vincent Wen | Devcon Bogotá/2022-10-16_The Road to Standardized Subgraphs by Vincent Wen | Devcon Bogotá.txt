foreign [Music] thanks for coming my name is Vincent I'm going to talk about standardized subgraphs today or how we can make it so much easier for you to build your dats if you ever built a dab or have ever considered building a DAV one of the first questions that comes to mind is probably where do you find the data and let me show you an example that component Finance has been working on so they're trying to build this uh predicted model uh to for people to look at different assets like if in this case and how the yield will be in the future and in order to do that they need a lot of historical data historical data on interest rate on total deposit from different lending protocols across different Networks and this is a small example to illustrate where you might go to find all these data today as you can see there are many different data sources that you need to hit to depending on which lending protocol you you want to pull data from if you're lucky there's a subgraph that you can already use that has all that data if not you might have to like work with Json RPC API and kind of transform and aggregate all of that data yourself and for each of that data you probably also need a data adapter to normalize so that your application can use it so the point I wanted to make here is that web3 data space is very fragmented there are dozens and dozens of different data source that focus on different parts of data or different kind of data if you're working with raw data it takes a lot of effort to aggregate transform them into something that you can use for example TVR Revenue those all require a lot of work uh historical data is often difficult to find you probably need an archive node and those are often difficult to access this is actually a problem that Missouri has run into when we first got into the Unchained space where a big data provider we're trying to get a lot of data and it was difficult for us to find those so we decided to collaborate with the graph to work on standardizing subgraphs so that we solve this problem for everyone in the space specifically the way that we we standardize these subgraphs is that we would look at all of the protocols in a specific category say lending protocols and we pick out all of the commonalities and differences among these protocols and see and come up with the unified data model that would apply to all of these and then we transformed that into a common subgraph schema in which we built all of our subgraphs again so for each of the lending protocols we integrate we use that standardized schema so that you can use the same query you can use the same data adapter to fetch all of that data and now instead of going to all of these different data sources to fetch that that data you just need to hit one single decentralized data source that's the graph and you'll be able to find all of the data you need including the historical ones so uh here's an example uh product or here's actually a product that mazari has built on top of all of the standardized subgraphs that we have built as you can see here we're showing there's a lot more metrics that we're showing uh that we are we have integrated it's not in this in this slide but you can check it out using the URL there so to give you a sense of where we are today on on the subgraph standardization work we have index data from 60 different protocols across 20 different networks surfacing over 500 unique metrics across all of the different protocol types and we have indexed over a billion data points that you can use in your Dev directly so that you don't have to do that work and the way that we are seeing kind of how the future will evolve is that today you're spending a lot of effort on kind of the data Plumbing on the data aggregation part and very little uh on the application logic but with the subgraph that we have built you know it's already done for you you can just use that so you can focus more on your application logic as adaptive developer yeah so all of the work we do is open source it's public here's the GitHub repo for all of our standardized subgraphs if you're a dab Builder or data scientist data analyst we if you work with a protocol team we are we're more than happy to integrate your protocol into our standard so feel free to reach out to me after the talk and if you're a subgraph developer or a Ross developer that's that interested in in this data stage uh feel free to scan that QR code there that will take you to our careers page and we are always hiring Yep this is my talk and thank you for coming he's aggregated subgraph is more is there assumptions of trust when you use the aggregate it's a graph compared to this I have a subgrapher compound sub graph yep so uh all of our subgraph source code is uh open source uh There Was You know the GitHub repo we showed so we we uh describe all of the methodology of our kind of you know the computation for for metrics in detail in the repo and of course you can go into the the source code to look at exactly how different numbers are integrated and the graph is also working on uh something called verifiable queries that will put that trust into the data that it indexes what's the approximate delay before the data is available I mean if we want to do something real time it's in real time yeah so it's block by block okay but on the order there's got to be some like 15 seconds to like two minutes okay depending on the Chain perfect 