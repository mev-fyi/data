foreign [Music] and during the last two years I've been contributing to the Sunderland and today I'm going to talk about using ibps to create the metaverse so let's first talk about what the meters is well it's a social network where you interact with friends people that you meet there in a three-dimensional way and also there you have a digital identity which is customized custom is custom for you and it's your the way that people recognizes you um what distinguished the central from other metaverses is that the users are the ones who owns the platform right so how do we do that well the world is divided into parcels and each parcel has an owner and is the owner who decides what to show on the on the world they could chose to set up an essene for example for a casino for a bar or even a music festival and how we do that we have deployed contracts in ethereum to check the ownership of those lands on the worlds and to check the ownership we use the graph in the backend services um so we have the the contract for lands which where you can own a Land and then let others have permissions to deploy some scene on the world we also have nft collections as well where the wearables creators can meet a collection and then sell them in the marketplace and then you as a user you can choose those wearables buy them and then set up your uh your avatar and that's where we store them in the users profiles and we you can also have a name in the sand run and that's like the identity that you own right what happened with that there are a lot of files and it's a it's too many assets to store scenes and free models and well some pictures so we need to store them in somewhere and we have to delete that the centralized right so what we have are the centralized servers we just store all the data that the client needs to to run right the community owns the the servers which means that there is a there isn't around Dio which is a responsible of approving the list of servers that that are in the Dao so they they have to synchronize between them because we have all the content replicated on each of them so the client can connect to any of them and we'll get the same information right um the way we do that is every every server which we name catalyst is doing a polling mechanism to all the others to retrieve the files and the entities and this works okay but we wanted to go a little bit further and test two things the first thing is that as you may assume we have lots of data and we have like the only historical data like all the changes that have happened on unseen and also the way that the files are replicated together well let's first talk about the historical data what happens for example this is the Genesis Plaza for the sandran which was away in 2020 and there was a change in 2021 so the servers need to retrieve the content the latest content they don't need to serve the how was the sundran two years before right but we want to store that data as a backup and for for example if you want to run the world how it looked a year before if you run a full node which means that you have all the historical data all you need to do is enlarge your disk and everything will work okay the only thing is that you will need two terabytes of of disk but if you want to run a light note then we you can enable the garage collection which is a mechanism that deletes all the all the files from the entities that were written by new ones right okay but what happens if all servers then enable garage collection then we may lose those data and we don't want that so our idea was to set up a node an ebfs node connected to a server which listens all the network and listens all the changes and stores well pins to ibps all the files that are synchronized so first we uploaded all the all the files and now and then um we set up the server to listen all the changes and automatically pins the new files and the other thing is the files replication which we what is that well the way that we share those files between the servers we are doing it by HTTP request and it's a full match topology right because every node is talking to every other node um oh I think I was well what what happens if we use ibps and we leverage that so we don't have to care about synchronizing files we only have to care about the evaluations that we need to do to the blockchain and the entities and the way that we need to retrieve those files but we con we only would need to know the hashes that we need to pin and then all of that part themselves so that's our idea on a trial to to make something different um test if we can Leverage The ipvs to work that um that's all thank you I was just wondering could you speak a little bit about your decision to use ipfs instead of RV for storing historical data instead of our weave for like permanent data to store like historical data we we currently have the the data stored locally like in the file system and we have the the way to configure that and store if you were running out and want to store them on as free you can we have been thinking a lot about the way that the catalysts sing each other and we've been assigned a lot how ipvs does that so that's why I think we chose ibps to test this um but we have done so far it's only the historical data right we haven't done used the ipvs to run the sync how do you handle content moderation or cases where like certain content or files might be illegal in certain countries but would be valid in other ones well the way that way now is each of the servers has an owner and it's there's a responsibility to deny list some entities or files or they think that they need to moderate so we I we are we are not taking care of the moderation ourselves we're letting the owners of the Catalyst do themselves we we only provide the mechanism for them to to remove to remove those files and don't serve them thank you 