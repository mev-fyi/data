all right so I'm also going to be talking about testing but specifically mutation testing which is kind of another subject so a little bit of background I wrote it too called vertigo which the implements mutation testing for smart contracts which I released about a year ago and in this presentation first give a little bit of background on mutation testing a crash course of sorts and then I'd like to talk about the features that are currently in the mutation testing tool and the features that I would like to add and how kind of other parts of the technologies that can enable these features because the mutation testing tool is kind of built on top of other tools like this a little bit in compiler I mean when we talk about mutation test saying you always always first have to talk about code coverage and code coverage is this ubiquitous method which is used to evaluate to Suites at the moment I think almost all people will use this metric to see whether there are two suite is adequate but there's a few issues with code coverage specifically it doesn't really tell you anything about the code that you do cover but it does tell you something namely the code that you doesn't don't cover yet so it is actually a very useful metric because it it helps you improve it it tells you where where to change your tests to have a better test suite better guarantees mutation testing on the other hand tries to improve on this metric by telling you exactly how efficient be up to speed is at detecting bugs rather than just telling you which part of the coder are covered which is great because it allows you to improve your test suite even more efficiently it also gives you a nice measure of the guarantees given by your test suite so kind of to give an overview of permutation testing this is the general strategy we start out by creating a lot of bugs which could be introduced in a subletting project then we run the test feet for each bug and see if the bug is detected then we know something about which where these bugs that didn't get detected played and we can improve the testing so generating these bugs how does it happen so in mutation testing we call this about mutants because they are mutations of the original program and we use so-called mutation operators to take the original project and modify it to get that this bug in the program and mutation operators are basically rules there can be substitution rules which describe how to inject bugs basically and for the two vertical what I did is I look at existing tools for the mutation operators use there also in previous research and I implemented some that are somewhat specific to you the weaknesses that happen in a bitly small contracts is to give you an example of what mutation operators do I have made a little table so for example we swap the addition sign with a subtraction another one which I really like is the modifier remove all mutation operator where we take a look at the source code and to generate a bug we move a modifier and what I like about this is that it kind of M elates a case where a developer forgets to introduce some authorization and authentication logic with which generally is used which generally is implemented using modifiers such as Yummie owner modifier after having generated a bunch of bugs we get to a part where we need to evaluate them to know like whether the tests we detection or not which is the naked next step so kind of the two basic things that can happen are the test feed succeeds or it fails so if the tech the suite succeeds that means that we were not actually able to find the bulk or the introduced bug in which case the the mutant survived and we call the mutant alive the other case is where the test feed fails in which case the mutant is detected and we say it's killed or dead the nares to two additional categories to deal with some edge cases so for example what could happen is a mutation operator modifies a piece of code that results in intellect solidity in which case the compiler will not successfully compiled and we can not even run the test feed so in this case we say the mutant is average the fourth case is time duct which we have included because Newton's can also introduce infinite loops so what we do we take a timeout based on the original time that test we took and after this time it has expired we killed the execution of the test feed and we categorize that the mutant has timed out so then there's this fifth category which I put in in brackets because it's not really a category on its own but rather a specific instance of a life Newton's so what mutation operators also can do is modify code so that there is a syntactic change while not changing the underlying meaning of the code so to give you an example I have the implementation of the the max function have by open indefinitely and as you can see there's a slight difference here in the comparison operator however so the difference lies at a point where a and B are equal but for the evaluation of the max function it doesn't really matter which branch should take when a MV are equal because both will be the max number so this is an equivalent mutant and we don't really want to account for this as an alive nutrient because the test feed was not insufficient it was doing okay because this is actually also correct so unfortunately this process is somewhat manual and we implemented some feature to ultimate this a little bit but it's not possible to automate that in general so there will always be some categorization manual categorization required when you're performing mutation testing once we have categorized all the mutants we can compute the mutation score which is kind of similar to the the code coverage metric but in this case we're talking about the efficiency of the second bugs of the test script so we actually we the the mutation score is computed using this formula and it's basically the rate at which you detect mutants so you take total number of mutants that you killed or that were detected and divided by the total number of valid mutant said these are the non equivalent alive Newton's and D killed mutants we disregard the other ones for the mutation score so this gives you a general metric of the quality of your test suite and then the specific surviving mutations tell you something if you really detailed information about which part of the code you could improve or you could improve the test feed for rather okay so that was kind of a bird's eye view of mutation testing the theory right now I'd like to go over a few of the features that are in vertigo the tool right now then what's kind of on my wish list followed by how can the foundational technologies such as the compiler or test frameworks can enable or support the development of these features so first what do we have today oh there's a few features listed here which which I think are kind of the main ones and the first one is parallel evaluation which is pretty straightforward instead of running the test feeds sequentially for each mutants we run them in parallel most of the times there's going to be a lot of tests so we won't run all of them in parallel but we'll be able to use whatever computational resources your machine might have the second optimization is mutant sampling where instead of taking the entire set of nutrients we've generated in the first phase we take a random sample of those this will give you an estimation of what the original mutation score would have been well we're just a clear adducing the time you need to compute it and there's a balance here because there's of course inaccuracy because you're taking a random sample the third really nice feature data what I think is a really nice feature is the support of universal mutator style rows so this is a project in for general mutation testing where the authors have designed a method of formulating mutation rules using back expectorants and this will allow you to easily develop and demo different mutation rules but what it will also do is enable you to write mutation rules specific to a certain product for example you might be able to write mutation rules for specific safe math library and here I have a little example from the universal mutator repository itself which describes some mutation rules for solidity specifically trying keywords also this should give you some idea of what this is capable of so lastly we have compiled a equivalence which is enabled by the solidity compiler and this has to do with these equivalent mutations so what vertical does is it takes the original program and the mutated program and it will compile both it will then compare the generated byte codes and if they are equal conclude that therefore also the source code must let mean equal in meaning and it will disregard the the mutants entirely so it won't even start the testing process all this assumes of course that the compiler is correct and let's hope this okay so what's next there's kind of two categories vs. optimizations the other is usability there's no time to really do demo but these would help but first optimization so first is incremental evaluation and this would be really nice to have because you in the regular scenario you would be running mutation testing every once in a while maybe and between those two runs you could reuse a lot of information so for example what you can do is look at the previous analysis results and look at which test killed which mutant and if you see the same mutant again try to find that test and run specifically that test first instead of running the entire test suite that can save a lot of time so maybe 80% of the mutants will be killed by the same test and that will save a town an execution time because you don't have to execute the entire test suite every time then there's a mutant clustering and newton clustering is kind of similar to using sampling but instead of taking a sample from the entire set of mutants we grouped them first and take samples from the groups and this gives a more accurate estimation of the mutation scored the third optimization which I really would like to have is the selection based on code coverage so what we do is give them detailed information on the coverage specifically you'd want to know which tests cover which lines of code you'd select just those tests that cover a mutant to evaluate rather than the entire test so assume for example that each mutant will only be covered by 10% of the test field then this optimization will give you a performance improvement of ten times which is huge it takes like well it's use anyway so then there's a usability aspect so I didn't get to show this but if she said a vertigo to run parallel evaluation then you have to instantiate a bunch of inertia networks and well this setup process shouldn't really be necessary I think and I think removing that will make setting up permutation testing a lot easier because you won't have to say that like for example 12 development networks the other part of this is that I believe Ganesh is not made to run the test feed like 500 times what happened on my machine is that it would create like a few million files which would use up the eye notes on my machine and it would break almost everything so with Ganesha network creation you could clean out after a test run and prevent this problem from happening and then we also have framework expansion which is basically means that I would extend fur to go to work with other frameworks which also are commonly used because currently we only really support truffle so then there's kind of three areas of foundational technology which support the development of mutation testing framework in general but specifically vertical and it's the compiler test framework and then I made a little category of others so first a compiler and so the solidity compiler those actually already does a bunch of things right for mutation testing so first we're we're vertically Jesus the sublimity compiler is in the ast it generates so instead of do forcing and analysis of the source code we can use the solidity generated HT to find specifically the locations that wanna mutate I mean based on the information in the HT we determine how we should modify the original file to get to the mutants since a recent version of solidity it's also I think six point two zero six two it's also possible to recompile upfront amount of ADHD so that would make the process even easier but on the other hand it would also likely require some more tight coupling between the mutation testing tool and a test framework because you need to be part of the compilation process the second part where the compiler really helps out is in the compiler equivalents feature which I mentioned previously so so I won't really go into it then we have the test framework which kind of enables almost everything of the mutation testing process because it's our interface to the project so the first part is the interaction with the unit test which is not optimal at the moment for mutation testing on because it's not as far as I know not easy at least to directly execute single tests or maybe a list of tests which I will which the mutation testing framework would want to do so for example the test selection optimization and the incremental mutation testing optimization would require this functionality I do think it's possible to sing out specific files to run so that's already like some improvement over the generic run the entire test week but but I think like a more detailed interface be super beneficial for mutation testing tools then we have the other part which is automation of test network creation and I think this is handled by some of the test frameworks or ieave frameworks but to a limited extent because I guess it's not a common use case to brown your test feed in parallel five times so that's probably why it hasn't been implemented yet to have multiple test different works being created and cleaned up all the time but this is also a feature that could be handled I'm head of the test Network and lastly there's this item of test evaluation speed where really any improvement to this evaluation speed so this could be like a compiler optimization a VM optimization or some other optimization also reflects in the performance of a mutation testing tool and then in the last category miscellaneous on detailed code coverage here because code coverage is can be handled by I think by separate tool called celebrity coverage and it's on the issue tracker for this project but I'm not sure when it's going to be implemented but this is one thing that would enable the test case election optimization and I believe some other features outside of mutations okay so that was the overview of mutation testing theory then what the tool does right now and what could be improved and how other people in other parts of the digital stack might help with the implementation of these optimizations and I think there's some time for questions I would also love to hear any suggestions maybe improvements on like usability or other questions yes thank you for your talk as you one already outlined we still have five minutes left for questions so feel free to raise your hand if you have a question and you are attending here in the chat room in the videoconference if you are watching the live stream please put your question in get a chat and we will be patient and wait a bit because we know there's a delay any feedback here from the room does not seem like it so far but let's give it a few more minutes to also give the people on the livestream the chance to react to this in the meantime just checking in with you and Matt in Europe both there already right yes I can see you and Nikolas wants to say something yes go ahead hi John we tried using a couple mutation testings tools in the urban sibling contracts every couple times and the usual places that did this really so large and the number of contracts so large that running the entire test before a single mutation doesn't make any sense do you think instead of having the automated like only run what tests need to be run based on courage if we could like have a way to very simply say only do mutations on this contract and there's only run these tests which would be a simple s provide a way for the easier of the library to write the desk amount where they could say I'll run this test that'll make it much more usable so that's either for disability I think you could certainly do that also protocol already supports the inversion out of this by allowing you to ignore certain directories so I guess what you could do right now is ignore everything except the thing you'd like to test there's no selection of tests implemented yet but I think I could but your question is kind of valid about like the duration on a project like yours and I even further go on well open sapling and in Aragon OS as well and it took well using 16 parallel processes to like two hours or between two and three and it's as you said a really long time but I I think that given these optimizations for example the selection and incremental evaluation optimizations that could be cut down a lot for example the desk a selection at 10 times speed up would decrease the time to maybe 30 minutes or so of course it would have to be evaluated to see if that's actually the speed-up that you would get but I think with some optimizations it should certainly become a lot more usable and practical to run in a CI setup or at least frequently yeah that sounds great Thanks 