[Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] okay it should be transitioning and the chatbox is talking about the winter barefoot full welcome chat box so you're feeling like you want to chat with the chat box chat all right cool let's get started thanks everyone for coming I think we have someone from all the different teams is it someone from solar parity here yes I was expecting Sheree this week maybe he'll join us a little bit okay so the agenda everyone has the agenda first we do client updates and research updates and a couple of specific things about the call and then that'll be about it who wants feel started with a client update I think you've been doing it a couple week Terri's from prison a few laps I can give an update is that okay yeah sure all right so um so so this couple highlights from our side basically we welcome keeping up and then kicking off lining our co-pays with the 2.0 inspect so right now every pretty much caught up we implemented the new stage calculation we implemented a new dynasty calculation and the only thing left is the balance recalculation related to the related to the FFG rewards on top of that we also implemented the validator service which talks to the vision note beard gr PC we implemented partial closure responsibility which includes proposal north when it's his turn to propose become blood a package is the pending at the station send up an extended blood back to the big engine note to broadcast we also implemented partial attached your responsibility which means the tester receives the incoming become blood verify the victim block is indeed the head vote on it and it's in that test session back to the B channel to broadcast and then a few other sightings we also referred our home base for breathability so which makes it easier to onboard newcomers we convert most of the blog and the stay processing functions into like pure function we we're currently using double DP at the same time what benchmark and other DB implementation to see what's out there and then and then and then we were share of I mean soup and that's it okay thank you about a look sir so on our end we've started planning the development of several libraries that will help us in building out the beacon cane and javascript so first we're starting to plan out a pairings library implemented in pure jazz we're still going to do research phrase before actually implementing it so that's still a thing that we're working on um the other libraries of course gossips up so we're still working on the research for that before we actually start writing code after that we're hoping to start building a deal with signatures library so that people could use bilis signatures in browser or for any other project we're hoping to also implement within that Billis scale will be less signature aggregation and lastly we're all open to build a verifiable delay function library so that people could use for a full delay functions for any project that they have even if it turns out that verifiable delay functions are broken I think it so being available on implementation and research project for the whole community I'm so that's Dayton and how about like like hell yep implemented SS said in rats and we raised an issue on on the beacon chain about something that we perceive as an issue we started working on block processing with focus on a resistance to attacks from people who are trying to basically boss us by sending a bunch of attestation records we raise an issue and get new shuffling and moving forward we've got more resources coming on to the project just exciting we're gonna start working a bit more on state transition logic trying to apply pretty serious rigor to everything that we implement and then we're gonna start working on some ancillary libraries I'm thinking this you know that big big types that rust doesn't have so from Erin yeah I can tell you oh yeah we've just been getting up to speed with our new joiners Nicola has been and Olivia have been working on Kasper analyzing latest Kasper and modeling it and looking for ways to test it out practically the blades who's joined the call has been he's been with us a week but he's getting up to speed with peer-to-peer protocols and looking at live p2p and I've kicked off a project with a couple of others to finally write some code for this beacon chain so we're just getting up to speed or that a little bit late idli because it's all systems go on that now great about Nimbus someone from Nimbus money given up to the Arctic okay Abby yeah sorry I was hoping mommy was on see him not there all right cook so yeah we've been implementing the fortress role so we have a part of that mummys writing here that he has a concern about using sequence of hash tables of heterogeneous types there's a discussion and easy research about that please check it out and the other thing the alt BN one two eight something that we might have to implement from scratch due to its licensing so we're exploring options there as well you know here mom is telling me that his mic is not working so that's all for from us what were you having issues with licensing around you said you had to implement something from scratch what was that because it licensing I can't hear about me I thought it was the ulti n library okay cool gotcha alright [Music] harmony is not here but they have they said last two weeks in working on state transition includes basic dynasty transition logic and Ganassi to be featured with committee shuffling a short time sup day doesn't included testers which are a part of the next milestone according to our roadmap during the previous column mission it would be great to outline an updated beacon change eb scheme which that was more suitable to clients but so while working on state transition we can pollution that requires more insight to get there so potential proposals on changing some of the state structure from the guy all next week next time I know after is here from parity if you want to give I know y'all have been looking at things that maybe not necessarily I'm planning it you wanna give any sort of updater intro yes thanks for having me um so for parity it was a bit for you we had some internet issues communicating what's going on a call so what's what status own party would be probably a start working on a new client for is 2.0 stuff but that's just an idea so far we have no resources allocated right now we don't have nobody actually looking into the spec right now so yeah that's basically how to sum this up what we are doing is we are having like team meeting and then personal team meeting in two weeks and one of again topics will be easier to point oh so that's it probably from Paraty side right now and more concrete updates will be available in a couple of weeks I guess okay thank you for joining did I miss any of the client Oh Python side of stuff implemented dice to change some work on justified slot being an attestation and I'm working on let's see there's some he wasn't people here do you all have any any progress you want of data son I don't love Alexes in the collar if Casey wants to jump in I think we've been very focused on preparing test the public test meant for lunch for DEFCON that's been certain but I know Casey has been starting a conversation around some chess / simulation and prototyping okay right yeah well she has an update he can loop done at some point okay let's move on - I guess the partially research we want to research does anybody here have any updates on the research side I mean there is the update that everyone already know it seems to know about which is basically that I am added to the spec for the dynasty updates and balance changes and aside from that I've been focusing more on I know things other than Casper in charting in the last week or so yeah so just an hour ago I think I found a way to simplify the Casper stashing conditions so as I was mentioning at the beginning of the call three months ago someone realized that the slashing conditions were unnecessary that they could be weakened and the city would still hold and they weakened the second special condition but if you do like a similar thing for the first condition as well then it turns out that like a very clean and unified single slashing condition comes out and it's it's kind of tight in the sense that it's maximally weak so yeah I'll be writing about that you in condition right after this cool otherwise I've been doing lots of vdf research so now thinking about some of the subtleties around the programming program program ability of the modulite so do we want the vdf ASIC to have a hard-coded modulus or programmable it's looking like we want them to be hard-coded at this point another thing is it's possible that if we choose the modulus very carefully or the modular very carefully then we can have huge gains in terms of reducing the number of logic gates in music so that would be very nice because it would means we could still have an optimal ASIC but it would be it wouldn't be very big in terms of diarrhea I've been debating quite a bit with brown on class groups versus RSA groups it's looking like yeah we'll go with class groups you know foul corn is also very interested in having ETFs as for the same reason as ask for I think this mechanism we haven't yet decided how we're gonna go forward but RSA groups is something also some new provers so the way that BDS work is that they compute the output and then in addition to the output that's a proof that is that is constructed and some of the provers well there's two types of previous and one which is the whistle Oscar Cooper which is optimal in size but it is optimal in terms of efforts to complete the proof and then what one which is super low effort but it's much longer when it turns out that there's some hybrids between the two which which are very much terms of actually building on own sake I found this this team called obelisk and they have this this service called Ovilus Launchpad and I think it's the guys from ASEA who went ahead and built an ASIC for their projects and so that's like a spin off of it and they're right now on the third ASIC and they seem to be extremely knowledgeable about the space they seem to have good contacts and they also share the same culture as us in terms of openness and open sourcing and all and you know we're potentially going to have one produce produced a report for for us specifically on the various tricks you can pull off in a performance ASIC and you know in terms and also in terms of specialized cooling there are things like nitrogen how much of an advantage can you get to use that I'm in touch now with so one of the new directions that were very seriously considering now is having a ceremony to pick the RSA modulus a little bit like what Z cash days you only need one honest participant and the modulus is secure as I said it's on factorizable now initially I thought it was unlikely that such an approach would be viable but just just a few months ago at crypto 2018 there was a very big breakthrough in the NPC's for this RSA setup it's like 10 times faster than than the previous construction and they could get it down to just a few minutes and one of the teams seems confident that they can extend the result about the Falcons without affecting performance that much so the the NPC will take a few minutes which would be amazing and then I'm also in touch with couple of modular multiplication research teams one in China one in in Sydney and they have very different approaches to dealing with applications and it so what one one works extremely well on on smaller bits bit width so they can do a 256 bit interpretation in just 10 nanoseconds and that's using some relatively old process 19 meter nanometer tsmc but if it doesn't scale as well if you increased the bit weight and then you have another approach which is extremely scalable but it doesn't work as well on 206 bit and so the question is how do they compete on these larger bit ways so I I'd like to have these two teams kind of try and compete with each other on these two approaches thank you it probably wants to kind of interject with a reminder for the substantial number of people here that don't have context that even if we take a kind of trusted set up dependence approach that were that the Casper ghost algorithm itself is designed in mind what's the idea that it does that it technically doesn't depend on the vdf working correctly to achieve the most basic guarantees of security so I mean if we do assume that the VD after that the video works correctly then I mean naturally a lot of the pram a lot of these you have parameters for safety and the kind of Tolerance this will be a several times lower and it'll be actually useful for all the lawyers who applications and so forth right we're gonna move on to some maybe some of the p2p research updates from sorry Jeremy okay I'm from Charlene video PPO see how we have done is mostly refactoring and about getting something related to the connections in the HP and the log aggregation so we turn to use go log on at the FS to trace things with open tracing and also the communication between go and Python and currently we have this idea to Restrepo for python so and it will also be possible to be used by other languages and to do things we're putting more efforts to start off testing our plans on multiple nodes you know larger scale and we'll also survey up the other options or sharp ear discovery because our existing on approach to discover the sharp ear might be not too scalable to when the node get very long the number of nodes get very large so remind me some other ways other approach to use as well yeah that's my that's our update I also got some results from simulations I simulated Croatian propagation in a single shot and the parameters that I used that were first a thousand nodes in the network so for comparison the currently theorem network has apparently about 15,000 nodes that are online once a day but they would have first fit up to all the shots so I think it's safe estimate and for bandwidth I use the distribution that I found in a paper that tried to measure this entity's distribution in the ECM network and they got sucked like 55 megabit per second on average and about 10 percent of the nodes have less than 3.4 megabit per second which I used just as a minimum yeah and I mostly looked at gossips up there and unfortunately I didn't really find anything that was too surprising that's just a couple of things I'd like to mention first thing is that maximum correlation size and that was possible in this network was about a three mega belt I'm given an 8 second block time so I think the one megabyte we are currently targeting if I remember correctly you should be fine also second thing is basically all but the slowest node in the network have bandwidth available at all times or almost all times and that bandwidth can be used for a sinking of XP for the white back of elevators and this is nice because it means that the length of the wine pack is only limited by basically the download speed of the validators and not by the network itself at least as as long as they are not too many the latest during this point back and last thing the number of key s that each node has does not actually matter that much on average and I got good results with PN numbers between four and eight and if you can go higher you basically risk that yeah the nodes with a lot of PS don't have enough time to send blocks out one thing to keep in mind though is that this should be of course proportional it was a bandwidth at each node test because otherwise if you have small note and a big number of keys and that's not good I also tested the push-pull protocol but I didn't really see an improvement over gossip so I don't think I will continue investigating this at least not at the moment because there's peer discovery I think it's the more complicated more important part if I look at now and I want to look this next i summarize these results in an issue if you're interested you can have a look I hope gonna post the link in the chat yeah but in basically a conclusion is that I like awesome stuff I think it's simple I think it performs good enough it can handle the load that we want and also that I blocked him that we want so I don't see a reason why we should not use it that's it great that's exciting to hear that your research is only more more solidifying that is the intuition rather than throwing us off questions I had is I wanted to bring up this issue that in the case where we have this a network with a very large number of participants and we are will need to say be aggregating something like fifteen thousand signatures every 16 seconds like basically has there any has anyone here done any thought to kind of protocols for aggregating messages from different getting signatures from different evaluators sort of step by step instead of kind of putting the burden on the entire proposer to download 16,000 of everyone else's signatures so in the the thought is to have kind of subsections of the network that are responsible for gathering and then aggregating signatures before they get to the proposer yeah basically things like that so the idea would be that every that there would be a subset of nodes that would just voluntarily out allocate themselves some random slice like possibly some multiple of 256 and then they'd be responsible for Granum grabbing grabbing everything within that subset and then they'd push it all along - whoever the proposer is but like I'm sure there's lots of different ways to do this maybe one could just basically everyone who wants to send an invitation can just wait random amount of time and see is there other stations coming in and then a great gate then this problem with unstructured attestation is that then you get you're likely to get a lot of address nations that kind of copy mess or that have redundant and invalid leaders between each other than when you ever done invalid leaders you can't merge the two anymore so one thing we can do here is that we can generalize the bit fields to be to allow for duplicates duplicate individual signatures so for example if you have aggregate for signatures one and two and and separately you have an aggregate for signatures two and three then if you were to sum these two you have 1/2 times 2 and then 3 you just we good but that would complicate the consensus all your significantly and like it feels like it would be a bad idea to just give up and go in that direction unless we have really good reason to believe that like that there is that some somewhere we dissolve in a network order well right like in the short-term it's it's Nautica it's not a concern because all of our test networks are probably not gonna pass like a few thousand notes anyway but like for launch we do need something right hmm could be thought about so here's one well I just came up with one interesting possibility which is that validators are separate segregated into shards already which means that validators are segregated into shard peer-to-peer networks already which means that we can dual purpose the existing gear to gear subnets in order dude in order to do kind of disjoint sub a groggy and then we can I think basically it published those republish those aggregates back on to the main peer-to-peer network and then have the pro Burroughs propose or grab them right you know this does require like a bridge dough and some kind of multiple rounds of communication and so forth which is basically my rationale for kind of suggesting increasing the slot lines for me to 16 but I don't really see a wage like it feels kind of fundamental out here that if we wants to sort of square root the bandwidth we'd have to double the latency or if we want to brew the bit the bandwidth we'd have to like triple the latency and so forth but that's still like an extremely favorable trade-off cool uh spend some time thinking about it between now in the next couple weeks definitely anybody else any other research updates I know some other teams actually I have another question to client developers have there been benchmarks on like the direction have there been benchmarks on how long it takes to verify a yeah block with I give assuming a given number of total validators so like for example if you assume I'm gonna know like 300,000 total valid ins three hundred twelve thousand five hundred twelve alligators so the number for ten million if then you seek that amount take that amount divided by 64 and you obviously get some somewhere around five thousand evaluators first wad so like how long does it just how long is it take for any of the implementations to be out by that kind of block I know the the Python implementation is probably we could probably pump those numbers out pretty easily and I imagine a couple of other implementations could as well so I can make an interview around that and whoever wants to do the benchmark can put the data there so we can look at it next time yeah sounds good and you know I'm not interested in like super high rigor I'm basically just interested in ballpark so I probably you know like the most useful thing for me would probably even actually the numbers numbers from both Python and like something like Prismatic for another fast language would be nice yeah I think it should know having to would be useful [Music] yeah yeah you know it'd be like just I just want to make sure that the kind of parameters that we're handing out or realistic kind of unlike in etherium 1.0 and it's here there isn't going to be kind of i/o overhead under and there are it's going to be her and that there aren't weird kind of quadratic execution surprises so what I like the average case will be much closer to the worst case cool any other research update I had do you hear me yeah yeah I had one question for Justin you talked about Aris modulos do we need to implement RSA we will use it or was it for vtf yeah it's only for the VCF and you know I say RSA simply because just like RSA you have this modulus which is on factorizable but the the only operation is modular squaring or modular multiplication ok perfect thanks hi Alexa here so I want to toss the question has anybody done any implementations of this sparse Merkle tree yet any of the language is because I was going to do it for something else and I was wondering if there's anybody's done it already I think there's one in go if I'm not wrong by let me post a link up thank you I think they also should be one in Python but I'm not sure how far that god I can find a link this way thank you very much what is back okay so I propose a yeah mole test format the creature is isomorphic with the previous proposed string format did anybody have a chance to look at that in your questions or comments online if not we can continue discussing an issue if anyone had a chance to review it can you post a link on the chat yes I'm somewhat happy with the structure i as I was writing it I decided I didn't really like yellow very much true like these kind of nested lists of objects I didn't think it looked very pretty but I'm not too concerned about that okay we can talk about it talk about it offline and maybe hopefully make a call on whether it's gonna suit our needs for the time being by next call in two weeks okay next just kind of e21 discussion if anybody has questions concerns comments that you want to address any sort of confusion that you want to work through and now it's a good time well was was that any discussion before about how to port or p2p to other languages or made available from other languages so the question how or when or if we should be supporting lid p2p to other languages yeah yeah how to make it a valuable from other languages right at anybody who's been working with what PGP have some insight on that I know the protocol labs are interested in assisting people in producing other implementations overhead status we've been discussing it in the possible implementation and name which would be very easy to expose them to see do town them works we would see which means that if that one were to be implemented that would offer sort of a C API to anybody in the can interface would see can use but that's it's it's nowhere near completely and also the main thing regarding that is that since we are still unsure about using leap p2p or not we didn't want to dig indicate a resource too soon on that right and that's something I want to talk about this week is based off of the research around the TTP are we feeling confident enough to to begin to move in that direction and to begin to develop around in these other languages so that we can begin to move in the direction of being able to push packets around the network between different clients which is definitely a goal in the short to medium term Ghana Kevin any other researchers want to weigh in on that yes as I said earlier and it was himself I like I know and I'm not sure about the discovery things I hadn't really have to look at this yet but for gossiping itself I think it should be fine cool so maybe we're not ready to make a firm decision but we are getting closer and closer to being confident about assets or being ready to move forward with Austin sub and maybe on the two to four week horizon we can become even more confident maybe even testing it I guess the existing discovery mechanism should all still work because if we start with a single shot that we don't really a big requirements on the discovery mechanism anyway yeah I actually have some thoughts on because lately TPM is gossip or other any other author and other components are returning go Java straight in rust but instead of other languages so I think on what Willy bit sorry well it'd be well it makes sense that if we have if we together work on some common code base for the p2p layer or and and like for for our current starting p2p POC repository we have we use G RPC currently to to send the data from go to Python and also from Python to go so I think if we if we have some common endeavors some on the same code base and we can just and also to use this code as well this is what I think the protocol labs guys did for ipfs you can use ipfs from different languages and they provided a HTTP daemon to read you connect so yeah maybe like Kevin said we can't do something like that sorry sorry just a note that yes in shortened the Python implementation will use to go implementation p2p layer but for the long term our foundation is calling for the Lippe python implementation as the Grint so that's the longer long term plan for us thank you right in terms of right like these solutions where you can talk to an existing implementation and another language are probably good measures for the time being I'm very close to being to being able to say like if you want to build out an implementation language like what let's go for it because it's what we're gonna use no that said I guess the research team isn't saying that a hundred percent yes it's saying that like what ninety to ninety percent ionic 95 percent yeah I don't know the nineteen that you find something to connect this yeah so you know if you have something you want to open up and begin to look at and what the implementation might look at like might look like and it's probably worth beginning to investigate a little bit harder than we were past couple months okay so almost a decision on that not quite a decisions getting close any other z21 stuff talked about so basically there's this registration contract on the main chain and you passing parameters such as public key char ID and in withdraw address and the fourth one is the Bo as proof of procession how do we generate that so there's a standard formula for that I think for now like basically just use the key it's a sign a hash of your public here I see gather and that the signature needs to be it can't be the same type of signature correct I I think it might be that like for the Hashi one needs to use some different hash function oh right right okay and we're we're almost certainly going to be verifying those parameters on the beacon chain rather than inside of the contract and so the beacon chain is going to be able to support the main hash that we're using and also some sort of auxilary hash to verify that have we decided on which library to use to generate the private and public key so it's a new way you think as far as curves go it's either bien 256 or BLS 12 381 and then like which library to us is gonna be different for different clients cuz there's different ones different languages I see cool call do you want to bring up the shuffling thing I didn't have I didn't have a chance of swearing to dig into it but we might be able to figure out yeah so I was looking at new shuffling and I'm just trying to figure out I guess what the motivations behind that function are I can see the first thing it's trying to do is its kind of spread out the validators across the slots evenly and then I would assume that its next goal after that is to try and ensure that every shot is attested to but there's some cases and I made an issue for it where like it would be possible to spread the validators evenly across the slots and then form enough committees that are above minimum community size or on it and attest to every shot but it's not actually doing that it seems presently to be targeting a committee size of two times men committed sighs have any comments on that yes so I think VM the reason why it's not so it definitely is about targeting two times main committee size the goal right but basically the intention is for it to for the king for for the men can be decides to be a mini committee size and not a targeted committee size right so I guess a number of a leaders approaches infinity the the committee size definitely should kind of stabilize us coming very close to twice the minimum okay sure so if we have like ten shards we should be focusing more on on making sure that we're on two times being committee size then then we are trying to attest every shot yeah basically okay sure I guess what what I wouldn't mind doing just from a like a software perspective is just trying to write out some requirements for it just so that I can I can kind of clearly understand it and test it so maybe I can try and I can try and work on that and I can get some feedback from from you Vitalik and yes researches yep definitely sounds very good yeah okay great thanks for telling I looking at validating a block when it comes in specifically I've been trying to make it so I can kind of like reject a block as quickly as I can once I figure out that it's invalid so that people can't Doss us basically so one of the things that I'm thinking is you know someone sends this is block and it's got you know a thousand of tests a station records and it takes us some time to to validate those and and during that process we we figure out oh it turns out that the block produces signal just wasn't in there so I don't like it it would be cool if there was a way that I could really easily like first go and say you know did the block producer sign this block is that something that exists already who if you know one thing that we could do I think is I'm not even sure if it's in the spec yet but it should specifically be the first at the station in the West that contains the a block proposer and oven size by two times main committee size signatures right so the cost of verifying like well that one as a station should be very small also the the doubt the validity rule for the proposer signature is actually that the parent proposer is included but I shouldn't I shouldn't process a block unless I've seen the signature come in on the wire so there's these four conditions before I process the block and one is like being in the correct spot time but one is that I've received a block and I've received the proposers attestation along with the block and if I haven't then I shouldn't even process it because what was that well just seeing very good point there yeah right so by the time I'm by the time I'm processing but but correct correct you could still add the ordering of the parent proposer is the first one because that's kind of like an obvious certainly what I was thinking was putting it in the first slot so that sounds great I think that would help protect us from some attacks so Danny you talking about serialization do you want to talk about serialization or you want to leave that yeah yeah I'd love to um like I kinda wanna I'm we're getting close to making the slip PTP decision I know a couple weeks ago that you presented some results around using temporal serialize for the wire serialization protocol and I wanted to check and see if anybody had any rebuttal to that or some alternative ideas so that if not we can at least make the temporary sensitive decision like this is what we're going to do any thoughts on simple serialize and why we should not use it as our wire serialization protocol the flights but I think that that like I'm not sure if that's even necessary and if it is it's just like you know some function we can put before and off to the serializer that should be pretty easy in the future if we decide we want to do it any other well had a couple things that we wanted to make decisions on today anything else Oh discovery protocol it seems like we are not ready to make any sort of informed decision on the discovery protocol and that's something that Yannick and some of the other researchers at the time on soon so looking table that decisions cool any other v21 and points of discussion since we set on super serialize should we maybe create a test repo so that we have a reference tests for super serialize maybe using your new AML scheme yeah the yellow scheme is very specific to the slots but you're right maybe it should be a little bit more generic in the way it specifies to us I'll think a little bit about that and and yes we should certainly have a standard testing serialization for this so good idea if anyone starts on simple serialize I open an issue I can't link just in this area and this issue number 92 there's just just an issue I race whether it be worth looking at if you're on if you're implementing it it's a small thing and then so I'm looking at this right now and oh I see okay yeah so let's see it okay so the length of the thing so I definitely personally prefer zero as a number being a yes like translating into empty rather than translating into as the translating into a zero byte like it is it is cleaner in a bunch of mathematical ways like specifically it preserves the like it makes a very clean invariant that says they like a very I got a number what I would always I just always can't begin with so with any zero bytes let's see him once you realizing is here okay yeah it does seem like option B is the thing that makes sense so wait hold on actually sorry one thing I realized here is that I think there might be two things that are called symbols he realized right yeah like in this Pikachu right notice I I remember I wrote like two serialization libraries where one of them is like this very simple version of our LP except instead of the big all of the complexity around our LP you just have the length prefixes are always exactly three bytes long and then there's this version of semper serialized where you try to avoid length prefixes as much as possible when you're serializing things that have static lines and for this like you're like the serial of into the serializer is specifying a type and so in 32 as a type it's a four byte long type and so it should output to what it outputs yeah so I think it might just be a name collection issue yeah for the record I've been using the one inside the beacon January 5 I've been ignoring that other one right yeah yeah no I mean if you're using the one inside the beacon chain repo then I'm pretty sure the answer is correct right because it's like the point is that because it's in 32 and in 32 is always have four bytes then you know it's just going to be four zero bytes like the the one inside the beacon chain was basically designed in order to really optimize for the ability to assay to have direct mappings that say like the 780 v bite of some particular value corresponds to this item of this array of this variable of this struct of this V inside of this array and which basically means like and that's intended to kind of speed up blog processing basically because you know theoretically like in some optimized implementations like you would never even need to serialize fergie serialize a bunch of things you would just kind of use the data structures as is so but it definitely sacrifices on kind of space optimality in order to achieve that and so you might want to compress a make a compression wrapper eventually yeah you can just kind of pick variables out of there and deserialize them one by one which seems really great I didn't quite follow on the I'm not maybe we should move this offline into the into the issue I'm not quite following on why you should say something as a length of zero if it's if it is a length of one I'm not saying you're wrong I just don't follow maybe we should take it off now so I basically by my point is that in the version of simple serialize that's in the beacon chain if you're specifying the type so in this case you're specifying in 32 then that like the length isn't anywhere in the output right the okhla just depends on zero so like if you specify like zero and then as the type you put in 48 and it should give you a 6-0 bytes instead of four okay right here sit so this so this is actually wrong and it should be giving us full byte size right is that right no no it's it's giving you four bytes and it should be giving you four bytes but on the first three bytes telling me how many bytes there are no that's only a property of the other symbol serialize or rather sorry that's a property of the other symbols you realize and it's also in the beacon chain simple serialize that sort of thing only exists in the specific case where you have a variable like data types but in 32 is not a variable in Thea type so you don't have it in any case for this piece of tea musician because I really like simple sterilized when you where you can just jump into the data structure at and know that the data starts there we can just use a GZ or LZ for snappy compression on top of that you reduce the space yeah yeah if you do snap your or any kind of compression or does that differ from parsing a format into a binary representation which is convenient to you that's what the decompression becomes at that point I [Music] guess that's true but it achieves kind of clean separation of layers because like ultimately our or our garlis and so like that's basically happened with the theorem 1.0 grade and so it makes sense to kind of have try to keep it at one level of a decoding instead of two levels of decoding all right and the other thing is everybody if we learn an expectation of decompression using one of these algorithms we'll have to look at attacks that of the kind where a small number of bytes explodes inside [Music] those kind of yeah and what definitely it definitely would be good to do that kind of study of snappy but I definitely think that they're kind of fundamental scalability of the protocol does not like doesn't depend on any of that stuff like not compressing at all should only cause the bandwidth sufficiency to maybe be I kind of knows two or three times higher than optimal will there be any formal specification of simple serialize so that we could all implement it according to the specification or our just depending on the Python implementation that's in the beacon chain repo but if we decide we're using it then like we could definitely work on a specification yeah well we'll target getting that but right now the only thing maybe just in the container though I was probably gonna pull that out and be its own library as well um so kind of be independently used by other projects cool any other v2 one things to discuss okay and we kind of dynamically did the next Jason the agent now just try to make some decisions the other the next thing I'll you know just kind of open discussion questions remarks before we just posted only free search fashion condition and the link is cool going once going twice anything else all right cool I haven't really looked at my calendar but I think I don't think there's anything anything big that's going to prevent us from doing a call and two weeks from today I'll get to call it notes soon and then I'll post an agenda for the next one as well thanks everyone for coming you thank you thank you [Music] [Music] [Music] [Music] [Music] you [Music] [Music] 