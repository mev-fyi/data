[Music] [Music] [Music] [Music] [Music] [Music] [Music] [Applause] [Music] [Applause] [Music] [Music] [Music] okay hi everybody I just switched over on the stream so we can start thanks Lane for making the agenda lanes gonna be helping me out Lane ready for the next at least couple of times and potentially be my backup or just kind of take over as far as running these meetings we might also just do them together you know have a collaboration going so yeah everybody 'welcome Lane he works for the etherium foundation kind of Foundation wide thank you great to meet those of you I haven't met before really excited to be part of this and please go easy on me because I'm pretty new to this whole process take Hudson good luck great thanks Lane so let's just get started on the agenda the first one is the EIP decision process and a general update on that so we've the EIP editors and other people have been having discussions on what the next steps forward are as far as what changes need to happen to e IPS and we think the best first steps are the following making a chatroom making a reddit post that we can link to Twitter and other stuff at a chatroom for people to discuss changes in governance there's already a governance channel and an e ip's channel so we'll just have to figure out which one of those we want to use on getter or I also heard maybe a discord was being set up so I'm kind of investigating what everyone's doing but the main point is we want to have something that everybody can use pretty easily to communicate about changes they want to happen additionally there is a group called the Fellowship of ethereal magicians they're gonna be presenting a workshop at FCC and I'm gonna post kind of a link to their document but it's basically yeah they talk on the governance get her a lot and they are a self-organizing group to maximize technical opportunities it's something that Jamie Pitts and Greg Colvin have mostly come up with and I'm gonna paste that link in chat and Greg if you want to say any words on it feel free yeah good morning think of it as an IETF for aetherium ITF for those who don't know is the internet Engineering Task Force it's a self-organized group of engineers and scientists under technologists who basically keep the internet running make sure that the that the consensus is reached to make sure that all of our all of our equipment speaks the same protocol and and here we are great so yeah necessarily the only thing that we'll be doing but it's definitely the only group that's so far come forward with you know some types of proposals and things like that Alex what were you saying did you think yes it's a bit whimsical but it was more fun than technologists engineers things like that yeah I liked it too instead of pulling rabbits out of hats we pull I don't know sha-3 hashes or something someone needs to cup the better joke geek X yeah there we go anyways so that documents there for everybody to kind of take a look at and comment on additionally we're going to be we're going to be you know having that meeting at FCC we're gonna be having discussions in a chat room I'll be doing a reddit post to invite the community to participate and hopefully we'll get a few things changed maybe not a full overhaul or anything like I was kind of thinking we needed before but something something a little bit better if things work out the large immediate colony Oh Casey just posted a link to a forum Casey what's this I think it's it's the discord forum that was set up or discourse excuse me it could be premature we're having we're still having troubles with the ISP but it there I think it's working the if you try and hook up the email it isn't it isn't always working I'll leave the link off for now then until I know from Jamie it's working all right here in publicly I mean yeah it was shared in the public a ip's room okay okay we've had trouble when you try to bridge it to your email it doesn't it doesn't always work when you try to set up your login it sends your your confirming email and it doesn't get to you okay sounds good well I'll definitely put this on the post when I talk to the community about this if someone doesn't do it first so yeah that's pretty much it okay cool anybody have any other comments on this well my comment was nothing face did I think it's a bit sad that you're a chippy that he shouldn't be I don't know what if he doesn't take part in the kind of governance process anymore think he should so I I missed the last part of that but you're saying yo et should be a part of these conversations but he seems to have chosen not to know so my understanding from talking to you each he is he's still figuring some stuff out personally legally and I don't think that for my understanding he's completely against participating in the future I think that at this time he just is choosing not to from my talking to him until he gets some more advice from from legal interest other things in his life so I think that it's not that he'll never join again because I did check on that to make sure that they're everything was facilitated for him and everyone else in the meeting but yeah I think there's a chance he'll join in the future and provide commentary I always argue every every objection and not every comment but Nick comment on that sure people can give me all right the I mean the sort of true points to be made from them one instead we need to be careful to distinguish between writing the standard and adopting it writing a standard is a technical process that needs to have domain expertise and we should be trying to make it the best technical stand between and that's what the IETF vrsc when I went to talks about and with something with people she really read because it makes you really good points about how consensus is not about majority though it was not about nobody objecting it's about making sure the very technical concerns people have raised to be resolved remain either these are fixed in the standard or them to be and the way the ietf does that is typically that the chair whose job is to Emily's furniture and instead of a basically assisting the second one is there but I'm muted around one unit you're unmuted oh you can hear me now yeah I can hear you now if you could mute while you're not talking though there was like motorcycles in the back can't can't to zoom operator manually mutant somebody to yeah but they won't know when they're muted well they will when they talk and nobody can hear them so anyway I think they should be really explicit about the thing but writing Andy is the standardization process and doesn't it's going to be adopted and a handful for the network simple process we need to be explicit about what companies for adopt images I think other people make a good point that 15 y/o jihad for well as the ultimate governance mechanism is you know blunt instrument and so maybe we need a way to get reliable community consensus on how popular a proposed deep is or for short of publishing the whole thing's letting people choose human plan okay I think that's definitely good commentary and yeah so you're saying basically firm up the process of what is considered merged and basically the technical requirements of EIP editors so that it doesn't become as political that's kind of what I read from your statement that and make it clear to everyone involved that the IP interesting is a technical process and that anyone can write a standard and that's it's well we're submitting the participants of consensus on should be merged but that doesn't mean that it has to be popular I could write a standard for you know the best way to grind kittens up into the Rito's and if it's technically well worse a minute should be accepted okay great any comments on that yes I mean this came up over over the proposal for an ERP YUM you know an ERP format and you know partly there are issues because you each he was concerned if he was legally exposed um and partly the thread just became about whether or not we should recover funds and that was not what the proposal was about it was how should we do it if we're going to and we've had a very hard time distinguishing technical issues from policy issues and we really have you know we don't have a good way to keep those separate and and those of us who are a IP editors have been trying very hard to simply maintain a process before technically putting out these proposals in a clear enough way for the community to to implement or not implement them and it just makes it impossible well difficult to do the work of editing proposals if we're just overwhelmed with debate on on the wisdom of the proposal down the line we're just trying to get a draft edited and merged into the system so that the debate is possible here is a document this is it's the IP number now we can debate you know whether implementing the CIP is a good idea um there really shouldn't be huge debates about should we assign the CIP in number and call it a draft that's that's a technical editorial question it should not be so hard and so contentious yep I agree with that last link I'm gonna post in here to everybody this is a really really nice article about rough consensus that Greg I think sent out on a different chat channel and I really liked it so whoever is actually the author of that um apparently saw an interview with me inclined xed and out of the blue I got that in an email saying you might find this helpful yeah any other comments on this topic before we move on oh let me make sure okay cool yeah perfect just just one of the things I found interesting about next read was the idea where you should we should try to separate comments from arguments the idea being that you can you can merge things once every objection has been addressed and it's I think it's hard to do that exactly because you can always like try make the same objection in a different language in a different way your earth and say your objection is new just because it's slightly different relation it would be interesting maybe two to one oh one of the ways to do it would be to add an obligatory section on every a be saying objection responses where you would list every one of the main objections and you will address it somehow and I think that that could be that we could be useful and the second thing I'd like comment is on Greg's nation on separating a draft from our Trouville I think it's I think it's hard to do it I I agree it's hard to do it because if you make a proposal that let's say someone things that is inherently a bad idea nobody should adopt that standard then you clearly them on that to be a standard right so I think I I don't want to come like AI want to go into specific examples but I think it's it's obvious that if you think that any implementation of that Center it's bad then you are agreeing with this standard as a whole but maybe we could make that clear by having bootiful states of food right it's approved as a standard the workflow is clear you go from once against a draft it can be deferred it can be rejected it can be accepted but and until it's a draft it doesn't have an EIP number and it's not you can't even refer to it in order to make these arguments it's just a nebulous you know you can argue about it in the community but in the EIP process becoming a draft is the first stage to even have an official document to argue about and if you hate it then you argue that it should be rejected although the point I was trying to make earlier is that if you hate it then you argue that it should never be implementers that doesn't mean it can't be in standards it just means that you don't want it on the main Ifrit that's an interesting point and that's why we need some sort of deliberative body where we can have these arguments in a civil deliberative way um and comment threads on the on the EIP pages or are not the best place especially at the pre draft stage you know once it's a draft the debate can spread out into all kinds of channels that exist okay cool I think we can move that point to the online theory magicians discourse let me post that link actually at least in the awkward dense chat okay great awesome anything else do we want to tie in any of the dialogue happening in the Kidder channel here like for example the talaq mentions just now but we have the carbon growth system that's been used for controversial topics in the past I don't know if you have a husband around linking the two threads or not I just saw that yeah so someone mentioned Tim I think you mentioned something about neo voting what is neo do yes I went to their conference it was in San Francisco and they recall it they have like kind of like electoral system kind of like in this stage so they have different basically they have like public people that verify their addresses and then they have like a more authority or more voting power with their votes so it's kind of like a hierarchy voting system where the core developers have more say in the total votes kind of system in general I personally just just like the idea of like involving any kind of coin votes for everything because they like just people with a lot of es are not the kinds of people that generally tend to have got a particularly strong technical opinions so I mean for stuff that's kind of cue controversial and feel like you feel it fails to pass kind of either fails to pass absolute developer consensus or where we recognize that there's just actual trade-offs and you can't like technically say which trade-off is correct because the depends what the values are and I actually think that you know like as much as the carbon vertebra or problematic in those cases are one of the kind of a least that mechanisms that we have around at least income in combination with some of the like various other kinds of community polling but I mean I do also feel like our currents sort of de facto approach or aware that sort of stuff as has only really been invoked for stuff that's really genuinely actually controversial like the d√°il for candy issuance reduction might make more sense and using it for everything yeah yeah I agree about that as far as like the people with a lot of ether being able to vote well the program is proposing a new mechanism is because we have everyone start like we start getting into more complex and interesting like algorithm is like prediction market feature markets etc and the problem is that most of them are still untested so it's a sort of argument where we it's sort of an argument where we can say okay so let's wait five years and until war to better tutor or made and better tools are available when they are tested for smaller things that you can use them for bigger things so I think that's that's my view on on any any unchained voting stuff that most of the nice ideas are not tested yet I mean technically the carbon vote it has been tested twice which is why it's like I think it's like obviously hazards for us and we shouldn't listen to it as a sole signal but it is you know what what one of several like some okay toll since you as long as you recognize it's only one of several yeah about hundred people maybe were responsible for 80% of the of the of the voting power and I think that's that's inevitable because of the of the Pareto distributions of tokens in general and because a lot of people are a lot of smaller people will not care to go there and do the voltage they don't have a large eater maybe maybe we could model is like the World Wide Web Consortium w3c and kind of like how they're able to like you know like implement web assembly is like a protocol specification and then start to the clients to adopter that yeah I feel like as a thing gets more popular you guys will just get more like random feature requests through the eyepiece death seems to be working so far what you guys have been doing yeah well just to repeat what I said on skype was the problem with prediction was that for any curl any of those designs to work we have to agree on objective function and like some people might say the price of user but I my impression of the etherion community is that it's not just about trying to optimize the price of ether so it's sound like once you one move away from just from like having simple numbers they can define what your objective is actually does become hard for prediction markets for themselves to say what's a sensible decision and I definitely and I will kind of say about any vote any governance mechanism other than kind of fairly simple votes and also totally on deathbed zoom returning to that returning to a Nelson idea like two or three years from now when you know we assume like make her guarantee or three other projects you would have ended up working well for them that's like a longer-term yes a short-term prediction markets are not really an option for us it sounds like I mean I actually personally think that in general our governance mechanism house so far as it is the as it is de facto well is really not that bad probably the main flaw is actually not so much in what the mechanism is as it is and how we communicate it so like you for example the biggest points that we've seen in regarding the standardized recovery is like not that like it's basically that by apparently getting annoyed getting merged like what basically the the impression that a lot of community members forgot from the outside is that it's a lot closer to being words or being like actually implemented or like actually finally accepted then anyone involving involved in the decision-making process actually intended the signal but it is yeah and we can fix that by having notes at the bottom of the PRS that says although this is becoming merged that does not imply that this is any more closer to accept it it just implies that it has been moved to draft status so that's kind of something we can do until the process becomes ingrained that even though it's myrrh it doesn't mean it's you know necessarily close to being accepted just like VIPs read yeah and like I people basically direct people to actually look at they look at actual developer sentiment and actual community sentiments and them rather than at least like that as an arbitrary marker just briefly I see a lot of people advocating don't formalize them because it will be subject to institutionalization and capture and so on and my concern is that not formalizing something just means that those same pressures exist if they just release transparent I think ad hoc government systems aren't actually more secure it's just harder to tell when your yeah I could see the point both ways but in general my personal perspective is what I do for most things in life which is everything in moderation so in general something needs to be at least somewhat formalized just like we have these meetings and we schedule them but you know having something that's super strict would probably be a strain on those involved in silence some voices and perspectives yeah and I generally agree like having these having these calls is good and having the ability for these calls to kind of to give different levels of indications about whether about the status of the area these is good but at the same time like if all of the participants of this particular call decide to approve any API if it's really terrible that you're not actually correlate with a hundred percent chance it's going in like irrelevant so someone open a new your European also I think sort of as a joke but the potato was standard response for for recovering Forex which was basically saying that it's a new standard where the standard the rest and the response for that other standard should be always and I think that I I think that was a joke but it's it's might be a good way to show that when standard doesn't you can have like controversial one standard engaging the others and both can be approved to the draft status yeah and I agree that's definitely a clever way of kind of undoing the signal any other comments okay so the next topic Constantinople so last core dev meeting we looked at some of the e IPs and we determined that the following a ip's could definitely go in VIP 145 for bitwise shifting I think did we decide if block hash refactoring was was something that definite or was that a maybe yeah I wish I could find the notes for this someone else worth than it was last week I don't think there's one complete implementation of that let alone two yeah that's a good point so we know 145 s going in at least because that one's pretty much I mean formed not not necessarily fully implemented or tested but formed and there's some test cases that are recent so let's go through some of the other a IPs again especially now that we have someone to represent the research team with metallic to kind of talk about some of these so II I p210 block hash refactoring my understanding about this EW is that let me paste the address of this inside of some of this enough my understanding about this is that it is something that can help us it's a it's an on chain contract and therefore it can help us kind of practice putting it on chain system contract on there before we do caspere which is another system contract is that accurate metallic yeah on chain contracts training realism people only purpose of the EIT but it's definitely one of the benefits so the other benefit basically guess that like you gain access to walks that are much further in the past which is a good thing for just both various kinds of applications that want to do things based on black ashes also a certain kind differently genomic white clients and also like certain kinds of proof of work based my clients so what you did treated it allows you to do things like having a version of Gathol light that does not depend on the economical hash cherry and just to recap of the talked about last time so basically it will replace the block hash of code but work the same way but it also has the feature that you can vote the contract directly to a call and thus gain access to more than the last 256 block houses is that correct yeah yeah so it creates a new contract and then contract like what you access all the Box 256 back then skipping back to your T six of the 65536 back and then skipping back 65536 after choosing 16.7 be also 0 to 24 bag so it basically means that you can access any previous block from the current port in a manner most lyrical ops so is this something we want to put into Constantinople and would what what's the level of difficult implementing this and that can be answered as far as different difficulty and there is already an implementation with like that piece of EDM code right so it's even basic we were just wants to write a hold on a whole bunch of tests for it and then I know I think it's already been already been implemented in at least a couple points it's just like basically sitting there with a sports number of like student 100 identify that so far it's never going to happen I want to only agree otherwise okay is there anyone else in favor of this or who have a strong opinion against it I don't really have a strong opinion but I would also estimate that it's not that difficult to implement in the client but then I guess the actual code that is up for deployment no that's finalized yet though I would like to see that the specification being finished but it's kind of hard to get it done I don't know why but like I write some comments many many months ago and still didn't get answer to them I think that should be at least merge as a draft so I can place direct requests to fix some small issues because now I have pre quest requests and nobody actually can review them so if that feels if that fits what we described in the beginning of the call I would recommend murdering the current document with the draft status and that would allow me to yeah to to propose small tweaks and also include unit tests for the contract itself as additional requesting a piece okay so yeah Vitalik if you can just make final changes to that AI p and then merge it over the next few weeks we can then start making tweaks to it to see if so I'd be happy to like if everyone else me you mean at Yeti 210 right maybe just like walk through it again and I really like if other people don't see any issues then well actually maybe I will be good to also have some more someone independent rights and passport and when basically I would ideally prefer not to actually merge until there is you know a very very high chance that the EDM code exactly as written with the correct EVM code so so I would like to like make it actually the opposite because now it's hard to actually propose the code changes there so there is at least one back I think in the contract and like it would be easier if there if the document is inside the repository already and I can send requests to it instead of having that mostly in the comments and all of them are in the same place instead of having individual issues addressed as separate for requests and so on that's the member home and Roseau G or what yes make it more convenient as a draft one and also there was a comment I don't remember from who but there was some comments accepting that as a draft and it was marked in comments as they're ready to be merged by AIP editors if that's not what the process we want I opened to the chain together but that would I recommend at least for this one so it seems to me personally more clear how to actually allow me to actually focus others to particular issues there when the comments in the the order request are just lost because of them and nobody is reading them at the moment okay I like I like idea so to summarize it's basically finish the draft merge the draft so that you can then have a PR where you have changes made incrementally puddle yes okay before test cases are done because doing test cases before something is completely written would no I will include test cases for the contract other other requests as well so that's something that people can help with and put in the comments or just give to the talaq so he could add them well no I think point is to merge it as a draft so that sembly up pulse communes submersible increase the key contains test cases and so on because that sort of collaboration so as possible as it's already register struck ah gotcha okay Vitalik does that sound okay yeah keep up with some of these two dues and send them out to people the next one is e IP 168 and 169 killing dust accounts so we talked about this last time and it looks like 168 is to actually get rid of the dust accounts 169 is to have reprieve protection for that for one replay protection for 168 I believe that there were some benchmarks performed that some people did Martin did you do those or did Aleksey no not me Alex today and also Andre is down some Russian rentals and I think summarize it is about 10 million accounts I think roughly or a bit less than half the accounts and state are zero cerebellar - okay I see the link now I'm gonna add it to all the chats yeah I wish I would have looked over this before the meeting but I think I can just quickly look at some of the charts the best threshold is zero a it does not create problems with destroying of someone's money but it does introduce the possibility of where you play attacks which can be mitigated okay so anyone have comments on this so far is that something that should be going into Constantinople is it important enough I would say as a short-term thing it's fine though let's see one of the statistics on it again again I'm actually looking for Andres findings right now is he on the call I think Andre did his graph was roughly similar to the one that collects I did I wanted italic we're gonna say it's fine do you think that should be in or do you think well I'll use my under the only to determine how many speech we nodes rather than accountants would be cleared okay so the no accounts would basically drop basically drops by half as soon as we do even one way and then if they're at shirt so if this one seems to stop at ten gray is there one that goes up that actually goes up to like four 427 mmm basically keep it but I'm not as much Indian like that elephant concerns about distracting destroying people's money or really that relevant because at the end of the day like this VIP you will only don't delete your money if at the end of a transaction your accounts Hausa lessons what do you want that was in finance a gas price which means in a worst-case scenario the worst thing that this accountant possibly or the worst thing of this yet you can possibly do is increase the user cost of a transaction by fact by a factor of 2 minus epsilon so like even as as originally with phobia or experience be you're veering or variance key I'm sorry I prefer variant be it I think is it's what we find how can I determine what's a gas prices yeah so once again like the thing that's important to stress is that you do have this kind of destroying variant but this yet you will not increase the cost of a of a particular transaction by more than a factor of two alright but what I'm asking is how does it know what the gas prices in order to determine their threshold when you're actually doing a transaction you know what the gas price which means actually as we even have an awkward for that sorry right and well in that case one teacher concern is when people fumble finger sending a transaction was ridiculously I guess priced they risk losing twice as much as they expected to or they should have yeah there's also the case we have a malicious miner who - one lakh with extremely high gas price just I don't know yeah that doesn't matter in this case because it checks the gas price of the transaction the clear key account to determine whether it should delete the remaining dust I was there Zola when you but this is whenever you touch an account right I'm sorry I didn't understand why it doesn't matter I I thought it was only you you seemed from an account no because now we know new base is never we will update the clearing accounts well we can do a one-time clear out for existing ones you can't really remove 10 million accounts in one go with static tax touch them over one love hi joined the call hi I'm a middle all my was like waiting for the YouTube channel but it looks like he's not active so I decided to join in on dinner so yeah what I was going to survive is that I think if if we have a dynamic limit where we clean out stuff I think that David hairy and potentially subjected to attacks so I would feel a lot more comfortable if we set a hard limit as protocol parameter and then we'll some future hard work I mean if we start setting it to 0 and then sometime later set it to 100 shabbos or whatever I think that would be more less risky approach it's also questionable how much benefit clearing the dust accounts would actually have because according to Andres post without the full database size is nine point seven gigs with dust without dust seven point three gigabytes so that's only a two point four gigabyte savings I know during the the state bloat do s attacks they took up a lot of size but yes like I think control is important for multiple reasons one of them is definitely saving raw gigabytes another one is reducing fasting time a third is that the bigger the state is the less of it it's possible to keep in memory which makes the idea wasn't axe worse if we ignore the best accounts we could do the adapt to say much more simply couldn't make I didn't catch that if we if we say you know we're not going to attempt to clean up existing dust accounts but the rule from now on is you know that your balance conservative at least if it's the one transaction live then we can do the dynamically adapting thing without risking our tags that'd be a good in-between especially if we can't decide if the savings are really worth it right now for the risk and Casey did you have another comment it was just that the the nonce replay protection scheme might also make it more difficult to do later charting approaches with with nonces and and and Merkel proofs so in mind that this entire scheme is like not even going to apply to any of the abstracted accounts at all because the abstract they cancel are going to have code and that's even if we do a count abstraction in the first place right yeah I mean I guess there is an argument that like if we do account extraction then this won't get rid of a quarter of the or whatever of the current state space but yes we look three years from now the state space is going to be like three times bigger native extracted accounts and the eventually gained illegal accounting I like seven or eight percent which you know like that's the only time this would be better spent you know making tests for FG better or starting or whatever mmhmm yeah so far this EIP kind of seems like there's a lot of mixed feelings on it for one and number two that it you know the the time like you said could be spent on other more important more important initiatives so that's kind of the feeling I'm getting from just all the conversation today that does anyone have other comments on this so yeah there are intermediate versions that we can consider as well so like one example is that if at some point we end up upgrading transaction format so then that would be any kind of great opportunity during which you can do without worrying about really protection issues so like at that point of like the it was maybe two three times simpler to implement and yeah one time I found clear of some kinds which would make it easier to actually do well I've got a longer-term thing um I have a question of that eight one six nine how do you sign a transaction it seems like you would have to know which bloke is going to be included in another sign no because like remember that when when in account an account going from broad existence to existence is not something that offended that that the owner of the account can do because you can only send each transaction from an account if yet defer to pay for it which means it can only send the transaction from that account that already exists which my show is one other people so much' to it yep okay does anyone want to advocate strongly for the CIP what if we I mean as a as an incremental step we could implement one six nine without ones excited initially so kind of like what you were saying earlier where you implement one six nine so that in the future we don't have any more bloat but we keep the previous bloat well one six nine on its own wouldn't prevent load but it would be it wouldn't meet the new nonce scheme which would give people a chance to adapt to that and and so forth because currently people get nonces by things like no gate transaction account so we could implement the new non scheme and then in a later fork I mean dust cleanup which requires a that sounds like an interesting trade-off between the amount of time spent implementing these II IPs and plans for the future or not a trade-off I should say but it sounds like a good combination anybody else have comments this is a kind of abstraction supersede this one like if you were to implement this would it be useless after the kind of abstraction is implemented the teller can confirm that I believe the answer is yes yeah but Alec you're on mute if you're talking it showed you talking for a second sorry what was the question yeah is just uh is this yet people just clean up there's a kind of abstraction Yeti supersede this one like what have you wasted effort we not are two separate things right it's an extraction applies annuities or like that's an abstraction is actually it's an optional thing in any of the current in the current proposal okay I think the question was if the transaction a new transaction format would supersede this the the account replay security or the because you just said that new transaction format would yeah would supersede that it's an opportunity to do a bunch of things like one of them is it's an opportunity to do a kind of one time kind of like hard block where transactions before it clearly can't be replayed after it which could be using the resources to delete a bunch of accounts there's also we in theoretical Easton it's an opportunity to do a situation nonce mechanism though alternative leave and I mean if we want to could basically just change the format without doing any of that either any other comments and just one when one objection lay ahead on that is that there is always a chance that people would move their F to rap F for instance would not be affected by that and in the end if a lot of people do it then of course there's no dust cleaning there is no dust for just claiming for tokens and in the end we can have more we can use more of the memory of the state if you need contracts that would be no left improvement for the state so yeah I'm just saying it might be moving contracts yeah I don't think people would mind you know if the dust was clean because I think most of the dust is actually leftovers from people trying to move although all day or the ether out of their accounts but they don't use big uns in JavaScript so they cannot make some miscalculation with inaccurate numbers and it happens to be a few way over and they don't I don't think people actually care about that money sitting there I don't think they would take steps to protect a couple of hundred ways so that's just my opinion okay any other comments on that since there's not really agreement on this we'll just go on to the next one too for the purpose of time account abstraction here we go again so a cat abstraction is this something I think the last time we discussed what we kind of came to is that there would be a choice to be made between account abstraction and having resources and time spent on that versus on Kaspar and other similar efforts going into clients does everyone think that's still the case in which case account abstraction would be tabled I mean so if from one thing that is going to happen it is that it has abstraction or get implemented inside of the sharding system so the like in some ways regardless really it will exist in stuck in some clients and in some form and so if we want to difference for the main as well then at some point it would like be the the code would be basically most mostly written in that it's a little bit of time away yes like if we were to try to implement it really quickly for the next artwork then essentially there might like one what would mean we might need to but it is a fairly substantial undertaking right especially because of thing of things like minor strategies so but if we try to do it very quickly we won't get won't be able to get the benefit of piggybacking on that works it's been already done on the show I think side I see so what it's sounding like is we don't really want to put this in Constantinople especially if it's gonna be going into a shard or sharding personally I mean that definitely is what I what what I would win to word does anybody listen okay sorry but Alec you can continue yeah no I guess the main main reason to do something similar would be because like there's if there is some kind of urgent need for a specific warship for a specific application the critic advantage of abstraction but if some not to learn in my case there may also do some they may also be simple way supervisor or the needy kinds like here we simple clutches that just provided with option protocols mmm-hmm anybody else have any comments yeah it definitely sounds like this is something that would and I mean we heard Peters comments from last meeting and other people's comments so it sounds like this would be a substantial enough undertaking that it is not worth it for Constantinople but should be reassessed after Constantinople especially depending on where sharding is at that time okay so Piper I don't think was able to make it today but he says do we want a limited version of EIP 232 VIP 232 is a new transaction format CIP that was created about a year ago bimetallic to create two new types of transactions do you remember that one Vitalik and can you kind of comment on it to give it just a brief explanation superset of the early extraction proposal because i'm basically one when I was making the abstraction proposal and particularly when we were doing VJ chain ID replay protection for a beer so I do not be replayed to aetherium classic when we basically have to do a bunch of collages where like some variants some numbers will be set such as zeros in some cases like the V value DV purpose and a chain idea then the V value would be like the G and idea times 2 plus 27 plus you know I'm not signature bit and it got a bit too complicated so the idea was to just make a kind of Queen new type of transaction where you know the first number would always be the transaction version number which would be basically a transaction type the second value would always be the network idea then from there just an unlevel the transaction type is and the benefit is that this is just like way more forward compatible anything you might want to do in the future does this fall into account abstraction enough to where we really wouldn't be doing this in Constantinople as we've already kind of discussed well I can on abstraction as a convenience kind of time to do it at the same time because like if there's only one type if we're not adding any new transaction types then there's really no game that we're getting we're just kind of really jigging a transaction formats and not getting too much out of it whereas if we do it at the same time at the kind abstraction then it actually makes sense because they're like there is an actual huge transactions format for which it makes and so there's an actual reason why we need without having transaction version numbers and so forth and having this new sort of transaction meta format would actually make the this back for abstraction substantially cleaner and simple okay so we don't really need to put this in Constantinople it sounds like yeah cool anybody else have comments I think it sounds like a really good idea to have a versioning format for transactions so that's when we changed it long in the future it will probably be easier to make that change for add new performance I don't know if it's neither right now long but anyway it's like a good idea okay cool all right so now we're on the timing phase and it looks like the only things that we've really agreed on certainly is the IP 145 and that IP 210 is something that we need to work on some more but it's kind of seeming like it's going in the direction of being approved for the next hard fork so that's only 2 e IPS for the next hard fork which isn't bad but is there other things that we want to add potentially or is it better to just focus on Casper and sharding and some of the other things that clients need to integrate any commentary on this and others another thing we keep on the horizon is that like I know that at least one implementation and possibly mores looking at seriously upgrading the libraries this year is for the old en 128 curves which created you here like a large increase and if we know that most of the clients have done that then I think we really should consider a substantial reduction in the gas box of those awkward because right now and I'm basically Jason orcs and any kind of racing insurers anything in that category is like extremely expensive and if price of that goes down by let's even a factor of three then it would improve by usability quite a lot that will be like just right doctor we trivially I did take into our it's a hard work that's worth keeping on the horizon do we remember the actual numbers from the past benchmarks I mean how different clients compared to one another yes they're in a benchmarking repository the ethereum organization again find the link okay interesting so would that be something would that be decided in a core dev meeting and then clients would just start to implement it so basically I think from where this whole thing stems from is that we've been exploring on the swapping out our own BN 256 carbon plantation to an optimized one from actually from clouds there and with that we still have to swap out the curve so I don't know how much work that would be and how stable that will be so it's big question mark but essentially their performance is about eighteen times faster than our current implantation which means that if we can integrate that then from our perspective gas prices can go down significantly but again it depends as far as I know go was was the slower of the implantation so I'm kind of curious that if our implementation gets 16 to 18 times faster than how does that compare to the remainder of the clients do other clients have other similar benchmarks in that repository which which clients were covered in that Martin yes that was CBP and guess and parity but it's not necessarily using the same vectors test vectors in all cases I think death had the most comprehensive work dimitri from the etherium jteem do you have any comment on this or have you all performed any benchmarks related to this or think you might do a more efficient implementation we don't have such benchmarks we are benchmarking always but different tests we access to curiosity for example hype does support benchmarking stuff so we could also look into assembling a couple benchmarks and just running it against all the kinds I think it's a good idea who runs high right now or is there a group of people kind of keeping up with high so I think we mostly use hive during I mean before consume before hard forks and in between it's kind of just a snapchat no it's not it's wrong time I think it's a time but eat that snack and it's run 24/7 you said it's tied to F stats dotnet or not we're only running on consensus that's not benchmark hard test dot it's that's the net yeah it's only running consensus test there it's not running or PC Justin it's not running any benchmark tests I see okay so another to do would be to kind of start getting a benchmark for that B and the reason that we'd want to be doing this earlier rather than later is because if we can finalize the e IPS over the next say month then we can actually start planning a hard date for caught for the testing for Constantinople and then the actual implementation of Constantinople ones testing is done and I think that would be pretty good and if we're gonna go through the client update soon but that actually might correlate somewhat to some of the first steps of Casper so we can kind of prepare for all of this at once and clients can start having this on their road maps okay the next agenda topic unless anyone had any other comments on the previous previous stuff is test RPC protocol changes and so that is Dmitry from the testing team Dmitry if you want to explain yeah so I started to work on this new approach which will allow us to generate the consensus test from any client that implements this new RPC test methods and it's just an idea and I still need time to write this tool and see which actually which methods do I need in order to replace the current version of test it with a new one but you could start their discussions and then make your proposals so what kind of method how would they look like what would be better to cause a RPC protocol so we need to come up with a standard there are pc tests made us wish every client will implement and resource material generates in your tests okay thanks Dimitri anyone have any comments on that looks pretty clean to me okay item four talk about when we should start considering to implement a proof of concept or MVP of 6:48 easy paralyze ability who brought that one up oh that was yeah I was just interested in that ones in do you guys thought it was important enough to start considering compared to other other things that you're focusing on murder yeah and that's actually a similar one transaction type for 232 am i right the new transaction type is basically a cosmetic change whereas the ETP realisability thing actually involves deep changes to architecture and it involves very significant changes through a protocol guarantees because you can basically have just arbitrary function across contract calls fail if they go outside the access list it actually brings us back to a situation but I think it's equivalent to what we had before the tangerine whistle hard work when you when you could do a call stack depth attacks like I'm pretty sure that any attacks agrees with that with against them B but the kind of attacks that this the access what subscription lets you do is an exact same same sort of stuff that the kind of taxi be do a call stack death attacks so the account of the security countermeasures are exactly the same so I would and the deep changes are basically that you know the parts that involve actually paralyzing all the transaction execution in the accesses I mean I would say it definitely totally find her people to try implement implementing going imperious and what what kind of realistic how you would test it Asians with what realistic strategy review is for testing and what kind information you want together with that yeah that's what I was wondering too like what would be a good client to make a branch on and - I don't know what kind of benchmarks would you run - actually uh confirm that it's working one possibility would be to try to here's a fairly simple algorithm to adjust retroactively we assign access lists to every transaction in the District of Washington and then just on top of whatever claim should implement that and try to run 3d piracy in parallel and see what the speed-up is okay I couldn't miss some idea what was the call stack depth of text and I was that related to parallel eyes ability well the reason why they're also the cost object attack is basically when you um : when an attacker creates a transaction which calls a contract then the contract called results 10:23 signs of the contract called somewhat target contracts and then it started contract if it then tries it tries to call out for something else then all those calls fail because the call stack depth at is is too high so the caller the cost can succeed in the in any of the current paralyze ability proposals a transaction after specifying access lists and or an access said will range or some kind of restriction on what address they can affect in any attempt to read or write outside of that range leads to an immediate on the exception serious for that call so basically it's like it also lets you make a transaction which call some contract and if that project is going to call another contract and the a transaction might could just have that that second-degree call we be outside the access lists all of the internal fails so it gets basically the exact same kind of attack so it's no it does become a bit easier to set up because they don't need to do this in 23 def sculpt out or okay so it makes it so this is a concern I mean so if a contract isn't written correctly then it could potentially write some storage that it doesn't intend to because if it assumes that all of its calls always succeed then that would be the vulnerability yeah when basically the idea that with the paralyze ability proposals aim with the call stack depth limit you cannot assume that any call will actually succeed until you have to handle the case where tails and to be here was before we did the Santa Rita 104 which ended up just making the problems not not exist anymore we did come up with a bunch of countermeasures on the area of smart contract only level and black defense coding standards so let's do Italy surmountable okay so it sounds like this is something we need to explore more before the next quartet meeting the paralyzed ability is I mean it's definitely not something that's going to go into constantinople because this is it requires kind of large changes in our clients right so yeah definitely nice if someone else gets it but but the other thing about the EEP 648 is it until we know for sure the bottleneck about about disk i/o and how that can be optimized 648 is not really gonna improve you know it doesn't make it possible to increase the block cast limit on without some of the some of the other disk i/o optimizations like are being explored with turbo gasps mm-hmm so in my opinion the like the turbo guests disk IO optimizations are the most important to explore an experiment with prior to this parallel eyes ability stuff agreed I need very interested in the results of all of those desk over optimizations okay sounds good so it won't be going into Constantinople is what it sounds like let's see the next topic is e I P 96 is Paul still here yeah you brought up that topic did you say that no response from authors what do you mean yeah address already so no point to going back there it was about block block our CIP so we discussed that in this meeting oh you know I am the author of 96 and I probably didn't reply because I think we all consider is like IV ended it superseded by 210 but that's at least how I deserve any situation so far it's the same right it's 210 and it has 96 before so I'm referring to the same one so that's resting before about ok sounds good I'll put a note in that EW that basically it's superseded by 210 and we can close that one out okay next oh did anybody else have a comment cool client research updates let's start with parody offer your Yuda if you have a comment nope okay no problem guess I think you just had a major release if you want to talk about that a little bit or any other things you have comments on so I'm not sure in the context of what I'm eating yes we could release one eight zero and one eight one following your kind of happy that the live client is is again seemingly functional there are some rough edges and there are some bugs that we discovered but we're kind of happy with it with respect to this cord of coal I think the only thing that might be interesting is that we've merged in Martin actually implemented emerged in the bit shifting operation EIP I mean if the implantation so if anyone wants to write tests or once has or needs a client that has it have implanted them they can use gas thank you theory MJ / harmony we are currently working on the next release we spent a lot of time for it but it's it's better than some current master version we had large memory footprint on the premise week four gigabytes now we reduced it to one and a half and it has very stable but we found about with video systems wants to be a library is fallen on many videos missions and we need to fix this back until release we think we can do it in two weeks and as for Casper there we could do basic sync now I am debugging my milk and validator the courtesans place but test network was not stable only three terminals go ahead and does a part of network was attached now it looks better and debugging it I think we could participate in it on the next week great thanks for the update CPP etherium I don't think I have anything to show no new features finished so I always keep my turn EPC no update so I'm using CPP client to develop those new APIs images and then the test each tool is now separated from the CPP client and I will use this to generate the test we are air PC me this also needs this new repository called retest it is the one we shall be working on and and the current version of tested and supported by og in his fork of a city PCM reppin so we learn to remove the test it from CBP client and make it more simple okay thank you a theory is nope no updates on a theorem yes it's just maintenance mode and most of the theorems yes team members have been working on CPP aetherium lately for the he wasn't test net so yeah how is that you awesome test net and he was I'm going it's coming along we just have some bugs we're trying to make it you know doctor eyes create a docker container to launch the chestnut and planning a demo at that ECC the Paris conference great so I don't think Piper's here for pi a VM is there anyone else who can speak to the Python updates I can really briefly in kind of high-level on it so as I think everyone knows sharding had been had been work being worked on in a branch of pi vm flash I guess Trinity's the name we should be kind of using for this going forward so one thing that's happened is we decided to it was decided to merge that branch into the master on the grounds that none of the work being done in sharding should effect kind of the main IBM stuff anyway I think that's still a bit of a work in progress there's I've maybe a few conflict that need to be worked out there and I think the two big things that are happening right now on IBM and Trinity are the networking code that's definitely a work in progress and some asynchronous kind of fun with Python okay thanks Lane and then the talent could you speak on the research updates and specifically where we are with Casper and sharding and any implementations yeah so whispering I think that I believe aetherium J is close to being ready to having something tech net compatible and there's like one more round of charting protocol updates that we need to do at some point soon and we're kind of like zeroing in on the exact details of that on the sorting side of us over the last couple of years and compliance right over the last couple of weeks you can find a lot of it on research talking about specific charting designs and trying to figure out like what what makes sense to do first what's forward compatible with what and kind of charting the right path from me like one we senses with MVP what makes sense is like stage one and stage two so that we can both get kind of like reasonably good suitability I'll quickly but at the same time not like seriously delay these are the goal of getting like the stronger capabilities out as soon as possible as well so that's kind of being discussed a lot between myself and Justin and probably continue going forward cool and then charting that what starting oh yeah I know what Casper was just not like here is that numbers look swollen moving toward the last round of changes to expect at least before you know like anything like watching EE auditors suggest and the theory mga is moving in as I as I've been watch what your stand is pretty close to something that's like that compatible great are there any other updates from clients or research teams or projects okay great let's see actually Oh solidity I forgot that any other solidity updates Christian I think there was like a release recently your volume a little bit Christian it's hard to hear sorry there we go yeah we had a release recently and we will have one soon and I hope that this next release 0 for 21 will be the last before 0 5 0 we're adding tons of breaking changes and yeah I'm really confident we're making great progress in there in the last few weeks so but yeah it would be too complicated to get any teaches now okay no problem thanks everybody the next agenda topic and the last one is that FCC is in two weeks I've counted and about fourteen people who are usually on the core dev call are gonna be at FCC maybe fifteen if I'm including people who are attending but not giving talks so should we skip the next core dev meaning and just have it a month from now or do we want to have it in two weeks and just to have it with like limited participation we fail from doing three weeks I guess right push it back when we yeah we could we could do it in three weeks that problem is I don't like getting off schedule like that because then the cadence gets kind of weird but that's just to me if we want to have it in three weeks I'm perfectly fine with that what would you say Peter I missed that no so I was also saying that three weeks sounds more meaningful but it doesn't really matter so one month is fine by me yeah sorry who was commenting I was just saying waise fine it doesn't matter I'm bad at making decisions like this someone else make it for me is there any sense of urgency in the sense you know there's a hard for coming up we need you know like one week would make a difference I mean my guts telling me no maybe maybe different a month yeah I I agree yeah I think a month is good because yeah there's nothing that one week won't really do as far as decisions being made especially since we kind of do out a little bit closer to finding the EIP is out for Constantinople and eliminated some of the ones like account abstraction and 232 so okay cool I'm gonna say we're skipping the meeting in two weeks and we will have a meeting in four weeks anybody objecting sounds good sounds good oh all right I'll see most of you guys at SCC and thanks everyone for joining in and I will talk to you all in about four weeks if I don't see you in Paris [Music] [Music] [Music] [Music] [Music] [Music] 