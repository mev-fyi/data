okay cool guys yeah um I'm Carter I'm the CEO of qad uh yeah so today we're going to be talking a little bit about um you know how QED State model works and how we're able to horizontally scale our blockchain so just a little bit about me um really briefly like so I come more from the security and reverse engineering community um I also ran proof of stake infrastructure for a bunch of like PS chains like specifically EOS we were top 21 block producer for quite a few years process like 150 million transactions in in um unique transaction in production so uh yeah we've been building like blockchain infrastructure as well um I also built mod P which is like a Minecraft Pocket Edition like mobile version of Minecraft modding engine we had over 150,000 uh developers in our community and over 20 million installs across Android and iOS so touched a little bit in the web too uh ecosystem with that but uh yeah um let's talk about like uh serial and scaling and horizontal scaling and parallel processing and in general as as far as it goes with the L2 space um I'm sure a lot of here a lot of you guys here are familiar with L2 beat probably yeah um so like right now if we look at l2s I mean we are able to process more transactions than ethereum alone could but it's not some like exponential growth curve like we're not seeing like oh suddenly all of our blockchain scaling problems are solved I can build Twitter on ethereum right this is not this has not happened um and it's we're even like low one digits and you know you can probably see a lot of these guys are optimistic rups that do not have fraud proofs which you know is a little bit sketchy um but yeah so like with with non ZK projects it makes a lot of sense to have serial execution because every node needs to check the results of every other node and you know if uh one ethereum node detects that a transaction was you know like let's say failed report has a certain state if another ethereum node wants to know that you know this state should be as it is they have to actually execute those trans actions um so if you want to build a you know an L1 where you have lots and lots of people running full nodes then the actual sort of requirements to run the full node needs to be sufficiently low so that you can have lots of people running full nodes cuz as soon as you try to even if you like build a parallel State model with an L1 let's say I need a whole data center of computers to run all of the parallel transactions right not many people would run full nodes in that situation because it would be like prohibitively costly right so there's this like with non CK l1s there's this big trade-off where you don't even want the performance to be that fast because then it makes it harder to run a full node um and then you become less decentralized which is like the whole point why we did this in the first place right so adding more nodes doesn't increase um TPS it actually kind of lowers it a little bit because you know we have to make sure that everyone can keep up um but yeah like the reason why blockchains are serial I'm sure most of the people here are kind of more familiar with this like we have race conditions right I have two transactions that try to access the same state slot like you can imagine if I send money to two different people and then someone also sends money to me at the same time um you know the rights that we're making to my balances in like an erc20 contract are not Atomic so you know everyone like each of these transactions uh if we run them in serial it will operate correctly but if we run them in parallel like each of them have different results about what the end contract State should be so yeah because of this raise condition you can't really parallelize some projects have tried to do like workarounds basically checking to see roughly like which state slots each transaction is is is doing and then later like so first I execute them all in parallel and then I see if there's any conflicts and then retry again there have been a few attempts in this area like you could also like try to use some like sort of modern acid database um like principles who try to do it but no one's really figured out it hasn't really worked um so yeah uh but then there's of course the question is like can we do better than this because right now the the limiting factor on you know blockchain uses is just that transaction space is scarce and that's why transactions are expensive right um like bidding for gas is the reason why you know you have to pay um so is there any is there any better that we can do than this and the answer is yes so if we if we um yeah so we have a new state model that we use on QED uh specifically for each user we have a separate um contract state tree for um the given user so you can imagine if there's a token contract every user will have a separate state tree um for that token contract and then um we have a tree which uh contains the um specifically the the the hash of verifier data for a bunch of zero knowledge circuits that are allowed to authenticate updates to each of the the contract trees and then as a user when I'm transacting I'm able to read from the other users you know contract State trees as they were at the end of the previous block so when they're already finalized but I'm only able to write to my own so you can imagine that transfer looks something like I burn X number of tokens in you know Tony's name and then in the next block Tony can like prove that oh I've burned these tokens in his name and he can now Min them for himself so uh we also have like multi-user interactions so we have a thing called covenants the way that works is essentially I say okay if um you like I burn these tokens for you and if you claim them you must also do these three transactions right so we can still have these sort of complex multi-user interactions um we also have you know some bot users that allow us to do also like pretty inherently serial things like build amm and Order books but um this is just kind of like a little bit of an overview there um but yeah because we've separated the users like what users are able to to write to um yeah we can uh batch or we can rather um yeah let me just show you the animation yeah so um users prove their transactions locally because we know for a fact that no one else can write to their users state tree um since you know it's confined to themselves so um the users prove a state transition on like specifically this node here so you can imagine that each user has one tree of trees and each of the sub trees is like a contract state tree and so as a user what I'm locally proving is that my contract State tre's Route has transitioned from certain route to a new route right and then I generate a series of proofs each of these proofs are going to recursively verify contract function proof that's defined by your original function the proofs that are allowed to be used to authenticate like contract state tree roots to be updated are stored in the leaves of this contract function tree so you can imagine we have over here a circuit which is going to recursively verify that contract function proof which shows that okay this contract state tree has mutated from a certain state to a new state and this is this circuit here is also going to check to ensure that that proofs verifier data is in the white uh like the the whitel list tree or the hash of verifier data is in the whel list tree for that particular contract so if we're trying to modify the nth contracts State trees route for a user we also must have a um a proof along with it that has verifier data which is in the nth oops that is in the nth contracts um contract function tree so these leaves index the the contracts um for their like specific white lists and then uh these lives uh index the contracts for the users index one in One Tree is the same as index you know one in another tree so so yeah and then we eventually generate um a single proof of you know all of those uh different uh transforms that I've done on the user's uh State Route and we end up with a succinct endcap proof um that basically shows okay this user's State Route has legally transitioned from State Route a to State Route B and then we send the proofs off to the network so each user has one proof no matter how many transactions they've done we send that proof along with all their state Deltas to our decentralized proving Network decentralized proving Network are going to do a series of 4 to one operations in the animation it's doing two to one but you can imagine like you have one proof which recursively verifies two proofs along with um associated with Delta Merkel proofs that prove the um like in the case of it being just the the end caps from the users from the users like Leaf roots or the the rather the leaves over here so you can imagine like this is all of the users in the chain right we first have a proof that takes these two users proofs along with the Delta meracle proofs that link them to their nearest common ancestor Merle cap and we verify the proofs and then generate a new proof which proves up to a certain Merkel cap and then we can continue to do this process for all the users in the block until we have one succinct proof for all of the transactions that occurred in the block and the great thing is we can do this process in parallel specifically we get Block times of O of log base 4 of N and the the 4 to1 proof process takes 400 milliseconds so you can do like a million users in 6 seconds and we've done this on AWS and it works so we're very happy about that but yeah so you can you can scale it quite easily proof size 30 kilobytes um yeah proving time is 35 seconds like and this is on my like MacBook we have an iPhone like we have mobile sdks right now only iOS because like we've partnered with a lot of like game companies um we actually just uh announced our partnership with we in like the unity accelerator so hopefully some more official Partnerships there but um yeah like uh on my laptop which is a old M1 um it's like 35 seconds so yeah if it takes like let's say 0.1 second to send a 30 KOB proof to the next person then yeah you can get 223,000 TPS with 1 million people participating in the block um the other thing is so we've separated our data availability miners from the the provs because in order for you to get these fast block times you have to have a lot of provs right so the great thing is like we we have data availability miners who are keeping the data available by just they have like a random challenge where they have to prove like um a certain random Leaf within a larger state tree they have to give a Merkel proof the which index it is um is determined by like a pseudo random number that's the same for everyone and then they hash that along with their user ID so we get like specifically for each user um but the great thing about that is that in order to prove your transtion locally and to participate in this 4 to1 proving you don't have to have a copy of the entire state tree so you can do it on your phone you can do it the people that are submitting the traction transactions can also participate in the proving um and there's no like trust or or you know anything in in uh um there's no like real uh there's no real like uh requirement to um barrier entry to to to uh um yeah participate so yeah we want uh normal people mining not just the the mining teams the mining teams can do the data availability but yeah um the great thing about that is we got one gas fee for unlimited transactions now you do have to pay for your state Delta so you can imagine that if I am making a bunch of transactions which are mutating like the same few State slots then I can save some money right but if I'm just adding more and more State slots you still got to pay if you you know storing a bunch of data to chain but the actual number of transactions that you're running doesn't affect you know the price you pay because the proof size is the same and you're proving it locally so it just means that you're going to spend more time you know executing locally but uh these contract function proofs it takes like generally these take about 80 milliseconds and then these like double recursive proofs take like 190 to 200 um but we are we're working on like improving our our Pro but uh yeah so like we're running um uh like it's it's 100 bits of fry so we're like um we're we're we're trying to make everything very ENT secure we could make things a lot faster if if we we took some shortcuts but um we know like we have to make sure that uh especially if we're we're not doing like centralized Pro that that everything is you know AOK up to spec but yeah so um the talic actually recently in a modular Summit showed this diagram which was very re reminiscent of what we're building so we're very happy that more people are getting on the uh the tree recursion bandwagon but the real important thing is that um in order to take advantage of this kind of parallel proving you need to have a state model which matches the topology of your proving so if you're proving in parallel you want to make sure that at each step when I'm doing the recursive verification I'm also doing an Associated Delta Merkle proof and you need to design your state model around that and that is like the cost of being horizontally scalable is you need to have this like very hard State isolation um otherwise you have you would have to implement like that sort of back off logic that some of the other parallelizable blockchains are doing in ZK which is probably not feasible um but you don't really need it uh it's pretty easy to build applications um we also support like I can just I know I've talked a a lot but um yeah like this just kind of goes through some of the things how I think everyone pretty much gets the idea um I can show you guys how we build contracts so we also support um JavaScript typescript and python um I can show you guys how like we can type up a real quick contract and compile to circom or like a circuit diagram if you guys are curious um I don't know like I've talked a lot I apologize uh we have programmable public key cryptography so public keys on QED are actually it's like that hash of verifier data for um some arbitrary circuit and then when I want to give a signature I just have to generate a proof which has public inputs that correspond to like the message that I'm signing as well as some contextual information about the state of the chain great thing with that is that you know if I want to make it QED compatible with ethereum signatures I just write an secp 256 K1 verifier in my circuit right verify in order to like sign transactions on QED I need to provide a um ethereum signature for this you know let's see public key right but you can also make like bot users lots of fun stuff um this kind of goes into random things yeah does anyone have any questions do you want to see a JavaScript contract yeah we can see that and then jump through questions Okay cool so here we have some like voting Ty maybe we should make something a little bit simpler so over here we have like an ABI format that um we should Define like the state and all the functions for the contract because we support JavaScript in Python and hopefully more languages in the future so there needs to be some kind of common calling convention in state layout um formatting uh actually we could see an example over here of like what like your state definition can look like so you can imagine that um we have some functions and uh yeah we can like address different um it basically takes like some State structure and converts it into the minimum bounding Merkel tree so that for any like this is what's use for the programming language is when I do like this do state do something do something it converts it into like a Merk lookup right so um yeah anyways I can make just really quickly okay so um yeah so here we have a simple voting contract it takes in like some different votes and it's going to Output a result so if you see like if I go over here let's remove this constraint for now and go age I don't know 28 1 9 22 12 if I go over here and I click compile contract I can then call so we can like you know test out the contract in the browser much uh much the same as something like remix however we also support um like browser debugging so I can go in here and as we can see like right now the results it's I don't know if you guys can see it clearly now I guess you can um we can like you know I know like for a lot of web 2 developers this may seem quite normal but if you've ever tried to debug a solidity contract you probably know that the solidity debugging experience is subpar um but uh yeah so we have debugger um in addition we can um uh generate a like circuit diagram for this particular this is going to be a big circuit diagram but uh this just shows like the arithmetization for our JavaScript code um maybe I should make a simpler one so that we can see exactly like what's going on give me a second uh compile all right let's see what are we returning some result change this let's have one output okay let's just make sure this is working should return one if I do that okay so I can do something like I don't know let's say let sum equals zero I don't know numbers. for each X I don't know like sum Plus or equals X and then I can return some and if we then compile and generate a nice circuit diagram ah we can see what's what's going on so as you can see it's summing up the numbers right um we can also generate like circum code I can make it more complex like let's say I want to do I don't know like some function hello turn I don't know x * y + 3 or let's say like I don't know if x equals let's just make it simple for now know hello x two three F compile and click latex circuit diagram as you can see yeah so it can handle like very very complex um like you know JavaScript programs it's anything that works in es6 that's not non-deterministic we currently support so like the ecma script like main unit tests um are working uh we don't support floating points right now uh but uh all the ecma like the ecma like script official unit tests that aren't floating point or non-deterministic are currently running um for JavaScript functions like you can imagine you have a for Loop where the number of iterations is like is dependent on the number of um or is dependent on the inputs to the function so you can imagine like um I have some function which takes an input of X and for you know I equals z like K is or I is less than um X we would have an indeterminate indeterminate number of constraints so for that our our our like highle um constraint language actually allows us to have like Loops in constraints so you can imagine that it has some like notion of uh permuting a function or iterating a function among on itself multiple times um so like for those kind of I guess uh if if those features are used in our high level constraint language then we compile to like our own little VM that's written in Starkey uh we also will very soon have mid in VM bite code support um so can imagine that going through those constraints you basically just like walk from the like um you do like a depth first walk um of like one of these constraint trees um in myvm instructions then you get the correct answer at the end um but uh yeah for um if you don't have any of those then uh yeah we compile currently you can Target R1 CS um uh plunky 2 and uh circom like generalized circom so so yeah that's uh QED I've talked a lot um if anyone has any questions please let me know otherwise yeah sure beautiful open up for questions I guess okay yeah question um you had a slide on bic's ideal um architecture for scalability blockchain could you maybe give a brief description of that and compares to what you're doing so um vitalic didn't actually talk that much about the scaling end he was more talking about having one synced proof for all of the activity that has occurred which we do which we do Implement so at the end of a QED block you get a single proof which recursively verifies the previous block proof and recursively verifies the proof from those those you know user operations that took place so you get all the transactions in the proof as well as the contract deployments and external events that we register on QED so uh yeah but he wasn't necessarily saying that just for like Flow full disclosure he wasn't saying like oh you should use a state model that like mirrors you know the hierarchy of your proof tree no that's that's what we're doing but um yeah yeah I got one question sure so I was wondering about the da providers in Q so basically the way to verify that data is available in their know like guess is to we give them like the very bottom leave and ask them to return the result exactly and then so but however it does not mean they cannot um basically turn away historical data so you you basically have to keep whatever has been there so currently the data of availability nodes their challenges will be are guaranteed to be from the past 10 blocks okay um and the reason why we do that is because technically as a local prover I don't have to be synced or proving a local proof chain that's sync to head right as long as I don't go backwards in time so if we in our diagram I guess it's not there we store like which is the last block that the user participated and then there's also a nons so you so I don't have to know about the rest of the world technically at the current block got the but we would expect the users to upgrade to the latest head after some period of time right but giving that that sort of flexibility of 10 like allows users not to have to like quickly submit off their proofs their proof chains whenever a new block begins right okay so basically we um doesn't care about whatever happens before the previous 10 blocks I mean you could so we do have like a full history solution if you want it but you know you don't have to MH but um for the data availability notes the main thing is like we have like a commit reveal process that generates a pseudo random number and that's actually done by the people that are participating in like the actual like um decentralized proving Network um and so they they they end up with a pseudo Ram number via like commit reveal or hash commit reveal exor um and then this like value is used so you hash this Value Plus your user ID and that generates the random number which directs you to the correct challenge um that you have to commit as a dat availability Miner and you could not do the data availability mining task you just don't get paid anything if you don't do it so M I was wondering if we can if we're able to implement something like the like cine for the DAT Solutions so so that um we can have you know a number of users checking on the providers probably could um another thing that that we're thinking so this this also comes up because um let's say I'm local proving right I don't have a full copy of the of the of the state why will the data availability providers provide me this this State information right now it's like why do ethereum nodes give you like why are you why do they respond with the correct answer right um there may be some way to to put to incentivize this Behavior or to have the portion of the user's final gas fee go to the person that provided them with proofs um yeah like once we launch our testet we're going to be exploring a lot of those things but uh yeah I mean for the right now we just have them generated zero knowledge proof that the Merkel the like you know okay I provided the correct Merkel proof with this like you know pseudo random number and then that's included as part of like the decentralized proving so we we all have like one group of people doing this like standardized task which is nice but uh yeah there's definitely a lot of other approaches we could look at yeah definitely so so it seems like our data providers still be more like segregated serving different users because different correct one user only care about their own they don't care about the entire correct yeah um we're we're thinking about ways to to work around that like you could apply like I mean you you could swap every now and then I guess or as part of the the as as you're moving up when you update if two users next to each other like are are on different branches you could probably swap them over I don't know it would make things quite complicated but if we want if we have to there are sort of ways to to go about doing that um but then you have some consistency issues with like the way that the apps track users like user ID so and so which ID does it actually math to um so yeah Food For Thought yeah any other questions sorry for talking so long no worries um I guess we love that and um thank you Carter cool thanks 